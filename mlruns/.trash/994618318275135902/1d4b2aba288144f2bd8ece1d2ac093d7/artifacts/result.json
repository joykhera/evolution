{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.020489248012503, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.841505891208848, "policy_loss": -0.026077500819034562, "vf_loss": 4.864421382298072, "vf_explained_var": -0.0017543299744526544, "kl": 0.015809973179145204, "entropy": 1.5934241324663163, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 480.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5314884259240001, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.7862261726606822, "policy_loss": -0.008134570596359855, "vf_loss": 0.7925357770993777, "vf_explained_var": 1.402074563587811e-05, "kl": 0.009124806763571178, "entropy": 1.6004543242725076, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 1410.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 4000, "num_env_steps_trained": 4000, "num_agent_steps_sampled": 16000, "num_agent_steps_trained": 16000}, "env_runners": {"episode_reward_max": 73.69677158074096, "episode_reward_min": -100.98478321155719, "episode_reward_mean": -5.5247664522024005, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 153, "episodes_timesteps_total": 3825, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -100.98478321155719}, "policy_reward_max": {"adversary_policy": 40.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 3.3333333333333335, "agent_policy": -15.524766452202403}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-12.579995866610702, -35.12583045426368, -32.52680067046425, -46.48740725657264, 0.0, 0.0, -4.625882517926883, 0.0, -9.946391868099356, -25.52513549171381, -42.42571448611438, 0.0, 60.0, -19.61493539986053, 0.0, -24.541661814122154, 73.69677158074096, 0.0, -23.555156793204752, 40.0, 0.0, -24.567436934975998, -85.64117140309398, -5.317919821576792, -5.961250730112961, 0.0, 0.0, -9.286517016200678, 0.0, -32.015260674599276, -7.810428043344958, 0.0, -8.807830729398058, -3.6535178215572897, 0.0, 0.0, -0.6351525045247908, -17.803169902626887, -57.30823969226707, -7.404526996144675, -12.375186746091668, 0.0, -1.6172902738030792, -2.3885318296765377, 0.0, -11.711019329326248, -16.550193384384094, 0.0, -17.023855372350777, 0.0, -62.175128201647546, 0.0, -11.766022583748414, 60.0, -1.277595489461868, 0.0, 0.0, 32.76377614929767, 0.0, 40.0, -2.6003857193319, -42.46093487503017, 52.54148013746982, -8.969371516301148, -10.609718446311142, 19.750042697787926, -20.523139037797485, 0.0, -32.96331732246442, 0.0, 0.0, 0.0, -14.672429212689961, 0.0, 0.0, 58.63733879630321, 0.0, -2.8081486816647443, 0.0, 0.0, 0.0, 13.122795928457322, -70.37244973749826, -0.2113319960614346, 0.0, -15.439162465348305, 57.987389926700175, -52.92277286254168, 0.0, -8.374373666947344, 0.0, 0.0, 0.0, -9.049584574575302, 60.0, -58.24172545377545, 0.0, -35.85165600742947, 0.0, -28.636189772560066, 0.0, -6.853819614889576, -23.024733563779474, 0.0, -23.044340274945647, -13.028641480131363, -10.133841002435673, 0.0, 8.474402951355719, 0.0, 0.0, -20.113702053123873, 0.0, 0.0, -4.820131741598985, 0.0, -20.024266919875167, -4.5983349087512275, -2.5651646064524725, -23.54587857934014, 0.0, 0.0, -20.976788605696335, 0.0, 60.0, -46.44679539111076, 60.0, 60.0, -30.914493647801034, -30.703859246248648, -34.459684579998914, 0.0, -2.2844881272882325, 0.0, -26.971274541175614, -13.434074593872706, 60.0, 0.0, -62.79009958655963, 40.0, -17.232373689025163, 0.0, -44.1293918151856, -0.37546355145383625, 0.0, -100.98478321155719, 0.0, -0.5100893001413753, -0.06648798148079837, -19.314898529378567, 0.0, -44.156514763587126, 40.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0], "policy_agent_policy_reward": [-12.579995866610702, -35.12583045426368, -32.52680067046425, -46.48740725657264, 0.0, 0.0, -4.625882517926883, 0.0, -9.946391868099356, -25.52513549171381, -42.42571448611438, 0.0, -30.0, -19.61493539986053, 0.0, -24.541661814122154, -46.303228419259035, 0.0, -23.555156793204752, -20.0, 0.0, -24.567436934975998, -85.64117140309398, -5.317919821576792, -5.961250730112961, 0.0, 0.0, -9.286517016200678, 0.0, -32.015260674599276, -7.810428043344958, 0.0, -8.807830729398058, -3.6535178215572897, 0.0, 0.0, -0.6351525045247908, -17.803169902626887, -57.30823969226707, -7.404526996144675, -12.375186746091668, 0.0, -1.6172902738030792, -2.3885318296765377, 0.0, -11.711019329326248, -16.550193384384094, 0.0, -17.023855372350777, 0.0, -62.175128201647546, 0.0, -11.766022583748414, -30.0, -61.277595489461866, 0.0, 0.0, -27.23622385070233, 0.0, -20.0, -2.6003857193319, -42.46093487503017, -67.4585198625302, -38.969371516301145, -10.609718446311142, -10.249957302212074, -20.523139037797485, 0.0, -32.96331732246442, 0.0, 0.0, 0.0, -14.672429212689961, 0.0, 0.0, -31.36266120369679, 0.0, -2.8081486816647443, 0.0, 0.0, 0.0, -16.87720407154269, -70.37244973749826, -0.2113319960614346, 0.0, -15.439162465348305, -32.012610073299825, -52.92277286254168, 0.0, -8.374373666947344, 0.0, 0.0, 0.0, -9.049584574575302, -30.0, -58.24172545377545, 0.0, -35.85165600742947, 0.0, -28.636189772560066, 0.0, -6.853819614889576, -23.024733563779474, 0.0, -23.044340274945647, -13.028641480131363, -10.133841002435673, 0.0, -21.525597048644286, 0.0, 0.0, -20.113702053123873, 0.0, 0.0, -4.820131741598985, 0.0, -20.024266919875167, -4.5983349087512275, -2.5651646064524725, -23.54587857934014, 0.0, 0.0, -20.976788605696335, 0.0, -30.0, -46.44679539111076, -30.0, -30.0, -30.914493647801034, -30.703859246248648, -34.459684579998914, 0.0, -2.2844881272882325, 0.0, -26.971274541175614, -13.434074593872706, -30.0, 0.0, -62.79009958655963, -20.0, -17.232373689025163, 0.0, -44.1293918151856, -0.37546355145383625, 0.0, -100.98478321155719, 0.0, -0.5100893001413753, -0.06648798148079837, -19.314898529378567, 0.0, -44.156514763587126, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7193624410362695, "mean_inference_ms": 1.2589016935494235, "mean_action_processing_ms": 0.25922047179113783, "mean_env_wait_ms": 0.5391949524757218, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004886723811330359, "StateBufferConnector_ms": 0.004482970518224379, "ViewRequirementAgentConnector_ms": 0.09664873671687506}, "num_episodes": 153, "episode_return_max": 73.69677158074096, "episode_return_min": -100.98478321155719, "episode_return_mean": -5.5247664522024005}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 16000, "num_agent_steps_trained": 16000, "num_env_steps_sampled": 4000, "num_env_steps_trained": 4000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 291.4060685466068, "num_env_steps_trained_throughput_per_sec": 291.4060685466068, "timesteps_total": 4000, "num_env_steps_sampled_lifetime": 4000, "num_agent_steps_sampled_lifetime": 16000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 16000, "timers": {"training_iteration_time_ms": 13726.558, "restore_workers_time_ms": 0.018, "training_step_time_ms": 13726.512, "sample_time_ms": 1330.963, "learn_time_ms": 12381.979, "learn_throughput": 323.05, "synch_weights_time_ms": 13.061}, "counters": {"num_env_steps_sampled": 4000, "num_env_steps_trained": 4000, "num_agent_steps_sampled": 16000, "num_agent_steps_trained": 16000}, "done": false, "training_iteration": 1, "trial_id": "b72b3_00000", "date": "2024-08-08_15-31-19", "timestamp": 1723145479, "time_this_iter_s": 13.738584280014038, "time_total_s": 13.738584280014038, "pid": 98177, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b8698790>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 13.738584280014038, "iterations_since_restore": 1, "perf": {"cpu_util_percent": 44.545, "ram_util_percent": 82.52000000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9671663117284576, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.557022899140914, "policy_loss": -0.02725378859274012, "vf_loss": 3.5810244063536327, "vf_explained_var": -0.0005089269950985908, "kl": 0.01626137685868438, "entropy": 1.56186396976312, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 1440.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5442042660258763, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.8635478778722439, "policy_loss": -0.008404539282853113, "vf_loss": 0.8700876531343088, "vf_explained_var": -4.6368609083459735e-05, "kl": 0.009323751101934397, "entropy": 1.5821320423843168, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 4230.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 8000, "num_env_steps_trained": 8000, "num_agent_steps_sampled": 32000, "num_agent_steps_trained": 32000}, "env_runners": {"episode_reward_max": 100.0, "episode_reward_min": -132.56616728349266, "episode_reward_mean": 1.1791292685929302, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -132.56616728349266}, "policy_reward_max": {"adversary_policy": 60.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 5.0, "agent_policy": -13.82087073140707}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, -19.796949015108936, -34.51819789985103, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -4.155076809539026, 20.0, 0.0, -53.24978119222213, 0.0, -0.35258502945799575, -4.359164090398407, -0.20691291194394834, 0.0, 0.0, -42.633356866222705, 43.18068298443637, 0.0, 0.0, 0.0, 0.0, 0.0, -28.29443521410831, 20.0, 0.0, 56.86576964660666, 0.0, 0.0, -25.03330938781539, 0.0, -34.011020785592905, 0.0, 0.0, -0.2118590235520701, 40.0, 0.0, -0.7390132203756516, -2.127475345701039, 0.0, -0.3630031307264925, 0.0, 60.0, 76.9233575205252, 0.0, -17.432549348872044, -19.97863454492054, 0.0, 0.0, -11.064571440280439, 0.0, 57.739790508757515, -25.548787645941236, 80.0, 20.0, -7.88129949573056, 0.0, 0.0, 0.0, 97.57056999441774, -44.14170439838107, -3.4129983349869395, -1.96707792666027, 59.85381005440482, -19.11566809913147, 0.0, 0.0, 0.0, -8.763687401577982, 0.0, -27.22215765543674, 0.0, -0.06760934211708758, -0.6691541967394776, 17.91012930031015, 40.0, 0.0, 39.192205016011854, 24.317395213208226, 100.0, -15.204979054475912, 0.0, -25.549149104371708, 0.0, 0.0, -5.457379802215158, 0.0, 0.0, -132.56616728349266, 0.0, 0.0, -44.79545441696206, -20.433361899956918, 37.605498279116276, -0.47899147444664836, -10.387752548519229, 0.0, -17.895797013316226, 0.0, -5.63396097944354, 0.0, -19.91026738160044, 0.0, 20.0, 0.0, -16.13663737758968, 0.0, 0.0, 0.0, -8.05143442709499, 0.0, 19.484789881387197, 0.0, -15.323409812799909, -14.420581113554464, -16.77795369489513, -26.347445790447942, 2.718784954919319, -13.239223725674266, -29.86210740395324, -13.564470005859667, 0.0, 0.0, -46.865846571664086, 60.0, 0.0, -21.520453229137196, 0.0, 0.0, -0.8627598711853257, 38.99977053331194, -2.9634950250147987, 0.0, 0.0, -81.45160373561939, 54.523222163636675, 38.529061202907734, 40.0, -2.610607748389753, 0.0, 0.0, -43.370019623928435, 0.0, -1.0764112698664707, 0.0, -24.368454289999057, 0.0, -1.7619673522477015, 40.0, 60.0, 38.94352025901557, 0.0, -39.04554286675789, 0.0, 0.0, -9.478857917181843, -8.608832435864933, 0.0, 60.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0], "policy_agent_policy_reward": [0.0, -19.796949015108936, -34.51819789985103, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -4.155076809539026, -10.0, 0.0, -53.24978119222213, 0.0, -0.35258502945799575, -4.359164090398407, -0.20691291194394834, 0.0, 0.0, -42.633356866222705, -46.81931701556364, 0.0, 0.0, 0.0, 0.0, 0.0, -28.29443521410831, -10.0, 0.0, -33.134230353393335, 0.0, 0.0, -25.03330938781539, 0.0, -64.0110207855929, 0.0, 0.0, -0.2118590235520701, -20.0, 0.0, -0.7390132203756516, -2.127475345701039, 0.0, -0.3630031307264925, 0.0, -30.0, -43.0766424794748, 0.0, -17.432549348872044, -19.97863454492054, 0.0, 0.0, -11.064571440280439, 0.0, -32.260209491242485, -25.548787645941236, -40.0, -10.0, -7.88129949573056, 0.0, 0.0, 0.0, -82.42943000558226, -44.14170439838107, -33.41299833498694, -1.96707792666027, -30.146189945595182, -19.11566809913147, 0.0, 0.0, 0.0, -8.763687401577982, 0.0, -27.22215765543674, 0.0, -0.06760934211708758, -0.6691541967394776, -12.08987069968985, -20.0, 0.0, -20.807794983988142, -35.682604786791785, -50.0, -45.20497905447592, 0.0, -25.549149104371708, 0.0, 0.0, -5.457379802215158, 0.0, 0.0, -132.56616728349266, 0.0, 0.0, -44.79545441696206, -20.433361899956918, -82.39450172088377, -0.47899147444664836, -10.387752548519229, 0.0, -17.895797013316226, 0.0, -5.63396097944354, 0.0, -19.91026738160044, 0.0, -10.0, 0.0, -16.13663737758968, 0.0, 0.0, 0.0, -8.05143442709499, 0.0, -10.515210118612803, 0.0, -15.323409812799909, -14.420581113554464, -16.77795369489513, -26.347445790447942, -87.2812150450807, -13.239223725674266, -29.86210740395324, -13.564470005859667, 0.0, 0.0, -46.865846571664086, -30.0, 0.0, -21.520453229137196, 0.0, 0.0, -0.8627598711853257, -21.000229466688065, -2.9634950250147987, 0.0, 0.0, -81.45160373561939, -35.476777836363325, -51.470938797092266, -20.0, -2.610607748389753, 0.0, 0.0, -43.370019623928435, 0.0, -1.0764112698664707, 0.0, -24.368454289999057, 0.0, -1.7619673522477015, -20.0, -30.0, -21.05647974098443, 0.0, -39.04554286675789, 0.0, 0.0, -9.478857917181843, -8.608832435864933, 0.0, -30.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7360638203309025, "mean_inference_ms": 1.2433725083276985, "mean_action_processing_ms": 0.25372860419377463, "mean_env_wait_ms": 0.5269643697256812, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0078052650263280045, "StateBufferConnector_ms": 0.004306766721937392, "ViewRequirementAgentConnector_ms": 0.12059822494601026}, "num_episodes": 162, "episode_return_max": 100.0, "episode_return_min": -132.56616728349266, "episode_return_mean": 1.1791292685929302}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 32000, "num_agent_steps_trained": 32000, "num_env_steps_sampled": 8000, "num_env_steps_trained": 8000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 308.510955013643, "num_env_steps_trained_throughput_per_sec": 308.510955013643, "timesteps_total": 8000, "num_env_steps_sampled_lifetime": 8000, "num_agent_steps_sampled_lifetime": 32000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 32000, "timers": {"training_iteration_time_ms": 13346.036, "restore_workers_time_ms": 0.015, "training_step_time_ms": 13345.985, "sample_time_ms": 1309.081, "learn_time_ms": 12023.743, "learn_throughput": 332.675, "synch_weights_time_ms": 12.574}, "counters": {"num_env_steps_sampled": 8000, "num_env_steps_trained": 8000, "num_agent_steps_sampled": 32000, "num_agent_steps_trained": 32000}, "done": false, "training_iteration": 2, "trial_id": "b72b3_00000", "date": "2024-08-08_15-31-32", "timestamp": 1723145492, "time_this_iter_s": 12.977946043014526, "time_total_s": 26.716530323028564, "pid": 98177, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b8698a60>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 26.716530323028564, "iterations_since_restore": 2, "perf": {"cpu_util_percent": 40.20526315789474, "ram_util_percent": 82.64736842105263}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1592573383823037, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.3596160752077897, "policy_loss": -0.016058587429870385, "vf_loss": 3.3733271243671576, "vf_explained_var": -0.006715979489187399, "kl": 0.01173768979104303, "entropy": 1.5423310245076816, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 2400.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5976817517944262, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.25987641247029, "policy_loss": -0.009472112736889906, "vf_loss": 1.2672875300049782, "vf_explained_var": 8.26460672608504e-06, "kl": 0.01030471284655808, "entropy": 1.5658398330634367, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 7050.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 12000, "num_env_steps_trained": 12000, "num_agent_steps_sampled": 48000, "num_agent_steps_trained": 48000}, "env_runners": {"episode_reward_max": 120.0, "episode_reward_min": -58.402845210973716, "episode_reward_mean": 6.754771928251241, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -81.18536211535749}, "policy_reward_max": {"adversary_policy": 60.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 6.172839506172839, "agent_policy": -11.763746590267278}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, -3.538732708066913, 60.0, 40.0, -0.12992064465780717, 80.0, -23.90050133619768, 40.0, -53.065495464848595, 0.0, 60.0, -30.90769229084485, 0.0, 60.0, 0.0, 0.0, 20.0, -29.608748376422202, -3.5400321953713796, 40.0, -5.322868542620077, 39.32677468053677, 0.0, -15.901291748545955, -15.72923688032134, 60.0, -2.5786470446031764, 0.0, 0.0, -18.543429845456643, 40.0, -0.5190943071881693, 0.0, -18.07696426732735, -27.965540011571747, 0.0, 40.0, 0.0, -15.97748243508122, 0.0, 0.0, -36.61455753642862, 58.209011846117896, 37.04601503349155, 0.0, 0.0, 0.0, -30.55193974400041, -28.441127182642, 0.0, 0.0, 0.0, -3.8759068051847945, 0.0, 0.0, -0.14218711897823533, 0.0, 0.0, 0.0, 0.0, -0.08154721021957578, -2.3191553969337155, 53.09205970269543, 0.0, 0.0, -12.014873315020878, 40.0, 0.0, -3.5004529604644237, -33.59969406771958, 0.0, -58.402845210973716, -16.158693386455752, 0.0, 60.0, 0.0, 0.0, 0.0, -10.173844427024855, 40.0, -15.463259879725562, 0.0, 49.9501579660122, 37.880271976878475, -28.70318419390567, -0.2170828653711021, -5.268454578522171, -14.84059365138807, -4.2438946686099275, 0.0, 0.0, 0.0, -10.634564126634164, 61.10841193681094, 39.57157928846133, -1.3821661906754779, 40.0, -20.113308264663466, -4.248456589305675, 0.0, 0.0, -21.38566592581056, 120.0, 40.0, -1.156267020198689, -4.434465590566962, 17.435727844574455, 0.0, -3.537143424340837, 35.15675555074189, -4.492342311805293, -0.6570260518055071, 0.0, 0.0, -1.640624950020314, -3.1934832776085145, 0.0, 40.0, 0.0, 40.97167569967314, 40.0, 12.51480590978884, 0.0, 60.0, 0.0, 0.0, 0.0, -1.9715262865104, 0.0, 0.0, 0.0, 0.0, 54.69921365799276, 40.0, -21.18536211535749, 40.0, 0.0, 60.0, 0.0, -0.19283508328472143, -0.07893441802890644, 0.46524987430345655, -21.030575964374457, -1.102760605342491, -17.447893914757806, -18.314859149318913, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -5.173075276776182, -9.862349755497018, 0.0, 80.0, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [0.0, 0.0, 0.0, -3.538732708066913, -30.0, -20.0, -0.12992064465780717, -40.0, -23.90050133619768, -20.0, -53.065495464848595, 0.0, -30.0, -30.90769229084485, 0.0, -30.0, 0.0, 0.0, -10.0, -29.608748376422202, -3.5400321953713796, -20.0, -5.322868542620077, -50.67322531946323, 0.0, -15.901291748545955, -15.72923688032134, -30.0, -2.5786470446031764, 0.0, 0.0, -18.543429845456643, -20.0, -0.5190943071881693, 0.0, -18.07696426732735, -27.965540011571747, 0.0, -20.0, 0.0, -15.97748243508122, 0.0, 0.0, -36.61455753642862, -31.790988153882104, -22.95398496650845, 0.0, 0.0, 0.0, -30.55193974400041, -28.441127182642, 0.0, 0.0, 0.0, -3.8759068051847945, 0.0, 0.0, -0.14218711897823533, 0.0, 0.0, 0.0, 0.0, -0.08154721021957578, -2.3191553969337155, -36.90794029730457, 0.0, 0.0, -12.014873315020878, -20.0, 0.0, -3.5004529604644237, -33.59969406771958, 0.0, -58.402845210973716, -16.158693386455752, 0.0, -30.0, 0.0, 0.0, 0.0, -10.173844427024855, -20.0, -15.463259879725562, 0.0, -40.0498420339878, -22.119728023121517, -28.70318419390567, -0.2170828653711021, -5.268454578522171, -14.84059365138807, -4.2438946686099275, 0.0, 0.0, 0.0, -10.634564126634164, -58.891588063189054, -20.42842071153867, -1.3821661906754779, -20.0, -20.113308264663466, -4.248456589305675, 0.0, 0.0, -21.38566592581056, -60.0, -20.0, -1.156267020198689, -4.434465590566962, -12.564272155425543, 0.0, -3.537143424340837, -24.843244449258112, -4.492342311805293, -0.6570260518055071, 0.0, 0.0, -1.640624950020314, -3.1934832776085145, 0.0, -20.0, 0.0, -49.02832430032686, -20.0, -17.48519409021116, 0.0, -30.0, 0.0, 0.0, 0.0, -1.9715262865104, 0.0, 0.0, 0.0, 0.0, -35.30078634200725, -20.0, -81.18536211535749, -20.0, 0.0, -30.0, 0.0, -0.19283508328472143, -0.07893441802890644, -29.534750125696544, -21.030575964374457, -1.102760605342491, -17.447893914757806, -18.314859149318913, -30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -5.173075276776182, -9.862349755497018, 0.0, -40.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7058595983548014, "mean_inference_ms": 1.1976706854054058, "mean_action_processing_ms": 0.24321488006258885, "mean_env_wait_ms": 0.5138206046383628, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0048305517361487875, "StateBufferConnector_ms": 0.003346175323297948, "ViewRequirementAgentConnector_ms": 0.09598010852013106}, "num_episodes": 162, "episode_return_max": 120.0, "episode_return_min": -58.402845210973716, "episode_return_mean": 6.754771928251241}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 48000, "num_agent_steps_trained": 48000, "num_env_steps_sampled": 12000, "num_env_steps_trained": 12000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 306.56196416986, "num_env_steps_trained_throughput_per_sec": 306.56196416986, "timesteps_total": 12000, "num_env_steps_sampled_lifetime": 12000, "num_agent_steps_sampled_lifetime": 48000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 48000, "timers": {"training_iteration_time_ms": 13246.672, "restore_workers_time_ms": 0.021, "training_step_time_ms": 13246.616, "sample_time_ms": 1257.859, "learn_time_ms": 11975.152, "learn_throughput": 334.025, "synch_weights_time_ms": 12.911}, "counters": {"num_env_steps_sampled": 12000, "num_env_steps_trained": 12000, "num_agent_steps_sampled": 48000, "num_agent_steps_trained": 48000}, "done": false, "training_iteration": 3, "trial_id": "b72b3_00000", "date": "2024-08-08_15-31-45", "timestamp": 1723145505, "time_this_iter_s": 13.084933042526245, "time_total_s": 39.80146336555481, "pid": 98177, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b86be430>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 39.80146336555481, "iterations_since_restore": 3, "perf": {"cpu_util_percent": 35.66842105263158, "ram_util_percent": 81.63157894736842}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8720612128265202, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.647209435577194, "policy_loss": -0.019033904250439566, "vf_loss": 2.6641755856573583, "vf_explained_var": 0.0019110649824142455, "kl": 0.010338766007493857, "entropy": 1.5288900401443244, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 3360.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6079182072734156, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.4144919422290003, "policy_loss": -0.009690936976971092, "vf_loss": 1.4224661361029807, "vf_explained_var": -4.29028737629559e-06, "kl": 0.008583242153477336, "entropy": 1.5482495366258824, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 9870.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 16000, "num_env_steps_trained": 16000, "num_agent_steps_sampled": 64000, "num_agent_steps_trained": 64000}, "env_runners": {"episode_reward_max": 120.0, "episode_reward_min": -75.31929418200414, "episode_reward_mean": 9.474584452142741, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -75.31929418200414}, "policy_reward_max": {"adversary_policy": 60.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 6.481481481481482, "agent_policy": -9.969859992301703}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 19.867212710358512, 6.652165345195213, 0.0, 0.0, 0.0, 0.0, -1.5612033311831075, 70.18043448295849, 0.0, 0.0, 40.0, -1.1006786295826265, 20.0, 0.0, 0.0, 0.0, -20.65903933947657, -6.144585867882836, 60.0, 0.0, -6.774626231948382, 60.0, 40.0, 0.0, 20.0, 0.0, 95.58300191582376, -7.968928046675854, 74.18652543451519, 0.0, -4.545688264099872, 0.0, 0.0, -2.0454969564869465, -5.045176513529356, -27.47406741253831, 0.0, 0.0, 0.0, 0.0, 0.0, 39.92928411671097, 0.0, 0.0, 80.0, 0.0, -43.477308830714385, 0.0, -44.51098657239097, -23.065139627435517, 80.0, 80.0, 60.0, 0.0, 35.56784238049792, 0.0, 0.0, 40.0, 0.0, 0.0, 0.0, -0.18615200541209687, -0.1500793537592915, -5.845684637326774, 0.0, -20.65248603667149, 60.0, -1.363661203308536, 0.0, 0.0, 57.49485457273432, -5.731956539608757, 0.0, 100.0, 0.0, -24.645543400535068, 0.0, -12.117206233636473, 60.0, 0.0, -14.872743381381696, 0.0, 0.0, 0.0, -0.11398962464807205, -9.141927658888953, 0.0, -0.1367314729785396, 60.0, 0.0, -0.5815100979682009, -1.1819035393719979, 100.0, 0.0, 0.0, 0.0, 0.0, 120.0, -1.0966525676268468, 20.0, -9.476694898303553, 0.0, 0.0, 0.0, 20.0, 38.89193790183897, 0.0, 14.46794362162405, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, -75.31929418200414, 0.0, -1.2776209136459449, 0.0, 0.0, 0.0, -1.1417035629881644, 0.0, -9.924732638432603, 16.525548941294257, 0.0, 0.0, -12.515474154742412, 23.90133031107045, 0.0, 0.0, 40.0, 0.0, 40.0, -9.226901647659728, 19.667631307495217, 0.0, -0.11303255694304903, 0.0, -0.22226196091070682, 0.0, 57.237900673374185, -0.9201227998576977, 0.0, 0.0, 120.0, 0.0, 0.0, 0.0, -13.410888121095962, 0.0, -1.8974108432439496, 40.0, 0.0, -1.1958924790463477, 0.0, -33.69770832223205, 0.0, 27.259959989806504], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0], "policy_agent_policy_reward": [0.0, -10.132787289641488, -23.34783465480478, 0.0, 0.0, 0.0, 0.0, -1.5612033311831075, -49.81956551704146, 0.0, 0.0, -20.0, -1.1006786295826265, -10.0, 0.0, 0.0, 0.0, -20.65903933947657, -6.144585867882836, -30.0, 0.0, -6.774626231948382, -30.0, -20.0, 0.0, -10.0, 0.0, -54.41699808417626, -7.968928046675854, -45.813474565484825, 0.0, -4.545688264099872, 0.0, 0.0, -2.0454969564869465, -5.045176513529356, -27.47406741253831, 0.0, 0.0, 0.0, 0.0, 0.0, -20.070715883289033, 0.0, 0.0, -40.0, 0.0, -43.477308830714385, 0.0, -44.51098657239097, -23.065139627435517, -40.0, -40.0, -30.0, 0.0, -24.43215761950208, 0.0, 0.0, -20.0, 0.0, 0.0, 0.0, -0.18615200541209687, -0.1500793537592915, -5.845684637326774, 0.0, -20.65248603667149, -30.0, -1.363661203308536, 0.0, 0.0, -32.50514542726568, -5.731956539608757, 0.0, -50.0, 0.0, -24.645543400535068, 0.0, -12.117206233636473, -30.0, 0.0, -14.872743381381696, 0.0, 0.0, 0.0, -0.11398962464807205, -9.141927658888953, 0.0, -0.1367314729785396, -30.0, 0.0, -0.5815100979682009, -1.1819035393719979, -50.0, 0.0, 0.0, 0.0, 0.0, -60.0, -1.0966525676268468, -10.0, -9.476694898303553, 0.0, 0.0, 0.0, -10.0, -21.108062098161028, 0.0, -15.532056378375946, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -10.0, -10.0, -75.31929418200414, 0.0, -1.2776209136459449, 0.0, 0.0, 0.0, -1.1417035629881644, 0.0, -9.924732638432603, -43.47445105870574, 0.0, 0.0, -12.515474154742412, -36.09866968892954, 0.0, 0.0, -20.0, 0.0, -20.0, -9.226901647659728, -10.332368692504783, 0.0, -0.11303255694304903, 0.0, -0.22226196091070682, 0.0, -32.762099326625815, -0.9201227998576977, 0.0, 0.0, -60.0, 0.0, 0.0, 0.0, -13.410888121095962, 0.0, -1.8974108432439496, -20.0, 0.0, -1.1958924790463477, 0.0, -33.69770832223205, 0.0, -32.740040010193496]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6994416860561307, "mean_inference_ms": 1.1897584735641957, "mean_action_processing_ms": 0.2399087527067654, "mean_env_wait_ms": 0.5137116773060072, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004984787952752761, "StateBufferConnector_ms": 0.003312178599981614, "ViewRequirementAgentConnector_ms": 0.10156476939166034}, "num_episodes": 162, "episode_return_max": 120.0, "episode_return_min": -75.31929418200414, "episode_return_mean": 9.474584452142741}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 64000, "num_agent_steps_trained": 64000, "num_env_steps_sampled": 16000, "num_env_steps_trained": 16000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 287.5620745661124, "num_env_steps_trained_throughput_per_sec": 287.5620745661124, "timesteps_total": 16000, "num_env_steps_sampled_lifetime": 16000, "num_agent_steps_sampled_lifetime": 64000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 64000, "timers": {"training_iteration_time_ms": 13412.517, "restore_workers_time_ms": 0.019, "training_step_time_ms": 13412.466, "sample_time_ms": 1244.055, "learn_time_ms": 12155.017, "learn_throughput": 329.082, "synch_weights_time_ms": 12.826}, "counters": {"num_env_steps_sampled": 16000, "num_env_steps_trained": 16000, "num_agent_steps_sampled": 64000, "num_agent_steps_trained": 64000}, "done": false, "training_iteration": 4, "trial_id": "b72b3_00000", "date": "2024-08-08_15-31-59", "timestamp": 1723145519, "time_this_iter_s": 13.915987968444824, "time_total_s": 53.717451333999634, "pid": 98177, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3175ae3a0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 53.717451333999634, "iterations_since_restore": 4, "perf": {"cpu_util_percent": 31.744999999999997, "ram_util_percent": 81.08999999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8950396945389608, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.8379452793548503, "policy_loss": -0.015085806941109088, "vf_loss": 2.8507211140046516, "vf_explained_var": -0.005078281958897909, "kl": 0.011549882547984561, "entropy": 1.5051062159240245, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 4320.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6024970753501493, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.5054795003106407, "policy_loss": -0.008910551672167283, "vf_loss": 1.5125776411371028, "vf_explained_var": -3.13719113667806e-06, "kl": 0.009061519033548873, "entropy": 1.522512444029463, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 12690.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 20000, "num_env_steps_trained": 20000, "num_agent_steps_sampled": 80000, "num_agent_steps_trained": 80000}, "env_runners": {"episode_reward_max": 120.0, "episode_reward_min": -34.24917564899178, "episode_reward_mean": 9.167949635798108, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 157, "episodes_timesteps_total": 3925, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -63.34971850879828}, "policy_reward_max": {"adversary_policy": 60.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 6.369426751592357, "agent_policy": -9.940330618978962}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-2.1175604782417903, -2.2576533813550306, 0.0, 60.0, 0.0, 60.0, -6.218609256496757, 0.0, 60.0, 60.0, -24.01319741521395, 0.0, -16.72090202056073, -3.349718508798281, 0.0, 20.0, 0.0, 20.0, 0.0, -12.679075723168577, 40.0, 14.910064492325876, 0.0, 60.0, -4.023091851939693, -4.810745795367958, 40.0, 20.0, 0.0, 0.0, 0.0, 31.395098076276664, 0.0, 0.0, 50.300061336867095, 37.18818035242731, 0.0, 40.0, -7.889886724566681, -34.24917564899178, 0.0, 0.0, 60.0, 0.0, 0.0, 0.0, -1.4599226329304504, -16.60076322539191, 80.0, 40.0, -23.14444486346711, 0.0, 0.0, 0.0, -16.49737656381945, -14.737788761149552, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.8203501876642336, 0.0, -2.5742332354098023, 0.0, 0.0, -9.41914968523782, -2.0483851527799715, 72.73996518708415, 0.0, 0.0, 39.394964825302736, 0.0, -21.003101160967724, 20.0, 0.0, -26.545785447660418, 16.251513603591405, -32.000343496305696, -12.906914681143636, 0.0, 20.0, -9.741381425340355, 0.0, -0.5724904575688572, 0.0, -0.6405499366574641, 0.0, 60.0, 120.0, 0.0, 0.0, 0.0, 0.0, 120.0, 0.0, 40.0, 0.0, 40.0, 0.0, -0.44398929414627863, -8.490890735842592, 53.20355812907262, -5.29273867078401, -31.546627463369305, -2.9799661206086294, 0.0, 0.0, -0.020400467771929387, 0.0, 0.0, 20.0, -0.5645435250930686, -5.22213900423673, -1.1426874582137447, 0.0, -0.025064168357484817, -0.9562350296568867, 0.0, -0.048161242715076824, 0.0, 43.880921443540664, -7.123821359358878, 0.0, -14.221874114821116, -0.5204734661495558, -0.16110522906006897, 0.0, 40.0, -3.3463062985524106, 0.0, 0.0, 0.0, 19.259659066176244, -4.4658248943993115, 39.39873165530181, 60.0, 0.0, 0.0, -23.99329158080394, -13.94966164387509, 39.90200170278565, 0.0, 20.0, 20.0, 0.0, 40.0, 0.0, 0.0, -0.4402839704982453, 0.0, 40.0, 77.80917261854997, 19.658246720824906, -0.9253629333139457], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-2.1175604782417903, -2.2576533813550306, 0.0, -30.0, 0.0, -30.0, -6.218609256496757, 0.0, -30.0, -30.0, -24.01319741521395, 0.0, -46.72090202056073, -63.34971850879828, 0.0, -10.0, 0.0, -10.0, 0.0, -12.679075723168577, -20.0, -15.089935507674124, 0.0, -30.0, -4.023091851939693, -4.810745795367958, -20.0, -10.0, 0.0, 0.0, 0.0, -28.60490192372334, 0.0, 0.0, -39.699938663132905, -22.81181964757269, 0.0, -20.0, -7.889886724566681, -34.24917564899178, 0.0, 0.0, -30.0, 0.0, 0.0, 0.0, -1.4599226329304504, -16.60076322539191, -40.0, -20.0, -23.14444486346711, 0.0, 0.0, 0.0, -16.49737656381945, -14.737788761149552, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.8203501876642336, 0.0, -2.5742332354098023, 0.0, 0.0, -9.41914968523782, -2.0483851527799715, -47.26003481291585, 0.0, 0.0, -20.605035174697264, 0.0, -21.003101160967724, -10.0, 0.0, -26.545785447660418, -13.748486396408593, -32.000343496305696, -12.906914681143636, 0.0, -10.0, -9.741381425340355, 0.0, -0.5724904575688572, 0.0, -0.6405499366574641, 0.0, -30.0, -60.0, 0.0, 0.0, 0.0, 0.0, -60.0, 0.0, -20.0, 0.0, -20.0, 0.0, -0.44398929414627863, -8.490890735842592, -36.79644187092738, -5.29273867078401, -31.546627463369305, -2.9799661206086294, 0.0, 0.0, -0.020400467771929387, 0.0, 0.0, -10.0, -0.5645435250930686, -5.22213900423673, -1.1426874582137447, 0.0, -0.025064168357484817, -0.9562350296568867, 0.0, -0.048161242715076824, 0.0, -46.119078556459336, -7.123821359358878, 0.0, -14.221874114821116, -0.5204734661495558, -0.16110522906006897, 0.0, -20.0, -3.3463062985524106, 0.0, 0.0, 0.0, -10.740340933823756, -4.4658248943993115, -20.60126834469819, -30.0, 0.0, 0.0, -23.99329158080394, -13.94966164387509, -20.097998297214353, 0.0, -10.0, -10.0, 0.0, -20.0, 0.0, 0.0, -0.4402839704982453, 0.0, -20.0, -42.190827381450035, -10.341753279175094, -0.9253629333139457]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6832773518474039, "mean_inference_ms": 1.165797850075612, "mean_action_processing_ms": 0.23653882973138615, "mean_env_wait_ms": 0.5037420493347456, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004443393391408738, "StateBufferConnector_ms": 0.0031804582875245694, "ViewRequirementAgentConnector_ms": 0.09142699514984325}, "num_episodes": 157, "episode_return_max": 120.0, "episode_return_min": -34.24917564899178, "episode_return_mean": 9.167949635798108}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 80000, "num_agent_steps_trained": 80000, "num_env_steps_sampled": 20000, "num_env_steps_trained": 20000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 290.1918844699353, "num_env_steps_trained_throughput_per_sec": 290.1918844699353, "timesteps_total": 20000, "num_env_steps_sampled_lifetime": 20000, "num_agent_steps_sampled_lifetime": 80000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 80000, "timers": {"training_iteration_time_ms": 13486.812, "restore_workers_time_ms": 0.018, "training_step_time_ms": 13486.764, "sample_time_ms": 1219.223, "learn_time_ms": 12254.519, "learn_throughput": 326.41, "synch_weights_time_ms": 12.529}, "counters": {"num_env_steps_sampled": 20000, "num_env_steps_trained": 20000, "num_agent_steps_sampled": 80000, "num_agent_steps_trained": 80000}, "done": false, "training_iteration": 5, "trial_id": "b72b3_00000", "date": "2024-08-08_15-32-13", "timestamp": 1723145533, "time_this_iter_s": 13.790475845336914, "time_total_s": 67.50792717933655, "pid": 98177, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3175ae5e0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 67.50792717933655, "iterations_since_restore": 5, "perf": {"cpu_util_percent": 31.200000000000003, "ram_util_percent": 81.6}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8243165116757154, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.7553748682141306, "policy_loss": -0.016292945164605045, "vf_loss": 2.7695782259106636, "vf_explained_var": 0.005884707284470399, "kl": 0.010447942118792155, "entropy": 1.5039688566078742, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 5280.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6136658520774638, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.9210682591225239, "policy_loss": -0.010991006746540567, "vf_loss": 1.929964556064166, "vf_explained_var": -6.343498297616945e-06, "kl": 0.010472965650922993, "entropy": 1.4913152948338935, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 15510.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 24000, "num_env_steps_trained": 24000, "num_agent_steps_sampled": 96000, "num_agent_steps_trained": 96000}, "env_runners": {"episode_reward_max": 140.0, "episode_reward_min": -74.30949257716935, "episode_reward_mean": 15.465580249652755, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 158, "episodes_timesteps_total": 3950, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -74.30949257716935}, "policy_reward_max": {"adversary_policy": 70.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 8.924050632911392, "agent_policy": -11.306571649081423}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 80.0, 0.0, 0.0, -1.1973788430998988, 0.0, 0.0, 0.0, 0.0, 20.0, 60.0, 0.0, 14.91073709881191, 20.0, -3.370471365011002, 0.0, 0.0, 0.0, -7.961940626527609, 0.0, 0.0, 40.0, 36.86377868846275, 0.0, 0.0, 60.0, 57.083719999177575, 0.0, -6.114651713964566, 0.0, 20.0, 0.0, -17.208139677442325, 60.0, 0.0, 7.927438807793834, 20.0, 0.0, -1.1990001050203714, 0.0, 0.0, 0.0, -18.509910945748572, -4.82897221406069, 60.0, 0.0, 120.0, 0.0, 20.0, -0.3568601134090499, 40.0, 40.0, 0.0, 0.0, -0.13468936584032365, 40.0, 140.0, 0.0, -4.071880054759163, 0.0, 60.0, 0.0, 0.0, 20.0, 0.0, 0.0, -12.321014766611242, 0.0, 40.0, -12.097016378685126, 100.0, 40.0, -15.510661766018654, 0.0, 25.414990785400352, 0.0, 60.0, 0.0, -74.30949257716935, 40.0, 20.0, 0.0, 37.14915525662436, 120.0, 20.0, 76.91195888324509, 37.80803881010643, -17.051148596547183, 19.907346997422973, -0.84107125403589, 80.0, 39.74626682905455, 0.0, 80.0, 15.556986531295088, 0.0, -17.23342528552063, 0.0, 52.88792202226721, 0.0, 15.580249498446516, -1.3013521630501657, 12.997984048227377, 16.113171937074902, 41.78486285387348, -0.23831326052912383, 0.0, -8.12844072548221, 0.0, 39.90114856219583, 0.0, -0.07722013942471184, 0.0, 0.0, 0.0, 60.0, 40.0, -0.7592302195277711, -0.07090660175306573, -1.332116896125265, -4.605045019458886, 0.0, 49.547634767305304, 0.0, -9.527582207296273, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, -0.2058925482712859, -0.7681805038342371, 20.0, 60.0, 0.0, 0.0, 60.0, 40.0, 0.0, -4.795575481947575, 0.0, -1.1565114117485498, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 54.76253939403223, 0.0, -0.007064833804554249, 0.0, 60.0, -2.003094663957128], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 60.0, 60.0, 60.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [0.0, 0.0, -40.0, 0.0, 0.0, -1.1973788430998988, 0.0, 0.0, 0.0, 0.0, -10.0, -30.0, 0.0, -15.08926290118809, -10.0, -3.370471365011002, 0.0, 0.0, 0.0, -7.961940626527609, 0.0, 0.0, -20.0, -23.13622131153725, 0.0, 0.0, -30.0, -32.916280000822425, 0.0, -6.114651713964566, 0.0, -10.0, 0.0, -17.208139677442325, -30.0, 0.0, -22.072561192206166, -10.0, 0.0, -1.1990001050203714, 0.0, 0.0, 0.0, -18.509910945748572, -4.82897221406069, -30.0, 0.0, -60.0, 0.0, -10.0, -0.3568601134090499, -20.0, -20.0, 0.0, 0.0, -0.13468936584032365, -20.0, -70.0, 0.0, -4.071880054759163, 0.0, -30.0, 0.0, 0.0, -10.0, 0.0, 0.0, -12.321014766611242, 0.0, -20.0, -12.097016378685126, -50.0, -20.0, -15.510661766018654, 0.0, -34.58500921459964, 0.0, -30.0, 0.0, -74.30949257716935, -20.0, -10.0, 0.0, -22.85084474337563, -60.0, -10.0, -43.08804111675491, -22.19196118989357, -17.051148596547183, -10.092653002577027, -0.84107125403589, -40.0, -20.253733170945452, 0.0, -40.0, -14.443013468704912, 0.0, -17.23342528552063, 0.0, -37.11207797773279, 0.0, -14.419750501553484, -1.3013521630501657, -47.00201595177262, -13.886828062925098, -48.21513714612653, -0.23831326052912383, 0.0, -8.12844072548221, 0.0, -20.09885143780417, 0.0, -0.07722013942471184, 0.0, 0.0, 0.0, -30.0, -20.0, -0.7592302195277711, -0.07090660175306573, -1.332116896125265, -4.605045019458886, 0.0, -40.452365232694696, 0.0, -9.527582207296273, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -30.0, -0.2058925482712859, -0.7681805038342371, -10.0, -30.0, 0.0, 0.0, -30.0, -20.0, 0.0, -4.795575481947575, 0.0, -1.1565114117485498, 0.0, -20.0, -20.0, -20.0, 0.0, 0.0, -35.23746060596777, 0.0, -0.007064833804554249, 0.0, -30.0, -2.003094663957128]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6700290815590098, "mean_inference_ms": 1.1481543588351044, "mean_action_processing_ms": 0.2326398855481638, "mean_env_wait_ms": 0.4977633448857251, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004831446877008752, "StateBufferConnector_ms": 0.0031635731081419353, "ViewRequirementAgentConnector_ms": 0.08825803104835221}, "num_episodes": 158, "episode_return_max": 140.0, "episode_return_min": -74.30949257716935, "episode_return_mean": 15.465580249652755}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 96000, "num_agent_steps_trained": 96000, "num_env_steps_sampled": 24000, "num_env_steps_trained": 24000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 273.3497242212631, "num_env_steps_trained_throughput_per_sec": 273.3497242212631, "timesteps_total": 24000, "num_env_steps_sampled_lifetime": 24000, "num_agent_steps_sampled_lifetime": 96000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 96000, "timers": {"training_iteration_time_ms": 13677.889, "restore_workers_time_ms": 0.017, "training_step_time_ms": 13677.844, "sample_time_ms": 1206.688, "learn_time_ms": 12457.512, "learn_throughput": 321.091, "synch_weights_time_ms": 12.84}, "counters": {"num_env_steps_sampled": 24000, "num_env_steps_trained": 24000, "num_agent_steps_sampled": 96000, "num_agent_steps_trained": 96000}, "done": false, "training_iteration": 6, "trial_id": "b72b3_00000", "date": "2024-08-08_15-32-28", "timestamp": 1723145548, "time_this_iter_s": 14.674067974090576, "time_total_s": 82.18199515342712, "pid": 98177, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b86fe430>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 82.18199515342712, "iterations_since_restore": 6, "perf": {"cpu_util_percent": 37.872727272727275, "ram_util_percent": 82.41818181818181}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.794254340728124, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.636565833352506, "policy_loss": -0.020478048517058294, "vf_loss": 2.6544326782847443, "vf_explained_var": 0.005162617315848669, "kl": 0.013056038020899744, "entropy": 1.4804717894643544, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 6240.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6488014838374253, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.989899482879233, "policy_loss": -0.009524877712870321, "vf_loss": 1.997663642244136, "vf_explained_var": 1.1669955355055788e-05, "kl": 0.008803102789497159, "entropy": 1.4787381932245078, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 18330.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 28000, "num_env_steps_trained": 28000, "num_agent_steps_sampled": 112000, "num_agent_steps_trained": 112000}, "env_runners": {"episode_reward_max": 180.0, "episode_reward_min": -84.32458254986534, "episode_reward_mean": 12.03114174511058, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -90.0}, "policy_reward_max": {"adversary_policy": 90.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 7.160493827160494, "agent_policy": -9.450339736370903}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-13.570258513478604, 0.0, 60.0, 14.436697819285282, 0.0, 0.0, 35.148781617709595, 58.74612074329332, 40.0, 0.0, 0.0, 0.0, -3.281315102036226, 0.0, 0.0, 58.441727403953635, 20.0, 20.0, 0.0, 0.0, 19.357700881875743, 0.0, 0.0, -12.645434348072492, 0.0, 0.0, 0.0, 58.24710465890609, 59.742386190171196, 60.0, -0.006822885438233506, 0.0, -9.776548738622004, -42.93992044025883, 98.65991043496534, 0.0, -4.739513227580775, 35.080093886803695, 0.0, 40.0, 0.0, -1.1655247947203928, 0.0, 19.928285266515974, 0.0, 20.0, -2.5799606959085075, -33.98368800978191, -0.13427874473943668, -9.700978931804098, 0.0, 0.0, -6.786759441570185, 20.0, 20.0, 40.0, 0.0, 20.0, 0.0, 0.0, -1.7692056945035328, -2.2509542423436066, 0.0, 0.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.4192686835535153, 11.952104296114495, 0.0, 0.0, 0.0, -23.841570224368443, 0.0, 57.747020991394635, 60.0, 0.0, -0.13839956332771908, 0.0, 0.0, 60.0, 0.0, -9.27985027603529, 20.0, 0.0, -0.4095508113637414, 0.0, 0.0, 180.0, -11.744128853633779, 40.0, 0.0, 60.0, 0.0, 120.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, -3.8027910415841797, -11.681017674160735, -1.574280299967309, -3.47078997103392, 0.0, 20.0, 0.0, 20.0, 0.0, 0.0, 60.0, 0.0, 0.0, 0.0, 0.0, 20.0, 0.0, -3.9421790008510036, 60.0, 37.11671205648311, 0.0, 38.47933864888367, 60.0, 0.0, -0.68199442157445, 0.0, 0.0, 19.507470437781674, 38.47046782404537, 0.0, 38.937302376509805, 0.0, -0.5744087657277797, 0.0, 40.0, 0.0, -0.3612859647242572, 0.0, 0.0, 33.258168768393425, 19.008290244799234, -13.41226513851919, -0.47355807430340624, 0.0, 0.0, 80.0, 12.24236328548131, 0.0, 0.0, 0.0, 0.0, 60.0, -84.32458254986534, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 90.0, 90.0, 90.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-13.570258513478604, 0.0, -30.0, -15.563302180714718, 0.0, 0.0, -24.851218382290405, -31.253879256706675, -20.0, 0.0, 0.0, 0.0, -3.281315102036226, 0.0, 0.0, -31.558272596046365, -10.0, -10.0, 0.0, 0.0, -10.642299118124255, 0.0, 0.0, -12.645434348072492, 0.0, 0.0, 0.0, -31.752895341093904, -30.257613809828804, -30.0, -0.006822885438233506, 0.0, -9.776548738622004, -42.93992044025883, -51.34008956503466, 0.0, -4.739513227580775, -24.919906113196298, 0.0, -20.0, 0.0, -1.1655247947203928, 0.0, -10.071714733484026, 0.0, -10.0, -2.5799606959085075, -33.98368800978191, -0.13427874473943668, -9.700978931804098, 0.0, 0.0, -6.786759441570185, -10.0, -10.0, -20.0, 0.0, -10.0, 0.0, 0.0, -1.7692056945035328, -2.2509542423436066, 0.0, 0.0, -30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.4192686835535153, -18.047895703885505, 0.0, 0.0, 0.0, -23.841570224368443, 0.0, -32.25297900860537, -30.0, 0.0, -0.13839956332771908, 0.0, 0.0, -30.0, 0.0, -9.27985027603529, -10.0, 0.0, -0.4095508113637414, 0.0, 0.0, -90.0, -11.744128853633779, -20.0, 0.0, -30.0, 0.0, -60.0, 0.0, 0.0, 0.0, 0.0, -30.0, -30.0, -3.8027910415841797, -11.681017674160735, -1.574280299967309, -3.47078997103392, 0.0, -10.0, 0.0, -10.0, 0.0, 0.0, -30.0, 0.0, 0.0, 0.0, 0.0, -10.0, 0.0, -3.9421790008510036, -30.0, -22.88328794351689, 0.0, -21.520661351116335, -30.0, 0.0, -0.68199442157445, 0.0, 0.0, -10.492529562218326, -21.529532175954632, 0.0, -21.062697623490195, 0.0, -0.5744087657277797, 0.0, -20.0, 0.0, -0.3612859647242572, 0.0, 0.0, -26.74183123160658, -10.991709755200773, -13.41226513851919, -0.47355807430340624, 0.0, 0.0, -40.0, -17.75763671451869, 0.0, 0.0, 0.0, 0.0, -30.0, -84.32458254986534, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6640187637489409, "mean_inference_ms": 1.136123352497192, "mean_action_processing_ms": 0.22965453010689013, "mean_env_wait_ms": 0.49315657366852556, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005214155456166209, "StateBufferConnector_ms": 0.003167655732896593, "ViewRequirementAgentConnector_ms": 0.0884484361719202}, "num_episodes": 162, "episode_return_max": 180.0, "episode_return_min": -84.32458254986534, "episode_return_mean": 12.03114174511058}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 112000, "num_agent_steps_trained": 112000, "num_env_steps_sampled": 28000, "num_env_steps_trained": 28000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 278.9378081273753, "num_env_steps_trained_throughput_per_sec": 278.9378081273753, "timesteps_total": 28000, "num_env_steps_sampled_lifetime": 28000, "num_agent_steps_sampled_lifetime": 112000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 112000, "timers": {"training_iteration_time_ms": 13772.494, "restore_workers_time_ms": 0.017, "training_step_time_ms": 13772.45, "sample_time_ms": 1195.498, "learn_time_ms": 12563.367, "learn_throughput": 318.386, "synch_weights_time_ms": 12.869}, "counters": {"num_env_steps_sampled": 28000, "num_env_steps_trained": 28000, "num_agent_steps_sampled": 112000, "num_agent_steps_trained": 112000}, "done": false, "training_iteration": 7, "trial_id": "b72b3_00000", "date": "2024-08-08_15-32-43", "timestamp": 1723145563, "time_this_iter_s": 14.347738981246948, "time_total_s": 96.52973413467407, "pid": 98177, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b86f5040>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 96.52973413467407, "iterations_since_restore": 7, "perf": {"cpu_util_percent": 33.330000000000005, "ram_util_percent": 82.06}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7777944216194252, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.810659783706069, "policy_loss": -0.010298988891008776, "vf_loss": 2.819353044902285, "vf_explained_var": 0.006521672879656156, "kl": 0.008028623808012681, "entropy": 1.4815151523798704, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 7200.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6562838807279336, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.364550165588974, "policy_loss": -0.012385320774418243, "vf_loss": 2.3751846927700315, "vf_explained_var": 1.83572160436752e-05, "kl": 0.008753658196649573, "entropy": 1.4542779968139974, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 21150.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 32000, "num_env_steps_trained": 32000, "num_agent_steps_sampled": 128000, "num_agent_steps_trained": 128000}, "env_runners": {"episode_reward_max": 120.0, "episode_reward_min": -32.26450144884981, "episode_reward_mean": 19.41658994949277, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -61.38466115661718}, "policy_reward_max": {"adversary_policy": 60.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 10.37037037037037, "agent_policy": -11.694521161618338}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, -1.8535455036744852, 60.0, 0.0, 0.0, 0.0, 89.12689488918627, 16.72591469167613, 40.0, 40.0, 40.0, -1.5280452447918613, 0.0, -1.685518316094784, 53.54747252800872, 0.0, 0.0, 0.0, 100.0, 60.0, 0.0, 0.0, 19.84601262022384, 100.0, 0.0, 40.0, 0.0, 0.0, -2.842978028976881, 20.0, 0.0, 0.0, 0.0, -3.7718596349120466, 100.0, -5.709950649545137, 80.0, 0.0, 0.0, 60.0, 0.0, 0.0, 0.0, -1.713682005674091, -0.8248002320277181, 0.0, 40.0, 0.0, 0.0, 0.0, 18.528141617311345, -3.851964945371793, 0.0, 20.0, 0.0, -32.26450144884981, -0.29448438337762783, -0.7393324991590533, -0.39674528354934235, 60.0, -16.51184632734189, 0.0, 36.29930182322534, 60.0, 0.0, -0.2103501591294188, 60.0, 0.0, -1.6766659559805197, 99.82120006886224, 60.0, 0.0, 0.0, -10.023174675914934, 0.0, 20.0, 80.0, -18.001734708952103, 50.67503773986728, 80.0, 60.0, 0.0, 40.0, 0.0, 20.0, 0.0, 0.0, 80.0, 100.0, 0.0, 20.0, 0.0, 60.0, 0.0, -0.09934922597827023, 0.0, -1.308140573303812, -3.9919131254979403, 0.0, -2.2014843198869016, 0.0, 0.0, -1.022767043129179, 20.0, 60.0, 0.0, 0.0, -6.585742413377893, 0.0, 75.66241518926918, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -11.490796180978222, 60.0, 16.084002921257017, 78.41811212212392, 120.0, 0.0, 0.0, 0.0, 0.0, 118.61533884338283, 0.0, 78.48529701359966, -1.3143206857550926, 60.0, 0.0, -8.917725706557937, 40.0, 39.6063723734356, 38.28737257876628, 0.0, 20.0, -2.2540235700597737, -2.6021348298694447, 0.0, 0.0, 0.0, 0.0, 0.0, 120.0, 0.0, 20.0, 40.0, -0.396828712252415, 0.0, 19.12236772202055, 60.0, -15.899745769045069, 40.0, 0.0, 60.0, 60.0, 20.0, 0.0, 0.0, 58.62246923462851], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0], "policy_agent_policy_reward": [0.0, -1.8535455036744852, -30.0, 0.0, 0.0, 0.0, -60.87310511081371, -13.274085308323867, -20.0, -20.0, -20.0, -1.5280452447918613, 0.0, -1.685518316094784, -36.45252747199128, 0.0, 0.0, 0.0, -50.0, -30.0, 0.0, 0.0, -10.153987379776163, -50.0, 0.0, -20.0, 0.0, 0.0, -2.842978028976881, -10.0, 0.0, 0.0, 0.0, -3.7718596349120466, -50.0, -5.709950649545137, -40.0, 0.0, 0.0, -30.0, 0.0, 0.0, 0.0, -1.713682005674091, -0.8248002320277181, 0.0, -20.0, 0.0, 0.0, 0.0, -11.471858382688655, -3.851964945371793, 0.0, -10.0, 0.0, -32.26450144884981, -0.29448438337762783, -0.7393324991590533, -0.39674528354934235, -30.0, -16.51184632734189, 0.0, -23.700698176774658, -30.0, 0.0, -0.2103501591294188, -30.0, 0.0, -1.6766659559805197, -50.17879993113776, -30.0, 0.0, 0.0, -10.023174675914934, 0.0, -10.0, -40.0, -18.001734708952103, -39.32496226013273, -40.0, -30.0, 0.0, -20.0, 0.0, -10.0, 0.0, 0.0, -40.0, -50.0, 0.0, -10.0, 0.0, -30.0, 0.0, -0.09934922597827023, 0.0, -1.308140573303812, -3.9919131254979403, 0.0, -2.2014843198869016, 0.0, 0.0, -1.022767043129179, -10.0, -30.0, 0.0, 0.0, -6.585742413377893, 0.0, -44.33758481073082, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -11.490796180978222, -30.0, -13.915997078742981, -41.58188787787607, -60.0, 0.0, 0.0, 0.0, 0.0, -61.38466115661718, 0.0, -41.514702986400344, -1.3143206857550926, -30.0, 0.0, -8.917725706557937, -20.0, -20.39362762656441, -21.71262742123372, 0.0, -10.0, -2.2540235700597737, -2.6021348298694447, 0.0, 0.0, 0.0, 0.0, 0.0, -60.0, 0.0, -10.0, -20.0, -0.396828712252415, 0.0, -10.877632277979453, -30.0, -15.899745769045069, -20.0, 0.0, -30.0, -30.0, -10.0, 0.0, 0.0, -31.37753076537149]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6625389817908607, "mean_inference_ms": 1.1368556432880976, "mean_action_processing_ms": 0.22873709846672727, "mean_env_wait_ms": 0.49152031227734677, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004716051949395074, "StateBufferConnector_ms": 0.0031792823179268544, "ViewRequirementAgentConnector_ms": 0.08948128900410217}, "num_episodes": 162, "episode_return_max": 120.0, "episode_return_min": -32.26450144884981, "episode_return_mean": 19.41658994949277}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 128000, "num_agent_steps_trained": 128000, "num_env_steps_sampled": 32000, "num_env_steps_trained": 32000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 281.5610198496537, "num_env_steps_trained_throughput_per_sec": 281.5610198496537, "timesteps_total": 32000, "num_env_steps_sampled_lifetime": 32000, "num_agent_steps_sampled_lifetime": 128000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 128000, "timers": {"training_iteration_time_ms": 13826.747, "restore_workers_time_ms": 0.016, "training_step_time_ms": 13826.704, "sample_time_ms": 1194.331, "learn_time_ms": 12618.737, "learn_throughput": 316.989, "synch_weights_time_ms": 12.873}, "counters": {"num_env_steps_sampled": 32000, "num_env_steps_trained": 32000, "num_agent_steps_sampled": 128000, "num_agent_steps_trained": 128000}, "done": false, "training_iteration": 8, "trial_id": "b72b3_00000", "date": "2024-08-08_15-32-57", "timestamp": 1723145577, "time_this_iter_s": 14.246750831604004, "time_total_s": 110.77648496627808, "pid": 98177, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b86f53a0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 110.77648496627808, "iterations_since_restore": 8, "perf": {"cpu_util_percent": 33.17142857142857, "ram_util_percent": 81.91428571428571}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8672513324456911, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.3866305332630873, "policy_loss": -0.015034841794113163, "vf_loss": 3.3997346575061482, "vf_explained_var": 0.003989801555871963, "kl": 0.009653532449162524, "entropy": 1.460720066477855, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 8160.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6830710578472057, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.667101271524497, "policy_loss": -0.012435369046042914, "vf_loss": 2.6775358302373413, "vf_explained_var": 2.581895665919527e-06, "kl": 0.010003826456399842, "entropy": 1.4105387902428919, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 23970.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 36000, "num_env_steps_trained": 36000, "num_agent_steps_sampled": 144000, "num_agent_steps_trained": 144000}, "env_runners": {"episode_reward_max": 120.0, "episode_reward_min": -61.197956274745934, "episode_reward_mean": 19.35296793102608, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 157, "episodes_timesteps_total": 3925, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -67.75987497895862}, "policy_reward_max": {"adversary_policy": 60.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 10.828025477707007, "agent_policy": -13.131108502094941}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 36.35705190766044, 0.0, -6.705569690833635, 60.0, 19.91257358673962, 12.24843468451159, 80.0, 60.0, 19.853003013103688, 37.73412482966708, 0.0, 40.0, 60.0, 0.0, 0.0, 60.0, 0.0, 0.0, -0.2580414673053921, 0.0, 20.0, 20.0, 0.0, 0.0, 60.0, 30.26468629056436, 0.0, 58.9817077523968, 0.0, 0.0, 29.187271612595197, 80.0, 80.0, 20.0, 0.0, 0.0, -2.7800199342335428, 40.0, 0.0, -4.3616245166875505, -16.66551096901123, 0.0, 0.0, 59.024672037703375, 60.0, 0.0, 0.0, 40.0, 0.0, 0.0, -6.474680144899822, 40.0, 0.0, 0.0, 0.0, 0.0, 38.31819253970832, 0.0, -12.208780250371698, 60.0, 0.0, 60.0, 0.0, -14.651251345916918, 0.0, 36.666940547289144, 80.0, 119.51431933283297, 20.0, 40.0, 60.0, 0.0, 0.0, 40.0, 39.76051023326485, 0.0, -1.2917329305143221, 40.0, 0.0, 60.0, 0.0, 60.0, 60.0, 60.0, 40.0, 0.0, 40.0, -0.5708650176492769, 60.0, 120.0, 20.0, 40.0, 0.0, 0.0, 0.0, 0.0, -61.197956274745934, 0.0, 0.0, 0.0, 58.401337162781026, 0.0, 0.0, 0.0, 0.0, 6.226151143311476, 0.0, -27.360029533599267, 0.0, 19.582242184556648, 0.0, 0.0, 82.24012502104141, 0.0, 60.0, -3.079501618254721, 76.90783644414478, 0.0, 0.0, -30.56333141794546, 0.0, 60.0, 45.59514872904312, 53.297545384915246, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 15.525813851340011, 40.0, -0.8669061272096568, -17.927831337092954, -11.165672436596513, 100.0, -0.035676367890392635, -0.5861023306221391, -1.9603726757621032, 0.0, -0.29998453418101034, 80.0, 20.0, 58.456429459857404, 0.0, 40.0, 0.0, 39.85167273784108, 0.0, 0.0, -1.9736576952075013, 0.0, 60.0, -12.50672669924441, 0.0, 40.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 60.0, 60.0, 60.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 60.0, 60.0, 60.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0], "policy_agent_policy_reward": [0.0, -23.64294809233956, 0.0, -6.705569690833635, -30.0, -10.08742641326038, -17.751565315488406, -40.0, -30.0, -10.146996986896314, -22.265875170332922, 0.0, -20.0, -30.0, 0.0, 0.0, -30.0, 0.0, 0.0, -0.2580414673053921, 0.0, -10.0, -10.0, 0.0, 0.0, -30.0, -59.735313709435644, 0.0, -31.018292247603206, 0.0, 0.0, -30.812728387404803, -40.0, -40.0, -10.0, 0.0, 0.0, -2.7800199342335428, -20.0, 0.0, -4.3616245166875505, -16.66551096901123, 0.0, 0.0, -30.975327962296618, -30.0, 0.0, 0.0, -20.0, 0.0, 0.0, -6.474680144899822, -20.0, 0.0, 0.0, 0.0, 0.0, -21.681807460291676, 0.0, -12.208780250371698, -30.0, 0.0, -30.0, 0.0, -14.651251345916918, 0.0, -23.333059452710845, -40.0, -60.485680667167024, -10.0, -20.0, -30.0, 0.0, 0.0, -20.0, -20.23948976673515, 0.0, -1.2917329305143221, -20.0, 0.0, -30.0, 0.0, -30.0, -30.0, -30.0, -20.0, 0.0, -20.0, -0.5708650176492769, -30.0, -60.0, -10.0, -20.0, 0.0, 0.0, 0.0, 0.0, -61.197956274745934, 0.0, 0.0, 0.0, -31.59866283721897, 0.0, 0.0, 0.0, 0.0, -23.773848856688527, 0.0, -27.360029533599267, 0.0, -10.417757815443352, 0.0, 0.0, -67.75987497895862, 0.0, -30.0, -3.079501618254721, -43.09216355585523, 0.0, 0.0, -30.56333141794546, 0.0, -30.0, -44.40485127095689, -36.702454615084754, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -14.474186148659989, -20.0, -0.8669061272096568, -17.927831337092954, -11.165672436596513, -50.0, -0.035676367890392635, -0.5861023306221391, -1.9603726757621032, 0.0, -0.29998453418101034, -40.0, -10.0, -31.543570540142596, 0.0, -20.0, 0.0, -20.148327262158922, 0.0, 0.0, -1.9736576952075013, 0.0, -30.0, -12.50672669924441, 0.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6583748358544873, "mean_inference_ms": 1.1344496074962578, "mean_action_processing_ms": 0.22745411915567182, "mean_env_wait_ms": 0.4889140320068631, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0043702732985186725, "StateBufferConnector_ms": 0.00317559880056199, "ViewRequirementAgentConnector_ms": 0.08712202120738424}, "num_episodes": 157, "episode_return_max": 120.0, "episode_return_min": -61.197956274745934, "episode_return_mean": 19.35296793102608}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 144000, "num_agent_steps_trained": 144000, "num_env_steps_sampled": 36000, "num_env_steps_trained": 36000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 279.50681950707576, "num_env_steps_trained_throughput_per_sec": 279.50681950707576, "timesteps_total": 36000, "num_env_steps_sampled_lifetime": 36000, "num_agent_steps_sampled_lifetime": 144000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 144000, "timers": {"training_iteration_time_ms": 13880.545, "restore_workers_time_ms": 0.016, "training_step_time_ms": 13880.502, "sample_time_ms": 1186.604, "learn_time_ms": 12680.413, "learn_throughput": 315.447, "synch_weights_time_ms": 12.725}, "counters": {"num_env_steps_sampled": 36000, "num_env_steps_trained": 36000, "num_agent_steps_sampled": 144000, "num_agent_steps_trained": 144000}, "done": false, "training_iteration": 9, "trial_id": "b72b3_00000", "date": "2024-08-08_15-33-12", "timestamp": 1723145592, "time_this_iter_s": 14.344980001449585, "time_total_s": 125.12146496772766, "pid": 98177, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b86fb160>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 125.12146496772766, "iterations_since_restore": 9, "perf": {"cpu_util_percent": 36.46, "ram_util_percent": 82.04}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.881065234541893, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.404843873841067, "policy_loss": -0.01383494254841935, "vf_loss": 3.4166463003804286, "vf_explained_var": 0.005453064665198326, "kl": 0.010162614782693069, "entropy": 1.4413809474557637, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 9120.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6795582249654946, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.468704927813077, "policy_loss": -0.010190372069749992, "vf_loss": 2.477328974515834, "vf_explained_var": 5.822126747023129e-06, "kl": 0.007831429431450128, "entropy": 1.4035475300558915, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 26790.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 40000, "num_env_steps_trained": 40000, "num_agent_steps_sampled": 160000, "num_agent_steps_trained": 160000}, "env_runners": {"episode_reward_max": 180.0, "episode_reward_min": -26.01208942055943, "episode_reward_mean": 18.93402268698567, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -90.0}, "policy_reward_max": {"adversary_policy": 90.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 10.617283950617283, "agent_policy": -12.917829164866182}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-1.2426948505720026, 40.0, 59.562924132563595, 180.0, 60.0, 20.0, -15.359302168112327, 0.0, 0.0, -15.271963925120684, 40.0, 60.0, 0.0, 20.0, -0.8540734646047221, 20.0, 100.0, 38.95373832222275, 180.0, 40.0, 100.0, 40.0, 0.0, 20.0, 2.97020858573775, 0.0, 54.59049084572687, -0.08492862001349244, 63.13714593970741, 18.61002532989525, 0.0, 58.886976123566626, 60.0, -21.355737870575553, 20.0, 0.0, 20.0, 0.0, 60.0, -9.866507007672634, -0.7865870205106584, 0.0, 20.0, 51.71467336635597, 0.0, 0.0, -0.811984442343805, 53.04475560405059, 0.0, 39.224975868765185, 0.0, -16.52704977608706, 91.95525566306617, 0.0, 40.0, 0.0, 20.0, 0.0, 0.0, -3.9597677954577053, -10.537012254473858, 0.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -7.792830938043949, 0.0, 80.0, 0.0, 60.0, 29.180199357294192, 0.0, -0.41344407031286723, 35.3498560471585, 0.0, 0.0, 0.0, 100.0, 0.0, -7.486079579137348, -0.12176798289173063, 0.0, 0.0, 0.0, 0.0, -8.654434564069266, 19.808863803337324, -0.5325765804356553, -0.5981955584628174, 37.40915232639989, -0.2409504523758832, -9.459914685022808, 0.0, 120.0, 0.0, 60.0, 0.0, 20.0, 0.0, 120.0, -7.585784656678945, -12.325521753014161, 0.0, -6.247850421974801, 58.85084853977452, -23.51912040819812, -0.9557360397217463, 0.0, 60.0, 0.0, 0.0, 38.47843845853472, 40.0, -5.072361634806254, 20.0, 60.0, 0.0, 40.0, 0.0, 20.0, -0.1747544468780604, 0.0, -0.9994910489545594, 80.0, 0.0, 0.0, -0.2985561595165964, 0.0, -2.0531530874617845, 0.0, 40.0, 20.0, 0.0, -3.1899415995019953, -0.8061732300098057, 100.0, 0.0, 57.23279617145083, -0.5924796896333562, 0.0, 0.0, 0.0, 0.0, -16.532691431566, 40.0, 40.0, 40.0, 0.0, 0.0, 40.0, 0.0, 0.0, -21.744910646172784, 100.0, -1.581229912984179, 0.0, -26.01208942055943, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 90.0, 90.0, 90.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 90.0, 90.0, 90.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-1.2426948505720026, -20.0, -30.437075867436405, -90.0, -30.0, -10.0, -15.359302168112327, 0.0, 0.0, -15.271963925120684, -20.0, -30.0, 0.0, -10.0, -0.8540734646047221, -10.0, -50.0, -21.046261677777252, -90.0, -20.0, -50.0, -20.0, 0.0, -10.0, -27.029791414262245, 0.0, -35.40950915427314, -0.08492862001349244, -56.862854060292605, -11.389974670104747, 0.0, -31.113023876433367, -30.0, -21.355737870575553, -10.0, 0.0, -10.0, 0.0, -30.0, -9.866507007672634, -0.7865870205106584, 0.0, -10.0, -38.28532663364403, 0.0, 0.0, -0.811984442343805, -36.95524439594941, 0.0, -20.775024131234815, 0.0, -16.52704977608706, -88.04474433693383, 0.0, -20.0, 0.0, -10.0, 0.0, 0.0, -3.9597677954577053, -10.537012254473858, 0.0, -30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -7.792830938043949, 0.0, -40.0, 0.0, -30.0, -30.81980064270579, 0.0, -0.41344407031286723, -24.650143952841503, 0.0, 0.0, 0.0, -50.0, 0.0, -7.486079579137348, -0.12176798289173063, 0.0, 0.0, 0.0, 0.0, -8.654434564069266, -10.191136196662677, -0.5325765804356553, -0.5981955584628174, -22.590847673600106, -0.2409504523758832, -9.459914685022808, 0.0, -60.0, 0.0, -30.0, 0.0, -10.0, 0.0, -60.0, -7.585784656678945, -12.325521753014161, 0.0, -6.247850421974801, -31.149151460225486, -23.51912040819812, -0.9557360397217463, 0.0, -30.0, 0.0, 0.0, -21.52156154146527, -20.0, -5.072361634806254, -10.0, -30.0, 0.0, -20.0, 0.0, -10.0, -0.1747544468780604, 0.0, -0.9994910489545594, -40.0, 0.0, 0.0, -0.2985561595165964, 0.0, -2.0531530874617845, 0.0, -20.0, -10.0, 0.0, -3.1899415995019953, -0.8061732300098057, -50.0, 0.0, -32.76720382854917, -0.5924796896333562, 0.0, 0.0, 0.0, 0.0, -16.532691431566, -20.0, -20.0, -20.0, 0.0, 0.0, -20.0, 0.0, 0.0, -21.744910646172784, -50.0, -1.581229912984179, 0.0, -26.01208942055943, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6540338604918026, "mean_inference_ms": 1.1281410574059814, "mean_action_processing_ms": 0.22634071918059023, "mean_env_wait_ms": 0.48650722501916566, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004575281967351466, "StateBufferConnector_ms": 0.0032483059682963805, "ViewRequirementAgentConnector_ms": 0.09224311805065767}, "num_episodes": 162, "episode_return_max": 180.0, "episode_return_min": -26.01208942055943, "episode_return_mean": 18.93402268698567}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 160000, "num_agent_steps_trained": 160000, "num_env_steps_sampled": 40000, "num_env_steps_trained": 40000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 277.47160058416966, "num_env_steps_trained_throughput_per_sec": 277.47160058416966, "timesteps_total": 40000, "num_env_steps_sampled_lifetime": 40000, "num_agent_steps_sampled_lifetime": 160000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 160000, "timers": {"training_iteration_time_ms": 13934.081, "restore_workers_time_ms": 0.016, "training_step_time_ms": 13934.038, "sample_time_ms": 1183.855, "learn_time_ms": 12736.83, "learn_throughput": 314.05, "synch_weights_time_ms": 12.648}, "counters": {"num_env_steps_sampled": 40000, "num_env_steps_trained": 40000, "num_agent_steps_sampled": 160000, "num_agent_steps_trained": 160000}, "done": false, "training_iteration": 10, "trial_id": "b72b3_00000", "date": "2024-08-08_15-33-26", "timestamp": 1723145606, "time_this_iter_s": 14.422921895980835, "time_total_s": 139.5443868637085, "pid": 98177, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b86fb3a0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 139.5443868637085, "iterations_since_restore": 10, "perf": {"cpu_util_percent": 32.71904761904762, "ram_util_percent": 82.52380952380952}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9484814266984661, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.197527860601743, "policy_loss": -0.012596837394327546, "vf_loss": 3.208116627857089, "vf_explained_var": 0.0014544139926632245, "kl": 0.010040338622280843, "entropy": 1.4372103318572045, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 10080.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7012609108119991, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.462287848215577, "policy_loss": -0.012111636171072427, "vf_loss": 2.4725823728328056, "vf_explained_var": 1.4795986473137605e-05, "kl": 0.00908538596563024, "entropy": 1.385272077803916, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 29610.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 44000, "num_env_steps_trained": 44000, "num_agent_steps_sampled": 176000, "num_agent_steps_trained": 176000}, "env_runners": {"episode_reward_max": 140.0, "episode_reward_min": -22.58391540656209, "episode_reward_mean": 21.409278916260263, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 158, "episodes_timesteps_total": 3950, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -70.0}, "policy_reward_max": {"adversary_policy": 70.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 11.645569620253164, "agent_policy": -13.52742994449923}, "custom_metrics": {}, "hist_stats": {"episode_reward": [58.143435158318994, 0.0, 0.0, -3.918110029722624, 13.67815007228078, 80.0, 100.0, -6.675853395434473, 0.0, 100.0, 55.082619156334204, 0.0, 0.0, -0.7706486848571492, 40.0, -22.58391540656209, 0.0, 0.0, 80.0, -7.770579832465927, 80.0, 0.0, 53.71670135414245, 0.0, -0.2782856899486119, 20.0, 0.0, 40.0, 0.0, -1.3204920904568307, -21.150753778464647, 60.0, -2.43206509916767, 0.0, -0.7439533267552556, 140.0, 40.0, 40.0, -22.57889844170995, -1.3384115180430212, -0.423444159317401, 60.0, 0.0, 20.0, 0.0, -1.7094448092175685, 37.51197105508702, 17.4680977900053, 0.0, 39.843080132483124, 20.0, -2.40441560851799, 0.0, 40.0, 0.0, 0.0, 46.68264783271337, 140.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 0.0, 0.0, 0.0, -2.715380214092261, 80.0, 120.0, -0.9917029632469287, 0.0, 30.22022467309212, -21.346471297841475, 0.0, 0.0, -16.75457252349477, 40.0, -4.8267026274770055, 0.0, 120.0, 0.0, -5.71088018375722, 0.0, 0.0, -4.937155479646623, 0.0, 0.0, 0.0, 60.0, 0.0, 58.69850078586276, 0.0, -1.3913976847172904, 119.90064583042175, 40.0, 37.573778907491466, -8.472999334926211, 0.0, 0.0, 20.0, -1.5571853867184704, 40.0, 0.0, 20.0, 100.0, 80.0, -7.90555464523627, 20.0, -1.1570839038731362, 0.0, 60.0, 0.0, 120.0, -0.5012921327022846, 60.0, 60.0, 0.0, 0.0, 80.0, 0.0, 0.0, -1.30010784190411, 0.0, -0.5716358043620129, 80.0, 0.0, 0.0, -11.930241277160151, 0.0, 40.0, 0.0, 0.0, 60.0, 0.0, 38.5122456716978, -20.498369216243013, -0.9809657041772124, 80.0, 55.91183453145876, 78.61363284426601, -1.6911945105033122, -6.111262105573565, -1.5472294097908912, 60.0, -0.6594609884472202, 20.0, -11.368185983919778, 19.495229457386937, 0.0, 0.0, -5.914867494841977, -1.4455558986269856, 80.0, 20.0, 120.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 70.0, 70.0, 70.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 60.0, 60.0, 60.0], "policy_agent_policy_reward": [-31.856564841681013, 0.0, 0.0, -3.918110029722624, -16.32184992771922, -40.0, -50.0, -6.675853395434473, 0.0, -50.0, -34.91738084366579, 0.0, 0.0, -0.7706486848571492, -20.0, -22.58391540656209, 0.0, 0.0, -40.0, -7.770579832465927, -40.0, 0.0, -36.283298645857556, 0.0, -0.2782856899486119, -10.0, 0.0, -20.0, 0.0, -1.3204920904568307, -21.150753778464647, -30.0, -2.43206509916767, 0.0, -0.7439533267552556, -70.0, -20.0, -20.0, -22.57889844170995, -1.3384115180430212, -0.423444159317401, -30.0, 0.0, -10.0, 0.0, -1.7094448092175685, -22.488028944912983, -12.531902209994701, 0.0, -20.156919867516876, -10.0, -2.40441560851799, 0.0, -20.0, 0.0, 0.0, -43.31735216728664, -70.0, -30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -10.0, 0.0, 0.0, 0.0, -2.715380214092261, -40.0, -60.0, -0.9917029632469287, 0.0, -29.77977532690788, -21.346471297841475, 0.0, 0.0, -16.75457252349477, -20.0, -4.8267026274770055, 0.0, -60.0, 0.0, -5.71088018375722, 0.0, 0.0, -4.937155479646623, 0.0, 0.0, 0.0, -30.0, 0.0, -31.301499214137245, 0.0, -1.3913976847172904, -60.099354169578255, -20.0, -22.426221092508534, -8.472999334926211, 0.0, 0.0, -10.0, -1.5571853867184704, -20.0, 0.0, -10.0, -50.0, -40.0, -7.90555464523627, -10.0, -1.1570839038731362, 0.0, -30.0, 0.0, -60.0, -0.5012921327022846, -30.0, -30.0, 0.0, 0.0, -40.0, 0.0, 0.0, -1.30010784190411, 0.0, -0.5716358043620129, -40.0, 0.0, 0.0, -11.930241277160151, 0.0, -20.0, 0.0, 0.0, -30.0, 0.0, -21.4877543283022, -20.498369216243013, -0.9809657041772124, -40.0, -34.08816546854125, -41.38636715573399, -1.6911945105033122, -6.111262105573565, -1.5472294097908912, -30.0, -0.6594609884472202, -10.0, -11.368185983919778, -10.504770542613063, 0.0, 0.0, -5.914867494841977, -1.4455558986269856, -40.0, -10.0, -60.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6496483714635329, "mean_inference_ms": 1.1196421107205636, "mean_action_processing_ms": 0.22511045506941163, "mean_env_wait_ms": 0.48377998109579756, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005249509328528296, "StateBufferConnector_ms": 0.003222347814825517, "ViewRequirementAgentConnector_ms": 0.08942409406734418}, "num_episodes": 158, "episode_return_max": 140.0, "episode_return_min": -22.58391540656209, "episode_return_mean": 21.409278916260263}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 176000, "num_agent_steps_trained": 176000, "num_env_steps_sampled": 44000, "num_env_steps_trained": 44000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 283.1302512669734, "num_env_steps_trained_throughput_per_sec": 283.1302512669734, "timesteps_total": 44000, "num_env_steps_sampled_lifetime": 44000, "num_agent_steps_sampled_lifetime": 176000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 176000, "timers": {"training_iteration_time_ms": 13974.203, "restore_workers_time_ms": 0.016, "training_step_time_ms": 13974.16, "sample_time_ms": 1161.211, "learn_time_ms": 12799.528, "learn_throughput": 312.512, "synch_weights_time_ms": 12.605}, "counters": {"num_env_steps_sampled": 44000, "num_env_steps_trained": 44000, "num_agent_steps_sampled": 176000, "num_agent_steps_trained": 176000}, "done": false, "training_iteration": 11, "trial_id": "b72b3_00000", "date": "2024-08-08_15-33-41", "timestamp": 1723145621, "time_this_iter_s": 14.165220022201538, "time_total_s": 153.70960688591003, "pid": 98177, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3175b3e50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 153.70960688591003, "iterations_since_restore": 11, "perf": {"cpu_util_percent": 29.350000000000005, "ram_util_percent": 82.37}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.0082616011922558, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.076402246206999, "policy_loss": -0.018387463191174902, "vf_loss": 4.092784596358737, "vf_explained_var": 0.008599207736551762, "kl": 0.010025561231137785, "entropy": 1.4313815070937077, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 11040.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7114866201442184, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.0013367259756047, "policy_loss": -0.010468540075961633, "vf_loss": 3.0102319741079993, "vf_explained_var": -2.961906980960927e-06, "kl": 0.007866290815762367, "entropy": 1.3631871384931795, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 32430.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 48000, "num_env_steps_trained": 48000, "num_agent_steps_sampled": 192000, "num_agent_steps_trained": 192000}, "env_runners": {"episode_reward_max": 140.0, "episode_reward_min": -35.423840427186676, "episode_reward_mean": 24.909815088352648, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -70.0}, "policy_reward_max": {"adversary_policy": 70.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 13.703703703703704, "agent_policy": -16.201296022758463}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 38.6610599563979, -5.698829315645091, 34.50023348898977, 40.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 100.0, 50.09816051026697, 0.0, 60.0, 0.0, 37.39952236940477, 37.36466677407801, 0.0, 60.0, -8.985290700976917, 0.0, -2.4880497726734676, 140.0, 40.0, 60.0, 80.0, 20.0, -1.247372614192802, 118.60906617993595, -7.065241304109875, 60.0, -10.267029090313256, 0.0, -10.701539866796638, -6.200969436679729, 40.0, 11.800817410022947, 80.0, 0.0, 20.0, 0.0, 0.0, -1.4537243014044143, -0.5215644958025023, 60.0, 39.475345315602624, 100.0, 0.0, 20.0, 80.0, 20.0, 0.0, 0.0, 40.0, 0.0, 0.0, 0.0, -10.772384180388421, -13.567363807567487, 37.0707978024706, 0.0, 120.0, 0.0, -14.83628849341445, 18.92126643701077, -0.3928077162587529, 60.0, -0.2519103973438974, 0.0, 60.0, 40.0, 0.0, 0.0, 0.0, 40.0, 100.0, 0.0, 0.0, 0.0, 100.0, 120.0, 0.0, 0.0, 100.0, -0.9784900006759305, 0.0, 35.47580290999466, 0.0, 99.14461139880132, 47.524270688505034, 0.0, 39.65301412678336, 75.71065074828184, 0.0, 40.0, 0.0, 120.0, -10.166050899070111, 0.0, 0.0, 80.0, 0.0, 0.0, -18.433069810686284, 0.0, 0.0, -5.949283904721869, 0.0, 80.0, 0.0, -0.6219564424117041, 31.222660746384186, 0.0, 40.0, 20.0, 0.0, 0.0, 0.0, 0.0, 100.0, 40.0, -12.139769475467789, 60.0, 0.0, 0.0, 0.0, 20.0, -4.191354672118152, 60.0, 60.0, 56.71630759433486, 59.42179272919741, -10.657431425462448, 0.0, -13.763732482749763, 100.0, 80.0, -2.755046052598881, 34.360950140463345, -35.423840427186676, 20.0, 0.0, 0.0, 0.0, -5.322453233037787, 40.0, -12.019079705013443, 60.0, -6.194647261371598, 45.73521510519424, 60.0, 60.0, 0.0, 40.0, -0.48337107406809743, 40.0, 80.0, -19.926225758783875, 60.0, 0.0, 60.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0], "policy_agent_policy_reward": [0.0, -21.3389400436021, -35.6988293156451, -25.499766511010236, -20.0, -30.0, 0.0, 0.0, 0.0, 0.0, 0.0, -50.0, -39.90183948973303, 0.0, -30.0, 0.0, -22.600477630595236, -22.63533322592199, 0.0, -30.0, -8.985290700976917, 0.0, -2.4880497726734676, -70.0, -20.0, -30.0, -40.0, -10.0, -1.247372614192802, -61.390933820064035, -7.065241304109875, -30.0, -10.267029090313256, 0.0, -10.701539866796638, -6.200969436679729, -20.0, -48.199182589977056, -40.0, 0.0, -10.0, 0.0, 0.0, -1.4537243014044143, -0.5215644958025023, -30.0, -20.52465468439738, -50.0, 0.0, -10.0, -40.0, -10.0, 0.0, 0.0, -20.0, 0.0, 0.0, 0.0, -10.772384180388421, -13.567363807567487, -22.929202197529396, 0.0, -60.0, 0.0, -14.83628849341445, -11.07873356298923, -0.3928077162587529, -30.0, -0.2519103973438974, 0.0, -30.0, -20.0, 0.0, 0.0, 0.0, -20.0, -50.0, 0.0, 0.0, 0.0, -50.0, -60.0, 0.0, 0.0, -50.0, -30.978490000675933, 0.0, -24.524197090005334, 0.0, -50.855388601198676, -42.475729311494966, 0.0, -20.346985873216635, -44.289349251718164, 0.0, -20.0, 0.0, -60.0, -10.166050899070111, 0.0, 0.0, -40.0, 0.0, 0.0, -18.433069810686284, 0.0, 0.0, -5.949283904721869, 0.0, -40.0, 0.0, -0.6219564424117041, -28.777339253615814, 0.0, -20.0, -10.0, 0.0, 0.0, 0.0, 0.0, -50.0, -20.0, -12.139769475467789, -30.0, 0.0, 0.0, 0.0, -10.0, -4.191354672118152, -30.0, -30.0, -33.28369240566514, -30.57820727080259, -10.657431425462448, 0.0, -13.763732482749763, -50.0, -40.0, -2.755046052598881, -25.639049859536655, -35.423840427186676, -10.0, 0.0, 0.0, 0.0, -5.322453233037787, -20.0, -12.019079705013443, -30.0, -6.194647261371598, -44.26478489480576, -30.0, -30.0, 0.0, -20.0, -0.48337107406809743, -20.0, -40.0, -19.926225758783875, -30.0, 0.0, -30.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6491001178483781, "mean_inference_ms": 1.119741124110982, "mean_action_processing_ms": 0.22445053441061977, "mean_env_wait_ms": 0.48354511319755683, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0044352478451199, "StateBufferConnector_ms": 0.003121075806794343, "ViewRequirementAgentConnector_ms": 0.09186606348296743}, "num_episodes": 162, "episode_return_max": 140.0, "episode_return_min": -35.423840427186676, "episode_return_mean": 24.909815088352648}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 192000, "num_agent_steps_trained": 192000, "num_env_steps_sampled": 48000, "num_env_steps_trained": 48000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 280.8949492198966, "num_env_steps_trained_throughput_per_sec": 280.8949492198966, "timesteps_total": 48000, "num_env_steps_sampled_lifetime": 48000, "num_agent_steps_sampled_lifetime": 192000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 192000, "timers": {"training_iteration_time_ms": 14101.672, "restore_workers_time_ms": 0.016, "training_step_time_ms": 14101.632, "sample_time_ms": 1156.916, "learn_time_ms": 12931.298, "learn_throughput": 309.327, "synch_weights_time_ms": 12.644}, "counters": {"num_env_steps_sampled": 48000, "num_env_steps_trained": 48000, "num_agent_steps_sampled": 192000, "num_agent_steps_trained": 192000}, "done": false, "training_iteration": 12, "trial_id": "b72b3_00000", "date": "2024-08-08_15-33-55", "timestamp": 1723145635, "time_this_iter_s": 14.24735403060913, "time_total_s": 167.95696091651917, "pid": 98177, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b86f00d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 167.95696091651917, "iterations_since_restore": 12, "perf": {"cpu_util_percent": 30.857142857142858, "ram_util_percent": 82.41428571428571}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9770834449678659, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.151271183043718, "policy_loss": -0.013974735832986578, "vf_loss": 4.163066966086626, "vf_explained_var": 0.0003339425971110662, "kl": 0.01089471473946864, "entropy": 1.4471921132256587, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 12000.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7172506791902772, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.8354443017049884, "policy_loss": -0.013965830435243217, "vf_loss": 2.8474530878219197, "vf_explained_var": 7.876563579478162e-06, "kl": 0.009785106950323277, "entropy": 1.3431807326509597, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 35250.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 52000, "num_env_steps_trained": 52000, "num_agent_steps_sampled": 208000, "num_agent_steps_trained": 208000}, "env_runners": {"episode_reward_max": 160.0, "episode_reward_min": -27.811462995883176, "episode_reward_mean": 21.438029083259654, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 157, "episodes_timesteps_total": 3925, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -80.0}, "policy_reward_max": {"adversary_policy": 80.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 12.101910828025478, "agent_policy": -14.86770340081678}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 40.0, 0.0, 20.0, 60.0, 40.0, 80.0, 0.0, -5.328762901792619, 0.0, -4.019392426581476, 140.0, 20.0, 0.0, 0.0, -7.2102677983261, 60.0, 0.0, -8.82410560862095, 38.27754133054859, 0.0, -11.182891655105344, 0.0, -25.72481998035622, 140.0, 40.0, -10.050122085132875, 30.41155572035848, -0.06249350913944074, 98.49680765061366, 40.0, 0.0, -1.3808357099806723, 100.0, 20.0, 19.62041450305592, 0.0, 60.0, -0.09358782402343335, 0.0, -11.376609401121884, 55.41202706964044, -0.18688998114074207, 40.0, -0.9708424433248197, 56.19187254774154, 35.6081514402109, 0.0, 80.0, -4.285723205432129, 20.0, 80.0, -0.19761108521901605, 0.0, 20.0, -25.056919905614397, 60.0, 0.0, 0.0, 0.0, 0.0, 21.19746956975343, 60.0, 0.0, 0.0, 38.824394421694194, 60.0, 0.0, -0.6131112096974223, -0.14591101228761616, 120.0, 20.0, 60.0, 100.0, 0.0, 79.6595778963445, 60.0, 20.0, 0.0, 100.0, -0.3705495878834597, 20.0, 0.0, 0.0, 80.0, -12.578065840114567, -0.7987148841225489, 20.0, 20.0, 59.45012856965121, 0.0, 0.0, 0.0, 0.0, -20.947726001102293, 60.0, 16.38432887719741, 80.0, -27.811462995883176, -8.667614626308598, 60.0, 0.0, -17.988217801418834, 33.38005609329815, 0.0, -1.2522507015261974, -10.838167569300039, -0.7446326837119588, 40.0, 0.0, 20.0, 9.414819243421736, 139.85434671235927, -24.747654815707033, -9.384106655117304, 0.0, 0.0, 0.0, -6.739393069807328, 20.0, -11.035717976315734, 0.0, 0.0, -0.631162222252516, 100.0, 7.603773862459086, 80.0, -13.454901335502306, -1.231935657872627, -20.472791658633547, 20.0, 60.0, -3.696497407023615, -4.295379017776941, 20.0, 160.0, 57.616879048933725, 0.0, 20.0, -0.06447493311478758, -3.3067168131502607, 0.0, 40.0, -9.169396913760302, 0.0, 100.0, 60.0, 0.0, -1.8618158166103476, 0.0, 0.0, 0.0, 20.0, 37.166666241397046, 0.0, 0.0, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 80.0, 80.0, 80.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [0.0, -20.0, 0.0, -10.0, -30.0, -20.0, -40.0, 0.0, -5.328762901792619, 0.0, -4.019392426581476, -70.0, -10.0, 0.0, 0.0, -7.2102677983261, -30.0, 0.0, -8.82410560862095, -21.722458669451413, 0.0, -11.182891655105344, 0.0, -25.72481998035622, -70.0, -20.0, -10.050122085132875, -29.58844427964152, -0.06249350913944074, -51.503192349386346, -20.0, 0.0, -1.3808357099806723, -50.0, -10.0, -10.379585496944081, 0.0, -30.0, -0.09358782402343335, 0.0, -11.376609401121884, -34.58797293035956, -0.18688998114074207, -20.0, -0.9708424433248197, -33.80812745225846, -54.3918485597891, 0.0, -40.0, -4.285723205432129, -10.0, -40.0, -0.19761108521901605, 0.0, -10.0, -25.056919905614397, -30.0, 0.0, 0.0, 0.0, 0.0, -38.80253043024657, -30.0, 0.0, 0.0, -21.175605578305806, -30.0, 0.0, -0.6131112096974223, -0.14591101228761616, -60.0, -10.0, -30.0, -50.0, 0.0, -40.340422103655506, -30.0, -10.0, 0.0, -50.0, -0.3705495878834597, -10.0, 0.0, 0.0, -40.0, -12.578065840114567, -0.7987148841225489, -10.0, -10.0, -30.549871430348794, 0.0, 0.0, 0.0, 0.0, -20.947726001102293, -30.0, -13.615671122802587, -40.0, -27.811462995883176, -8.667614626308598, -30.0, 0.0, -17.988217801418834, -26.619943906701856, 0.0, -1.2522507015261974, -10.838167569300039, -0.7446326837119588, -20.0, 0.0, -10.0, -20.585180756578268, -70.14565328764073, -24.747654815707033, -9.384106655117304, 0.0, 0.0, 0.0, -6.739393069807328, -10.0, -11.035717976315734, 0.0, 0.0, -0.631162222252516, -50.0, -22.396226137540914, -40.0, -13.454901335502306, -1.231935657872627, -20.472791658633547, -10.0, -30.0, -3.696497407023615, -4.295379017776941, -10.0, -80.0, -32.38312095106628, 0.0, -10.0, -0.06447493311478758, -3.3067168131502607, 0.0, -20.0, -9.169396913760302, 0.0, -50.0, -30.0, 0.0, -1.8618158166103476, 0.0, 0.0, 0.0, -10.0, -22.833333758602947, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6455950660864387, "mean_inference_ms": 1.1131763058425423, "mean_action_processing_ms": 0.2239887603391177, "mean_env_wait_ms": 0.48182984749973296, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004408541758348987, "StateBufferConnector_ms": 0.0030342940312282295, "ViewRequirementAgentConnector_ms": 0.08907128291524899}, "num_episodes": 157, "episode_return_max": 160.0, "episode_return_min": -27.811462995883176, "episode_return_mean": 21.438029083259654}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 208000, "num_agent_steps_trained": 208000, "num_env_steps_sampled": 52000, "num_env_steps_trained": 52000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 290.31576559393227, "num_env_steps_trained_throughput_per_sec": 290.31576559393227, "timesteps_total": 52000, "num_env_steps_sampled_lifetime": 52000, "num_agent_steps_sampled_lifetime": 208000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 208000, "timers": {"training_iteration_time_ms": 14174.689, "restore_workers_time_ms": 0.014, "training_step_time_ms": 14174.651, "sample_time_ms": 1147.853, "learn_time_ms": 13013.677, "learn_throughput": 307.369, "synch_weights_time_ms": 12.367}, "counters": {"num_env_steps_sampled": 52000, "num_env_steps_trained": 52000, "num_agent_steps_sampled": 208000, "num_agent_steps_trained": 208000}, "done": false, "training_iteration": 13, "trial_id": "b72b3_00000", "date": "2024-08-08_15-34-09", "timestamp": 1723145649, "time_this_iter_s": 13.78404688835144, "time_total_s": 181.7410078048706, "pid": 98177, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3175bc3a0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 181.7410078048706, "iterations_since_restore": 13, "perf": {"cpu_util_percent": 30.290000000000003, "ram_util_percent": 82.53}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2256959370026985, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.280616776148478, "policy_loss": -0.012079744699197667, "vf_loss": 4.29080753053228, "vf_explained_var": 0.0026899817089239757, "kl": 0.009444897121760335, "entropy": 1.4381794047852356, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 12960.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7127273877778797, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.246173812692047, "policy_loss": -0.01319378351735724, "vf_loss": 3.2574892879800594, "vf_explained_var": -1.3636147722284846e-06, "kl": 0.009391428466275602, "entropy": 1.2940037724396862, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 38070.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 56000, "num_env_steps_trained": 56000, "num_agent_steps_sampled": 224000, "num_agent_steps_trained": 224000}, "env_runners": {"episode_reward_max": 179.81078456625264, "episode_reward_min": -33.63726843933102, "episode_reward_mean": 22.487144620334345, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -101.72674782738392}, "policy_reward_max": {"adversary_policy": 90.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 12.654320987654321, "agent_policy": -15.475818342628619}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 42.35789255137159, -0.8147711898186416, -7.964556616642931, -4.571313970317994, 0.0, 0.0, 36.618454019910345, 0.0, 60.0, 179.81078456625264, -1.5602306790169729, 80.0, 0.0, 60.0, 40.0, 39.8120677567248, 60.0, 5.0091268846163715, 0.0, -2.765874325394563, 40.0, 0.0, 20.0, 60.0, 0.0, 0.0, 0.0, 0.0, 60.0, 0.0, 59.35340827277251, 0.0, 0.0, 0.0, 0.0, 20.0, 53.104041919891046, 80.0, -0.8511779121688723, -1.1140303006059793, 40.0, -7.224375233200153, -1.168090030476684, 20.0, 58.52436249470377, 0.0, 97.07272421367212, 60.0, -3.5253263599647804, 40.0, 40.0, 0.0, 98.18659836373848, -0.6983304881358543, 78.27325217261607, 0.0, 0.0, 0.0, 20.0, 0.0, 59.68113361222245, 48.121581606267426, -33.63726843933102, 0.0, -19.530893986316524, -0.49144859571826016, 37.36270111178288, -3.6429667387486546, 119.78734084256749, -1.7407316300419406, 0.0, -25.682812472727296, 37.07627406433827, 0.0, 0.0, 60.0, 0.0, 40.0, 16.57870086760741, -9.272316304404084, -9.96297305926145, 60.0, 0.0, 140.0, -14.379777829292625, 60.0, 20.0, 0.0, 40.0, 80.0, 18.661555683099394, 0.0, 59.63454329278295, 0.0, 0.0, 40.0, 98.60041179501735, 0.0, -11.324746934400011, 60.0, 0.0, 0.0, -13.991001072010793, -2.017071592949489, -1.2779447744693084, 20.0, 0.0, -1.7806192352884576, 20.0, 72.55816747631191, 38.444100725175645, 60.0, 0.0, 0.0, 0.0, 59.40094685371665, -32.954276695357706, 40.0, 60.0, 60.0, 0.0, -9.238646056495647, 0.0, -11.137572389702692, -0.8418004951998104, 0.0, -8.222374336780671, 60.0, -0.33136463640465075, 60.0, 60.0, 140.0, 20.0, 0.0, 0.0, 0.0, 35.925666284935176, 0.0, 60.0, 40.0, -3.9476982384156045, 40.0, 0.0, 27.42220914136525, 20.0, 0.0, 0.0, -22.285732459296277, 59.508704671604704, 60.0, -2.41886925497103, 0.0, -3.661611922836369, 39.27324978055778, 0.0, 40.0, -0.057066128326638266, 0.0, -3.1927872715111656, 100.0, -13.962122875457455], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 90.0, 90.0, 90.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 70.0, 70.0, 70.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [0.0, -47.64210744862841, -0.8147711898186416, -7.964556616642931, -4.571313970317994, 0.0, 0.0, -23.381545980089655, 0.0, -30.0, -90.18921543374736, -1.5602306790169729, -40.0, 0.0, -30.0, -20.0, -20.1879322432752, -30.0, -24.99087311538363, 0.0, -2.765874325394563, -20.0, 0.0, -10.0, -30.0, 0.0, 0.0, 0.0, 0.0, -30.0, 0.0, -30.646591727227488, 0.0, 0.0, 0.0, 0.0, -10.0, -36.89595808010895, -40.0, -0.8511779121688723, -1.1140303006059793, -20.0, -7.224375233200153, -1.168090030476684, -10.0, -31.47563750529623, 0.0, -52.927275786327876, -30.0, -3.5253263599647804, -20.0, -20.0, 0.0, -51.81340163626151, -0.6983304881358543, -101.72674782738392, 0.0, 0.0, 0.0, -10.0, 0.0, -30.318866387777554, -41.878418393732574, -33.63726843933102, 0.0, -19.530893986316524, -0.49144859571826016, -22.637298888217114, -3.6429667387486546, -60.21265915743251, -1.7407316300419406, 0.0, -25.682812472727296, -22.92372593566173, 0.0, 0.0, -30.0, 0.0, -20.0, -13.421299132392596, -9.272316304404084, -9.96297305926145, -30.0, 0.0, -70.0, -14.379777829292625, -30.0, -10.0, 0.0, -20.0, -40.0, -11.338444316900604, 0.0, -30.365456707217056, 0.0, 0.0, -20.0, -51.39958820498265, 0.0, -11.324746934400011, -30.0, 0.0, 0.0, -13.991001072010793, -2.017071592949489, -1.2779447744693084, -10.0, 0.0, -1.7806192352884576, -10.0, -47.44183252368809, -21.555899274824355, -30.0, 0.0, 0.0, 0.0, -30.59905314628336, -32.954276695357706, -20.0, -30.0, -30.0, 0.0, -39.23864605649565, 0.0, -11.137572389702692, -0.8418004951998104, 0.0, -8.222374336780671, -30.0, -0.33136463640465075, -30.0, -30.0, -70.0, -10.0, 0.0, 0.0, 0.0, -24.07433371506482, 0.0, -30.0, -20.0, -3.9476982384156045, -20.0, 0.0, -32.577790858634735, -10.0, 0.0, 0.0, -22.285732459296277, -30.491295328395296, -30.0, -2.41886925497103, 0.0, -3.661611922836369, -20.72675021944222, 0.0, -20.0, -0.057066128326638266, 0.0, -3.1927872715111656, -50.0, -13.962122875457455]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6425100070434752, "mean_inference_ms": 1.1079461201522662, "mean_action_processing_ms": 0.2232241968780771, "mean_env_wait_ms": 0.4799947869297175, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004140535990397136, "StateBufferConnector_ms": 0.003561855834207417, "ViewRequirementAgentConnector_ms": 0.0858255374578782}, "num_episodes": 162, "episode_return_max": 179.81078456625264, "episode_return_min": -33.63726843933102, "episode_return_mean": 22.487144620334345}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 224000, "num_agent_steps_trained": 224000, "num_env_steps_sampled": 56000, "num_env_steps_trained": 56000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 278.4358146330086, "num_env_steps_trained_throughput_per_sec": 278.4358146330086, "timesteps_total": 56000, "num_env_steps_sampled_lifetime": 56000, "num_agent_steps_sampled_lifetime": 224000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 224000, "timers": {"training_iteration_time_ms": 14220.282, "restore_workers_time_ms": 0.015, "training_step_time_ms": 14220.243, "sample_time_ms": 1136.86, "learn_time_ms": 13070.123, "learn_throughput": 306.042, "synch_weights_time_ms": 12.429}, "counters": {"num_env_steps_sampled": 56000, "num_env_steps_trained": 56000, "num_agent_steps_sampled": 224000, "num_agent_steps_trained": 224000}, "done": false, "training_iteration": 14, "trial_id": "b72b3_00000", "date": "2024-08-08_15-34-23", "timestamp": 1723145663, "time_this_iter_s": 14.419694900512695, "time_total_s": 196.1607027053833, "pid": 98177, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3175bcd30>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 196.1607027053833, "iterations_since_restore": 14, "perf": {"cpu_util_percent": 32.305, "ram_util_percent": 82.99499999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.0980317398905755, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.72529190008839, "policy_loss": -0.017169606711831875, "vf_loss": 4.740070347984632, "vf_explained_var": 0.0011186928177873293, "kl": 0.01195585013985226, "entropy": 1.417450577641527, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 13920.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.723548468281614, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.6531617137557224, "policy_loss": -0.013552515741011644, "vf_loss": 3.664976728977041, "vf_explained_var": -1.7813968320264884e-06, "kl": 0.008687389292980553, "entropy": 1.2849727854238335, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 40890.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 60000, "num_env_steps_trained": 60000, "num_agent_steps_sampled": 240000, "num_agent_steps_trained": 240000}, "env_runners": {"episode_reward_max": 180.0, "episode_reward_min": -45.603450694606636, "episode_reward_mean": 28.257738442082573, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -90.0}, "policy_reward_max": {"adversary_policy": 90.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 15.925925925925926, "agent_policy": -19.520039335695206}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 32.168221130733535, -0.2290798857169707, -23.005916559881392, 0.0, 0.0, -0.5364842321961649, 60.0, 80.0, -4.46428995565343, -5.388930987790258, 0.0, 20.0, 60.0, 40.0, 120.0, 20.0, 0.0, 0.0, -25.71954454685978, 0.0, 0.0, 60.0, 40.0, 60.0, 55.42672099428522, 100.0, 120.0, 39.72498717584175, 40.0, -0.06956190750241009, 0.0, 0.0, 59.64321707287094, 60.0, 99.77330992320293, 0.0, 12.924304611731369, 0.0, 59.83333802848922, -0.059441819060668255, 0.0, -7.0166960605012685, 40.0, 0.0, 60.0, 0.0, -6.924210804621723, 0.0, 20.0, -8.151892064941347, 0.0, 60.0, -5.063526791408381, 0.0, 60.0, 80.0, 100.0, 0.0, 20.0, 0.0, 40.0, 100.0, 40.0, -45.603450694606636, 100.0, 0.0, 0.0, 59.82092792488153, 79.83325115533462, -0.4474817390023167, 0.0, -1.1308506192375245, 0.0, -0.2568978972578162, 60.0, -1.72674730845506, 60.0, -0.06926330250013213, -10.95114876211916, 40.0, 0.0, -29.2302447818491, 0.0, 0.0, 18.626167363992394, 40.0, 37.53584395892957, 0.0, 180.0, -14.465349956390302, 40.0, 20.0, -1.2306500773728357, -22.209593067547594, -0.6421283986723536, 80.0, 40.0, 60.0, 51.664479545088454, 20.0, -1.2861119389865772, 0.0, -32.372199808024874, -31.34401198128711, 0.0, 0.0, 0.0, 20.0, 60.0, 60.0, 0.0, 40.0, 0.0, 120.0, 117.06676941690752, 8.757971051868342, -22.567653368419954, -28.159254863935686, 140.0, -7.602466044530858, 140.0, 59.51038325117871, 80.0, 80.0, 60.0, 40.0, 38.768818125814164, 38.24814866257903, 0.0, 54.047162933685584, 44.1347793426819, 17.378188053220978, 20.0, 40.0, 60.0, 0.0, -30.01951679171434, 100.0, 0.0, 0.0, 100.0, 0.0, 20.0, 34.42538832610035, 20.0, -13.43123113098101, 80.0, 0.0, 60.0, -21.814346671800216, 0.0, 60.0, 130.41139868104753, -29.410276181324683, -5.1509417745986035, 0.0, 95.30855490808781, 20.0, 50.47268875557229, 60.0, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 60.0, 60.0, 60.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 90.0, 90.0, 90.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 60.0, 60.0, 60.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [0.0, -27.83177886926647, -0.2290798857169707, -23.005916559881392, 0.0, 0.0, -0.5364842321961649, -30.0, -40.0, -4.46428995565343, -5.388930987790258, 0.0, -10.0, -30.0, -20.0, -60.0, -10.0, 0.0, 0.0, -25.71954454685978, 0.0, 0.0, -30.0, -20.0, -30.0, -34.57327900571479, -50.0, -60.0, -20.27501282415826, -20.0, -0.06956190750241009, 0.0, 0.0, -30.356782927129068, -30.0, -50.22669007679707, 0.0, -17.075695388268628, 0.0, -30.166661971510777, -0.059441819060668255, 0.0, -7.0166960605012685, -20.0, 0.0, -30.0, 0.0, -6.924210804621723, 0.0, -10.0, -8.151892064941347, 0.0, -30.0, -5.063526791408381, 0.0, -30.0, -40.0, -50.0, 0.0, -10.0, 0.0, -20.0, -50.0, -20.0, -45.603450694606636, -50.0, 0.0, 0.0, -30.179072075118473, -40.16674884466538, -0.4474817390023167, 0.0, -1.1308506192375245, 0.0, -0.2568978972578162, -30.0, -1.72674730845506, -30.0, -0.06926330250013213, -10.95114876211916, -20.0, 0.0, -29.2302447818491, 0.0, 0.0, -11.373832636007604, -20.0, -22.46415604107044, 0.0, -90.0, -14.465349956390302, -20.0, -10.0, -1.2306500773728357, -82.2095930675476, -0.6421283986723536, -40.0, -20.0, -30.0, -38.33552045491155, -10.0, -1.2861119389865772, 0.0, -32.372199808024874, -31.34401198128711, 0.0, 0.0, 0.0, -10.0, -30.0, -30.0, 0.0, -20.0, 0.0, -60.0, -62.93323058309248, -21.242028948131658, -22.567653368419954, -28.159254863935686, -70.0, -7.602466044530858, -70.0, -30.48961674882129, -40.0, -40.0, -30.0, -20.0, -21.231181874185836, -21.751851337420973, 0.0, -35.952837066314416, -45.8652206573181, -12.621811946779022, -10.0, -20.0, -30.0, 0.0, -30.01951679171434, -50.0, 0.0, 0.0, -50.0, 0.0, -10.0, -25.57461167389966, -10.0, -13.43123113098101, -40.0, 0.0, -30.0, -21.814346671800216, 0.0, -30.0, -79.5886013189525, -29.410276181324683, -5.1509417745986035, 0.0, -54.69144509191218, -10.0, -39.52731124442771, -30.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6396446465315913, "mean_inference_ms": 1.1043051925419907, "mean_action_processing_ms": 0.22224499039300205, "mean_env_wait_ms": 0.4783191766744331, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005653390177973994, "StateBufferConnector_ms": 0.003272589342093762, "ViewRequirementAgentConnector_ms": 0.09230228117954584}, "num_episodes": 162, "episode_return_max": 180.0, "episode_return_min": -45.603450694606636, "episode_return_mean": 28.257738442082573}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 240000, "num_agent_steps_trained": 240000, "num_env_steps_sampled": 60000, "num_env_steps_trained": 60000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 271.83048391619326, "num_env_steps_trained_throughput_per_sec": 271.83048391619326, "timesteps_total": 60000, "num_env_steps_sampled_lifetime": 60000, "num_agent_steps_sampled_lifetime": 240000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 240000, "timers": {"training_iteration_time_ms": 14313.39, "restore_workers_time_ms": 0.015, "training_step_time_ms": 14313.325, "sample_time_ms": 1133.556, "learn_time_ms": 13165.826, "learn_throughput": 303.817, "synch_weights_time_ms": 12.831}, "counters": {"num_env_steps_sampled": 60000, "num_env_steps_trained": 60000, "num_agent_steps_sampled": 240000, "num_agent_steps_trained": 240000}, "done": false, "training_iteration": 15, "trial_id": "b72b3_00000", "date": "2024-08-08_15-34-38", "timestamp": 1723145678, "time_this_iter_s": 14.749825716018677, "time_total_s": 210.91052842140198, "pid": 98177, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3175bcf70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 210.91052842140198, "iterations_since_restore": 15, "perf": {"cpu_util_percent": 37.17142857142857, "ram_util_percent": 83.20476190476191}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2761052528396248, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.751804240047932, "policy_loss": -0.016648100151360267, "vf_loss": 4.766223683456579, "vf_explained_var": -0.007405966520309448, "kl": 0.011143243395495972, "entropy": 1.4412525981664657, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 14880.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7124716406384258, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.473905656016465, "policy_loss": -0.012899283395753183, "vf_loss": 3.485012189716312, "vf_explained_var": -5.122321717282559e-06, "kl": 0.008963698529529213, "entropy": 1.2511863779514394, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 43710.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 64000, "num_env_steps_trained": 64000, "num_agent_steps_sampled": 256000, "num_agent_steps_trained": 256000}, "env_runners": {"episode_reward_max": 140.0, "episode_reward_min": -49.83219604637938, "episode_reward_mean": 25.62272531944188, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 158, "episodes_timesteps_total": 3950, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -70.0}, "policy_reward_max": {"adversary_policy": 70.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 14.873417721518987, "agent_policy": -18.99752784511508}, "custom_metrics": {}, "hist_stats": {"episode_reward": [19.853017843457813, -1.0888033877201941, -4.609732138752721, 80.0, -0.16468723006277108, 0.0, 20.0, 20.0, -1.2174864391897866, 0.0, 0.0, 20.0, 20.0, 0.0, 0.0, 34.51021256406958, 0.0, 0.0, 0.0, 0.0, 97.50444094862009, 40.0, 58.718008732297875, -5.81861939940018, 0.0, -2.6818103342586808, -13.735062945872887, 40.0, -0.7829684710510887, -5.811813756134643, -5.088301561368289, -34.58923026931614, 40.0, 40.0, 80.0, 140.0, -4.110675294897362, -1.6641471857207468, 0.0, 120.0, 60.0, 0.0, 60.0, 20.0, -22.863569003554932, 40.0, 58.69958403607997, -19.927726339614996, 0.0, 60.0, 0.0, 80.0, 0.0, 100.0, 0.0, 0.0, 100.0, 40.0, 140.0, 120.0, -1.9368807657740905, 0.0, 86.22962755703188, 60.0, -0.051420672125878086, 40.0, 20.0, 98.59167212033428, -3.6934510079556846, 120.0, -2.0785287135714214, 120.0, 79.5635152500996, 140.0, 0.0, 60.0, 19.17929009542265, 100.0, 99.41520820540687, 0.0, 40.0, 0.0, 60.0, -49.83219604637938, 40.0, 120.0, -26.662068991439696, 60.0, -36.490951298200756, 60.0, -5.025474651376295, -21.383402760900264, 53.65992530575643, 20.0, 56.73875851037525, -1.5568733453375083, 60.0, 0.0, -3.3165431329718063, 80.0, 0.0, -33.776644397492106, -1.2413352255660637, 80.0, -19.63480230688563, -2.021187543612398, 80.0, -4.915519209824177, 0.0, 0.0, 60.0, -33.42410529772172, -41.79498657531679, 80.0, -1.5485283683904527, 0.0, 0.0, 40.0, -1.6100021353983118, -2.7176529904213784, 0.0, -31.411426094193295, -0.31815912569938765, 0.0, 80.0, 120.0, -1.0622730144945636, 0.0, 0.0, 20.0, 0.0, -23.415812649508215, 38.872120471154965, -6.182924518140699, 20.0, 33.02503014691284, 0.0, 30.334818544734862, 20.0, 0.0, 0.0, 20.0, 60.0, 38.91985196948736, 29.68265025915597, 0.0, -2.624553865412702, 59.99571632539784, -31.026945229336715, -7.139560427519752, 60.0, 40.0, -9.098911537534415, 0.0, 23.86082076198388, 2.184086479454418, 100.0, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 70.0, 70.0, 70.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 40.0, 40.0, 40.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-10.146982156542188, -31.088803387720194, -4.609732138752721, -40.0, -0.16468723006277108, 0.0, -10.0, -10.0, -1.2174864391897866, 0.0, 0.0, -10.0, -10.0, 0.0, 0.0, -25.489787435930417, 0.0, 0.0, 0.0, 0.0, -52.4955590513799, -20.0, -31.281991267702132, -5.81861939940018, 0.0, -2.6818103342586808, -13.735062945872887, -20.0, -0.7829684710510887, -5.811813756134643, -5.088301561368289, -34.58923026931614, -20.0, -20.0, -40.0, -70.0, -4.110675294897362, -1.6641471857207468, 0.0, -60.0, -30.0, 0.0, -30.0, -10.0, -22.863569003554932, -20.0, -31.30041596392003, -19.927726339614996, 0.0, -30.0, 0.0, -40.0, 0.0, -50.0, 0.0, 0.0, -50.0, -20.0, -70.0, -60.0, -1.9368807657740905, 0.0, -63.770372442968096, -30.0, -0.051420672125878086, -20.0, -10.0, -51.40832787966572, -3.6934510079556846, -60.0, -2.0785287135714214, -60.0, -40.4364847499004, -70.0, 0.0, -30.0, -10.82070990457735, -50.0, -50.58479179459314, 0.0, -20.0, 0.0, -30.0, -49.83219604637938, -20.0, -60.0, -26.662068991439696, -30.0, -36.490951298200756, -30.0, -5.025474651376295, -21.383402760900264, -36.34007469424357, -10.0, -33.26124148962475, -1.5568733453375083, -30.0, 0.0, -3.3165431329718063, -40.0, 0.0, -33.776644397492106, -1.2413352255660637, -40.0, -19.63480230688563, -2.021187543612398, -40.0, -4.915519209824177, 0.0, 0.0, -30.0, -33.42410529772172, -41.79498657531679, -40.0, -1.5485283683904527, 0.0, 0.0, -20.0, -1.6100021353983118, -2.7176529904213784, 0.0, -31.411426094193295, -0.31815912569938765, 0.0, -40.0, -60.0, -1.0622730144945636, 0.0, 0.0, -10.0, 0.0, -23.415812649508215, -21.127879528845035, -6.182924518140699, -10.0, -26.97496985308716, 0.0, -29.665181455265135, -10.0, 0.0, 0.0, -10.0, -30.0, -21.08014803051264, -30.317349740844033, 0.0, -2.624553865412702, -30.00428367460216, -31.026945229336715, -7.139560427519752, -30.0, -20.0, -9.098911537534415, 0.0, -36.13917923801612, -27.815913520545582, -50.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6420573310250713, "mean_inference_ms": 1.1114753427852677, "mean_action_processing_ms": 0.22283994066798804, "mean_env_wait_ms": 0.4800744005029125, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006864870650858819, "StateBufferConnector_ms": 0.003249207629433161, "ViewRequirementAgentConnector_ms": 0.09260275695897356}, "num_episodes": 158, "episode_return_max": 140.0, "episode_return_min": -49.83219604637938, "episode_return_mean": 25.62272531944188}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 256000, "num_agent_steps_trained": 256000, "num_env_steps_sampled": 64000, "num_env_steps_trained": 64000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 266.85129435844624, "num_env_steps_trained_throughput_per_sec": 266.85129435844624, "timesteps_total": 64000, "num_env_steps_sampled_lifetime": 64000, "num_agent_steps_sampled_lifetime": 256000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 256000, "timers": {"training_iteration_time_ms": 14349.027, "restore_workers_time_ms": 0.015, "training_step_time_ms": 14348.959, "sample_time_ms": 1146.465, "learn_time_ms": 13188.953, "learn_throughput": 303.284, "synch_weights_time_ms": 12.496}, "counters": {"num_env_steps_sampled": 64000, "num_env_steps_trained": 64000, "num_agent_steps_sampled": 256000, "num_agent_steps_trained": 256000}, "done": false, "training_iteration": 16, "trial_id": "b72b3_00000", "date": "2024-08-08_15-34-54", "timestamp": 1723145694, "time_this_iter_s": 15.02149224281311, "time_total_s": 225.9320206642151, "pid": 98177, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b86db790>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 225.9320206642151, "iterations_since_restore": 16, "perf": {"cpu_util_percent": 42.013636363636365, "ram_util_percent": 83.00909090909092}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1007583965236942, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.3044499921302, "policy_loss": -0.01582514446757462, "vf_loss": 4.318026779343684, "vf_explained_var": -0.005123188967506091, "kl": 0.011241776692797304, "entropy": 1.4226122616479795, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 15840.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.721529946787983, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.635357478408949, "policy_loss": -0.013838235324773778, "vf_loss": 3.647449394151674, "vf_explained_var": 2.7576025496137905e-06, "kl": 0.008731530455939702, "entropy": 1.224097317076744, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 46530.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 68000, "num_env_steps_trained": 68000, "num_agent_steps_sampled": 272000, "num_agent_steps_trained": 272000}, "env_runners": {"episode_reward_max": 160.0, "episode_reward_min": -19.692845061110273, "episode_reward_mean": 29.77077072644913, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 157, "episodes_timesteps_total": 3925, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -80.0}, "policy_reward_max": {"adversary_policy": 80.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 15.668789808917197, "agent_policy": -17.235598700302464}, "custom_metrics": {}, "hist_stats": {"episode_reward": [160.0, 0.0, 40.0, 120.0, 60.0, 78.0836238655232, -14.429999827662707, 0.0, 100.0, 80.0, 30.53310134571747, 60.0, 39.289480698548786, 0.0, 0.0, 38.524716002749855, 80.0, 0.0, 40.0, -0.07537701092564908, 40.0, 60.0, -0.4899146346262717, -0.5233475524296205, 0.0, 0.0, 20.0, 0.0, 60.0, 0.0, 18.83089574015148, -14.372374925591844, 80.0, -0.08156373803789863, -0.26770504843836695, 40.0, 20.0, 119.79439647521957, 41.245832896579685, 20.0, -6.979744396271523, 80.0, 20.0, 30.783935255707984, 0.0, 20.0, 0.0, 20.0, 60.0, 20.0, 40.0, 40.0, 98.08564765108275, 0.0, 0.0, 60.0, 18.45176032548193, -3.1002762898459126, 92.35921562392468, 160.0, 59.996434919930095, 160.0, 20.0, 57.07757741385751, 0.0, -1.0321065128335727, 40.0, -13.044112393899375, 40.0, -2.629059569139274, 0.0, 74.63797524561673, -10.991559634687237, 60.0, 40.0, 20.0, 0.0, 20.0, 40.0, 80.0, -0.9122167843526219, 0.0, -2.128924959736099, 20.0, 0.0, 60.0, 20.0, 80.0, 0.0, 0.0, 40.0, 0.0, 98.39839667383356, 40.0, 60.0, 0.0, 20.0, 37.67662596070159, 80.0, 20.0, 39.14987504453497, 140.0, 0.0, -2.827898704000396, 57.93132670114798, -1.9176759877090255, 60.0, 0.0, 0.0, 16.35795833158437, -8.722615144272197, 79.74784145175425, 0.0, 0.0, 0.0, -3.482067289033238, -4.630325350801599, 0.0, 20.0, 0.0, 0.0, 68.74676879387954, 60.0, 100.0, 0.0, -1.5388468664397315, 0.0, -0.10781873786348872, 0.0, -19.692845061110273, 0.0, 60.0, 0.0, -7.789819378524322, -0.3339099523907063, 19.664757126517806, 40.0, 0.0, 100.0, 20.0, 0.0, 40.0, 0.0, 0.0, 40.0, 0.0, 38.55357681852816, 0.0, -9.820000530843492, -0.96841618378675, -1.7895428184086926, 60.0, 99.97071691937076, 0.0, 40.0, 80.0, 34.79863205423033], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [80.0, 80.0, 80.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 60.0, 60.0, 60.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 60.0, 60.0, 60.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 80.0, 80.0, 80.0, 30.0, 30.0, 30.0, 80.0, 80.0, 80.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0], "policy_agent_policy_reward": [-80.0, 0.0, -20.0, -60.0, -30.0, -41.916376134476806, -14.429999827662707, 0.0, -50.0, -40.0, -29.466898654282527, -30.0, -20.710519301451214, 0.0, 0.0, -21.47528399725015, -40.0, 0.0, -20.0, -0.07537701092564908, -20.0, -30.0, -0.4899146346262717, -0.5233475524296205, 0.0, 0.0, -10.0, 0.0, -30.0, 0.0, -11.169104259848519, -14.372374925591844, -40.0, -0.08156373803789863, -0.26770504843836695, -20.0, -10.0, -60.20560352478043, -48.754167103420315, -10.0, -6.979744396271523, -40.0, -10.0, -59.21606474429201, 0.0, -10.0, 0.0, -10.0, -30.0, -10.0, -20.0, -20.0, -51.91435234891726, 0.0, 0.0, -30.0, -11.548239674518069, -3.1002762898459126, -57.64078437607532, -80.0, -30.003565080069905, -80.0, -10.0, -32.92242258614248, 0.0, -1.0321065128335727, -20.0, -13.044112393899375, -20.0, -2.629059569139274, 0.0, -45.362024754383285, -10.991559634687237, -30.0, -20.0, -10.0, 0.0, -10.0, -20.0, -40.0, -0.9122167843526219, 0.0, -2.128924959736099, -10.0, 0.0, -30.0, -10.0, -40.0, 0.0, 0.0, -20.0, 0.0, -51.60160332616644, -20.0, -30.0, 0.0, -10.0, -22.323374039298407, -40.0, -10.0, -20.850124955465034, -70.0, 0.0, -2.827898704000396, -32.06867329885202, -1.9176759877090255, -30.0, 0.0, 0.0, -13.642041668415631, -8.722615144272197, -40.25215854824575, 0.0, 0.0, 0.0, -3.482067289033238, -4.630325350801599, 0.0, -10.0, 0.0, 0.0, -51.25323120612046, -30.0, -50.0, 0.0, -1.5388468664397315, 0.0, -0.10781873786348872, 0.0, -19.692845061110273, 0.0, -30.0, 0.0, -7.789819378524322, -0.3339099523907063, -10.335242873482192, -20.0, 0.0, -50.0, -10.0, 0.0, -20.0, 0.0, 0.0, -20.0, 0.0, -21.44642318147184, 0.0, -9.820000530843492, -0.96841618378675, -1.7895428184086926, -30.0, -50.02928308062924, 0.0, -20.0, -40.0, -25.201367945769665]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6447120674066531, "mean_inference_ms": 1.113527051297156, "mean_action_processing_ms": 0.2232477820918259, "mean_env_wait_ms": 0.4809189173948408, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004990389392634106, "StateBufferConnector_ms": 0.003350464401731066, "ViewRequirementAgentConnector_ms": 0.09824948705685367}, "num_episodes": 157, "episode_return_max": 160.0, "episode_return_min": -19.692845061110273, "episode_return_mean": 29.77077072644913}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 272000, "num_agent_steps_trained": 272000, "num_env_steps_sampled": 68000, "num_env_steps_trained": 68000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 190.48869935259427, "num_env_steps_trained_throughput_per_sec": 190.48869935259427, "timesteps_total": 68000, "num_env_steps_sampled_lifetime": 68000, "num_agent_steps_sampled_lifetime": 272000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 272000, "timers": {"training_iteration_time_ms": 15014.878, "restore_workers_time_ms": 0.015, "training_step_time_ms": 15014.809, "sample_time_ms": 1159.871, "learn_time_ms": 13840.975, "learn_throughput": 288.997, "synch_weights_time_ms": 12.899}, "counters": {"num_env_steps_sampled": 68000, "num_env_steps_trained": 68000, "num_agent_steps_sampled": 272000, "num_agent_steps_trained": 272000}, "done": false, "training_iteration": 17, "trial_id": "b72b3_00000", "date": "2024-08-08_15-35-15", "timestamp": 1723145715, "time_this_iter_s": 21.013206958770752, "time_total_s": 246.94522762298584, "pid": 98177, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b86dbca0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 246.94522762298584, "iterations_since_restore": 17, "perf": {"cpu_util_percent": 64.65666666666667, "ram_util_percent": 83.19666666666667}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.229240535137554, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.212065983066956, "policy_loss": -0.016726470186646716, "vf_loss": 5.226606817295154, "vf_explained_var": 0.0025920582314332328, "kl": 0.010928218188206721, "entropy": 1.390547909339269, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 16800.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7639287605564645, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.011629241155394, "policy_loss": -0.015006302738337652, "vf_loss": 4.024831929866304, "vf_explained_var": -2.790871241413955e-06, "kl": 0.009018024916026175, "entropy": 1.2119843392507403, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 49350.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 72000, "num_env_steps_trained": 72000, "num_agent_steps_sampled": 288000, "num_agent_steps_trained": 288000}, "env_runners": {"episode_reward_max": 160.0, "episode_reward_min": -36.567120871707914, "episode_reward_mean": 31.580614502714322, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -80.0}, "policy_reward_max": {"adversary_policy": 80.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 17.530864197530864, "agent_policy": -21.01197808987827}, "custom_metrics": {}, "hist_stats": {"episode_reward": [79.36219935531051, -0.7765303179830851, 39.95928461636581, 60.0, -22.51819165735244, -10.352431506569662, 0.0, -36.567120871707914, 76.48750494301486, -24.163038298751378, 80.0, 117.79841476121297, -7.8660736698084595, 0.0, 11.787591748330993, -2.3804468947002277, -1.8006664129460248, 30.940217687841578, 20.0, 0.0, 80.0, -0.3962073617487216, 100.0, 0.0, 140.0, 140.0, 0.0, 60.0, -22.366485298270504, 20.0, 0.0, 60.0, 100.0, 0.0, -17.079207249513246, -16.098120128768354, 0.0, 80.0, 0.0, -0.795245970257884, 0.0, 0.0, 20.0, 0.0, 80.0, 58.553565178066975, 40.0, 60.0, 80.0, 0.0, 20.0, 60.0, 59.18383307115417, 80.0, 39.005786935833, 9.380513527501385, 20.0, 100.0, 60.0, -23.70455523936659, 120.0, 54.08952598400853, 18.822050050897083, 60.0, 60.0, 160.0, 79.74156457016849, 19.983409847897335, 40.0, -22.601812735112162, 119.75846416870746, -5.825478467175014, 0.0, -9.452368337395685, 40.0, 0.0, 96.60228593946864, 58.4673345295451, -18.990082611692337, 0.0, 0.0, 40.0, 0.0, 60.0, 0.0, 0.0, -8.996733645194825, 0.0, 118.95074973429766, 0.0, 0.0, 19.741596601078918, 60.0, 0.0, 20.0, 60.28231411695525, 100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 28.37691725160326, 40.0, 2.233082192978938, 80.0, -0.4743115227549799, -13.786409397958066, 0.0, -2.4253624856493405, -8.191182023216504, 100.0, 19.859445973959367, 0.0, 60.0, -24.741158532759023, 60.0, 40.0, -0.7364212431466599, 60.0, 80.0, 74.90653707454847, -0.37859739618001376, 40.0, 40.0, -3.728755832437092, 0.0, 15.618988329632769, 60.0, -0.30022036918281647, 0.0, 0.0, 80.0, 15.411168956444971, -16.270536407082012, 40.0, 0.0, 0.0, 40.0, 120.0, 60.0, 60.0, 19.818486661317056, 58.89845341141168, 80.0, 120.0, 160.0, -1.7139212612123755, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 57.51593536606033, 0.0, 0.0, 0.0, 40.0, 0.0, 80.0, 60.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 80.0, 80.0, 80.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 60.0, 60.0, 60.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 60.0, 60.0, 60.0, 80.0, 80.0, 80.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0], "policy_agent_policy_reward": [-40.63780064468949, -0.7765303179830851, -20.040715383634193, -30.0, -22.51819165735244, -10.352431506569662, 0.0, -36.567120871707914, -43.512495056985145, -24.163038298751378, -40.0, -62.20158523878704, -7.8660736698084595, 0.0, -18.212408251669007, -2.3804468947002277, -1.8006664129460248, -29.059782312158426, -10.0, 0.0, -40.0, -0.3962073617487216, -50.0, 0.0, -70.0, -70.0, 0.0, -30.0, -22.366485298270504, -10.0, 0.0, -30.0, -50.0, 0.0, -47.079207249513246, -16.098120128768354, 0.0, -40.0, 0.0, -0.795245970257884, 0.0, 0.0, -10.0, 0.0, -40.0, -31.44643482193303, -20.0, -30.0, -40.0, 0.0, -10.0, -30.0, -30.81616692884584, -40.0, -20.994213064166996, -50.619486472498615, -10.0, -50.0, -30.0, -23.70455523936659, -60.0, -35.910474015991475, -11.17794994910292, -30.0, -30.0, -80.0, -40.2584354298315, -10.016590152102664, -20.0, -22.601812735112162, -60.24153583129252, -5.825478467175014, 0.0, -39.45236833739568, -20.0, 0.0, -53.39771406053136, -31.532665470454894, -18.990082611692337, 0.0, 0.0, -20.0, 0.0, -30.0, 0.0, 0.0, -8.996733645194825, 0.0, -61.04925026570235, 0.0, 0.0, -40.25840339892108, -30.0, 0.0, -10.0, -59.71768588304475, -50.0, 0.0, 0.0, 0.0, 0.0, 0.0, -31.623082748396744, -20.0, -27.76691780702106, -40.0, -0.4743115227549799, -13.786409397958066, 0.0, -2.4253624856493405, -8.191182023216504, -50.0, -40.14055402604063, 0.0, -30.0, -24.741158532759023, -30.0, -20.0, -0.7364212431466599, -30.0, -40.0, -45.09346292545153, -0.37859739618001376, -20.0, -20.0, -3.728755832437092, 0.0, -44.38101167036723, -30.0, -0.30022036918281647, 0.0, 0.0, -40.0, -14.588831043555032, -16.270536407082012, -20.0, 0.0, 0.0, -20.0, -60.0, -30.0, -30.0, -10.181513338682944, -31.101546588588324, -40.0, -60.0, -80.0, -1.7139212612123755, -10.0, -10.0, 0.0, 0.0, 0.0, -10.0, -32.48406463393967, 0.0, 0.0, 0.0, -20.0, 0.0, -40.0, -30.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6496460376939591, "mean_inference_ms": 1.1225001596175783, "mean_action_processing_ms": 0.2244812896814712, "mean_env_wait_ms": 0.4845203602798537, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0064008765750461155, "StateBufferConnector_ms": 0.003358832112065068, "ViewRequirementAgentConnector_ms": 0.11921510284329638}, "num_episodes": 162, "episode_return_max": 160.0, "episode_return_min": -36.567120871707914, "episode_return_mean": 31.580614502714322}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 288000, "num_agent_steps_trained": 288000, "num_env_steps_sampled": 72000, "num_env_steps_trained": 72000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 248.2941154445476, "num_env_steps_trained_throughput_per_sec": 248.2941154445476, "timesteps_total": 72000, "num_env_steps_sampled_lifetime": 72000, "num_agent_steps_sampled_lifetime": 288000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 288000, "timers": {"training_iteration_time_ms": 15205.22, "restore_workers_time_ms": 0.016, "training_step_time_ms": 15205.15, "sample_time_ms": 1182.868, "learn_time_ms": 14008.33, "learn_throughput": 285.544, "synch_weights_time_ms": 12.966}, "counters": {"num_env_steps_sampled": 72000, "num_env_steps_trained": 72000, "num_agent_steps_sampled": 288000, "num_agent_steps_trained": 288000}, "done": false, "training_iteration": 18, "trial_id": "b72b3_00000", "date": "2024-08-08_15-35-31", "timestamp": 1723145731, "time_this_iter_s": 16.15370488166809, "time_total_s": 263.09893250465393, "pid": 98177, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b870d1f0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 263.09893250465393, "iterations_since_restore": 18, "perf": {"cpu_util_percent": 38.673913043478265, "ram_util_percent": 83.42173913043476}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2755269781375924, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.227200993150473, "policy_loss": -0.02223080447729444, "vf_loss": 5.246652709444364, "vf_explained_var": -0.0013213465611139933, "kl": 0.01389556387652425, "entropy": 1.3894201880941788, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 17760.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7445198840177651, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.055676504145278, "policy_loss": -0.010048572902884731, "vf_loss": 4.064439273303282, "vf_explained_var": -1.8642515155440527e-06, "kl": 0.006428986834159407, "entropy": 1.177614931307786, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 52170.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 76000, "num_env_steps_trained": 76000, "num_agent_steps_sampled": 304000, "num_agent_steps_trained": 304000}, "env_runners": {"episode_reward_max": 140.0, "episode_reward_min": -43.010887433041084, "episode_reward_mean": 32.85843058657764, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -70.0}, "policy_reward_max": {"adversary_policy": 70.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 18.14814814814815, "agent_policy": -21.5860138578668}, "custom_metrics": {}, "hist_stats": {"episode_reward": [65.39889261829607, 0.0, 0.0, -6.636311528289115, -0.0928580474723073, 58.079541683944235, 20.0, 20.0, -2.591055932681911, 140.0, 60.0, 100.0, -6.060404611487043, 40.0, 0.0, 40.0, 54.84750032209366, 0.0, 100.0, 100.0, -11.256257597844549, 140.0, 0.0, 100.0, 100.0, -11.44213919706008, 13.965387206710624, -2.566450122043047, -3.5103767849092127, 100.0, 59.61202074327451, 0.0, -24.249975574119837, 0.0, -0.5966685471360189, 0.0, 38.37880287842481, 0.0, -43.010887433041084, -15.136353426952498, 58.64289354038547, 40.0, 60.0, 0.0, 39.71172008914694, 29.734647766574476, 80.0, 0.0, 140.0, 60.0, 60.0, 40.0, -20.959064865425923, 52.82050952673116, -9.936935370075057, 40.0, 0.0, 120.0, 60.0, 79.7971930843237, 80.0, 73.54904125313635, -31.81246584372836, 0.0, 40.0, -20.707905281229188, 79.43329359648628, 60.0, 37.502087529678235, 0.0, -0.5274694466310859, 60.0, 0.0, 0.0, -17.718354668774012, 58.9339396227718, -1.3172201750488932, -18.599392490368682, 0.0, -9.42993903783084, 58.43212881550156, 0.0, -10.495741327398761, 112.78749127716125, 59.48364976906874, 60.0, 60.0, 60.0, 120.0, 0.0, -3.7069797071409143, 40.0, 80.0, 0.0, 40.0, 100.0, 120.0, 0.0, 80.0, 40.0, 40.0, 58.795119996377764, 0.0, 100.0, -24.735373376762904, 80.0, 56.15387693720642, 60.0, -23.547982891279677, -15.490866039316048, 17.25062735759274, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 0.0, 0.0, 0.0, 54.25722244512542, 99.86105908821791, 20.0, 0.0, 0.0, 59.368383309762635, -33.47776408479908, 13.117382449805945, 0.6097547795512419, -21.01188538636013, 0.0, -0.21798932294115891, 0.0, 0.0, 99.18637139295757, 20.0, 59.88790036377182, 40.0, 20.0, 60.0, 88.15796599355446, 0.0, 0.0, 0.0, 40.0, 20.0, 48.95250635786815, 34.18295942798485, -13.175716898152263, 60.0, 0.0, 140.0, 80.0, 0.0, -0.6594644893472723, -1.6921346011792104, 33.111934276508144, 35.43233363241009, 100.0, 0.0, 100.0, 100.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0], "policy_agent_policy_reward": [-54.60110738170393, 0.0, 0.0, -6.636311528289115, -0.0928580474723073, -31.92045831605576, -10.0, -10.0, -2.591055932681911, -70.0, -30.0, -50.0, -6.060404611487043, -20.0, 0.0, -20.0, -35.15249967790634, 0.0, -50.0, -50.0, -11.256257597844549, -70.0, 0.0, -50.0, -50.0, -11.44213919706008, -16.034612793289376, -2.566450122043047, -3.5103767849092127, -50.0, -30.387979256725494, 0.0, -24.249975574119837, 0.0, -0.5966685471360189, 0.0, -21.621197121575197, 0.0, -43.010887433041084, -15.136353426952498, -31.357106459614535, -20.0, -30.0, 0.0, -20.288279910853063, -30.265352233425524, -40.0, 0.0, -70.0, -30.0, -30.0, -20.0, -20.959064865425923, -37.17949047326884, -9.936935370075057, -20.0, 0.0, -60.0, -30.0, -40.202806915676305, -40.0, -46.45095874686364, -31.81246584372836, 0.0, -20.0, -20.707905281229188, -40.56670640351372, -30.0, -22.497912470321765, 0.0, -0.5274694466310859, -30.0, 0.0, 0.0, -17.718354668774012, -31.0660603772282, -1.3172201750488932, -18.599392490368682, 0.0, -9.42993903783084, -31.567871184498447, 0.0, -10.495741327398761, -67.21250872283875, -30.51635023093126, -30.0, -30.0, -30.0, -60.0, 0.0, -3.7069797071409143, -20.0, -40.0, 0.0, -20.0, -50.0, -60.0, 0.0, -40.0, -20.0, -20.0, -31.20488000362224, 0.0, -50.0, -24.735373376762904, -40.0, -33.84612306279358, -30.0, -23.547982891279677, -15.490866039316048, -12.749372642407259, -10.0, -10.0, 0.0, 0.0, 0.0, -10.0, 0.0, 0.0, 0.0, -35.74277755487458, -50.138940911782086, -10.0, 0.0, 0.0, -30.631616690237372, -33.47776408479908, -16.882617550194055, -29.390245220448758, -21.01188538636013, 0.0, -0.21798932294115891, 0.0, 0.0, -50.81362860704244, -10.0, -30.112099636228187, -20.0, -10.0, -30.0, -61.84203400644553, 0.0, 0.0, 0.0, -20.0, -10.0, -41.04749364213185, -25.817040572015152, -13.175716898152263, -30.0, 0.0, -70.0, -40.0, 0.0, -0.6594644893472723, -1.6921346011792104, -26.888065723491856, -24.5676663675899, -50.0, 0.0, -50.0, -50.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6500465546810209, "mean_inference_ms": 1.122567842309164, "mean_action_processing_ms": 0.22483653565129783, "mean_env_wait_ms": 0.48418731996661957, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0066321573139708715, "StateBufferConnector_ms": 0.003412549878344124, "ViewRequirementAgentConnector_ms": 0.09895636711591556}, "num_episodes": 162, "episode_return_max": 140.0, "episode_return_min": -43.010887433041084, "episode_return_mean": 32.85843058657764}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 304000, "num_agent_steps_trained": 304000, "num_env_steps_sampled": 76000, "num_env_steps_trained": 76000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 269.5787459313849, "num_env_steps_trained_throughput_per_sec": 269.5787459313849, "timesteps_total": 76000, "num_env_steps_sampled_lifetime": 76000, "num_agent_steps_sampled_lifetime": 304000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 304000, "timers": {"training_iteration_time_ms": 15257.925, "restore_workers_time_ms": 0.016, "training_step_time_ms": 15257.852, "sample_time_ms": 1188.504, "learn_time_ms": 14053.66, "learn_throughput": 284.623, "synch_weights_time_ms": 14.169}, "counters": {"num_env_steps_sampled": 76000, "num_env_steps_trained": 76000, "num_agent_steps_sampled": 304000, "num_agent_steps_trained": 304000}, "done": false, "training_iteration": 19, "trial_id": "b72b3_00000", "date": "2024-08-08_15-35-46", "timestamp": 1723145746, "time_this_iter_s": 14.875202178955078, "time_total_s": 277.974134683609, "pid": 98177, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b870d430>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 277.974134683609, "iterations_since_restore": 19, "perf": {"cpu_util_percent": 36.37619047619047, "ram_util_percent": 83.54285714285714}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4522567848985395, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.427921338627736, "policy_loss": -0.0158524981517985, "vf_loss": 5.441575934986274, "vf_explained_var": 0.0018732103829582532, "kl": 0.010989430260407152, "entropy": 1.378672470897436, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 18720.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7428823661191244, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.6214179950402983, "policy_loss": -0.01300184631174024, "vf_loss": 3.6329602544189346, "vf_explained_var": -1.2475125333096119e-06, "kl": 0.007297883712744233, "entropy": 1.156459333668364, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 54990.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 80000, "num_env_steps_trained": 80000, "num_agent_steps_sampled": 320000, "num_agent_steps_trained": 320000}, "env_runners": {"episode_reward_max": 200.0, "episode_reward_min": -52.37451247032446, "episode_reward_mean": 30.610550949150383, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -100.0}, "policy_reward_max": {"adversary_policy": 100.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 17.71604938271605, "agent_policy": -22.537597198997766}, "custom_metrics": {}, "hist_stats": {"episode_reward": [80.0, -32.193149378663975, 20.0, 117.54249203508249, 38.53259289849427, 0.0, 39.88550072693945, 59.04642128473884, 0.0, 37.615031625031776, 56.14663732691642, 60.0, -52.37451247032446, -15.668438065688614, -4.954074383613738, 0.0, 60.0, 0.0, -24.05277315992579, 17.190541386004387, 78.72597331934766, -10.170592748277102, 40.0, 0.0, 160.0, 78.46851945099357, 40.0, 80.0, 0.0, 40.0, -11.276044442624318, -4.806295236960792, 59.55162547272789, 40.0, 80.0, 60.0, -7.07532621659044, 79.85919970231487, 53.37856269419183, -13.027221450755786, 60.0, 0.0, 100.0, -0.48814237671863214, 113.87228141942828, -1.9325059891666885, -10.186530700235615, -2.4178490501326086, 160.0, 60.0, 100.0, 0.0, 60.0, -18.825045143445553, -2.8552906230230732, 100.0, 96.03629203163868, 0.0, 40.0, 0.0, 139.70424395406758, 43.58349450934716, 40.0, 0.0, 20.0, 80.0, 66.26618007466827, 0.0, 0.0, -44.88376492394998, 40.0, -23.231239626302937, 40.0, 57.862072162674025, 20.0, 38.63388097693905, 40.0, 18.02645512152033, 60.0, 0.0, -0.7229803338413165, 200.0, -11.017971916469007, 160.0, 20.0, 0.0, 40.0, 60.0, -1.0238827242564663, 60.0, 73.34177133591864, 33.67043282165648, -16.074873808701902, 75.43132298848343, 20.0, 0.0, 0.0, -13.140822795711207, 140.0, 0.0, 0.0, -10.483504929564312, -1.87402612886859, 35.501909321492285, 60.0, 0.0, 0.0, 0.0, 200.0, 60.0, 0.0, -30.426537638106655, -0.35797830190883895, 40.0, -10.242921562097104, -22.702276967116983, -0.23360466875968822, -12.098680157590548, 0.0, -8.21076828284176, 0.0, 80.0, -20.02778664522355, 0.0, 57.28087252183177, 37.174154522064526, 34.31784809211013, 0.0, 0.0, 40.0, 15.319481495555133, 0.0, -20.44764034627937, 0.0, 20.0, 20.0, 0.0, 40.0, 40.0, 39.8123726360632, -26.868931446363266, 159.7536019529597, -48.63511802615245, 0.0, -17.820354710739952, -13.733686701674406, 40.0, 19.517104136515435, 20.0, 39.84307015732501, 80.0, -13.955878730017384, 20.0, 36.281180400067754, 57.283796620241446, 100.0, 19.750919269802313, 0.9075720455027083, 40.0, 100.0, 34.312868080390075, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 80.0, 80.0, 80.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 80.0, 80.0, 80.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 100.0, 100.0, 100.0, 0.0, 0.0, 0.0, 80.0, 80.0, 80.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 100.0, 100.0, 100.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 80.0, 80.0, 80.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-40.0, -32.193149378663975, -10.0, -62.45750796491751, -21.467407101505728, 0.0, -20.114499273060552, -30.953578715261155, 0.0, -22.38496837496822, -33.85336267308358, -30.0, -52.37451247032446, -15.668438065688614, -4.954074383613738, 0.0, -30.0, 0.0, -24.05277315992579, -12.809458613995616, -41.27402668065234, -10.170592748277102, -20.0, 0.0, -80.0, -41.531480549006424, -20.0, -40.0, 0.0, -20.0, -11.276044442624318, -4.806295236960792, -30.448374527272104, -20.0, -40.0, -30.0, -7.07532621659044, -40.14080029768513, -36.62143730580817, -13.027221450755786, -30.0, 0.0, -50.0, -0.48814237671863214, -66.12771858057172, -1.9325059891666885, -10.186530700235615, -2.4178490501326086, -80.0, -30.0, -50.0, 0.0, -30.0, -18.825045143445553, -2.8552906230230732, -50.0, -53.96370796836132, 0.0, -20.0, 0.0, -70.29575604593242, -46.41650549065283, -20.0, 0.0, -10.0, -40.0, -53.73381992533172, 0.0, 0.0, -44.88376492394998, -20.0, -23.231239626302937, -20.0, -32.13792783732598, -10.0, -21.366119023060953, -20.0, -11.973544878479672, -30.0, 0.0, -0.7229803338413165, -100.0, -11.017971916469007, -80.0, -10.0, 0.0, -20.0, -30.0, -1.0238827242564663, -30.0, -46.65822866408136, -26.329567178343506, -16.074873808701902, -44.568677011516556, -10.0, 0.0, 0.0, -13.140822795711207, -70.0, 0.0, 0.0, -10.483504929564312, -1.87402612886859, -54.498090678507715, -30.0, 0.0, 0.0, 0.0, -100.0, -30.0, 0.0, -30.426537638106655, -0.35797830190883895, -20.0, -10.242921562097104, -22.702276967116983, -0.23360466875968822, -12.098680157590548, 0.0, -8.21076828284176, 0.0, -40.0, -20.02778664522355, 0.0, -32.71912747816824, -22.825845477935474, -25.682151907889864, 0.0, 0.0, -20.0, -44.68051850444487, 0.0, -20.44764034627937, 0.0, -10.0, -10.0, 0.0, -20.0, -20.0, -50.1876273639368, -26.868931446363266, -80.24639804704029, -48.63511802615245, 0.0, -17.820354710739952, -13.733686701674406, -20.0, -10.482895863484563, -10.0, -20.15692984267499, -40.0, -13.955878730017384, -10.0, -23.71881959993225, -32.716203379758554, -50.0, -10.249080730197687, -29.092427954497296, -20.0, -50.0, -25.687131919609925, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6538363370267594, "mean_inference_ms": 1.1261386932611848, "mean_action_processing_ms": 0.22575508301125796, "mean_env_wait_ms": 0.48549555837978614, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004519871723504714, "StateBufferConnector_ms": 0.004271371864978178, "ViewRequirementAgentConnector_ms": 0.09614928269091948}, "num_episodes": 162, "episode_return_max": 200.0, "episode_return_min": -52.37451247032446, "episode_return_mean": 30.610550949150383}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 320000, "num_agent_steps_trained": 320000, "num_env_steps_sampled": 80000, "num_env_steps_trained": 80000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 259.05477184573954, "num_env_steps_trained_throughput_per_sec": 259.05477184573954, "timesteps_total": 80000, "num_env_steps_sampled_lifetime": 80000, "num_agent_steps_sampled_lifetime": 320000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 320000, "timers": {"training_iteration_time_ms": 15360.411, "restore_workers_time_ms": 0.016, "training_step_time_ms": 15360.325, "sample_time_ms": 1202.43, "learn_time_ms": 14141.013, "learn_throughput": 282.865, "synch_weights_time_ms": 15.128}, "counters": {"num_env_steps_sampled": 80000, "num_env_steps_trained": 80000, "num_agent_steps_sampled": 320000, "num_agent_steps_trained": 320000}, "done": false, "training_iteration": 20, "trial_id": "b72b3_00000", "date": "2024-08-08_15-36-02", "timestamp": 1723145762, "time_this_iter_s": 15.504165887832642, "time_total_s": 293.47830057144165, "pid": 98177, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b870daf0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 293.47830057144165, "iterations_since_restore": 20, "perf": {"cpu_util_percent": 36.73478260869565, "ram_util_percent": 83.15652173913043}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.535886406339705, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.621966171761354, "policy_loss": -0.016354245889912515, "vf_loss": 5.63650509317716, "vf_explained_var": -0.002563389576971531, "kl": 0.009076563111521451, "entropy": 1.3639965936541558, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 19680.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.750817224742673, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.300022867300831, "policy_loss": -0.014470313998692213, "vf_loss": 4.312804742823256, "vf_explained_var": 3.5575518371365596e-06, "kl": 0.008442145246930478, "entropy": 1.134755628117433, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 57810.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 84000, "num_env_steps_trained": 84000, "num_agent_steps_sampled": 336000, "num_agent_steps_trained": 336000}, "env_runners": {"episode_reward_max": 160.0, "episode_reward_min": -44.52416538056761, "episode_reward_mean": 31.90875025821811, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 153, "episodes_timesteps_total": 3825, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -91.13666414432566}, "policy_reward_max": {"adversary_policy": 80.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 18.235294117647058, "agent_policy": -22.797132094723068}, "custom_metrics": {}, "hist_stats": {"episode_reward": [100.0, 60.0, 0.0, -37.11507154516608, 20.0, 40.0, -3.4837800828870025, 79.1909606746599, -12.686271896476894, 100.0, 33.465675743289175, 59.57298608283811, -0.634366503326429, 100.0, -12.453866379455423, 60.0, 60.0, 36.04700360945751, 5.510265906954807, 0.0, 19.74599089287841, 40.0, 20.0, 60.0, 0.0, -1.6409623407685914, 0.0, -24.539726425809523, 0.0, 120.0, 55.35825216246576, 38.259228171009795, 0.0, 40.0, -19.647205522302926, -0.9217159595634095, -6.516211601171945, 0.0, 48.65808465256195, 60.0, -15.847386018470052, 20.0, -2.3140839891713156, 40.0, -41.88053456471916, 79.6453883417337, -1.4435808358458058, 0.0, 140.0, 91.64506294321981, 100.0, -12.961958959330463, -29.76179597731676, 40.0, -4.342704283797366, 40.0, 20.0, 40.0, 60.0, 100.0, 160.0, -6.033567310650366, 40.0, 20.0, 16.539473810005752, 0.0, 100.0, 0.0, 40.0, 0.0, 78.23802863460912, 0.0, -10.718296943218544, 100.0, 47.70221213484323, 60.0, -1.8186988779448376, 22.029872274473448, 40.0, 120.0, -1.431215130514967, 60.0, 60.0, -35.04082548365326, 0.0, 148.86333585567434, -0.23226934149517708, 90.05692227669168, -2.8662827351121285, 16.823046740552215, 99.65990511132858, 0.0, 60.0, 12.855565674677354, 0.0, -0.4761206268274676, 60.0, -14.300346268885699, 19.920123686151456, 100.0, 20.0, 0.0, 38.48259293832664, 40.0, 60.0, 60.0, 0.0, 37.043488759985, -4.2276833167990455, 100.0, 60.0, 100.0, -0.3248784339679134, 80.0, 0.0, 20.0, 80.0, 96.0369068964315, 60.0, -0.3153514718971273, 160.0, 0.0, 60.0, -6.220319335022097, 20.0, 40.0, -8.12429657058861, 40.0, -11.54543768218572, 0.0, 20.0, 0.0, 30.800007761305835, 68.60480964100262, 60.0, 0.0, 120.0, -18.317692220117756, 19.743126048143438, -28.628904139627906, -1.3199287559920136, -28.396369661360467, 39.581544425577285, -21.311415106272364, 140.0, 0.0, 55.967557376289136, 13.921621854113832, 16.43503610439926, -44.52416538056761, 0.0, 0.0, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 80.0, 80.0, 80.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 80.0, 80.0, 80.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 80.0, 80.0, 80.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-50.0, -30.0, 0.0, -37.11507154516608, -10.0, -20.0, -3.4837800828870025, -40.809039325340095, -12.686271896476894, -50.0, -26.534324256710804, -30.427013917161887, -0.634366503326429, -50.0, -12.453866379455423, -30.0, -30.0, -23.952996390542488, -54.48973409304519, 0.0, -10.254009107121592, -20.0, -10.0, -30.0, 0.0, -1.6409623407685914, 0.0, -24.539726425809523, 0.0, -60.0, -34.64174783753424, -21.740771828990205, 0.0, -20.0, -19.647205522302926, -0.9217159595634095, -6.516211601171945, 0.0, -41.341915347438054, -30.0, -15.847386018470052, -10.0, -2.3140839891713156, -20.0, -41.88053456471916, -70.35461165826628, -1.4435808358458058, 0.0, -70.0, -58.354937056780194, -50.0, -12.961958959330463, -29.76179597731676, -20.0, -4.342704283797366, -20.0, -10.0, -20.0, -30.0, -50.0, -80.0, -6.033567310650366, -20.0, -10.0, -13.46052618999425, 0.0, -50.0, 0.0, -20.0, 0.0, -41.76197136539087, 0.0, -10.718296943218544, -50.0, -42.29778786515677, -30.0, -1.8186988779448376, -37.97012772552655, -20.0, -60.0, -1.431215130514967, -30.0, -30.0, -35.04082548365326, 0.0, -91.13666414432566, -0.23226934149517708, -59.94307772330832, -2.8662827351121285, -13.176953259447785, -50.34009488867142, 0.0, -30.0, -47.144434325322635, 0.0, -0.4761206268274676, -30.0, -14.300346268885699, -10.079876313848542, -50.0, -10.0, 0.0, -21.51740706167336, -20.0, -30.0, -30.0, 0.0, -22.956511240015, -4.2276833167990455, -50.0, -30.0, -50.0, -0.3248784339679134, -40.0, 0.0, -10.0, -40.0, -53.9630931035685, -30.0, -0.3153514718971273, -80.0, 0.0, -30.0, -6.220319335022097, -10.0, -20.0, -8.12429657058861, -20.0, -11.54543768218572, 0.0, -10.0, 0.0, -29.199992238694165, -51.395190358997375, -30.0, 0.0, -60.0, -18.317692220117756, -10.25687395185656, -28.628904139627906, -1.3199287559920136, -28.396369661360467, -20.418455574422715, -21.311415106272364, -70.0, 0.0, -34.03244262371087, -16.078378145886173, -13.564963895600739, -44.52416538056761, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6562483370810736, "mean_inference_ms": 1.132193177990669, "mean_action_processing_ms": 0.22627262849738744, "mean_env_wait_ms": 0.4874564711449883, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.008308653737984452, "StateBufferConnector_ms": 0.003411723118202359, "ViewRequirementAgentConnector_ms": 0.09992699217952154}, "num_episodes": 153, "episode_return_max": 160.0, "episode_return_min": -44.52416538056761, "episode_return_mean": 31.90875025821811}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 336000, "num_agent_steps_trained": 336000, "num_env_steps_sampled": 84000, "num_env_steps_trained": 84000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 251.62045415639935, "num_env_steps_trained_throughput_per_sec": 251.62045415639935, "timesteps_total": 84000, "num_env_steps_sampled_lifetime": 84000, "num_agent_steps_sampled_lifetime": 336000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 336000, "timers": {"training_iteration_time_ms": 15537.33, "restore_workers_time_ms": 0.016, "training_step_time_ms": 15537.243, "sample_time_ms": 1231.363, "learn_time_ms": 14287.75, "learn_throughput": 279.96, "synch_weights_time_ms": 16.11}, "counters": {"num_env_steps_sampled": 84000, "num_env_steps_trained": 84000, "num_agent_steps_sampled": 336000, "num_agent_steps_trained": 336000}, "done": false, "training_iteration": 21, "trial_id": "b72b3_00000", "date": "2024-08-08_15-36-18", "timestamp": 1723145778, "time_this_iter_s": 15.91989779472351, "time_total_s": 309.39819836616516, "pid": 98177, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b870dd30>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 309.39819836616516, "iterations_since_restore": 21, "perf": {"cpu_util_percent": 39.93043478260869, "ram_util_percent": 83.36086956521739}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6178464654212197, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.509448713064193, "policy_loss": -0.0171930781386133, "vf_loss": 5.524434244632721, "vf_explained_var": -0.010658033254245917, "kl": 0.011037786739148436, "entropy": 1.340791252007087, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 20640.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7396402817562963, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.060221357125762, "policy_loss": -0.014021512444117866, "vf_loss": 4.072547281380241, "vf_explained_var": 2.4876273270194414e-06, "kl": 0.008477904769494683, "entropy": 1.1073714172586482, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 60630.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 88000, "num_env_steps_trained": 88000, "num_agent_steps_sampled": 352000, "num_agent_steps_trained": 352000}, "env_runners": {"episode_reward_max": 179.07209796980092, "episode_reward_min": -52.60829306225238, "episode_reward_mean": 34.77376809119555, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -90.92790203019908}, "policy_reward_max": {"adversary_policy": 90.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 19.382716049382715, "agent_policy": -23.374380056952607}, "custom_metrics": {}, "hist_stats": {"episode_reward": [60.0, 80.0, 74.49073608266515, -0.03180914627063269, 57.77624677380028, 40.0, -11.973529139151816, -1.8463110792261193, 120.0, 56.36079236576973, 100.0, -5.552531309867564, -20.574272672487453, 118.49723221734023, 0.0, 0.0, 0.0, 22.54570461685966, 40.0, 60.0, 40.0, 53.19199834907292, 20.0, 100.0, 39.467320488849495, -9.685288757379782, 38.333400171596665, -2.2358521205853767, 0.0, 40.0, 60.0, 59.83100834926376, 0.0, 18.00703474276452, -2.348756085400524, -16.7191370030151, 0.0, 80.0, 40.0, 80.0, 79.51639456237635, -5.25573265105517, 40.0, 122.80459789113725, 60.0, 0.0, 80.0, 60.0, -1.830011198736864, 80.0, 120.0, -1.305983103310634, -8.59036034279219, -6.484840388104798, 120.0, 0.0, 60.0, 40.0, 70.90004181638473, 20.0, 28.474113583178706, 60.0, -0.014524332299555853, 60.0, 60.0, 120.0, 0.0, 80.0, 60.0, -6.755207529580002, -19.88293463453481, 40.0, 60.0, 60.0, 0.0, -0.10071013311185206, 80.0, -17.412388974094515, 66.84008201001546, -0.020897893756158803, -0.9398551790056446, 58.913369297862076, 80.0, 100.0, 60.0, 40.0, 20.0, -9.859140790577927, 17.577231916796467, 99.84051798073781, 60.0, 60.0, 20.0, -2.1465256129610712, 76.19824419295452, -4.097255791292213, 100.0, 40.0, 59.88995668559669, 120.0, 76.65889185427166, -29.085060646174426, -18.236719900891345, -27.65194001183304, 20.0, -8.857120543078675, 0.0, 0.0, 0.0, 4.97721109417051, -0.3301837339468139, 17.933142065565917, 100.0, 36.506409305914865, 40.0, 0.0, 20.0, 100.0, 0.0, 20.0, 0.0, 20.0, 40.0, -14.401907426363449, 57.25904674819837, 80.0, 60.0, 80.0, -6.801955839591497, 179.07209796980092, 60.0, -2.9760254784321525, 120.0, 39.58693433101881, 0.0, 0.0, -17.563445314992073, -52.60829306225238, -11.755925388719549, 0.0, 55.38062291524612, 27.018748728538952, -28.252352506923163, 0.0, 58.64570928428533, 60.0, 0.0, 97.6195421224203, 0.0, 20.0, 60.0, 100.0, -17.495691960587745, 0.0, 60.0, -4.053395753007187, 0.0, -0.2735557553244916, 80.0, -0.7565205500606464, 0.0, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 70.0, 70.0, 70.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 60.0, 60.0, 60.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 90.0, 90.0, 90.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-30.0, -40.0, -75.50926391733483, -0.03180914627063269, -32.22375322619973, -20.0, -11.973529139151816, -1.8463110792261193, -60.0, -33.639207634230274, -50.0, -5.552531309867564, -20.574272672487453, -61.502767782659774, 0.0, 0.0, 0.0, -37.45429538314034, -20.0, -30.0, -20.0, -36.80800165092709, -10.0, -50.0, -20.53267951115051, -9.685288757379782, -21.666599828403335, -2.2358521205853767, 0.0, -20.0, -30.0, -30.16899165073624, 0.0, -11.992965257235479, -32.348756085400524, -16.7191370030151, 0.0, -40.0, -20.0, -40.0, -40.483605437623666, -5.25573265105517, -20.0, -87.19540210886275, -30.0, 0.0, -40.0, -30.0, -1.830011198736864, -40.0, -60.0, -1.305983103310634, -8.59036034279219, -6.484840388104798, -60.0, 0.0, -30.0, -20.0, -49.09995818361525, -10.0, -61.525886416821294, -30.0, -0.014524332299555853, -30.0, -30.0, -60.0, 0.0, -40.0, -30.0, -6.755207529580002, -19.88293463453481, -20.0, -30.0, -30.0, 0.0, -0.10071013311185206, -40.0, -17.412388974094515, -53.15991798998458, -0.020897893756158803, -30.939855179005647, -31.086630702137928, -40.0, -50.0, -30.0, -20.0, -10.0, -9.859140790577927, -12.422768083203533, -50.1594820192622, -30.0, -30.0, -10.0, -2.1465256129610712, -43.80175580704549, -34.09725579129221, -50.0, -20.0, -30.110043314403313, -60.0, -43.34110814572834, -29.085060646174426, -18.236719900891345, -27.65194001183304, -10.0, -8.857120543078675, 0.0, 0.0, 0.0, -25.02278890582949, -0.3301837339468139, -12.066857934434084, -50.0, -23.493590694085135, -20.0, 0.0, -10.0, -50.0, 0.0, -10.0, 0.0, -10.0, -20.0, -14.401907426363449, -32.74095325180163, -40.0, -30.0, -40.0, -6.801955839591497, -90.92790203019908, -30.0, -2.9760254784321525, -60.0, -20.413065668981194, 0.0, 0.0, -17.563445314992073, -52.60829306225238, -11.755925388719549, 0.0, -34.61937708475388, -32.98125127146105, -28.252352506923163, 0.0, -31.354290715714665, -30.0, 0.0, -52.38045787757971, 0.0, -10.0, -30.0, -50.0, -17.495691960587745, 0.0, -30.0, -4.053395753007187, 0.0, -0.2735557553244916, -40.0, -0.7565205500606464, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.657627543941472, "mean_inference_ms": 1.1331032427915881, "mean_action_processing_ms": 0.22634413812594997, "mean_env_wait_ms": 0.4877335117388692, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005814322718867549, "StateBufferConnector_ms": 0.003994026301819601, "ViewRequirementAgentConnector_ms": 0.10745127995808919}, "num_episodes": 162, "episode_return_max": 179.07209796980092, "episode_return_min": -52.60829306225238, "episode_return_mean": 34.77376809119555}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 352000, "num_agent_steps_trained": 352000, "num_env_steps_sampled": 88000, "num_env_steps_trained": 88000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 229.7358053082515, "num_env_steps_trained_throughput_per_sec": 229.7358053082515, "timesteps_total": 88000, "num_env_steps_sampled_lifetime": 88000, "num_agent_steps_sampled_lifetime": 352000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 352000, "timers": {"training_iteration_time_ms": 15854.441, "restore_workers_time_ms": 0.016, "training_step_time_ms": 15854.341, "sample_time_ms": 1228.486, "learn_time_ms": 14607.084, "learn_throughput": 273.84, "synch_weights_time_ms": 16.567}, "counters": {"num_env_steps_sampled": 88000, "num_env_steps_trained": 88000, "num_agent_steps_sampled": 352000, "num_agent_steps_trained": 352000}, "done": false, "training_iteration": 22, "trial_id": "b72b3_00000", "date": "2024-08-08_15-36-36", "timestamp": 1723145796, "time_this_iter_s": 17.470895051956177, "time_total_s": 326.86909341812134, "pid": 98177, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3174fd280>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 326.86909341812134, "iterations_since_restore": 22, "perf": {"cpu_util_percent": 43.68, "ram_util_percent": 83.30799999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8092541497200727, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.5325918540358545, "policy_loss": -0.016274757831221603, "vf_loss": 5.546876365939776, "vf_explained_var": 0.01709547278781732, "kl": 0.009951227599525353, "entropy": 1.3057462257643542, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 21600.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7426879253053497, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.037934334903744, "policy_loss": -0.013287705555145385, "vf_loss": 4.049820848136929, "vf_explained_var": 3.069618069533761e-06, "kl": 0.007005962717705846, "entropy": 1.0912032450767273, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 63450.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 92000, "num_env_steps_trained": 92000, "num_agent_steps_sampled": 368000, "num_agent_steps_trained": 368000}, "env_runners": {"episode_reward_max": 200.0, "episode_reward_min": -58.40230122136693, "episode_reward_mean": 29.884810220106985, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -100.0}, "policy_reward_max": {"adversary_policy": 100.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 17.59259259259259, "agent_policy": -22.892967557670794}, "custom_metrics": {}, "hist_stats": {"episode_reward": [41.88271294407758, 60.0, 20.0, -3.0075084030522192, 60.0, 42.667403471757105, 0.0, 10.330846190504218, 74.02176546061754, 7.716335578529026, 13.974640714098577, -1.8105587154075542, 18.32351140722655, -8.92718648449018, 100.0, 40.0, 37.184531558902414, 100.0, 33.04123911017053, 80.0, 20.0, -5.197749028805207, 0.0, -0.7758608419184987, 80.0, 40.0, 0.0, -8.412354570773745, -0.1380439565431879, 120.0, -11.428750643908035, -14.916392907988435, -25.338762312430735, 56.18773008733601, -0.053752634631777374, 13.807409501242539, 40.0, -1.0560121104629094, -3.4847706510087493, 60.0, -58.40230122136693, 0.0, 100.0, 40.0, 60.0, -4.19568363321007, 18.535911214500498, 40.0, -46.05956247569371, 0.0, 0.0, 14.77334735655402, -8.972415483505838, 96.36049225740643, -7.695416446072543, 36.83664679972746, 34.761419888061496, -24.550096119396834, -0.5248476886248432, 20.0, -12.83260956561556, 41.47937921424093, -0.0884906440484301, 39.89623399212773, -10.478950998180643, 200.0, 0.0, 69.09243706630733, 40.0, -15.531168300369671, 40.0, 40.0, 0.0, 0.0, 142.6427758947985, 0.0, -22.47557762584211, 0.0, 20.0, 0.0, 0.0, -7.529933638385978, 50.13191686108407, 93.87272618172135, 60.0, -33.680846281606385, 0.0, -5.284365689907019, 42.913960126047876, 57.01594407918708, 0.0, -38.00918390969494, 80.0, -5.4955694770403625, -32.652098220752755, -17.986549050599866, -15.404475919892134, 99.35893555550528, 60.0, 39.71229843216346, 79.60063594697459, 0.0, 92.13320437710965, 0.0, -5.627629367620797, 120.0, 38.92290415173599, 100.0, 18.733176453130902, 0.0, 60.0, -29.5266500530984, -1.0884134116610056, 20.0, 60.0, -4.192882718798962, 20.0, 160.0, -2.2118190813653857, 0.0, 80.0, 40.0, 37.162804147599026, 120.0, 0.0, 100.0, 140.0, 72.24455955620047, 100.0, 20.0, 59.455907350607035, -0.1538568122452577, -10.015110615477402, 53.67665662558747, 0.0, 28.421806419615066, -0.46729526554110046, 80.0, -1.5589776326057088, 0.0, 0.0, 20.0, 100.0, 20.0, 60.0, 0.0, 40.0, 0.0, 33.890212807663865, 80.0, 100.0, 60.0, 80.0, 40.0, 0.0, 0.0, -5.782100715042489, 55.261365994038435, 0.0, 58.33605220785766, 0.0, 60.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 100.0, 100.0, 100.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 80.0, 80.0, 80.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 80.0, 80.0, 80.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 70.0, 70.0, 70.0, 40.0, 40.0, 40.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0], "policy_agent_policy_reward": [-48.11728705592242, -30.0, -10.0, -3.0075084030522192, -30.0, -47.33259652824291, 0.0, -19.669153809495782, -45.978234539382456, -22.283664421470974, -46.02535928590142, -1.8105587154075542, -41.676488592773445, -8.92718648449018, -50.0, -20.0, -22.815468441097586, -50.0, -26.95876088982947, -40.0, -10.0, -5.197749028805207, 0.0, -0.7758608419184987, -40.0, -20.0, 0.0, -8.412354570773745, -0.1380439565431879, -60.0, -11.428750643908035, -14.916392907988435, -25.338762312430735, -33.812269912664, -0.053752634631777374, -16.19259049875746, -20.0, -1.0560121104629094, -3.4847706510087493, -30.0, -58.40230122136693, 0.0, -50.0, -20.0, -30.0, -4.19568363321007, -11.464088785499502, -20.0, -46.05956247569371, 0.0, 0.0, -15.226652643445979, -8.972415483505838, -53.63950774259357, -7.695416446072543, -23.163353200272535, -55.238580111938504, -24.550096119396834, -0.5248476886248432, -10.0, -12.83260956561556, -48.52062078575907, -0.0884906440484301, -20.103766007872263, -40.47895099818064, -100.0, 0.0, -50.907562933692674, -20.0, -15.531168300369671, -20.0, -20.0, 0.0, 0.0, -97.3572241052015, 0.0, -22.47557762584211, 0.0, -10.0, 0.0, 0.0, -7.529933638385978, -39.86808313891593, -56.12727381827864, -30.0, -33.680846281606385, 0.0, -5.284365689907019, -47.08603987395212, -32.984055920812914, 0.0, -38.00918390969494, -40.0, -5.4955694770403625, -32.652098220752755, -17.986549050599866, -15.404475919892134, -50.64106444449472, -30.0, -20.287701567836542, -40.39936405302541, 0.0, -57.86679562289036, 0.0, -5.627629367620797, -60.0, -21.07709584826401, -50.0, -11.266823546869096, 0.0, -30.0, -29.5266500530984, -1.0884134116610056, -10.0, -30.0, -4.192882718798962, -10.0, -80.0, -2.2118190813653857, 0.0, -40.0, -20.0, -22.837195852400974, -60.0, 0.0, -50.0, -70.0, -47.75544044379952, -50.0, -10.0, -30.544092649392965, -0.1538568122452577, -10.015110615477402, -36.32334337441253, 0.0, -31.578193580384937, -30.4672952655411, -40.0, -1.5589776326057088, 0.0, 0.0, -10.0, -50.0, -10.0, -30.0, 0.0, -20.0, 0.0, -26.109787192336135, -40.0, -50.0, -30.0, -40.0, -20.0, 0.0, 0.0, -5.782100715042489, -34.73863400596157, 0.0, -31.66394779214234, 0.0, -30.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6640730022396809, "mean_inference_ms": 1.1430729571206661, "mean_action_processing_ms": 0.2280166185222017, "mean_env_wait_ms": 0.49187383145432095, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006371221424620829, "StateBufferConnector_ms": 0.00539208635871793, "ViewRequirementAgentConnector_ms": 0.11954601900077161}, "num_episodes": 162, "episode_return_max": 200.0, "episode_return_min": -58.40230122136693, "episode_return_mean": 29.884810220106985}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 368000, "num_agent_steps_trained": 368000, "num_env_steps_sampled": 92000, "num_env_steps_trained": 92000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 231.05567547899676, "num_env_steps_trained_throughput_per_sec": 231.05567547899676, "timesteps_total": 92000, "num_env_steps_sampled_lifetime": 92000, "num_agent_steps_sampled_lifetime": 368000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 368000, "timers": {"training_iteration_time_ms": 16207.815, "restore_workers_time_ms": 0.019, "training_step_time_ms": 16207.711, "sample_time_ms": 1288.316, "learn_time_ms": 14899.835, "learn_throughput": 268.459, "synch_weights_time_ms": 17.017}, "counters": {"num_env_steps_sampled": 92000, "num_env_steps_trained": 92000, "num_agent_steps_sampled": 368000, "num_agent_steps_trained": 368000}, "done": false, "training_iteration": 23, "trial_id": "b72b3_00000", "date": "2024-08-08_15-36-54", "timestamp": 1723145814, "time_this_iter_s": 17.342753887176514, "time_total_s": 344.21184730529785, "pid": 98177, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3174fd670>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 344.21184730529785, "iterations_since_restore": 23, "perf": {"cpu_util_percent": 44.12916666666666, "ram_util_percent": 81.40833333333333}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5925711097195745, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.333480634788672, "policy_loss": -0.018810200612642804, "vf_loss": 5.350134699294965, "vf_explained_var": 0.012636137939989567, "kl": 0.010780704366368592, "entropy": 1.3052687325825294, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 22560.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7349088686683499, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.111517058027552, "policy_loss": -0.012462344489734064, "vf_loss": 4.122571291145704, "vf_explained_var": 3.4667287312500864e-06, "kl": 0.007040532928786973, "entropy": 1.071474171551407, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 66270.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 96000, "num_env_steps_trained": 96000, "num_agent_steps_sampled": 384000, "num_agent_steps_trained": 384000}, "env_runners": {"episode_reward_max": 180.0, "episode_reward_min": -81.11527255028815, "episode_reward_mean": 32.83624774479118, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -90.0}, "policy_reward_max": {"adversary_policy": 90.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 18.703703703703702, "agent_policy": -23.27486336631993}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-17.72101680952438, -81.11527255028815, 100.0, 40.0, 80.0, -1.8776564107979554, 20.0, -27.72029757751988, 20.0, -2.3915628598772942, 0.0, -5.5114974934964405, -59.6964857493652, 60.0, 100.0, 60.0, 80.0, 0.0, 40.0, 60.0, 33.343622572347165, 21.923279104467976, 20.0, 54.1477803727111, 0.0, 0.0, 20.0, 0.0, 56.376418958679935, 20.0, 60.0, 40.0, 60.0, 60.0, -0.24726786477052065, 60.0, 60.0, 20.0, 80.0, 40.0, 80.0, 60.0, 100.0, -0.3233110404950079, 98.76299253423716, 0.0, -0.08728408991103387, 0.0, 20.0, 100.0, 20.0, -0.9529955573107962, 60.0, -5.972046665304106, 40.0, 77.51068045537974, 120.0, 19.05928639232416, 0.0, 33.67940778998644, 120.0, 48.73982240624751, 60.0, 79.01688284565158, 60.0, 80.0, 180.0, 40.0, 0.0, 80.0, 40.0, 120.0, -20.338810090194144, 0.0, 0.0, 56.060473831404536, 0.0, 40.0, 0.0, 0.0, 0.0, 58.51898717542899, 0.0, -22.68831384929054, 20.0, 19.333714912939552, -14.057709153818253, 36.2615280510835, 22.840276680300434, 60.0, 58.86356889193669, 40.0, -6.731741005116702, 0.0, 60.0, 0.0, -28.273841319628982, 0.0, 20.0, 76.45863954371865, 60.0, 60.0, -19.079305291567664, 20.0, 0.0, -51.81709615240625, -26.01462920731885, 0.0, 18.756803093527637, -8.525810110264128, 0.0, 45.036443518089506, 0.0, 60.0, 60.0, 120.0, 44.1631909936887, 100.0, -23.358075035851147, 60.0, 0.0, 0.0, 59.38124133197363, -40.759198624159794, 0.0, -7.414735313073354, 120.0, 40.0, 80.0, 0.0, 0.0, 60.0, 0.0, 0.0, 58.29765517125986, 97.19355373954902, -6.442282617126455, 60.0, 0.0, -29.097042134434375, 56.43923549619808, 98.16479167463656, 40.0, 0.0, 0.0, 0.0, 50.50244862912194, 59.875232147931825, 40.0, 40.0, 79.83092896100374, 79.74295776244986, -2.509400348975996, 0.0, 60.0, 60.0, 0.0, 34.747643692315194, -12.110469255849434, 29.277800103317155, 80.0, 140.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 60.0, 60.0, 60.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 60.0, 60.0, 60.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 90.0, 90.0, 90.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 60.0, 60.0, 60.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 70.0, 70.0, 70.0], "policy_agent_policy_reward": [-17.72101680952438, -81.11527255028815, -50.0, -20.0, -40.0, -1.8776564107979554, -10.0, -27.72029757751988, -10.0, -2.3915628598772942, 0.0, -5.5114974934964405, -59.6964857493652, -30.0, -50.0, -30.0, -40.0, 0.0, -20.0, -30.0, -56.656377427652835, -38.07672089553203, -10.0, -35.8522196272889, 0.0, 0.0, -10.0, 0.0, -33.623581041320065, -10.0, -30.0, -20.0, -30.0, -30.0, -0.24726786477052065, -30.0, -30.0, -10.0, -40.0, -20.0, -40.0, -30.0, -50.0, -0.3233110404950079, -51.23700746576285, 0.0, -0.08728408991103387, 0.0, -10.0, -50.0, -10.0, -0.9529955573107962, -30.0, -5.972046665304106, -20.0, -42.48931954462025, -60.0, -10.940713607675841, 0.0, -26.32059221001356, -60.0, -41.26017759375249, -30.0, -40.98311715434842, -30.0, -40.0, -90.0, -20.0, 0.0, -40.0, -20.0, -60.0, -20.338810090194144, 0.0, 0.0, -33.939526168595464, 0.0, -20.0, 0.0, 0.0, 0.0, -31.481012824571017, 0.0, -22.68831384929054, -10.0, -10.666285087060448, -14.057709153818253, -23.738471948916494, -37.159723319699566, -30.0, -31.136431108063313, -20.0, -6.731741005116702, 0.0, -30.0, 0.0, -28.273841319628982, 0.0, -10.0, -73.54136045628137, -30.0, -30.0, -49.079305291567664, -10.0, 0.0, -51.81709615240625, -26.01462920731885, 0.0, -11.243196906472367, -8.525810110264128, 0.0, -44.96355648191049, 0.0, -30.0, -30.0, -60.0, -45.8368090063113, -50.0, -23.358075035851147, -30.0, 0.0, 0.0, -30.61875866802638, -40.759198624159794, 0.0, -7.414735313073354, -60.0, -20.0, -40.0, 0.0, 0.0, -30.0, 0.0, 0.0, -31.702344828740138, -52.80644626045098, -6.442282617126455, -30.0, 0.0, -29.097042134434375, -33.56076450380193, -51.83520832536344, -20.0, 0.0, 0.0, 0.0, -39.49755137087806, -30.12476785206818, -20.0, -20.0, -40.169071038996265, -40.25704223755014, -2.509400348975996, 0.0, -30.0, -30.0, 0.0, -25.252356307684806, -12.110469255849434, -30.722199896682845, -40.0, -70.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6664999406813162, "mean_inference_ms": 1.145724627716221, "mean_action_processing_ms": 0.22833785327324888, "mean_env_wait_ms": 0.4932993330210998, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005739780119907709, "StateBufferConnector_ms": 0.0038176407048731674, "ViewRequirementAgentConnector_ms": 0.10028805261776771}, "num_episodes": 162, "episode_return_max": 180.0, "episode_return_min": -81.11527255028815, "episode_return_mean": 32.83624774479118}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 384000, "num_agent_steps_trained": 384000, "num_env_steps_sampled": 96000, "num_env_steps_trained": 96000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 256.4017740995423, "num_env_steps_trained_throughput_per_sec": 256.4017740995423, "timesteps_total": 96000, "num_env_steps_sampled_lifetime": 96000, "num_agent_steps_sampled_lifetime": 384000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 384000, "timers": {"training_iteration_time_ms": 16331.27, "restore_workers_time_ms": 0.018, "training_step_time_ms": 16331.166, "sample_time_ms": 1314.088, "learn_time_ms": 14997.314, "learn_throughput": 266.714, "synch_weights_time_ms": 17.276}, "counters": {"num_env_steps_sampled": 96000, "num_env_steps_trained": 96000, "num_agent_steps_sampled": 384000, "num_agent_steps_trained": 384000}, "done": false, "training_iteration": 24, "trial_id": "b72b3_00000", "date": "2024-08-08_15-37-09", "timestamp": 1723145829, "time_this_iter_s": 15.650718927383423, "time_total_s": 359.8625662326813, "pid": 98177, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3174fd8b0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 359.8625662326813, "iterations_since_restore": 24, "perf": {"cpu_util_percent": 37.14545454545455, "ram_util_percent": 81.45}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5755249174311756, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.959757512807846, "policy_loss": -0.02062370523926802, "vf_loss": 5.978214820722739, "vf_explained_var": -0.004184459025661151, "kl": 0.010831845638103093, "entropy": 1.2899738885462284, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 23520.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7466487661109749, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.591061382513519, "policy_loss": -0.01534451057074314, "vf_loss": 4.604905437324064, "vf_explained_var": 3.6005855452084374e-07, "kl": 0.007502222579742152, "entropy": 1.0459633170290197, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 69090.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 100000, "num_env_steps_trained": 100000, "num_agent_steps_sampled": 400000, "num_agent_steps_trained": 400000}, "env_runners": {"episode_reward_max": 240.0, "episode_reward_min": -37.188231372761344, "episode_reward_mean": 35.408082814379476, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -120.0}, "policy_reward_max": {"adversary_policy": 120.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 19.814814814814813, "agent_policy": -24.036361630064967}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.0, -7.482122279728588, 8.719973277436878, -0.5977968099468711, 120.0, 0.0, -0.6700953297861567, 0.0, 80.0, 156.6581576496754, 100.0, 40.0, 54.27101130380231, -19.1098737154016, 0.0, -2.7956142810326696, 39.4060254958229, 80.0, 0.0, -34.41752812792634, 20.0, 66.88048759619745, 0.0, 119.2309802133623, 0.0, 0.0, 80.0, 24.56817071276753, 40.0, 80.0, -16.1365986873185, 40.0, 60.0, 0.0, 40.0, -2.3573886534427193, -21.52139535035415, 60.0, 20.0, 35.42289354969885, 0.0, 0.0, 100.0, 40.0, 40.0, 100.0, 40.0, 80.0, 80.0, 0.0, 0.0, 100.0, 0.0, 60.0, -6.064689278343813, 79.77786396416235, 40.0, 40.0, -26.293466404719254, 60.0, -14.871790579173046, 0.0, 69.86343658565659, 195.29063053233935, 240.0, 0.0, -1.2690103661614016, 37.16128587930644, 100.0, -25.206859297219996, 100.0, 59.29839307166489, 51.6625284522309, 60.0, 120.0, 40.0, 0.0, -18.075390486892108, -0.21190597432356295, 80.0, 29.448910989530457, 0.0, 16.98070589649724, -0.006964134597498006, -7.3639945216415015, 100.0, 100.0, 140.0, 40.0, 0.0, 20.0, 0.0, 40.0, 120.0, -12.86122762368823, -5.1987942688878235, 0.0, 20.0, 60.0, -14.52557989030313, -2.310191702571456, -10.0199436986078, 77.98759260618924, 119.02746590501593, 51.497332989868994, -5.335522931505931, 11.86667703039981, 0.0, 40.0, 0.0, -10.49589588726925, 100.0, 20.0, 100.0, 0.0, -6.479028499728463, 0.0, 45.65944857504521, 60.0, 32.54593422621327, 51.912698455064664, 80.0, 120.0, -21.816581645233374, 80.0, 100.0, 0.0, 60.0, 3.9911260541087623, 60.0, 20.0, -8.91603419238733, -6.876212715732984, 60.0, -6.3573175626119065, 40.0, -28.011016613171, 40.0, 60.0, -3.715701950338058, 60.0, -12.080232035184077, 19.875000372101425, 60.0, 0.0, 0.0, 0.0, -37.188231372761344, 20.0, 0.0, 60.0, 69.71126391245832, 58.297931554472086, -14.846299466278625, -3.093776231409583, 40.0, 80.0, 20.0, 60.0, 60.0, -4.460395235962237, 8.135956880028207], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 80.0, 80.0, 80.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 100.0, 100.0, 100.0, 120.0, 120.0, 120.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 70.0, 70.0, 70.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 60.0, 60.0, 60.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0], "policy_agent_policy_reward": [-20.0, -7.482122279728588, -21.28002672256312, -0.5977968099468711, -60.0, 0.0, -0.6700953297861567, 0.0, -40.0, -83.34184235032461, -50.0, -20.0, -35.72898869619769, -19.1098737154016, 0.0, -2.7956142810326696, -20.593974504177098, -40.0, 0.0, -34.41752812792634, -10.0, -53.11951240380254, 0.0, -60.769019786637685, 0.0, 0.0, -40.0, -35.43182928723247, -20.0, -40.0, -16.1365986873185, -20.0, -30.0, 0.0, -20.0, -2.3573886534427193, -21.52139535035415, -30.0, -10.0, -24.577106450301155, 0.0, 0.0, -50.0, -20.0, -20.0, -50.0, -20.0, -40.0, -40.0, 0.0, 0.0, -50.0, 0.0, -30.0, -6.064689278343813, -40.22213603583764, -20.0, -20.0, -26.293466404719254, -30.0, -14.871790579173046, 0.0, -50.136563414343414, -104.70936946766066, -120.0, 0.0, -1.2690103661614016, -22.83871412069356, -50.0, -25.206859297219996, -50.0, -30.701606928335103, -38.3374715477691, -30.0, -60.0, -20.0, 0.0, -18.075390486892108, -0.21190597432356295, -40.0, -60.55108901046954, 0.0, -13.019294103502759, -0.006964134597498006, -7.3639945216415015, -50.0, -50.0, -70.0, -20.0, 0.0, -10.0, 0.0, -20.0, -60.0, -12.86122762368823, -5.1987942688878235, 0.0, -10.0, -30.0, -14.52557989030313, -2.310191702571456, -10.0199436986078, -72.01240739381075, -60.97253409498406, -38.502667010131006, -5.335522931505931, -18.13332296960019, 0.0, -20.0, 0.0, -10.49589588726925, -50.0, -10.0, -50.0, 0.0, -6.479028499728463, 0.0, -44.34055142495479, -30.0, -27.45406577378673, -38.087301544935336, -40.0, -60.0, -81.81658164523337, -40.0, -50.0, 0.0, -30.0, -26.008873945891242, -30.0, -10.0, -8.91603419238733, -6.876212715732984, -30.0, -6.3573175626119065, -20.0, -28.011016613171, -20.0, -30.0, -3.715701950338058, -30.0, -12.080232035184077, -10.124999627898575, -30.0, 0.0, 0.0, 0.0, -37.188231372761344, -10.0, 0.0, -30.0, -50.28873608754167, -31.702068445527914, -14.846299466278625, -3.093776231409583, -20.0, -40.0, -10.0, -30.0, -30.0, -4.460395235962237, -21.864043119971793]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6661366419372363, "mean_inference_ms": 1.1467778526408787, "mean_action_processing_ms": 0.22829168640767802, "mean_env_wait_ms": 0.4931378363274836, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004673887182165075, "StateBufferConnector_ms": 0.003346248909279152, "ViewRequirementAgentConnector_ms": 0.0924475399064429}, "num_episodes": 162, "episode_return_max": 240.0, "episode_return_min": -37.188231372761344, "episode_return_mean": 35.408082814379476}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 400000, "num_agent_steps_trained": 400000, "num_env_steps_sampled": 100000, "num_env_steps_trained": 100000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 269.5389094818156, "num_env_steps_trained_throughput_per_sec": 269.5389094818156, "timesteps_total": 100000, "num_env_steps_sampled_lifetime": 100000, "num_agent_steps_sampled_lifetime": 400000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 400000, "timers": {"training_iteration_time_ms": 16343.78, "restore_workers_time_ms": 0.019, "training_step_time_ms": 16343.701, "sample_time_ms": 1326.766, "learn_time_ms": 14997.374, "learn_throughput": 266.713, "synch_weights_time_ms": 17.277}, "counters": {"num_env_steps_sampled": 100000, "num_env_steps_trained": 100000, "num_agent_steps_sampled": 400000, "num_agent_steps_trained": 400000}, "done": false, "training_iteration": 25, "trial_id": "b72b3_00000", "date": "2024-08-08_15-37-24", "timestamp": 1723145844, "time_this_iter_s": 14.846998929977417, "time_total_s": 374.7095651626587, "pid": 98177, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3174fde50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 374.7095651626587, "iterations_since_restore": 25, "perf": {"cpu_util_percent": 34.1047619047619, "ram_util_percent": 81.6904761904762}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6169367497165998, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.832305148243904, "policy_loss": -0.01910444320261983, "vf_loss": 5.849155852198601, "vf_explained_var": 0.0052850980311632155, "kl": 0.011268697449680355, "entropy": 1.2606500256806612, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 24480.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7575100786297034, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.3544895970229565, "policy_loss": -0.0138446205422771, "vf_loss": 4.366947399555369, "vf_explained_var": 5.196066612892962e-06, "kl": 0.006934035890491285, "entropy": 1.0587567959271424, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 71910.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 104000, "num_env_steps_trained": 104000, "num_agent_steps_sampled": 416000, "num_agent_steps_trained": 416000}, "env_runners": {"episode_reward_max": 200.0, "episode_reward_min": -72.5454253207199, "episode_reward_mean": 36.522308131106364, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 153, "episodes_timesteps_total": 3825, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -100.0}, "policy_reward_max": {"adversary_policy": 100.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 20.84967320261438, "agent_policy": -26.02671147673677}, "custom_metrics": {}, "hist_stats": {"episode_reward": [60.0, -1.3771192591426007, -1.537514662757542, 20.0, -64.4518162842847, 7.344050154931939, 0.0, -34.983923866556715, -22.682545174433297, -26.765206389042497, 0.0, -11.41088523846348, 98.61455964132712, 100.0, 0.0, 60.0, -42.05313112466648, 40.0, 80.0, -10.654869051631533, 60.0, 0.0, 36.97576681974979, 60.0, 75.97789507497083, 0.0, 40.0, 100.0, 120.0, 22.72557992044309, 20.0, -11.813620554475804, -0.2467427511951641, 40.0, 100.0, 0.0, 99.07885092044441, 19.3155979910391, 40.0, -8.587099994751641, 80.0, 120.0, 0.0, 0.0, -6.34971133838344, 80.0, 59.05129585168001, 0.0, 60.0, 0.0, 60.0, -10.322409557387578, 60.0, 40.0, 60.0, 20.0, 51.59148949430443, 60.0, 15.386926357257988, -1.1245925772956766, 40.0, -10.096191970982574, 80.0, 0.0, 60.0, 58.007448590738626, 40.0, 100.0, 0.0, -15.357092492627924, -13.059947943848902, 0.0, 59.1957455228173, 99.17920009428158, 20.0, 30.410435798822235, 120.0, 40.0, 60.0, -72.5454253207199, 32.90071806473713, -17.219238501314184, 40.0, 20.0, -2.4284613422593826, 0.0, 100.0, 120.0, 40.0, 0.0, 40.0, 40.0, -5.393047159555518, 60.0, 30.4268455260067, 20.0, 120.0, 60.0, -35.43203042185166, -11.448711189798441, 0.0, 139.55494113632122, 80.0, 0.0, 100.0, 40.0, 113.94863527581464, 0.0, 100.0, 0.0, 0.0, -25.50219094032509, -0.961710222168416, 40.0, 120.0, 120.0, 40.0, 14.900748435931039, 200.0, 60.0, 109.91265226859839, 100.0, 20.0, 0.0, 60.0, 60.0, 0.0, 60.0, 97.52738597847961, -13.839819019294866, 0.0, 0.0, 40.0, 40.0, 58.712943717322716, 138.53781195629787, 0.0, 160.0, 59.94099270792546, 0.0, 60.0, 57.730674796384235, 40.0, 95.66786031312613, 32.310986804685484, -6.6066379525553, -32.292497041150135, 0.0, 20.0, -30.470705812244866, 40.0, 0.0, 20.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 60.0, 60.0, 60.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 60.0, 60.0, 60.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 100.0, 100.0, 100.0, 30.0, 30.0, 30.0, 60.0, 60.0, 60.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 80.0, 80.0, 80.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0], "policy_agent_policy_reward": [-30.0, -1.3771192591426007, -1.537514662757542, -10.0, -64.4518162842847, -22.65594984506806, 0.0, -34.983923866556715, -22.682545174433297, -26.765206389042497, 0.0, -11.41088523846348, -51.38544035867288, -50.0, 0.0, -30.0, -42.05313112466648, -20.0, -40.0, -10.654869051631533, -30.0, 0.0, -23.02423318025021, -30.0, -44.02210492502917, 0.0, -20.0, -50.0, -60.0, -37.2744200795569, -10.0, -11.813620554475804, -30.246742751195164, -20.0, -50.0, 0.0, -80.92114907955559, -40.6844020089609, -20.0, -8.587099994751641, -40.0, -60.0, 0.0, 0.0, -6.34971133838344, -40.0, -30.948704148319983, 0.0, -30.0, 0.0, -30.0, -10.322409557387578, -30.0, -20.0, -30.0, -10.0, -38.40851050569557, -30.0, -44.61307364274202, -1.1245925772956766, -20.0, -40.09619197098258, -40.0, 0.0, -30.0, -31.992551409261377, -20.0, -50.0, 0.0, -15.357092492627924, -13.059947943848902, 0.0, -30.804254477182706, -50.82079990571842, -10.0, -29.589564201177765, -60.0, -20.0, -30.0, -72.5454253207199, -57.09928193526287, -17.219238501314184, -20.0, -10.0, -2.4284613422593826, 0.0, -50.0, -60.0, -20.0, 0.0, -20.0, -20.0, -5.393047159555518, -30.0, -29.573154473993295, -10.0, -60.0, -30.0, -35.43203042185166, -11.448711189798441, 0.0, -70.44505886367878, -40.0, 0.0, -50.0, -20.0, -66.05136472418536, 0.0, -50.0, 0.0, 0.0, -25.50219094032509, -0.961710222168416, -20.0, -60.0, -60.0, -20.0, -15.099251564068965, -100.0, -30.0, -70.08734773140162, -50.0, -10.0, 0.0, -30.0, -30.0, 0.0, -30.0, -52.472614021520386, -13.839819019294866, 0.0, 0.0, -20.0, -20.0, -31.287056282677288, -71.46218804370216, 0.0, -80.0, -30.05900729207454, 0.0, -30.0, -32.26932520361576, -20.0, -54.33213968687387, -27.689013195314516, -6.6066379525553, -32.292497041150135, 0.0, -10.0, -30.470705812244866, -20.0, 0.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6658315107352989, "mean_inference_ms": 1.1464875356188229, "mean_action_processing_ms": 0.2283269483387507, "mean_env_wait_ms": 0.4931378569077778, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0045409389570647595, "StateBufferConnector_ms": 0.004362047108170254, "ViewRequirementAgentConnector_ms": 0.09834953382903454}, "num_episodes": 153, "episode_return_max": 200.0, "episode_return_min": -72.5454253207199, "episode_return_mean": 36.522308131106364}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 416000, "num_agent_steps_trained": 416000, "num_env_steps_sampled": 104000, "num_env_steps_trained": 104000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 212.7269644306253, "num_env_steps_trained_throughput_per_sec": 212.7269644306253, "timesteps_total": 104000, "num_env_steps_sampled_lifetime": 104000, "num_agent_steps_sampled_lifetime": 416000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 416000, "timers": {"training_iteration_time_ms": 16725.162, "restore_workers_time_ms": 0.019, "training_step_time_ms": 16725.081, "sample_time_ms": 1323.702, "learn_time_ms": 15376.332, "learn_throughput": 260.14, "synch_weights_time_ms": 22.353}, "counters": {"num_env_steps_sampled": 104000, "num_env_steps_trained": 104000, "num_agent_steps_sampled": 416000, "num_agent_steps_trained": 416000}, "done": false, "training_iteration": 26, "trial_id": "b72b3_00000", "date": "2024-08-08_15-37-43", "timestamp": 1723145863, "time_this_iter_s": 18.859495878219604, "time_total_s": 393.5690610408783, "pid": 98177, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3174ea280>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 393.5690610408783, "iterations_since_restore": 26, "perf": {"cpu_util_percent": 52.18518518518519, "ram_util_percent": 82.05555555555556}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3942730743438005, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.000076676905155, "policy_loss": -0.019247309603573133, "vf_loss": 6.01725493222475, "vf_explained_var": 0.00047635814795891446, "kl": 0.010345227524273224, "entropy": 1.2480852422614892, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 25440.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7270039320943203, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.793450347159771, "policy_loss": -0.015436846676162042, "vf_loss": 4.807199320387333, "vf_explained_var": -2.212220049918966e-06, "kl": 0.008439302589683489, "entropy": 1.0207134974129657, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 74730.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 108000, "num_env_steps_trained": 108000, "num_agent_steps_sampled": 432000, "num_agent_steps_trained": 432000}, "env_runners": {"episode_reward_max": 220.0, "episode_reward_min": -41.29696109088003, "episode_reward_mean": 42.854464902360164, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -110.0}, "policy_reward_max": {"adversary_policy": 110.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 23.271604938271604, "agent_policy": -26.960349912454653}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, -19.119713059984335, 46.7920202917659, -1.7722534261725098, 80.0, -13.092269357565568, 0.0, -19.612627753682823, 60.0, 40.0, 13.179986446149044, 0.0, 0.0, 60.0, -24.548104481270336, 20.0, 20.0, 60.0, -41.29696109088003, 80.0, 80.0, 19.867631065110693, 100.0, 80.0, -0.8207364278740548, -10.149572995459032, 0.0, -22.8779151706797, 0.0, 60.0, 0.0, 80.0, 59.94036747310142, 0.0, 139.71604912229907, 140.0, 100.0, 160.0, 40.0, 120.0, 20.0, 40.0, 0.0, -5.580802727354876, 100.0, 50.101192545573085, 0.0, -41.08297567884136, 26.58109212922434, 98.19426283129243, 120.0, 60.0, 0.0, 0.0, 19.37247129525854, 0.0, 31.65319933384225, 80.0, 98.45756768302705, 60.0, 120.0, 80.0, 80.0, 0.0, -0.7196883404681587, 220.0, 60.0, 0.0, 100.0, 100.0, 80.0, 80.0, 60.0, -0.8005180174887752, 17.528467569238874, 17.682238955253474, 60.0, 60.0, -7.939341913948744, 120.0, -0.24924392095195036, 52.07309162726369, 40.0, 120.0, 100.0, 32.92731674700666, 60.0, 37.64470427122674, 100.0, -7.4632039920875, 0.0, 19.10159921991889, 94.06852507928562, 0.0, 39.839619861220974, 0.0, 40.0, 0.0, 40.0, 17.92751244679052, 80.0, 0.0, 60.0, 120.0, 40.0, 20.0, -7.209049373387774, 33.04176747342443, 9.109993351596724, 160.0, 0.0, 0.0, -0.9064497772336133, 80.0, 0.0, -5.8874773414581725, 42.96541542014169, 19.83382403417017, 20.0, 40.0, 0.0, 0.0, 100.0, -29.33761992279656, 0.0, 58.059309471807396, 77.89128605869215, 160.0, 0.0, 0.0, 55.72404673824887, 137.03589580675435, 160.0, 0.0, -25.578502085435264, 160.0, 38.93517172802419, 200.0, 80.0, 60.0, 60.0, 100.0, 40.0, 37.60441274400875, 55.22839545313166, 54.75153725984623, -17.23690404643666, -24.62788658018494, 80.0, -19.30158251435993, -4.167083699014006, 58.5836336542973, -22.551517727900457, 0.0, 40.0, 53.22284460813546, 60.0, 80.0, 39.62906750476208, 19.232650617471144, -7.14485231309887, 20.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 70.0, 70.0, 70.0, 50.0, 50.0, 50.0, 80.0, 80.0, 80.0, 20.0, 20.0, 20.0, 60.0, 60.0, 60.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 60.0, 60.0, 60.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 60.0, 60.0, 60.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 110.0, 110.0, 110.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 60.0, 60.0, 60.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 80.0, 80.0, 80.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 80.0, 80.0, 80.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 70.0, 70.0, 70.0, 80.0, 80.0, 80.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 80.0, 80.0, 80.0, 20.0, 20.0, 20.0, 100.0, 100.0, 100.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0], "policy_agent_policy_reward": [0.0, -19.119713059984335, -43.20797970823409, -1.7722534261725098, -40.0, -13.092269357565568, 0.0, -19.612627753682823, -30.0, -20.0, -16.820013553850956, 0.0, 0.0, -30.0, -24.548104481270336, -10.0, -10.0, -30.0, -41.29696109088003, -40.0, -40.0, -10.132368934889307, -50.0, -40.0, -0.8207364278740548, -10.149572995459032, 0.0, -22.8779151706797, 0.0, -30.0, 0.0, -40.0, -30.059632526898582, 0.0, -70.28395087770093, -70.0, -50.0, -80.0, -20.0, -60.0, -10.0, -20.0, 0.0, -5.580802727354876, -50.0, -39.898807454426915, 0.0, -41.08297567884136, -33.41890787077567, -51.80573716870755, -60.0, -30.0, 0.0, 0.0, -10.627528704741461, 0.0, -58.34680066615775, -40.0, -51.542432316972935, -30.0, -60.0, -40.0, -40.0, 0.0, -0.7196883404681587, -110.0, -30.0, 0.0, -50.0, -50.0, -40.0, -40.0, -30.0, -30.800518017488777, -42.47153243076113, -12.317761044746526, -30.0, -30.0, -7.939341913948744, -60.0, -0.24924392095195036, -37.92690837273631, -20.0, -60.0, -50.0, -27.07268325299334, -30.0, -22.355295728773253, -50.0, -7.4632039920875, 0.0, -10.898400780081113, -55.93147492071438, 0.0, -20.160380138779026, 0.0, -20.0, 0.0, -20.0, -12.072487553209482, -40.0, 0.0, -30.0, -60.0, -20.0, -10.0, -7.209049373387774, -26.95823252657557, -20.890006648403276, -80.0, 0.0, 0.0, -0.9064497772336133, -40.0, 0.0, -5.8874773414581725, -47.03458457985831, -10.166175965829828, -10.0, -20.0, 0.0, 0.0, -50.0, -29.33761992279656, 0.0, -31.940690528192604, -42.10871394130785, -80.0, 0.0, 0.0, -34.27595326175113, -72.96410419324563, -80.0, 0.0, -25.578502085435264, -80.0, -21.064828271975813, -100.0, -40.0, -30.0, -30.0, -50.0, -20.0, -22.395587255991245, -34.77160454686834, -35.24846274015376, -17.23690404643666, -24.62788658018494, -40.0, -19.30158251435993, -4.167083699014006, -31.416366345702702, -22.551517727900457, 0.0, -20.0, -36.77715539186454, -30.0, -40.0, -20.37093249523792, -10.767349382528854, -7.14485231309887, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6709740873997011, "mean_inference_ms": 1.153850991704241, "mean_action_processing_ms": 0.2296317436605141, "mean_env_wait_ms": 0.49601048227838784, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.010369000611481842, "StateBufferConnector_ms": 0.003453537269874855, "ViewRequirementAgentConnector_ms": 0.11266646561799226}, "num_episodes": 162, "episode_return_max": 220.0, "episode_return_min": -41.29696109088003, "episode_return_mean": 42.854464902360164}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 432000, "num_agent_steps_trained": 432000, "num_env_steps_sampled": 108000, "num_env_steps_trained": 108000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 172.90762184236763, "num_env_steps_trained_throughput_per_sec": 172.90762184236763, "timesteps_total": 108000, "num_env_steps_sampled_lifetime": 108000, "num_agent_steps_sampled_lifetime": 432000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 432000, "timers": {"training_iteration_time_ms": 16938.673, "restore_workers_time_ms": 0.019, "training_step_time_ms": 16938.592, "sample_time_ms": 1368.578, "learn_time_ms": 15539.723, "learn_throughput": 257.405, "synch_weights_time_ms": 26.361}, "counters": {"num_env_steps_sampled": 108000, "num_env_steps_trained": 108000, "num_agent_steps_sampled": 432000, "num_agent_steps_trained": 432000}, "done": false, "training_iteration": 27, "trial_id": "b72b3_00000", "date": "2024-08-08_15-38-07", "timestamp": 1723145887, "time_this_iter_s": 23.158097743988037, "time_total_s": 416.72715878486633, "pid": 98177, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3174ea700>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 416.72715878486633, "iterations_since_restore": 27, "perf": {"cpu_util_percent": 63.881818181818176, "ram_util_percent": 82.13030303030304}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5723331287503242, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.0288394026458265, "policy_loss": -0.017088498317995495, "vf_loss": 6.043498428165913, "vf_explained_var": 0.0014435764402151107, "kl": 0.012147412019908528, "entropy": 1.215406296029687, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 26400.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.742918044455508, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.77997126976649, "policy_loss": -0.016678279302141163, "vf_loss": 4.7949080229650995, "vf_explained_var": -8.012174714541604e-07, "kl": 0.008707594637914743, "entropy": 0.9813034734193314, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 77550.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 112000, "num_env_steps_trained": 112000, "num_agent_steps_sampled": 448000, "num_agent_steps_trained": 448000}, "env_runners": {"episode_reward_max": 200.0, "episode_reward_min": -40.71881979334435, "episode_reward_mean": 37.30141486653647, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -106.05798942671684}, "policy_reward_max": {"adversary_policy": 100.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 21.17283950617284, "agent_policy": -26.217103651982054}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.5625768118131225, 19.85857935414341, 60.0, 60.0, 72.37295805178229, 0.0, 35.06439472361012, 140.0, 0.0, 0.0, 40.0, 0.0, -8.928559690003384, 100.0, 0.0, 39.06675131643082, 0.0, 40.0, 56.45723551698575, 31.507669067219386, 0.0, 0.0, 60.0, 60.0, 80.0, -0.5956234243243697, 160.0, 20.0, 120.0, -6.398701493995642, 193.94201057328317, -34.20345359106685, 100.0, 18.493328048284074, -6.815203801604014, 55.606437919898696, 20.0, 0.0, 4.759617240096242, 0.0, 60.0, 60.0, 100.0, 5.570332165403526, 100.19674530101088, 40.0, 80.0, 0.0, 40.0, 0.0, 60.0, 80.0, -33.680690310157686, 38.95525522195409, 20.0, 20.0, 120.0, 100.0, 79.64180492319008, 136.2683468727594, 57.58208998574948, 200.0, 40.0, -0.215063451655777, 120.0, 160.0, 120.0, 60.0, 80.0, 28.62770739874239, 0.0, -1.5529943806877444, 0.0, 40.0, -5.949064127117437, 35.00349587540707, -22.094084774545095, 180.0, 0.0, 0.0, 60.0, 60.0, 40.0, 35.19212845672587, -15.255550452601437, 40.0, 0.0, 59.732644850792695, 60.0, -14.665183369363076, 0.0, 74.38059954441724, 70.00170300009088, 0.0, -40.71881979334435, -34.170086583203236, 0.0, 0.0, -0.8422121258611992, 80.0, 40.0, 0.0, 60.0, 0.0, 77.55612436551269, -1.0812768013137275, 44.93021388730928, 37.10518134680237, -18.678586050859508, -2.217749917098105, 100.0, -20.96686262302261, 20.0, 40.0, -4.127873446832692, 40.0, -0.0493559259710008, 78.63413644873752, 40.0, 60.0, 60.0, -0.5909743779108156, -23.47148812499015, 20.0, 0.0, -2.7122399209291546, 80.0, 0.0, 79.44370154053841, -4.057537648014719, 0.0, -4.595254860126258, -11.183461965027725, 0.0, 23.430872625819372, 40.0, 32.32887460452326, 39.62811593447944, -28.373822282519228, -17.308394807211315, 60.0, 20.0, 140.0, 20.0, 53.70684096779585, 60.0, 77.57437954747044, 16.622805779568665, 60.0, 36.5369136504207, -5.300541727375264, 36.499641410607694, 0.0, 39.67925032108023, 0.0, 135.25191734808962, 40.0, -14.582973175783419, -22.211670331797375, 59.974785546178595, 60.0, 93.80154981412377], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 80.0, 80.0, 80.0, 10.0, 10.0, 10.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 100.0, 100.0, 100.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 60.0, 60.0, 60.0, 50.0, 50.0, 50.0, 40.0, 40.0, 40.0, 70.0, 70.0, 70.0, 30.0, 30.0, 30.0, 100.0, 100.0, 100.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 80.0, 80.0, 80.0, 60.0, 60.0, 60.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 90.0, 90.0, 90.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 70.0, 70.0, 70.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 60.0, 60.0, 60.0], "policy_agent_policy_reward": [-0.5625768118131225, -10.141420645856593, -30.0, -30.0, -47.627041948217695, 0.0, -24.93560527638988, -70.0, 0.0, 0.0, -20.0, 0.0, -8.928559690003384, -50.0, 0.0, -20.933248683569182, 0.0, -20.0, -33.54276448301425, -58.49233093278062, 0.0, 0.0, -30.0, -30.0, -40.0, -0.5956234243243697, -80.0, -10.0, -60.0, -6.398701493995642, -106.05798942671684, -34.20345359106685, -50.0, -41.50667195171592, -6.815203801604014, -34.393562080101304, -10.0, 0.0, -25.24038275990376, 0.0, -30.0, -30.0, -50.0, -24.429667834596472, -79.80325469898912, -20.0, -40.0, 0.0, -20.0, 0.0, -30.0, -40.0, -33.680690310157686, -21.04474477804591, -10.0, -10.0, -60.0, -50.0, -40.35819507680993, -73.7316531272406, -32.41791001425052, -100.0, -20.0, -0.215063451655777, -60.0, -80.0, -60.0, -30.0, -40.0, -61.37229260125761, 0.0, -1.5529943806877444, 0.0, -20.0, -5.949064127117437, -24.996504124592935, -22.094084774545095, -90.0, 0.0, 0.0, -30.0, -30.0, -20.0, -24.80787154327414, -15.255550452601437, -20.0, 0.0, -30.267355149207315, -30.0, -14.665183369363076, 0.0, -45.61940045558276, -49.9982969999091, 0.0, -40.71881979334435, -34.170086583203236, 0.0, 0.0, -0.8422121258611992, -40.0, -20.0, 0.0, -30.0, 0.0, -42.44387563448731, -1.0812768013137275, -45.06978611269072, -22.894818653197643, -18.678586050859508, -32.217749917098104, -50.0, -20.96686262302261, -10.0, -20.0, -4.127873446832692, -20.0, -0.0493559259710008, -41.36586355126248, -20.0, -30.0, -30.0, -0.5909743779108156, -23.47148812499015, -10.0, 0.0, -2.7122399209291546, -40.0, 0.0, -40.55629845946159, -34.057537648014716, 0.0, -4.595254860126258, -11.183461965027725, 0.0, -66.56912737418062, -20.0, -27.671125395476743, -20.371884065520558, -28.373822282519228, -17.308394807211315, -30.0, -10.0, -70.0, -10.0, -66.29315903220416, -30.0, -72.42562045252954, -13.377194220431335, -30.0, -23.463086349579314, -5.300541727375264, -23.500358589392306, 0.0, -20.320749678919768, 0.0, -74.74808265191037, -20.0, -14.582973175783419, -52.21167033179738, -30.025214453821405, -30.0, -86.19845018587623]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6734861690424156, "mean_inference_ms": 1.1590463821408665, "mean_action_processing_ms": 0.2304690065746141, "mean_env_wait_ms": 0.4978145117910253, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006781316097871757, "StateBufferConnector_ms": 0.0037483962965600285, "ViewRequirementAgentConnector_ms": 0.11412030384864336}, "num_episodes": 162, "episode_return_max": 200.0, "episode_return_min": -40.71881979334435, "episode_return_mean": 37.30141486653647}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 448000, "num_agent_steps_trained": 448000, "num_env_steps_sampled": 112000, "num_env_steps_trained": 112000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 255.05946821097203, "num_env_steps_trained_throughput_per_sec": 255.05946821097203, "timesteps_total": 112000, "num_env_steps_sampled_lifetime": 112000, "num_agent_steps_sampled_lifetime": 448000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 448000, "timers": {"training_iteration_time_ms": 16895.942, "restore_workers_time_ms": 0.022, "training_step_time_ms": 16895.851, "sample_time_ms": 1369.085, "learn_time_ms": 15496.292, "learn_throughput": 258.126, "synch_weights_time_ms": 26.412}, "counters": {"num_env_steps_sampled": 112000, "num_env_steps_trained": 112000, "num_agent_steps_sampled": 448000, "num_agent_steps_trained": 448000}, "done": false, "training_iteration": 28, "trial_id": "b72b3_00000", "date": "2024-08-08_15-38-23", "timestamp": 1723145903, "time_this_iter_s": 15.730101108551025, "time_total_s": 432.45725989341736, "pid": 98177, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3174eaa60>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 432.45725989341736, "iterations_since_restore": 28, "perf": {"cpu_util_percent": 40.381818181818176, "ram_util_percent": 82.05909090909091}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7196673468997081, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.812567238509655, "policy_loss": -0.015373688902279052, "vf_loss": 5.826072315871715, "vf_explained_var": -0.0056869713589549065, "kl": 0.00934313322828886, "entropy": 1.1964841390649477, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 27360.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7390315460609206, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.678972995873039, "policy_loss": -0.014947045764700899, "vf_loss": 4.692625221715751, "vf_explained_var": 9.025030947746115e-07, "kl": 0.006474079224174726, "entropy": 0.9653186628581785, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 80370.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 116000, "num_env_steps_trained": 116000, "num_agent_steps_sampled": 464000, "num_agent_steps_trained": 464000}, "env_runners": {"episode_reward_max": 179.03702635435528, "episode_reward_min": -53.1287204249894, "episode_reward_mean": 42.3495159215282, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -90.96297364564472}, "policy_reward_max": {"adversary_policy": 90.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 23.209876543209877, "agent_policy": -27.28011370810143}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.0, 0.0, 80.0, 0.0, 49.553255500657436, 36.636306253667186, 80.0, 120.0, -7.090293592322823, 40.0, 126.05378143436147, 60.0, 0.0, 80.0, 100.0, 77.20679506344594, 35.19703326298929, 160.0, 80.0, 100.0, 0.0, 20.0, 90.01715027066294, 80.0, 100.0, 179.03702635435528, 140.0, 60.0, 0.0, 54.33922585249687, 119.88708230128634, -1.044191456712078, 60.0, 40.0, 39.94241029716792, 16.63537970708379, 60.0, 120.0, 19.511717991281852, 0.0, 60.0, 11.38389127789447, 57.71265971498653, 40.0, 77.08308212710679, 120.0, 116.92496650646942, 0.0, -6.326576475203786, 15.91864577555206, 80.0, 0.0, 0.0, 0.0, 80.0, 80.0, 60.0, 98.04856301727136, 74.39052787319393, 0.0, -3.186082219362136, 57.60593112683354, 60.0, 60.0, -2.6950493576025876, -4.584876950085751, 40.0, 59.694228238151915, 99.26878987557663, 0.0, 18.245332262706007, 20.0, 58.753078820731346, 53.86960572550341, 51.20336778388005, 30.430317904051993, 33.268603963864415, 10.29982374748837, 0.0, -4.689583952232935, -7.952860803156809, 60.0, 20.0, -43.793021890405726, 40.0, -2.377721422503548, -0.1409742297967964, 40.0, 39.35223476727132, 32.178460360215844, 0.0, 140.0, 100.0, 0.0, 20.0, 60.0, 0.0, -27.701330136754496, 80.0, 0.0, 3.6033399029476505, 31.567263988995165, -17.63196248816283, 54.83617722070892, 46.421441136952225, -5.336211921656584, -0.051154948247020826, 0.0, 79.77653207158481, 0.0, 53.90459458759129, -28.250974673671365, 0.0, 40.0, 40.0, 52.20706114702496, 117.43924055774289, 40.0, 14.327217510903452, 0.0, 60.0, 40.0, -7.551430929396495, -14.021297112075075, 60.0, -1.278859541637346, 120.0, 40.0, 0.0, -0.47550222167894063, 78.24876657243524, -53.1287204249894, 11.491839029988201, 140.0, 100.0, 60.0, 40.0, 0.0, 20.0, 0.0, -8.886412747420556, 40.0, 60.0, 100.0, 99.46347414999305, 79.5709456851256, 125.11279703404972, 20.0, 13.281876466070237, 120.0, 60.0, 80.0, 20.0, 110.15516346856262, -0.012523896598687356, -8.091319006480397, 49.16753657773797, 0.0, 40.0, 0.0, 36.69596941910224, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 70.0, 70.0, 70.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 50.0, 50.0, 50.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 80.0, 80.0, 80.0, 40.0, 40.0, 40.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 40.0, 40.0, 40.0, 50.0, 50.0, 50.0, 90.0, 90.0, 90.0, 70.0, 70.0, 70.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 60.0, 60.0, 60.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 60.0, 60.0, 60.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 70.0, 70.0, 70.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 40.0, 40.0, 40.0, 70.0, 70.0, 70.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 60.0, 60.0, 60.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-20.0, 0.0, -40.0, 0.0, -40.446744499342564, -23.36369374633281, -40.0, -60.0, -7.090293592322823, -20.0, -83.94621856563853, -30.0, 0.0, -40.0, -50.0, -42.79320493655406, -24.802966737010717, -80.0, -40.0, -50.0, 0.0, -10.0, -59.982849729337076, -40.0, -50.0, -90.96297364564472, -70.0, -30.0, 0.0, -35.66077414750313, -60.11291769871366, -1.044191456712078, -30.0, -20.0, -20.05758970283208, -13.364620292916207, -30.0, -60.0, -10.488282008718144, 0.0, -30.0, -18.61610872210553, -32.28734028501347, -20.0, -72.91691787289321, -60.0, -63.075033493530576, 0.0, -6.326576475203786, -44.08135422444794, -40.0, 0.0, 0.0, 0.0, -40.0, -40.0, -30.0, -51.95143698272863, -45.60947212680607, 0.0, -3.186082219362136, -32.39406887316647, -30.0, -30.0, -2.6950493576025876, -4.584876950085751, -20.0, -30.305771761848085, -50.73121012442337, 0.0, -11.75466773729399, -10.0, -31.246921179268647, -36.13039427449659, -38.79663221611995, -59.56968209594801, -56.73139603613558, -19.700176252511632, 0.0, -4.689583952232935, -7.952860803156809, -30.0, -10.0, -43.793021890405726, -20.0, -2.377721422503548, -0.1409742297967964, -20.0, -20.647765232728673, -27.821539639784163, 0.0, -70.0, -50.0, 0.0, -10.0, -30.0, 0.0, -27.701330136754496, -40.0, 0.0, -26.396660097052354, -58.43273601100483, -17.63196248816283, -35.16382277929108, -43.57855886304776, -5.336211921656584, -0.051154948247020826, 0.0, -40.22346792841519, 0.0, -36.09540541240871, -28.250974673671365, 0.0, -20.0, -20.0, -37.79293885297504, -62.5607594422571, -20.0, -15.672782489096546, 0.0, -30.0, -20.0, -7.551430929396495, -14.021297112075075, -30.0, -1.278859541637346, -60.0, -20.0, 0.0, -0.47550222167894063, -41.75123342756477, -53.1287204249894, -48.508160970011794, -70.0, -50.0, -30.0, -20.0, 0.0, -10.0, 0.0, -8.886412747420556, -20.0, -30.0, -50.0, -50.53652585000695, -40.429054314874406, -84.88720296595028, -10.0, -16.718123533929763, -60.0, -30.0, -40.0, -10.0, -69.84483653143741, -0.012523896598687356, -8.091319006480397, -40.83246342226203, 0.0, -20.0, 0.0, -53.30403058089776, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6755171614788018, "mean_inference_ms": 1.161114727479034, "mean_action_processing_ms": 0.23084669928304535, "mean_env_wait_ms": 0.49925297212732106, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005150797926349405, "StateBufferConnector_ms": 0.0037876912105230635, "ViewRequirementAgentConnector_ms": 0.09985418967258783}, "num_episodes": 162, "episode_return_max": 179.03702635435528, "episode_return_min": -53.1287204249894, "episode_return_mean": 42.3495159215282}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 464000, "num_agent_steps_trained": 464000, "num_env_steps_sampled": 116000, "num_env_steps_trained": 116000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 269.9508868521467, "num_env_steps_trained_throughput_per_sec": 269.9508868521467, "timesteps_total": 116000, "num_env_steps_sampled_lifetime": 116000, "num_agent_steps_sampled_lifetime": 464000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 464000, "timers": {"training_iteration_time_ms": 16893.896, "restore_workers_time_ms": 0.021, "training_step_time_ms": 16893.808, "sample_time_ms": 1378.486, "learn_time_ms": 15485.943, "learn_throughput": 258.299, "synch_weights_time_ms": 25.653}, "counters": {"num_env_steps_sampled": 116000, "num_env_steps_trained": 116000, "num_agent_steps_sampled": 464000, "num_agent_steps_trained": 464000}, "done": false, "training_iteration": 29, "trial_id": "b72b3_00000", "date": "2024-08-08_15-38-38", "timestamp": 1723145918, "time_this_iter_s": 14.853816032409668, "time_total_s": 447.311075925827, "pid": 98177, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3174eaca0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 447.311075925827, "iterations_since_restore": 29, "perf": {"cpu_util_percent": 33.33181818181819, "ram_util_percent": 82.24090909090908}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7988274891550342, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.976395839452744, "policy_loss": -0.01620929232885828, "vf_loss": 5.990747831761837, "vf_explained_var": -0.012214007166524729, "kl": 0.00928647170137321, "entropy": 1.2055762245009343, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 28320.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7317588927898001, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.631900781435324, "policy_loss": -0.0175026017429426, "vf_loss": 4.647772606213888, "vf_explained_var": -2.6439309965634175e-06, "kl": 0.008153845016923664, "entropy": 0.9399536494033557, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 83190.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 120000, "num_env_steps_trained": 120000, "num_agent_steps_sampled": 480000, "num_agent_steps_trained": 480000}, "env_runners": {"episode_reward_max": 200.0, "episode_reward_min": -44.5510642318895, "episode_reward_mean": 39.833616225407866, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 157, "episodes_timesteps_total": 3925, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -100.0}, "policy_reward_max": {"adversary_policy": 100.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 22.101910828025478, "agent_policy": -26.472116258668567}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.0, 60.0, 200.0, 60.0, 60.0, -5.818667271691339, 0.0, 0.0, 0.0, -6.345000437981885, -21.697782285791643, 40.0, -1.0148849125214165, 38.015129664791516, -4.247748447825117, 120.0, 0.0, 39.53123306840905, 140.0, 79.72664753143559, 0.0, 140.0, -26.151686723816503, 180.0, 111.34949237629704, -29.080972001481246, 20.0, 0.0, 60.0, -2.7188441299476436, 40.0, -2.0151805664455713, -8.408379323907083, 17.200037468114903, 0.0, 60.0, -0.4567489880258513, -9.929856222221241, 60.0, 0.0, -1.0847101035098083, -0.5724315854586592, 60.0, 19.326286952005464, -4.6930354810807176, 60.0, 29.29049592065979, 80.0, -2.1094486627279743, 60.0, 20.0, 7.086148340362403, -5.109680330923899, 32.04100566196662, 56.72606602222841, 20.0, 60.0, 99.61796294644816, 0.0, 80.0, -2.970532420704889, 80.0, -1.6486987442544399, 35.39142981320319, 120.0, 200.0, -2.0535508674702587, 60.0, 0.0, 22.060920158747606, 60.0, 100.0, 40.0, 100.0, -23.095704613509454, 0.0, 100.0, 77.41045160686893, -3.1265168649480195, 0.0, -15.691819945123212, 100.0, 80.0, -1.0373833793558884, 0.0, 200.0, 0.0, 49.014803021014856, 44.2778499398778, 80.0, 41.38844692239747, 40.0, 45.915410358280106, 80.0, -20.388816111848104, 40.0, -3.6967851350417593, 40.0, 55.89046812885, 60.0, -4.693301695851925, 100.0, 80.0, 120.0, -13.220019413639218, 20.0, -11.846051293126452, 0.0, 0.0, 20.0, 60.0, 84.76813019684721, 0.0, 59.63995648702337, 40.0, 60.0, 37.41808683556428, 20.0, 40.0, 0.0, 60.0, 16.831993450025763, 60.0, 48.548168355129235, -44.5510642318895, 30.428057609700062, 40.0, -0.13069528196267433, 60.0, 0.0, 60.0, 80.0, 0.0, 42.111571959024985, -3.899265364677901, 60.0, 28.80781123570227, -23.245944511329945, -21.608334286145702, 100.0, 60.0, 19.639280786987126, 56.28566926277389, 40.0, 180.0, 0.0, 100.0, 80.0, 40.0, 60.0, 35.16952977106733, 60.0, 99.59040818075583, -1.2874494129926517, 80.0, 60.0, -16.97421159429513], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 100.0, 100.0, 100.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 70.0, 70.0, 70.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 90.0, 90.0, 90.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 60.0, 60.0, 60.0, 100.0, 100.0, 100.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 100.0, 100.0, 100.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 40.0, 40.0, 40.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 90.0, 90.0, 90.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-20.0, -30.0, -100.0, -30.0, -30.0, -35.81866727169134, 0.0, 0.0, 0.0, -6.345000437981885, -21.697782285791643, -20.0, -1.0148849125214165, -21.98487033520848, -4.247748447825117, -60.0, 0.0, -20.46876693159095, -70.0, -40.27335246856441, 0.0, -70.0, -26.151686723816503, -90.0, -68.65050762370298, -29.080972001481246, -10.0, 0.0, -30.0, -2.7188441299476436, -20.0, -2.0151805664455713, -8.408379323907083, -42.7999625318851, 0.0, -30.0, -0.4567489880258513, -9.929856222221241, -30.0, 0.0, -1.0847101035098083, -0.5724315854586592, -30.0, -10.673713047994534, -4.6930354810807176, -30.0, -30.709504079340206, -40.0, -2.1094486627279743, -30.0, -10.0, -22.913851659637604, -5.109680330923899, -27.95899433803338, -33.273933977771584, -10.0, -30.0, -50.38203705355185, 0.0, -40.0, -2.970532420704889, -40.0, -1.6486987442544399, -54.60857018679681, -60.0, -100.0, -2.0535508674702587, -30.0, 0.0, -37.93907984125239, -30.0, -50.0, -20.0, -50.0, -23.095704613509454, 0.0, -50.0, -42.58954839313107, -3.1265168649480195, 0.0, -15.691819945123212, -50.0, -40.0, -1.0373833793558884, 0.0, -100.0, 0.0, -40.985196978985144, -45.7221500601222, -40.0, -48.61155307760254, -20.0, -44.08458964171989, -40.0, -20.388816111848104, -20.0, -3.6967851350417593, -20.0, -34.10953187115, -30.0, -4.693301695851925, -50.0, -40.0, -60.0, -13.220019413639218, -10.0, -11.846051293126452, 0.0, 0.0, -10.0, -30.0, -65.23186980315279, 0.0, -60.360043512976645, -20.0, -30.0, -22.58191316443572, -10.0, -20.0, 0.0, -30.0, -13.168006549974237, -30.0, -71.45183164487075, -44.5510642318895, -29.571942390299938, -20.0, -30.13069528196267, -30.0, 0.0, -30.0, -40.0, 0.0, -47.888428040975015, -3.899265364677901, -30.0, -31.19218876429773, -23.245944511329945, -21.608334286145702, -50.0, -30.0, -10.360719213012874, -33.71433073722611, -20.0, -90.0, 0.0, -50.0, -40.0, -20.0, -30.0, -24.83047022893267, -30.0, -50.40959181924417, -1.2874494129926517, -40.0, -30.0, -16.97421159429513]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6761685907105014, "mean_inference_ms": 1.1626852454285121, "mean_action_processing_ms": 0.23112230792584212, "mean_env_wait_ms": 0.4997169367601829, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005713010289866454, "StateBufferConnector_ms": 0.0036176602551891545, "ViewRequirementAgentConnector_ms": 0.09858615838797988}, "num_episodes": 157, "episode_return_max": 200.0, "episode_return_min": -44.5510642318895, "episode_return_mean": 39.833616225407866}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 480000, "num_agent_steps_trained": 480000, "num_env_steps_sampled": 120000, "num_env_steps_trained": 120000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 260.8878413493928, "num_env_steps_trained_throughput_per_sec": 260.8878413493928, "timesteps_total": 120000, "num_env_steps_sampled_lifetime": 120000, "num_agent_steps_sampled_lifetime": 480000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 480000, "timers": {"training_iteration_time_ms": 16883.047, "restore_workers_time_ms": 0.021, "training_step_time_ms": 16882.972, "sample_time_ms": 1372.537, "learn_time_ms": 15481.798, "learn_throughput": 258.368, "synch_weights_time_ms": 24.919}, "counters": {"num_env_steps_sampled": 120000, "num_env_steps_trained": 120000, "num_agent_steps_sampled": 480000, "num_agent_steps_trained": 480000}, "done": false, "training_iteration": 30, "trial_id": "b72b3_00000", "date": "2024-08-08_15-38-53", "timestamp": 1723145933, "time_this_iter_s": 15.365731716156006, "time_total_s": 462.67680764198303, "pid": 98177, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3174ed310>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 462.67680764198303, "iterations_since_restore": 30, "perf": {"cpu_util_percent": 43.90909090909091, "ram_util_percent": 82.61363636363636}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.795889643083016, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.486023773252964, "policy_loss": -0.01754955992025013, "vf_loss": 6.501629871626695, "vf_explained_var": 0.03349233598758777, "kl": 0.009717346945285487, "entropy": 1.1791346376140912, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 29280.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7433179393305, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.501999171913093, "policy_loss": -0.01694937240462816, "vf_loss": 4.517536569064391, "vf_explained_var": -4.357564533855898e-06, "kl": 0.007059837379964908, "entropy": 0.9213717388557204, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 86010.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 124000, "num_env_steps_trained": 124000, "num_agent_steps_sampled": 496000, "num_agent_steps_trained": 496000}, "env_runners": {"episode_reward_max": 160.0, "episode_reward_min": -71.05096533776724, "episode_reward_mean": 31.3417839538951, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 158, "episodes_timesteps_total": 3950, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -80.0}, "policy_reward_max": {"adversary_policy": 80.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 18.734177215189874, "agent_policy": -24.860747691674515}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-27.207689273278707, 20.0, 20.0, 40.0, 0.0, 0.0, 15.56676003163048, 0.0, 0.0, 40.0, 12.495414302229186, -5.876953103845098, 119.5262502448669, 40.0, 73.65154657677033, -2.7169070648379963, 80.0, 100.0, 27.247195118023583, 60.0, 160.0, -71.05096533776724, -11.358121205476515, -10.43247499207433, 60.0, 56.30707859803442, 50.24262534415016, -66.26147750569575, 0.0, -10.69371928825874, 48.37681350195739, 0.0, 37.747103100109555, 100.0, 20.0, -17.690910508261183, 100.0, 60.0, 40.0, 20.0, -8.827120422459245, 88.07349478710809, 0.0, 0.0, 140.0, 100.0, 60.0, 31.76792671843189, 0.0, 0.0, 19.714054232331076, 80.0, 40.0, 19.589026102230214, 80.0, 5.492602682049518, 20.0, 160.0, 78.67103706167396, 0.0, 40.0, 20.0, 40.0, -20.171442702433723, 100.0, 34.92950050434746, 20.0, -11.30353177522745, 40.0, -23.893669904699205, 60.0, 20.0, -6.104594615711882, 60.0, -32.64505194243913, -1.4013656540108999, -18.185352729946803, 38.966189381061554, -13.052689052728306, 0.0, -4.956228606367944, 60.0, 60.0, 0.0, 100.0, 60.0, 17.368738514572257, 58.47081250718871, 160.0, 71.50765620442776, 19.045028543670266, 120.0, 9.122370780865909, -5.90231992334321, 97.31033267624208, -14.233550961488024, -3.6838746485835143, -9.120364933657457, 0.0, 20.0, -2.8669945567477697, 0.0, 33.03795104111953, 100.0, -15.7762283304187, 58.5094424202802, 37.20997138454455, 20.0, 0.0, 38.10544735735978, 60.0, 33.68005192090999, -2.0275198087880986, -5.716337831803694, 138.95860583319404, 35.24216987230341, 60.0, 10.153189389163359, -50.880666657981564, 82.91545613010989, 60.0, 78.53291141120911, 0.0, 60.0, -23.33299594224331, 40.0, 0.0, 99.63998199133422, 0.0, 60.0, 8.171686322529702, 9.507541804285538, -0.9620261818945974, 0.0, 0.0, 0.0, 20.0, 100.0, 36.46191363966273, 100.0, 52.37806905611051, -4.509034404694586, 80.0, -1.5732313220988612, -21.87756911725593, 0.0, -2.549763170749059, -15.719186768691007, 0.0, 40.0, 0.0, -16.108619882070716, 139.22352816662044, 100.0, 54.59454330629971, 0.0, -23.116378483086773, 38.276774765533546], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 80.0, 80.0, 80.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 80.0, 80.0, 80.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 80.0, 80.0, 80.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 60.0, 60.0, 60.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 70.0, 70.0, 70.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0], "policy_agent_policy_reward": [-27.207689273278707, -10.0, -10.0, -20.0, 0.0, 0.0, -14.433239968369518, 0.0, 0.0, -20.0, -17.504585697770814, -5.876953103845098, -60.473749755133106, -20.0, -46.34845342322969, -2.7169070648379963, -40.0, -50.0, -32.75280488197642, -30.0, -80.0, -71.05096533776724, -11.358121205476515, -10.43247499207433, -30.0, -33.69292140196558, -39.757374655849844, -66.26147750569575, 0.0, -10.69371928825874, -41.62318649804259, 0.0, -52.252896899890445, -50.0, -10.0, -17.690910508261183, -50.0, -30.0, -20.0, -10.0, -8.827120422459245, -61.926505212891904, 0.0, 0.0, -70.0, -50.0, -30.0, -28.232073281568116, 0.0, 0.0, -10.285945767668924, -40.0, -20.0, -10.410973897769784, -40.0, -54.50739731795048, -10.0, -80.0, -41.328962938326036, 0.0, -20.0, -10.0, -20.0, -20.171442702433723, -50.0, -55.07049949565254, -10.0, -11.30353177522745, -20.0, -23.893669904699205, -30.0, -10.0, -36.10459461571188, -30.0, -32.64505194243913, -1.4013656540108999, -18.185352729946803, -21.033810618938446, -13.052689052728306, 0.0, -4.956228606367944, -30.0, -30.0, 0.0, -50.0, -30.0, -12.631261485427743, -31.529187492811296, -80.0, -48.49234379557224, -40.95497145632973, -60.0, -20.87762921913409, -5.90231992334321, -52.68966732375792, -14.233550961488024, -3.6838746485835143, -9.120364933657457, 0.0, -10.0, -2.8669945567477697, 0.0, -26.96204895888047, -50.0, -15.7762283304187, -31.490557579719795, -22.790028615455448, -10.0, 0.0, -21.89455264264022, -30.0, -26.319948079090015, -2.0275198087880986, -35.71633783180369, -71.04139416680593, -24.757830127696593, -30.0, -19.84681061083665, -50.880666657981564, -67.08454386989013, -30.0, -41.46708858879089, 0.0, -30.0, -23.33299594224331, -20.0, 0.0, -50.360018008665776, 0.0, -30.0, -51.8283136774703, -50.49245819571446, -0.9620261818945974, 0.0, 0.0, 0.0, -10.0, -50.0, -23.538086360337267, -50.0, -37.62193094388949, -4.509034404694586, -40.0, -1.5732313220988612, -21.87756911725593, 0.0, -2.549763170749059, -15.719186768691007, 0.0, -20.0, 0.0, -16.108619882070716, -70.77647183337956, -50.0, -35.40545669370029, 0.0, -23.116378483086773, -21.723225234466454]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.675654800012771, "mean_inference_ms": 1.162974503197024, "mean_action_processing_ms": 0.23105127881705184, "mean_env_wait_ms": 0.5001444886238671, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0054718572882157335, "StateBufferConnector_ms": 0.004126376743558087, "ViewRequirementAgentConnector_ms": 0.1022253609910796}, "num_episodes": 158, "episode_return_max": 160.0, "episode_return_min": -71.05096533776724, "episode_return_mean": 31.3417839538951}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 496000, "num_agent_steps_trained": 496000, "num_env_steps_sampled": 124000, "num_env_steps_trained": 124000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 282.0526985406377, "num_env_steps_trained_throughput_per_sec": 282.0526985406377, "timesteps_total": 124000, "num_env_steps_sampled_lifetime": 124000, "num_agent_steps_sampled_lifetime": 496000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 496000, "timers": {"training_iteration_time_ms": 16711.525, "restore_workers_time_ms": 0.021, "training_step_time_ms": 16711.451, "sample_time_ms": 1358.713, "learn_time_ms": 15325.417, "learn_throughput": 261.004, "synch_weights_time_ms": 23.967}, "counters": {"num_env_steps_sampled": 124000, "num_env_steps_trained": 124000, "num_agent_steps_sampled": 496000, "num_agent_steps_trained": 496000}, "done": false, "training_iteration": 31, "trial_id": "b72b3_00000", "date": "2024-08-08_15-39-08", "timestamp": 1723145948, "time_this_iter_s": 14.18741774559021, "time_total_s": 476.86422538757324, "pid": 98177, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3174ed550>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 476.86422538757324, "iterations_since_restore": 31, "perf": {"cpu_util_percent": 36.410000000000004, "ram_util_percent": 82.46500000000002}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9069682395085692, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.208037960529327, "policy_loss": -0.015533205712563359, "vf_loss": 6.221824610233307, "vf_explained_var": 0.009619027686615786, "kl": 0.008732730358455143, "entropy": 1.1965730996181567, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 30240.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7406523804081248, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.68379521293843, "policy_loss": -0.01496048312075271, "vf_loss": 4.697630392997823, "vf_explained_var": 1.8225916733978487e-07, "kl": 0.00562650766791551, "entropy": 0.9074941372195034, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 88830.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 128000, "num_env_steps_trained": 128000, "num_agent_steps_sampled": 512000, "num_agent_steps_trained": 512000}, "env_runners": {"episode_reward_max": 200.0, "episode_reward_min": -40.137942387136775, "episode_reward_mean": 38.67791263385417, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -100.0}, "policy_reward_max": {"adversary_policy": 100.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 21.728395061728396, "agent_policy": -26.507272551331017}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-23.19916086149243, 56.23169080972728, -33.76140642613684, 15.52964837784127, -8.48813762728797, 40.0, -5.710930352825406, 35.28775912584339, 19.802426505938556, 16.198300614068618, -0.3786282571472932, 35.659670231094225, 60.0, 58.69271894724165, 37.72372330800121, 0.0, 40.0, 10.012061525936808, 15.020946295229528, 40.0, 40.0, 40.0, 40.0, 140.0, -1.1251712358906252, -33.61141876442099, -0.789472283813446, -8.495300897610683, 15.496557640280535, 0.0, 100.0, -7.455554564963643, -32.51503278659336, 20.0, 0.0, 79.16241203445719, 160.0, 0.0, 0.0, 40.0, 60.0, 20.0, -5.963706065398407, 0.0, -0.21102164471418106, 0.0, 59.01473346296002, -11.375828147549047, 40.0, -2.022988398427156, 58.210563562777935, 0.0, 66.29176676253338, 180.0, 200.0, 20.0, 0.0, 80.0, 20.0, 79.90421753383875, -8.165927032502278, 20.0, 20.0, 39.72764538462543, 36.99185930233972, -3.849867186385666, 100.0, 100.0, 100.0, 100.0, -13.384980560174686, -4.480979722382241, -2.0545484530539238, 0.0, 40.0, 0.0, 0.0, 0.0, 24.721097127682558, 39.92882747962044, -14.680081194852646, 0.0, -0.42615921560571257, 76.50809933156712, -34.769355596557766, 80.0, -16.63195005898496, 13.122840780669918, 80.0, -12.929215330761048, -19.796903391886403, 0.0, 80.0, 20.0, 34.52756036272788, 52.91271374915093, 60.0, 80.0, 0.0, 0.0, 40.0, 0.0, 20.0, 40.0, 60.0, 180.0, 120.0, 120.0, 100.0, 20.0, 40.0, 100.0, 75.67624553489125, 60.0, 159.89192611236007, 29.639197404652425, 18.69113498886056, 19.97444314714442, 100.0, -22.84471856980103, 94.40512292442357, 20.05431267016723, -14.937034407857773, -0.11869250744088511, 40.0, 160.0, 120.0, 40.0, 37.873318953366734, 100.0, 120.0, 60.0, -3.2838387727043514, 0.0, -9.258601584366764, 60.0, 157.7970097532218, 38.51064937326663, 60.0, 40.0, -40.137942387136775, -2.7697502028599033, 0.0, -2.109769258790922, 59.02401020897115, 59.67967877922804, 39.872681164356, 100.0, 100.0, 40.0, 132.12569828171684, 60.0, 0.0, -2.5233433202155156, 60.0, -3.7081031494849968, 40.0, 15.57328520722185, 80.0, 178.44422914853658, -0.12541700608568518, 20.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 80.0, 80.0, 80.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 90.0, 90.0, 90.0, 100.0, 100.0, 100.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 90.0, 90.0, 90.0, 60.0, 60.0, 60.0, 60.0, 60.0, 60.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 80.0, 80.0, 80.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 80.0, 80.0, 80.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 60.0, 60.0, 60.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 80.0, 80.0, 80.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 70.0, 70.0, 70.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 90.0, 90.0, 90.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0], "policy_agent_policy_reward": [-23.19916086149243, -33.76830919027271, -33.76140642613684, -14.470351622158727, -8.48813762728797, -20.0, -5.710930352825406, -24.712240874156617, -10.197573494061443, -43.801699385931386, -0.3786282571472932, -24.340329768905775, -30.0, -31.30728105275835, -22.276276691998792, 0.0, -20.0, -49.98793847406319, -14.979053704770468, -20.0, -20.0, -20.0, -20.0, -70.0, -1.1251712358906252, -33.61141876442099, -0.789472283813446, -8.495300897610683, -14.503442359719463, 0.0, -50.0, -7.455554564963643, -32.51503278659336, -10.0, 0.0, -40.8375879655428, -80.0, 0.0, 0.0, -20.0, -30.0, -10.0, -5.963706065398407, 0.0, -0.21102164471418106, 0.0, -30.98526653703998, -11.375828147549047, -20.0, -2.022988398427156, -31.789436437222058, 0.0, -53.70823323746663, -90.0, -100.0, -10.0, 0.0, -40.0, -10.0, -40.09578246616125, -38.165927032502275, -10.0, -10.0, -20.272354615374567, -23.00814069766028, -3.849867186385666, -50.0, -50.0, -50.0, -50.0, -73.38498056017468, -4.480979722382241, -2.0545484530539238, 0.0, -20.0, 0.0, 0.0, 0.0, -35.278902872317445, -20.071172520379562, -14.680081194852646, 0.0, -0.42615921560571257, -43.49190066843287, -34.769355596557766, -40.0, -16.63195005898496, -16.877159219330082, -40.0, -12.929215330761048, -19.796903391886403, 0.0, -40.0, -10.0, -25.472439637272117, -37.08728625084907, -30.0, -40.0, 0.0, 0.0, -20.0, 0.0, -10.0, -20.0, -30.0, -90.0, -60.0, -60.0, -50.0, -10.0, -20.0, -50.0, -44.323754465108756, -30.0, -80.10807388763995, -30.360802595347582, -11.308865011139437, -10.025556852855582, -50.0, -22.84471856980103, -55.594877075576434, -39.945687329832765, -14.937034407857773, -0.11869250744088511, -20.0, -80.0, -60.0, -20.0, -52.126681046633266, -50.0, -60.0, -30.0, -33.28383877270434, 0.0, -9.258601584366764, -30.0, -82.2029902467782, -21.48935062673337, -30.0, -20.0, -40.137942387136775, -2.7697502028599033, 0.0, -2.109769258790922, -60.975989791028844, -30.32032122077196, -20.127318835643994, -50.0, -50.0, -20.0, -77.87430171828319, -30.0, 0.0, -2.5233433202155156, -30.0, -3.7081031494849968, -20.0, -74.42671479277816, -40.0, -91.55577085146342, -0.12541700608568518, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6737131249105491, "mean_inference_ms": 1.1597336164529752, "mean_action_processing_ms": 0.2307088177774799, "mean_env_wait_ms": 0.49946213339511697, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0042164767229998555, "StateBufferConnector_ms": 0.0031591197590769074, "ViewRequirementAgentConnector_ms": 0.08959637747870551}, "num_episodes": 162, "episode_return_max": 200.0, "episode_return_min": -40.137942387136775, "episode_return_mean": 38.67791263385417}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 512000, "num_agent_steps_trained": 512000, "num_env_steps_sampled": 128000, "num_env_steps_trained": 128000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 292.4527267505734, "num_env_steps_trained_throughput_per_sec": 292.4527267505734, "timesteps_total": 128000, "num_env_steps_sampled_lifetime": 128000, "num_agent_steps_sampled_lifetime": 512000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 512000, "timers": {"training_iteration_time_ms": 16338.139, "restore_workers_time_ms": 0.024, "training_step_time_ms": 16338.072, "sample_time_ms": 1349.687, "learn_time_ms": 14961.524, "learn_throughput": 267.352, "synch_weights_time_ms": 23.688}, "counters": {"num_env_steps_sampled": 128000, "num_env_steps_trained": 128000, "num_agent_steps_sampled": 512000, "num_agent_steps_trained": 512000}, "done": false, "training_iteration": 32, "trial_id": "b72b3_00000", "date": "2024-08-08_15-39-22", "timestamp": 1723145962, "time_this_iter_s": 13.683519124984741, "time_total_s": 490.547744512558, "pid": 98177, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3174eaca0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 490.547744512558, "iterations_since_restore": 32, "perf": {"cpu_util_percent": 33.22, "ram_util_percent": 82.83}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9042551754663388, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.93167644366622, "policy_loss": -0.02206648871554838, "vf_loss": 5.951414614419142, "vf_explained_var": -0.0041204210991660755, "kl": 0.011641600335186445, "entropy": 1.1892942360291878, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 31200.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7408457273498494, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.432938319909657, "policy_loss": -0.016239532931752797, "vf_loss": 4.447741208516114, "vf_explained_var": 8.810707863340986e-07, "kl": 0.007183229880402985, "entropy": 0.9009230442715029, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 91650.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 132000, "num_env_steps_trained": 132000, "num_agent_steps_sampled": 528000, "num_agent_steps_trained": 528000}, "env_runners": {"episode_reward_max": 200.0, "episode_reward_min": -50.10778105362279, "episode_reward_mean": 37.87602190938853, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -100.0}, "policy_reward_max": {"adversary_policy": 100.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 21.234567901234566, "agent_policy": -25.82768179431518}, "custom_metrics": {}, "hist_stats": {"episode_reward": [17.69403796862689, 60.0, 20.0, -4.432500584648484, 32.67639316119808, 40.0, -0.18526256292412113, 100.0, -17.222819060892807, 0.0, -6.669829907621551, 40.0, 40.0, -22.421399879143838, 0.0, 115.5048974647761, -4.2470929561182675, -37.249470518799605, 40.0, -10.293300594066977, 36.51273980399903, 20.0, 40.0, 39.31986002068315, 20.0, 40.0, 80.0, -24.560300714246008, -0.7880568840265734, -5.605124746583924, 20.0, 60.0, 0.0, 40.0, -13.993740182132843, 0.0, 0.7007120061495566, 159.56002051228393, 80.0, 79.18931696589786, 57.10431105891931, -1.2016066248309099, 60.0, 56.029574083857966, -4.290939898239205, 20.0, 120.0, 80.0, 0.0, 120.0, 160.0, 80.0, 120.0, 40.0, 60.0, 119.52401424071724, 80.0, 0.0, 0.0, -14.720273201785908, -23.568787908070682, 80.0, 120.0, 0.0, 18.07825732589722, -28.902511974113526, 0.0, 75.14362908496032, -8.068412339992866, 78.48421365707864, 120.0, 34.57599712088913, -0.4077546883884531, 0.0, -6.341397051875651, -17.325532931402147, -25.020095850149897, -1.723442963880366, 119.3483167489926, 60.0, 60.0, 56.2181004329037, 140.0, 98.88588246409702, 0.0, 60.0, 15.976914499512457, 120.0, 40.0, 98.65965959461106, 0.0, 44.368106081526506, 40.0, 100.0, 26.258723403853942, 40.0, 40.0, 0.0, -14.539789839895594, -11.163195856631534, 60.0, -3.739178318592286, 0.0, -10.641857674972584, 0.0, 0.0, 55.96456158818856, -41.23058909715592, 17.66968745147671, 24.76152204318288, 80.0, 99.00455837448965, -2.780248204959431, 0.0, 38.29105886338384, 60.0, 120.0, 39.75888052568769, -11.95396325815042, 25.958756498029096, 99.7114221751944, 0.0, 100.0, 60.0, 59.83192943741426, 75.99581036356221, 60.0, -0.4139409654698578, 59.57379776724106, 95.15513771866846, 120.0, 40.0, -2.1251194104061155, 21.74848897064324, -10.702866681358401, 38.961659719745654, 140.0, 18.322075628832366, -0.5982026916367122, 60.0, -13.081211506175256, 39.929543768376384, 20.0, 40.0, 59.75601106396115, 20.0, -50.10778105362279, 100.0, -2.2325703088206517, 18.749767820276254, 99.64709622308655, 200.0, 60.0, -2.235248427871384, 0.0, -5.44299852673273, 0.0, 80.0, 60.0, 29.731440025117948, 0.0, 19.80708143933717], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 80.0, 80.0, 80.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 60.0, 60.0, 60.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 80.0, 80.0, 80.0, 40.0, 40.0, 40.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 60.0, 60.0, 60.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 70.0, 70.0, 70.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 70.0, 70.0, 70.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 100.0, 100.0, 100.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0], "policy_agent_policy_reward": [-42.30596203137311, -30.0, -10.0, -4.432500584648484, -27.323606838801922, -20.0, -0.18526256292412113, -50.0, -17.222819060892807, 0.0, -6.669829907621551, -20.0, -20.0, -22.421399879143838, 0.0, -64.49510253522388, -4.2470929561182675, -37.249470518799605, -20.0, -10.293300594066977, -23.487260196000967, -10.0, -20.0, -20.68013997931685, -10.0, -20.0, -40.0, -24.560300714246008, -0.7880568840265734, -5.605124746583924, -10.0, -30.0, 0.0, -20.0, -13.993740182132843, 0.0, -29.29928799385044, -80.43997948771606, -40.0, -40.81068303410214, -32.8956889410807, -1.2016066248309099, -30.0, -33.97042591614204, -4.290939898239205, -10.0, -60.0, -40.0, 0.0, -60.0, -80.0, -40.0, -60.0, -20.0, -30.0, -60.47598575928276, -40.0, 0.0, 0.0, -14.720273201785908, -23.568787908070682, -40.0, -60.0, 0.0, -11.921742674102783, -28.902511974113526, 0.0, -44.856370915039655, -8.068412339992866, -41.51578634292136, -60.0, -25.42400287911087, -0.4077546883884531, 0.0, -6.341397051875651, -17.325532931402147, -25.020095850149897, -1.723442963880366, -60.65168325100739, -30.0, -30.0, -33.7818995670963, -70.0, -51.114117535902984, 0.0, -30.0, -14.023085500487543, -60.0, -20.0, -51.34034040538894, 0.0, -75.6318939184735, -20.0, -50.0, -33.74127659614606, -20.0, -20.0, 0.0, -14.539789839895594, -11.163195856631534, -30.0, -3.739178318592286, 0.0, -10.641857674972584, 0.0, 0.0, -34.03543841181145, -41.23058909715592, -12.330312548523288, -35.23847795681712, -40.0, -50.995441625510345, -2.780248204959431, 0.0, -21.708941136616158, -30.0, -60.0, -20.241119474312313, -11.95396325815042, -34.041243501970904, -50.28857782480559, 0.0, -50.0, -30.0, -30.168070562585743, -44.004189636437786, -30.0, -0.4139409654698578, -90.42620223275894, -54.844862281331544, -60.0, -20.0, -2.1251194104061155, -38.251511029356756, -10.702866681358401, -21.038340280254342, -70.0, -11.677924371167636, -0.5982026916367122, -30.0, -13.081211506175256, -20.070456231623616, -10.0, -20.0, -30.243988936038857, -10.0, -50.10778105362279, -50.0, -2.2325703088206517, -11.250232179723746, -50.35290377691346, -100.0, -30.0, -2.235248427871384, 0.0, -5.44299852673273, 0.0, -40.0, -30.0, -60.268559974882045, 0.0, -10.192918560662829]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6738931236188634, "mean_inference_ms": 1.1588851098345376, "mean_action_processing_ms": 0.23076259822001025, "mean_env_wait_ms": 0.4991927343224142, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004478222058143144, "StateBufferConnector_ms": 0.003755019034868405, "ViewRequirementAgentConnector_ms": 0.09660963658933286}, "num_episodes": 162, "episode_return_max": 200.0, "episode_return_min": -50.10778105362279, "episode_return_mean": 37.87602190938853}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 528000, "num_agent_steps_trained": 528000, "num_env_steps_sampled": 132000, "num_env_steps_trained": 132000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 285.12202401027247, "num_env_steps_trained_throughput_per_sec": 285.12202401027247, "timesteps_total": 132000, "num_env_steps_sampled_lifetime": 132000, "num_agent_steps_sampled_lifetime": 528000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 528000, "timers": {"training_iteration_time_ms": 16009.862, "restore_workers_time_ms": 0.022, "training_step_time_ms": 16009.799, "sample_time_ms": 1306.567, "learn_time_ms": 14676.962, "learn_throughput": 272.536, "synch_weights_time_ms": 23.41}, "counters": {"num_env_steps_sampled": 132000, "num_env_steps_trained": 132000, "num_agent_steps_sampled": 528000, "num_agent_steps_trained": 528000}, "done": false, "training_iteration": 33, "trial_id": "b72b3_00000", "date": "2024-08-08_15-39-36", "timestamp": 1723145976, "time_this_iter_s": 14.047964096069336, "time_total_s": 504.5957086086273, "pid": 98177, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3174edee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 504.5957086086273, "iterations_since_restore": 33, "perf": {"cpu_util_percent": 32.225, "ram_util_percent": 82.39999999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.1371005920072395, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.120323703189691, "policy_loss": -0.015627856602804968, "vf_loss": 6.134192819396655, "vf_explained_var": -0.027564731736977894, "kl": 0.008793840865072922, "entropy": 1.1633506905287505, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 32160.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7265319333325887, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.429508334440542, "policy_loss": -0.016909341775343246, "vf_loss": 4.44496158378344, "vf_explained_var": 1.5523205412195084e-06, "kl": 0.00728043285240782, "entropy": 0.8671354762417205, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 94470.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 136000, "num_env_steps_trained": 136000, "num_agent_steps_sampled": 544000, "num_agent_steps_trained": 544000}, "env_runners": {"episode_reward_max": 239.62871545774124, "episode_reward_min": -38.20880505877896, "episode_reward_mean": 34.26325439649741, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 157, "episodes_timesteps_total": 3925, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -120.37128454225876}, "policy_reward_max": {"adversary_policy": 120.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 19.29936305732484, "agent_policy": -23.634834775477117}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 19.873205414023978, 19.742230884097594, 56.1533246418435, 0.0, 40.0, -0.4781895137799408, 19.100511197142893, -2.9561451442345215, 100.0, 98.28416494043206, 20.0, 239.62871545774124, 60.0, 100.0, 0.0, 79.95090268847406, 0.0, 40.0, -1.840016163718593, -3.575172264770269, -6.279378493116068, 100.0, 40.0, 100.0, 28.63112016192475, 59.45404286747929, 40.0, -38.20880505877896, 0.0, -14.265566876585437, 59.51763997562326, 78.87487556637426, 160.0, 119.55183936761938, 78.87981084332705, 0.0, 40.0, -1.6273222699817647, 99.951043874585, 180.0, 100.0, -0.41158075267104577, 20.0, -0.2387759930005422, -6.186871941256649, 0.0, 60.0, -10.492898751637451, 59.79619339527203, 20.0, 60.0, 0.0, 0.0, -10.336474560060646, 6.617968146779944, 60.0, 12.593055319211324, 60.0, 17.260163782047226, 103.37759625861354, -1.2889791256307626, -2.110829650281648, -4.340494252344138, 105.01174981914777, 1.3554049384411957, 154.37824354975464, 20.0, -5.019080032086382, 80.0, 40.0, -1.1408497318802524, -22.957019416913624, 20.0, -12.095853681376964, 0.0, -2.5002618673036117, 40.0, -0.9327800216668714, 39.751482825726896, 58.84364377430309, 80.0, 37.409766886728214, 40.0, 0.0, -3.5071135444906356, 60.0, 17.445285587668977, -11.167511449815366, 0.0, 72.49874466809084, -1.6504196249226921, 13.408877864300328, -33.33810456236744, 100.0, 20.0, 60.0, -12.799666622926654, -8.038912466825138, 0.0, 0.0, 82.92659206751759, 80.0, 139.95426936219874, 40.0, 36.91648927692989, -25.41841981553352, 14.390929610316485, -1.9224285149711695, -2.673195537088686, 20.0, 0.0, 0.0, -1.3422798458796004, 0.0, 35.88971948766326, 39.01555408570735, -8.48155503354394, -10.197228271950694, 160.0, 7.641762968929072, -5.136985677909382, 60.0, 35.123297838667014, 39.24604430792186, 40.0, 29.530552768853767, 40.0, -14.179881051758855, 35.74259273629356, -17.56181494603433, -10.416148204675748, 80.0, 37.9532085087212, -9.34004626737284, 80.0, 0.0, 100.0, 60.0, 0.0, 0.020869511157076914, -14.298191010819348, 200.0, 100.0, -31.943751072321533, -7.0885719988445715, -2.03763841386749, 60.0, -19.873498858771395, 0.0, -10.665838621791789, 100.0, 60.0, 80.0, 60.0, 120.0, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 120.0, 120.0, 120.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 80.0, 80.0, 80.0, 60.0, 60.0, 60.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 90.0, 90.0, 90.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 10.0, 10.0, 10.0, 80.0, 80.0, 80.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 40.0, 40.0, 40.0, 70.0, 70.0, 70.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 80.0, 80.0, 80.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 100.0, 100.0, 100.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [0.0, -10.12679458597602, -10.257769115902404, -33.84667535815652, 0.0, -20.0, -0.4781895137799408, -40.89948880285709, -2.9561451442345215, -50.0, -51.71583505956794, -10.0, -120.37128454225876, -30.0, -50.0, 0.0, -40.04909731152594, 0.0, -20.0, -1.840016163718593, -3.575172264770269, -6.279378493116068, -50.0, -20.0, -50.0, -31.36887983807525, -30.545957132520716, -20.0, -38.20880505877896, 0.0, -14.265566876585437, -30.482360024376742, -41.12512443362574, -80.0, -60.44816063238062, -41.12018915667294, 0.0, -20.0, -1.6273222699817647, -50.048956125414996, -90.0, -50.0, -0.41158075267104577, -10.0, -30.23877599300053, -6.186871941256649, 0.0, -30.0, -10.492898751637451, -30.20380660472797, -10.0, -30.0, 0.0, 0.0, -10.336474560060646, -23.382031853220056, -30.0, -17.406944680788673, -30.0, -12.739836217952774, -76.62240374138649, -1.2889791256307626, -2.110829650281648, -4.340494252344138, -74.98825018085223, -28.644595061558803, -85.62175645024536, -10.0, -5.019080032086382, -40.0, -20.0, -1.1408497318802524, -22.957019416913624, -10.0, -12.095853681376964, 0.0, -2.5002618673036117, -20.0, -0.9327800216668714, -20.248517174273104, -31.15635622569691, -40.0, -22.590233113271786, -20.0, 0.0, -3.5071135444906356, -30.0, -12.554714412331023, -11.167511449815366, 0.0, -47.50125533190917, -1.6504196249226921, -16.591122135699667, -33.33810456236744, -50.0, -10.0, -30.0, -12.799666622926654, -8.038912466825138, 0.0, 0.0, -67.07340793248241, -40.0, -70.04573063780124, -20.0, -23.08351072307012, -55.41841981553351, -15.609070389683515, -1.9224285149711695, -2.673195537088686, -10.0, 0.0, 0.0, -1.3422798458796004, 0.0, -24.110280512336743, -20.984445914292646, -8.48155503354394, -10.197228271950694, -80.0, -22.358237031070928, -5.136985677909382, -30.0, -24.876702161332986, -20.753955692078144, -20.0, -30.469447231146233, -20.0, -14.179881051758855, -24.25740726370643, -17.56181494603433, -10.416148204675748, -40.0, -22.046791491278803, -9.34004626737284, -40.0, 0.0, -50.0, -30.0, 0.0, -29.979130488842923, -14.298191010819348, -100.0, -50.0, -31.943751072321533, -7.0885719988445715, -2.03763841386749, -30.0, -19.873498858771395, 0.0, -10.665838621791789, -50.0, -30.0, -40.0, -30.0, -60.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6725453452369391, "mean_inference_ms": 1.155930428052913, "mean_action_processing_ms": 0.23034699033704203, "mean_env_wait_ms": 0.498237938080155, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004025781230562052, "StateBufferConnector_ms": 0.0043029997758804615, "ViewRequirementAgentConnector_ms": 0.08758655778921334}, "num_episodes": 157, "episode_return_max": 239.62871545774124, "episode_return_min": -38.20880505877896, "episode_return_mean": 34.26325439649741}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 544000, "num_agent_steps_trained": 544000, "num_env_steps_sampled": 136000, "num_env_steps_trained": 136000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 279.03946462368344, "num_env_steps_trained_throughput_per_sec": 279.03946462368344, "timesteps_total": 136000, "num_env_steps_sampled_lifetime": 136000, "num_agent_steps_sampled_lifetime": 544000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 544000, "timers": {"training_iteration_time_ms": 15883.299, "restore_workers_time_ms": 0.021, "training_step_time_ms": 15883.237, "sample_time_ms": 1285.173, "learn_time_ms": 14571.962, "learn_throughput": 274.5, "synch_weights_time_ms": 23.167}, "counters": {"num_env_steps_sampled": 136000, "num_env_steps_trained": 136000, "num_agent_steps_sampled": 544000, "num_agent_steps_trained": 544000}, "done": false, "training_iteration": 34, "trial_id": "b72b3_00000", "date": "2024-08-08_15-39-50", "timestamp": 1723145990, "time_this_iter_s": 14.369923114776611, "time_total_s": 518.9656317234039, "pid": 98177, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3174f5310>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 518.9656317234039, "iterations_since_restore": 34, "perf": {"cpu_util_percent": 32.01904761904762, "ram_util_percent": 81.66190476190475}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9794200389335552, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.505043501655261, "policy_loss": -0.019644837123632897, "vf_loss": 6.522729221979777, "vf_explained_var": -0.010234562307596206, "kl": 0.009795676762917153, "entropy": 1.1425009574741125, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 33120.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7355704573663414, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.102944029814808, "policy_loss": -0.015858463553715074, "vf_loss": 5.117427600444631, "vf_explained_var": 1.4003498334411189e-06, "kl": 0.006874481553384222, "entropy": 0.860455849005821, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 97290.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 140000, "num_env_steps_trained": 140000, "num_agent_steps_sampled": 560000, "num_agent_steps_trained": 560000}, "env_runners": {"episode_reward_max": 180.0, "episode_reward_min": -37.61292292979908, "episode_reward_mean": 39.665208677946225, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -90.0}, "policy_reward_max": {"adversary_policy": 90.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 22.160493827160494, "agent_policy": -26.816272803535256}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-2.497506710393921, 0.0, 79.63266242598111, 38.653124033424135, 74.27248915213681, 46.69846844737046, -0.21760943673135746, 0.0, 40.0, 55.37760583178214, 120.0, 140.0, 180.0, -34.4013875708218, 78.47994396224738, 40.0, 50.27778447668274, 40.0, 11.638469162253333, 140.0, 0.0, 80.0, 40.0, -37.61292292979908, 20.0, 60.0, -13.081055743555092, 60.0, 0.0, 6.1278322072646745, -8.780776984370661, 180.0, 24.00312076456164, 28.45024331922358, 0.0, 20.0, 59.85420833938093, 60.0, 40.0, -12.257616776046273, 120.0, 0.0, -18.652368402332264, 160.0, 38.690807367988775, 0.0, 100.0, -1.6765121958173068, -0.33028586787370307, -5.431532831789861, -0.750462819751242, 160.0, -22.222910267420584, 80.0, 40.0, 60.0, -5.533085441363794, 60.0, 80.0, 100.0, 120.0, 0.0, 135.17235552643066, 0.0, 60.0, 40.0, 18.466996263984754, 158.1143085611049, -6.995994557780932, 40.0, -5.439658448234194, 180.0, 60.0, -31.296488786149876, -3.753234738808909, 60.0, -2.2000037271371964, 80.0, 40.0, 60.0, 20.0, -0.5102701633151752, 59.696389029577716, 120.0, 17.54718968102116, 40.0, -27.18260148605374, 80.0, -14.477784576268837, 100.0, 80.0, 0.0, 1.0606940318266478, 60.0, 60.0, 0.0, 94.21467298238093, -17.491517334813903, 40.0, 40.0, 39.64464483290763, 40.0, 40.0, -3.0402744731622295, 60.0, 40.0, 9.42646767951495, 60.0, 20.0, 96.09122962658066, -9.553541456721392, 7.51841017823631, 60.0, 9.002393970451166, 20.0, 60.0, 54.98660826589887, 40.0, 0.0, 20.0, 37.80649967403311, 0.0, 100.0, 0.0, 49.763583382806125, -3.5707599095964206, -18.492997379236222, 60.0, -1.1404640222299023, 20.0, 60.0, 0.0, 95.51298915026523, 0.0, 8.2584560033539, 16.949111770720652, 120.0, 80.0, 80.0, 60.0, -20.290848609076075, 16.16537167219203, 55.870603289866594, 100.0, -1.03262372982464, -17.911187384563046, 51.011287851250515, 60.0, 80.0, 40.0, 0.0, -27.37058211235946, 0.0, 22.223388278874324, -17.254728575732944, 0.0, 56.64272231942009, 0.0, -2.2537932422781335, 39.17215036489202, 97.99391064081003, 60.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 60.0, 60.0, 60.0, 70.0, 70.0, 70.0, 90.0, 90.0, 90.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 90.0, 90.0, 90.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 80.0, 80.0, 80.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 80.0, 80.0, 80.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 50.0, 50.0, 50.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 80.0, 80.0, 80.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 90.0, 90.0, 90.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 60.0, 60.0, 60.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 60.0, 60.0, 60.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0], "policy_agent_policy_reward": [-2.497506710393921, 0.0, -40.367337574018876, -21.346875966575865, -45.72751084786318, -43.30153155262954, -0.21760943673135746, 0.0, -20.0, -34.62239416821786, -60.0, -70.0, -90.0, -34.4013875708218, -41.52005603775264, -20.0, -39.72221552331726, -20.0, -18.361530837746667, -70.0, 0.0, -40.0, -20.0, -37.61292292979908, -10.0, -30.0, -13.081055743555092, -30.0, 0.0, -23.87216779273532, -38.78077698437066, -90.0, -35.996879235438364, -31.54975668077642, 0.0, -10.0, -30.145791660619064, -30.0, -20.0, -12.257616776046273, -60.0, 0.0, -18.652368402332264, -80.0, -21.309192632011232, 0.0, -50.0, -1.6765121958173068, -0.33028586787370307, -5.431532831789861, -0.750462819751242, -80.0, -22.222910267420584, -40.0, -20.0, -30.0, -5.533085441363794, -30.0, -40.0, -50.0, -60.0, 0.0, -74.82764447356931, 0.0, -30.0, -20.0, -41.533003736015246, -81.88569143889508, -66.99599455778092, -20.0, -5.439658448234194, -90.0, -30.0, -31.296488786149876, -3.753234738808909, -30.0, -32.200003727137194, -40.0, -20.0, -30.0, -10.0, -0.5102701633151752, -30.303610970422284, -60.0, -12.452810318978843, -20.0, -27.18260148605374, -40.0, -14.477784576268837, -50.0, -40.0, 0.0, -28.939305968173354, -30.0, -30.0, 0.0, -55.78532701761907, -17.491517334813903, -20.0, -20.0, -20.355355167092373, -20.0, -20.0, -3.0402744731622295, -30.0, -20.0, -20.57353232048505, -30.0, -10.0, -53.908770373419344, -9.553541456721392, -22.481589821763688, -30.0, -20.997606029548834, -10.0, -30.0, -35.01339173410112, -20.0, 0.0, -10.0, -22.193500325966887, 0.0, -50.0, 0.0, -40.236416617193875, -3.5707599095964206, -18.492997379236222, -30.0, -1.1404640222299023, -10.0, -30.0, 0.0, -54.48701084973477, 0.0, -21.7415439966461, -13.050888229279348, -60.0, -40.0, -40.0, -30.0, -20.290848609076075, -13.834628327807964, -34.129396710133406, -50.0, -1.03262372982464, -17.911187384563046, -38.988712148749485, -30.0, -40.0, -20.0, 0.0, -27.37058211235946, 0.0, -37.776611721125676, -17.254728575732944, 0.0, -33.35727768057991, 0.0, -2.2537932422781335, -50.82784963510798, -52.006089359189986, -30.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6701378468797634, "mean_inference_ms": 1.1520368881206953, "mean_action_processing_ms": 0.22975338213985483, "mean_env_wait_ms": 0.4969737827755276, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00490583019492067, "StateBufferConnector_ms": 0.003074275122748481, "ViewRequirementAgentConnector_ms": 0.08563193274132999}, "num_episodes": 162, "episode_return_max": 180.0, "episode_return_min": -37.61292292979908, "episode_return_mean": 39.665208677946225}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 560000, "num_agent_steps_trained": 560000, "num_env_steps_sampled": 140000, "num_env_steps_trained": 140000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 288.76815298508103, "num_env_steps_trained_throughput_per_sec": 288.76815298508103, "timesteps_total": 140000, "num_env_steps_sampled_lifetime": 140000, "num_agent_steps_sampled_lifetime": 560000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 560000, "timers": {"training_iteration_time_ms": 15784.477, "restore_workers_time_ms": 0.022, "training_step_time_ms": 15784.415, "sample_time_ms": 1271.24, "learn_time_ms": 14487.204, "learn_throughput": 276.106, "synch_weights_time_ms": 23.041}, "counters": {"num_env_steps_sampled": 140000, "num_env_steps_trained": 140000, "num_agent_steps_sampled": 560000, "num_agent_steps_trained": 560000}, "done": false, "training_iteration": 35, "trial_id": "b72b3_00000", "date": "2024-08-08_15-40-04", "timestamp": 1723146004, "time_this_iter_s": 13.858759880065918, "time_total_s": 532.8243916034698, "pid": 98177, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3174f5820>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 532.8243916034698, "iterations_since_restore": 35, "perf": {"cpu_util_percent": 28.40526315789474, "ram_util_percent": 81.2578947368421}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.2167734543482465, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.530142631133398, "policy_loss": -0.019014903839949207, "vf_loss": 6.547240014374256, "vf_explained_var": -0.009489227024217447, "kl": 0.00958758505122329, "entropy": 1.1264362855503955, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 34080.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7354294511654699, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.561830969989723, "policy_loss": -0.0168183662008258, "vf_loss": 4.577386229258057, "vf_explained_var": -3.4031715798885266e-07, "kl": 0.006315493847183072, "entropy": 0.8239125072956085, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 100110.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 144000, "num_env_steps_trained": 144000, "num_agent_steps_sampled": 576000, "num_agent_steps_trained": 576000}, "env_runners": {"episode_reward_max": 240.0, "episode_reward_min": -49.66408058938351, "episode_reward_mean": 40.63808877333945, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 158, "episodes_timesteps_total": 3950, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -120.0}, "policy_reward_max": {"adversary_policy": 120.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 23.164556962025316, "agent_policy": -28.8555821127365}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.0, 79.74247553607654, -11.68750689023614, -7.928680629790107, 58.40535888388201, 140.0, 40.44124789701876, 72.44884886007425, 120.0, 51.178799569582395, 80.0, 35.2031082511247, 0.0, 20.0, -15.70935524537651, 0.0, 34.899830326770335, 140.0, 80.0, 0.0, 12.042434271499454, 0.0, 31.4272513129445, -19.35409449869648, 56.429058817053374, -0.9420773855192333, 140.0, 6.9574411358793595, 0.0, 100.0, 0.0, 59.32541434687349, 0.0, -0.3647988429076976, -8.891383355786521, 0.0, -6.177163594677333, -27.951962716841837, 37.92419376507717, 40.0, 125.52770026424739, -21.861467152834496, 20.0, 17.44845459475992, 120.0, -0.469444349974919, -0.5151028450618167, 37.80976728501422, -2.559895607648468, 100.0, 60.0, -4.4886858613988725, 0.0, 99.39888202680508, 28.435890838010955, 29.252727472688225, -16.404692649236264, 80.0, 77.98176244432088, 240.0, 0.0, 56.886322613997145, 51.52137363953953, 100.0, -37.40032165464295, -3.530666039165445, -4.395011036257093, 40.0, 140.0, 40.0, 140.0, -1.3817180401942608, 93.03381472472067, -10.266156196942418, -17.725469537853833, 16.419196462204816, 20.0, 35.06708153524589, 120.0, 120.0, 100.0, 79.48734886358054, 59.84762432841082, -17.84774218691922, 38.275394783539994, -24.16559870939187, 39.068472950078814, 140.0, 60.0, 138.17127587678578, 40.0, 23.618830127491616, -26.093223335796576, 98.720553975825, 17.569586563592566, 59.083815484928905, -14.716751492448946, -23.435512825895316, -49.66408058938351, -26.211097857757196, 80.0, 20.0, -0.10763791983276705, 60.0, -18.445285542877475, 160.0, 140.0, -3.6203415293073484, 40.0, 136.497657902418, -11.1360364727557, 154.41671938848373, 96.48435170141997, -13.657517928165515, -12.07923329954775, 80.0, 80.0, 0.0, 76.79380983153402, -6.00989848175288, 60.0, 33.95408200658101, 20.0, 60.0, 41.159656293957624, 0.0, 37.469510824131746, 36.69552992260271, 160.0, 60.0, 40.0, 40.0, -0.15062664612642385, -0.23846204208941235, -3.944632318226354, 0.0, 59.86028053557857, 58.667519320951186, 36.07422818211572, 26.34546526159641, 0.0, 100.0, 42.58070071143751, 56.48727556936194, 139.51918806699695, 68.22215000006172, 57.04393891721338, -0.3735639512397537, -5.307271025145858, -2.9027264890298476, 79.74810040119618, 12.389643347201847, -24.917309905292036, -34.73473642261585, 40.0, 0.0, 91.12181927578787, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 70.0, 70.0, 70.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 60.0, 60.0, 60.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 70.0, 70.0, 70.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 120.0, 120.0, 120.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 70.0, 70.0, 70.0, 20.0, 20.0, 20.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 60.0, 60.0, 60.0, 60.0, 60.0, 60.0, 50.0, 50.0, 50.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 70.0, 70.0, 70.0, 30.0, 30.0, 30.0, 70.0, 70.0, 70.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 80.0, 80.0, 80.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 80.0, 80.0, 80.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 80.0, 80.0, 80.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 70.0, 70.0, 70.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-20.0, -40.25752446392345, -11.68750689023614, -37.92868062979011, -31.594641116117987, -70.0, -49.55875210298124, -47.55115113992575, -60.0, -38.821200430417605, -40.0, -24.796891748875293, 0.0, -10.0, -15.70935524537651, 0.0, -25.100169673229658, -70.0, -40.0, 0.0, -17.95756572850055, 0.0, -28.57274868705549, -19.35409449869648, -33.570941182946626, -0.9420773855192333, -70.0, -53.04255886412063, 0.0, -50.0, 0.0, -30.674585653126506, 0.0, -0.3647988429076976, -8.891383355786521, 0.0, -6.177163594677333, -27.951962716841837, -22.075806234922833, -20.0, -84.47229973575261, -21.861467152834496, -10.0, -12.55154540524008, -60.0, -0.469444349974919, -0.5151028450618167, -22.19023271498578, -2.559895607648468, -50.0, -30.0, -4.4886858613988725, 0.0, -50.601117973194924, -31.564109161989045, -30.747272527311775, -16.404692649236264, -40.0, -42.01823755567912, -120.0, 0.0, -33.113677386002855, -38.47862636046047, -50.0, -37.40032165464295, -3.530666039165445, -4.395011036257093, -20.0, -70.0, -20.0, -70.0, -1.3817180401942608, -56.96618527527933, -10.266156196942418, -17.725469537853833, -13.580803537795184, -10.0, -24.93291846475411, -60.0, -60.0, -50.0, -40.512651136419464, -30.152375671589187, -17.84774218691922, -21.724605216460006, -24.16559870939187, -20.931527049921186, -70.0, -30.0, -71.8287241232142, -20.0, -66.3811698725084, -26.093223335796576, -51.279446024175, -12.430413436407434, -30.916184515071098, -14.716751492448946, -23.435512825895316, -49.66408058938351, -26.211097857757196, -40.0, -10.0, -0.10763791983276705, -30.0, -18.445285542877475, -80.0, -70.0, -3.6203415293073484, -20.0, -73.50234209758199, -11.1360364727557, -85.58328061151627, -53.51564829858002, -13.657517928165515, -12.07923329954775, -40.0, -40.0, 0.0, -43.20619016846598, -6.00989848175288, -30.0, -26.04591799341898, -10.0, -30.0, -48.840343706042376, 0.0, -22.530489175868254, -23.304470077397294, -80.0, -30.0, -20.0, -20.0, -0.15062664612642385, -0.23846204208941235, -3.944632318226354, 0.0, -30.139719464421425, -31.332480679048825, -23.925771817884282, -33.65453473840359, 0.0, -50.0, -47.41929928856249, -33.51272443063805, -70.48081193300305, -51.77784999993828, -32.95606108278662, -0.3735639512397537, -5.307271025145858, -2.9027264890298476, -40.251899598803824, -17.610356652798153, -24.917309905292036, -34.73473642261585, -20.0, 0.0, -58.87818072421213, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6679672546414696, "mean_inference_ms": 1.148259919780507, "mean_action_processing_ms": 0.22928414953786216, "mean_env_wait_ms": 0.49561289908553896, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004342839687685424, "StateBufferConnector_ms": 0.003118907349019111, "ViewRequirementAgentConnector_ms": 0.08671902403046813}, "num_episodes": 158, "episode_return_max": 240.0, "episode_return_min": -49.66408058938351, "episode_return_mean": 40.63808877333945}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 576000, "num_agent_steps_trained": 576000, "num_env_steps_sampled": 144000, "num_env_steps_trained": 144000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 283.74652278838147, "num_env_steps_trained_throughput_per_sec": 283.74652278838147, "timesteps_total": 144000, "num_env_steps_sampled_lifetime": 144000, "num_agent_steps_sampled_lifetime": 576000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 576000, "timers": {"training_iteration_time_ms": 15313.841, "restore_workers_time_ms": 0.022, "training_step_time_ms": 15313.782, "sample_time_ms": 1257.572, "learn_time_ms": 14035.697, "learn_throughput": 284.988, "synch_weights_time_ms": 18.04}, "counters": {"num_env_steps_sampled": 144000, "num_env_steps_trained": 144000, "num_agent_steps_sampled": 576000, "num_agent_steps_trained": 576000}, "done": false, "training_iteration": 36, "trial_id": "b72b3_00000", "date": "2024-08-08_15-40-19", "timestamp": 1723146019, "time_this_iter_s": 14.104267835617065, "time_total_s": 546.9286594390869, "pid": 98177, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3174f5a60>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 546.9286594390869, "iterations_since_restore": 36, "perf": {"cpu_util_percent": 27.83809523809524, "ram_util_percent": 80.9714285714286}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.452550488213698, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.221972901622454, "policy_loss": -0.020846533420747923, "vf_loss": 6.240865980585416, "vf_explained_var": 0.013815493074556191, "kl": 0.009767266943787161, "entropy": 1.141216227163871, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 35040.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7263815386498228, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.193149416412868, "policy_loss": -0.015501323498617065, "vf_loss": 4.207308288584364, "vf_explained_var": 1.0265526196635362e-06, "kl": 0.0067122415540824204, "entropy": 0.8129232067588373, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 102930.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 148000, "num_env_steps_trained": 148000, "num_agent_steps_sampled": 592000, "num_agent_steps_trained": 592000}, "env_runners": {"episode_reward_max": 180.0, "episode_reward_min": -58.35349585325048, "episode_reward_mean": 33.41095473461725, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -90.0}, "policy_reward_max": {"adversary_policy": 90.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 19.691358024691358, "agent_policy": -25.663119339456824}, "custom_metrics": {}, "hist_stats": {"episode_reward": [100.0, 40.0, -3.613495948819173, -6.216244926667529, -23.442085134009186, 60.0, 80.0, 19.6070903096498, 53.49261618415969, 54.09783008281468, 0.0, -1.0277380774078393, -37.9265147878172, -5.015997353798495, -9.09927928917476, -7.880137674020775, 0.0, 59.56134920064835, 120.0, -1.967357714312934, -2.0361664389569984, 77.45350944604905, 80.0, 40.0, 58.62691073865227, 37.85492581458092, 39.34980114483302, 157.63388849995312, 0.0, -0.05288390902195794, 26.084996029921783, -32.14631706489292, -45.292571028485156, -5.748116037884148, 19.57678384939246, 60.0, -1.3910168633679154, 60.0, 99.39440002988552, -11.181648276444063, 13.64333497794797, -8.646948617280236, 0.0, -8.584802914547444, 76.62484204675533, 80.0, -0.08010515368353954, -47.625420468689214, 33.209253485894656, -33.31231162816917, 19.726456000441946, 60.0, 20.0, 95.06652581499213, 16.310591964835822, 58.60185989035433, 120.0, -3.5886339612434677, 54.71287547007909, 48.35331512448218, 28.508537963371605, 0.0, -7.3465465114645, -18.63922813995132, -0.2287371875872557, 42.21567940435619, 72.94770258338241, 0.0, 100.0, 47.00202116995419, 0.0, 84.66202952686533, 60.0, 59.971533718668496, 20.0, 60.0, -7.848497884871483, -0.4569634733590111, -58.35349585325048, -13.065979782277145, 100.0, -8.278350289647745, 0.0, 56.526139499715775, 37.512409168486684, -3.627897303967448, -12.957818061983666, 0.0, 0.0, 40.206020007426396, -0.02514994244995239, -42.39637815179156, -0.09094742233836106, -5.826166217862944, -5.25481621911724, 159.70036853920658, -12.412728362098163, 39.708759228470264, 42.91842916673636, 0.0, 16.425837190808938, -9.607944301311427, -3.9142943526940437, -12.020222933759566, 37.773481682112845, -23.711292934487393, -7.384819764084227, 59.843168985773325, 0.0, 60.0, 99.39457061149605, 0.0, 57.22288597095735, -0.7488093722215505, 74.540208960417, 20.0, 0.0, 0.0, -8.690853680893188, -0.07797072464729826, 39.92144865635357, 0.0, 140.0, 0.0, 98.43997466430149, 98.46958460377402, -9.108822510499865, 180.0, 80.0, 38.65264497377496, 40.0, 100.0, -10.907225950417576, 97.04902014535821, 37.62158002986557, -6.669827691446503, 80.0, -0.7202264330346964, 99.92605161152652, 140.0, 20.0, 98.47072253729232, 100.0, 34.514268041451, -5.432202029357822, 40.0, 58.984739081893196, -11.650056292940826, 38.64947370008063, 100.0, 70.92475168745958, 160.0, 114.9842069002548, 40.0, 0.0, 120.0, 38.94815267602043, -9.852872488860612, 77.58521117288441, 27.04202616390969, 39.637857960260035, 59.87294845037275], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 80.0, 80.0, 80.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 80.0, 80.0, 80.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 90.0, 90.0, 90.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 70.0, 70.0, 70.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 40.0, 40.0, 40.0, 80.0, 80.0, 80.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0], "policy_agent_policy_reward": [-50.0, -20.0, -3.613495948819173, -6.216244926667529, -23.442085134009186, -30.0, -40.0, -10.392909690350203, -36.50738381584031, -35.902169917185326, 0.0, -1.0277380774078393, -37.9265147878172, -5.015997353798495, -9.09927928917476, -37.88013767402077, 0.0, -30.438650799351652, -60.0, -1.967357714312934, -2.0361664389569984, -42.546490553950946, -40.0, -20.0, -31.37308926134773, -22.145074185419077, -20.650198855166977, -82.36611150004688, 0.0, -0.05288390902195794, -33.91500397007822, -32.14631706489292, -75.29257102848516, -5.748116037884148, -10.42321615060754, -30.0, -1.3910168633679154, -30.0, -50.60559997011449, -11.181648276444063, -16.356665022052027, -8.646948617280236, 0.0, -8.584802914547444, -43.37515795324466, -40.0, -0.08010515368353954, -47.625420468689214, -26.790746514105333, -33.31231162816917, -10.273543999558052, -30.0, -10.0, -54.93347418500787, -43.68940803516418, -61.39814010964567, -60.0, -3.5886339612434677, -35.28712452992091, -41.64668487551781, -31.491462036628395, 0.0, -7.3465465114645, -18.63922813995132, -0.2287371875872557, -47.78432059564382, -47.052297416617584, 0.0, -50.0, -42.99797883004581, 0.0, -65.33797047313466, -30.0, -30.028466281331504, -10.0, -30.0, -7.848497884871483, -0.4569634733590111, -58.35349585325048, -13.065979782277145, -50.0, -8.278350289647745, 0.0, -33.473860500284225, -22.48759083151331, -3.627897303967448, -12.957818061983666, 0.0, 0.0, -49.793979992573604, -0.02514994244995239, -42.39637815179156, -0.09094742233836106, -5.826166217862944, -5.25481621911724, -80.29963146079342, -12.412728362098163, -20.291240771529733, -47.08157083326364, 0.0, -43.57416280919105, -9.607944301311427, -3.9142943526940437, -12.020222933759566, -22.22651831788715, -23.711292934487393, -7.384819764084227, -30.15683101422668, 0.0, -30.0, -50.60542938850395, 0.0, -32.77711402904264, -0.7488093722215505, -45.45979103958299, -10.0, 0.0, 0.0, -8.690853680893188, -0.07797072464729826, -20.07855134364643, 0.0, -70.0, 0.0, -51.560025335698505, -51.53041539622597, -9.108822510499865, -90.0, -40.0, -21.34735502622504, -20.0, -50.0, -10.907225950417576, -52.950979854641794, -22.37841997013443, -6.669827691446503, -40.0, -0.7202264330346964, -50.07394838847348, -70.0, -10.0, -51.529277462707675, -50.0, -25.48573195854901, -5.432202029357822, -20.0, -31.0152609181068, -11.650056292940826, -21.350526299919373, -50.0, -49.07524831254042, -80.0, -65.0157930997452, -20.0, 0.0, -60.0, -21.051847323979572, -9.852872488860612, -42.414788827115586, -32.95797383609031, -20.362142039739965, -30.127051549627243]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6661737633106257, "mean_inference_ms": 1.1451843683148928, "mean_action_processing_ms": 0.22891121076789403, "mean_env_wait_ms": 0.4946218089208525, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003958116342991959, "StateBufferConnector_ms": 0.0030512427106315705, "ViewRequirementAgentConnector_ms": 0.08561949671050649}, "num_episodes": 162, "episode_return_max": 180.0, "episode_return_min": -58.35349585325048, "episode_return_mean": 33.41095473461725}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 592000, "num_agent_steps_trained": 592000, "num_env_steps_sampled": 148000, "num_env_steps_trained": 148000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 289.035890190999, "num_env_steps_trained_throughput_per_sec": 289.035890190999, "timesteps_total": 148000, "num_env_steps_sampled_lifetime": 148000, "num_agent_steps_sampled_lifetime": 592000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 592000, "timers": {"training_iteration_time_ms": 14384.378, "restore_workers_time_ms": 0.022, "training_step_time_ms": 14384.32, "sample_time_ms": 1200.63, "learn_time_ms": 13168.747, "learn_throughput": 303.749, "synch_weights_time_ms": 13.665}, "counters": {"num_env_steps_sampled": 148000, "num_env_steps_trained": 148000, "num_agent_steps_sampled": 592000, "num_agent_steps_trained": 592000}, "done": false, "training_iteration": 37, "trial_id": "b72b3_00000", "date": "2024-08-08_15-40-32", "timestamp": 1723146032, "time_this_iter_s": 13.846571922302246, "time_total_s": 560.7752313613892, "pid": 98177, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3174f5f70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 560.7752313613892, "iterations_since_restore": 37, "perf": {"cpu_util_percent": 28.1, "ram_util_percent": 80.875}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.4814219600210587, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.812775987386703, "policy_loss": -0.02135791244994228, "vf_loss": 5.832160052657128, "vf_explained_var": -0.004207964055240154, "kl": 0.009869126674706526, "entropy": 1.1241314003864924, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 36000.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.742733000895233, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.087471712481046, "policy_loss": -0.016346707400586788, "vf_loss": 4.102606013480653, "vf_explained_var": -2.8534138456304024e-08, "kl": 0.006062036015222933, "entropy": 0.7931899377428894, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 105750.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 152000, "num_env_steps_trained": 152000, "num_agent_steps_sampled": 608000, "num_agent_steps_trained": 608000}, "env_runners": {"episode_reward_max": 220.0, "episode_reward_min": -49.91274761948688, "episode_reward_mean": 34.43327337455831, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 157, "episodes_timesteps_total": 3925, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -110.0}, "policy_reward_max": {"adversary_policy": 110.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 19.29936305732484, "agent_policy": -23.46481579741621}, "custom_metrics": {}, "hist_stats": {"episode_reward": [20.0, 120.0, 49.932171058657374, 59.62875142857105, 57.621524668290114, 60.0, 60.0, 38.37960231652594, -3.1703352378146135, 40.0, 0.0, 80.0, -8.558889934427514, 12.978693475865558, 80.0, 0.0, 98.8004166947253, 40.0, -0.47289743874504575, 0.0, 100.0, 160.0, 0.0, 0.0, 0.0, 60.0, 59.948366562563905, 17.219475420672676, -0.05893368393621645, 0.0, 18.5785182111375, 60.0, -3.8596108917419096, 80.0, 120.0, 16.92099759090057, 80.0, 20.81248892427817, -5.747493461447435, 20.0, -0.49711836938245213, 60.0, 40.0, 80.0, 0.0, 0.0, 60.0, 0.0, 0.0, -11.720348369189855, 20.0, 60.0, 35.03071872813572, -5.734466197952555, -2.5455718737705277, 0.0, 96.94831539201587, -9.290351758560522, 160.0, 99.99701814204002, 0.0, -25.792719358889556, 39.948952521043594, 80.0, 100.0, 52.06666323689473, -1.016974821130484, 40.0, -2.227951645834163, 220.0, 57.921053148032705, 1.2575957297196272, 17.455806315093273, 0.0, -0.4438832701878126, 18.869196855110225, 140.0, 20.0, 92.58694473171103, 80.0, 33.48493906876362, 50.21700582233596, 0.0, -15.73746574924468, 0.0, 0.0, 60.0, 28.48087318706775, 73.47159874042194, 57.06491426285902, -3.512685927706897, 38.9858817355702, 0.0, 45.42745827424942, 116.88139689081896, 160.0, 55.37132581054419, 0.0, 140.0, 20.0, -0.6920446124638691, 0.0, 0.0, 20.0, 0.0, -17.817674546653812, -11.783092586147296, 38.410469364962886, -49.91274761948688, 60.0, 100.0, -6.164646579576759, 19.51084672936086, -1.0169566692717658, 12.28091717176855, 40.0, -37.15167535841031, 100.0, 40.0, 40.0, 60.0, 6.348001607508159, -5.6495745893884255, 54.176237257697345, 100.0, -5.06118446330112, -23.212409354750424, 40.0, 60.0, 59.81952853878552, -19.049824270005065, 20.0, 40.0, -10.72992868095293, 140.0, 0.0, 18.80303170544049, 38.275785696567496, -6.3390023395108805, 60.0, -20.26122521172658, 42.628133968859366, 0.0, -12.555783884305187, 60.0, 0.0, 0.0, -6.333408452588028, -37.373609877504094, -0.19706733141681587, 37.01195049532275, 0.0, 60.0, 154.22946996054762, -5.7599660589153, 40.0, 39.69040284055521], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [10.0, 10.0, 10.0, 60.0, 60.0, 60.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 80.0, 80.0, 80.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 80.0, 80.0, 80.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 110.0, 110.0, 110.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 70.0, 70.0, 70.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 60.0, 60.0, 60.0, 80.0, 80.0, 80.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 80.0, 80.0, 80.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0], "policy_agent_policy_reward": [-10.0, -60.0, -40.067828941342626, -30.371248571428946, -32.37847533170988, -30.0, -30.0, -21.620397683474067, -3.1703352378146135, -20.0, 0.0, -40.0, -8.558889934427514, -17.02130652413444, -40.0, 0.0, -51.199583305274686, -20.0, -0.47289743874504575, 0.0, -50.0, -80.0, 0.0, 0.0, 0.0, -30.0, -30.051633437436095, -12.780524579327324, -0.05893368393621645, 0.0, -11.421481788862499, -30.0, -3.8596108917419096, -40.0, -60.0, -43.07900240909944, -40.0, -39.18751107572183, -5.747493461447435, -10.0, -0.49711836938245213, -30.0, -20.0, -40.0, 0.0, 0.0, -30.0, 0.0, 0.0, -11.720348369189855, -10.0, -30.0, -24.969281271864283, -5.734466197952555, -2.5455718737705277, 0.0, -53.05168460798413, -9.290351758560522, -80.0, -50.00298185795997, 0.0, -25.792719358889556, -20.051047478956406, -40.0, -50.0, -37.93333676310527, -1.016974821130484, -20.0, -2.227951645834163, -110.0, -32.07894685196729, -28.74240427028037, -12.544193684906725, 0.0, -0.4438832701878126, -11.130803144889773, -70.0, -10.0, -57.41305526828896, -40.0, -26.515060931236377, -39.78299417766404, 0.0, -15.73746574924468, 0.0, 0.0, -30.0, -31.51912681293225, -46.52840125957805, -32.93508573714097, -33.5126859277069, -21.014118264429797, 0.0, -44.57254172575058, -63.11860310918104, -80.0, -34.62867418945581, 0.0, -70.0, -10.0, -0.6920446124638691, 0.0, 0.0, -10.0, 0.0, -17.817674546653812, -11.783092586147296, -21.589530635037114, -49.91274761948688, -30.0, -50.0, -6.164646579576759, -10.48915327063914, -1.0169566692717658, -17.719082828231446, -20.0, -37.15167535841031, -50.0, -20.0, -20.0, -30.0, -23.65199839249184, -5.6495745893884255, -35.823762742302655, -50.0, -35.06118446330112, -23.212409354750424, -20.0, -30.0, -30.18047146121448, -19.049824270005065, -10.0, -20.0, -10.72992868095293, -70.0, 0.0, -11.196968294559515, -21.724214303432504, -6.3390023395108805, -30.0, -20.26122521172658, -47.371866031140634, 0.0, -12.555783884305187, -30.0, 0.0, 0.0, -6.333408452588028, -37.373609877504094, -0.19706733141681587, -22.988049504677253, 0.0, -30.0, -85.77053003945238, -5.7599660589153, -20.0, -20.30959715944479]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6644846995794228, "mean_inference_ms": 1.1428816176013117, "mean_action_processing_ms": 0.22873531203705874, "mean_env_wait_ms": 0.4939612274695991, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0042823469562894975, "StateBufferConnector_ms": 0.0030875965288490246, "ViewRequirementAgentConnector_ms": 0.08725246806053599}, "num_episodes": 157, "episode_return_max": 220.0, "episode_return_min": -49.91274761948688, "episode_return_mean": 34.43327337455831}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 608000, "num_agent_steps_trained": 608000, "num_env_steps_sampled": 152000, "num_env_steps_trained": 152000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 281.9269412130661, "num_env_steps_trained_throughput_per_sec": 281.9269412130661, "timesteps_total": 152000, "num_env_steps_sampled_lifetime": 152000, "num_agent_steps_sampled_lifetime": 608000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 608000, "timers": {"training_iteration_time_ms": 14234.923, "restore_workers_time_ms": 0.019, "training_step_time_ms": 14234.877, "sample_time_ms": 1169.817, "learn_time_ms": 13050.54, "learn_throughput": 306.501, "synch_weights_time_ms": 13.385}, "counters": {"num_env_steps_sampled": 152000, "num_env_steps_trained": 152000, "num_agent_steps_sampled": 608000, "num_agent_steps_trained": 608000}, "done": false, "training_iteration": 38, "trial_id": "b72b3_00000", "date": "2024-08-08_15-40-47", "timestamp": 1723146047, "time_this_iter_s": 14.195323944091797, "time_total_s": 574.970555305481, "pid": 98177, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3174e51f0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 574.970555305481, "iterations_since_restore": 38, "perf": {"cpu_util_percent": 29.264999999999997, "ram_util_percent": 81.09}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.299064641445875, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.150902385512988, "policy_loss": -0.02016474461609808, "vf_loss": 6.168755071113507, "vf_explained_var": 0.016910097002983092, "kl": 0.011560309166882839, "entropy": 1.1074311908955374, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 36960.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7200806472424074, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.9300466629630284, "policy_loss": -0.01665068752579389, "vf_loss": 3.945349438308824, "vf_explained_var": 2.218582105974779e-06, "kl": 0.006739538193127437, "entropy": 0.7680710879834831, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 108570.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 156000, "num_env_steps_trained": 156000, "num_agent_steps_sampled": 624000, "num_agent_steps_trained": 624000}, "env_runners": {"episode_reward_max": 220.0, "episode_reward_min": -43.20181188634824, "episode_reward_mean": 33.849571629617685, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -110.0}, "policy_reward_max": {"adversary_policy": 110.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 20.0, "agent_policy": -26.15042837038231}, "custom_metrics": {}, "hist_stats": {"episode_reward": [57.23284830505612, 0.0, 119.33847256303397, 83.32115192567457, -42.90746841581866, -14.981363935600921, 113.7541206139322, -2.391334783541394, 133.38095330226682, 40.0, 11.173879721466735, 29.44652839746703, 79.10032735476317, 40.0, 0.0, 20.0, 0.0, 40.0, 44.71431125220698, 34.6582063442707, -16.142005403358212, 80.0, 100.0, 40.0, -1.5578308026367405, 140.0, 98.77071764989206, -2.4452873267013366, 70.24385267382416, 7.220852084324074, -26.338685084920815, 0.0, 60.0, 0.0, 136.31651899051522, 0.0, 120.0, 58.259390673376515, 136.85638823024695, -13.076443869562594, 100.0, -5.440877280651598, -0.9290785232698606, -13.778994781957968, 40.0, -7.704880551042043, -24.757416959951588, -11.911620401601265, 120.0, -43.20181188634824, 0.0, 60.0, -15.30156746364691, 0.0, 0.0, 58.94282322383134, 40.0, -9.39424449446511, 160.0, -2.839007618261528, 40.0, -17.41987015082438, 0.0, -3.2699151204372185, 220.0, 40.0, 39.82071147746369, 80.0, 85.53071112184155, -5.779447515117968, -12.05328021910498, -0.9213594527626567, -0.7295237699906265, 38.46091356172712, 0.0, -5.961662865006257, 0.0, 58.140220687369755, -20.426680881799, 80.0, 220.0, 36.66800543565402, 13.943354211855054, 14.132809561025335, 40.0, 0.0, 0.0, 59.76018120674081, 60.0, 80.0, 39.8299372853635, 19.509801571349445, 60.0, -20.003480939551533, 53.358775761290545, 80.0, -15.857536795048587, 0.0, 59.50883581802697, 140.0, -36.764770976591294, 99.45453981223757, 18.70264197036688, 0.0, 44.5005605546931, -5.409698071361549, 20.0, 98.62252481929623, -4.329668793371754, 0.0, 60.0, 60.0, 40.0, -31.43975276955502, 20.385578689720653, 0.0, -1.5927694881667156, -23.086208064884993, 12.731346093515686, -8.844062138177158, 20.0, -27.760966982821984, -7.047129670203938, 0.0, -20.600690019203117, 55.413836561863675, 80.0, 0.0, 60.0, 45.910398629222364, 60.0, 0.0, -1.1354424203133717, 180.0, 0.0, 120.0, -31.13762172258134, 60.0, 46.96267798409946, 6.678091099446894, 0.0, -18.712026215792722, 120.0, -21.24117084463263, 100.0, 100.0, -0.12392017229560848, 40.0, -20.365768937344946, 20.0, 20.0, 60.0, 0.0, 20.0, 0.0, 60.0, 140.0, 0.0, 40.0, 40.0, 0.0, -0.012848641975580222], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 30.0, 30.0, 30.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 80.0, 80.0, 80.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 110.0, 110.0, 110.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 110.0, 110.0, 110.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 90.0, 90.0, 90.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-62.76715169494388, 0.0, -60.66152743696604, -66.67884807432547, -42.90746841581866, -14.981363935600921, -66.24587938606778, -2.391334783541394, -76.61904669773318, -20.0, -18.82612027853326, -60.55347160253297, -40.89967264523683, -20.0, 0.0, -10.0, 0.0, -20.0, -45.28568874779302, -25.341793655729305, -16.142005403358212, -40.0, -50.0, -20.0, -1.5578308026367405, -70.0, -51.22928235010794, -2.4452873267013366, -79.75614732617584, -52.77914791567593, -26.338685084920815, 0.0, -30.0, 0.0, -73.68348100948478, 0.0, -60.0, -31.74060932662349, -73.14361176975305, -13.076443869562594, -50.0, -35.4408772806516, -0.9290785232698606, -13.778994781957968, -20.0, -7.704880551042043, -24.757416959951588, -11.911620401601265, -60.0, -43.20181188634824, 0.0, -30.0, -15.30156746364691, 0.0, 0.0, -31.057176776168653, -20.0, -9.39424449446511, -80.0, -2.839007618261528, -20.0, -17.41987015082438, 0.0, -3.2699151204372185, -110.0, -20.0, -20.17928852253631, -40.0, -64.46928887815847, -5.779447515117968, -12.05328021910498, -0.9213594527626567, -0.7295237699906265, -21.539086438272882, 0.0, -5.961662865006257, 0.0, -31.859779312630252, -20.426680881799, -40.0, -110.0, -23.33199456434598, -16.056645788144948, -15.867190438974664, -20.0, 0.0, 0.0, -30.239818793259197, -30.0, -40.0, -20.170062714636504, -10.490198428650555, -30.0, -20.003480939551533, -36.641224238709455, -40.0, -15.857536795048587, 0.0, -30.49116418197304, -70.0, -36.764770976591294, -50.54546018776243, -11.29735802963312, 0.0, -45.49943944530691, -5.409698071361549, -10.0, -51.37747518070376, -4.329668793371754, 0.0, -30.0, -30.0, -20.0, -31.43975276955502, -39.61442131027935, 0.0, -31.59276948816671, -23.086208064884993, -17.268653906484317, -8.844062138177158, -10.0, -27.760966982821984, -37.04712967020394, 0.0, -20.600690019203117, -34.586163438136325, -40.0, 0.0, -30.0, -44.08960137077764, -30.0, 0.0, -1.1354424203133717, -90.0, 0.0, -60.0, -31.13762172258134, -30.0, -43.03732201590055, -23.321908900553105, 0.0, -18.712026215792722, -60.0, -21.24117084463263, -50.0, -50.0, -0.12392017229560848, -20.0, -20.365768937344946, -10.0, -10.0, -30.0, 0.0, -10.0, 0.0, -30.0, -70.0, 0.0, -20.0, -20.0, 0.0, -0.012848641975580222]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6632997110812141, "mean_inference_ms": 1.141180033186055, "mean_action_processing_ms": 0.22860107853155381, "mean_env_wait_ms": 0.49319654754784803, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004477044682443878, "StateBufferConnector_ms": 0.0032981972635528186, "ViewRequirementAgentConnector_ms": 0.09246726094940562}, "num_episodes": 162, "episode_return_max": 220.0, "episode_return_min": -43.20181188634824, "episode_return_mean": 33.849571629617685}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 624000, "num_agent_steps_trained": 624000, "num_env_steps_sampled": 156000, "num_env_steps_trained": 156000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 284.780716324698, "num_env_steps_trained_throughput_per_sec": 284.780716324698, "timesteps_total": 156000, "num_env_steps_sampled_lifetime": 156000, "num_agent_steps_sampled_lifetime": 624000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 624000, "timers": {"training_iteration_time_ms": 14157.762, "restore_workers_time_ms": 0.019, "training_step_time_ms": 14157.716, "sample_time_ms": 1161.322, "learn_time_ms": 12982.283, "learn_throughput": 308.112, "synch_weights_time_ms": 13.178}, "counters": {"num_env_steps_sampled": 156000, "num_env_steps_trained": 156000, "num_agent_steps_sampled": 624000, "num_agent_steps_trained": 624000}, "done": false, "training_iteration": 39, "trial_id": "b72b3_00000", "date": "2024-08-08_15-41-01", "timestamp": 1723146061, "time_this_iter_s": 14.052846193313599, "time_total_s": 589.0234014987946, "pid": 98177, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b86fb8b0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 589.0234014987946, "iterations_since_restore": 39, "perf": {"cpu_util_percent": 29.855, "ram_util_percent": 81.23499999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.3753756184130905, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.149247134228547, "policy_loss": -0.017972929728178617, "vf_loss": 6.165245876212915, "vf_explained_var": -0.020786398090422153, "kl": 0.00987093627175426, "entropy": 1.0869534074018399, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 37920.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7320175057924385, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.513868907157411, "policy_loss": -0.01764954694130636, "vf_loss": 4.530160313464226, "vf_explained_var": 2.7230022646856645e-07, "kl": 0.006790694012455552, "entropy": 0.7583114005149679, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 111390.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 160000, "num_env_steps_trained": 160000, "num_agent_steps_sampled": 640000, "num_agent_steps_trained": 640000}, "env_runners": {"episode_reward_max": 220.0, "episode_reward_min": -68.76937157648709, "episode_reward_mean": 40.47510745364665, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -110.0}, "policy_reward_max": {"adversary_policy": 110.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 22.34567901234568, "agent_policy": -26.561929583390388}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 15.527638956166996, -7.923193743961423, 20.0, 0.0, 80.0, 220.0, 39.931348687148194, -12.856166245418935, 60.0, 40.0, 0.0, 139.81540844769953, 178.3388657319358, -20.423608545737864, 120.0, 114.84471172312193, -68.76937157648709, 98.58226913103115, -2.63459284141474, 40.0, 13.547321933667453, 60.0, 80.0, -0.2530726920984916, -1.0826847516370142, 120.0, 40.0, 100.0, 120.0, 0.0, 11.154560922946406, 18.57031650578366, 0.0, -12.518865648522496, 57.80831213584918, 80.0, -6.138669959805006, 20.0, 20.0, 0.0, 20.0, 120.0, 0.0, 0.0, -7.4435605600456425, 79.77192585669968, -0.5720073711326623, 39.80903182755563, 40.0, -1.4285681612074674, 0.0, 42.93640656138478, 0.0, 80.0, 59.03898828775737, 80.0, 0.0, 115.10272197402253, -3.2280287300663066, 57.73903942299048, 0.0, 60.0, 40.0, 79.92491207002502, 60.0, -14.533944017083138, 0.0, 40.0, 60.0, 110.65184472909341, -3.863128033207839, -8.854715059222167, 0.0, 80.0, 60.0, 60.0, 120.0, 35.57644092549528, 18.789861822342743, 99.82811449694604, -1.3366772131409665, -3.3135259057466357, 17.541217023118545, 160.0, -26.331452628863776, 40.0, 17.41446780281255, -0.8488457689292761, 56.00279823122371, 160.0, -26.481746773262927, 80.0, 60.0, 24.651949140731922, 13.333713345842044, 50.16017391151175, 0.0, -18.182592433401112, 59.81241663712693, 59.33026933111272, -2.9598428896383497, 47.93311289443478, 17.933147731601046, 53.21624745716515, 60.0, 40.0, 60.0, -17.17040690725967, 19.050305888094208, -1.564915713530849, -3.1374532227442558, -0.4328951969797423, -9.408653981861715, 120.0, 0.0, 80.0, -20.091438504063444, 0.0, 36.18024773807643, 60.0, 120.0, 68.1157115186018, 43.48223217637017, 80.0, 80.0, 40.0, 19.466464013855774, 0.0, -0.30154843624489724, 20.0, 40.0, -30.626650660156958, 115.91760469401254, -1.6062585793722117, 38.68480063638604, 60.0, 74.50316893840909, -22.84305988541386, 20.0, 19.657642851480507, -21.736970322927277, 20.0, 119.91623987434477, 0.0, 100.0, 137.8393098943511, 199.8126861131536, 60.0, 77.68160980720954, -31.911139644830374, -4.7809625513249845, 53.362688256198126, 40.0, 60.0, -1.3337041800875993, -9.43460303138319, 75.36943328800453, 60.0, 100.0, 38.238179157238356, 43.429049356838256], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 110.0, 110.0, 110.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 90.0, 90.0, 90.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 80.0, 80.0, 80.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 80.0, 80.0, 80.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 60.0, 60.0, 60.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 70.0, 70.0, 70.0, 100.0, 100.0, 100.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0], "policy_agent_policy_reward": [0.0, -14.472361043833, -7.923193743961423, -10.0, 0.0, -40.0, -110.0, -20.068651312851802, -12.856166245418935, -30.0, -20.0, 0.0, -70.18459155230047, -91.66113426806419, -20.423608545737864, -60.0, -65.15528827687807, -68.76937157648709, -51.41773086896884, -2.63459284141474, -20.0, -16.452678066332545, -30.0, -40.0, -0.2530726920984916, -1.0826847516370142, -60.0, -20.0, -50.0, -60.0, 0.0, -18.8454390770536, -11.429683494216341, 0.0, -12.518865648522496, -32.19168786415082, -40.0, -6.138669959805006, -10.0, -10.0, 0.0, -10.0, -60.0, 0.0, 0.0, -7.4435605600456425, -40.22807414330032, -0.5720073711326623, -20.19096817244437, -20.0, -1.4285681612074674, 0.0, -47.06359343861523, 0.0, -40.0, -30.961011712242634, -40.0, 0.0, -64.89727802597747, -3.2280287300663066, -32.26096057700952, 0.0, -30.0, -20.0, -40.07508792997499, -30.0, -14.533944017083138, 0.0, -20.0, -30.0, -69.34815527090659, -3.863128033207839, -8.854715059222167, 0.0, -40.0, -30.0, -30.0, -60.0, -24.423559074504727, -11.210138177657257, -50.17188550305395, -1.3366772131409665, -3.3135259057466357, -12.458782976881455, -80.0, -26.331452628863776, -20.0, -12.585532197187451, -0.8488457689292761, -33.997201768776286, -80.0, -26.481746773262927, -40.0, -30.0, -35.34805085926808, -16.666286654157958, -39.839826088488245, 0.0, -18.182592433401112, -30.18758336287307, -30.66973066888729, -2.9598428896383497, -42.066887105565215, -42.06685226839895, -36.78375254283485, -30.0, -20.0, -30.0, -17.17040690725967, -10.949694111905794, -1.564915713530849, -3.1374532227442558, -0.4328951969797423, -9.408653981861715, -60.0, 0.0, -40.0, -20.091438504063444, 0.0, -53.81975226192357, -30.0, -60.0, -51.8842884813982, -46.51776782362984, -40.0, -40.0, -20.0, -10.533535986144226, 0.0, -0.30154843624489724, -10.0, -20.0, -30.626650660156958, -64.08239530598746, -1.6062585793722117, -21.31519936361396, -30.0, -45.49683106159092, -22.84305988541386, -10.0, -10.342357148519493, -21.736970322927277, -10.0, -60.08376012565524, 0.0, -50.0, -72.16069010564891, -100.1873138868464, -30.0, -42.31839019279047, -31.911139644830374, -4.7809625513249845, -36.637311743801874, -20.0, -30.0, -1.3337041800875993, -9.43460303138319, -44.63056671199549, -30.0, -50.0, -21.76182084276164, -46.570950643161744]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6632966721440768, "mean_inference_ms": 1.1412943092420758, "mean_action_processing_ms": 0.22877757942548674, "mean_env_wait_ms": 0.4930772127296315, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005073753404028622, "StateBufferConnector_ms": 0.0033773021933473186, "ViewRequirementAgentConnector_ms": 0.09848482814835913}, "num_episodes": 162, "episode_return_max": 220.0, "episode_return_min": -68.76937157648709, "episode_return_mean": 40.47510745364665}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 640000, "num_agent_steps_trained": 640000, "num_env_steps_sampled": 160000, "num_env_steps_trained": 160000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 277.34059630022784, "num_env_steps_trained_throughput_per_sec": 277.34059630022784, "timesteps_total": 160000, "num_env_steps_sampled_lifetime": 160000, "num_agent_steps_sampled_lifetime": 640000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 640000, "timers": {"training_iteration_time_ms": 14066.805, "restore_workers_time_ms": 0.019, "training_step_time_ms": 14066.761, "sample_time_ms": 1157.966, "learn_time_ms": 12894.95, "learn_throughput": 310.199, "synch_weights_time_ms": 13.084}, "counters": {"num_env_steps_sampled": 160000, "num_env_steps_trained": 160000, "num_agent_steps_sampled": 640000, "num_agent_steps_trained": 640000}, "done": false, "training_iteration": 40, "trial_id": "b72b3_00000", "date": "2024-08-08_15-41-16", "timestamp": 1723146076, "time_this_iter_s": 14.430490016937256, "time_total_s": 603.4538915157318, "pid": 98177, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3174e5a60>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 603.4538915157318, "iterations_since_restore": 40, "perf": {"cpu_util_percent": 28.02380952380952, "ram_util_percent": 80.82380952380952}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.5319411953290305, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.462457206845284, "policy_loss": -0.01752791505762919, "vf_loss": 6.478129144012928, "vf_explained_var": 0.005826165713369846, "kl": 0.009280012484676137, "entropy": 1.095680152873198, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 38880.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7046675141187424, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.113942540114653, "policy_loss": -0.014464098923998152, "vf_loss": 4.1273640660529445, "vf_explained_var": -1.9754078371304993e-07, "kl": 0.005212846639620832, "entropy": 0.7210001973607016, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 114210.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 164000, "num_env_steps_trained": 164000, "num_agent_steps_sampled": 656000, "num_agent_steps_trained": 656000}, "env_runners": {"episode_reward_max": 216.32852104213782, "episode_reward_min": -45.07794435926953, "episode_reward_mean": 29.330409840715323, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 158, "episodes_timesteps_total": 3950, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -113.67147895786215}, "policy_reward_max": {"adversary_policy": 110.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 18.10126582278481, "agent_policy": -24.973387627639106}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.0, 85.21780805370858, 100.0, -27.496298266624702, 90.03551552419313, 40.0, -7.863121809703857, 64.56009432123287, -22.617980528454222, -0.5430052255980677, -0.8492699864619246, 72.52159653768118, 75.59622639753043, 40.0, 0.0, 30.582481023231626, 80.0, 95.82759900449787, -9.943524779898121, 40.0, -37.75479425498255, 20.0, -2.898147797098097, -10.395613888377367, -8.917781818253097, 0.0, -35.73550749496806, 174.7238449290647, -16.117801154492827, -9.426589449485004, -8.649469040091102, -11.918140918484708, 60.740736915324604, 22.566315378972746, -19.362346806920606, 75.52891810146636, 60.0, 40.0, -5.140596631241379, 54.02824472649785, 8.535794281745511, 18.765442841826527, 33.352086115637206, 40.0, -10.16294224374993, 1.4319544275919394, 37.974384612636854, 79.88131253513052, 120.0, 40.0, -8.0953452087712, 18.88518428349391, -45.07794435926953, 60.0, -3.065754839366299, 54.367471920224766, 17.028646010126543, -7.696016866744488, 0.0, -17.26349562361272, 38.91159712736081, -4.070322878445089, 54.18907474739356, 180.0, -27.366386819551337, 0.0, -6.699972526166001, 0.0, 39.29372565986803, -4.135171925076428, 40.0, 31.75847536262853, -25.25810082553477, 216.32852104213782, 18.774223427578555, 0.0, 0.0, 0.0, -0.9200685755892901, -1.3355101067176833, 20.48648242120285, 119.81459947348344, -1.6044119480836128, 9.164182879337876, 0.0, 20.269006190508723, 59.226809707631126, 19.974821622077744, 95.10383366238834, 57.35876031269507, -10.831979044086486, 20.0, 0.0, 159.33124390837494, 60.0, 156.05096569148665, 0.0, 58.3817372356385, 0.0, 79.70743626285939, 0.0, -5.021707224044949, 39.776792904131256, 38.01804444576653, 20.0, -3.6686561634012604, 60.0, 80.0, 60.0, -6.742548583092499, 80.0, -7.79890816388606, 40.0, 38.27454535159162, 76.7259665894334, -6.509100011404086, 80.0, -32.11599144003773, 0.0, -30.994006819713533, 31.405589514929687, 40.0, 58.50741489713896, 40.0, 15.598875210601708, 0.0, 72.57897907701528, -8.132746732714455, -13.682791223394466, 1.7808846562877, -5.610284665092712, 40.0, 38.34579847254907, 33.81676767132069, 40.0, -9.836035415444963, -6.670732749915603, 0.0, 35.47286248373078, 4.364067589262108, -4.529765515931927, 50.94191933676555, -3.096964820829334, 38.77307049727699, 0.0, 0.3431702894699562, 20.0, 180.0, 0.0, 80.0, 80.0, 19.58242556953094, -1.0093712060067417, 132.71605131155562, -1.9196279433956653, 25.38734654228888, 0.0, 52.06968006611359], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 90.0, 90.0, 90.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 90.0, 90.0, 90.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 110.0, 110.0, 110.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 80.0, 80.0, 80.0, 30.0, 30.0, 30.0, 80.0, 80.0, 80.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 90.0, 90.0, 90.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0], "policy_agent_policy_reward": [-20.0, -64.78219194629142, -50.0, -27.496298266624702, -59.96448447580686, -20.0, -7.863121809703857, -55.43990567876712, -22.617980528454222, -0.5430052255980677, -0.8492699864619246, -47.47840346231882, -44.40377360246959, -20.0, 0.0, -29.417518976768378, -40.0, -54.17240099550214, -9.943524779898121, -20.0, -37.75479425498255, -10.0, -2.898147797098097, -10.395613888377367, -8.917781818253097, 0.0, -35.73550749496806, -95.27615507093526, -16.117801154492827, -9.426589449485004, -8.649469040091102, -41.91814091848471, -59.259263084675396, -67.43368462102725, -19.362346806920606, -44.471081898533654, -30.0, -20.0, -5.140596631241379, -35.97175527350216, -21.464205718254494, -11.234557158173477, -26.647913884362808, -20.0, -10.16294224374993, -28.56804557240806, -22.02561538736315, -40.11868746486948, -60.0, -20.0, -8.0953452087712, -11.11481571650609, -45.07794435926953, -30.0, -3.065754839366299, -35.632528079775234, -12.971353989873457, -7.696016866744488, 0.0, -17.26349562361272, -21.088402872639193, -4.070322878445089, -35.81092525260644, -90.0, -27.366386819551337, 0.0, -6.699972526166001, 0.0, -20.706274340131966, -34.13517192507643, -20.0, -28.24152463737147, -25.25810082553477, -113.67147895786215, -11.225776572421447, 0.0, 0.0, 0.0, -0.9200685755892901, -1.3355101067176833, -39.51351757879715, -60.18540052651657, -1.6044119480836128, -20.835817120662117, 0.0, -39.73099380949128, -30.773190292368877, -10.025178377922256, -54.89616633761166, -32.64123968730494, -10.831979044086486, -10.0, 0.0, -80.66875609162506, -30.0, -83.94903430851336, 0.0, -31.618262764361496, 0.0, -40.29256373714062, 0.0, -5.021707224044949, -20.223207095868744, -21.98195555423347, -10.0, -33.66865616340126, -30.0, -40.0, -30.0, -6.742548583092499, -40.0, -7.79890816388606, -20.0, -21.72545464840838, -43.274033410566595, -6.509100011404086, -40.0, -32.11599144003773, 0.0, -30.994006819713533, -58.59441048507031, -20.0, -31.492585102861042, -20.0, -14.401124789398292, 0.0, -47.42102092298472, -8.132746732714455, -13.682791223394466, -28.2191153437123, -35.61028466509271, -20.0, -21.65420152745093, -26.183232328679303, -20.0, -9.836035415444963, -6.670732749915603, 0.0, -24.52713751626922, -25.635932410737894, -4.529765515931927, -39.05808066323445, -3.096964820829334, -21.22692950272301, 0.0, -29.656829710530044, -10.0, -90.0, 0.0, -40.0, -40.0, -40.41757443046906, -1.0093712060067417, -77.28394868844435, -1.9196279433956653, -34.61265345771112, 0.0, -37.930319933886395]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6617600860020676, "mean_inference_ms": 1.139332631538366, "mean_action_processing_ms": 0.22844843731899198, "mean_env_wait_ms": 0.49236403871609175, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00445246696472168, "StateBufferConnector_ms": 0.003248000446754166, "ViewRequirementAgentConnector_ms": 0.08609664591052864}, "num_episodes": 158, "episode_return_max": 216.32852104213782, "episode_return_min": -45.07794435926953, "episode_return_mean": 29.330409840715323}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 656000, "num_agent_steps_trained": 656000, "num_env_steps_sampled": 164000, "num_env_steps_trained": 164000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 282.06942376045095, "num_env_steps_trained_throughput_per_sec": 282.06942376045095, "timesteps_total": 164000, "num_env_steps_sampled_lifetime": 164000, "num_agent_steps_sampled_lifetime": 656000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 656000, "timers": {"training_iteration_time_ms": 14066.721, "restore_workers_time_ms": 0.018, "training_step_time_ms": 14066.676, "sample_time_ms": 1144.5, "learn_time_ms": 12908.191, "learn_throughput": 309.881, "synch_weights_time_ms": 13.268}, "counters": {"num_env_steps_sampled": 164000, "num_env_steps_trained": 164000, "num_agent_steps_sampled": 656000, "num_agent_steps_trained": 656000}, "done": false, "training_iteration": 41, "trial_id": "b72b3_00000", "date": "2024-08-08_15-41-30", "timestamp": 1723146090, "time_this_iter_s": 14.190605640411377, "time_total_s": 617.6444971561432, "pid": 98177, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3174e5ca0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 617.6444971561432, "iterations_since_restore": 41, "perf": {"cpu_util_percent": 28.159999999999997, "ram_util_percent": 81.35499999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.343760357176264, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.439397343248129, "policy_loss": -0.022182669982551792, "vf_loss": 6.459560660272837, "vf_explained_var": 0.012564429330329101, "kl": 0.010096609965765332, "entropy": 1.0771665006875992, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 39840.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7362170577577666, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.543634516465748, "policy_loss": -0.017520562006558577, "vf_loss": 4.559988179697212, "vf_explained_var": 2.195226385238323e-07, "kl": 0.005834517227885938, "entropy": 0.7211627074167238, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 117030.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 168000, "num_env_steps_trained": 168000, "num_agent_steps_sampled": 672000, "num_agent_steps_trained": 672000}, "env_runners": {"episode_reward_max": 140.0, "episode_reward_min": -52.30189803340629, "episode_reward_mean": 32.6847634799029, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 157, "episodes_timesteps_total": 3925, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -79.74257720449518}, "policy_reward_max": {"adversary_policy": 70.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 19.426751592356688, "agent_policy": -25.595491297167165}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, -9.942043630014084, 130.86721503018737, 19.90196233007203, 0.0, 60.0, 60.0, -5.750561763225772, 60.0, 0.0, 40.0, 60.0, 40.0, -6.902255087146577, 57.059960475165255, 100.0, 119.99132430776125, 33.0328801827449, -15.169649440718407, 12.409927825721935, 0.0, 40.0, -7.85944900022819, -0.0662628053811698, 0.0, -2.539407832468754, -16.420911697673468, -21.393208925134935, 60.0, -39.43497647182459, 60.0, 28.57014123790027, 59.9144993681482, 136.00601732259258, 60.0, -14.189131982666789, 0.0, -4.8168496038917255, 139.7484297159487, 1.0591274476951504, 59.18934114001234, 114.4947467945514, -5.8872665937298585, 11.75598113091435, 78.42350544627877, 0.0, 77.27960107629147, -3.4086461675702404, 40.0, 0.0, 32.478617673460775, -22.446041004398616, 80.0, -52.30189803340629, 80.0, -9.05104761163843, 60.0, 58.62646438695818, -18.24226641267004, -0.8756151104834098, 33.83652210819338, -32.414772830656, 79.75392396056114, 20.0, 20.0, 116.53960180087014, 60.0, 40.0, 39.25852949045329, -6.536112511196393, -0.10713828806460213, 55.47986021491549, 32.62058466155135, 19.44158201413596, 0.0, 58.685227838419166, 64.4728024253217, 52.6513834508112, 78.2212220982181, 18.861600644983543, 19.803075362588164, 56.26745459904671, 60.0, -4.8073879391201935, 57.417267218133134, 30.937823338673773, 60.0, 52.63130350487264, 54.36883714630755, 40.0, -5.0792168910074365, 60.0, 16.542799189531163, -0.6044864296028707, 80.0, 0.0, -0.24423857016784067, 120.0, 60.0, 140.0, 60.0, -13.241037792257078, 25.05111429619076, 45.26252149962733, -5.931208923532059, 0.0, 36.52651801889292, 80.0, 29.21261778401326, 118.19030912687047, 20.0, 2.815807758215783, -4.600005840284698, 58.10409346198431, -22.590802349058837, 20.0, 38.59778115633661, -4.341101959203762, 120.0, -14.223146107304435, 39.891807292560955, -8.179651966771399, 36.38812884816652, 60.0, 79.66247193692934, -5.2436350409095045, 86.54799806496634, 0.0, 0.0, -25.77409197477359, 40.0, 0.0, 40.0, 7.564656253683623, 20.0, 0.0, 37.20262938576373, 6.042448345750007, -10.9127000804365, 40.25742279550483, 40.0, 0.0, 40.0, 80.0, 0.0, 140.0, -14.37320469139144, -4.883330530194299, 80.0, 68.74039595006235, 68.94680797139856, -1.4701460645440623, 56.3070751176126, 100.0, -6.313778414567048, -9.837198310451566], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 50.0, 50.0, 50.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 70.0, 70.0, 70.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 60.0, 60.0, 60.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 30.0, 30.0, 30.0, 70.0, 70.0, 70.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 60.0, 60.0, 60.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [0.0, 0.0, -9.942043630014084, -79.13278496981263, -40.09803766992797, 0.0, -30.0, -30.0, -5.750561763225772, -30.0, 0.0, -20.0, -30.0, -20.0, -6.902255087146577, -62.94003952483474, -50.0, -60.00867569223875, -26.967119817255103, -15.169649440718407, -47.59007217427806, 0.0, -20.0, -7.85944900022819, -0.0662628053811698, 0.0, -2.539407832468754, -16.420911697673468, -21.393208925134935, -30.0, -39.43497647182459, -30.0, -31.429858762099734, -30.0855006318518, -73.99398267740739, -30.0, -14.189131982666789, 0.0, -4.8168496038917255, -70.2515702840513, -28.94087255230485, -30.81065885998767, -65.50525320544862, -5.8872665937298585, -18.244018869085654, -41.57649455372123, 0.0, -42.72039892370853, -3.4086461675702404, -20.0, 0.0, -27.521382326539225, -22.446041004398616, -40.0, -52.30189803340629, -40.0, -9.05104761163843, -30.0, -61.37353561304179, -18.24226641267004, -0.8756151104834098, -26.163477891806618, -32.414772830656, -40.246076039438854, -10.0, -10.0, -63.46039819912986, -30.0, -20.0, -50.7414705095467, -6.536112511196393, -0.10713828806460213, -34.52013978508451, -27.37941533844866, -10.558417985864036, 0.0, -31.314772161580834, -55.5271975746783, -37.3486165491888, -41.7787779017819, -11.138399355016459, -10.196924637411836, -33.73254540095329, -30.0, -34.80738793912019, -32.582732781866866, -29.062176661326227, -30.0, -37.36869649512736, -35.63116285369245, -20.0, -5.0792168910074365, -30.0, -13.457200810468837, -0.6044864296028707, -40.0, 0.0, -0.24423857016784067, -60.0, -30.0, -70.0, -30.0, -13.241037792257078, -34.948885703809246, -44.737478500372674, -5.931208923532059, 0.0, -23.47348198110707, -40.0, -30.78738221598674, -61.80969087312952, -10.0, -27.184192241784217, -4.600005840284698, -31.895906538015698, -22.590802349058837, -10.0, -21.402218843663388, -4.341101959203762, -60.0, -14.223146107304435, -20.108192707439045, -8.179651966771399, -23.611871151833476, -30.0, -40.33752806307067, -5.2436350409095045, -63.45200193503365, 0.0, 0.0, -25.77409197477359, -20.0, 0.0, -20.0, -52.43534374631638, -10.0, 0.0, -52.79737061423627, -23.957551654249993, -10.9127000804365, -79.74257720449518, -20.0, 0.0, -20.0, -40.0, 0.0, -70.0, -14.37320469139144, -4.883330530194299, -40.0, -51.259604049937636, -51.053192028601444, -1.4701460645440623, -33.6929248823874, -50.0, -6.313778414567048, -9.837198310451566]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6613603513344779, "mean_inference_ms": 1.138422286992225, "mean_action_processing_ms": 0.25768319478091234, "mean_env_wait_ms": 0.49181820486776034, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004282043238354336, "StateBufferConnector_ms": 0.0034358850709951608, "ViewRequirementAgentConnector_ms": 0.09297216014497599}, "num_episodes": 157, "episode_return_max": 140.0, "episode_return_min": -52.30189803340629, "episode_return_mean": 32.6847634799029}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 672000, "num_agent_steps_trained": 672000, "num_env_steps_sampled": 168000, "num_env_steps_trained": 168000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 269.76372076641945, "num_env_steps_trained_throughput_per_sec": 269.76372076641945, "timesteps_total": 168000, "num_env_steps_sampled_lifetime": 168000, "num_agent_steps_sampled_lifetime": 672000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 672000, "timers": {"training_iteration_time_ms": 14181.756, "restore_workers_time_ms": 0.015, "training_step_time_ms": 14181.718, "sample_time_ms": 1207.275, "learn_time_ms": 12960.641, "learn_throughput": 308.627, "synch_weights_time_ms": 13.083}, "counters": {"num_env_steps_sampled": 168000, "num_env_steps_trained": 168000, "num_agent_steps_sampled": 672000, "num_agent_steps_trained": 672000}, "done": false, "training_iteration": 42, "trial_id": "b72b3_00000", "date": "2024-08-08_15-41-45", "timestamp": 1723146105, "time_this_iter_s": 14.878906011581421, "time_total_s": 632.5234031677246, "pid": 98177, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3174f3160>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 632.5234031677246, "iterations_since_restore": 42, "perf": {"cpu_util_percent": 30.971428571428575, "ram_util_percent": 82.54285714285713}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.413385390428205, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.550929228961468, "policy_loss": -0.02378316432053301, "vf_loss": 6.572613521913687, "vf_explained_var": 0.016510334673027198, "kl": 0.010494352915390538, "entropy": 1.06747760673364, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 40800.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7065322872594739, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.121881733464856, "policy_loss": -0.01681033563164413, "vf_loss": 4.137457520911034, "vf_explained_var": -5.193635927024462e-07, "kl": 0.006172741658829246, "entropy": 0.7195779078607019, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 119850.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 172000, "num_env_steps_trained": 172000, "num_agent_steps_sampled": 688000, "num_agent_steps_trained": 688000}, "env_runners": {"episode_reward_max": 200.0, "episode_reward_min": -84.35126698775092, "episode_reward_mean": 32.23696863329443, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -100.0}, "policy_reward_max": {"adversary_policy": 100.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 20.0, "agent_policy": -27.763031366705576}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.0, 6.949410182067499, 29.05832320888254, 39.77300555767, 0.0, 53.67009399523065, 116.45530998403741, 67.60587211427094, 40.0, 73.69431527604769, 51.96067074218445, 60.0, 79.7828746774617, -1.2392341041800292, 37.51026127074152, 60.0, -19.981045520385067, 100.0, 40.0, -9.098808325023871, 0.0, 41.39889706631295, -40.14110695921613, 119.78540406366886, 0.0, 0.0, 60.0, -35.44261645494434, -18.115855654096258, 200.0, -13.278929981502458, -10.447867890316267, 60.0, 78.6629483358323, -2.3265615035102867, 16.397683563892322, 80.0, 75.85213547484298, 32.96934605293198, 40.0, 38.639405078405886, 12.864167084274712, 0.0, -0.03711925484943479, -21.598781541204254, -14.806318214336674, 39.9116926012376, 40.0, -1.4508348108254265, 120.0, 36.41179905075137, 32.77860661788105, 42.49850960382536, 0.0, -0.048929280226821525, -21.96490848532813, 140.0, -6.500715484484605, -1.824056653509849, -15.321123967692543, 20.0, 33.90405237119123, 45.15711647067074, 79.1576637114408, 17.146079258303054, 0.0, 58.83360264299913, 20.0, 40.0, 0.0, 15.466164114348786, 29.799171537913736, 20.0, 0.0, 32.49325603596232, -8.602544993374192, 120.0, -28.071390730153155, -14.541258931328379, 180.0, 79.24045703083482, 54.626005263666826, 40.0, 28.406703631877022, -32.45804922832508, 37.90047948211374, 80.0, 0.0, -24.08371633813624, -3.5050044757682253, 60.0, 15.914399008990838, 100.0, 80.0, 60.0, 6.303084576280426, -20.94136637162879, 0.0, -48.17838718944958, 0.0, 0.0, 80.0, 77.99182368154213, 80.0, 80.0, -59.4603064534921, -18.68269170504951, -16.802410640877913, 52.361285261975496, -21.53535449528402, -84.35126698775092, 20.0, 49.54351126803089, 9.898590280740416, -14.842365459752655, -16.252370156657765, 40.0, 0.0, 40.0, -36.75144067765092, 132.16506242275807, 25.01641502200161, 120.0, -4.50312630611546, 0.0, -0.76986980885979, -3.504709872586453, -37.56514354893409, -5.811977123389122, 40.0, 75.42686347341365, -0.11308552559183838, -13.841968270857727, -4.179513084663955, 40.0, 20.0, -10.08321629749076, -21.860790944881117, 140.0, 140.0, 20.0, 60.0, -6.452251513461431, 0.0, 140.0, 59.08355472713501, 20.0, 49.143228867114004, 48.511604616177046, 40.0, 100.0, 80.0, 60.0, 79.20647493384001, -17.767946924185516, 0.0, -23.52153224358484, 0.0, 140.0, 80.0, 57.7214076848381, 200.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 60.0, 60.0, 60.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 100.0, 100.0, 100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 90.0, 90.0, 90.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 20.0, 20.0, 20.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 70.0, 70.0, 70.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 100.0, 100.0, 100.0], "policy_agent_policy_reward": [-20.0, -23.0505898179325, -30.94167679111746, -50.226994442329996, 0.0, -36.329906004769356, -63.5446900159626, -52.39412788572905, -20.0, -46.30568472395231, -38.03932925781555, -30.0, -40.21712532253829, -1.2392341041800292, -22.48973872925848, -30.0, -79.98104552038507, -50.0, -20.0, -9.098808325023871, 0.0, -48.60110293368705, -70.14110695921613, -60.214595936331136, 0.0, 0.0, -30.0, -35.44261645494434, -18.115855654096258, -100.0, -13.278929981502458, -10.447867890316267, -30.0, -41.3370516641677, -2.3265615035102867, -13.602316436107676, -40.0, -44.14786452515702, -27.030653947068025, -20.0, -21.360594921594114, -17.135832915725288, 0.0, -0.03711925484943479, -21.598781541204254, -14.806318214336674, -20.088307398762403, -20.0, -1.4508348108254265, -60.0, -23.58820094924863, -27.221393382118954, -47.50149039617464, 0.0, -0.048929280226821525, -21.96490848532813, -70.0, -6.500715484484605, -1.824056653509849, -15.321123967692543, -10.0, -56.09594762880877, -44.84288352932925, -40.8423362885592, -12.85392074169695, 0.0, -31.166397357000868, -10.0, -20.0, 0.0, -14.53383588565121, -30.200828462086264, -10.0, 0.0, -27.506743964037685, -8.602544993374192, -60.0, -28.071390730153155, -14.541258931328379, -90.0, -40.75954296916519, -35.373994736333174, -20.0, -61.59329636812299, -32.45804922832508, -22.09952051788626, -40.0, 0.0, -24.08371633813624, -3.5050044757682253, -30.0, -14.08560099100916, -50.0, -40.0, -30.0, -23.696915423719574, -20.94136637162879, 0.0, -48.17838718944958, 0.0, 0.0, -40.0, -42.00817631845787, -40.0, -40.0, -59.4603064534921, -18.68269170504951, -16.802410640877913, -37.63871473802451, -21.53535449528402, -84.35126698775092, -10.0, -40.45648873196912, -20.101409719259582, -14.842365459752655, -16.252370156657765, -20.0, 0.0, -20.0, -36.75144067765092, -77.83493757724194, -34.98358497799839, -60.0, -4.50312630611546, 0.0, -0.76986980885979, -3.504709872586453, -37.56514354893409, -5.811977123389122, -20.0, -44.573136526586346, -0.11308552559183838, -13.841968270857727, -4.179513084663955, -20.0, -10.0, -10.08321629749076, -21.860790944881117, -70.0, -70.0, -10.0, -30.0, -6.452251513461431, 0.0, -70.0, -30.916445272864983, -10.0, -40.856771132885996, -41.488395383822954, -20.0, -50.0, -40.0, -30.0, -40.793525066160015, -17.767946924185516, 0.0, -23.52153224358484, 0.0, -70.0, -40.0, -32.2785923151619, -100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6610931705931453, "mean_inference_ms": 1.1370706161308013, "mean_action_processing_ms": 0.25670498253319646, "mean_env_wait_ms": 0.49127263935562615, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004654828413033191, "StateBufferConnector_ms": 0.003480028223108362, "ViewRequirementAgentConnector_ms": 0.09602793940791378}, "num_episodes": 162, "episode_return_max": 200.0, "episode_return_min": -84.35126698775092, "episode_return_mean": 32.23696863329443}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 688000, "num_agent_steps_trained": 688000, "num_env_steps_sampled": 172000, "num_env_steps_trained": 172000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 292.3711372113175, "num_env_steps_trained_throughput_per_sec": 292.3711372113175, "timesteps_total": 172000, "num_env_steps_sampled_lifetime": 172000, "num_agent_steps_sampled_lifetime": 688000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 688000, "timers": {"training_iteration_time_ms": 14146.972, "restore_workers_time_ms": 0.015, "training_step_time_ms": 14146.934, "sample_time_ms": 1206.465, "learn_time_ms": 12926.705, "learn_throughput": 309.437, "synch_weights_time_ms": 13.083}, "counters": {"num_env_steps_sampled": 172000, "num_env_steps_trained": 172000, "num_agent_steps_sampled": 688000, "num_agent_steps_trained": 688000}, "done": false, "training_iteration": 43, "trial_id": "b72b3_00000", "date": "2024-08-08_15-41-59", "timestamp": 1723146119, "time_this_iter_s": 13.687839984893799, "time_total_s": 646.2112431526184, "pid": 98177, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3174f33a0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 646.2112431526184, "iterations_since_restore": 43, "perf": {"cpu_util_percent": 30.035000000000007, "ram_util_percent": 82.97999999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.434501264244318, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.589863430460294, "policy_loss": -0.01730373193640844, "vf_loss": 6.605633217096329, "vf_explained_var": -0.020537431165575982, "kl": 0.007669580439043379, "entropy": 1.0472133095065752, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 41760.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7172205816663749, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.2415079980877275, "policy_loss": -0.017109308612338062, "vf_loss": 4.2573600030114465, "vf_explained_var": 2.03890157929549e-06, "kl": 0.006286453374580202, "entropy": 0.7005106047324255, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 122670.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 176000, "num_env_steps_trained": 176000, "num_agent_steps_sampled": 704000, "num_agent_steps_trained": 704000}, "env_runners": {"episode_reward_max": 240.0, "episode_reward_min": -50.18518168588222, "episode_reward_mean": 39.9968388846119, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -120.0}, "policy_reward_max": {"adversary_policy": 120.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 23.51851851851852, "agent_policy": -30.558716670943667}, "custom_metrics": {}, "hist_stats": {"episode_reward": [20.0, 100.0, 40.0, -0.03239828355058871, 0.0, -14.876460958443092, 57.892150634634476, -40.67028358768878, 38.772716134786805, -6.147539660008369, 0.0, -11.29328136688808, 52.483240720745655, 160.0, 100.0, 113.04817039193114, 33.47168533614651, -35.388288006741504, 17.08683586057513, 60.0, 6.917042650788023, -10.616057886574161, -2.4538519050850782, 40.0, -33.42463274672653, -0.3147222116304338, 100.0, 0.0, -3.161662301490169, -4.802188500611194, 99.18081653525141, 110.89109368198223, -4.132670826091755, 78.51758354822705, 40.0, 60.0, 51.12688480204973, 97.93285006995484, 16.14518039540981, 60.0, 138.60196284292454, 4.85878038943099, 100.0, -10.811950398293105, 64.34381498939895, 60.0, 75.01418085754736, 0.0, -1.5774652421315305, 80.0, 39.66783043745805, -22.266611541735813, 100.0, 40.0, 59.205293413319524, 38.10879083642257, 120.0, -23.846765604314893, 40.0, 47.91587184641908, 59.01524860576834, 80.0, 7.404604016423176, 27.157200252672567, 11.846181287800542, -8.992237362610364, -12.172808808054134, 240.0, 116.44527031713137, 40.0, 100.0, 119.40919626704408, -3.2113013678943467, 60.0, -34.80282668610757, 53.53907320044466, 99.90215635384224, 0.0, 80.0, 90.62621403927507, 0.0, 68.95862745546094, 75.75963186801168, 50.65690436660652, 40.0, 55.360875451732625, -2.7214899791490654, 100.0, 0.0, 39.77567122443626, 49.66708467697789, -26.372197662668455, 79.76431608118168, -4.2357929606274185, 100.0, 0.0, 56.9754897771864, 100.0, 59.98791202067048, 0.0, 60.0, 0.0, 13.126964030561513, 38.801212947709615, 14.126487522215157, -33.09544693746539, 96.49910116893795, 100.0, 80.0, 0.0, 87.47886438811565, 0.0, -8.055725428768431, -13.805952143342742, 0.0, 60.0, 32.47240613560771, 40.0, -36.51475121788613, 48.250830173584255, -0.8150431884407738, -50.18518168588222, 60.0, 180.0, 40.0, 100.0, 0.0, -1.1294053986909047, 41.863577075172515, 200.0, 57.80441512980027, 37.37603581595701, -0.6880981720514934, 21.940858867568597, -29.294293411008745, 60.0, -3.573464847806199, 109.03315686932581, 60.0, 77.37594501691932, 0.0, 19.55272721402184, -2.7813834598619036, -12.235251213822107, 0.0, 80.0, -4.780617232270799, 52.60707303729563, -7.382712407218108, 100.0, 148.3922475616049, 40.0, 27.63013431469152, -2.0224513276210416, 30.620700441784066, -11.93846345663578, 0.0, 30.254694650498095, -13.204551897886212, 40.0, 88.35173600125968, 32.32257658820025], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 80.0, 80.0, 80.0, 50.0, 50.0, 50.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 70.0, 70.0, 70.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 120.0, 120.0, 120.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 90.0, 90.0, 90.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 100.0, 100.0, 100.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 60.0, 60.0, 60.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 80.0, 80.0, 80.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0], "policy_agent_policy_reward": [-10.0, -50.0, -20.0, -0.03239828355058871, 0.0, -14.876460958443092, -32.10784936536553, -40.67028358768878, -21.22728386521319, -6.147539660008369, 0.0, -11.29328136688808, -37.516759279254345, -80.0, -50.0, -66.95182960806886, -26.528314663853493, -35.388288006741504, -12.913164139424872, -30.0, -53.08295734921198, -10.616057886574161, -32.453851905085074, -20.0, -33.42463274672653, -0.3147222116304338, -50.0, 0.0, -3.161662301490169, -4.802188500611194, -50.81918346474859, -69.10890631801777, -4.132670826091755, -41.48241645177295, -20.0, -30.0, -68.87311519795028, -52.067149930045176, -13.85481960459019, -30.0, -71.39803715707545, -25.141219610569014, -50.0, -10.811950398293105, -55.65618501060106, -30.0, -44.98581914245264, 0.0, -1.5774652421315305, -40.0, -20.332169562541953, -22.266611541735813, -50.0, -20.0, -30.79470658668048, -21.89120916357743, -60.0, -23.846765604314893, -20.0, -42.084128153580934, -30.98475139423166, -40.0, -22.59539598357682, -32.842799747327426, -48.15381871219944, -8.992237362610364, -12.172808808054134, -120.0, -63.554729682868626, -20.0, -50.0, -60.59080373295591, -3.2113013678943467, -30.0, -34.80282668610757, -36.46092679955534, -50.097843646157756, 0.0, -40.0, -59.37378596072494, 0.0, -51.041372544539065, -44.24036813198832, -39.34309563339348, -20.0, -34.639124548267375, -2.7214899791490654, -50.0, 0.0, -20.22432877556374, -40.332915323022114, -26.372197662668455, -40.23568391881833, -4.2357929606274185, -50.0, 0.0, -33.024510222813596, -50.0, -30.012087979329515, 0.0, -30.0, 0.0, -16.87303596943849, -21.198787052290385, -15.873512477784843, -33.09544693746539, -53.50089883106207, -50.0, -40.0, 0.0, -62.52113561188434, 0.0, -8.055725428768431, -13.805952143342742, 0.0, -30.0, -57.52759386439229, -20.0, -36.51475121788613, -41.749169826415745, -0.8150431884407738, -50.18518168588222, -30.0, -90.0, -20.0, -50.0, 0.0, -1.1294053986909047, -48.136422924827485, -100.0, -32.19558487019974, -22.623964184042986, -0.6880981720514934, -38.05914113243141, -29.294293411008745, -30.0, -63.57346484780622, -70.96684313067419, -30.0, -72.62405498308068, 0.0, -70.44727278597817, -2.7813834598619036, -12.235251213822107, 0.0, -40.0, -4.780617232270799, -37.39292696270437, -7.382712407218108, -50.0, -91.60775243839512, -20.0, -32.36986568530847, -2.0224513276210416, -29.379299558215934, -11.93846345663578, 0.0, -29.745305349501905, -13.204551897886212, -20.0, -61.64826399874032, -27.67742341179975]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6596183457097169, "mean_inference_ms": 1.1347019562260787, "mean_action_processing_ms": 0.2557858625246422, "mean_env_wait_ms": 0.49067439268045737, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004497575171199845, "StateBufferConnector_ms": 0.003505194628680194, "ViewRequirementAgentConnector_ms": 0.08822061397411206}, "num_episodes": 162, "episode_return_max": 240.0, "episode_return_min": -50.18518168588222, "episode_return_mean": 39.9968388846119}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 704000, "num_agent_steps_trained": 704000, "num_env_steps_sampled": 176000, "num_env_steps_trained": 176000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 293.01859055628455, "num_env_steps_trained_throughput_per_sec": 293.01859055628455, "timesteps_total": 176000, "num_env_steps_sampled_lifetime": 176000, "num_agent_steps_sampled_lifetime": 704000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 704000, "timers": {"training_iteration_time_ms": 14078.584, "restore_workers_time_ms": 0.015, "training_step_time_ms": 14078.547, "sample_time_ms": 1201.654, "learn_time_ms": 12863.095, "learn_throughput": 310.967, "synch_weights_time_ms": 13.16}, "counters": {"num_env_steps_sampled": 176000, "num_env_steps_trained": 176000, "num_agent_steps_sampled": 704000, "num_agent_steps_trained": 704000}, "done": false, "training_iteration": 44, "trial_id": "b72b3_00000", "date": "2024-08-08_15-42-13", "timestamp": 1723146133, "time_this_iter_s": 13.659240245819092, "time_total_s": 659.8704833984375, "pid": 98177, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3174e5ca0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 659.8704833984375, "iterations_since_restore": 44, "perf": {"cpu_util_percent": 26.93, "ram_util_percent": 82.935}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.683327620476484, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.361317867537339, "policy_loss": -0.017564014572417363, "vf_loss": 6.37728535135587, "vf_explained_var": 0.0029098986958463985, "kl": 0.007982707141247426, "entropy": 1.0279463302964966, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 42720.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7038139149229578, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.1867435790122824, "policy_loss": -0.01661577588182557, "vf_loss": 4.2020907210120075, "vf_explained_var": -7.042225371015833e-07, "kl": 0.006343161615014664, "entropy": 0.6922038431074602, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 125490.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 180000, "num_env_steps_trained": 180000, "num_agent_steps_sampled": 720000, "num_agent_steps_trained": 720000}, "env_runners": {"episode_reward_max": 200.0, "episode_reward_min": -43.19395118926132, "episode_reward_mean": 29.656007862332714, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -111.27795931758145}, "policy_reward_max": {"adversary_policy": 100.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 18.209876543209877, "agent_policy": -24.97362176729692}, "custom_metrics": {}, "hist_stats": {"episode_reward": [60.0, 57.321759172762114, -11.232918431051102, -0.12843979143164375, 39.21373163264374, -0.9963858053243324, 0.0, 11.623821118414893, 100.0, 60.0, 57.496227586574044, 0.0, 100.0, 40.0, -5.9408618245653715, 40.0, 17.91781370160715, 120.0, 0.0, 0.0, -0.22920082807908138, 50.88918430637685, -0.014806233911135891, 200.0, 59.83085122494924, 40.0, 128.72204068241857, 11.82684169027003, -10.634744095325985, 99.21620413556087, -26.41863172358471, 40.0, 120.0, 40.0, 60.0, -3.810071633277367, -40.61447952514892, 20.0, 140.0, -9.286992437876709, 40.0, 8.905700228659725, 40.0, -12.335511830386208, -40.11293726878718, 0.0, -14.07927582478824, 117.12768736165441, 99.42260792604989, 34.83810621873297, -6.747479670945366, 40.0, 79.38072397047623, 0.0, -23.781214803791016, 30.460844186183294, -2.3930911346920833, -9.681578117102205, 38.264569556514694, -1.3644215482169875, 18.670080737772825, 53.50057301868573, 0.0, 57.96584493508091, 40.0, 10.18007824618744, -23.203552448407525, 15.866625759561384, 53.05354334258535, -7.40791972762352, 20.0, 59.362642854627644, 7.318810720100762, -0.7927858818260525, -19.832126404463626, 39.05728043879839, -13.261353499041507, 38.235269796926985, 23.92203970179872, -2.965892996536602, 0.0, 59.26618904845978, 38.81713755777103, -22.28176987593071, 13.388231377961855, 46.81776898687267, 35.17072669795849, 35.05128890255853, -8.736526865918663, -4.251479481873609, 0.0, 26.758420186151863, -7.127431245738125, -17.002205555089922, 40.0, 80.0, 50.08089044707721, -0.14662138711941552, -0.67776049631176, 40.0, 0.0, 39.17925097940634, 14.95078265166506, 0.0, -1.2914883024770685, 60.0, -17.59458726269316, -11.067539851122964, -3.902760510685205, 0.0, 35.14423981097185, 40.0, 46.236764517076786, 33.746622100037236, 60.0, -19.08336629317176, 120.0, 60.0, 100.0, 79.22367604274993, 118.07147071356633, 105.33829919698262, 40.0, 20.0, 53.57755589761937, 118.68590023525755, 15.4907050772293, 0.0, 0.0, -20.003727574107113, 34.38503290903548, -0.3293833797147283, -10.893788468490033, 77.93063873890115, 51.85047947305429, 20.0, 0.0, 100.0, 40.0, -9.86794845006196, 56.79725208187822, 51.457359345353794, -13.334928646908343, -0.22352823638572383, -0.7951215024438085, -11.681544520729839, 14.327874614063582, -29.504710824592088, 90.62951521302485, -43.19395118926132, 120.0, -8.614940733516143, 43.25196650269696, -13.976081846465926, 40.0, 95.09597607452535, 100.77319832839278, 17.037735530035125, 58.156072679093555, 73.11399131470307, -6.964220391117816, -15.307157408095964], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 100.0, 100.0, 100.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 80.0, 80.0, 80.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 60.0, 60.0, 60.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 40.0, 40.0, 40.0, 60.0, 60.0, 60.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 60.0, 60.0, 60.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 60.0, 60.0, 60.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-30.0, -32.678240827237886, -11.232918431051102, -0.12843979143164375, -20.786268367356257, -0.9963858053243324, 0.0, -18.376178881585105, -50.0, -30.0, -32.503772413425956, 0.0, -50.0, -20.0, -5.9408618245653715, -20.0, -12.082186298392847, -60.0, 0.0, 0.0, -0.22920082807908138, -69.11081569362315, -30.014806233911138, -100.0, -30.169148775050758, -20.0, -111.27795931758145, -18.17315830972997, -10.634744095325985, -50.78379586443913, -26.41863172358471, -20.0, -60.0, -20.0, -30.0, -3.810071633277367, -40.61447952514892, -10.0, -70.0, -9.286992437876709, -20.0, -21.09429977134028, -20.0, -12.335511830386208, -40.11293726878718, 0.0, -44.07927582478824, -62.8723126383456, -50.5773920739501, -25.161893781267032, -6.747479670945366, -20.0, -40.61927602952377, 0.0, -23.781214803791016, -29.539155813816706, -2.3930911346920833, -9.681578117102205, -21.735430443485306, -1.3644215482169875, -11.329919262227175, -36.49942698131427, 0.0, -32.034155064919084, -20.0, -19.819921753812558, -23.203552448407525, -14.133374240438613, -36.94645665741466, -7.40791972762352, -10.0, -30.637357145372352, -22.681189279899236, -0.7927858818260525, -19.832126404463626, -20.94271956120161, -13.261353499041507, -21.764730203073015, -66.07796029820129, -2.965892996536602, 0.0, -30.733810951540217, -21.182862442228974, -22.28176987593071, -16.611768622038145, -43.18223101312733, -24.829273302041507, -24.948711097441464, -8.736526865918663, -4.251479481873609, 0.0, -33.24157981384813, -7.127431245738125, -17.002205555089922, -20.0, -40.0, -39.9191095529228, -0.14662138711941552, -0.67776049631176, -20.0, 0.0, -20.82074902059366, -15.04921734833494, 0.0, -1.2914883024770685, -30.0, -17.59458726269316, -11.067539851122964, -3.902760510685205, 0.0, -24.85576018902815, -20.0, -43.76323548292322, -26.253377899962768, -30.0, -19.08336629317176, -60.0, -30.0, -50.0, -40.77632395725009, -61.92852928643368, -74.66170080301737, -20.0, -10.0, -36.42244410238062, -61.314099764742444, -14.5092949227707, 0.0, 0.0, -20.003727574107113, -55.61496709096452, -0.3293833797147283, -10.893788468490033, -72.06936126109883, -38.14952052694571, -10.0, 0.0, -50.0, -20.0, -9.86794845006196, -63.2027479181218, -38.542640654646206, -13.334928646908343, -0.22352823638572383, -0.7951215024438085, -11.681544520729839, -15.672125385936418, -29.504710824592088, -59.370484786975155, -43.19395118926132, -60.0, -8.614940733516143, -46.74803349730304, -13.976081846465926, -20.0, -54.90402392547465, -79.22680167160723, -12.962264469964875, -31.843927320906445, -46.88600868529692, -6.964220391117816, -15.307157408095964]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6585274143494809, "mean_inference_ms": 1.1333399447618628, "mean_action_processing_ms": 0.2549347078608087, "mean_env_wait_ms": 0.49011272553934, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00419388582677017, "StateBufferConnector_ms": 0.003155440460016698, "ViewRequirementAgentConnector_ms": 0.09039677219626344}, "num_episodes": 162, "episode_return_max": 200.0, "episode_return_min": -43.19395118926132, "episode_return_mean": 29.656007862332714}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 720000, "num_agent_steps_trained": 720000, "num_env_steps_sampled": 180000, "num_env_steps_trained": 180000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 280.8945965010363, "num_env_steps_trained_throughput_per_sec": 280.8945965010363, "timesteps_total": 180000, "num_env_steps_sampled_lifetime": 180000, "num_agent_steps_sampled_lifetime": 720000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 720000, "timers": {"training_iteration_time_ms": 14117.411, "restore_workers_time_ms": 0.014, "training_step_time_ms": 14117.375, "sample_time_ms": 1205.639, "learn_time_ms": 12898.152, "learn_throughput": 310.122, "synch_weights_time_ms": 13.014}, "counters": {"num_env_steps_sampled": 180000, "num_env_steps_trained": 180000, "num_agent_steps_sampled": 720000, "num_agent_steps_trained": 720000}, "done": false, "training_iteration": 45, "trial_id": "b72b3_00000", "date": "2024-08-08_15-42-27", "timestamp": 1723146147, "time_this_iter_s": 14.24761700630188, "time_total_s": 674.1181004047394, "pid": 98177, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3174f3b80>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 674.1181004047394, "iterations_since_restore": 45, "perf": {"cpu_util_percent": 27.509999999999998, "ram_util_percent": 83.08}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.62079138122499, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.822725642720858, "policy_loss": -0.018945567899694045, "vf_loss": 6.8397390931844715, "vf_explained_var": -0.02064472232013941, "kl": 0.00966061295352058, "entropy": 1.0113450432817142, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 43680.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7073601132166301, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.2420064913465625, "policy_loss": -0.016308196272671303, "vf_loss": 4.2571476062984335, "vf_explained_var": -1.2879887371198506e-06, "kl": 0.005835409746448311, "entropy": 0.6868585719707164, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 128310.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 184000, "num_env_steps_trained": 184000, "num_agent_steps_sampled": 736000, "num_agent_steps_trained": 736000}, "env_runners": {"episode_reward_max": 156.11277725010586, "episode_reward_min": -44.72015945830857, "episode_reward_mean": 35.19324696639271, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 153, "episodes_timesteps_total": 3825, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -83.88722274989412}, "policy_reward_max": {"adversary_policy": 80.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 20.84967320261438, "agent_policy": -27.355772641450432}, "custom_metrics": {}, "hist_stats": {"episode_reward": [20.0, 0.0, 60.0, 120.0, 0.0, -38.874761205516364, 52.58041196115937, -17.723215164710595, 40.0, 80.0, 36.379536755548756, -0.26074590396213737, -4.8959464744256636, -12.039584633068944, 80.0, 62.54556063442002, 14.81287992047225, 20.0, 0.0, 101.11300588183826, -9.160893423638155, -5.662938634362408, 55.72155579040031, -6.829711617379746, 99.15827854697561, 40.0, 20.81751537192286, -17.976506620092525, 55.506158380240215, 60.0, -12.989224801645001, 74.17092337919402, -9.062595073969325, -1.4073919558658965, 100.0, -0.12077672982010124, -14.60108070058838, 55.793993542424865, 38.34315590519068, 60.0, -10.386926416089844, 20.0, 58.28407658171581, -0.5626429667620414, 120.0, -0.7686035424434834, -1.1449321450544325, 118.81883397321724, 10.027977070063281, 0.0, 40.0, -0.4186691109734464, 80.0, 20.0, 100.0, -5.575398815212809, 40.0, 100.0, 0.0, 117.37079569227977, 120.0, -4.759583021966137, 60.0, -18.12089599627416, 120.0, 58.12081927755049, 78.71343013661274, -17.933882863514235, 0.0, 59.68704262768142, -38.386790090459066, -11.367436457826269, 100.0, 40.0, 100.0, 59.93062674090558, 0.2752579044894754, 20.0, -19.07669436934611, 60.0, -26.675051658610702, 13.84322322933587, 80.0, -9.400009115638907, 80.0, 139.90564783010507, 140.0, 60.0, 116.19467295853093, -2.1494485509154524, 35.237368638799694, -18.24688976267981, 99.85843795217322, 44.30667400123179, -14.014781167679102, 156.11277725010586, 120.0, -10.907662753020697, 39.81048385690851, 35.92481411502621, 40.0, 132.19137515328507, -12.60371518195356, 14.90162290517654, 0.0, 60.0, 79.76501056970527, 60.0, 13.071997242316948, -25.874531266753834, -9.634735522633907, 60.0, 0.0, -11.437332508505271, 19.69804927467246, 20.0, -13.628936185679608, -5.547141485094306, -20.65007259779875, 60.0, 60.0, 10.100018612253622, 40.0, 15.350980972592172, 57.12645458896517, 139.55617086391143, -11.615252170119826, 0.0, 65.93137769701266, 59.68180560646096, -13.22336449195432, -3.3621962652037047, 43.45192310787649, -17.092776222329444, 20.0, 38.18493964978649, 40.0, 27.72689238660256, 20.0, 60.0, 45.274936949204196, 120.0, 48.097299766415105, -2.9622768378300512, -44.72015945830857, -0.8111792594605871, 98.3492119123606, 48.07865306062267, 80.0, 40.0, -21.95749824808173, 51.26133676588598, -35.97636768832372], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 70.0, 70.0, 70.0, 70.0, 70.0, 70.0, 30.0, 30.0, 30.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 80.0, 80.0, 80.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 60.0, 60.0, 60.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-10.0, 0.0, -30.0, -60.0, 0.0, -38.874761205516364, -37.41958803884064, -17.723215164710595, -20.0, -40.0, -23.620463244451244, -0.26074590396213737, -4.8959464744256636, -12.039584633068944, -40.0, -57.45443936557998, -15.18712007952775, -10.0, 0.0, -78.88699411816172, -9.160893423638155, -5.662938634362408, -34.27844420959969, -6.829711617379746, -50.84172145302439, -20.0, -39.18248462807714, -17.976506620092525, -34.493841619759785, -30.0, -12.989224801645001, -45.82907662080598, -9.062595073969325, -1.4073919558658965, -50.0, -0.12077672982010124, -14.60108070058838, -64.20600645757514, -21.656844094809323, -30.0, -10.386926416089844, -10.0, -31.715923418284206, -0.5626429667620414, -60.0, -0.7686035424434834, -1.1449321450544325, -61.181166026782755, -49.97202292993672, 0.0, -20.0, -0.4186691109734464, -40.0, -10.0, -50.0, -5.575398815212809, -20.0, -50.0, 0.0, -62.62920430772023, -60.0, -4.759583021966137, -30.0, -18.12089599627416, -60.0, -31.87918072244951, -41.28656986338726, -17.933882863514235, 0.0, -30.31295737231858, -38.386790090459066, -11.367436457826269, -50.0, -20.0, -50.0, -30.06937325909441, -29.724742095510514, -10.0, -19.07669436934611, -30.0, -26.675051658610702, -16.156776770664127, -40.0, -9.400009115638907, -40.0, -70.09435216989493, -70.0, -30.0, -63.80532704146908, -2.1494485509154524, -24.762631361200302, -18.24688976267981, -50.14156204782678, -45.6933259987682, -14.014781167679102, -83.88722274989412, -60.0, -10.907662753020697, -20.18951614309149, -24.075185884973795, -20.0, -77.80862484671493, -12.60371518195356, -15.098377094823462, 0.0, -30.0, -40.23498943029473, -30.0, -46.928002757683046, -25.874531266753834, -9.634735522633907, -30.0, 0.0, -11.437332508505271, -10.301950725327542, -10.0, -13.628936185679608, -5.547141485094306, -20.65007259779875, -30.0, -30.0, -49.89998138774637, -20.0, -14.649019027407828, -32.873545411034826, -70.44382913608857, -11.615252170119826, 0.0, -54.068622302987336, -30.318194393539038, -13.22336449195432, -3.3621962652037047, -46.54807689212351, -17.092776222329444, -10.0, -21.815060350213514, -20.0, -32.273107613397436, -10.0, -30.0, -44.725063050795804, -60.0, -41.902700233584895, -2.9622768378300512, -44.72015945830857, -0.8111792594605871, -51.6507880876394, -41.92134693937733, -40.0, -20.0, -21.95749824808173, -38.73866323411402, -35.97636768832372]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6583625782147657, "mean_inference_ms": 1.132872767677238, "mean_action_processing_ms": 0.25438618477691266, "mean_env_wait_ms": 0.4901190346564847, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004358618867163565, "StateBufferConnector_ms": 0.003294539607428258, "ViewRequirementAgentConnector_ms": 0.0953416419185065}, "num_episodes": 153, "episode_return_max": 156.11277725010586, "episode_return_min": -44.72015945830857, "episode_return_mean": 35.19324696639271}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 736000, "num_agent_steps_trained": 736000, "num_env_steps_sampled": 184000, "num_env_steps_trained": 184000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 284.2942729972076, "num_env_steps_trained_throughput_per_sec": 284.2942729972076, "timesteps_total": 184000, "num_env_steps_sampled_lifetime": 184000, "num_agent_steps_sampled_lifetime": 736000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 736000, "timers": {"training_iteration_time_ms": 14114.695, "restore_workers_time_ms": 0.014, "training_step_time_ms": 14114.659, "sample_time_ms": 1212.173, "learn_time_ms": 12888.964, "learn_throughput": 310.343, "synch_weights_time_ms": 13.058}, "counters": {"num_env_steps_sampled": 184000, "num_env_steps_trained": 184000, "num_agent_steps_sampled": 736000, "num_agent_steps_trained": 736000}, "done": false, "training_iteration": 46, "trial_id": "b72b3_00000", "date": "2024-08-08_15-42-41", "timestamp": 1723146161, "time_this_iter_s": 14.078540086746216, "time_total_s": 688.1966404914856, "pid": 98177, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3174f5b80>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 688.1966404914856, "iterations_since_restore": 46, "perf": {"cpu_util_percent": 27.205000000000002, "ram_util_percent": 83.04999999999998}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.0194188481817643, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.636138812204202, "policy_loss": -0.018403136992128567, "vf_loss": 6.653081148366133, "vf_explained_var": -0.014965591828028361, "kl": 0.007303975390970645, "entropy": 0.9883756538232168, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 44640.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6966535102919484, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.953777632307499, "policy_loss": -0.017496288964419182, "vf_loss": 3.9700520832487878, "vf_explained_var": -1.4051477959815492e-07, "kl": 0.006109180862669818, "entropy": 0.6611583783482828, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 131130.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 188000, "num_env_steps_trained": 188000, "num_agent_steps_sampled": 752000, "num_agent_steps_trained": 752000}, "env_runners": {"episode_reward_max": 200.0, "episode_reward_min": -40.50467095969594, "episode_reward_mean": 34.969951819572394, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -106.66080576934354}, "policy_reward_max": {"adversary_policy": 100.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 20.987654320987655, "agent_policy": -27.99301114339058}, "custom_metrics": {}, "hist_stats": {"episode_reward": [160.0, 72.57420347801042, -33.189683287771295, -10.870200019574046, 0.0, 59.0192003069878, 19.451360327366285, 32.68202071624329, 28.84854594967224, 77.52744869207444, 0.0, 40.0, 12.017545115321676, 180.0, 50.907551577182495, -0.655184473255479, 0.0, 80.0, -9.538244823353802, -11.659610919203224, 0.0, -0.9868364388802098, -7.779672575574798, -10.291495074810367, -24.457150146960085, 80.0, 75.3052363286419, 100.0, 108.81088946308273, 20.0, 112.58583094527185, 140.0, 100.0, 59.54194082756271, 12.067437772905322, 40.0, -16.175169065628246, 0.0, -21.437851152975004, 178.03152756218674, -11.094596112716083, 17.92944166216756, 80.0, 147.74522963864015, 0.0, 19.14874058467129, -18.602563529555134, 46.02194146732803, 38.516510647021235, 18.474933315330887, -1.402038764215774, 80.0, -7.309698677297959, 80.0, 53.9944145645215, 54.632334379493656, -8.823565043010426, -10.972310528806155, 19.993013217588683, -25.72280463232694, 100.0, 0.0, -14.288496566868316, 140.0, 19.709990278711185, -26.703370457225923, 0.0, 40.0, 76.500094915994, 12.020762292367746, 80.0, 60.0, -3.6270319109351634, 60.0, 0.0, 20.0, 53.216652737467584, 0.0, 80.0, 3.176061166158122, -13.89124142305219, 18.420206228809, 16.564395429172393, -6.012624729002242, 34.841057112005025, 50.076212295312864, -6.261676043923348, 40.0, 160.0, -5.2175087118981205, 58.99533545914215, 69.04420069490041, 86.97216999815254, -1.728540689856738, 0.0, -5.320056790367726, -2.4319586201414745, 40.0, 120.0, 17.86842674195877, 55.82867218862285, 91.30643626945471, 33.250577981779166, -7.534673087088345, 140.0, -21.518308972521254, 60.0, 100.0, -24.86996716321051, 49.33386635483249, 163.33919423065646, 0.0, 19.835302788921567, -22.30963055789589, -5.411497841393087, 160.0, -17.958529780221102, 40.0, 0.0, 60.0, -40.50467095969594, 92.73426697513764, 80.0, -12.271471580507686, 68.78127164463505, -10.662932690646501, -16.19092284262059, -11.57871032986242, 40.0, 0.0, 200.0, 100.0, 48.75707280911679, -14.00776482891374, -27.173200732559263, -29.410323229851652, -2.5366474684132867, 79.1929656429393, 60.0, 0.0, 60.0, -21.86712236242525, 20.0, -16.380891717498972, -3.3820308592429247, 140.0, -4.982057514112727, -34.20524401924609, -13.283607368842661, 0.0, -13.567976437549614, 80.0, 40.0, 0.0, 80.0, 37.54356290323863, 60.0, 20.0, 11.964225739614179, -1.181214475326049, 114.48479666140568, -5.212303280220745], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [80.0, 80.0, 80.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 90.0, 90.0, 90.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 50.0, 50.0, 50.0, 60.0, 60.0, 60.0, 10.0, 10.0, 10.0, 60.0, 60.0, 60.0, 70.0, 70.0, 70.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 90.0, 90.0, 90.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 80.0, 80.0, 80.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 80.0, 80.0, 80.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 60.0, 60.0, 60.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 90.0, 90.0, 90.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 80.0, 80.0, 80.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 100.0, 100.0, 100.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-80.0, -47.42579652198959, -33.189683287771295, -10.870200019574046, 0.0, -30.9807996930122, -10.548639672633715, -27.317979283756724, -61.151454050327764, -42.47255130792555, 0.0, -20.0, -17.982454884678326, -90.0, -69.09244842281751, -0.655184473255479, 0.0, -40.0, -9.538244823353802, -11.659610919203224, 0.0, -0.9868364388802098, -7.779672575574798, -10.291495074810367, -24.457150146960085, -40.0, -44.6947636713581, -50.0, -71.18911053691728, -10.0, -67.41416905472815, -70.0, -50.0, -30.458059172437295, -17.932562227094685, -20.0, -16.175169065628246, 0.0, -21.437851152975004, -91.96847243781326, -11.094596112716083, -12.070558337832443, -40.0, -92.25477036135982, 0.0, -10.85125941532871, -18.602563529555134, -43.97805853267197, -21.48348935297876, -11.525066684669113, -1.402038764215774, -40.0, -7.309698677297959, -40.0, -36.00558543547849, -35.36766562050635, -8.823565043010426, -10.972310528806155, -10.006986782411317, -25.72280463232694, -50.0, 0.0, -14.288496566868316, -70.0, -10.290009721288815, -26.703370457225923, 0.0, -20.0, -43.499905084006, -17.979237707632254, -40.0, -30.0, -3.6270319109351634, -30.0, 0.0, -10.0, -36.78334726253241, 0.0, -40.0, -26.82393883384188, -13.89124142305219, -11.579793771191001, -13.435604570827605, -6.012624729002242, -55.158942887994975, -39.923787704687136, -6.261676043923348, -20.0, -80.0, -5.2175087118981205, -31.004664540857856, -50.955799305099596, -93.02783000184746, -1.728540689856738, 0.0, -5.320056790367726, -2.4319586201414745, -20.0, -60.0, -12.131573258041229, -34.171327811377154, -58.69356373054529, -26.749422018220827, -7.534673087088345, -70.0, -21.518308972521254, -30.0, -50.0, -24.86996716321051, -40.66613364516751, -106.66080576934354, 0.0, -10.164697211078433, -22.30963055789589, -5.411497841393087, -80.0, -17.958529780221102, -20.0, 0.0, -30.0, -40.50467095969594, -87.26573302486236, -40.0, -12.271471580507686, -51.21872835536495, -10.662932690646501, -16.19092284262059, -11.57871032986242, -20.0, 0.0, -100.0, -50.0, -41.24292719088321, -14.00776482891374, -27.173200732559263, -29.410323229851652, -2.5366474684132867, -40.8070343570607, -30.0, 0.0, -30.0, -21.86712236242525, -10.0, -46.380891717498976, -3.3820308592429247, -70.0, -4.982057514112727, -34.20524401924609, -13.283607368842661, 0.0, -13.567976437549614, -40.0, -20.0, 0.0, -40.0, -22.456437096761363, -30.0, -10.0, -48.03577426038582, -1.181214475326049, -65.51520333859432, -5.212303280220745]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.657950312743798, "mean_inference_ms": 1.1322633719035466, "mean_action_processing_ms": 0.2537649251011523, "mean_env_wait_ms": 0.4900035641225048, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004506479074925553, "StateBufferConnector_ms": 0.0032425662617624543, "ViewRequirementAgentConnector_ms": 0.09601462034531581}, "num_episodes": 162, "episode_return_max": 200.0, "episode_return_min": -40.50467095969594, "episode_return_mean": 34.969951819572394}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 752000, "num_agent_steps_trained": 752000, "num_env_steps_sampled": 188000, "num_env_steps_trained": 188000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 285.09961033263, "num_env_steps_trained_throughput_per_sec": 285.09961033263, "timesteps_total": 188000, "num_env_steps_sampled_lifetime": 188000, "num_agent_steps_sampled_lifetime": 752000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 752000, "timers": {"training_iteration_time_ms": 14133.802, "restore_workers_time_ms": 0.014, "training_step_time_ms": 14133.765, "sample_time_ms": 1216.961, "learn_time_ms": 12902.934, "learn_throughput": 310.007, "synch_weights_time_ms": 13.448}, "counters": {"num_env_steps_sampled": 188000, "num_env_steps_trained": 188000, "num_agent_steps_sampled": 752000, "num_agent_steps_trained": 752000}, "done": false, "training_iteration": 47, "trial_id": "b72b3_00000", "date": "2024-08-08_15-42-55", "timestamp": 1723146175, "time_this_iter_s": 14.065126180648804, "time_total_s": 702.2617666721344, "pid": 98177, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3281aa280>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 702.2617666721344, "iterations_since_restore": 47, "perf": {"cpu_util_percent": 28.999999999999993, "ram_util_percent": 83.16190476190475}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.9193064038952192, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.262241917351882, "policy_loss": -0.023926060683152173, "vf_loss": 6.28391201471289, "vf_explained_var": -0.004410034107665221, "kl": 0.011279936617695585, "entropy": 0.9810638907675941, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 45600.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6801777273416519, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.9640145718628634, "policy_loss": -0.017524495983747303, "vf_loss": 3.980330230242817, "vf_explained_var": -6.045644164930844e-07, "kl": 0.0060441731372430805, "entropy": 0.6492610856573633, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 133950.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 192000, "num_env_steps_trained": 192000, "num_agent_steps_sampled": 768000, "num_agent_steps_trained": 768000}, "env_runners": {"episode_reward_max": 196.17395940400576, "episode_reward_min": -30.386096793499647, "episode_reward_mean": 32.44227974752674, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -103.82604059599421}, "policy_reward_max": {"adversary_policy": 100.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 19.567901234567902, "agent_policy": -26.261423956176966}, "custom_metrics": {}, "hist_stats": {"episode_reward": [79.76462887668292, 58.617344772313594, 0.0, 14.186945216249626, 154.0986340316961, 37.1324142694212, 0.0, 60.0, -5.987912687044373, 36.162171676298385, -4.542118647058266, 160.0, -0.21127711890581158, -20.91902722973066, -12.418044792311465, 116.66843051430487, 20.0, -16.326817472309877, -12.001768887152853, 119.24868467392605, 17.8961497470392, 15.073254222941435, -12.258966857533862, 155.3037521190854, -21.635267536140606, 38.40524794547018, 38.33733798221831, 132.76957071984012, 60.0, -7.814702727221187, 60.0, 39.74080557559809, 19.915701260761324, 40.0, 19.329217748365387, 60.0, 33.34076015098054, -0.7390839748170541, 0.0, 37.621910768913494, -0.6646855182386946, 100.0, 39.41278045998794, 20.0, 58.28532735260664, 43.7570152579836, -2.903238739726371, 20.0, -3.417232009685737, 63.79027696032247, 0.0, -10.897254748021846, 60.0, 40.0, 41.49948933607074, -16.19035093487661, 39.75357151747205, 0.0, 19.91221141363547, 2.653627523824279, -4.491534661470807, 32.53182091596871, 40.0, 20.0, 55.29600834007073, 120.0, -24.267819834146472, -11.050449051825247, 30.08416057163818, 60.0, 15.545138126547245, 0.0, -19.90840607948677, 18.98280711676846, 58.616211339592915, 15.682864466156456, 37.94955699212952, 111.35821516937719, 0.0, -4.082941082348234, 80.0, 20.0, 24.34448840021678, 87.8509940314473, 76.69308062604787, 196.17395940400576, 139.65071115636414, -1.6459703494505051, 39.53553134540037, 100.0, 37.47482006549105, 80.0, -9.386471420164447, 114.00474770643362, 0.0, -2.4124711274471666, 0.0, 32.574857227156954, 80.0, 50.973816717861816, 33.790506507431836, 14.746088231812088, -9.183525288506134, 58.69074165153883, -10.115304439441678, 115.05306632186321, -13.067717825406428, 45.11477705146915, -17.997765477787144, 53.39246175785046, 13.235529637469636, 0.0, 30.189725065186778, 40.0, 27.75647732190905, 0.0, 60.0, -1.2412617724685249, 60.0, -15.597118001014797, 0.0, 0.0, 80.0, -9.484889282646837, -1.0571150749296565, 18.91268150518628, 53.06739139537106, -9.88433486500503, 0.0, 33.550538995615014, 120.0, -30.386096793499647, -1.6187102220120408, -18.13674581244848, 53.30332073993089, -20.378690156538784, 80.0, 20.279203726976334, 70.73970871052153, -9.98288330515884, 15.855068113301906, 40.6116861066903, 33.10168567528651, 38.90175280878889, 33.71636436358488, 27.05734796950562, 36.967647391010004, 20.0, 60.0, 0.0, 0.0, 75.44289691198361, -10.322551218303717, 12.787148613660486, 80.0, 60.0, 0.0, -28.06414502456518, -0.15335037922960204, 0.0, -15.769530861219783, 140.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 80.0, 80.0, 80.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 80.0, 80.0, 80.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 80.0, 80.0, 80.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 70.0, 70.0, 70.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 40.0, 40.0, 40.0, 100.0, 100.0, 100.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0], "policy_agent_policy_reward": [-40.23537112331708, -61.38265522768639, 0.0, -15.813054783750372, -85.9013659683039, -22.8675857305788, 0.0, -30.0, -5.987912687044373, -23.83782832370162, -4.542118647058266, -80.0, -0.21127711890581158, -20.91902722973066, -12.418044792311465, -63.33156948569513, -10.0, -16.326817472309877, -12.001768887152853, -60.75131532607396, -12.103850252960799, -74.92674577705858, -12.258966857533862, -84.6962478809146, -21.635267536140606, -21.59475205452982, -21.662662017781688, -77.23042928015988, -30.0, -7.814702727221187, -30.0, -20.259194424401915, -10.084298739238678, -20.0, -10.670782251634614, -30.0, -26.659239849019457, -0.7390839748170541, 0.0, -22.378089231086506, -0.6646855182386946, -50.0, -20.587219540012057, -10.0, -31.714672647393353, -46.2429847420164, -2.903238739726371, -10.0, -3.417232009685737, -56.20972303967754, 0.0, -10.897254748021846, -30.0, -20.0, -48.50051066392926, -16.19035093487661, -20.246428482527953, 0.0, -10.087788586364528, -27.346372476175723, -4.491534661470807, -27.468179084031295, -20.0, -10.0, -34.70399165992927, -60.0, -24.267819834146472, -11.050449051825247, -29.91583942836182, -30.0, -14.454861873452755, 0.0, -19.90840607948677, -11.01719288323154, -31.38378866040708, -14.317135533843544, -22.050443007870477, -68.64178483062281, 0.0, -4.082941082348234, -40.0, -10.0, -35.655511599783225, -62.1490059685527, -43.306919373952134, -103.82604059599421, -70.34928884363586, -1.6459703494505051, -20.464468654599628, -50.0, -22.525179934508948, -40.0, -39.38647142016444, -95.9952522935664, 0.0, -2.4124711274471666, 0.0, -57.425142772843046, -40.0, -39.026183282138184, -56.20949349256818, -45.25391176818792, -9.183525288506134, -31.309258348461174, -10.115304439441678, -64.94693367813679, -13.067717825406428, -44.88522294853085, -17.997765477787144, -36.60753824214954, -16.764470362530368, 0.0, -29.810274934813222, -20.0, -32.24352267809095, 0.0, -30.0, -1.2412617724685249, -30.0, -15.597118001014797, 0.0, 0.0, -40.0, -9.484889282646837, -1.0571150749296565, -11.087318494813719, -36.93260860462894, -9.88433486500503, 0.0, -26.449461004384986, -60.0, -30.386096793499647, -1.6187102220120408, -18.13674581244848, -36.69667926006912, -20.378690156538784, -40.0, -39.720796273023666, -49.26029128947848, -9.98288330515884, -14.144931886698096, -49.3883138933097, -56.89831432471349, -21.098247191211108, -26.283635636415124, -32.94265203049438, -53.032352608989996, -10.0, -30.0, 0.0, 0.0, -44.55710308801638, -10.322551218303717, -47.21285138633952, -40.0, -30.0, 0.0, -28.06414502456518, -0.15335037922960204, 0.0, -15.769530861219783, -70.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.657344012758901, "mean_inference_ms": 1.1310007810047809, "mean_action_processing_ms": 0.25295008113970024, "mean_env_wait_ms": 0.4895405000352923, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007888417185088734, "StateBufferConnector_ms": 0.003422483985806689, "ViewRequirementAgentConnector_ms": 0.10212255112918807}, "num_episodes": 162, "episode_return_max": 196.17395940400576, "episode_return_min": -30.386096793499647, "episode_return_mean": 32.44227974752674}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 768000, "num_agent_steps_trained": 768000, "num_env_steps_sampled": 192000, "num_env_steps_trained": 192000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 285.8251641718774, "num_env_steps_trained_throughput_per_sec": 285.8251641718774, "timesteps_total": 192000, "num_env_steps_sampled_lifetime": 192000, "num_agent_steps_sampled_lifetime": 768000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 768000, "timers": {"training_iteration_time_ms": 14114.452, "restore_workers_time_ms": 0.014, "training_step_time_ms": 14114.414, "sample_time_ms": 1224.027, "learn_time_ms": 12876.308, "learn_throughput": 310.648, "synch_weights_time_ms": 13.601}, "counters": {"num_env_steps_sampled": 192000, "num_env_steps_trained": 192000, "num_agent_steps_sampled": 768000, "num_agent_steps_trained": 768000}, "done": false, "training_iteration": 48, "trial_id": "b72b3_00000", "date": "2024-08-08_15-43-10", "timestamp": 1723146190, "time_this_iter_s": 14.00285816192627, "time_total_s": 716.2646248340607, "pid": 98177, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3281aa4c0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 716.2646248340607, "iterations_since_restore": 48, "perf": {"cpu_util_percent": 28.51, "ram_util_percent": 83.145}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.0460624682406583, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.498359097043673, "policy_loss": -0.021604323852807285, "vf_loss": 6.518182739118735, "vf_explained_var": -0.013044282111028831, "kl": 0.008903303649632422, "entropy": 0.9605881343285243, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 46560.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6767990712578416, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.570489520384065, "policy_loss": -0.017967150267296148, "vf_loss": 3.5872026447708727, "vf_explained_var": 5.187083643378941e-07, "kl": 0.00627013757367057, "entropy": 0.6242717611028793, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 136770.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 196000, "num_env_steps_trained": 196000, "num_agent_steps_sampled": 784000, "num_agent_steps_trained": 784000}, "env_runners": {"episode_reward_max": 153.65819306218262, "episode_reward_min": -41.35150440126467, "episode_reward_mean": 28.044177781232772, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -127.88010254072616}, "policy_reward_max": {"adversary_policy": 80.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 17.77777777777778, "agent_policy": -25.28915555210056}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-24.51258417572203, 59.15034682318827, -8.12594361392136, -18.02188790054851, 40.0, 36.64053643193895, -36.69343306330785, 60.0, 40.0, -12.897986738221148, 60.0, 0.0, -12.298101196978859, 129.31438444091276, -12.55705468662227, 39.93058351633985, -12.846112758271035, 0.0, 60.0, -25.835593801241217, 58.73933873042044, 20.0, 140.0, 0.0, 33.28597841164239, -15.4596345797146, -33.286081331246535, 0.0, -18.55954473119562, 80.0, 76.39003735625563, -24.132881982929312, 0.0, 40.0, -2.649276140938884, 153.65819306218262, -17.427103752638157, 80.0, 120.0, 33.462550992561006, -0.10074140340251891, 60.0, -2.0191858108640126, 96.55316175846728, 0.0, 14.413623465227001, 20.0, 39.651551930684846, 59.528242485940495, 0.0, 59.82942964815231, 11.970426632630302, 20.0, 72.74847411893091, 100.0, 10.70857887370443, 24.59648953481107, -41.35150440126467, -0.1108424342379799, 21.06388190310206, 46.11629430281205, 120.0, -28.098291525871595, -11.142870499223115, 0.0, 20.0, 58.55060745918226, -12.47357260474155, 20.0, 120.0, -4.3012626038861805, 92.31026441518814, 75.04577508988177, 0.0, 60.0, 133.28649818950868, -9.231959598294065, 60.0, 87.0026712306668, 0.0, -3.049083681746362, 38.551336009651926, 3.444805775065237, -6.214940198313547, -5.703019898857729, 98.90572477153623, 0.0, -19.542020534889268, -23.316042782312017, -8.246310828616407, 55.00714773796847, -0.6489146329423601, 19.04545813452177, -8.731991002443078, 56.755564010209014, -17.792473301894592, -14.399909769794814, -9.454554412748626, -0.2928598845908381, 34.23888564352659, -6.440695414940688, 110.16812256458367, -0.2979009687699896, 100.0, -0.5162826001947762, 0.0, 58.656567099581366, 0.0, -23.967853271019113, 40.0, 82.11989745927383, 117.24306822335255, -34.58672415020313, 22.465733485701982, -4.97444497456514, 80.0, -8.146834831018591, 18.557369401986275, 60.0, -22.209186763925654, 0.0, 79.3043081990006, 35.644614339008356, 76.23836344043568, 20.0, 20.0, 0.0, 72.42081706510673, -6.412798152660783, 58.88426774483975, 60.0, 19.964330360080698, -11.28767326863731, 139.82456650586937, 39.88628819229278, 100.0, -9.531637655110712, -16.19212943565573, 39.73413053040824, 80.0, 141.12510040751957, 20.0, -5.064037382677815, 15.226454909188112, 37.397773983885656, -3.7305696961337045, 5.759809989473804, 40.0, -7.534318794847368, -10.89070326094926, 14.272399911130284, 53.40420559536819, 99.22648833023284, -0.810597779066009, 15.22221142504361, 120.0, -14.56784279228534, -28.097956153924592, 18.830074040117758, -10.813184911105134, -4.961285154681501, -5.756775853779481], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 80.0, 80.0, 80.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 70.0, 70.0, 70.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 70.0, 70.0, 70.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 80.0, 80.0, 80.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-24.51258417572203, -30.849653176811724, -8.12594361392136, -18.02188790054851, -20.0, -23.359463568061052, -36.69343306330785, -30.0, -20.0, -12.897986738221148, -30.0, 0.0, -12.298101196978859, -80.68561555908725, -12.55705468662227, -20.06941648366015, -12.846112758271035, 0.0, -30.0, -25.835593801241217, -31.260661269579554, -10.0, -70.0, 0.0, -26.714021588357614, -15.4596345797146, -33.286081331246535, 0.0, -18.55954473119562, -40.0, -43.60996264374434, -24.132881982929312, 0.0, -20.0, -2.649276140938884, -86.34180693781735, -17.427103752638157, -40.0, -60.0, -26.537449007438987, -0.10074140340251891, -30.0, -2.0191858108640126, -53.44683824153271, 0.0, -15.586376534773004, -10.0, -20.348448069315157, -30.471757514059515, 0.0, -30.17057035184769, -78.0295733673697, -10.0, -47.2515258810691, -50.0, -19.291421126295575, -35.40351046518893, -41.35150440126467, -0.1108424342379799, -38.936118096897935, -43.88370569718795, -60.0, -28.098291525871595, -11.142870499223115, 0.0, -10.0, -31.449392540817737, -12.47357260474155, -10.0, -60.0, -4.3012626038861805, -57.68973558481186, -44.954224910118235, 0.0, -30.0, -76.71350181049137, -9.231959598294065, -30.0, -62.9973287693332, 0.0, -3.049083681746362, -21.44866399034807, -26.555194224934766, -6.214940198313547, -5.703019898857729, -51.094275228463765, 0.0, -19.542020534889268, -23.316042782312017, -8.246310828616407, -34.99285226203153, -0.6489146329423601, -40.954541865478234, -8.731991002443078, -33.244435989790986, -17.792473301894592, -14.399909769794814, -9.454554412748626, -0.2928598845908381, -25.761114356473414, -6.440695414940688, -69.83187743541633, -0.2979009687699896, -50.0, -0.5162826001947762, 0.0, -31.34343290041863, 0.0, -23.967853271019113, -20.0, -127.88010254072616, -62.75693177664744, -34.58672415020313, -37.534266514298025, -4.97444497456514, -40.0, -8.146834831018591, -11.442630598013725, -30.0, -22.209186763925654, 0.0, -40.695691800999384, -24.355385660991633, -43.76163655956433, -10.0, -10.0, 0.0, -47.579182934893275, -6.412798152660783, -31.11573225516026, -30.0, -10.035669639919302, -41.28767326863731, -70.17543349413063, -20.11371180770722, -50.0, -9.531637655110712, -16.19212943565573, -20.265869469591763, -40.0, -98.87489959248043, -10.0, -5.064037382677815, -14.773545090811886, -22.602226016114344, -3.7305696961337045, -54.240190010526184, -20.0, -7.534318794847368, -10.89070326094926, -45.72760008886972, -36.59579440463181, -50.77351166976716, -0.810597779066009, -14.77778857495639, -60.0, -14.56784279228534, -28.097956153924592, -11.16992595988224, -10.813184911105134, -4.961285154681501, -5.756775853779481]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6561756503689302, "mean_inference_ms": 1.1289083929648152, "mean_action_processing_ms": 0.2521629338668759, "mean_env_wait_ms": 0.48887532835086595, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0044967657254066, "StateBufferConnector_ms": 0.0033155635551170067, "ViewRequirementAgentConnector_ms": 0.08755981186289846}, "num_episodes": 162, "episode_return_max": 153.65819306218262, "episode_return_min": -41.35150440126467, "episode_return_mean": 28.044177781232772}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 784000, "num_agent_steps_trained": 784000, "num_env_steps_sampled": 196000, "num_env_steps_trained": 196000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 284.58116618696835, "num_env_steps_trained_throughput_per_sec": 284.58116618696835, "timesteps_total": 196000, "num_env_steps_sampled_lifetime": 196000, "num_agent_steps_sampled_lifetime": 784000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 784000, "timers": {"training_iteration_time_ms": 14115.437, "restore_workers_time_ms": 0.013, "training_step_time_ms": 14115.399, "sample_time_ms": 1213.312, "learn_time_ms": 12887.751, "learn_throughput": 310.372, "synch_weights_time_ms": 13.841}, "counters": {"num_env_steps_sampled": 196000, "num_env_steps_trained": 196000, "num_agent_steps_sampled": 784000, "num_agent_steps_trained": 784000}, "done": false, "training_iteration": 49, "trial_id": "b72b3_00000", "date": "2024-08-08_15-43-24", "timestamp": 1723146204, "time_this_iter_s": 14.097707748413086, "time_total_s": 730.3623325824738, "pid": 98177, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3281aa9d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 730.3623325824738, "iterations_since_restore": 49, "perf": {"cpu_util_percent": 30.6, "ram_util_percent": 83.23}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.0453296365837255, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.324076172957818, "policy_loss": -0.022243996239073263, "vf_loss": 6.344420730322599, "vf_explained_var": 0.01275492695470651, "kl": 0.009497190608829087, "entropy": 0.9417918578411142, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 47520.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6947881914622395, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.735322048393547, "policy_loss": -0.01818917362607276, "vf_loss": 3.752290189266205, "vf_explained_var": -3.6263719518133934e-07, "kl": 0.006105162291935406, "entropy": 0.6280373287961838, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 139590.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 200000, "num_env_steps_trained": 200000, "num_agent_steps_sampled": 800000, "num_agent_steps_trained": 800000}, "env_runners": {"episode_reward_max": 160.0, "episode_reward_min": -35.92302796867558, "episode_reward_mean": 27.77246434779094, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -111.42300249576138}, "policy_reward_max": {"adversary_policy": 90.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 17.037037037037038, "agent_policy": -23.338646763320178}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 16.829291033259906, -0.8323861764359342, 56.98677801670618, 58.02238923051935, 26.297213801235447, 120.0, -22.88746304312925, -1.6401680019524012, -7.8833959375225025, -2.793101199689505, -0.03774786467819702, 0.0, 79.77995223190935, 40.0, 111.86215082162337, 51.95490103942641, 0.0, 105.57360079625269, 78.04975333059554, -1.8592780884312343, 60.0, 40.0, 37.4020974435575, -1.440812262827904, -0.10001973640024975, 37.25538402552042, 31.24508638749904, -1.1381741307860083, 60.0, 0.0, 60.0, -26.001284853200318, 87.58442810213282, 40.45042309101947, -14.433166655560985, -17.670235766818013, 33.4680954860554, 80.0, -10.470766896258965, 0.0, 60.0, -13.650106336579473, -1.033906729060421, 19.386784502269137, -32.60885945807035, 40.0, 0.0, -8.01764587040924, 60.0, 40.0, -16.058259045727002, 60.0, 20.0, 0.0, 60.0, -4.546179744695284, 131.50837775407734, 59.544393027254074, 58.88122895908136, -0.3357990453055437, 60.0, 58.56759145242722, 40.0, 73.48369051783135, -14.203726112390804, 80.0, 50.44602229751692, -25.65083325889093, 40.0, 100.0, -10.832498522457822, 35.24857901786394, 32.55599067559989, 18.14846813838743, 31.636521773133907, 20.0, 99.74110476328312, -1.0596372452488656, 113.70274210043209, 158.57699750423865, -12.568139891166624, 0.0, 0.0, 39.85684417943041, -1.1452334953011623, 62.25004612190466, 26.5567113445426, -7.328961219236825, 88.97276734979546, -8.376803963945308, 0.0, 0.0, -10.055445344068286, 120.0, 19.450049193074744, -3.416745600876762, 10.438073074159679, 56.915685817172786, 4.513171954093958, 0.0, 56.38194072751985, 32.19210466349938, -9.224741179312714, -15.884278826247202, 100.0, 20.0, -7.737441172358086, 80.0, -5.7474363584996775, 40.0, -0.669415015635445, -0.4053737830252324, 0.5438357936229972, 0.0, -23.77892033493742, 39.40076594438749, 31.05007358142003, 80.0, 78.46807999293263, 19.302645728558403, 31.4028143658294, -2.545801135966564, -0.08477448366922435, 20.0, 0.0, 39.714306037186354, 60.0, 57.57445397835249, -8.226494121478, -0.9194144440612051, 0.0, 131.27626211309843, 8.331539768868417, 20.0, 53.28718502786597, 80.0, -11.552601015978121, 0.0, -19.448147625920488, 35.88055251173996, 44.98929034530697, -16.537540065689473, 12.884592472360296, -3.019247429536567, 57.23007049232612, 30.24365135120086, -23.228339893746906, 0.0, -35.92302796867558, -12.332317261296385, 34.3571660667163, 28.491939939294056, 51.18603251777794, 0.0, 160.0, 24.737436760497904, 7.778585269361595, 0.0, 20.0, 26.632606150680584], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 60.0, 60.0, 60.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 90.0, 90.0, 90.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 80.0, 80.0, 80.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0], "policy_agent_policy_reward": [0.0, 0.0, -13.170708966740099, -0.8323861764359342, -33.01322198329381, -31.977610769480652, -33.70278619876456, -60.0, -22.88746304312925, -1.6401680019524012, -7.8833959375225025, -2.793101199689505, -0.03774786467819702, 0.0, -40.22004776809066, -20.0, -68.13784917837663, -38.0450989605736, 0.0, -74.42639920374728, -41.950246669404464, -1.8592780884312343, -30.0, -20.0, -22.5979025564425, -1.440812262827904, -0.10001973640024975, -22.74461597447958, -28.754913612500957, -1.1381741307860083, -30.0, 0.0, -30.0, -26.001284853200318, -62.41557189786717, -49.549576908980534, -14.433166655560985, -17.670235766818013, -26.531904513944593, -40.0, -10.470766896258965, 0.0, -30.0, -13.650106336579473, -1.033906729060421, -40.61321549773086, -32.60885945807035, -20.0, 0.0, -8.01764587040924, -30.0, -20.0, -16.058259045727002, -30.0, -10.0, 0.0, -30.0, -4.546179744695284, -78.49162224592267, -30.455606972745926, -31.118771040918627, -0.3357990453055437, -30.0, -31.43240854757277, -20.0, -46.51630948216866, -14.203726112390804, -40.0, -39.55397770248308, -25.65083325889093, -20.0, -50.0, -10.832498522457822, -24.751420982136054, -27.444009324400117, -11.85153186161257, -28.3634782268661, -10.0, -50.25889523671688, -1.0596372452488656, -66.29725789956791, -111.42300249576138, -12.568139891166624, 0.0, 0.0, -20.14315582056959, -1.1452334953011623, -57.74995387809535, -33.4432886554574, -7.328961219236825, -61.027232650204525, -8.376803963945308, 0.0, 0.0, -10.055445344068286, -60.0, -40.54995080692526, -3.416745600876762, -19.56192692584032, -33.084314182827214, -25.486828045906048, 0.0, -33.61805927248015, -27.807895336500625, -9.224741179312714, -15.884278826247202, -50.0, -10.0, -7.737441172358086, -40.0, -5.7474363584996775, -20.0, -0.669415015635445, -0.4053737830252324, -29.45616420637699, 0.0, -23.77892033493742, -50.59923405561251, -28.94992641857997, -40.0, -41.53192000706736, -10.697354271441599, -28.5971856341706, -2.545801135966564, -0.08477448366922435, -10.0, 0.0, -20.285693962813646, -30.0, -32.42554602164752, -8.226494121478, -0.9194144440612051, 0.0, -78.72373788690159, -21.668460231131583, -10.0, -36.71281497213403, -40.0, -11.552601015978121, 0.0, -19.448147625920488, -24.119447488260043, -45.01070965469303, -16.537540065689473, -47.115407527639704, -3.019247429536567, -32.76992950767387, -59.75634864879914, -23.228339893746906, 0.0, -35.92302796867558, -12.332317261296385, -25.64283393328369, -31.508060060705944, -38.81396748222206, 0.0, -80.0, -35.26256323950211, -22.22141473063841, 0.0, -10.0, -33.36739384931941]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6551590687679965, "mean_inference_ms": 1.1270565968296495, "mean_action_processing_ms": 0.2513721495460871, "mean_env_wait_ms": 0.4882736169156712, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004691989333541305, "StateBufferConnector_ms": 0.0031719973057876398, "ViewRequirementAgentConnector_ms": 0.0867800948060589}, "num_episodes": 162, "episode_return_max": 160.0, "episode_return_min": -35.92302796867558, "episode_return_mean": 27.77246434779094}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 800000, "num_agent_steps_trained": 800000, "num_env_steps_sampled": 200000, "num_env_steps_trained": 200000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 284.1441300976874, "num_env_steps_trained_throughput_per_sec": 284.1441300976874, "timesteps_total": 200000, "num_env_steps_sampled_lifetime": 200000, "num_agent_steps_sampled_lifetime": 800000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 800000, "timers": {"training_iteration_time_ms": 14080.903, "restore_workers_time_ms": 0.013, "training_step_time_ms": 14080.865, "sample_time_ms": 1205.279, "learn_time_ms": 12861.25, "learn_throughput": 311.012, "synch_weights_time_ms": 13.8}, "counters": {"num_env_steps_sampled": 200000, "num_env_steps_trained": 200000, "num_agent_steps_sampled": 800000, "num_agent_steps_trained": 800000}, "done": false, "training_iteration": 50, "trial_id": "b72b3_00000", "date": "2024-08-08_15-43-38", "timestamp": 1723146218, "time_this_iter_s": 14.083964824676514, "time_total_s": 744.4462974071503, "pid": 98177, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3281aac10>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 744.4462974071503, "iterations_since_restore": 50, "perf": {"cpu_util_percent": 27.9, "ram_util_percent": 82.62}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.0271629934509594, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.292605876177549, "policy_loss": -0.02383681860519573, "vf_loss": 6.314306902388732, "vf_explained_var": -0.013791390508413316, "kl": 0.010678982093929161, "entropy": 0.9735444894060492, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 48480.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6854833344829844, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.952172335580731, "policy_loss": -0.019436705013555853, "vf_loss": 3.9702367758920007, "vf_explained_var": 1.4530428757904269e-06, "kl": 0.006861313275051334, "entropy": 0.6203527871387224, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 142410.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 204000, "num_env_steps_trained": 204000, "num_agent_steps_sampled": 816000, "num_agent_steps_trained": 816000}, "env_runners": {"episode_reward_max": 177.81153285040622, "episode_reward_min": -45.470911199091, "episode_reward_mean": 31.714191648211347, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 153, "episodes_timesteps_total": 3825, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -92.18846714959376}, "policy_reward_max": {"adversary_policy": 90.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 18.88888888888889, "agent_policy": -24.952475018455324}, "custom_metrics": {}, "hist_stats": {"episode_reward": [19.82119542415857, -1.8587457106180982, 40.0, -3.667234248104732, -8.301937455256661, -12.211602536829824, -23.366974163506026, -9.632199268703513, -7.421130115411092, -14.725372522142852, 60.0, 60.0, 118.69991716108703, 40.0, 90.12010362597688, 74.82228485157245, 20.0, -12.859316332362368, 115.56547813413226, -8.512332275140182, 0.0, 0.0, 177.81153285040622, 39.79267736400952, -22.77065292022251, -4.852767056444449, 40.0, 100.0, 26.579508110514233, 4.883512325323135, 60.0, 60.0, 36.744160096307255, 59.31917400364287, 53.85342571365509, 21.33780956237986, 24.386565511768296, 13.36962720157201, -3.3150633095399584, 76.66132414906636, -27.40560864851841, -24.811867639415055, -0.8570556968229615, -1.7284687250030273, 0.0, -11.030974686992675, 54.148995527669896, -10.13017726120005, -45.470911199091, 100.0, -5.93188046145349, -9.468238426691745, 60.0, 0.0, 38.776366692405105, -0.6478493342291758, 108.13463580509152, 26.154039905858944, -30.03777689796823, 0.0, 40.0, 39.72665984905268, -2.0214464648747987, 60.0, 65.35174995150868, 26.142100070798172, 120.0, 22.524784381252054, -11.339315040977306, 40.0, 39.64730897583362, 0.0, 60.0, 18.57542645216847, 59.434953717599996, 40.0, 40.0, 67.1490478784109, 60.0, 20.0, -14.509193016681374, 44.329477810181956, -4.542504667515989, -16.451480844574842, 35.47473793171558, 0.0, -25.47085629474916, 40.0, 140.0, -7.652995769615957, -18.913776309682756, 76.50115307795403, -17.439124650990372, 140.0, 100.0, 60.0, -4.657542761381819, 39.58382933541593, -13.331758523134393, 120.0, -20.20084229284239, -1.4317586603569166, 36.067488182518474, 60.0, 51.3027868464149, -7.832055919219313, 160.0, -9.176286755527828, -0.10584719799097253, 7.23940745055488, 0.0, 40.0, 35.82058682060635, 60.0, 78.02694374092744, 137.71760132128543, 20.0, 120.0, 38.3785081980075, -0.8699626457595877, 0.0, 40.0, 49.82874838185456, 39.553473541780555, -2.077848848337829, 60.0, 5.530033120408907, 80.0, -18.947197006795136, -2.3034124762669412, -4.835536302730071, -3.8127869588824908, 120.0, 38.82898156287109, -0.07591410352197459, -4.8178057962107, 60.0, 120.0, 60.0, 100.0, 0.0, 100.0, 49.767434873866684, -7.566845038007479, 20.0, 60.0, 80.0, 40.0, 18.128759208928436, 20.0, -26.736704553022694, -22.70136085267282, -18.50469787818685], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 90.0, 90.0, 90.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 80.0, 80.0, 80.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 70.0, 70.0, 70.0, 10.0, 10.0, 10.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 60.0, 60.0, 60.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-10.17880457584143, -1.8587457106180982, -20.0, -3.667234248104732, -8.301937455256661, -12.211602536829824, -23.366974163506026, -9.632199268703513, -7.421130115411092, -14.725372522142852, -30.0, -30.0, -61.30008283891299, -20.0, -59.87989637402314, -45.17771514842755, -10.0, -12.859316332362368, -64.43452186586774, -8.512332275140182, 0.0, 0.0, -92.18846714959376, -20.207322635990483, -22.77065292022251, -4.852767056444449, -20.0, -50.0, -33.420491889485774, -25.116487674676865, -30.0, -30.0, -53.255839903692745, -30.680825996357136, -36.14657428634491, -38.66219043762014, -35.613434488231704, -16.63037279842799, -3.3150633095399584, -43.33867585093365, -27.40560864851841, -24.811867639415055, -0.8570556968229615, -1.7284687250030273, 0.0, -11.030974686992675, -35.851004472330104, -10.13017726120005, -45.470911199091, -50.0, -5.93188046145349, -9.468238426691745, -30.0, 0.0, -21.223633307594895, -0.6478493342291758, -71.86536419490847, -33.845960094141056, -30.03777689796823, 0.0, -20.0, -20.273340150947323, -2.0214464648747987, -30.0, -54.64825004849132, -33.85789992920183, -60.0, -37.475215618747924, -11.339315040977306, -20.0, -20.352691024166383, 0.0, -30.0, -11.424573547831526, -30.5650462824, -20.0, -20.0, -52.85095212158908, -30.0, -10.0, -14.509193016681374, -45.670522189818044, -4.542504667515989, -16.451480844574842, -24.525262068284423, 0.0, -25.47085629474916, -20.0, -70.0, -7.652995769615957, -18.913776309682756, -43.49884692204598, -17.439124650990372, -70.0, -50.0, -30.0, -4.657542761381819, -20.416170664584076, -13.331758523134393, -60.0, -20.20084229284239, -1.4317586603569166, -23.932511817481533, -30.0, -38.69721315358511, -7.832055919219313, -80.0, -9.176286755527828, -0.10584719799097253, -22.76059254944512, 0.0, -20.0, -24.179413179393634, -30.0, -41.973056259072564, -72.28239867871459, -10.0, -60.0, -21.621491801992498, -0.8699626457595877, 0.0, -20.0, -40.17125161814545, -20.446526458219445, -2.077848848337829, -30.0, -24.469966879591095, -40.0, -18.947197006795136, -2.3034124762669412, -4.835536302730071, -3.8127869588824908, -60.0, -51.1710184371289, -0.07591410352197459, -4.8178057962107, -30.0, -60.0, -30.0, -50.0, 0.0, -50.0, -40.232565126133316, -7.566845038007479, -10.0, -30.0, -40.0, -20.0, -11.871240791071566, -10.0, -26.736704553022694, -22.70136085267282, -18.50469787818685]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6538618519702912, "mean_inference_ms": 1.124872723325461, "mean_action_processing_ms": 0.2506261910157239, "mean_env_wait_ms": 0.4874203411743419, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003970993889702691, "StateBufferConnector_ms": 0.003117283964468763, "ViewRequirementAgentConnector_ms": 0.08709874807619582}, "num_episodes": 153, "episode_return_max": 177.81153285040622, "episode_return_min": -45.470911199091, "episode_return_mean": 31.714191648211347}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 816000, "num_agent_steps_trained": 816000, "num_env_steps_sampled": 204000, "num_env_steps_trained": 204000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 283.06736192663254, "num_env_steps_trained_throughput_per_sec": 283.06736192663254, "timesteps_total": 204000, "num_env_steps_sampled_lifetime": 204000, "num_agent_steps_sampled_lifetime": 816000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 816000, "timers": {"training_iteration_time_ms": 14075.904, "restore_workers_time_ms": 0.013, "training_step_time_ms": 14075.865, "sample_time_ms": 1207.333, "learn_time_ms": 12852.84, "learn_throughput": 311.215, "synch_weights_time_ms": 14.746}, "counters": {"num_env_steps_sampled": 204000, "num_env_steps_trained": 204000, "num_agent_steps_sampled": 816000, "num_agent_steps_trained": 816000}, "done": false, "training_iteration": 51, "trial_id": "b72b3_00000", "date": "2024-08-08_15-43-52", "timestamp": 1723146232, "time_this_iter_s": 14.171957015991211, "time_total_s": 758.6182544231415, "pid": 98177, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3174f3b80>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 758.6182544231415, "iterations_since_restore": 51, "perf": {"cpu_util_percent": 28.26, "ram_util_percent": 82.66}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.857533125082652, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.695631335179011, "policy_loss": -0.024919030026406594, "vf_loss": 6.718419517079989, "vf_explained_var": 0.0026296872024734815, "kl": 0.010654197237810248, "entropy": 0.9800241436809302, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 49440.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7165548835768767, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.559276330471039, "policy_loss": -0.01897605087555258, "vf_loss": 4.577136894320765, "vf_explained_var": 6.493101728723404e-08, "kl": 0.005577470656533609, "entropy": 0.6251103574291189, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 145230.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 208000, "num_env_steps_trained": 208000, "num_agent_steps_sampled": 832000, "num_agent_steps_trained": 832000}, "env_runners": {"episode_reward_max": 195.6227776252952, "episode_reward_min": -42.649348520440626, "episode_reward_mean": 34.99667546404329, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -104.37722237470477}, "policy_reward_max": {"adversary_policy": 100.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 20.555555555555557, "agent_policy": -26.66999120262338}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-22.308976943153382, -16.094958376564136, 20.0, -0.028436033709898778, 57.7613203484496, 58.913999785423925, 60.0, 80.0, 74.37816240911346, -1.4998272059538431, 71.66784504113755, 80.0, 31.09263416162161, 54.219423820855845, 133.18557011281854, 160.0, -4.083187629776879, 0.0, 57.74588428573132, 60.0, 157.6572678963656, -4.8904884648838305, 60.0, 20.0, 60.0, -5.552224482759657, 60.0, 60.0, -6.060977836238542, -42.649348520440626, 37.98584903735746, 103.90816260627777, 66.75591968028183, -14.82571960489181, 139.39198334988424, 47.23545771151527, 0.0, 60.0, 55.8884882588312, 0.0, -8.44509834220028, -38.799121286184366, 100.0, 0.0, -8.0380740117835, -14.867417429393146, 40.0, -7.11993349376681, 56.84708534750897, 1.9438717664966196, 0.0, 120.0, -14.769358595286057, 140.0, -7.387058385715468, -10.873380227388143, 0.0, 16.923747484653543, 0.0, 100.0, -15.81299322604795, -17.402605447737624, 20.0, 80.0, 20.0, 77.31845130208512, 38.966545348734996, -3.712639405785781, 38.45689027181487, 16.053958802576716, 0.0, 5.779568637055684, 13.617126240283376, 0.0, 100.0, -19.155462861070657, 40.0, 61.707209072346785, 20.0, 57.22096026994168, 119.21789576393581, 40.0, -21.581500965335763, 40.0, 34.71002581556428, 60.0, 20.0, 38.0505753540582, 0.0, 60.0, 23.49840667847836, 35.22071166342167, 80.0, -29.76883379639484, 44.7643027135602, 20.0, -33.89557164686338, -3.2010253314261323, 46.023788642790926, 80.0, 0.0, 7.952781662431748, 0.0, 80.0, -39.87912845066216, 40.0, 69.32943646262252, 16.306671158648633, -9.701600295365896, 59.57216306799191, 39.165257562105204, 80.0, 14.814842068594485, 38.61321800020716, -22.123068288479214, 19.61867880715592, 100.0, -2.073368374041743, 59.07098792619628, 0.0, 39.950708395264726, -6.738457970948944, 20.0, 19.755567032776298, 27.43018734145255, 0.0, 87.1165454740298, 118.70712294717725, 98.53292049937555, 100.0, -0.4528791759006612, 39.35599498841375, 54.53977531926208, -5.0598261896293835, 100.0, 40.0, 0.0, 59.33002498374574, -1.726208675493227, -0.6480075570942101, 14.83184203919716, 57.75533433783359, -10.552787289600195, 58.38200911652188, -4.140396271843509, -2.0616320315142413, -15.944591663138368, -10.968814316100053, -7.241881296716163, 100.0, 195.6227776252952, 20.0, 78.32450559199587, 19.902959607417145, -21.6365547360894, 80.0, 98.65046671211606, -0.9760280692317924, 60.0, 79.50278489043436, -2.033777921621245, 80.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 70.0, 70.0, 70.0, 80.0, 80.0, 80.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 80.0, 80.0, 80.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 60.0, 60.0, 60.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 60.0, 60.0, 60.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 100.0, 100.0, 100.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0], "policy_agent_policy_reward": [-22.308976943153382, -16.094958376564136, -10.0, -0.028436033709898778, -32.2386796515504, -31.086000214576067, -30.0, -40.0, -45.62183759088656, -1.4998272059538431, -48.33215495886245, -40.0, -28.907365838378404, -35.780576179144155, -76.81442988718148, -80.0, -4.083187629776879, 0.0, -32.25411571426868, -30.0, -82.3427321036344, -4.8904884648838305, -30.0, -10.0, -30.0, -35.552224482759655, -30.0, -30.0, -6.060977836238542, -42.649348520440626, -22.01415096264254, -76.09183739372223, -53.244080319718165, -14.82571960489181, -70.60801665011576, -42.76454228848473, 0.0, -30.0, -34.1115117411688, 0.0, -8.44509834220028, -38.799121286184366, -50.0, 0.0, -8.0380740117835, -14.867417429393146, -20.0, -7.11993349376681, -63.15291465249103, -28.05612823350338, 0.0, -60.0, -14.769358595286057, -70.0, -7.387058385715468, -10.873380227388143, 0.0, -13.076252515346457, 0.0, -50.0, -15.81299322604795, -17.402605447737624, -10.0, -40.0, -10.0, -72.68154869791488, -51.033454651265004, -3.712639405785781, -21.54310972818513, -13.946041197423282, 0.0, -24.220431362944318, -16.382873759716624, 0.0, -50.0, -19.155462861070657, -20.0, -58.292790927653215, -10.0, -32.77903973005833, -60.78210423606417, -20.0, -21.581500965335763, -20.0, -25.289974184435724, -30.0, -10.0, -21.949424645941797, 0.0, -30.0, -36.50159332152165, -24.77928833657834, -40.0, -29.76883379639484, -45.2356972864398, -10.0, -33.89557164686338, -3.2010253314261323, -43.976211357209074, -40.0, 0.0, -22.047218337568253, 0.0, -40.0, -39.87912845066216, -20.0, -50.67056353737747, -13.693328841351365, -9.701600295365896, -30.42783693200809, -20.834742437894796, -40.0, -15.185157931405515, -21.38678199979284, -22.123068288479214, -10.38132119284408, -50.0, -2.073368374041743, -30.92901207380372, 0.0, -20.049291604735277, -6.738457970948944, -10.0, -70.2444329672237, -32.56981265854745, 0.0, -62.88345452597019, -61.292877052822725, -51.46707950062446, -50.0, -0.4528791759006612, -20.644005011586252, -35.46022468073793, -5.0598261896293835, -50.0, -20.0, 0.0, -30.669975016254263, -1.726208675493227, -0.6480075570942101, -15.16815796080284, -32.24466566216641, -10.552787289600195, -31.617990883478125, -4.140396271843509, -2.0616320315142413, -15.944591663138368, -40.96881431610005, -7.241881296716163, -50.0, -104.37722237470477, -10.0, -41.67549440800413, -10.097040392582855, -21.6365547360894, -40.0, -51.34953328788394, -0.9760280692317924, -30.0, -40.497215109565644, -2.033777921621245, -40.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.653420405065711, "mean_inference_ms": 1.1235976587958953, "mean_action_processing_ms": 0.2499031260047121, "mean_env_wait_ms": 0.48691404941819566, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005581275916393892, "StateBufferConnector_ms": 0.0033589056980462724, "ViewRequirementAgentConnector_ms": 0.09917101742308816}, "num_episodes": 162, "episode_return_max": 195.6227776252952, "episode_return_min": -42.649348520440626, "episode_return_mean": 34.99667546404329}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 832000, "num_agent_steps_trained": 832000, "num_env_steps_sampled": 208000, "num_env_steps_trained": 208000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 289.22280607535566, "num_env_steps_trained_throughput_per_sec": 289.22280607535566, "timesteps_total": 208000, "num_env_steps_sampled_lifetime": 208000, "num_agent_steps_sampled_lifetime": 832000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 832000, "timers": {"training_iteration_time_ms": 13976.143, "restore_workers_time_ms": 0.014, "training_step_time_ms": 13976.103, "sample_time_ms": 1147.885, "learn_time_ms": 12812.513, "learn_throughput": 312.195, "synch_weights_time_ms": 14.765}, "counters": {"num_env_steps_sampled": 208000, "num_env_steps_trained": 208000, "num_agent_steps_sampled": 832000, "num_agent_steps_trained": 832000}, "done": false, "training_iteration": 52, "trial_id": "b72b3_00000", "date": "2024-08-08_15-44-06", "timestamp": 1723146246, "time_this_iter_s": 13.838595867156982, "time_total_s": 772.4568502902985, "pid": 98177, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x32818d550>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 772.4568502902985, "iterations_since_restore": 52, "perf": {"cpu_util_percent": 28.36499999999999, "ram_util_percent": 82.48500000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.370009256899357, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.27312853783369, "policy_loss": -0.01862607849567818, "vf_loss": 6.289913515249888, "vf_explained_var": -0.003088901626567046, "kl": 0.00920540942112686, "entropy": 0.9336710115894675, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 50400.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6778528906669177, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.506622794080288, "policy_loss": -0.01975861198181313, "vf_loss": 3.5251089686197594, "vf_explained_var": -3.794194958734174e-07, "kl": 0.006362176417225116, "entropy": 0.5931879381127392, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 148050.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 212000, "num_env_steps_trained": 212000, "num_agent_steps_sampled": 848000, "num_agent_steps_trained": 848000}, "env_runners": {"episode_reward_max": 154.75818656573836, "episode_reward_min": -39.83939502827317, "episode_reward_mean": 26.087270231022725, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -114.74426130741493}, "policy_reward_max": {"adversary_policy": 80.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 16.358024691358025, "agent_policy": -22.986803843051344}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-2.8408505560476094, 0.0, -30.36166246913667, -7.640312577257825, 32.346715272548096, -9.61592734676255, 43.57089088475347, 98.54889736946492, -24.764683885577895, -13.5261041069165, -4.649592429487801, 0.0, 0.0, 80.0, 0.0, 0.0, 59.673880763713, -11.363705073050642, 40.0, -5.155382657556252, 0.0, -1.1774557131560348, 59.585212741704424, 40.0, 40.0, 0.0, 42.64674003549901, 8.713956866717997, 40.0, 58.01899204833154, -0.8789034656270278, -8.653753974922934, -7.741165222900025, 31.161691855356707, -28.453066794376404, -2.623439227439243, 78.79472399561922, 19.957554988729655, -6.981225181934105, -0.6414776528471489, -8.811061854702517, 57.46647685889124, -9.938809054343313, -9.538089259284707, 0.0, 0.0, 0.0, 154.75818656573836, 140.0, 40.0, 40.0, 33.964972077312865, 0.0, 19.859980259087763, 60.0, 73.70090900614954, -7.733175511751878, 0.0, 53.57077917840917, -2.9031364563553366, 19.43081232967655, 73.96032634460367, 60.0, 48.96020051377904, -5.290211918774196, 57.17098258714342, 80.0, 100.0, -3.135115656438685, 98.71455672158467, 0.0, -4.977556813321842, 10.201396124572593, 59.804893925675614, -6.461115729672731, 28.411093879576754, -6.885141223805854, -24.305575496609315, -18.955816301316744, -3.2674708763671023, 78.97168977782181, -30.341097484314734, 125.25573869258511, -4.7531631814942585, 59.98212640793781, 40.0, -1.8522101932041168, 24.105886395789902, 69.84269032669022, -14.162430939513769, -10.793326739801419, -6.949382191415264, 134.9484946429696, 139.27740664070103, -9.44196841136873, 55.596037486772865, 60.0, -17.214557262680188, 100.0, 0.0, 40.0, -22.603906326174517, 59.52680391863586, 80.0, -22.46474769380846, 0.0, 40.0, 120.0, 34.466302268734, 16.37349131538427, -11.14589508341804, -11.588110610671581, 0.0, -19.57099901642877, 38.49915824314719, 80.0, 39.94549532167835, 80.0, 88.298580516338, -18.099495886496754, -1.741097296273895, 120.0, 41.146439144870946, 41.26078839020837, 16.532026601242364, -0.5214471692109579, -5.281826661000672, 40.91390311308903, 39.88337029462147, 0.0, -9.361962620545496, 116.57776230050814, -5.801403312372494, 53.20030290792202, 20.0, -9.620975775835499, 1.2898650354434529, 60.0, -21.032727576284366, 52.105790843858315, 59.28366628833069, 18.707059089655445, 17.47952986375773, 40.0, -39.83939502827317, 32.79488082699923, -7.857178711187751, 32.35938943433549, 24.370769307278586, 60.0, 40.0, 0.0, 39.9679033596875, -12.511005270275493, 20.0, -12.061979741026168, 80.0, 56.91401712284671, 31.173573366013485, 0.0, -0.30643415080199743, -11.718276193192441], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 80.0, 80.0, 80.0, 70.0, 70.0, 70.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 80.0, 80.0, 80.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 70.0, 70.0, 70.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-2.8408505560476094, 0.0, -30.36166246913667, -7.640312577257825, -27.653284727451908, -9.61592734676255, -46.42910911524653, -51.45110263053509, -24.764683885577895, -13.5261041069165, -4.649592429487801, 0.0, 0.0, -40.0, 0.0, 0.0, -30.326119236287003, -11.363705073050642, -20.0, -5.155382657556252, 0.0, -1.1774557131560348, -60.414787258295576, -20.0, -20.0, 0.0, -47.35325996450099, -21.286043133282, -20.0, -31.98100795166846, -0.8789034656270278, -8.653753974922934, -7.741165222900025, -28.838308144643293, -28.453066794376404, -2.623439227439243, -41.20527600438078, -40.042445011270345, -6.981225181934105, -0.6414776528471489, -8.811061854702517, -32.533523141108766, -9.938809054343313, -9.538089259284707, 0.0, 0.0, 0.0, -85.24181343426164, -70.0, -20.0, -20.0, -26.03502792268713, 0.0, -10.140019740912235, -30.0, -46.29909099385045, -7.733175511751878, 0.0, -36.42922082159083, -2.9031364563553366, -10.56918767032345, -46.039673655396335, -30.0, -41.03979948622096, -5.290211918774196, -32.82901741285658, -40.0, -50.0, -3.135115656438685, -51.28544327841534, 0.0, -4.977556813321842, -19.79860387542741, -30.19510607432438, -6.461115729672731, -31.588906120423246, -6.885141223805854, -24.305575496609315, -18.955816301316744, -3.2674708763671023, -41.0283102221782, -30.341097484314734, -114.74426130741493, -4.7531631814942585, -30.01787359206218, -20.0, -1.8522101932041168, -35.8941136042101, -50.15730967330977, -14.162430939513769, -10.793326739801419, -6.949382191415264, -75.05150535703041, -70.72259335929897, -39.441968411368734, -34.403962513227135, -30.0, -17.214557262680188, -50.0, 0.0, -20.0, -22.603906326174517, -30.473196081364144, -40.0, -22.46474769380846, 0.0, -20.0, -60.0, -25.533697731266006, -13.626508684615734, -11.14589508341804, -11.588110610671581, 0.0, -19.57099901642877, -21.500841756852807, -40.0, -20.054504678321646, -40.0, -61.701419483661994, -18.099495886496754, -1.741097296273895, -60.0, -48.853560855129054, -48.73921160979163, -13.467973398757636, -30.52144716921096, -5.281826661000672, -49.086096886910966, -20.11662970537853, 0.0, -9.361962620545496, -63.42223769949187, -5.801403312372494, -36.79969709207798, -10.0, -9.620975775835499, -28.71013496455655, -30.0, -21.032727576284366, -37.89420915614168, -30.716333711669314, -11.292940910344557, -12.52047013624227, -20.0, -39.83939502827317, -27.205119173000767, -7.857178711187751, -27.640610565664513, -35.62923069272142, -30.0, -20.0, 0.0, -20.0320966403125, -12.511005270275493, -10.0, -12.061979741026168, -40.0, -33.08598287715329, -28.82642663398651, 0.0, -0.30643415080199743, -11.718276193192441]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6521048739701826, "mean_inference_ms": 1.121655632604737, "mean_action_processing_ms": 0.24914216374780462, "mean_env_wait_ms": 0.4862072525619907, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004242967676233362, "StateBufferConnector_ms": 0.003164565121686017, "ViewRequirementAgentConnector_ms": 0.08776290917102202}, "num_episodes": 162, "episode_return_max": 154.75818656573836, "episode_return_min": -39.83939502827317, "episode_return_mean": 26.087270231022725}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 848000, "num_agent_steps_trained": 848000, "num_env_steps_sampled": 212000, "num_env_steps_trained": 212000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 288.7331964416798, "num_env_steps_trained_throughput_per_sec": 288.7331964416798, "timesteps_total": 212000, "num_env_steps_sampled_lifetime": 212000, "num_agent_steps_sampled_lifetime": 848000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 848000, "timers": {"training_iteration_time_ms": 13993.381, "restore_workers_time_ms": 0.014, "training_step_time_ms": 13993.34, "sample_time_ms": 1134.959, "learn_time_ms": 12842.657, "learn_throughput": 311.462, "synch_weights_time_ms": 14.819}, "counters": {"num_env_steps_sampled": 212000, "num_env_steps_trained": 212000, "num_agent_steps_sampled": 848000, "num_agent_steps_trained": 848000}, "done": false, "training_iteration": 53, "trial_id": "b72b3_00000", "date": "2024-08-08_15-44-20", "timestamp": 1723146260, "time_this_iter_s": 13.861278057098389, "time_total_s": 786.3181283473969, "pid": 98177, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x32818d280>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 786.3181283473969, "iterations_since_restore": 53, "perf": {"cpu_util_percent": 26.909999999999997, "ram_util_percent": 82.575}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.2157178702453773, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.537912721435229, "policy_loss": -0.022071845062358382, "vf_loss": 6.558165816962719, "vf_explained_var": -0.011986791777114073, "kl": 0.009093698388745072, "entropy": 0.9803726008782784, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 51360.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6946269323745518, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.825535123483509, "policy_loss": -0.01795218822589443, "vf_loss": 3.842429447258618, "vf_explained_var": 5.149672217402898e-07, "kl": 0.0052892839239598475, "entropy": 0.587754963222125, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 150870.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 216000, "num_env_steps_trained": 216000, "num_agent_steps_sampled": 864000, "num_agent_steps_trained": 864000}, "env_runners": {"episode_reward_max": 160.0, "episode_reward_min": -46.2554362328692, "episode_reward_mean": 28.60351692572536, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -89.81627569730591}, "policy_reward_max": {"adversary_policy": 80.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 17.40740740740741, "agent_policy": -23.61870529649686}, "custom_metrics": {}, "hist_stats": {"episode_reward": [160.0, -14.044152829310521, 0.0, 20.0, -46.2554362328692, 19.361410042821284, 16.68807771109654, 0.0, 0.0, 16.1316017103221, 0.0, -8.823192326743984, 33.65635342931914, 40.0, 60.0, 74.68351776245498, -11.405145211011419, -2.1551216574802545, -5.391350955822778, -4.846964888804427, -14.337147110767408, 60.0, 0.0, -31.34830366243954, 97.40745855311755, 20.0, -1.1206501973861793, 26.065895956211723, 120.0, 90.70973965004536, 73.58785752603023, 19.65325616200175, -7.4569048633441914, 40.0, 100.0, -1.669491459091209, -5.590836602928837, -12.453313073838181, -8.184837012804557, -12.32849528508242, -18.85552254541586, -10.537001319651514, -2.743445269737583, 31.893579783031637, 160.0, 50.158438061126404, 50.626169430042765, -4.102803712661067, -0.03469414044596064, -25.527856539075977, 19.931496597499184, 119.49856144039867, 56.83588275761455, -13.648327027316022, 0.0, -25.52796985678615, 60.0, 0.0, -12.175759941899054, -14.943979276693623, 60.0, 45.44629048272226, 20.0, 20.0, -33.91313406007671, 99.25006153713933, 51.311017212094654, -1.1289256333202213, -12.561158399813497, 80.0, 59.77412365903514, 60.0, 10.659587975001738, -6.519997017010537, 20.0, 100.0, -13.700457627732634, 71.27919573195125, 60.0, 119.76342256761325, 100.0, 60.0, -0.913068795020594, 26.5454628404433, 140.0, 39.70798645651648, -7.985078396858387, 40.0, -26.250063142917753, -10.625981625123105, -8.685017196594345, 80.0, 60.0, 27.848551459982225, 58.70154095716443, -1.7296832429995925, -0.11290030889860025, -0.19568622663430402, 22.685501014142933, 60.0, 160.0, 0.0, -10.988342449187254, 56.435007449986344, -8.323604053708616, -2.002295716008662, 0.0, 138.9651752540623, 0.0, 20.0, -0.3077067862309457, 60.0, 76.67009502747602, 60.0, 98.8777168369258, 31.180010124320024, -2.5446199905705633, -15.089668495001307, 58.59959057800813, 0.0, -12.985801045559796, 0.0, 60.0, -0.9940640520348532, 116.52005626620797, 68.23037332083666, 20.0, 48.084084726512145, 60.0, 0.0, -13.634200263493822, -7.017714086760048, 76.80094792241881, -0.5211016777958322, 0.0, 2.4713132380765472, 20.0, 97.8654637141863, 14.278877456671697, -17.42945545195028, 40.0, 29.701095034900288, 0.0, 9.682402428611837, 71.72438997944806, -38.4877704292716, 20.0, 0.0, 0.0, 54.10701677259442, -1.0929014020286032, -0.79150002429903, 12.828421961792152, 40.0, 48.05446887852783, 98.43189519473012, 0.0, 49.91816433031844, -24.453121154192957, 150.18372430269406, 36.77848208197813, -5.987347630213848], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [80.0, 80.0, 80.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 60.0, 60.0, 60.0, 50.0, 50.0, 50.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 80.0, 80.0, 80.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 60.0, 60.0, 60.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 60.0, 60.0, 60.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 70.0, 70.0, 70.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 80.0, 80.0, 80.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 80.0, 80.0, 80.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-80.0, -14.044152829310521, 0.0, -10.0, -46.2554362328692, -10.638589957178715, -13.311922288903464, 0.0, 0.0, -13.868398289677897, 0.0, -8.823192326743984, -26.343646570680857, -20.0, -30.0, -45.31648223754502, -11.405145211011419, -2.1551216574802545, -5.391350955822778, -4.846964888804427, -14.337147110767408, -30.0, 0.0, -31.34830366243954, -52.592541446882436, -10.0, -1.1206501973861793, -33.93410404378828, -60.0, -59.290260349954636, -46.41214247396977, -10.34674383799825, -7.4569048633441914, -20.0, -50.0, -1.669491459091209, -5.590836602928837, -12.453313073838181, -8.184837012804557, -12.32849528508242, -18.85552254541586, -10.537001319651514, -2.743445269737583, -28.10642021696836, -80.0, -39.841561938873596, -39.373830569957235, -4.102803712661067, -30.03469414044596, -25.527856539075977, -10.068503402500815, -60.50143855960133, -33.164117242385444, -13.648327027316022, 0.0, -25.52796985678615, -30.0, 0.0, -12.175759941899054, -14.943979276693623, -30.0, -44.55370951727774, -10.0, -10.0, -33.91313406007671, -50.74993846286067, -38.68898278790535, -1.1289256333202213, -12.561158399813497, -40.0, -30.225876340964863, -30.0, -19.340412024998265, -6.519997017010537, -10.0, -50.0, -13.700457627732634, -48.72080426804877, -30.0, -60.23657743238677, -50.0, -30.0, -0.913068795020594, -33.45453715955669, -70.0, -20.29201354348352, -7.985078396858387, -20.0, -26.250063142917753, -10.625981625123105, -8.685017196594345, -40.0, -30.0, -32.15144854001776, -31.29845904283557, -1.7296832429995925, -0.11290030889860025, -0.19568622663430402, -67.31449898585707, -30.0, -80.0, 0.0, -10.988342449187254, -33.56499255001366, -38.3236040537086, -2.002295716008662, 0.0, -71.03482474593768, 0.0, -10.0, -0.3077067862309457, -30.0, -43.32990497252398, -30.0, -51.122283163074194, -28.819989875679976, -2.5446199905705633, -15.089668495001307, -31.400409421991867, 0.0, -12.985801045559796, 0.0, -30.0, -0.9940640520348532, -63.47994373379202, -51.76962667916336, -10.0, -41.915915273487855, -30.0, 0.0, -13.634200263493822, -7.017714086760048, -43.19905207758118, -0.5211016777958322, 0.0, -27.528686761923453, -10.0, -52.134536285813695, -45.72112254332831, -17.42945545195028, -20.0, -30.298904965099716, 0.0, -20.317597571388166, -48.27561002055193, -38.4877704292716, -10.0, 0.0, 0.0, -35.89298322740559, -1.0929014020286032, -0.79150002429903, -17.171578038207848, -20.0, -41.94553112147217, -51.56810480526988, 0.0, -40.08183566968156, -24.453121154192957, -89.81627569730591, -23.22151791802185, -5.987347630213848]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6511215110844778, "mean_inference_ms": 1.119904983435554, "mean_action_processing_ms": 0.248470991968617, "mean_env_wait_ms": 0.4856710279055739, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004184687579119647, "StateBufferConnector_ms": 0.0030001740396758654, "ViewRequirementAgentConnector_ms": 0.08598830964830187}, "num_episodes": 162, "episode_return_max": 160.0, "episode_return_min": -46.2554362328692, "episode_return_mean": 28.60351692572536}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 864000, "num_agent_steps_trained": 864000, "num_env_steps_sampled": 216000, "num_env_steps_trained": 216000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 301.01745532481755, "num_env_steps_trained_throughput_per_sec": 301.01745532481755, "timesteps_total": 216000, "num_env_steps_sampled_lifetime": 216000, "num_agent_steps_sampled_lifetime": 864000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 864000, "timers": {"training_iteration_time_ms": 13957.107, "restore_workers_time_ms": 0.014, "training_step_time_ms": 13957.066, "sample_time_ms": 1137.048, "learn_time_ms": 12804.761, "learn_throughput": 312.384, "synch_weights_time_ms": 14.404}, "counters": {"num_env_steps_sampled": 216000, "num_env_steps_trained": 216000, "num_agent_steps_sampled": 864000, "num_agent_steps_trained": 864000}, "done": false, "training_iteration": 54, "trial_id": "b72b3_00000", "date": "2024-08-08_15-44-34", "timestamp": 1723146274, "time_this_iter_s": 13.293678283691406, "time_total_s": 799.6118066310883, "pid": 98177, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x32818dca0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 799.6118066310883, "iterations_since_restore": 54, "perf": {"cpu_util_percent": 26.942105263157895, "ram_util_percent": 82.59473684210528}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.2493843108415605, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.59657057672739, "policy_loss": -0.023395951021181343, "vf_loss": 6.618240485092004, "vf_explained_var": 3.063368300596873e-05, "kl": 0.008630198314356465, "entropy": 0.9268763837094108, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 52320.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6675641865172285, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.1272113647866755, "policy_loss": -0.01844842814306187, "vf_loss": 3.1445312499154543, "vf_explained_var": 9.815532264980018e-07, "kl": 0.0056426972399364695, "entropy": 0.5859847886870939, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 153690.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 220000, "num_env_steps_trained": 220000, "num_agent_steps_sampled": 880000, "num_agent_steps_trained": 880000}, "env_runners": {"episode_reward_max": 180.0, "episode_reward_min": -46.098103756317094, "episode_reward_mean": 23.43387449071176, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 157, "episodes_timesteps_total": 3925, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -90.0}, "policy_reward_max": {"adversary_policy": 90.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 15.605095541401274, "agent_policy": -23.381412133492063}, "custom_metrics": {}, "hist_stats": {"episode_reward": [19.548222948202934, -16.301444604981526, 41.1203915550701, -3.7351007435382337, -0.2306989086474942, 80.0, 20.0, 34.27822858377282, -14.328121465929652, 76.96702877944051, 55.68533992273501, -24.52370077950967, 20.0, 20.0, -2.88417746561779, -27.544194279436248, -2.2019333344980083, 100.0, -10.570833492128152, 0.0, -1.2472329122237158, 90.85904052944039, -46.098103756317094, -7.594391977872267, -18.010370314161662, 57.791084391553056, -5.952443943593013, -18.49979271687351, -5.351132043260206, -1.735662100218226, -5.20171312025686, 20.202488364516825, 20.0, -20.66834020305565, 60.0, -12.097935257602712, 40.0, 33.705962161130735, -0.629409277529418, 28.79865241242523, -19.154207189586547, 58.35172124864877, -13.551619589262563, 8.616782424007734, 94.12926793310632, 20.0, -5.1673682078983925, -8.931821715991974, 20.0, -2.435784561804185, 0.0, 40.0, 0.0, 39.958200702659376, 140.0, -10.71675205296488, -9.234734389786427, 100.05413288658221, 45.59567676228799, 0.0, 54.807158691390896, -12.934002413569397, -0.20980114869707522, -2.2623206830199356, 40.0, 22.999655217251078, 57.04938851908903, 39.33116829090511, 40.0, -8.607975949707804, -2.1692165442228575, 30.406802229994607, -12.95555952224785, 114.06248320886517, -6.570434508221559, 19.233326163152487, 20.0, -13.94358984511856, 57.685114923553755, 73.54728980949136, -0.9316961873903296, 60.0, -5.658046550178102, 0.0, 16.439521963462305, 79.69590239462613, -8.8444369736683, -25.931904828974933, -18.800886255814817, -10.162869962220498, 41.499768120426744, -0.7236647448975497, 2.7754887443202314, -12.655693331404024, 35.15840520371316, -44.90809189706617, 66.03426956256256, -0.8612354563076363, -2.604092204331522, 0.0, 120.0, 60.0, 60.0, -18.378051322087515, 180.0, 100.0, 12.038980019134726, -4.986709699603695, 14.760542532373453, 0.0, 60.0, -6.735260311950861, 54.02202502415663, 40.0, 0.0, 39.914625040679674, -19.550114198360365, -0.5396134638198258, 32.58532282445496, 99.88694647268048, -0.06041173208962691, 58.005255366588415, 6.665531658470095, 23.02727485123028, 0.0, -2.3986230925927288, 100.0, -25.503004900377178, 48.74152867335854, -3.9939250255180374, 29.92120927802344, -6.682857482313885, 80.0, -11.982168293970355, 48.37312002181404, 94.63485970156219, 40.0, 40.0, 0.0, 100.0, -0.15557480358121656, 120.0, -22.96780758266148, 93.64454570550778, 48.13766324148253, 22.920630701556917, -1.640221420552247, 76.14869425336862, 10.80322851347966, 0.0, 20.0, -9.514033898920905, 98.52396796085648, 19.324165443646255, -7.742281178232755, -39.861617448737896, 59.677028375912165], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 90.0, 90.0, 90.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0], "policy_agent_policy_reward": [-10.451777051797066, -16.301444604981526, -48.8796084449299, -3.7351007435382337, -0.2306989086474942, -40.0, -10.0, -25.721771416227174, -14.328121465929652, -43.03297122055949, -34.31466007726499, -24.52370077950967, -10.0, -10.0, -2.88417746561779, -27.544194279436248, -2.2019333344980083, -50.0, -10.570833492128152, 0.0, -1.2472329122237158, -59.14095947055961, -46.098103756317094, -7.594391977872267, -18.010370314161662, -32.20891560844695, -5.952443943593013, -18.49979271687351, -5.351132043260206, -1.735662100218226, -5.20171312025686, -39.797511635483175, -10.0, -20.66834020305565, -30.0, -12.097935257602712, -20.0, -26.29403783886927, -0.629409277529418, -31.20134758757477, -19.154207189586547, -31.648278751351235, -13.551619589262563, -21.383217575992266, -55.870732066893694, -10.0, -5.1673682078983925, -8.931821715991974, -10.0, -2.435784561804185, 0.0, -20.0, 0.0, -20.041799297340624, -70.0, -10.71675205296488, -9.234734389786427, -79.94586711341779, -74.40432323771202, 0.0, -35.1928413086091, -12.934002413569397, -0.20980114869707522, -2.2623206830199356, -20.0, -37.00034478274892, -32.95061148091097, -20.668831709094892, -20.0, -8.607975949707804, -62.16921654422285, -29.593197770005396, -12.95555952224785, -65.93751679113485, -6.570434508221559, -10.766673836847513, -10.0, -13.94358984511856, -32.314885076446245, -46.45271019050864, -30.93169618739033, -30.0, -5.658046550178102, 0.0, -13.560478036537695, -40.304097605373876, -8.8444369736683, -25.931904828974933, -18.800886255814817, -10.162869962220498, -48.500231879573256, -0.7236647448975497, -27.22451125567977, -12.655693331404024, -54.841594796286856, -44.90809189706617, -53.96573043743743, -0.8612354563076363, -2.604092204331522, 0.0, -60.0, -30.0, -30.0, -18.378051322087515, -90.0, -50.0, -17.961019980865274, -4.986709699603695, -15.239457467626547, 0.0, -30.0, -6.735260311950861, -35.97797497584337, -20.0, 0.0, -20.085374959320326, -19.550114198360365, -0.5396134638198258, -27.41467717554503, -50.11305352731952, -0.06041173208962691, -61.99474463341156, -23.334468341529906, -36.972725148769726, 0.0, -2.3986230925927288, -50.0, -25.503004900377178, -41.25847132664147, -3.9939250255180374, -30.07879072197656, -6.682857482313885, -40.0, -11.982168293970355, -41.62687997818596, -55.365140298437815, -20.0, -20.0, 0.0, -50.0, -0.15557480358121656, -60.0, -22.96780758266148, -56.35545429449222, -41.86233675851747, -37.07936929844308, -1.640221420552247, -43.85130574663139, -19.19677148652034, 0.0, -10.0, -9.514033898920905, -51.47603203914351, -40.67583455635375, -7.742281178232755, -39.861617448737896, -30.322971624087838]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6499970565965374, "mean_inference_ms": 1.1182083539737302, "mean_action_processing_ms": 0.24780431464796085, "mean_env_wait_ms": 0.485159276058646, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004516589413782594, "StateBufferConnector_ms": 0.0030994415283203125, "ViewRequirementAgentConnector_ms": 0.08896186852910716}, "num_episodes": 157, "episode_return_max": 180.0, "episode_return_min": -46.098103756317094, "episode_return_mean": 23.43387449071176}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 880000, "num_agent_steps_trained": 880000, "num_env_steps_sampled": 220000, "num_env_steps_trained": 220000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 287.1168689744654, "num_env_steps_trained_throughput_per_sec": 287.1168689744654, "timesteps_total": 220000, "num_env_steps_sampled_lifetime": 220000, "num_agent_steps_sampled_lifetime": 880000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 880000, "timers": {"training_iteration_time_ms": 13926.246, "restore_workers_time_ms": 0.014, "training_step_time_ms": 13926.204, "sample_time_ms": 1136.803, "learn_time_ms": 12773.102, "learn_throughput": 313.158, "synch_weights_time_ms": 15.106}, "counters": {"num_env_steps_sampled": 220000, "num_env_steps_trained": 220000, "num_agent_steps_sampled": 880000, "num_agent_steps_trained": 880000}, "done": false, "training_iteration": 55, "trial_id": "b72b3_00000", "date": "2024-08-08_15-44-48", "timestamp": 1723146288, "time_this_iter_s": 13.959437131881714, "time_total_s": 813.57124376297, "pid": 98177, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x32818dee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 813.57124376297, "iterations_since_restore": 55, "perf": {"cpu_util_percent": 27.450000000000006, "ram_util_percent": 82.47999999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.08208287867407, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.810566254953543, "policy_loss": -0.01754590910107557, "vf_loss": 6.826588360965252, "vf_explained_var": 0.029225460129479568, "kl": 0.007618985847339317, "entropy": 0.9620497867465019, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 53280.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6835533207295634, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.705707847564779, "policy_loss": -0.018164053203452192, "vf_loss": 4.722776300602771, "vf_explained_var": -1.891496333670109e-07, "kl": 0.005477974348247179, "entropy": 0.5696553230708372, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 156510.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 224000, "num_env_steps_trained": 224000, "num_agent_steps_sampled": 896000, "num_agent_steps_trained": 896000}, "env_runners": {"episode_reward_max": 229.1369986321726, "episode_reward_min": -27.74785236283414, "episode_reward_mean": 35.19116353200384, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 158, "episodes_timesteps_total": 3950, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -130.8630013678274}, "policy_reward_max": {"adversary_policy": 120.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 20.31645569620253, "agent_policy": -25.75820355660375}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.0, 20.0, 100.0, -2.4966196976747903, -6.089566336545675, -3.2851859192112354, 39.82908703542692, 26.45191230038291, 120.0, -21.612353307010164, 7.192213988411086, -13.773607142157484, 78.66853577143166, 22.458186094260366, -7.418237958779136, -8.560954377215813, -3.258308855321921, 10.41033269358541, 60.0, 0.0, 40.0, 0.0, 0.0, 40.0, 20.0, 60.0, -8.006868560577942, 35.74811528256992, 58.18213900490363, 20.0, 130.90280039642596, 91.5325507297569, 60.0, 23.387130309194543, 31.462353977984126, 16.857140256108895, 35.325855791433895, 40.0, 98.81171454755076, 140.0, -22.388094001688188, 38.560234377332165, 92.84882241283793, 59.8208708897626, -18.37910393731588, 40.0, -0.21831991264838813, 60.0, 120.0, 16.67136690080035, 52.02422266221315, 59.9330231415685, -5.1355240217935325, 40.0, 40.0, -1.1560280320808602, -0.7071669577559991, 112.09657669307558, 47.76249888711974, 0.0, 76.30465320612325, 40.0, 229.1369986321726, 54.13845155555225, -14.103469173193437, 80.0, 50.26315272725066, 73.1192565280495, -21.547218960825184, 39.645749854209214, 40.0, 60.0, 26.927155805357, -11.168871494338653, 92.3308601532848, -2.858923637623379, 40.0, 19.825548212684133, 56.33968839033236, -17.955501376164868, 11.765029679917557, -4.610773165764774, 100.0, 36.79563171289255, 80.0, 24.794850681016957, -0.33007348546085336, 29.704613296579517, 59.54387247798465, 100.0, -27.74785236283414, -12.340946241853105, 59.06185944143111, -3.235117724893154, 78.67877404805525, -9.677297651340513, 0.0, 20.0, 39.83193325368965, 60.0, 18.46042543743938, 40.0, 36.04567444924666, 111.71151183370068, -16.160044656811884, -5.800573366727142, 58.89432269157952, 100.0, 97.79832615073713, 112.61893094402791, 59.26825177098882, -7.038442590390946, 60.0, 15.873319496605733, 26.65511884938835, -11.629235660742893, 18.30718170674274, -22.448928280209138, 140.0, 0.0, 56.75068633257716, 33.78062865029803, 20.0, 47.496520188886585, 34.291037020303044, -12.082860054250306, 35.105884151212535, 60.0, 16.048789820033484, 0.0, 98.99864280427477, 16.503280404169352, 40.0, -3.1224262358388444, 0.0, 39.93324625244906, -2.460746945667602, 19.847902037993027, 0.0, 120.0, -5.107948452238365, -11.059294244239391, 60.0, -6.43678624480494, 39.86207239233456, 46.8428769985194, 58.74510554638144, -4.469524909994349, 34.88963661996661, 0.0, 0.0, 40.0, 14.504678941384181, 80.0, 57.67628367545254, -15.82107059785794, 40.0, -0.1523943789618465], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 70.0, 70.0, 70.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 60.0, 60.0, 60.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 120.0, 120.0, 120.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 60.0, 60.0, 60.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-20.0, -10.0, -50.0, -2.4966196976747903, -6.089566336545675, -3.2851859192112354, -20.170912964573077, -33.54808769961709, -60.0, -21.612353307010164, -22.807786011588917, -13.773607142157484, -41.331464228568315, -37.54181390573964, -7.418237958779136, -8.560954377215813, -3.258308855321921, -19.58966730641459, -30.0, 0.0, -20.0, 0.0, 0.0, -20.0, -10.0, -30.0, -8.006868560577942, -24.25188471743008, -31.81786099509636, -10.0, -79.09719960357405, -58.46744927024308, -30.0, -36.612869690805454, -28.537646022015874, -13.142859743891105, -24.674144208566105, -20.0, -51.188285452449236, -70.0, -22.388094001688188, -21.439765622667828, -57.15117758716206, -30.179129110237398, -18.37910393731588, -20.0, -0.21831991264838813, -30.0, -60.0, -13.32863309919965, -37.97577733778685, -30.066976858431502, -5.1355240217935325, -20.0, -20.0, -1.1560280320808602, -0.7071669577559991, -67.90342330692442, -42.23750111288026, 0.0, -73.69534679387677, -20.0, -130.8630013678274, -35.86154844444775, -14.103469173193437, -40.0, -39.73684727274934, -46.88074347195048, -21.547218960825184, -20.354250145790786, -20.0, -30.0, -33.072844194643004, -11.168871494338653, -57.6691398467152, -2.858923637623379, -20.0, -10.174451787315865, -63.66031160966764, -17.955501376164868, -48.23497032008244, -4.610773165764774, -50.0, -23.204368287107457, -40.0, -35.20514931898305, -0.33007348546085336, -60.29538670342049, -30.456127522015343, -50.0, -27.74785236283414, -12.340946241853105, -30.93814055856889, -3.235117724893154, -41.321225951944754, -9.677297651340513, 0.0, -10.0, -20.168066746310352, -30.0, -11.53957456256062, -20.0, -23.95432555075334, -68.28848816629932, -16.160044656811884, -5.800573366727142, -31.105677308420482, -50.0, -52.20167384926288, -67.3810690559721, -30.73174822901118, -7.038442590390946, -30.0, -14.126680503394269, -33.34488115061166, -11.629235660742893, -11.692818293257263, -22.448928280209138, -70.0, 0.0, -33.24931366742284, -26.219371349701976, -10.0, -42.50347981111342, -25.70896297969695, -12.082860054250306, -24.894115848787468, -30.0, -13.951210179966516, 0.0, -51.00135719572523, -43.49671959583064, -20.0, -3.1224262358388444, 0.0, -20.06675374755094, -32.4607469456676, -10.152097962006973, 0.0, -60.0, -5.107948452238365, -11.059294244239391, -30.0, -6.43678624480494, -20.13792760766544, -43.1571230014806, -31.25489445361856, -4.469524909994349, -25.11036338003339, 0.0, 0.0, -20.0, -15.495321058615819, -40.0, -32.32371632454746, -15.82107059785794, -20.0, -0.1523943789618465]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6497302555693192, "mean_inference_ms": 1.1177041313227245, "mean_action_processing_ms": 0.24735015755100956, "mean_env_wait_ms": 0.4850308036859403, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005610758745217625, "StateBufferConnector_ms": 0.0032767464842977405, "ViewRequirementAgentConnector_ms": 0.09450746487967576}, "num_episodes": 158, "episode_return_max": 229.1369986321726, "episode_return_min": -27.74785236283414, "episode_return_mean": 35.19116353200384}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 896000, "num_agent_steps_trained": 896000, "num_env_steps_sampled": 224000, "num_env_steps_trained": 224000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 280.2995773640681, "num_env_steps_trained_throughput_per_sec": 280.2995773640681, "timesteps_total": 224000, "num_env_steps_sampled_lifetime": 224000, "num_agent_steps_sampled_lifetime": 896000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 896000, "timers": {"training_iteration_time_ms": 13946.3, "restore_workers_time_ms": 0.018, "training_step_time_ms": 13946.241, "sample_time_ms": 1136.505, "learn_time_ms": 12792.509, "learn_throughput": 312.683, "synch_weights_time_ms": 15.997}, "counters": {"num_env_steps_sampled": 224000, "num_env_steps_trained": 224000, "num_agent_steps_sampled": 896000, "num_agent_steps_trained": 896000}, "done": false, "training_iteration": 56, "trial_id": "b72b3_00000", "date": "2024-08-08_15-45-02", "timestamp": 1723146302, "time_this_iter_s": 14.292772054672241, "time_total_s": 827.8640158176422, "pid": 98177, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3174edca0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 827.8640158176422, "iterations_since_restore": 56, "perf": {"cpu_util_percent": 31.34500000000001, "ram_util_percent": 83.0}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.172120447953542, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.1944388518730795, "policy_loss": -0.02243182070039135, "vf_loss": 6.2153929968674975, "vf_explained_var": -0.0009243880088130633, "kl": 0.007388200686103375, "entropy": 0.9731946245456735, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 54240.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.672162308411818, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.107823502763789, "policy_loss": -0.01845371224009267, "vf_loss": 4.125193927051328, "vf_explained_var": 6.56707912472123e-08, "kl": 0.00541644683235098, "entropy": 0.5453300553222075, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 159330.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 228000, "num_env_steps_trained": 228000, "num_agent_steps_sampled": 912000, "num_agent_steps_trained": 912000}, "env_runners": {"episode_reward_max": 260.0, "episode_reward_min": -40.594140209006625, "episode_reward_mean": 28.996693253634632, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -130.0}, "policy_reward_max": {"adversary_policy": 130.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 17.34567901234568, "agent_policy": -23.04034378340241}, "custom_metrics": {}, "hist_stats": {"episode_reward": [120.0, -2.041625461009508, -0.5893514278180523, 37.38670298050934, 41.239490964794044, -4.062916710952335, 38.62533640258356, 0.0, 11.478374263027897, 20.0, -4.943672793977454, 20.0, 36.426319153354676, 29.672371955363424, 56.35296244789444, -4.641072725661807, 120.0, 9.040415429023255, -8.344889759537747, 160.0, 60.0, 16.509962722445152, 15.432120764934504, -20.851217803550544, 19.532515907650584, -7.282375208711158, 40.0, 60.0, -9.70440834268749, -0.8957042509448798, 20.0, 60.0, 21.31597027390756, 60.0, -10.30304426770781, 69.26739049187479, -8.170501811829938, 20.0, -5.41674301500709, 43.89577514982306, -1.5681825352738243, -19.7669949378747, 18.75573264656482, 99.87660443770368, 60.0, -25.358106870236348, -10.672313509846685, 39.31966181956528, 0.0, -16.753074850918185, -14.793695941951952, 35.080027153588375, 40.0, 20.515024611885792, 40.0, 80.0, 18.89736557738012, 79.67010738330036, 60.0, 20.0, 0.0, 60.0, 57.95982370333672, 260.0, -7.313364372297812, 20.0, 80.0, 119.25181498089934, 19.942589981892514, 0.0, 39.73035302526508, -33.80408777697606, 0.0, -27.973060739977424, -2.394247745382454, 51.31749937302687, -15.039837848353645, 20.0, 100.0, 37.06539876840112, -5.46943615968443, 40.0, 15.775104329972677, -7.6197400919787786, 0.0, -14.956567665903629, 36.47049750939252, -7.96422518274594, -7.699672875803235, -6.420787086376981, 68.54895331410746, -5.627018272400424, 53.687320174611884, 0.0, 60.0, 60.0, 57.61191102707677, 39.148347978555066, 34.35078868410077, 17.734262514008357, -12.477732942013885, 20.092042955815437, 117.65601131411748, 120.0, 80.0, -13.390811371756229, -2.367080565397032, -1.4521835419653684, 119.91021498001754, 0.0, 57.97087887312206, 100.0, 0.0, 98.8119287267169, 47.90681383184659, 39.67447751685315, 4.866177747135444, 20.0, 60.0, -10.337493891779145, -27.367315252229183, 0.0, -14.94417879265005, -20.850215539475847, 0.0, 2.6006553644044113, -40.594140209006625, 51.08759328585378, 60.0, 18.90209242285655, 94.69142635946805, 74.6701472822837, 40.0, 100.0, -7.452452503906618, -24.31958842662212, 0.0, 20.0, -4.859365884257824, -6.149146152169213, -6.903803441536702, -7.878571931690889, 110.10895284135962, -11.321334975281836, 0.0, 60.0, 20.0, 19.40946246438569, 40.0, -16.08124905898641, -15.084736052489765, -12.157328314349753, -4.044999016970658, 17.90919107133108, 38.362607888089016, 54.81798399727447, 59.60641617197044, 60.0, 0.0, 160.0, 80.0, 40.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 80.0, 80.0, 80.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 130.0, 130.0, 130.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 60.0, 60.0, 60.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 60.0, 60.0, 60.0, 60.0, 60.0, 60.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 80.0, 80.0, 80.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0], "policy_agent_policy_reward": [-60.0, -2.041625461009508, -0.5893514278180523, -22.61329701949066, -48.760509035205956, -4.062916710952335, -21.374663597416443, 0.0, -48.521625736972105, -10.0, -4.943672793977454, -10.0, -53.57368084664534, -30.327628044636576, -33.64703755210555, -4.641072725661807, -60.0, -20.959584570976745, -8.344889759537747, -80.0, -30.0, -13.490037277554848, -14.567879235065497, -20.851217803550544, -10.467484092349416, -7.282375208711158, -20.0, -30.0, -9.70440834268749, -0.8957042509448798, -10.0, -30.0, -38.68402972609245, -30.0, -10.30304426770781, -50.73260950812521, -8.170501811829938, -10.0, -5.41674301500709, -46.10422485017694, -1.5681825352738243, -19.7669949378747, -11.24426735343518, -50.12339556229632, -30.0, -25.358106870236348, -10.672313509846685, -20.680338180434713, 0.0, -16.753074850918185, -14.793695941951952, -24.919972846411632, -20.0, -39.48497538811421, -20.0, -40.0, -11.102634422619879, -40.32989261669963, -30.0, -10.0, 0.0, -30.0, -32.04017629666328, -130.0, -7.313364372297812, -10.0, -40.0, -60.74818501910067, -10.057410018107488, 0.0, -20.26964697473492, -33.80408777697606, 0.0, -27.973060739977424, -2.394247745382454, -38.68250062697313, -15.039837848353645, -10.0, -50.0, -22.934601231598883, -5.46943615968443, -20.0, -14.224895670027323, -7.6197400919787786, 0.0, -14.956567665903629, -23.529502490607477, -7.96422518274594, -7.699672875803235, -6.420787086376981, -51.45104668589254, -5.627018272400424, -36.312679825388116, 0.0, -30.0, -30.0, -32.38808897292323, -20.851652021444934, -25.64921131589923, -12.265737485991641, -12.477732942013885, -39.90795704418456, -62.343988685882515, -60.0, -40.0, -13.390811371756229, -2.367080565397032, -1.4521835419653684, -60.08978501998244, 0.0, -32.029121126877925, -50.0, 0.0, -51.18807127328309, -42.09318616815341, -20.325522483146848, -25.133822252864555, -10.0, -30.0, -10.337493891779145, -27.367315252229183, 0.0, -14.94417879265005, -20.850215539475847, 0.0, -27.399344635595586, -40.594140209006625, -38.91240671414622, -30.0, -11.09790757714345, -55.30857364053195, -45.329852717716314, -20.0, -50.0, -7.452452503906618, -24.31958842662212, 0.0, -10.0, -4.859365884257824, -6.149146152169213, -6.903803441536702, -7.878571931690889, -69.89104715864038, -11.321334975281836, 0.0, -30.0, -10.0, -10.590537535614311, -20.0, -16.08124905898641, -15.084736052489765, -12.157328314349753, -4.044999016970658, -12.090808928668926, -21.637392111910984, -35.18201600272554, -30.39358382802956, -30.0, 0.0, -80.0, -40.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.648918558673814, "mean_inference_ms": 1.1165572760790223, "mean_action_processing_ms": 0.2467786729992253, "mean_env_wait_ms": 0.48453747162692373, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005584366527604468, "StateBufferConnector_ms": 0.0031335854235990546, "ViewRequirementAgentConnector_ms": 0.08792928707452467}, "num_episodes": 162, "episode_return_max": 260.0, "episode_return_min": -40.594140209006625, "episode_return_mean": 28.996693253634632}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 912000, "num_agent_steps_trained": 912000, "num_env_steps_sampled": 228000, "num_env_steps_trained": 228000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 290.1908354219701, "num_env_steps_trained_throughput_per_sec": 290.1908354219701, "timesteps_total": 228000, "num_env_steps_sampled_lifetime": 228000, "num_agent_steps_sampled_lifetime": 912000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 912000, "timers": {"training_iteration_time_ms": 13921.685, "restore_workers_time_ms": 0.018, "training_step_time_ms": 13921.628, "sample_time_ms": 1130.044, "learn_time_ms": 12774.871, "learn_throughput": 313.115, "synch_weights_time_ms": 15.5}, "counters": {"num_env_steps_sampled": 228000, "num_env_steps_trained": 228000, "num_agent_steps_sampled": 912000, "num_agent_steps_trained": 912000}, "done": false, "training_iteration": 57, "trial_id": "b72b3_00000", "date": "2024-08-08_15-45-16", "timestamp": 1723146316, "time_this_iter_s": 13.792527914047241, "time_total_s": 841.6565437316895, "pid": 98177, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3281945e0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 841.6565437316895, "iterations_since_restore": 57, "perf": {"cpu_util_percent": 28.155, "ram_util_percent": 83.165}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.2390465368827184, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.3668025578061735, "policy_loss": -0.023502242353667196, "vf_loss": 6.388288565476736, "vf_explained_var": 0.008191959063212077, "kl": 0.01008121534688411, "entropy": 0.940102398643891, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 55200.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7048692530562691, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.9452747053288397, "policy_loss": -0.018508248515460138, "vf_loss": 3.962682845913772, "vf_explained_var": 9.005374096809549e-07, "kl": 0.005500540672403033, "entropy": 0.5663378718579914, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 162150.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 232000, "num_env_steps_trained": 232000, "num_agent_steps_sampled": 928000, "num_agent_steps_trained": 928000}, "env_runners": {"episode_reward_max": 178.99157732710796, "episode_reward_min": -40.990099874482645, "episode_reward_mean": 32.84586338704833, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -91.00842267289204}, "policy_reward_max": {"adversary_policy": 90.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 19.012345679012345, "agent_policy": -24.191173649988706}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.0, 80.0, -1.4674936361716973, -8.151362143495467, 77.89853504384415, -10.857167314150034, 66.69297252225468, 40.0, 8.392835075187858, 72.66684470437981, -0.6439231225042685, -5.947251615675424, -6.372705608949782, 80.0, 42.71709884433153, 71.3944871851202, -11.441635896779745, 0.0, 59.7447088210852, -18.84760915683312, 117.575411967076, 133.1055540658162, 75.5589101381311, -5.827525487650568, -17.179669193692835, 59.90707258739978, -0.24503017807290917, 19.983177278403172, 99.63625447085849, -3.4059350898832497, -6.888650794118079, -0.04707150247550085, -13.559366280652352, 60.0, 32.724871270440616, 60.0, 0.0, 53.55965588492854, 40.0, 0.0, 39.82336926446301, 59.95870679224003, 40.0, 20.0, 56.3784866436354, 58.02264268725785, 0.0, 0.0, -8.574516621708575, -3.0550308598221596, -16.602562380086574, 80.0, 99.68856147665514, 37.84380440957035, 0.0, -3.9261674735089382, 0.0, 38.072597364244665, 79.96540558425696, 36.53302470643836, 100.0, 20.0, -12.336295429580847, -20.53341483224336, 18.893142167162694, -23.938482089948707, 52.626313496308, 80.0, -24.38415089442989, 20.0, 40.0, -40.990099874482645, -31.83778719612394, 56.36938607228102, 0.0, 56.195979576223394, 140.0, 58.70148487917165, 60.0, 73.7549331896203, 82.55157412920775, 49.964838157680624, 0.0, -1.7167954254129292, -0.2214086411128302, 6.268329390889519, 117.73204123050232, 93.67439848690906, -6.65914067892847, -1.2778337196848066, 0.0, 53.65569489256442, 47.74013005672636, 80.0, 178.99157732710796, -25.05019251078982, 19.492528943391417, 74.87100436291995, -0.44664009476565014, -1.77514468533593, 120.0, 60.0, 19.974679504552675, -0.9733410697414213, 0.0, -2.3618068253680446, -0.3593608727430331, 30.373431385101647, 60.0, -4.348132175002599, 60.0, 48.75023994425178, 20.0, -12.297877944369386, 40.0, 19.443647661839904, 7.17780257240645, -3.2878905960546954, 100.0, 40.0, 20.0, 120.0, 55.627459351293226, 15.31709813422858, -5.510024777574496, 60.0, 53.09116276657136, 16.490519129003058, -3.190093749653972, -28.46693928392569, -0.1919182630102534, 138.72048592767828, 35.848954379535854, 19.184150244987624, 15.896073830241692, -3.0109903895511887, 0.0, 60.0, -8.53544895415879, 82.13631564987203, 73.11057734752399, 40.0, 53.518569794092556, 49.3660022904619, -0.21733530730086104, -2.450102964294559, 72.95102595323883, -0.3272878617078556, 40.0, 6.767783524256087, -19.59953575974579, 0.0, 20.0, -1.3002443618890547, 120.0, 0.0, 40.0, 159.44807246995077, 0.0, 19.143863279218877, 40.0, 80.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 70.0, 70.0, 70.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 70.0, 70.0, 70.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 60.0, 60.0, 60.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 90.0, 90.0, 90.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 60.0, 60.0, 60.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 80.0, 80.0, 80.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0], "policy_agent_policy_reward": [-20.0, -40.0, -1.4674936361716973, -8.151362143495467, -42.10146495615585, -10.857167314150034, -53.307027477745336, -20.0, -21.607164924812142, -47.33315529562019, -0.6439231225042685, -5.947251615675424, -6.372705608949782, -40.0, -47.28290115566847, -48.60551281487981, -11.441635896779745, 0.0, -30.2552911789148, -18.84760915683312, -62.42458803292401, -76.89444593418382, -44.44108986186891, -5.827525487650568, -17.179669193692835, -30.092927412600222, -0.24503017807290917, -10.016822721596828, -50.36374552914151, -3.4059350898832497, -6.888650794118079, -0.04707150247550085, -13.559366280652352, -30.0, -27.275128729559388, -30.0, 0.0, -36.44034411507146, -20.0, 0.0, -20.176630735536985, -30.04129320775997, -20.0, -10.0, -33.6215133563646, -31.977357312742154, 0.0, 0.0, -8.574516621708575, -3.0550308598221596, -16.602562380086574, -40.0, -50.311438523344854, -22.15619559042965, 0.0, -3.9261674735089382, 0.0, -51.927402635755335, -40.03459441574304, -23.466975293561642, -50.0, -10.0, -12.336295429580847, -20.53341483224336, -11.106857832837306, -23.938482089948707, -37.373686503692, -40.0, -24.38415089442989, -10.0, -20.0, -40.990099874482645, -31.83778719612394, -33.63061392771898, 0.0, -33.804020423776606, -70.0, -31.298515120828345, -30.0, -46.24506681037969, -67.44842587079224, -40.03516184231938, 0.0, -1.7167954254129292, -0.2214086411128302, -23.731670609110484, -62.26795876949768, -56.325601513090966, -6.65914067892847, -1.2778337196848066, 0.0, -66.34430510743559, -42.25986994327364, -40.0, -91.00842267289204, -25.05019251078982, -40.507471056608594, -45.128995637080045, -0.44664009476565014, -1.77514468533593, -60.0, -30.0, -10.025320495447325, -0.9733410697414213, 0.0, -2.3618068253680446, -0.3593608727430331, -29.62656861489835, -30.0, -4.348132175002599, -30.0, -41.24976005574822, -10.0, -12.297877944369386, -20.0, -10.556352338160096, -22.82219742759355, -3.2878905960546954, -50.0, -20.0, -10.0, -60.0, -34.372540648706774, -14.68290186577142, -5.510024777574496, -30.0, -36.90883723342865, -13.509480870996944, -33.190093749653975, -28.46693928392569, -0.1919182630102534, -71.27951407232173, -24.151045620464142, -10.815849755012376, -14.103926169758308, -3.0109903895511887, 0.0, -30.0, -8.53544895415879, -67.86368435012795, -46.889422652476014, -20.0, -36.481430205907444, -40.6339977095381, -0.21733530730086104, -2.450102964294559, -47.04897404676116, -0.3272878617078556, -20.0, -23.232216475743915, -19.59953575974579, 0.0, -10.0, -1.3002443618890547, -60.0, 0.0, -20.0, -80.55192753004921, 0.0, -10.856136720781123, -20.0, -40.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.648225309213224, "mean_inference_ms": 1.1154262557821057, "mean_action_processing_ms": 0.24620381554745627, "mean_env_wait_ms": 0.48425229000437753, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0043371577321747205, "StateBufferConnector_ms": 0.0030656655629475913, "ViewRequirementAgentConnector_ms": 0.08936671563136725}, "num_episodes": 162, "episode_return_max": 178.99157732710796, "episode_return_min": -40.990099874482645, "episode_return_mean": 32.84586338704833}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 928000, "num_agent_steps_trained": 928000, "num_env_steps_sampled": 232000, "num_env_steps_trained": 232000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 292.87577033828626, "num_env_steps_trained_throughput_per_sec": 292.87577033828626, "timesteps_total": 232000, "num_env_steps_sampled_lifetime": 232000, "num_agent_steps_sampled_lifetime": 928000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 928000, "timers": {"training_iteration_time_ms": 13887.994, "restore_workers_time_ms": 0.018, "training_step_time_ms": 13887.938, "sample_time_ms": 1125.583, "learn_time_ms": 12745.156, "learn_throughput": 313.845, "synch_weights_time_ms": 15.971}, "counters": {"num_env_steps_sampled": 232000, "num_env_steps_trained": 232000, "num_agent_steps_sampled": 928000, "num_agent_steps_trained": 928000}, "done": false, "training_iteration": 58, "trial_id": "b72b3_00000", "date": "2024-08-08_15-45-30", "timestamp": 1723146330, "time_this_iter_s": 13.677026987075806, "time_total_s": 855.3335707187653, "pid": 98177, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x328194820>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 855.3335707187653, "iterations_since_restore": 58, "perf": {"cpu_util_percent": 29.550000000000004, "ram_util_percent": 83.17999999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.500869780903061, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.267075636486212, "policy_loss": -0.023201116489023357, "vf_loss": 6.288233796258767, "vf_explained_var": -0.02287723800788323, "kl": 0.01021489617066041, "entropy": 0.9329666582867503, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 56160.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6734089454120779, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.6847700620373938, "policy_loss": -0.018819628860008843, "vf_loss": 3.7023862291735115, "vf_explained_var": -8.855939756893943e-07, "kl": 0.006017286601166686, "entropy": 0.5470988505064173, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 164970.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 236000, "num_env_steps_trained": 236000, "num_agent_steps_sampled": 944000, "num_agent_steps_trained": 944000}, "env_runners": {"episode_reward_max": 220.0, "episode_reward_min": -28.712849560025003, "episode_reward_mean": 31.94660950724765, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 157, "episodes_timesteps_total": 3925, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -110.0}, "policy_reward_max": {"adversary_policy": 110.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 18.78980891719745, "agent_policy": -24.422817244344703}, "custom_metrics": {}, "hist_stats": {"episode_reward": [77.6806891199191, 16.61540545301977, 54.55907498316448, -5.143383031515531, 35.221078525317694, 80.0, 11.270885468088338, 140.0, 9.934659348845651, 60.0, 20.0, 80.0, 15.913997549782554, -28.712849560025003, 40.0, 6.2407307726180505, -0.2219390846759517, -2.969866213796582, -10.21131212854136, 0.0, 56.71634163785389, -14.396301915281931, 39.40280037869211, 0.0, 20.0, -7.118597324406046, 39.813298716908, -2.8169017519152257, 100.0, -4.127608075781849, 59.20121764224456, -25.16781840338453, -1.4707150482301556, 60.0, -25.451131137542408, 120.0, 18.14163611838713, 14.013927764137179, 47.153217621414036, 37.44252916907014, 79.64137713987108, 75.06739209751697, 19.637056743048166, 0.0, -1.8005989137552523, 38.90563375998917, -5.6942416077357, 60.0, 0.0, -14.846531150694066, 51.24275925053519, 40.0, 60.0, 35.076363677418186, -14.361687071771962, 65.4416324323028, 40.0, -3.408635270818822, 53.343407009885915, 6.631552241662169, 10.445986708590247, -8.49992948612032, 0.0, 60.0, -15.13773524670477, 60.0, -2.0337572759941356, 85.56272905204736, -2.578276246103809, 40.0, 0.0, -7.182711645201592, 12.383590712130006, -21.942355780003187, 60.0, -12.416592339309524, 99.7110610938613, -5.506299566176485, 57.20811910342425, -2.258277285045401, 119.0102062100432, 79.00188114494324, -7.340806186400932, 53.58861445154609, 0.0, 60.0, 19.330708517675667, 144.1842028632235, -8.288610782858608, 17.341268512764696, 120.0, 60.0, 27.30512931946793, -1.9740463465759672, 140.0, 40.0, 80.0, 40.0, 17.59900030280494, 20.0, 15.460471130769612, -5.415973750231739, -12.871001145337052, 0.0, 0.0, 56.066951722223465, -7.066301172328158, 115.67013927375757, -12.277708659925446, 17.63481059220706, 92.21740177538283, 55.58380480063741, 39.50715139393289, 0.0, -6.316213279592424, 105.23379853508283, 120.0, 0.0, 220.0, 80.0, -2.7231610545878677, -1.478188122854982, -10.883283483176344, 100.0, 0.0, 109.28009024748454, 60.0, 54.75790908969918, 0.0, -17.046517082033976, -18.979406591507733, -10.8101015854545, -1.0929380957749601, 13.641805676527069, 40.0, 49.36018899115027, 29.696994352649234, 60.0, -0.12931399746157313, 60.0, -23.75694032296282, 38.522787922565385, -4.7814049402141885, 73.57520783316706, 12.733366969333538, 57.66909692248463, 0.0, 0.0, 27.101763637154008, 79.39457134492109, -3.4066015880817724, 0.0, 73.97698256984737, 33.14622294153763, 60.0, 9.15999582712111, 51.359587221924144], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 70.0, 70.0, 70.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 80.0, 80.0, 80.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 60.0, 60.0, 60.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 110.0, 110.0, 110.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0], "policy_agent_policy_reward": [-42.31931088008089, -13.384594546980233, -35.440925016835514, -5.143383031515531, -24.778921474682306, -40.0, -48.72911453191166, -70.0, -20.06534065115435, -30.0, -10.0, -40.0, -14.086002450217444, -28.712849560025003, -20.0, -23.75926922738195, -0.2219390846759517, -2.969866213796582, -10.21131212854136, 0.0, -33.283658362146106, -14.396301915281931, -20.597199621307887, 0.0, -10.0, -7.118597324406046, -20.186701283092, -2.8169017519152257, -50.0, -4.127608075781849, -30.79878235775545, -25.16781840338453, -1.4707150482301556, -30.0, -25.451131137542408, -60.0, -11.85836388161287, -15.986072235862821, -42.846782378585964, -22.557470830929855, -40.358622860128925, -44.93260790248305, -10.362943256951834, 0.0, -31.80059891375524, -51.094366240010814, -5.6942416077357, -30.0, 0.0, -14.846531150694066, -38.75724074946482, -20.0, -30.0, -24.923636322581814, -14.361687071771962, -54.5583675676972, -20.0, -3.408635270818822, -36.656592990114085, -23.36844775833783, -19.554013291409756, -8.49992948612032, 0.0, -30.0, -15.13773524670477, -30.0, -2.0337572759941356, -64.43727094795264, -2.578276246103809, -20.0, 0.0, -7.182711645201592, -47.61640928787, -21.942355780003187, -30.0, -12.416592339309524, -50.28893890613871, -5.506299566176485, -32.79188089657574, -2.258277285045401, -60.989793789956806, -40.99811885505676, -7.340806186400932, -36.411385548453914, 0.0, -30.0, -10.669291482324335, -95.81579713677648, -8.288610782858608, -12.658731487235304, -60.0, -30.0, -32.69487068053207, -1.9740463465759672, -70.0, -20.0, -40.0, -20.0, -12.400999697195063, -10.0, -14.53952886923039, -5.415973750231739, -12.871001145337052, 0.0, 0.0, -33.933048277776535, -7.066301172328158, -64.32986072624243, -12.277708659925446, -12.365189407792938, -57.78259822461719, -34.416195199362576, -20.492848606067113, 0.0, -6.316213279592424, -74.76620146491717, -60.0, 0.0, -110.0, -40.0, -2.7231610545878677, -1.478188122854982, -10.883283483176344, -50.0, 0.0, -70.71990975251543, -30.0, -35.242090910300824, 0.0, -47.04651708203397, -18.979406591507733, -10.8101015854545, -1.0929380957749601, -16.358194323472933, -20.0, -40.63981100884973, -30.303005647350755, -30.0, -0.12931399746157313, -30.0, -23.75694032296282, -51.477212077434615, -4.7814049402141885, -46.42479216683293, -17.266633030666462, -32.33090307751537, 0.0, 0.0, -32.898236362846, -40.60542865507891, -3.4066015880817724, 0.0, -46.02301743015264, -26.85377705846237, -30.0, -20.840004172878896, -38.64041277807586]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6472874785002094, "mean_inference_ms": 1.113940795661317, "mean_action_processing_ms": 0.24553889605861134, "mean_env_wait_ms": 0.48366706995258346, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004642632356874502, "StateBufferConnector_ms": 0.0033489458120552597, "ViewRequirementAgentConnector_ms": 0.08731564139104953}, "num_episodes": 157, "episode_return_max": 220.0, "episode_return_min": -28.712849560025003, "episode_return_mean": 31.94660950724765}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 944000, "num_agent_steps_trained": 944000, "num_env_steps_sampled": 236000, "num_env_steps_trained": 236000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 288.0121881988899, "num_env_steps_trained_throughput_per_sec": 288.0121881988899, "timesteps_total": 236000, "num_env_steps_sampled_lifetime": 236000, "num_agent_steps_sampled_lifetime": 944000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 944000, "timers": {"training_iteration_time_ms": 13871.314, "restore_workers_time_ms": 0.026, "training_step_time_ms": 13871.177, "sample_time_ms": 1130.603, "learn_time_ms": 12723.13, "learn_throughput": 314.388, "synch_weights_time_ms": 16.036}, "counters": {"num_env_steps_sampled": 236000, "num_env_steps_trained": 236000, "num_agent_steps_sampled": 944000, "num_agent_steps_trained": 944000}, "done": false, "training_iteration": 59, "trial_id": "b72b3_00000", "date": "2024-08-08_15-45-44", "timestamp": 1723146344, "time_this_iter_s": 13.94254994392395, "time_total_s": 869.2761206626892, "pid": 98177, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x328194ee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 869.2761206626892, "iterations_since_restore": 59, "perf": {"cpu_util_percent": 31.080000000000002, "ram_util_percent": 83.1}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.6153734010954697, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.087251510471106, "policy_loss": -0.024279519665287807, "vf_loss": 6.109708671768506, "vf_explained_var": -0.04150447907547156, "kl": 0.009111897924574074, "entropy": 0.9167653360714515, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 57120.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6411183160881624, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.471641082966581, "policy_loss": -0.01671090492436246, "vf_loss": 3.4873485519530925, "vf_explained_var": -1.047097199352075e-06, "kl": 0.005017177749628974, "entropy": 0.5175116701751736, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 167790.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 240000, "num_env_steps_trained": 240000, "num_agent_steps_sampled": 960000, "num_agent_steps_trained": 960000}, "env_runners": {"episode_reward_max": 159.41218245917625, "episode_reward_min": -28.45099113225225, "episode_reward_mean": 24.738938550836956, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -80.58781754082375}, "policy_reward_max": {"adversary_policy": 80.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 15.679012345679013, "agent_policy": -22.298098486200082}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-10.43262458466756, 60.0, -1.7160285385422869, 80.0, -0.7735600868742254, 40.0, 27.92938165345368, 40.0, 12.468984149779125, 20.0, 80.0, 138.90677587706432, 0.0, 27.096258600762035, -14.962743387208327, 13.50963890250354, 59.61915772956743, 5.357392188359544, 60.0, 2.1856207808494634, 26.389459234890825, 17.589212265341587, -10.310631633067178, 14.509631202367196, -6.6005184003501, 59.75600995568882, 47.25104513902453, 40.0, 79.76622403351708, -15.341451548367548, -2.5793359507928715, 40.0, 112.62137488698727, 0.0, -8.124303785238112, 40.0, -15.131448155241971, 40.0, 20.0, -6.71278595824466, 20.0, -1.5515010220848602, -9.142122987051273, -3.335091787812684, 11.710635140432965, 49.99643393135377, 20.0, -4.748948342763525, 41.54916370046474, 17.52027311650447, 0.0, 20.0, 29.31511508072121, -8.873726466368849, 59.345768586487964, -1.6775034164428992, 44.5923175370522, 0.0, 48.40407646944083, 20.0, 4.828132075679882, 85.77357231331962, 37.73743148060865, 100.0, 35.42923806654126, -20.376934621424354, -11.177590060025606, 28.410448651473963, -16.552280989513815, 0.0, -6.511996366302553, 20.0, -24.364019085972824, 44.84729303884498, 28.49361170047369, 79.26267782094104, 0.0, 58.991476948270844, 0.0, 60.0, -10.941227118385807, -5.194091006343259, 0.0, 83.49769280681663, 29.708245414821132, 52.32591241203734, 12.091605842898348, 52.13076937464404, 36.48335175189286, 0.0, 38.659597495778804, -10.73095964586134, -28.45099113225225, 60.0, 33.00521326169888, 119.1285376018156, 0.0, 19.490617591439083, 40.21433337207893, 60.0, -7.791228287511977, 19.378492069707804, 40.605372632806116, -13.623332117593353, -20.080746584333443, 40.0, 0.0, 64.82688017865613, 60.0, -3.3142702620764757, 4.670134762888142, 25.05374569201054, 19.95958258385778, 0.0, 20.0, -13.691546812813508, -24.3532427712436, -12.029501317816793, 0.0, 60.0, -0.4526496573679095, -10.422203926852616, 159.41218245917625, 44.92571338772114, 40.0, -1.1136923570670054, -4.421128948491639, -7.019024521221544, 46.66308093280576, 99.43896572398735, -9.918540580749294, 20.0, -4.312952753204539, 57.34671573982182, -0.09493012798470146, 36.18380163849637, 19.324761990557512, 19.61086495367717, -1.270131315923403, 76.13120241546915, 31.49796455316997, -0.08028229162966638, 0.0, 99.87459147577644, -3.7950572161331477, -4.180327037253221, -8.39975138289789, 56.6797005000821, 54.35642863130338, 40.0, 54.12842083520421, -2.59222441324364, 51.38242140761905, 78.61197349321542, 60.0, 1.8578082266152631, -0.21385329355538607, -21.783640830666926, 10.792204582184155, 0.0, 18.801014462667368, 99.56298560625287], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 80.0, 80.0, 80.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0], "policy_agent_policy_reward": [-10.43262458466756, -30.0, -1.7160285385422869, -40.0, -0.7735600868742254, -20.0, -32.07061834654633, -20.0, -47.531015850220875, -10.0, -40.0, -71.09322412293567, 0.0, -32.903741399237965, -14.962743387208327, -46.49036109749647, -30.380842270432574, -24.642607811640456, -30.0, -27.814379219150535, -33.61054076510918, -12.410787734658411, -10.310631633067178, -15.490368797632804, -6.6005184003501, -30.243990044311182, -42.74895486097547, -20.0, -40.233775966482916, -15.341451548367548, -2.5793359507928715, -20.0, -67.37862511301273, 0.0, -38.12430378523811, -20.0, -15.131448155241971, -20.0, -10.0, -6.71278595824466, -10.0, -1.5515010220848602, -9.142122987051273, -3.335091787812684, -18.28936485956703, -40.003566068646215, -10.0, -4.748948342763525, -48.450836299535275, -12.479726883495532, 0.0, -10.0, -30.684884919278794, -8.873726466368849, -30.654231413512036, -1.6775034164428992, -45.4076824629478, 0.0, -41.59592353055917, -10.0, -55.17186792432012, -64.22642768668038, -22.262568519391348, -50.0, -24.570761933458726, -20.376934621424354, -11.177590060025606, -61.58955134852604, -16.552280989513815, 0.0, -6.511996366302553, -10.0, -24.364019085972824, -45.15270696115502, -31.506388299526325, -40.737322179058964, 0.0, -31.008523051729163, 0.0, -30.0, -10.941227118385807, -5.194091006343259, 0.0, -66.50230719318337, -60.291754585178865, -37.67408758796265, -17.908394157101654, -37.86923062535596, -23.51664824810713, 0.0, -21.3404025042212, -10.73095964586134, -28.45099113225225, -30.0, -26.994786738301126, -60.87146239818439, 0.0, -10.509382408560917, -49.78566662792107, -30.0, -7.791228287511977, -10.621507930292198, -49.39462736719389, -13.623332117593353, -20.080746584333443, -20.0, 0.0, -55.17311982134389, -30.0, -3.3142702620764757, -25.329865237111857, -34.94625430798945, -10.040417416142219, 0.0, -10.0, -13.691546812813508, -24.3532427712436, -12.029501317816793, 0.0, -30.0, -0.4526496573679095, -10.422203926852616, -80.58781754082375, -45.07428661227887, -20.0, -1.1136923570670054, -4.421128948491639, -7.019024521221544, -43.33691906719424, -50.56103427601265, -9.918540580749294, -10.0, -4.312952753204539, -32.65328426017818, -0.09493012798470146, -23.816198361503623, -10.67523800944249, -10.389135046322833, -1.270131315923403, -43.868797584530846, -28.50203544683003, -0.08028229162966638, 0.0, -50.125408524223566, -3.7950572161331477, -4.180327037253221, -8.39975138289789, -33.3202994999179, -35.64357136869663, -20.0, -35.87157916479578, -2.59222441324364, -38.61757859238095, -41.38802650678457, -30.0, -28.142191773384734, -0.21385329355538607, -21.783640830666926, -19.207795417815845, 0.0, -11.198985537332632, -50.437014393747134]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6471531975241652, "mean_inference_ms": 1.1137037347445393, "mean_action_processing_ms": 0.2452047271766109, "mean_env_wait_ms": 0.48360633136261233, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005172064274917414, "StateBufferConnector_ms": 0.004539445594505027, "ViewRequirementAgentConnector_ms": 0.09342770517608266}, "num_episodes": 162, "episode_return_max": 159.41218245917625, "episode_return_min": -28.45099113225225, "episode_return_mean": 24.738938550836956}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 960000, "num_agent_steps_trained": 960000, "num_env_steps_sampled": 240000, "num_env_steps_trained": 240000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 289.6251352642624, "num_env_steps_trained_throughput_per_sec": 289.6251352642624, "timesteps_total": 240000, "num_env_steps_sampled_lifetime": 240000, "num_agent_steps_sampled_lifetime": 960000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 960000, "timers": {"training_iteration_time_ms": 13844.674, "restore_workers_time_ms": 0.026, "training_step_time_ms": 13844.536, "sample_time_ms": 1138.122, "learn_time_ms": 12689.031, "learn_throughput": 315.233, "synch_weights_time_ms": 16.024}, "counters": {"num_env_steps_sampled": 240000, "num_env_steps_trained": 240000, "num_agent_steps_sampled": 960000, "num_agent_steps_trained": 960000}, "done": false, "training_iteration": 60, "trial_id": "b72b3_00000", "date": "2024-08-08_15-45-58", "timestamp": 1723146358, "time_this_iter_s": 13.817605972290039, "time_total_s": 883.0937266349792, "pid": 98177, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x328194f70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 883.0937266349792, "iterations_since_restore": 60, "perf": {"cpu_util_percent": 28.210526315789473, "ram_util_percent": 82.05789473684212}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.370971141134699, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.451238262156646, "policy_loss": -0.019365158090173886, "vf_loss": 6.468919733166695, "vf_explained_var": -0.031547030247747895, "kl": 0.008418402164688794, "entropy": 0.9109989647443096, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 58080.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6425640646553209, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.344444353107019, "policy_loss": -0.01894861076811049, "vf_loss": 4.36223773626571, "vf_explained_var": 2.485217777549798e-07, "kl": 0.005776168219399878, "entropy": 0.5337807957373613, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 170610.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 244000, "num_env_steps_trained": 244000, "num_agent_steps_sampled": 976000, "num_agent_steps_trained": 976000}, "env_runners": {"episode_reward_max": 220.0, "episode_reward_min": -34.75726673520188, "episode_reward_mean": 33.07287020565453, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 158, "episodes_timesteps_total": 3950, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -110.0}, "policy_reward_max": {"adversary_policy": 110.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 19.240506329113924, "agent_policy": -24.648648781687243}, "custom_metrics": {}, "hist_stats": {"episode_reward": [32.37254614862153, 16.643412628528253, 10.60462474208405, -6.133176055056364, 39.69088451820687, 92.5458339260399, 56.271624039253936, 67.3649266205043, 53.05508248566475, -16.203055295487275, 0.0, 40.0, 11.344754190066514, 18.096006877025953, 80.0, 111.92024140409208, 35.396153670561056, 40.0, -1.7518550527788623, -2.3950318368762824, 78.74419789433385, 155.5662738869292, 59.52667684226299, 220.0, 40.0, 0.0, -1.8198494105097074, 19.86735551410633, 20.0, 60.0, 0.0, -6.268469685593358, -23.60592059273908, -1.9521747094231579, 16.528278626859112, -6.555726628773457, 60.0, -8.091107651849384, 35.98064938959877, 48.498717351857756, 27.159712188772644, -1.0025340966942398, 23.59591753585775, 20.0, 60.0, 19.365312188787847, 59.90313868587434, 7.283377271464272, 20.0, -4.453860110537362, -21.9700599125188, 15.024314719927226, 0.0, 19.064378140434396, 40.0, -12.154339325466397, 40.0, 0.0, 40.0, 0.0, 79.99279773029825, 0.0, -10.240866596599872, 7.360921797997646, 40.0, 26.987435862657374, 0.0, 54.881765209920744, 35.589110966880796, -13.254639131227185, 0.0, -15.537751054884582, 35.71176066262247, 34.9641631356531, 40.0, -13.518336483448943, -6.835612284432294, 31.87451805060061, 60.0, 33.494363997687394, 59.864396880677795, 36.164126132453866, 59.54701398492564, 78.53462446004912, 0.0, 39.8361858255828, 40.0, 60.0, -5.525073334672418, 15.04204308566198, 40.0, 113.69167715976081, 38.85514173251445, 74.44705879729547, 32.959288247066006, -1.5850990536686527, 32.685950662655515, 0.0, -15.927111719479067, -10.440445500600482, -34.75726673520188, 98.27497119483144, 98.41570582872524, 33.26089425467103, 51.62988287745854, -2.4232674017286557, -19.849104080128175, 77.31312023257618, 38.178880339029845, 97.32954438073159, 45.07749879398324, 174.13991743266504, 38.81243287119068, 16.789272707097297, -7.394169859401927, 0.0, 31.879926307190104, 32.50068661137478, 53.184250445391115, 0.0, 110.91942417372557, 26.89304627598809, 0.26758934109211907, 78.87620867949198, 59.32922504251975, 98.54450707320076, -4.314050872250312, 47.197021201784295, 0.0, 40.0, -3.226140465564368, 0.0, -1.0943467846484034, 36.90359882453279, 60.0, 0.0, 37.979459002079494, 21.95806076183311, -25.94414328775193, 169.68297050315655, 94.39606051065226, -8.15997966645945, 50.208373373670824, 20.0, 80.0, 100.0, 100.0, -4.579314291182692, 66.9952381700648, 39.87212217613884, 0.0, -10.97983238974973, 60.0, 10.991320681360436, 80.0, -16.212150659489755, 39.96940857140436, 40.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 80.0, 80.0, 80.0, 30.0, 30.0, 30.0, 110.0, 110.0, 110.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 60.0, 60.0, 60.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 90.0, 90.0, 90.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 90.0, 90.0, 90.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0], "policy_agent_policy_reward": [-27.62745385137847, -13.356587371471747, -19.39537525791595, -6.133176055056364, -20.309115481793132, -57.45416607396011, -33.728375960746064, -52.635073379495694, -36.94491751433525, -16.203055295487275, 0.0, -20.0, -18.65524580993349, -11.903993122974045, -40.0, -68.07975859590793, -24.603846329438948, -20.0, -1.7518550527788623, -2.3950318368762824, -41.255802105666135, -84.4337261130708, -30.473323157737013, -110.0, -20.0, 0.0, -1.8198494105097074, -10.132644485893671, -10.0, -30.0, 0.0, -6.268469685593358, -23.60592059273908, -1.9521747094231579, -13.471721373140888, -6.555726628773457, -30.0, -8.091107651849384, -24.019350610401233, -41.50128264814223, -32.840287811227356, -1.0025340966942398, -36.40408246414224, -10.0, -30.0, -10.634687811212155, -30.09686131412566, -22.71662272853573, -10.0, -4.453860110537362, -21.9700599125188, -14.975685280072772, 0.0, -10.935621859565604, -20.0, -12.154339325466397, -20.0, 0.0, -20.0, 0.0, -40.00720226970176, 0.0, -10.240866596599872, -22.63907820200235, -20.0, -33.01256413734262, 0.0, -35.118234790079256, -24.410889033119208, -13.254639131227185, 0.0, -15.537751054884582, -24.28823933737753, -25.035836864346887, -20.0, -13.518336483448943, -6.835612284432294, -28.12548194939938, -30.0, -26.50563600231262, -30.13560311932221, -53.835873867546134, -30.452986015074355, -41.465375539950884, 0.0, -20.1638141744172, -20.0, -30.0, -5.525073334672418, -14.957956914338018, -20.0, -66.30832284023919, -21.144858267485553, -45.552941202704545, -27.040711752933994, -1.5850990536686527, -27.314049337344482, 0.0, -15.927111719479067, -10.440445500600482, -34.75726673520188, -51.725028805168556, -81.58429417127476, -56.73910574532897, -38.370117122541465, -2.4232674017286557, -19.849104080128175, -42.68687976742381, -21.82111966097015, -52.67045561926841, -44.92250120601677, -95.86008256733494, -21.187567128809324, -13.210727292902703, -7.394169859401927, 0.0, -28.120073692809896, -27.49931338862522, -36.815749554608885, 0.0, -69.08057582627443, -33.10695372401191, -29.73241065890788, -41.12379132050801, -30.670774957480244, -51.45549292679924, -4.314050872250312, -42.802978798215705, 0.0, -20.0, -3.226140465564368, 0.0, -1.0943467846484034, -23.096401175467207, -30.0, 0.0, -22.02054099792051, -38.04193923816689, -25.94414328775193, -100.31702949684339, -55.60393948934774, -8.15997966645945, -39.79162662632916, -10.0, -40.0, -50.0, -50.0, -4.579314291182692, -53.004761829935205, -20.127877823861162, 0.0, -10.97983238974973, -30.0, -19.008679318639565, -40.0, -16.212150659489755, -20.03059142859564, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6461389232433926, "mean_inference_ms": 1.1122498494679205, "mean_action_processing_ms": 0.24476673798544044, "mean_env_wait_ms": 0.48310706228602546, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005765730821633641, "StateBufferConnector_ms": 0.003229892706569237, "ViewRequirementAgentConnector_ms": 0.08749328082120872}, "num_episodes": 158, "episode_return_max": 220.0, "episode_return_min": -34.75726673520188, "episode_return_mean": 33.07287020565453}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 976000, "num_agent_steps_trained": 976000, "num_env_steps_sampled": 244000, "num_env_steps_trained": 244000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 292.79826757525285, "num_env_steps_trained_throughput_per_sec": 292.79826757525285, "timesteps_total": 244000, "num_env_steps_sampled_lifetime": 244000, "num_agent_steps_sampled_lifetime": 976000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 976000, "timers": {"training_iteration_time_ms": 13797.711, "restore_workers_time_ms": 0.026, "training_step_time_ms": 13797.574, "sample_time_ms": 1132.329, "learn_time_ms": 12649.381, "learn_throughput": 316.221, "synch_weights_time_ms": 14.917}, "counters": {"num_env_steps_sampled": 244000, "num_env_steps_trained": 244000, "num_agent_steps_sampled": 976000, "num_agent_steps_trained": 976000}, "done": false, "training_iteration": 61, "trial_id": "b72b3_00000", "date": "2024-08-08_15-46-12", "timestamp": 1723146372, "time_this_iter_s": 13.668037176132202, "time_total_s": 896.7617638111115, "pid": 98177, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3175be160>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 896.7617638111115, "iterations_since_restore": 61, "perf": {"cpu_util_percent": 28.580000000000002, "ram_util_percent": 81.52000000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.295667270819346, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.259774373968442, "policy_loss": -0.021925511237835357, "vf_loss": 6.280065662662188, "vf_explained_var": -0.052785022929310796, "kl": 0.008171121610899234, "entropy": 0.8933836384986837, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 59040.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6683994282010599, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.6949431865773303, "policy_loss": -0.018197822933091867, "vf_loss": 3.7121934103627576, "vf_explained_var": -7.431769201941524e-07, "kl": 0.004737961958765245, "entropy": 0.5216754797713976, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 173430.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 248000, "num_env_steps_trained": 248000, "num_agent_steps_sampled": 992000, "num_agent_steps_trained": 992000}, "env_runners": {"episode_reward_max": 180.0, "episode_reward_min": -56.77559380079615, "episode_reward_mean": 27.992646245740193, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -90.0}, "policy_reward_max": {"adversary_policy": 90.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 17.34567901234568, "agent_policy": -24.04439079129684}, "custom_metrics": {}, "hist_stats": {"episode_reward": [56.36357592647673, 10.486170752672887, -17.9333868422091, -2.033608286599648, 106.32289682533498, -1.8587347335939575, -26.750366384482657, 20.0, -10.043060396148485, 85.38966465639805, 0.0, 28.56137129737088, -7.1734203110644525, 38.10983107692448, -0.4261386597439554, 59.03163630422954, -19.32242738259066, 78.95322652790293, 0.0, 24.01148638604151, -28.871655682082316, 56.70703666339667, 33.45989081571437, -10.432531537407591, 58.04848295537782, -10.037056428087745, 40.0, 80.0, 100.0, 0.0, 0.0, 13.146579284850738, -4.540129507814795, 100.0, -15.922947804469322, 140.0, 55.33995022167392, 55.39309988042123, 0.0, 34.37400099168564, 80.0, 0.0, -2.093919935430746, 58.7950096811318, 0.0, 35.03940031512786, -15.595746202910334, 20.0, 119.15934884698464, 98.9269284336444, -10.481989999824592, 40.0, -3.4780136276612525, 60.0, 40.0, 0.0, 96.43554979999081, 119.91193453074897, 74.42098691561219, 49.057372502582304, -0.9929917898971719, -1.3929523190921045, 80.0, 60.0, 100.0, 26.225460409842004, 80.0, -8.204989385271817, -17.135115288721103, -18.031439933756857, 40.0, 60.0, -6.5856333648967755, 40.0, -8.263282502753762, -9.602739589719054, 19.799792415391252, -12.531480754898505, -1.2211891013964926, 80.0, 60.0, 0.0, 10.16745511463613, 55.90916331928685, 59.58280597521329, 38.17767355537228, 20.0, 0.0, -14.766461363583272, 46.509990033923046, 39.69986555942619, -0.46153765781329237, 0.0, 37.23431567570034, 20.0, 58.534133194836826, -17.37122159006448, 0.0, -27.53755895450859, -8.54942640369409, 16.298083166563675, 40.0, 20.0, 55.143696256699904, 40.0, 80.0, 0.0, -2.6912392604215847, -5.927431907616303, 40.0, -16.197608103053472, 60.0, 100.0, 5.418553724987653, 57.47565607648952, -6.556115946651509, -9.265148425279333, 131.92985425376898, 49.86279953468884, 0.0, -36.05238057435176, 35.83108503767464, -7.727355183050812, 40.0, -8.681406093970152, 40.0, 55.57764699025286, 117.53568707296162, 0.0, 53.71782385693453, 0.0, -3.830545482635917, 26.87555899772579, 19.517650298414665, 54.550976840959436, 40.0, -0.7474424106806321, -0.4796755789384233, -56.77559380079615, 95.33972396897677, 35.16639234965704, 20.0, -9.176475685851317, -1.939471232740243, 32.13653308655471, -19.905263270300054, 32.00507888006456, 57.21882066136714, 139.89143778249388, 180.0, 0.0, -15.362510701099975, -7.2867213574898395, -3.7332573800144733, -4.477218354599705, 38.06422350746553, -24.040623843068154, 115.01640733402468, -20.454004797973045, -4.547386354134759, 18.446944752168278, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 60.0, 60.0, 60.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 60.0, 60.0, 60.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 70.0, 70.0, 70.0, 90.0, 90.0, 90.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-33.63642407352327, -49.51382924732711, -17.9333868422091, -32.033608286599645, -73.67710317466502, -1.8587347335939575, -26.750366384482657, -10.0, -10.043060396148485, -64.61033534360195, 0.0, -31.438628702629114, -7.1734203110644525, -21.89016892307551, -0.4261386597439554, -30.968363695770464, -19.32242738259066, -41.04677347209708, 0.0, -35.988513613958474, -28.871655682082316, -33.292963336603336, -56.54010918428563, -10.432531537407591, -61.95151704462218, -10.037056428087745, -20.0, -40.0, -50.0, 0.0, 0.0, -46.85342071514927, -4.540129507814795, -50.0, -15.922947804469322, -70.0, -34.660049778326076, -34.606900119578754, 0.0, -25.62599900831436, -40.0, 0.0, -2.093919935430746, -31.20499031886819, 0.0, -24.960599684872143, -15.595746202910334, -10.0, -60.84065115301537, -51.073071566355594, -10.481989999824592, -20.0, -3.4780136276612525, -30.0, -20.0, 0.0, -53.56445020000918, -60.08806546925103, -45.579013084387825, -40.942627497417696, -0.9929917898971719, -1.3929523190921045, -40.0, -30.0, -50.0, -63.774539590157985, -40.0, -8.204989385271817, -17.135115288721103, -18.031439933756857, -20.0, -30.0, -6.5856333648967755, -20.0, -8.263282502753762, -9.602739589719054, -10.20020758460875, -12.531480754898505, -1.2211891013964926, -40.0, -30.0, 0.0, -49.832544885363866, -34.09083668071315, -30.417194024786706, -21.822326444627727, -10.0, 0.0, -14.766461363583272, -43.49000996607696, -20.300134440573807, -0.46153765781329237, 0.0, -22.765684324299663, -10.0, -31.465866805163163, -17.37122159006448, 0.0, -27.53755895450859, -8.54942640369409, -13.701916833436321, -20.0, -10.0, -34.8563037433001, -20.0, -40.0, 0.0, -2.6912392604215847, -5.927431907616303, -20.0, -16.197608103053472, -30.0, -50.0, -54.58144627501235, -32.52434392351048, -6.556115946651509, -9.265148425279333, -78.07014574623102, -40.13720046531116, 0.0, -36.05238057435176, -24.168914962325356, -7.727355183050812, -20.0, -8.681406093970152, -20.0, -64.42235300974714, -62.464312927038385, 0.0, -36.28217614306547, 0.0, -3.830545482635917, -33.12444100227421, -10.482349701585337, -35.44902315904057, -20.0, -0.7474424106806321, -0.4796755789384233, -56.77559380079615, -54.66027603102323, -24.833607650342962, -10.0, -9.176475685851317, -1.939471232740243, -27.86346691344529, -19.905263270300054, -27.994921119935444, -32.78117933863286, -70.10856221750612, -90.0, 0.0, -15.362510701099975, -7.2867213574898395, -3.7332573800144733, -4.477218354599705, -21.935776492534465, -24.040623843068154, -64.98359266597534, -20.454004797973045, -4.547386354134759, -11.55305524783172, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6452648975558805, "mean_inference_ms": 1.1109434587702767, "mean_action_processing_ms": 0.24421249326951713, "mean_env_wait_ms": 0.48268979286705765, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004349225833092207, "StateBufferConnector_ms": 0.003283921583199207, "ViewRequirementAgentConnector_ms": 0.08431673049926758}, "num_episodes": 162, "episode_return_max": 180.0, "episode_return_min": -56.77559380079615, "episode_return_mean": 27.992646245740193}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 992000, "num_agent_steps_trained": 992000, "num_env_steps_sampled": 248000, "num_env_steps_trained": 248000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 286.8611929951509, "num_env_steps_trained_throughput_per_sec": 286.8611929951509, "timesteps_total": 248000, "num_env_steps_sampled_lifetime": 248000, "num_agent_steps_sampled_lifetime": 992000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 992000, "timers": {"training_iteration_time_ms": 13809.094, "restore_workers_time_ms": 0.026, "training_step_time_ms": 13808.96, "sample_time_ms": 1125.516, "learn_time_ms": 12667.576, "learn_throughput": 315.767, "synch_weights_time_ms": 14.881}, "counters": {"num_env_steps_sampled": 248000, "num_env_steps_trained": 248000, "num_agent_steps_sampled": 992000, "num_agent_steps_trained": 992000}, "done": false, "training_iteration": 62, "trial_id": "b72b3_00000", "date": "2024-08-08_15-46-26", "timestamp": 1723146386, "time_this_iter_s": 13.950423955917358, "time_total_s": 910.7121877670288, "pid": 98177, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3175be820>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 910.7121877670288, "iterations_since_restore": 62, "perf": {"cpu_util_percent": 27.47, "ram_util_percent": 81.375}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.1618228890001774, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.120510366807381, "policy_loss": -0.02077733686552771, "vf_loss": 6.139502905805906, "vf_explained_var": -0.06914728929599126, "kl": 0.008923851895494295, "entropy": 0.8585303315892816, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 60000.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6510527084693841, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.7022057384463913, "policy_loss": -0.018730764274637327, "vf_loss": 3.720347591579383, "vf_explained_var": -2.7099188337934777e-06, "kl": 0.005889155583095076, "entropy": 0.5220638152238325, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 176250.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 252000, "num_env_steps_trained": 252000, "num_agent_steps_sampled": 1008000, "num_agent_steps_trained": 1008000}, "env_runners": {"episode_reward_max": 180.0, "episode_reward_min": -36.92181490832511, "episode_reward_mean": 27.24033403160293, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 157, "episodes_timesteps_total": 3925, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -90.0}, "policy_reward_max": {"adversary_policy": 90.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 16.751592356687897, "agent_policy": -23.014443038460765}, "custom_metrics": {}, "hist_stats": {"episode_reward": [80.0, -3.8747846184608834, 16.518747080764065, -16.547959655522867, 83.33823882689556, 82.5516726001131, -20.500307922374404, -7.351704390738236, -1.9705797104433032, 40.0, 31.857937694504656, 40.0, 53.671085251060994, 0.0, -13.412040470945106, 80.0, 0.0, 53.12323062161803, -31.10904231489853, 0.0, 37.873558158031166, 4.080650713455121, 40.0, 0.0, -14.448675254232686, 20.0, -7.097249770649581, 80.0, -6.894866982021061, -12.268736533962885, 14.011882471005936, 18.20726400470518, 77.52613241820126, 45.180534034242775, 0.0, 0.0, 0.0, 2.7414396347899235, 7.597150027901629, 33.271101045227454, -0.7412677290626912, 54.17571582285599, 57.47619689232984, 17.62909325129602, 38.42125526182252, 60.0, 49.09495768504565, 16.26265000721349, 7.031018836562517, 0.0, 0.0, 40.0, 115.96497960461089, 76.98886613667455, 120.0, 0.0, 39.12896435574939, 40.0, -9.929368115058466, 139.55424745795477, 13.943760840251109, -21.073040546947354, 60.0, 27.000037261957008, -2.8009510350223765, 20.0, 38.86212446130676, -0.9052326234371955, -9.349462092849617, -15.144337344337186, 38.77108843731774, -23.509594441817047, 0.0, 0.0, 118.96332572420033, 0.0, -5.983135750648959, -0.667073025058853, 75.94665540150257, 36.581134482387405, 158.77910348198517, 110.78660660177661, 36.77788763573579, -11.831178584219142, 20.0, -13.455353857877633, 0.0, -28.666222859521206, 0.0, 53.51354378432121, -12.406718020692416, 39.19072775301835, 23.009392910447744, 140.0, 59.32476278009725, 58.23670195932576, 0.0, 79.0942216533936, 0.0, -11.426319413032891, 20.0, 18.019814202195363, -5.896883315444199, 160.0, 79.42837842585112, 27.846529241768703, -3.678827327874279, 0.0, 17.68852004533775, 40.0, 14.769939291664375, 14.588065246996454, -12.904775796316006, -10.222038189327485, -9.262848147667935, 20.0, 20.0, 37.90033645439258, 33.72861236924056, 17.565456741051307, 19.92420544938418, 40.0, 0.0, -11.063731593722544, 40.0, 20.0, 25.103526589976607, 60.0, 20.0, -33.185383561587585, 20.0, -36.92181490832511, -5.33344454959326, 39.185846824470005, -0.060315320184185506, 60.0, 28.291051044676777, -22.544155751334365, 60.0, 37.76784857646736, -6.54526072648595, 119.9566438919019, 28.488379045309255, 120.0, 79.50284600383918, -22.344126868103487, 82.43880115963417, -8.763163846638871, 32.07706824875157, 80.0, 58.03003382971438, 180.0, -9.485206905434035, -10.105172738731245, -1.6271976207136867, -4.40253623501223, 0.08298168170874742], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 60.0, 60.0, 60.0, 40.0, 40.0, 40.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 80.0, 80.0, 80.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 70.0, 70.0, 70.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 80.0, 80.0, 80.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 60.0, 60.0, 60.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 90.0, 90.0, 90.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0], "policy_agent_policy_reward": [-40.0, -3.8747846184608834, -13.481252919235938, -16.547959655522867, -66.66176117310442, -67.44832739988692, -20.500307922374404, -7.351704390738236, -1.9705797104433032, -20.0, -28.142062305495344, -20.0, -36.328914748939, 0.0, -13.412040470945106, -40.0, 0.0, -36.87676937838197, -31.10904231489853, 0.0, -22.126441841968838, -25.91934928654488, -20.0, 0.0, -14.448675254232686, -10.0, -7.097249770649581, -40.0, -6.894866982021061, -12.268736533962885, -15.988117528994064, -11.79273599529482, -42.47386758179875, -44.819465965757225, 0.0, 0.0, 0.0, -57.25856036521007, -52.40284997209835, -26.728898954772546, -0.7412677290626912, -35.82428417714401, -32.52380310767016, -12.37090674870398, -21.57874473817747, -30.0, -40.90504231495435, -13.73734999278651, -22.968981163437483, 0.0, 0.0, -20.0, -64.03502039538911, -43.01113386332546, -60.0, 0.0, -20.871035644250615, -20.0, -9.929368115058466, -70.44575254204523, -16.05623915974889, -21.073040546947354, -30.0, -32.999962738042996, -2.8009510350223765, -10.0, -21.13787553869324, -0.9052326234371955, -9.349462092849617, -15.144337344337186, -21.228911562682274, -23.509594441817047, 0.0, 0.0, -61.03667427579968, 0.0, -5.983135750648959, -0.667073025058853, -44.053344598497425, -23.418865517612595, -81.22089651801483, -69.21339339822339, -23.22211236426422, -11.831178584219142, -10.0, -13.455353857877633, 0.0, -28.666222859521206, 0.0, -36.4864562156788, -12.406718020692416, -20.809272246981653, -36.990607089552256, -70.0, -30.67523721990275, -31.76329804067424, 0.0, -40.9057783466064, 0.0, -11.426319413032891, -10.0, -11.98018579780464, -5.896883315444199, -80.0, -40.57162157414888, -32.1534707582313, -3.678827327874279, 0.0, -12.31147995466225, -20.0, -15.230060708335625, -15.411934753003546, -12.904775796316006, -10.222038189327485, -9.262848147667935, -10.0, -10.0, -22.09966354560742, -26.271387630759442, -42.43454325894869, -10.075794550615823, -20.0, 0.0, -11.063731593722544, -20.0, -10.0, -34.89647341002339, -30.0, -10.0, -33.185383561587585, -10.0, -36.92181490832511, -5.33344454959326, -20.81415317552999, -0.060315320184185506, -30.0, -31.70894895532323, -22.544155751334365, -30.0, -22.23215142353263, -6.54526072648595, -60.04335610809809, -31.51162095469075, -60.0, -40.49715399616081, -22.344126868103487, -67.56119884036583, -8.763163846638871, -27.922931751248427, -40.0, -31.969966170285616, -90.0, -9.485206905434035, -10.105172738731245, -31.62719762071369, -4.40253623501223, -29.917018318291248]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6444416882195502, "mean_inference_ms": 1.109480920209455, "mean_action_processing_ms": 0.24367776336971939, "mean_env_wait_ms": 0.48214460896158423, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004133373309092916, "StateBufferConnector_ms": 0.002735207794578212, "ViewRequirementAgentConnector_ms": 0.0846737509320496}, "num_episodes": 157, "episode_return_max": 180.0, "episode_return_min": -36.92181490832511, "episode_return_mean": 27.24033403160293}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1008000, "num_agent_steps_trained": 1008000, "num_env_steps_sampled": 252000, "num_env_steps_trained": 252000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 298.7200641240113, "num_env_steps_trained_throughput_per_sec": 298.7200641240113, "timesteps_total": 252000, "num_env_steps_sampled_lifetime": 252000, "num_agent_steps_sampled_lifetime": 1008000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1008000, "timers": {"training_iteration_time_ms": 13762.779, "restore_workers_time_ms": 0.026, "training_step_time_ms": 13762.644, "sample_time_ms": 1131.441, "learn_time_ms": 12615.392, "learn_throughput": 317.073, "synch_weights_time_ms": 14.834}, "counters": {"num_env_steps_sampled": 252000, "num_env_steps_trained": 252000, "num_agent_steps_sampled": 1008000, "num_agent_steps_trained": 1008000}, "done": false, "training_iteration": 63, "trial_id": "b72b3_00000", "date": "2024-08-08_15-46-40", "timestamp": 1723146400, "time_this_iter_s": 13.395807981491089, "time_total_s": 924.1079957485199, "pid": 98177, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3175bea60>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 924.1079957485199, "iterations_since_restore": 63, "perf": {"cpu_util_percent": 26.826315789473686, "ram_util_percent": 81.34210526315788}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.421614779656132, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.027443141490221, "policy_loss": -0.024939769476865572, "vf_loss": 6.050279041628043, "vf_explained_var": 0.02351935307184855, "kl": 0.010519352158866013, "entropy": 0.8913397115965684, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 60960.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6397770559956841, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.4614511768023175, "policy_loss": -0.019030807997225552, "vf_loss": 3.47986849901524, "vf_explained_var": 8.473370937590904e-07, "kl": 0.006134889782676771, "entropy": 0.5153774868406302, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 179070.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 256000, "num_env_steps_trained": 256000, "num_agent_steps_sampled": 1024000, "num_agent_steps_trained": 1024000}, "env_runners": {"episode_reward_max": 160.0, "episode_reward_min": -41.19419040555762, "episode_reward_mean": 27.836282172480683, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -99.2968162389928}, "policy_reward_max": {"adversary_policy": 80.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 16.666666666666668, "agent_policy": -22.163717827519317}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-4.549761565505581, 58.98052372815376, -7.12530785265953, 6.701453181413298, 20.0, 58.0520547395825, 17.628362019282733, -0.15290911513251348, 0.0, 39.64453634916528, 0.0, -41.19419040555762, 8.891615632305173, 60.0, 29.08635303254185, 0.0, 0.0, 60.0, 0.0, -0.06028921475437099, 18.66915242661837, 40.0, -16.906292322382992, 117.29804148104972, 21.45620559360718, 0.0, 8.449619467005661, 60.0, 0.0, 27.479331280458595, 58.96037352894635, 50.703183761007196, -2.9093181781164086, 34.371500189938374, -14.846571004441707, -2.214334421674372, 38.59454686251727, 60.0, -5.610950592108857, 55.07005724448864, 30.456349064953304, -7.842933943586418, 0.8024009100151268, 140.0, 0.0, 80.0, 20.0, -5.972338186967067, 80.0, 60.0, 80.0, -2.121007238968853, -1.7098013632414577, 51.99446289478714, 113.9398067752069, 38.77382156904333, 80.0, 60.0, 80.0, 58.940297174265595, 0.0, -12.127471814169745, 68.71183401526558, 160.0, 33.994009838725226, 0.0, -6.869647087254787, 40.0, 104.51536438668805, 57.890939497530354, 55.84162831262474, 79.29779036116763, 112.81631782756452, -0.7002259443391878, 60.0, -1.2337517758221284, 32.77298920341844, 0.0, -4.834692718032932, 20.0, 27.772595167673018, 60.0, 132.64239990431616, 54.108793347435764, -2.09220138702521, -15.659094296512672, -37.34444565111891, 20.0, 136.35553194953536, 39.310737074420956, -0.36341646524248206, 80.0, 60.0, 40.0, 18.766189887611905, 59.01844782336073, 17.718725598409012, 100.0, -2.165407961508291, 0.0, -2.0220304948734458, 0.0, 19.84465324824906, 160.0, 18.72085771999396, -0.9188679903862773, 39.906580974916686, 0.0, 0.0, -4.625548873655574, 0.0, 19.03433678028703, -6.683385920444428, 0.18140797780377493, -16.54466664387379, 40.0, 31.756205844696357, 0.0, -2.120608562826572, 20.0, -17.21905710974694, 0.0, 20.0, -13.585775631175602, 0.0, 73.65940908868664, -3.0210848359495577, 60.0, 42.30974773605221, -4.849242910751196, 13.7864307677297, 20.0, 17.118576475538084, -0.28434200680250266, 0.0, -3.140122135382204, 60.0, 40.0, 120.0, 8.980627328917752, -21.52454075789417, -4.838861280342418, 0.0, -2.5430890778757442, 20.0, 20.0, 59.81994891330083, 36.50202436144965, 38.993626218955356, 56.08315040579227, 60.0, -0.5451151245891972, -16.344468617382308, -2.599202629414963, -3.4063582528150476, -35.308640180497164, 99.57280622472955, 20.0, -13.473763235159824, -15.690281905934148, 22.07230878983836, 42.55208466672933], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 60.0, 60.0, 60.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 80.0, 80.0, 80.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 60.0, 60.0, 60.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 70.0, 70.0, 70.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 70.0, 70.0, 70.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 80.0, 80.0, 80.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 60.0, 60.0, 60.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0], "policy_agent_policy_reward": [-4.549761565505581, -31.019476271846237, -7.12530785265953, -23.298546818586694, -10.0, -31.947945260417484, -12.371637980717267, -0.15290911513251348, 0.0, -20.355463650834718, 0.0, -41.19419040555762, -21.108384367694825, -30.0, -30.913646967458146, 0.0, 0.0, -30.0, 0.0, -0.06028921475437099, -11.330847573381625, -20.0, -16.906292322382992, -62.70195851895027, -38.54379440639282, 0.0, -21.550380532994343, -30.0, 0.0, -32.520668719541405, -31.039626471053644, -99.2968162389928, -2.9093181781164086, -25.628499810061626, -14.846571004441707, -32.21433442167437, -21.40545313748273, -30.0, -5.610950592108857, -34.929942755511355, -29.54365093504669, -7.842933943586418, -29.197599089984873, -70.0, 0.0, -40.0, -10.0, -5.972338186967067, -40.0, -30.0, -40.0, -2.121007238968853, -1.7098013632414577, -38.00553710521286, -66.0601932247931, -51.22617843095668, -40.0, -30.0, -40.0, -31.0597028257344, 0.0, -12.127471814169745, -51.28816598473442, -80.0, -26.005990161274767, 0.0, -6.869647087254787, -20.0, -75.48463561331195, -32.10906050246964, -34.15837168737526, -40.70220963883237, -67.18368217243548, -0.7002259443391878, -30.0, -1.2337517758221284, -27.22701079658156, 0.0, -4.834692718032932, -10.0, -32.22740483232698, -30.0, -77.35760009568384, -35.891206652564236, -2.09220138702521, -15.659094296512672, -37.34444565111891, -10.0, -73.64446805046465, -50.689262925579044, -0.36341646524248206, -40.0, -30.0, -20.0, -11.233810112388094, -30.981552176639273, -12.281274401590988, -50.0, -2.165407961508291, 0.0, -2.0220304948734458, 0.0, -10.15534675175094, -80.0, -41.27914228000605, -0.9188679903862773, -20.093419025083314, 0.0, 0.0, -4.625548873655574, 0.0, -10.965663219712967, -6.683385920444428, -29.818592022196224, -16.54466664387379, -20.0, -28.243794155303632, 0.0, -2.120608562826572, -10.0, -17.21905710974694, 0.0, -10.0, -13.585775631175602, 0.0, -46.340590911313356, -3.0210848359495577, -30.0, -47.69025226394779, -4.849242910751196, -16.213569232270306, -10.0, -42.881423524461916, -0.28434200680250266, 0.0, -3.140122135382204, -30.0, -20.0, -60.0, -21.019372671082248, -21.52454075789417, -4.838861280342418, 0.0, -2.5430890778757442, -10.0, -10.0, -30.18005108669917, -23.497975638550344, -21.006373781044644, -33.91684959420773, -30.0, -0.5451151245891972, -16.344468617382308, -2.599202629414963, -3.4063582528150476, -35.308640180497164, -50.42719377527045, -10.0, -13.473763235159824, -15.690281905934148, -37.92769121016164, -47.447915333270686]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6435192867355234, "mean_inference_ms": 1.1079103716119436, "mean_action_processing_ms": 0.2432017181986103, "mean_env_wait_ms": 0.4815778963376499, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004254667847244827, "StateBufferConnector_ms": 0.0030881092872148677, "ViewRequirementAgentConnector_ms": 0.08541110121173623}, "num_episodes": 162, "episode_return_max": 160.0, "episode_return_min": -41.19419040555762, "episode_return_mean": 27.836282172480683}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1024000, "num_agent_steps_trained": 1024000, "num_env_steps_sampled": 256000, "num_env_steps_trained": 256000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 287.8804590626114, "num_env_steps_trained_throughput_per_sec": 287.8804590626114, "timesteps_total": 256000, "num_env_steps_sampled_lifetime": 256000, "num_agent_steps_sampled_lifetime": 1024000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1024000, "timers": {"training_iteration_time_ms": 13823.418, "restore_workers_time_ms": 0.026, "training_step_time_ms": 13823.283, "sample_time_ms": 1130.458, "learn_time_ms": 12676.617, "learn_throughput": 315.542, "synch_weights_time_ms": 15.232}, "counters": {"num_env_steps_sampled": 256000, "num_env_steps_trained": 256000, "num_agent_steps_sampled": 1024000, "num_agent_steps_trained": 1024000}, "done": false, "training_iteration": 64, "trial_id": "b72b3_00000", "date": "2024-08-08_15-46-54", "timestamp": 1723146414, "time_this_iter_s": 13.90282392501831, "time_total_s": 938.0108196735382, "pid": 98177, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3281949d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 938.0108196735382, "iterations_since_restore": 64, "perf": {"cpu_util_percent": 27.525, "ram_util_percent": 81.31000000000002}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.1947875498483578, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.422057119011879, "policy_loss": -0.024653480947502734, "vf_loss": 6.444905144472917, "vf_explained_var": 0.055051332153379914, "kl": 0.009027369647726742, "entropy": 0.8926262230922778, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 61920.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6647848449066176, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.146063830497417, "policy_loss": -0.019790635912692346, "vf_loss": 4.165207594421738, "vf_explained_var": 1.1005722884590744e-06, "kl": 0.006468729067007778, "entropy": 0.5005272397546904, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 181890.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 260000, "num_env_steps_trained": 260000, "num_agent_steps_sampled": 1040000, "num_agent_steps_trained": 1040000}, "env_runners": {"episode_reward_max": 159.62110969362132, "episode_reward_min": -52.23506232711425, "episode_reward_mean": 29.286886687862786, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -81.62206379366539}, "policy_reward_max": {"adversary_policy": 80.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 17.839506172839506, "agent_policy": -24.231631830655736}, "custom_metrics": {}, "hist_stats": {"episode_reward": [60.0, 38.22957919716442, 60.0, -0.45054491929219953, -2.127201766791762, 40.0, -4.59785490970485, -6.64041148496793, -0.23983730148265936, 40.0, 75.3587970331531, -1.8685021779205135, 40.0, 35.56178034121828, 20.0, 76.21740683648704, -0.19423155916276635, -11.391496923755383, 80.0, 38.45662095181435, 56.13824733370063, 97.24755024475999, 140.0, -10.173052782572752, 26.05817272947751, 0.0, 18.492835156485683, 6.950823443018205, 52.87664278976384, 40.0, 6.59551695612864, 60.0, 38.11778552634337, 0.0, 40.0, 110.90516929077623, -11.522625962440289, 28.101428150481823, 19.911063230440746, 87.25522723080455, 57.44661128789465, -11.530132652422974, -2.7402412391678777, 15.505366000339585, 59.7266462842737, -8.74481657728353, 22.215567276150864, 5.503857554043474, -4.508147721701363, -4.105645667139669, -3.085130397910154, 116.93860083104592, 20.0, -1.4313579628604045, -20.008967318818698, 58.245889709604796, 60.0, 60.0, 0.0, -9.910106691913276, 120.0, 0.0, 28.15708145216125, 136.90965088863436, 15.477685028143902, -14.6483729801519, 34.18995561444442, -0.3228721182490657, 79.3298704149124, -8.398044725644226, 33.23996543209577, 140.0, 49.598545939393254, 40.0, 0.0, 119.73617159520813, 57.55366045445359, 34.369137812582125, -52.23506232711425, 120.0, 37.67948727619064, 0.0, -6.822345464620075, 40.0, -21.90048417827742, -12.386084712199839, 38.37793620633459, 0.0, 38.83029991588157, 120.0, -12.689924942303472, 79.84946705765506, 19.498831734878518, 15.820373754632513, 0.0, -21.180288422753833, -0.22334764372029636, 20.0, -19.69823500209651, -11.736892944222557, 20.0, 138.96588169257143, -5.799889796296244, 20.0, -0.4442420587635565, -50.551074804046365, 20.0, 41.1787574231516, -19.59715903091556, 20.0, 37.123461552546175, 20.0, 37.50445706580494, 115.73319182763555, 100.0, 0.0, 15.264968879513974, 20.0, 159.62110969362132, 40.0, 40.0, -37.912185287276536, 99.48585786135597, -6.175844996608343, 0.0, 57.69357642776855, -2.3008073572073044, -8.341553593624422, 12.72387866720152, 11.972977730953655, -2.2163498657501908, -15.26828973477637, 40.0, -1.594949537289262, -0.2331812026373814, 0.0, 20.0, 11.190543282724143, 40.0, 40.0, 20.0, 60.0, 36.83786636172093, -7.355687716378462, 20.0, 40.0, -27.310401298900388, 12.633481679458537, -1.1891497375975801, -7.5012612664280445, 51.07625516399356, -9.593912226709946, -9.004150561358802, 56.5805689101623, 40.0, -0.06465522614723329, 80.0, 120.0, 67.05167269917365, 92.13057507659099, -0.786062919578262, 53.784325171801655], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 70.0, 70.0, 70.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 70.0, 70.0, 70.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 60.0, 60.0, 60.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 80.0, 80.0, 80.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 60.0, 60.0, 60.0, 40.0, 40.0, 40.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0], "policy_agent_policy_reward": [-30.0, -21.77042080283558, -30.0, -0.45054491929219953, -2.127201766791762, -20.0, -4.59785490970485, -6.64041148496793, -30.239837301482666, -20.0, -44.6412029668469, -1.8685021779205135, -20.0, -24.43821965878172, -10.0, -43.78259316351295, -0.19423155916276635, -11.391496923755383, -40.0, -21.543379048185653, -33.86175266629937, -52.75244975524, -70.0, -10.173052782572752, -63.9418272705225, 0.0, -11.507164843514314, -23.049176556981795, -37.12335721023615, -20.0, -23.404483043871366, -30.0, -21.882214473656635, 0.0, -20.0, -69.09483070922379, -11.522625962440289, -31.898571849518184, -10.088936769559256, -62.74477276919545, -32.55338871210536, -11.530132652422974, -2.7402412391678777, -14.494633999660415, -30.273353715726294, -8.74481657728353, -37.78443272384915, -24.496142445956526, -64.50814772170136, -4.105645667139669, -3.085130397910154, -63.06139916895409, -10.0, -1.4313579628604045, -20.008967318818698, -31.754110290395204, -30.0, -30.0, 0.0, -9.910106691913276, -60.0, 0.0, -31.84291854783875, -73.09034911136565, -14.522314971856096, -14.6483729801519, -25.81004438555558, -0.3228721182490657, -40.670129585087594, -8.398044725644226, -26.760034567904228, -70.0, -40.401454060606746, -20.0, 0.0, -60.26382840479185, -32.446339545546415, -25.630862187417875, -52.23506232711425, -60.0, -52.32051272380936, 0.0, -6.822345464620075, -20.0, -21.90048417827742, -12.386084712199839, -81.62206379366539, 0.0, -21.169700084118436, -60.0, -12.689924942303472, -40.15053294234493, -10.501168265121484, -14.179626245367487, 0.0, -21.180288422753833, -0.22334764372029636, -10.0, -19.69823500209651, -11.736892944222557, -10.0, -71.03411830742859, -5.799889796296244, -10.0, -0.4442420587635565, -50.551074804046365, -10.0, -48.821242576848405, -19.59715903091556, -10.0, -22.876538447453818, -10.0, -22.49554293419506, -64.26680817236445, -50.0, 0.0, -14.735031120486028, -10.0, -80.37889030637868, -20.0, -20.0, -37.912185287276536, -50.514142138644026, -6.175844996608343, 0.0, -32.30642357223145, -2.3008073572073044, -8.341553593624422, -17.276121332798482, -48.02702226904636, -2.2163498657501908, -15.26828973477637, -20.0, -1.594949537289262, -0.2331812026373814, 0.0, -10.0, -18.809456717275857, -20.0, -20.0, -10.0, -30.0, -23.16213363827907, -7.355687716378462, -10.0, -20.0, -27.310401298900388, -17.366518320541463, -1.1891497375975801, -37.501261266428045, -38.92374483600645, -9.593912226709946, -9.004150561358802, -33.419431089837694, -20.0, -0.06465522614723329, -40.0, -60.0, -52.948327300826335, -57.86942492340902, -0.786062919578262, -66.21567482819835]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6429360050192664, "mean_inference_ms": 1.1069189240133106, "mean_action_processing_ms": 0.24279519304093558, "mean_env_wait_ms": 0.4812829770362065, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004153855052995093, "StateBufferConnector_ms": 0.003105990680647485, "ViewRequirementAgentConnector_ms": 0.08799021626696174}, "num_episodes": 162, "episode_return_max": 159.62110969362132, "episode_return_min": -52.23506232711425, "episode_return_mean": 29.286886687862786}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1040000, "num_agent_steps_trained": 1040000, "num_env_steps_sampled": 260000, "num_env_steps_trained": 260000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 297.03337815835124, "num_env_steps_trained_throughput_per_sec": 297.03337815835124, "timesteps_total": 260000, "num_env_steps_sampled_lifetime": 260000, "num_agent_steps_sampled_lifetime": 1040000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1040000, "timers": {"training_iteration_time_ms": 13776.907, "restore_workers_time_ms": 0.026, "training_step_time_ms": 13776.774, "sample_time_ms": 1129.133, "learn_time_ms": 12632.69, "learn_throughput": 316.639, "synch_weights_time_ms": 14.311}, "counters": {"num_env_steps_sampled": 260000, "num_env_steps_trained": 260000, "num_agent_steps_sampled": 1040000, "num_agent_steps_trained": 1040000}, "done": false, "training_iteration": 65, "trial_id": "b72b3_00000", "date": "2024-08-08_15-47-07", "timestamp": 1723146427, "time_this_iter_s": 13.47478175163269, "time_total_s": 951.4856014251709, "pid": 98177, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3175df4c0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 951.4856014251709, "iterations_since_restore": 65, "perf": {"cpu_util_percent": 29.28421052631579, "ram_util_percent": 81.19473684210527}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.7738274691005547, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.983293565114339, "policy_loss": -0.02239831861758527, "vf_loss": 6.003955395023028, "vf_explained_var": -0.028946585270265737, "kl": 0.008682548508254052, "entropy": 0.8554341036826372, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 62880.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6408874617295063, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.0218505773138493, "policy_loss": -0.01874834941336819, "vf_loss": 3.0399213208374403, "vf_explained_var": -2.806491040168925e-07, "kl": 0.006776079621333135, "entropy": 0.5011672062125612, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 184710.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 264000, "num_env_steps_trained": 264000, "num_agent_steps_sampled": 1056000, "num_agent_steps_trained": 1056000}, "env_runners": {"episode_reward_max": 240.0, "episode_reward_min": -56.97574156342796, "episode_reward_mean": 21.237510941240963, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 158, "episodes_timesteps_total": 3950, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -120.0}, "policy_reward_max": {"adversary_policy": 120.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 13.987341772151899, "agent_policy": -20.724514375214735}, "custom_metrics": {}, "hist_stats": {"episode_reward": [115.23068022080245, 12.377673915029922, -39.980724362740084, 16.20297415173455, 80.0, -10.473270391449507, -3.2752673759550692, 32.15761951179796, -12.074207738000627, 0.0, 112.08929872905654, 20.0, -24.361420829445116, -5.602375530800471, -5.956246468155914, 37.941978881169355, -0.3732692336344312, -8.82907409276314, 57.40164132196729, 0.0, 60.0, 59.049572514422444, 23.877924295632656, -17.394982881829858, -3.8177097595649383, 0.0, 5.585777096616708, -11.323013491357402, -4.694666501332712, -8.001210530829528, -5.298153225610557, 59.8831434038717, 57.521171595195625, 40.0, -20.36261087953313, 0.0, 80.0, -6.009021866587874, -29.706786263912793, 76.11333350760142, 3.198858202527944, -3.265271395209586, 5.727862041705169, 8.487759633807723, 240.0, 44.469351507263724, 117.32961887558261, 100.72085069692113, 100.0, 60.0, 0.09741029583161276, -1.685792312541906, 120.0, -7.540909783762588, -1.1098761729721862, -17.010458365926766, 20.0, -5.888648854373372, -0.6024201065628976, -0.40570222093412545, -56.97574156342796, -24.28973490016499, 80.0, 57.835475404291834, -2.4233937839080832, -12.90860380707575, -7.9606109865500425, 80.0, 0.0, 32.989895369766636, 0.0, 0.0, 23.380385799351025, -7.937582298061992, -10.804276978704413, 29.088108205061868, 68.26896522004434, 47.96932678212004, 0.0, -6.584005241326379, 69.37367175090122, 138.84589894540002, 35.076990013011795, 32.71008079313403, -1.4564316966015136, 17.327895345713696, 100.0, -2.654319148862191, 20.0, 20.0, 0.0, 0.0, 40.0, -0.15934323400727424, -0.08662357861401127, -10.318014706789876, 57.19952441644937, 100.0, 0.0, 20.0, 0.0, 80.0, 40.0, 32.60298508345035, 60.0, 88.22657277274627, -19.9908713408129, 15.055221445440212, -9.423180857998723, 20.0, -15.299094047014067, -9.640746089744356, -1.8304640702038022, 40.48191114192828, -1.176717082290638, 0.0, 160.0, -0.5909119781381755, 19.460733545255543, 0.0, 32.23384262142693, 0.0, 30.7937669058881, 27.765472030640378, -24.18424640267291, 0.0, -4.724563060628494, -1.2960851485282099, -6.967887208750357, 0.0, -0.820305015130065, -8.085832262711458, 0.0, -2.044867404454993, 0.0, 0.0, -0.41577303621867623, -16.958786230025094, 0.0, 34.518166794855155, 35.8471066341334, 59.031630570502216, 28.377870170965156, -4.66677500272114, -3.995370096372591, 60.0, -9.656778491055235, 0.0, 60.0, -15.674660814844295, 0.0, -5.592926050534916, 40.0, 80.0, 0.0, 39.873689705322974, 18.951961121486693, -20.58630602102201], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [60.0, 60.0, 60.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 120.0, 120.0, 120.0, 40.0, 40.0, 40.0, 60.0, 60.0, 60.0, 60.0, 60.0, 60.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 70.0, 70.0, 70.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 80.0, 80.0, 80.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-64.76931977919756, -17.622326084970076, -39.980724362740084, -13.797025848265449, -40.0, -10.473270391449507, -3.2752673759550692, -27.842380488202036, -12.074207738000627, 0.0, -67.91070127094346, -10.0, -24.361420829445116, -5.602375530800471, -5.956246468155914, -22.058021118830645, -0.3732692336344312, -8.82907409276314, -32.59835867803271, 0.0, -30.0, -30.95042748557756, -36.122075704367354, -17.394982881829858, -3.8177097595649383, 0.0, -24.41422290338329, -11.323013491357402, -4.694666501332712, -8.001210530829528, -5.298153225610557, -30.1168565961283, -32.478828404804375, -20.0, -20.36261087953313, 0.0, -40.0, -6.009021866587874, -29.706786263912793, -73.88666649239858, -26.801141797472056, -3.265271395209586, -24.27213795829483, -51.51224036619228, -120.0, -75.53064849273628, -62.67038112441739, -79.27914930307887, -50.0, -30.0, -29.90258970416839, -1.685792312541906, -60.0, -7.540909783762588, -1.1098761729721862, -17.010458365926766, -10.0, -35.88864885437337, -0.6024201065628976, -0.40570222093412545, -56.97574156342796, -24.28973490016499, -40.0, -32.16452459570818, -2.4233937839080832, -12.90860380707575, -7.9606109865500425, -40.0, 0.0, -27.010104630233364, 0.0, 0.0, -36.619614200648975, -7.937582298061992, -10.804276978704413, -30.91189179493813, -51.731034779955664, -42.03067321787996, 0.0, -6.584005241326379, -50.62632824909879, -71.15410105459998, -54.923009986988205, -27.289919206865974, -1.4564316966015136, -12.672104654286303, -50.0, -2.654319148862191, -10.0, -10.0, 0.0, 0.0, -20.0, -0.15934323400727424, -0.08662357861401127, -10.318014706789876, -32.800475583550636, -50.0, 0.0, -10.0, 0.0, -40.0, -20.0, -27.397014916549647, -30.0, -61.77342722725373, -19.9908713408129, -44.9447785545598, -9.423180857998723, -10.0, -15.299094047014067, -9.640746089744356, -1.8304640702038022, -49.518088858071714, -1.176717082290638, 0.0, -80.0, -0.5909119781381755, -10.539266454744459, 0.0, -27.76615737857307, 0.0, -29.2062330941119, -32.234527969359625, -24.18424640267291, 0.0, -4.724563060628494, -1.2960851485282099, -6.967887208750357, 0.0, -0.820305015130065, -8.085832262711458, 0.0, -2.044867404454993, 0.0, 0.0, -0.41577303621867623, -16.958786230025094, 0.0, -25.481833205144845, -24.152893365866607, -30.968369429497784, -31.622129829034836, -4.66677500272114, -3.995370096372591, -30.0, -9.656778491055235, 0.0, -30.0, -15.674660814844295, 0.0, -5.592926050534916, -20.0, -40.0, 0.0, -20.126310294677022, -11.048038878513307, -20.58630602102201]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6422314580045045, "mean_inference_ms": 1.1054388686729797, "mean_action_processing_ms": 0.24231551677382873, "mean_env_wait_ms": 0.4808435161729737, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004878677899324441, "StateBufferConnector_ms": 0.0032621848432323602, "ViewRequirementAgentConnector_ms": 0.08679462384574022}, "num_episodes": 158, "episode_return_max": 240.0, "episode_return_min": -56.97574156342796, "episode_return_mean": 21.237510941240963}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1056000, "num_agent_steps_trained": 1056000, "num_env_steps_sampled": 264000, "num_env_steps_trained": 264000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 294.78531543493926, "num_env_steps_trained_throughput_per_sec": 294.78531543493926, "timesteps_total": 264000, "num_env_steps_sampled_lifetime": 264000, "num_agent_steps_sampled_lifetime": 1056000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1056000, "timers": {"training_iteration_time_ms": 13706.78, "restore_workers_time_ms": 0.022, "training_step_time_ms": 13706.663, "sample_time_ms": 1126.3, "learn_time_ms": 12566.292, "learn_throughput": 318.312, "synch_weights_time_ms": 13.375}, "counters": {"num_env_steps_sampled": 264000, "num_env_steps_trained": 264000, "num_agent_steps_sampled": 1056000, "num_agent_steps_trained": 1056000}, "done": false, "training_iteration": 66, "trial_id": "b72b3_00000", "date": "2024-08-08_15-47-21", "timestamp": 1723146441, "time_this_iter_s": 13.624095916748047, "time_total_s": 965.109697341919, "pid": 98177, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3175df8b0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 965.109697341919, "iterations_since_restore": 66, "perf": {"cpu_util_percent": 28.415789473684214, "ram_util_percent": 81.55263157894737}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.3859867757807174, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.383725568652153, "policy_loss": -0.019287542110638847, "vf_loss": 6.401528505980968, "vf_explained_var": -0.020349052113791306, "kl": 0.007423064115197112, "entropy": 0.8598982910936077, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 63840.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6372107001061135, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.125371158207562, "policy_loss": -0.018197207791311336, "vf_loss": 4.142905954350817, "vf_explained_var": -2.376365323438712e-07, "kl": 0.0066241012167785746, "entropy": 0.47694245140391883, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 187530.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 268000, "num_env_steps_trained": 268000, "num_agent_steps_sampled": 1072000, "num_agent_steps_trained": 1072000}, "env_runners": {"episode_reward_max": 180.0, "episode_reward_min": -35.02839389447513, "episode_reward_mean": 35.77961753715585, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 157, "episodes_timesteps_total": 3925, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -90.84242269925315}, "policy_reward_max": {"adversary_policy": 90.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 20.063694267515924, "agent_policy": -24.411465265391918}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 33.47266872760465, 99.79860693074951, -9.004623597399808, 100.0, 16.12466024164786, -35.02839389447513, -2.771492126087115, 39.69657383111509, 40.0, 34.25304486721333, 16.149838837500468, 39.89281771408237, 40.0, -17.64490943963936, 58.15455511894402, 14.641231504513087, 54.4992318228951, 139.80967956811037, 0.0, 19.692401879388324, 0.0, 8.289146593888946, -6.963411347911389, 0.0, 100.0, -7.9642039284894395, 80.0, -7.664574118949213, 17.96344685999723, 60.0, 60.0, 0.0, 39.34559394130671, 40.0, 180.0, 46.962507440224734, -9.892456963848437, 80.0, 0.0, -0.2121523396767755, 100.0, 20.0, 0.0, 19.63741940396815, 60.0, 130.33076247212597, 79.01521031232669, 36.74703390318118, 99.58230179648888, 112.5268625955663, -12.375015557772711, 0.0, 120.0, 36.46056661353532, -5.942017184295507, 119.60218159233125, 51.98562382590056, -3.560395943682355, 40.0, -2.6281091169024107, 31.64112699460984, 40.0, -19.779916040723414, 0.0, 96.83861979008242, 40.0, 0.0, -0.9774889739006221, 38.234163535205575, 40.0, 37.01062861405495, -6.086862336834204, 39.613215977843915, 80.0, 3.0640112709363185, -1.5842255463135524, 58.70223525991867, 38.00168526098873, 60.0, -14.320563097477724, -3.786678763023457, 60.0, 0.0, 39.59378706977026, 119.05071649306848, -1.002384802076428, -1.0215196024016504, 40.0, 80.0, 0.0, -15.627280625191794, -0.8521651888942794, 37.99734455259803, 60.0, 40.0, -9.355582488126712, 78.41275584658679, -9.225777279684465, 0.0, 33.98271120398181, -21.178933871738465, -13.309985184120293, 140.0, 100.0, 60.0, 20.0, -27.23325175647415, 35.88596588509914, 80.0, 0.0, 38.10859354365156, 80.0, 24.79632502998856, 7.443465653543315, 53.768162048275926, 80.0, 46.402588574550315, 59.491294150294905, 179.15757730074685, 40.0, 76.34468050247, -9.499351011714907, -16.770105678456012, -0.9277952263293732, 55.74681143375956, 40.0, 120.0, 0.0, 40.0, 80.0, -11.519545280816681, 48.46334467191606, 44.64029981539603, 20.0, 80.0, 0.0, 60.0, 25.81178344753028, 39.419701356419914, 10.711699411040733, 119.66353865130924, -7.138587250758973, 0.0, 47.52957202120953, 40.0, 60.0, -7.266029525550283, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 27.353364661752394, 60.0, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 90.0, 90.0, 90.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 70.0, 70.0, 70.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 60.0, 60.0, 60.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 90.0, 90.0, 90.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [0.0, -26.527331272395344, -50.201393069250486, -9.004623597399808, -50.0, -13.87533975835214, -35.02839389447513, -2.771492126087115, -20.30342616888491, -20.0, -55.74695513278667, -13.850161162499536, -20.10718228591763, -20.0, -17.64490943963936, -31.845444881055982, -15.358768495486913, -35.5007681771049, -70.19032043188965, 0.0, -10.307598120611676, 0.0, -21.71085340611106, -6.963411347911389, 0.0, -50.0, -7.9642039284894395, -40.0, -7.664574118949213, -12.036553140002775, -30.0, -30.0, 0.0, -20.654406058693286, -20.0, -90.0, -43.037492559775266, -9.892456963848437, -40.0, 0.0, -0.2121523396767755, -50.0, -10.0, 0.0, -10.36258059603185, -30.0, -79.66923752787403, -70.98478968767331, -23.252966096818817, -50.41769820351112, -67.4731374044337, -42.375015557772706, 0.0, -60.0, -23.539433386464676, -5.942017184295507, -60.39781840766875, -38.01437617409944, -3.560395943682355, -20.0, -2.6281091169024107, -28.35887300539016, -20.0, -19.779916040723414, 0.0, -53.16138020991757, -20.0, 0.0, -0.9774889739006221, -21.765836464794415, -20.0, -22.989371385945045, -6.086862336834204, -20.386784022156075, -40.0, -26.935988729063688, -1.5842255463135524, -31.297764740081323, -21.998314739011267, -30.0, -14.320563097477724, -3.786678763023457, -30.0, 0.0, -20.406212930229742, -60.94928350693152, -1.002384802076428, -1.0215196024016504, -20.0, -40.0, 0.0, -15.627280625191794, -0.8521651888942794, -22.00265544740197, -30.0, -20.0, -9.355582488126712, -41.58724415341321, -9.225777279684465, 0.0, -26.017288796018185, -51.178933871738465, -13.309985184120293, -70.0, -50.0, -30.0, -10.0, -27.23325175647415, -24.114034114900857, -40.0, 0.0, -21.89140645634844, -40.0, -35.20367497001144, -22.55653434645669, -36.231837951724074, -40.0, -43.59741142544969, -30.5087058497051, -90.84242269925315, -20.0, -43.65531949753, -9.499351011714907, -16.770105678456012, -0.9277952263293732, -34.25318856624043, -20.0, -60.0, 0.0, -20.0, -40.0, -11.519545280816681, -41.53665532808394, -45.35970018460397, -10.0, -40.0, 0.0, -30.0, -34.188216552469726, -20.580298643580086, -19.288300588959267, -60.33646134869075, -7.138587250758973, 0.0, -42.470427978790454, -20.0, -30.0, -7.266029525550283, 0.0, -20.0, -20.0, -20.0, 0.0, 0.0, -32.646635338247606, -30.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6416962881986301, "mean_inference_ms": 1.1046851270066227, "mean_action_processing_ms": 0.24184347537357515, "mean_env_wait_ms": 0.48056781593065734, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004284928558738368, "StateBufferConnector_ms": 0.0033564628309505, "ViewRequirementAgentConnector_ms": 0.09028251004067196}, "num_episodes": 157, "episode_return_max": 180.0, "episode_return_min": -35.02839389447513, "episode_return_mean": 35.77961753715585}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1072000, "num_agent_steps_trained": 1072000, "num_env_steps_sampled": 268000, "num_env_steps_trained": 268000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 295.76037882649496, "num_env_steps_trained_throughput_per_sec": 295.76037882649496, "timesteps_total": 268000, "num_env_steps_sampled_lifetime": 268000, "num_agent_steps_sampled_lifetime": 1072000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1072000, "timers": {"training_iteration_time_ms": 13680.823, "restore_workers_time_ms": 0.022, "training_step_time_ms": 13680.706, "sample_time_ms": 1122.557, "learn_time_ms": 12544.026, "learn_throughput": 318.877, "synch_weights_time_ms": 13.381}, "counters": {"num_env_steps_sampled": 268000, "num_env_steps_trained": 268000, "num_agent_steps_sampled": 1072000, "num_agent_steps_trained": 1072000}, "done": false, "training_iteration": 67, "trial_id": "b72b3_00000", "date": "2024-08-08_15-47-35", "timestamp": 1723146455, "time_this_iter_s": 13.529783725738525, "time_total_s": 978.6394810676575, "pid": 98177, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3175dff70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 978.6394810676575, "iterations_since_restore": 67, "perf": {"cpu_util_percent": 29.294999999999998, "ram_util_percent": 81.75999999999998}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.3401450077692667, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.299578418085972, "policy_loss": -0.023677489394807103, "vf_loss": 6.321464358270168, "vf_explained_var": 0.027799277752637862, "kl": 0.00895782985063, "entropy": 0.8791877948368589, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 64800.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6567008263147469, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.713094509831557, "policy_loss": -0.017756989669692143, "vf_loss": 3.730311761257496, "vf_explained_var": -8.055081604220343e-07, "kl": 0.005397315112761451, "entropy": 0.474240982997502, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 190350.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 272000, "num_env_steps_trained": 272000, "num_agent_steps_sampled": 1088000, "num_agent_steps_trained": 1088000}, "env_runners": {"episode_reward_max": 180.0, "episode_reward_min": -30.733589419150803, "episode_reward_mean": 30.82602404835547, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -90.0}, "policy_reward_max": {"adversary_policy": 90.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 18.271604938271604, "agent_policy": -23.988790766459346}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, -29.221429726613827, -0.02787544137017206, 19.855648140426464, 40.0, 28.11199791269871, 20.0, 60.0, -3.217333926247831, 40.0, 38.863562046477156, -16.990348235623966, 54.47922817003542, 78.06918495552327, -27.637842857714897, 20.0, -30.733589419150803, 100.0, -14.357857517450677, 80.0, 48.234697776238136, 180.0, -14.984496410472168, -2.416745471128774, -20.438222790787783, 36.33312926862384, -2.204194764433889, 55.678625565765685, 0.0, -0.6753221365669526, 60.0, 57.47647073692771, 33.67894266300277, -13.480493692857221, 20.0, 0.0, -1.0545535166076903, -10.417449214211201, 39.68251746960377, 17.26609874229139, 78.94391918065023, -12.442130549306505, 32.90362271463734, 19.917901922964255, 22.361426073613185, 8.617032175747216, 37.275101948042305, 60.0, 40.0, 2.9792434889817287, 59.79040169768221, 40.0, -10.773566878888305, 40.0, 20.0, 60.0, -20.223869335787615, 47.307422923080274, 34.580459046996225, 14.081721038138758, 92.17330484446549, 45.59718818800972, 0.0, 100.0, 60.0, 0.0, 79.75611586629365, 58.829402774996666, 160.0, 60.0, -4.3575968742474664, -0.04637138869436508, 54.2070258323051, -6.327901383482724, 60.0, 60.0, -8.608258485652795, -0.17401829697725857, 18.189382795651664, 0.0, -10.1830427647785, 0.0, 76.18542961598224, 120.0, 160.0, 24.745911622413985, 23.395649845937346, -1.4923686173091855, -6.810244027648393, 10.21394579699414, 74.14249037131088, 0.0, 40.0, 59.8752113169318, 79.65887962168574, 54.86880081168533, -18.87948303547926, -8.47750683732054, 0.0, -6.979609290649192, 110.71233530590013, 60.0, 20.395361020314752, 0.0, 15.345384547823755, -21.158675622988806, 36.296978233475215, 80.0, 100.0, 79.81864458006066, 37.58246434612008, 98.652969503135, 75.46225459689201, 9.556351815130785, -0.48185877424785195, 0.0, -8.761113551902145, 80.0, 60.0, 8.53432698120142, 55.898575972501966, 31.421746241034818, 120.0, -10.035587480955769, 56.25275664630807, 0.0, -1.1131078465580446, -7.746165866062298, 9.66531062745615, 0.0, -10.324105668772187, 0.0, 51.736553098469976, 20.0, 40.0, 40.0, 17.878480951868816, 40.0, 91.18019243925346, 23.36845201005982, 49.473887994064555, 98.961032786571, 80.0, 39.63548490615301, 158.70510134438376, 57.113675661366436, -9.393110618279962, -9.00885726896333, 15.618750137551658, -20.58820330113934, 0.0, 40.0, 0.0, 60.0, 0.0, -15.632699614438367, -13.982873079463982, 0.0, -0.023516597338631984, -19.078169082892707, 57.18349638514001, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 90.0, 90.0, 90.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 80.0, 80.0, 80.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 60.0, 60.0, 60.0, 80.0, 80.0, 80.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 50.0, 50.0, 50.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 80.0, 80.0, 80.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [0.0, -29.221429726613827, -0.02787544137017206, -10.14435185957354, -20.0, -31.88800208730128, -10.0, -30.0, -3.217333926247831, -20.0, -21.136437953522847, -16.990348235623966, -35.52077182996457, -41.93081504447673, -27.637842857714897, -10.0, -30.733589419150803, -50.0, -14.357857517450677, -40.0, -41.765302223761864, -90.0, -14.984496410472168, -32.41674547112878, -20.438222790787783, -23.666870731376157, -2.204194764433889, -34.321374434234315, 0.0, -0.6753221365669526, -30.0, -32.52352926307229, -26.321057336997228, -13.480493692857221, -10.0, 0.0, -1.0545535166076903, -10.417449214211201, -20.317482530396227, -12.733901257708606, -41.05608081934978, -12.442130549306505, -27.096377285362674, -10.082098077035743, -37.63857392638682, -21.38296782425278, -22.72489805195769, -30.0, -20.0, -27.02075651101827, -30.209598302317783, -20.0, -10.773566878888305, -20.0, -10.0, -30.0, -50.22386933578761, -42.69257707691973, -25.41954095300378, -45.91827896186124, -57.82669515553451, -44.402811811990276, 0.0, -50.0, -30.0, 0.0, -40.243884133706345, -31.170597225003338, -80.0, -30.0, -4.3575968742474664, -0.04637138869436508, -35.7929741676949, -6.327901383482724, -30.0, -30.0, -8.608258485652795, -0.17401829697725857, -11.810617204348336, 0.0, -10.1830427647785, 0.0, -43.81457038401775, -60.0, -80.0, -35.254088377586015, -36.60435015406265, -1.4923686173091855, -6.810244027648393, -19.78605420300586, -45.85750962868912, 0.0, -20.0, -30.124788683068203, -40.341120378314265, -35.13119918831467, -18.87948303547926, -8.47750683732054, 0.0, -6.979609290649192, -69.28766469409989, -30.0, -39.604638979685255, 0.0, -14.654615452176245, -21.158675622988806, -23.703021766524788, -40.0, -50.0, -40.18135541993933, -22.417535653879924, -51.347030496865, -44.53774540310799, -20.443648184869208, -0.48185877424785195, 0.0, -8.761113551902145, -40.0, -30.0, -21.46567301879858, -34.101424027498034, -28.578253758965182, -60.0, -10.035587480955769, -33.74724335369193, 0.0, -1.1131078465580446, -37.7461658660623, -50.33468937254384, 0.0, -10.324105668772187, 0.0, -38.263446901530024, -10.0, -20.0, -20.0, -12.12151904813118, -20.0, -58.81980756074654, -36.63154798994019, -40.526112005935445, -51.038967213429004, -40.0, -20.36451509384699, -81.29489865561624, -32.88632433863357, -9.393110618279962, -9.00885726896333, -14.381249862448342, -20.58820330113934, 0.0, -20.0, 0.0, -30.0, 0.0, -15.632699614438367, -13.982873079463982, 0.0, -0.023516597338631984, -19.078169082892707, -32.81650361485999, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6410376307451318, "mean_inference_ms": 1.1033770904000257, "mean_action_processing_ms": 0.24145888692516373, "mean_env_wait_ms": 0.4801186378776353, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00415098519972813, "StateBufferConnector_ms": 0.0031410176077006774, "ViewRequirementAgentConnector_ms": 0.08566607663660873}, "num_episodes": 162, "episode_return_max": 180.0, "episode_return_min": -30.733589419150803, "episode_return_mean": 30.82602404835547}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1088000, "num_agent_steps_trained": 1088000, "num_env_steps_sampled": 272000, "num_env_steps_trained": 272000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 295.2023661211074, "num_env_steps_trained_throughput_per_sec": 295.2023661211074, "timesteps_total": 272000, "num_env_steps_sampled_lifetime": 272000, "num_agent_steps_sampled_lifetime": 1088000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1088000, "timers": {"training_iteration_time_ms": 13670.059, "restore_workers_time_ms": 0.023, "training_step_time_ms": 13669.941, "sample_time_ms": 1117.355, "learn_time_ms": 12539.081, "learn_throughput": 319.003, "synch_weights_time_ms": 12.836}, "counters": {"num_env_steps_sampled": 272000, "num_env_steps_trained": 272000, "num_agent_steps_sampled": 1088000, "num_agent_steps_trained": 1088000}, "done": false, "training_iteration": 68, "trial_id": "b72b3_00000", "date": "2024-08-08_15-47-49", "timestamp": 1723146469, "time_this_iter_s": 13.557133913040161, "time_total_s": 992.1966149806976, "pid": 98177, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3175de040>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 992.1966149806976, "iterations_since_restore": 68, "perf": {"cpu_util_percent": 28.221052631578942, "ram_util_percent": 81.7578947368421}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.556701131289204, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.775436778366566, "policy_loss": -0.02231496654324777, "vf_loss": 5.796248144408067, "vf_explained_var": 0.04454576460023721, "kl": 0.007518070335826332, "entropy": 0.8598989805206656, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 65760.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6250906593516363, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.580830531762847, "policy_loss": -0.01950607406506348, "vf_loss": 3.5996971038216397, "vf_explained_var": 1.4916379401024351e-06, "kl": 0.006394995947069448, "entropy": 0.4687565010701511, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 193170.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 276000, "num_env_steps_trained": 276000, "num_agent_steps_sampled": 1104000, "num_agent_steps_trained": 1104000}, "env_runners": {"episode_reward_max": 200.0, "episode_reward_min": -39.5582790970351, "episode_reward_mean": 29.698421357868607, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -100.0}, "policy_reward_max": {"adversary_policy": 100.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 17.469135802469136, "agent_policy": -22.7089860495388}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 60.32281611572888, 40.0, 80.0, -2.1123506628265787, 45.75561298309518, 13.785529441519529, 20.0, 48.61017726896434, 14.983349900888697, 37.73747562527752, 20.0, -6.811095315402002, 60.0, 33.17365687365017, 45.63309462081609, 49.203240868266, 20.0, 29.147000727831937, 4.312288841121834, 56.300909998244336, -15.437531987317197, 0.0, 0.0, -5.177133267172115, -37.70587216222992, -5.61398127912023, 80.0, 200.0, -39.5582790970351, 27.284991707087073, 56.043368411985625, 40.0, 14.32929925969539, 40.0, 0.0, 29.336824921737634, 40.0, -0.762295444534068, 20.0, -4.024958163421307, 0.0, -2.1743935498002758, 40.0, 118.70056832768032, -0.41979885046922405, 15.559360304242752, 38.71903262200331, 0.0, -9.684049018237465, 0.0, -20.116273974515146, 100.0, -18.438193630166225, -7.274204181544204, 80.0, -0.25281714302584857, 23.46834556191089, 0.0, -0.18110609593668392, -26.15697940450819, 20.0, 80.0, -33.229642751436614, 33.689144842395045, 0.0, 117.64467910093595, -4.80396697956699, 80.0, -8.572467438855268, -0.25994354856287094, 5.334287260884019, -0.7170934541029095, 40.0, 80.0, -5.827227171636908, 45.39727456486533, -0.7750346469447023, 79.62052039675804, -7.674477645379323, -10.36764620625724, -4.4576663139086055, -5.823732296275745, 63.01534967994801, -3.7339241114267416, 80.0, 36.4224982133143, 60.0, 55.54866296644054, 57.76543051236959, -6.817085008039885, 80.0, 40.0, 47.81432226920285, 15.599402542870264, -11.618628234147428, 33.382319722343205, 100.0, 39.71300621126897, 0.0, 118.54430374925676, 29.93553263991554, -9.02512000736556, 0.0, 60.0, 77.75613262405008, 15.70717216773199, 39.96263626623802, -9.771676546982032, -9.124746639852702, 98.37526274788516, -5.901389992890806, 0.0, 58.63706326248584, -3.1901359417616204, 20.0, -8.188155422227535, 50.14083100391279, 25.674432545600204, -6.050995725805171, -1.3876925070896962, 35.36603653518237, 9.645162551967552, 40.0, 140.0, 60.0, 60.0, -7.908143892237354, 138.7407916356711, 79.22542203095797, 39.21556211011709, 38.676347558385146, -9.7390991242667, 26.3154060003174, -5.9002053598566935, 40.0, 20.0, 49.75086410031715, 9.954936655643463, -3.83786943815742, -1.2934889662348215, 35.34963230838876, 18.688735657626523, 80.0, 0.0, 0.0, -26.61768127180733, 140.0, -9.176629928518018, 0.0, 60.0, 91.12456192467732, -2.6789526927417384, 55.92279631824671, 80.0, 0.0, 120.0, -13.175441977583485, 55.40170589878384, 19.22636348519379, 20.0, 160.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 100.0, 100.0, 100.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 70.0, 70.0, 70.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 80.0, 80.0, 80.0], "policy_agent_policy_reward": [0.0, -59.6771838842711, -20.0, -40.0, -2.1123506628265787, -44.24438701690482, -46.21447055848046, -10.0, -41.38982273103566, -15.016650099111303, -22.262524374722474, -10.0, -6.811095315402002, -30.0, -26.826343126349837, -44.36690537918391, -40.796759131734, -10.0, -30.85299927216807, -25.687711158878166, -33.699090001755664, -15.437531987317197, 0.0, 0.0, -5.177133267172115, -37.70587216222992, -5.61398127912023, -40.0, -100.0, -39.5582790970351, -32.71500829291293, -33.95663158801437, -20.0, -15.670700740304609, -20.0, 0.0, -30.663175078262363, -20.0, -0.762295444534068, -10.0, -4.024958163421307, 0.0, -2.1743935498002758, -20.0, -61.299431672319685, -0.41979885046922405, -14.440639695757248, -21.28096737799669, 0.0, -9.684049018237465, 0.0, -20.116273974515146, -50.0, -18.438193630166225, -7.274204181544204, -40.0, -0.25281714302584857, -36.531654438089106, 0.0, -0.18110609593668392, -26.15697940450819, -10.0, -40.0, -33.229642751436614, -26.310855157604973, 0.0, -62.35532089906405, -4.80396697956699, -40.0, -8.572467438855268, -0.25994354856287094, -24.665712739115982, -0.7170934541029095, -20.0, -40.0, -5.827227171636908, -44.602725435134666, -0.7750346469447023, -40.37947960324196, -7.674477645379323, -10.36764620625724, -4.4576663139086055, -5.823732296275745, -56.98465032005199, -3.7339241114267416, -40.0, -23.577501786685698, -30.0, -34.45133703355947, -32.23456948763041, -6.817085008039885, -40.0, -20.0, -42.18567773079715, -14.400597457129745, -11.618628234147428, -26.617680277656795, -50.0, -20.28699378873103, 0.0, -61.455696250743244, -30.064467360084453, -9.02512000736556, 0.0, -30.0, -42.24386737594992, -14.29282783226801, -20.037363733761982, -9.771676546982032, -9.124746639852702, -51.62473725211484, -5.901389992890806, 0.0, -31.36293673751417, -3.1901359417616204, -10.0, -8.188155422227535, -39.85916899608722, -34.325567454399796, -6.050995725805171, -1.3876925070896962, -24.633963464817622, -20.35483744803245, -20.0, -70.0, -30.0, -30.0, -7.908143892237354, -71.25920836432893, -40.77457796904204, -20.784437889882916, -21.32365244161485, -9.7390991242667, -33.684593999682605, -5.9002053598566935, -20.0, -10.0, -40.24913589968285, -20.045063344356535, -3.83786943815742, -1.2934889662348215, -24.65036769161123, -11.311264342373477, -40.0, 0.0, 0.0, -26.61768127180733, -70.0, -9.176629928518018, 0.0, -30.0, -58.87543807532268, -2.6789526927417384, -34.07720368175328, -40.0, 0.0, -60.0, -13.175441977583485, -34.59829410121617, -10.77363651480621, -10.0, -80.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6404867791538964, "mean_inference_ms": 1.1024867681274282, "mean_action_processing_ms": 0.24107905422754256, "mean_env_wait_ms": 0.4798581552821725, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0043038232826892245, "StateBufferConnector_ms": 0.0033297656494894147, "ViewRequirementAgentConnector_ms": 0.08791331891660337}, "num_episodes": 162, "episode_return_max": 200.0, "episode_return_min": -39.5582790970351, "episode_return_mean": 29.698421357868607}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1104000, "num_agent_steps_trained": 1104000, "num_env_steps_sampled": 276000, "num_env_steps_trained": 276000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 287.56732878861567, "num_env_steps_trained_throughput_per_sec": 287.56732878861567, "timesteps_total": 276000, "num_env_steps_sampled_lifetime": 276000, "num_agent_steps_sampled_lifetime": 1104000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1104000, "timers": {"training_iteration_time_ms": 13672.144, "restore_workers_time_ms": 0.015, "training_step_time_ms": 13672.106, "sample_time_ms": 1116.524, "learn_time_ms": 12542.857, "learn_throughput": 318.907, "synch_weights_time_ms": 12.223}, "counters": {"num_env_steps_sampled": 276000, "num_env_steps_trained": 276000, "num_agent_steps_sampled": 1104000, "num_agent_steps_trained": 1104000}, "done": false, "training_iteration": 69, "trial_id": "b72b3_00000", "date": "2024-08-08_15-48-03", "timestamp": 1723146483, "time_this_iter_s": 13.916965007781982, "time_total_s": 1006.1135799884796, "pid": 98177, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3175de1f0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1006.1135799884796, "iterations_since_restore": 69, "perf": {"cpu_util_percent": 31.310000000000002, "ram_util_percent": 82.14000000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.5307276539504526, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.942580516636371, "policy_loss": -0.023500730052182915, "vf_loss": 5.964213372766972, "vf_explained_var": -0.014428194736440976, "kl": 0.009339328581202185, "entropy": 0.8552137049535911, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 66720.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6115500820549667, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.5112361134366785, "policy_loss": -0.01913637719926233, "vf_loss": 3.529726285291902, "vf_explained_var": -2.9718622248223488e-06, "kl": 0.006462093877295756, "entropy": 0.4606367679775184, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 195990.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 280000, "num_env_steps_trained": 280000, "num_agent_steps_sampled": 1120000, "num_agent_steps_trained": 1120000}, "env_runners": {"episode_reward_max": 180.0, "episode_reward_min": -36.50101977000137, "episode_reward_mean": 29.61727167377303, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -90.0}, "policy_reward_max": {"adversary_policy": 90.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 16.97530864197531, "agent_policy": -21.3086542521529}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 60.0, -27.717339693403154, 26.524305586047582, -5.057710531838806, -6.655388888902258, -13.16395977812515, -0.19004374831001813, 90.99605625349349, 60.0, 60.0, 56.23532172773276, 40.0, -11.765468532690543, -15.137095793699448, 0.0, 34.12627438500591, -7.919002355146816, -9.584439091641295, 77.95865211281892, 0.0, -33.176882400838814, 39.36918517066496, 0.0, 0.0, -0.11718168343317736, 37.12512011820629, -3.967179032702351, -3.9886434691945327, 20.0, -0.5828612812815737, 60.0, -36.50101977000137, 100.0, -5.584463394392641, 79.74573824840596, -0.9874602916869579, 100.0, -1.299084661299944, 77.2423493966614, -9.86117082140746, -8.22986306069012, 0.0, -2.1973159599155565, 59.29915446594722, -18.679729597127547, 80.0, -11.588301010611413, 20.0, 47.37246145085407, 0.0, 60.0, 60.0, -22.22718662337767, 60.0, 0.0, 45.98992733062496, 57.93791575380685, 60.0, 0.0, 120.0, -0.6487217486885499, -1.0857320304134972, 0.0, 0.0, -0.5203415146358581, -11.546411908482169, -10.279678508329102, 31.43793495784349, 60.0, 0.0, 120.0, 35.1494836132278, 18.34216740808554, 116.46883825542452, 46.053133643305706, 20.0, 80.0, -2.6162924938327894, 20.0, -1.8672087207574417, -2.69083808782013, 160.0, -17.708615830556898, 35.23102048354419, 99.27690744568652, 20.0, 60.0, 120.0, 95.85053074277059, -0.4117143050300387, 20.0, 77.12129791341887, 40.0, 55.35258142243102, 72.63227797142017, 15.661733912470293, 100.0, -7.7500751848316805, 32.90872343329358, 78.27654884181291, -10.289092325347012, -0.9437635832208957, 180.0, -3.3020199642316452, -0.34601383329719737, -15.997794836784152, 20.0, 40.0, -6.362546225197972, 80.0, -18.36918204156229, 39.76844527119727, -1.1009020428737037, 0.0, 180.0, -3.2895630991654903, 80.0, 57.53743495107909, 18.234973363299694, 20.0, -0.06715129125839714, 0.0, 160.0, 40.0, 38.2889884059983, 120.0, 95.00212556682965, -3.057746718213359, 79.95256209863142, 27.566527046226668, -8.632619621801279, 18.3606401015277, 19.428079405770696, 40.0, -8.607632464334879, 60.0, 98.75882762953502, 17.94418944878928, 0.0, -0.11538313695911961, -4.898071721494149, 57.559815443817655, 37.688425117067816, 20.0, -1.3180653727370117, 40.0, -6.989662266703688, 90.33823101217678, 0.0, -5.977251227350036, 0.0, -13.698502471905412, -1.6418666499255996, 0.0, -6.141239367615611, -0.826970643798427, 97.65385791299029, 19.985890806145928, -0.1966574991669634, -20.282524264817273, 40.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 60.0, 60.0, 60.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 80.0, 80.0, 80.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 60.0, 60.0, 60.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 90.0, 90.0, 90.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 90.0, 90.0, 90.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 80.0, 80.0, 80.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 60.0, 60.0, 60.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0], "policy_agent_policy_reward": [0.0, -30.0, -27.717339693403154, -33.475694413952425, -5.057710531838806, -6.655388888902258, -13.16395977812515, -0.19004374831001813, -59.00394374650651, -30.0, -30.0, -33.76467827226724, -20.0, -11.765468532690543, -15.137095793699448, 0.0, -25.873725614994083, -7.919002355146816, -39.58443909164129, -42.04134788718108, 0.0, -33.176882400838814, -20.63081482933504, 0.0, 0.0, -0.11718168343317736, -22.874879881793706, -3.967179032702351, -3.9886434691945327, -10.0, -0.5828612812815737, -30.0, -36.50101977000137, -50.0, -5.584463394392641, -40.25426175159405, -0.9874602916869579, -50.0, -1.299084661299944, -42.7576506033386, -9.86117082140746, -8.22986306069012, 0.0, -2.1973159599155565, -30.700845534052778, -18.679729597127547, -40.0, -11.588301010611413, -10.0, -42.627538549145925, 0.0, -30.0, -30.0, -22.22718662337767, -30.0, 0.0, -44.01007266937504, -32.06208424619315, -30.0, 0.0, -60.0, -0.6487217486885499, -1.0857320304134972, 0.0, 0.0, -0.5203415146358581, -11.546411908482169, -10.279678508329102, -28.562065042156515, -30.0, 0.0, -60.0, -24.850516386772206, -41.65783259191448, -63.53116174457547, -43.94686635669431, -10.0, -40.0, -2.6162924938327894, -10.0, -1.8672087207574417, -2.69083808782013, -80.0, -17.708615830556898, -24.768979516455808, -50.72309255431348, -10.0, -30.0, -60.0, -84.14946925722941, -0.4117143050300387, -10.0, -42.87870208658113, -20.0, -34.64741857756898, -47.36772202857984, -14.338266087529707, -50.0, -7.7500751848316805, -27.09127656670642, -41.72345115818709, -10.289092325347012, -0.9437635832208957, -90.0, -3.3020199642316452, -0.34601383329719737, -15.997794836784152, -10.0, -20.0, -6.362546225197972, -40.0, -18.36918204156229, -20.231554728802728, -1.1009020428737037, 0.0, -90.0, -3.2895630991654903, -40.0, -32.462565048920915, -11.765026636700304, -10.0, -0.06715129125839714, 0.0, -80.0, -20.0, -21.711011594001693, -60.0, -54.99787443317036, -3.057746718213359, -40.04743790136858, -32.43347295377333, -8.632619621801279, -11.639359898472298, -10.571920594229304, -20.0, -8.607632464334879, -30.0, -51.24117237046498, -12.055810551210719, 0.0, -0.11538313695911961, -4.898071721494149, -32.44018455618234, -22.311574882932184, -10.0, -1.3180653727370117, -20.0, -6.989662266703688, -59.661768987823216, 0.0, -5.977251227350036, 0.0, -13.698502471905412, -1.6418666499255996, 0.0, -6.141239367615611, -0.826970643798427, -52.34614208700972, -10.014109193854072, -0.1966574991669634, -20.282524264817273, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6404643552943741, "mean_inference_ms": 1.1022116061596807, "mean_action_processing_ms": 0.24082763789555936, "mean_env_wait_ms": 0.47989330810142017, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004763514907271774, "StateBufferConnector_ms": 0.0032770780869472173, "ViewRequirementAgentConnector_ms": 0.09099259788607374}, "num_episodes": 162, "episode_return_max": 180.0, "episode_return_min": -36.50101977000137, "episode_return_mean": 29.61727167377303}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1120000, "num_agent_steps_trained": 1120000, "num_env_steps_sampled": 280000, "num_env_steps_trained": 280000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 301.06757290960775, "num_env_steps_trained_throughput_per_sec": 301.06757290960775, "timesteps_total": 280000, "num_env_steps_sampled_lifetime": 280000, "num_agent_steps_sampled_lifetime": 1120000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1120000, "timers": {"training_iteration_time_ms": 13619.653, "restore_workers_time_ms": 0.015, "training_step_time_ms": 13619.616, "sample_time_ms": 1112.785, "learn_time_ms": 12494.397, "learn_throughput": 320.143, "synch_weights_time_ms": 11.979}, "counters": {"num_env_steps_sampled": 280000, "num_env_steps_trained": 280000, "num_agent_steps_sampled": 1120000, "num_agent_steps_trained": 1120000}, "done": false, "training_iteration": 70, "trial_id": "b72b3_00000", "date": "2024-08-08_15-48-16", "timestamp": 1723146496, "time_this_iter_s": 13.292958974838257, "time_total_s": 1019.4065389633179, "pid": 98177, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3175de9d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1019.4065389633179, "iterations_since_restore": 70, "perf": {"cpu_util_percent": 31.084210526315786, "ram_util_percent": 82.4421052631579}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.420868967473507, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.07759290933609, "policy_loss": -0.028959327591292095, "vf_loss": 6.104484692712625, "vf_explained_var": 0.0019170054545005163, "kl": 0.010337673583513307, "entropy": 0.8814931896825632, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 67680.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6150731195055001, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.697163611608194, "policy_loss": -0.01829685494683498, "vf_loss": 3.7148714536470724, "vf_explained_var": -1.8585235514539353e-07, "kl": 0.005890127408585411, "entropy": 0.453434235058355, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 198810.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 284000, "num_env_steps_trained": 284000, "num_agent_steps_sampled": 1136000, "num_agent_steps_trained": 1136000}, "env_runners": {"episode_reward_max": 200.0, "episode_reward_min": -22.530714545965925, "episode_reward_mean": 30.55063666931085, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 153, "episodes_timesteps_total": 3825, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -100.96914261752961}, "policy_reward_max": {"adversary_policy": 100.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 17.973856209150327, "agent_policy": -23.370931958140126}, "custom_metrics": {}, "hist_stats": {"episode_reward": [180.0, 74.64383881830175, 37.74993216244185, -12.360827025923642, 60.0, -17.50948131300351, 0.0, 200.0, -5.433933444640717, 60.0, 40.0, 20.0, 159.8942446615457, -15.358327593747529, 36.35838119741434, -7.674261993763098, -4.326751522524663, -16.972415815194005, 56.46079266860767, -0.2765081342855946, -0.6914724489995472, 39.309188468834634, 40.0, 78.68566809622874, -13.600551093553332, 17.7898050400932, 0.0, 100.0, 27.123830646521625, -13.812811623371338, 40.0, 138.30565583388986, 54.63230191552684, 10.880782458545792, 0.0, -5.2686239610291326, 70.08656081724341, 39.99838802209173, 0.0, 37.731217274548875, 52.37958188359402, -9.337886550249182, -10.865814715284044, 0.0, -4.70230641778943, 60.0, 160.0, -3.1490669277361087, 40.0, 160.0, -0.18200162629327, 2.825232710960041, 179.60154055458483, 0.0, 12.779094659602759, 0.0, 17.655979140833644, 58.442176443231354, 0.0, -4.12097043776256, 0.0, 20.0, 24.66709995276094, 40.0, 30.745513956937597, 60.0, 0.0, -5.436528187001513, 0.0, -10.754526452851417, -17.331488213659213, -5.279999686992871, 36.261647219999084, -22.530714545965925, -1.2419540078927427, 0.0, 0.0, 74.9205576083682, 2.642551819266666, -13.818688730106729, -0.031211521951455268, 0.0, -0.8068316760982364, 40.0, 34.56652790824036, 54.28644164409521, 76.43577135155607, 51.97176306175001, -11.436802040740458, -15.918069441873556, 118.86086873285097, 33.83090210294186, 54.22007104933232, 39.51523458324361, 60.0, 100.0, 8.137480046012556, 39.25769926374062, -13.827367249998293, -12.680734775010944, 40.0, 40.0, 100.0, 48.434448039670265, -1.5124792526331918, -12.212591386925155, -0.6671590967317431, 39.99088507030419, 0.0, -8.04698884602278, 6.284947956443503, 40.0, 40.0, 13.030134185011155, -0.5033086065558545, 139.03085738247043, 140.0, 39.185031009813756, 79.22826194113853, 56.834276303498086, 20.0, 37.37438594360435, -4.5915197291336876, 120.0, 0.0, 79.98220719674853, 16.95558108276202, 35.64625005175046, 55.16149914627603, 60.0, 18.14185084712155, -5.362127997086357, -7.020036287969768, -1.347935610482064, 31.84327639500818, -0.47908555797812613, 13.524204195572585, 33.97061600723472, 60.0, -15.704203803446852, -8.985119289206015, -7.313784485304399, 10.099706239374669, 32.11905119409426, 20.0, 0.0, 59.93825951801982, 60.0, -11.814513266202523, -1.9842168727856724, 60.0, 31.016289988788394, -2.914933802125657], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [90.0, 90.0, 90.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 100.0, 100.0, 100.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 80.0, 80.0, 80.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 70.0, 70.0, 70.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 80.0, 80.0, 80.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 80.0, 80.0, 80.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 90.0, 90.0, 90.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 80.0, 80.0, 80.0, 70.0, 70.0, 70.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-90.0, -45.35616118169827, -52.25006783755814, -12.360827025923642, -30.0, -17.50948131300351, 0.0, -100.0, -5.433933444640717, -30.0, -20.0, -10.0, -80.10575533845429, -15.358327593747529, -23.64161880258566, -7.674261993763098, -4.326751522524663, -16.972415815194005, -63.53920733139234, -0.2765081342855946, -0.6914724489995472, -20.690811531165362, -20.0, -41.31433190377126, -13.600551093553332, -12.2101949599068, 0.0, -50.0, -32.87616935347838, -13.812811623371338, -20.0, -71.69434416611014, -35.36769808447317, -19.119217541454212, 0.0, -5.2686239610291326, -49.91343918275658, -20.001611977908272, 0.0, -22.268782725451125, -37.62041811640598, -9.337886550249182, -10.865814715284044, 0.0, -4.70230641778943, -30.0, -80.0, -3.1490669277361087, -20.0, -80.0, -0.18200162629327, -27.174767289039963, -90.39845944541517, 0.0, -17.22090534039724, 0.0, -12.344020859166356, -31.557823556768646, 0.0, -4.12097043776256, 0.0, -10.0, -35.332900047239065, -20.0, -29.254486043062396, -30.0, 0.0, -5.436528187001513, 0.0, -10.754526452851417, -17.331488213659213, -5.279999686992871, -23.738352780000923, -22.530714545965925, -1.2419540078927427, 0.0, 0.0, -45.079442391631794, -27.357448180733336, -13.818688730106729, -0.031211521951455268, 0.0, -0.8068316760982364, -20.0, -25.43347209175965, -35.71355835590479, -43.56422864844393, -38.02823693824999, -11.436802040740458, -15.918069441873556, -61.139131267149025, -56.169097897058144, -35.77992895066768, -50.48476541675639, -30.0, -50.0, -21.862519953987444, -20.74230073625938, -13.827367249998293, -12.680734775010944, -20.0, -20.0, -50.0, -41.56555196032973, -1.5124792526331918, -12.212591386925155, -0.6671590967317431, -20.009114929695812, 0.0, -8.04698884602278, -23.715052043556497, -20.0, -20.0, -16.969865814988847, -0.5033086065558545, -100.96914261752961, -70.0, -50.81496899018624, -40.77173805886147, -33.16572369650192, -10.0, -22.625614056395644, -4.5915197291336876, -60.0, 0.0, -40.01779280325146, -43.044418917237984, -24.353749948249543, -34.838500853723964, -30.0, -11.85814915287845, -5.362127997086357, -7.020036287969768, -1.347935610482064, -28.15672360499182, -0.47908555797812613, -16.47579580442742, -56.029383992765275, -30.0, -15.704203803446852, -8.985119289206015, -7.313784485304399, -19.90029376062533, -27.880948805905728, -10.0, 0.0, -30.061740481980184, -30.0, -11.814513266202523, -1.9842168727856724, -30.0, -28.983710011211613, -2.914933802125657]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6398285727244478, "mean_inference_ms": 1.1009009307755255, "mean_action_processing_ms": 0.24037027882122083, "mean_env_wait_ms": 0.47957755087717313, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004468945895924288, "StateBufferConnector_ms": 0.0030879880867752374, "ViewRequirementAgentConnector_ms": 0.08702465132171032}, "num_episodes": 153, "episode_return_max": 200.0, "episode_return_min": -22.530714545965925, "episode_return_mean": 30.55063666931085}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1136000, "num_agent_steps_trained": 1136000, "num_env_steps_sampled": 284000, "num_env_steps_trained": 284000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 307.4647567310127, "num_env_steps_trained_throughput_per_sec": 307.4647567310127, "timesteps_total": 284000, "num_env_steps_sampled_lifetime": 284000, "num_agent_steps_sampled_lifetime": 1136000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1136000, "timers": {"training_iteration_time_ms": 13554.487, "restore_workers_time_ms": 0.015, "training_step_time_ms": 13554.45, "sample_time_ms": 1112.017, "learn_time_ms": 12430.16, "learn_throughput": 321.798, "synch_weights_time_ms": 11.82}, "counters": {"num_env_steps_sampled": 284000, "num_env_steps_trained": 284000, "num_agent_steps_sampled": 1136000, "num_agent_steps_trained": 1136000}, "done": false, "training_iteration": 71, "trial_id": "b72b3_00000", "date": "2024-08-08_15-48-29", "timestamp": 1723146509, "time_this_iter_s": 13.015650033950806, "time_total_s": 1032.4221889972687, "pid": 98177, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3175dec10>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1032.4221889972687, "iterations_since_restore": 71, "perf": {"cpu_util_percent": 27.378947368421056, "ram_util_percent": 82.44736842105266}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.5794922955334187, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.057807527979215, "policy_loss": -0.02571531515714014, "vf_loss": 6.08177288522323, "vf_explained_var": -0.030620398682852587, "kl": 0.008749739420382005, "entropy": 0.8582871356979013, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 68640.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.623298772292357, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.81410926639611, "policy_loss": -0.0191914171376761, "vf_loss": 3.8326776742935182, "vf_explained_var": -2.39898127021519e-08, "kl": 0.006230098202788388, "entropy": 0.44637704697695185, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 201630.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 288000, "num_env_steps_trained": 288000, "num_agent_steps_sampled": 1152000, "num_agent_steps_trained": 1152000}, "env_runners": {"episode_reward_max": 266.0754993369986, "episode_reward_min": -32.22767110158892, "episode_reward_mean": 30.949742889500023, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -153.92450066300142}, "policy_reward_max": {"adversary_policy": 140.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 18.02469135802469, "agent_policy": -23.124331184574046}, "custom_metrics": {}, "hist_stats": {"episode_reward": [98.60495712310194, 160.0, 60.0, 42.30044417955512, 11.454760118664273, 38.28981922155243, -0.3300808581891057, -10.172566711901045, 17.104352805317603, 0.0, -7.013780068809863, 73.32775906770732, 20.0, 0.0, -7.341841205761297, 72.17040257561358, -5.255578305583658, -6.179047027066595, -4.950602819345076, 20.0, 80.0, 80.0, -20.9588001373175, 18.305517991020217, 97.71200583472843, 43.85187873609909, 0.0, -3.026098698529781, -5.559044011087626, 47.06160275100274, -5.1828869066752015, 158.5314341954617, 0.0, 40.0, 99.7402651614998, 33.85309916343263, 60.0, 39.55377433176686, -12.058535315604901, -14.359693843102662, 100.0, 60.0, -5.255743570236211, 80.0, -0.14210932126830333, 60.0, 60.0, -9.23363530132095, -10.733716131582916, 39.31833142400992, -11.292686133067933, 37.043245781164686, 40.0, 0.0, -4.043689408409401, 158.9593637187184, 60.0, 40.0, 36.996083338055584, 60.0, -29.76368851707136, -14.748022315464715, 55.06520726649714, -0.38802880917737537, 60.0, 20.0, 8.886876016995963, 99.94052461538797, 60.0, 40.0, 59.80527461562872, -15.99332009412617, 100.0, 60.0, -0.24918877556406538, 0.0, 120.0, 0.0, -8.538443937292415, 140.0, 0.0, 60.0, -7.97778504248145, 31.915211336555192, 0.0, -2.012907439828896, 45.697900771408186, -4.022982767873009, 20.0, 0.0, -32.22767110158892, 18.684708221539925, -3.290105131602837, 60.0, 14.34948033700297, 14.535050775888513, 0.0, 20.0, 0.0, 34.597205855683285, -2.931871357298035, 12.000893670101366, 79.31814583799775, -11.525523184694997, 33.82778516752529, 98.57176954909582, -13.289283020693018, 29.0566854939837, 0.0, 26.68293891981643, 60.0, -10.47394405346008, 34.92309284649213, 266.0754993369986, 37.82698071124645, -3.311946138190014, 53.460649841812995, 41.89590131211097, -6.623755313902839, -3.1135181157738527, 40.0, -4.459038234540026, 36.212165470877835, 0.0, -9.269843432029937, -10.510793849695458, 40.0, 20.0, -8.815015819564723, -3.1364710317264266, -22.385440115545833, 0.0, 80.0, 120.0, 40.0, 26.43905144706375, -13.013918267404382, 19.434287913828747, 80.0, 38.79091978878037, 78.5752032593567, 60.0, -14.706984494188141, -12.51784927560707, 37.21308164220555, 57.583714166439975, -12.74234967295732, 5.487858368736028, -10.518170828312241, 59.73107856532434, -6.920916258635741, 30.72063338086778, 80.0, -9.995189590651677, 33.29719401509334, 0.0, 37.480799847516565, 12.355808378521111, 37.61493777697531, 39.59243793577249, 140.0, 54.596397885206045], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [50.0, 50.0, 50.0, 80.0, 80.0, 80.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 80.0, 80.0, 80.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 80.0, 80.0, 80.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 140.0, 140.0, 140.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 70.0, 70.0, 70.0, 30.0, 30.0, 30.0], "policy_agent_policy_reward": [-51.39504287689807, -80.0, -30.0, -47.69955582044488, -18.54523988133573, -21.710180778447572, -0.3300808581891057, -10.172566711901045, -42.8956471946824, 0.0, -7.013780068809863, -46.67224093229269, -10.0, 0.0, -7.341841205761297, -47.829597424386414, -5.255578305583658, -6.179047027066595, -4.950602819345076, -10.0, -40.0, -40.0, -20.9588001373175, -11.694482008979781, -52.28799416527157, -46.14812126390091, 0.0, -3.026098698529781, -5.559044011087626, -42.93839724899726, -5.1828869066752015, -81.4685658045383, 0.0, -20.0, -50.259734838500194, -26.14690083656737, -30.0, -20.446225668233144, -12.058535315604901, -14.359693843102662, -50.0, -30.0, -5.255743570236211, -40.0, -0.14210932126830333, -30.0, -30.0, -9.23363530132095, -10.733716131582916, -20.68166857599008, -11.292686133067933, -22.956754218835314, -20.0, 0.0, -4.043689408409401, -81.04063628128158, -30.0, -20.0, -53.00391666194443, -30.0, -29.76368851707136, -14.748022315464715, -34.93479273350285, -0.38802880917737537, -30.0, -10.0, -21.11312398300404, -50.05947538461202, -30.0, -20.0, -30.194725384371285, -15.99332009412617, -50.0, -30.0, -0.24918877556406538, 0.0, -60.0, 0.0, -8.538443937292415, -70.0, 0.0, -30.0, -7.97778504248145, -28.0847886634448, 0.0, -2.012907439828896, -44.302099228591814, -4.022982767873009, -10.0, 0.0, -32.22767110158892, -11.315291778460075, -3.290105131602837, -30.0, -15.65051966299703, -15.464949224111487, 0.0, -10.0, 0.0, -25.40279414431671, -2.931871357298035, -17.999106329898634, -40.68185416200225, -11.525523184694997, -56.17221483247472, -51.42823045090418, -13.289283020693018, -30.943314506016304, 0.0, -33.31706108018357, -30.0, -10.47394405346008, -25.076907153507868, -153.92450066300142, -22.17301928875355, -3.311946138190014, -36.539350158187005, -48.10409868788903, -6.623755313902839, -3.1135181157738527, -20.0, -4.459038234540026, -23.787834529122172, 0.0, -9.269843432029937, -10.510793849695458, -20.0, -10.0, -8.815015819564723, -3.1364710317264266, -22.385440115545833, 0.0, -40.0, -60.0, -20.0, -33.56094855293624, -13.013918267404382, -10.565712086171251, -40.0, -21.209080211219632, -41.42479674064331, -30.0, -14.706984494188141, -12.51784927560707, -22.78691835779445, -32.41628583356004, -12.74234967295732, -24.512141631263976, -10.518170828312241, -30.26892143467567, -6.920916258635741, -29.279366619132222, -40.0, -9.995189590651677, -26.70280598490666, 0.0, -22.51920015248343, -17.64419162147889, -22.385062223024697, -20.407562064227506, -70.0, -35.40360211479395]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6394814979317404, "mean_inference_ms": 1.1000789762977317, "mean_action_processing_ms": 0.24001033874254055, "mean_env_wait_ms": 0.47926745738136667, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004761822429704078, "StateBufferConnector_ms": 0.004026477719530647, "ViewRequirementAgentConnector_ms": 0.08882181144055025}, "num_episodes": 162, "episode_return_max": 266.0754993369986, "episode_return_min": -32.22767110158892, "episode_return_mean": 30.949742889500023}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1152000, "num_agent_steps_trained": 1152000, "num_env_steps_sampled": 288000, "num_env_steps_trained": 288000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 297.5439998365542, "num_env_steps_trained_throughput_per_sec": 297.5439998365542, "timesteps_total": 288000, "num_env_steps_sampled_lifetime": 288000, "num_agent_steps_sampled_lifetime": 1152000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1152000, "timers": {"training_iteration_time_ms": 13504.423, "restore_workers_time_ms": 0.015, "training_step_time_ms": 13504.386, "sample_time_ms": 1113.478, "learn_time_ms": 12378.819, "learn_throughput": 323.133, "synch_weights_time_ms": 11.669}, "counters": {"num_env_steps_sampled": 288000, "num_env_steps_trained": 288000, "num_agent_steps_sampled": 1152000, "num_agent_steps_trained": 1152000}, "done": false, "training_iteration": 72, "trial_id": "b72b3_00000", "date": "2024-08-08_15-48-43", "timestamp": 1723146523, "time_this_iter_s": 13.450541973114014, "time_total_s": 1045.8727309703827, "pid": 98177, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3175dedc0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1045.8727309703827, "iterations_since_restore": 72, "perf": {"cpu_util_percent": 27.321052631578947, "ram_util_percent": 82.34736842105262}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.443695326025287, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.744490127513806, "policy_loss": -0.021207824874484988, "vf_loss": 5.764106971770525, "vf_explained_var": 0.014846851490437985, "kl": 0.007954932859423891, "entropy": 0.8053434137254953, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 69600.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6300617242958528, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.1183044574784895, "policy_loss": -0.02017258552792903, "vf_loss": 3.1378176715357085, "vf_explained_var": -1.2723900747637377e-06, "kl": 0.006593678237697745, "entropy": 0.4705204855888448, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 204450.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 292000, "num_env_steps_trained": 292000, "num_agent_steps_sampled": 1168000, "num_agent_steps_trained": 1168000}, "env_runners": {"episode_reward_max": 140.0, "episode_reward_min": -28.885502589814102, "episode_reward_mean": 24.51509332013797, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -80.91592532424707}, "policy_reward_max": {"adversary_policy": 70.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 15.061728395061728, "agent_policy": -20.670091865047215}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.8644645457436506, -0.3184499104646432, -11.367719475425954, 48.64473923250354, 60.0, -1.9989819943621345, -14.422598579769442, -20.352904449929177, 50.732005139447914, -21.419703182626673, 11.055183187526369, 0.0, 0.0, 33.404929526429115, 36.33802409920017, 79.38908644758406, 79.67488624318537, -1.081245750306622, -18.773281830759117, 80.0, 29.688409095348618, 32.836417895635755, 100.0, -20.63539712800361, 20.0, 60.0, 100.0, 98.67896077794745, -7.691810191782349, -17.181538470967475, 73.62587611288858, 120.0, 40.0, 47.17387571873651, 60.0, 96.23938829774288, 0.0, 40.0, 40.0, -2.4539877195201454, -26.736991876325806, 0.0, -7.643616395712975, 1.6948594881444632, -3.483352644541947, 6.721836794538396, 74.3831407011681, -5.216047108916539, -0.6715505546713452, 0.0, -6.544166795419934, 34.022647527214154, 32.89401135268979, 0.0, 40.0, -9.868164093985978, -8.89009119000128, 0.0, 31.778075517451256, 19.225791525709916, -19.741850842142398, -7.83020166618201, 20.0, 60.0, -0.42552276554911006, 0.0, -17.48529464772119, -5.286706428444093, -1.2870342946922153, 3.054214981770913, 0.0, 12.596836079603108, 20.0, 60.0, -4.762095437301784, 40.0, -16.433723480052844, 50.50428228418845, 35.570106350594884, -7.3020652157036805, 88.6034842067884, 37.02349541402831, 20.0, 60.0, -11.956601994963378, -9.943663948389297, 77.81484721300262, 100.0, 0.0, 60.0, -10.779204127464252, 0.0, 3.7553005903310748, -0.25511441627760756, 40.360329838671944, -0.18336651523500724, 100.0, -12.022822845085962, 0.0, 57.66934935382089, -3.3767375192147346, 39.95547188757771, 35.73473317342558, 16.234226048420314, 40.0, 20.0, 80.0, 20.0, -6.726168021710693, 20.0, -27.132047885629262, 99.08407467575294, -18.476325563446657, -18.80923673756322, -6.998632153817536, -5.340989197028903, 16.71541310340953, -1.4038353926763025, -26.904730352293264, -1.4919039899628561, 40.0, -1.307748949275307, 120.0, -12.240377762260032, -3.587042745507027, 0.0, 0.0, 77.22748696354124, 120.0, 59.78979376625435, 27.5584109543921, -5.384605651148073, -13.451191144681632, 0.0, 60.0, 60.0, 61.323423003698394, 60.0, -10.829208655392298, 60.0, -3.241621171484731, 60.0, 80.0, 80.0, -7.075340144268273, -0.5418738227007613, 140.0, 12.62097145679462, -28.885502589814102, -9.325470578673354, -1.977352364866407, 0.0, 140.0, -12.810559260264743, 36.01266749004814, -5.745078957605351, 60.0, 79.53742607578508, -7.215844386722422, -1.9126142181922101, 60.0, 40.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 60.0, 60.0, 60.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0], "policy_agent_policy_reward": [-0.8644645457436506, -0.3184499104646432, -11.367719475425954, -41.35526076749646, -30.0, -1.9989819943621345, -14.422598579769442, -20.352904449929177, -39.26799486055209, -21.419703182626673, -18.94481681247363, 0.0, 0.0, -26.595070473570882, -23.661975900799835, -40.61091355241594, -40.32511375681463, -1.081245750306622, -18.773281830759117, -40.0, -30.311590904651382, -27.163582104364245, -50.0, -20.63539712800361, -10.0, -30.0, -50.0, -51.32103922205255, -7.691810191782349, -17.181538470967475, -46.3741238871114, -60.0, -20.0, -42.82612428126349, -30.0, -53.76061170225714, 0.0, -20.0, -20.0, -2.4539877195201454, -26.736991876325806, 0.0, -7.643616395712975, -28.305140511855537, -3.483352644541947, -23.278163205461603, -45.61685929883189, -5.216047108916539, -0.6715505546713452, 0.0, -6.544166795419934, -25.977352472785846, -27.105988647310216, 0.0, -20.0, -9.868164093985978, -8.89009119000128, 0.0, -28.221924482548744, -10.774208474290086, -19.741850842142398, -37.83020166618202, -10.0, -30.0, -0.42552276554911006, 0.0, -17.48529464772119, -5.286706428444093, -1.2870342946922153, -26.94578501822909, 0.0, -17.40316392039689, -10.0, -30.0, -4.762095437301784, -20.0, -16.433723480052844, -39.49571771581155, -24.42989364940511, -7.3020652157036805, -61.39651579321159, -22.97650458597169, -10.0, -30.0, -11.956601994963378, -9.943663948389297, -42.185152786997385, -50.0, 0.0, -30.0, -10.779204127464252, 0.0, -26.24469940966892, -0.25511441627760756, -49.63967016132804, -0.18336651523500724, -50.0, -12.022822845085962, 0.0, -32.33065064617911, -3.3767375192147346, -20.044528112422288, -24.26526682657442, -13.765773951579686, -20.0, -10.0, -40.0, -10.0, -6.726168021710693, -10.0, -27.132047885629262, -80.91592532424707, -18.476325563446657, -18.80923673756322, -6.998632153817536, -5.340989197028903, -13.284586896590467, -1.4038353926763025, -26.904730352293264, -1.4919039899628561, -20.0, -1.307748949275307, -60.0, -12.240377762260032, -3.587042745507027, 0.0, 0.0, -42.772513036458754, -60.0, -30.210206233745645, -32.4415890456079, -5.384605651148073, -13.451191144681632, 0.0, -30.0, -30.0, -58.67657699630159, -30.0, -10.829208655392298, -30.0, -3.241621171484731, -30.0, -40.0, -40.0, -7.075340144268273, -0.5418738227007613, -70.0, -17.37902854320538, -28.885502589814102, -9.325470578673354, -1.977352364866407, 0.0, -70.0, -12.810559260264743, -23.987332509951866, -5.745078957605351, -30.0, -40.46257392421493, -7.215844386722422, -1.9126142181922101, -30.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6391476574323043, "mean_inference_ms": 1.0996291429840965, "mean_action_processing_ms": 0.23970541196196127, "mean_env_wait_ms": 0.47914502114387, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004690076098029996, "StateBufferConnector_ms": 0.003227481135615596, "ViewRequirementAgentConnector_ms": 0.09183883666992188}, "num_episodes": 162, "episode_return_max": 140.0, "episode_return_min": -28.885502589814102, "episode_return_mean": 24.51509332013797}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1168000, "num_agent_steps_trained": 1168000, "num_env_steps_sampled": 292000, "num_env_steps_trained": 292000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 307.4638889896834, "num_env_steps_trained_throughput_per_sec": 307.4638889896834, "timesteps_total": 292000, "num_env_steps_sampled_lifetime": 292000, "num_agent_steps_sampled_lifetime": 1168000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1168000, "timers": {"training_iteration_time_ms": 13466.343, "restore_workers_time_ms": 0.015, "training_step_time_ms": 13466.305, "sample_time_ms": 1110.931, "learn_time_ms": 12343.375, "learn_throughput": 324.06, "synch_weights_time_ms": 11.576}, "counters": {"num_env_steps_sampled": 292000, "num_env_steps_trained": 292000, "num_agent_steps_sampled": 1168000, "num_agent_steps_trained": 1168000}, "done": false, "training_iteration": 73, "trial_id": "b72b3_00000", "date": "2024-08-08_15-48-56", "timestamp": 1723146536, "time_this_iter_s": 13.015851020812988, "time_total_s": 1058.8885819911957, "pid": 98177, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3175ba550>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1058.8885819911957, "iterations_since_restore": 73, "perf": {"cpu_util_percent": 29.021052631578947, "ram_util_percent": 82.17894736842106}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.1610204447060823, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.405981236696244, "policy_loss": -0.023313315465444854, "vf_loss": 6.427676944434642, "vf_explained_var": 0.05270499245574077, "kl": 0.008088132545303968, "entropy": 0.8706813354666034, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 70560.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6379433181585995, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.4064543360513997, "policy_loss": -0.019305060520901918, "vf_loss": 3.425153294691803, "vf_explained_var": 1.5482412162401998e-06, "kl": 0.006061029404622483, "entropy": 0.452120256783269, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 207270.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 296000, "num_env_steps_trained": 296000, "num_agent_steps_sampled": 1184000, "num_agent_steps_trained": 1184000}, "env_runners": {"episode_reward_max": 174.3084212265834, "episode_reward_min": -44.45522370914793, "episode_reward_mean": 23.96394929480104, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -125.69157877341661}, "policy_reward_max": {"adversary_policy": 100.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 15.432098765432098, "agent_policy": -22.332347001495258}, "custom_metrics": {}, "hist_stats": {"episode_reward": [75.5569975147797, 80.0, 18.378053875869963, -1.1911304122230604, -31.673164674286667, -9.771585530080301, 60.0, 60.0, 14.83630390514226, 20.037850113171302, 50.9024567462806, 0.0, -25.61587904034634, -10.70810475034823, 99.0204203848618, 0.0, 35.22640265514288, 20.0, 20.0, 0.0, -19.01697432851575, -2.074652315579418, -7.060853916453626, -0.07061110589483888, 0.0, -0.7049122973794175, -18.823918848095328, 9.923554917866078, -12.097692946884647, 174.3084212265834, -23.682084672252028, 80.0, -5.339733764220522, 0.0, 13.023378774884407, -7.436022290905408, 44.34183207646912, 30.912965696967362, 9.31567666238953, -5.682564458915579, 52.49937115496709, -2.832661274376202, 18.55665628996855, -13.237489735656315, 15.403644733825002, 80.0, 80.0, 60.0, -17.04147493327654, 39.81548204304799, 0.0, -23.016700146760655, 39.01418997949145, 20.0, 24.207572654520476, 0.0, 44.99422971982456, 39.83452014903961, -18.669584626050113, 60.0, -2.484411802590458, 0.0, 87.52369832166502, 53.789778765718694, 40.0, 58.054063123066584, 25.75160906597825, 18.397694204488587, -6.093740268665683, 0.0, 60.0, 40.0, 20.0, 20.0, 40.0, -1.249751770385309, 28.665831437270814, 79.13750767671998, 35.652356962770426, 0.0, 9.278496137253628, -19.217374860560337, -8.136618316471242, 160.0, 40.0, 79.48731387141255, 57.33521817851725, 76.33150953293004, 35.45362909452276, 0.0, 40.0, -0.000994413970768493, 26.71695700189877, -11.548642331535737, -15.934162906731846, 38.99100545193376, -0.12369198159971062, 40.0, -1.767247739868134, -13.686931618318841, 25.299323636210932, 137.8333488472128, 60.0, -44.45522370914793, -9.577544881676411, -24.389718335818667, -16.73884203800398, -33.14993194110485, 0.0, 0.0, 70.52104943767804, -6.674825048791517, 94.78404852334077, 40.0, 59.86055898367492, 79.7168062833556, 0.0, 78.17120486916787, 139.24082299951812, 80.0, 33.65999251905743, 20.0, 0.0, -8.21690619924293, -1.1585117672524403, 14.21148829145307, -17.57096285185099, -0.3421012892929598, 61.9260875548447, -16.103774147389146, 37.934836093240335, 100.0, -1.0381048866301967, -2.813449299896207, 23.643848499523912, -4.750233032807796, -10.859598269408199, -6.2539300674374, 20.0, -11.999008265370147, -13.363009618032423, 50.98720879928472, 60.0, 33.169617886665826, -7.209027058407368, 49.78966415167718, 0.0, 120.0, 25.393724695135845, 20.0, 59.99392228301615, 100.0, -12.580674598456598, -1.1110988142278455, -7.64693252464952, 35.194239029548605, -26.181701365217435, -5.84629879728481, 9.579169223167908, 40.0, 26.594945936350115, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 100.0, 100.0, 100.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 80.0, 80.0, 80.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 70.0, 70.0, 70.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 70.0, 70.0, 70.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-44.4430024852203, -40.0, -41.621946124130034, -1.1911304122230604, -31.673164674286667, -9.771585530080301, -30.0, -30.0, -45.16369609485774, -39.962149886828705, -39.0975432537194, 0.0, -25.61587904034634, -10.70810475034823, -50.97957961513821, 0.0, -24.773597344857123, -10.0, -10.0, 0.0, -19.01697432851575, -2.074652315579418, -7.060853916453626, -0.07061110589483888, 0.0, -0.7049122973794175, -18.823918848095328, -20.076445082133926, -12.097692946884647, -125.69157877341661, -23.682084672252028, -40.0, -5.339733764220522, 0.0, -46.97662122511559, -7.436022290905408, -45.65816792353088, -29.087034303032638, -20.684323337610472, -5.682564458915579, -67.50062884503289, -2.832661274376202, -11.443343710031451, -13.237489735656315, -14.596355266174996, -40.0, -40.0, -30.0, -17.04147493327654, -20.184517956952007, 0.0, -23.016700146760655, -20.985810020508552, -10.0, -35.79242734547952, 0.0, -45.00577028017544, -20.165479850960388, -18.669584626050113, -30.0, -2.484411802590458, 0.0, -62.47630167833498, -36.210221234281306, -20.0, -31.94593687693341, -34.24839093402174, -11.602305795511414, -6.093740268665683, 0.0, -30.0, -20.0, -10.0, -10.0, -20.0, -1.249751770385309, -31.33416856272918, -40.86249232328002, -24.347643037229574, 0.0, -20.721503862746374, -19.217374860560337, -8.136618316471242, -80.0, -20.0, -40.51268612858744, -32.66478182148275, -43.66849046706996, -24.54637090547724, 0.0, -20.0, -0.000994413970768493, -33.28304299810123, -11.548642331535737, -15.934162906731846, -21.008994548066237, -0.12369198159971062, -20.0, -1.767247739868134, -13.686931618318841, -34.70067636378907, -72.16665115278721, -30.0, -44.45522370914793, -9.577544881676411, -24.389718335818667, -16.73884203800398, -33.14993194110485, 0.0, 0.0, -49.47895056232195, -6.674825048791517, -55.21595147665923, -20.0, -30.139441016325076, -40.2831937166444, 0.0, -41.828795130832134, -70.75917700048188, -40.0, -26.340007480942564, -10.0, 0.0, -8.21690619924293, -1.1585117672524403, -15.788511708546928, -17.57096285185099, -0.3421012892929598, -58.0739124451553, -16.103774147389146, -22.06516390675966, -50.0, -1.0381048866301967, -2.813449299896207, -36.35615150047608, -4.750233032807796, -10.859598269408199, -6.2539300674374, -10.0, -11.999008265370147, -13.363009618032423, -39.01279120071528, -30.0, -26.830382113334178, -7.209027058407368, -40.21033584832281, 0.0, -60.0, -34.606275304864155, -10.0, -30.006077716983853, -50.0, -12.580674598456598, -1.1110988142278455, -7.64693252464952, -24.805760970451395, -26.181701365217435, -5.84629879728481, -20.420830776832094, -20.0, -33.405054063649885, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6388527591649479, "mean_inference_ms": 1.0988642823868346, "mean_action_processing_ms": 0.23936518462546091, "mean_env_wait_ms": 0.47885326929350996, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004283439965895665, "StateBufferConnector_ms": 0.0035490518734778887, "ViewRequirementAgentConnector_ms": 0.0880261998117706}, "num_episodes": 162, "episode_return_max": 174.3084212265834, "episode_return_min": -44.45522370914793, "episode_return_mean": 23.96394929480104}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1184000, "num_agent_steps_trained": 1184000, "num_env_steps_sampled": 296000, "num_env_steps_trained": 296000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 297.5199178127104, "num_env_steps_trained_throughput_per_sec": 297.5199178127104, "timesteps_total": 296000, "num_env_steps_sampled_lifetime": 296000, "num_agent_steps_sampled_lifetime": 1184000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1184000, "timers": {"training_iteration_time_ms": 13421.325, "restore_workers_time_ms": 0.015, "training_step_time_ms": 13421.287, "sample_time_ms": 1114.159, "learn_time_ms": 12295.391, "learn_throughput": 325.325, "synch_weights_time_ms": 11.318}, "counters": {"num_env_steps_sampled": 296000, "num_env_steps_trained": 296000, "num_agent_steps_sampled": 1184000, "num_agent_steps_trained": 1184000}, "done": false, "training_iteration": 74, "trial_id": "b72b3_00000", "date": "2024-08-08_15-49-10", "timestamp": 1723146550, "time_this_iter_s": 13.449367046356201, "time_total_s": 1072.3379490375519, "pid": 98177, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3175ba790>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1072.3379490375519, "iterations_since_restore": 74, "perf": {"cpu_util_percent": 28.063157894736843, "ram_util_percent": 82.28947368421053}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.681262659902374, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.52560153628389, "policy_loss": -0.02406143424741458, "vf_loss": 5.548161209623019, "vf_explained_var": 0.03051411285996437, "kl": 0.007508853714516299, "entropy": 0.8417034201323986, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 71520.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6266711628870338, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.7940220670919893, "policy_loss": -0.019115606262550874, "vf_loss": 2.8125831116598548, "vf_explained_var": 3.404651127808483e-07, "kl": 0.005545597711825567, "entropy": 0.44943715569609444, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 210090.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 300000, "num_env_steps_trained": 300000, "num_agent_steps_sampled": 1200000, "num_agent_steps_trained": 1200000}, "env_runners": {"episode_reward_max": 209.7894904295635, "episode_reward_min": -30.740815923069484, "episode_reward_mean": 23.125761965785994, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -150.21050957043656}, "policy_reward_max": {"adversary_policy": 120.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 14.320987654320987, "agent_policy": -19.83720099717697}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-13.56529801107635, -0.5676910273929292, 26.00524823836263, -23.871697818827627, 209.7894904295635, 39.94935239971341, 59.0219664806012, 13.404949233540407, -4.035073216082719, 36.39264314854445, 53.28648888148223, -0.12531915710566888, -0.02504721666092835, 40.0, -1.1400383016991056, 36.36332408650536, 86.85146620264032, 20.0, 16.593384350469485, 0.0, 0.0, 132.6866684283019, -0.5563194948432919, 0.0, 19.700240893576773, 40.0, -1.7702385163665069, 60.0, 79.9079551620748, -7.33849724342382, -0.13303230417635503, 40.0, 40.0, 80.0, -9.893628688384545, 31.38219006366145, 20.0, 0.0, 19.273349253170423, -22.40736038316937, -9.672146685452573, 40.0, 60.0, -8.513078525304952, -11.170704025256182, 54.01838486770632, 10.322786835698093, -4.445788189371819, 60.0, 40.0, -4.1518305118549, 60.0, -0.6943636302418155, 77.11414063258734, 60.0, -0.35680806621005035, 39.477498831688195, 0.0, -7.3507384042014365, 87.8313872395403, 0.0, -7.733495946854524, 0.0, 196.9092295958875, -0.8163922240532462, 60.0, 56.20898914421283, -0.11111746634583697, 0.0, -0.8832333114784796, 44.26475659600829, -12.342974496319611, 0.0, -7.141743642856285, 59.1492886291343, 54.861983565071974, -1.2744461671316198, -7.175196691522752, -3.7201476602525823, 18.093936525100382, -13.813984220730685, -8.511538744918028, 20.0, -18.710694855385402, 111.37402132873956, -0.7195934155800321, 16.793336946583455, 19.44686689008851, -11.417181347277554, 33.59208475708358, 133.670407267443, -10.798213500100134, -10.411094541865028, -5.4661261462109705, 16.895859117532627, 99.67247768324225, 73.5136075369988, -3.256451963445901, 39.851994911341585, -20.563652469424873, -19.692332003663903, 60.0, -17.504855943514603, -3.1931483357119674, -12.022372831497092, 40.0, 19.390405473264423, -8.362086045690944, 51.8399047412871, -0.7216450303865185, -5.469995774747849, -4.998931898177048, 19.97862605314029, 34.115344352887924, 40.0, -7.45204663615227, 40.0, -0.23812404133505938, 100.0, 37.89168486606419, 73.178438897954, 0.0, -12.887304326339427, -6.436761078003566, -1.4741539045825491, 28.609221272662733, 43.48326893022064, 0.0, -3.2360825810842124, 23.873373004656298, 73.68854762896521, 60.0, -1.225174522672141, 18.39582502497725, -6.812148415567984, 40.0, -13.140910116521718, 118.89660774826129, 40.04283717006771, 0.0, -9.55397651549622, -0.17341396410477938, 40.0, -1.1547521502171632, -13.331420886839055, 60.0, 0.0, -30.740815923069484, -2.3792677105436733, 0.0, 0.0, 20.0, 17.959257028120128, 17.08556704910766, 139.78575595579917, -29.138538082463825, 5.591220026618863, 54.072814206482384, 0.0, 0.0, 74.43322520176268, -1.6180053816265871], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 120.0, 120.0, 120.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 100.0, 100.0, 100.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-13.56529801107635, -0.5676910273929292, -33.99475176163737, -23.871697818827627, -150.21050957043656, -20.050647600286585, -30.9780335193988, -16.595050766459593, -4.035073216082719, -23.607356851455556, -36.71351111851777, -0.12531915710566888, -0.02504721666092835, -20.0, -1.1400383016991056, -23.63667591349464, -63.1485337973597, -10.0, -13.406615649530522, 0.0, 0.0, -77.3133315716981, -30.55631949484329, 0.0, -10.299759106423227, -20.0, -1.7702385163665069, -30.0, -40.0920448379252, -7.33849724342382, -30.133032304176357, -20.0, -20.0, -40.0, -9.893628688384545, -28.617809936338553, -10.0, 0.0, -10.726650746829575, -22.40736038316937, -9.672146685452573, -20.0, -30.0, -8.513078525304952, -11.170704025256182, -35.98161513229368, -19.67721316430191, -4.445788189371819, -30.0, -20.0, -4.1518305118549, -30.0, -0.6943636302418155, -42.88585936741265, -30.0, -0.35680806621005035, -20.52250116831181, 0.0, -7.3507384042014365, -62.168612760459695, 0.0, -7.733495946854524, 0.0, -103.09077040411252, -0.8163922240532462, -30.0, -33.79101085578717, -0.11111746634583697, 0.0, -0.8832333114784796, -45.73524340399171, -12.342974496319611, 0.0, -7.141743642856285, -30.8507113708657, -35.13801643492802, -1.2744461671316198, -7.175196691522752, -3.7201476602525823, -11.906063474899618, -13.813984220730685, -8.511538744918028, -10.0, -18.710694855385402, -68.62597867126046, -0.7195934155800321, -13.206663053416547, -10.553133109911489, -11.417181347277554, -26.407915242916427, -76.32959273255697, -10.798213500100134, -10.411094541865028, -5.4661261462109705, -13.104140882467373, -50.32752231675775, -46.486392463001195, -3.256451963445901, -20.148005088658415, -20.563652469424873, -19.692332003663903, -30.0, -17.504855943514603, -3.1931483357119674, -12.022372831497092, -20.0, -10.609594526735574, -8.362086045690944, -38.16009525871289, -0.7216450303865185, -5.469995774747849, -4.998931898177048, -10.021373946859713, -55.884655647112076, -20.0, -7.45204663615227, -20.0, -0.23812404133505938, -50.0, -22.10831513393581, -46.821561102046, 0.0, -12.887304326339427, -6.436761078003566, -1.4741539045825491, -61.39077872733727, -46.51673106977936, 0.0, -3.2360825810842124, -36.1266269953437, -46.3114523710348, -30.0, -1.225174522672141, -11.604174975022751, -6.812148415567984, -20.0, -13.140910116521718, -61.10339225173871, -49.95716282993229, 0.0, -9.55397651549622, -0.17341396410477938, -20.0, -1.1547521502171632, -13.331420886839055, -30.0, 0.0, -30.740815923069484, -2.3792677105436733, 0.0, 0.0, -10.0, -12.040742971879872, -12.914432950892339, -70.21424404420083, -29.138538082463825, -24.408779973381133, -35.927185793517616, 0.0, 0.0, -45.566774798237304, -1.6180053816265871]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6381364641527413, "mean_inference_ms": 1.0978571526776066, "mean_action_processing_ms": 0.23903546171045717, "mean_env_wait_ms": 0.47853791453791145, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004388667919017651, "StateBufferConnector_ms": 0.0037846741852936923, "ViewRequirementAgentConnector_ms": 0.088152841285423}, "num_episodes": 162, "episode_return_max": 209.7894904295635, "episode_return_min": -30.740815923069484, "episode_return_mean": 23.125761965785994}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1200000, "num_agent_steps_trained": 1200000, "num_env_steps_sampled": 300000, "num_env_steps_trained": 300000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 300.03286244797914, "num_env_steps_trained_throughput_per_sec": 300.03286244797914, "timesteps_total": 300000, "num_env_steps_sampled_lifetime": 300000, "num_agent_steps_sampled_lifetime": 1200000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1200000, "timers": {"training_iteration_time_ms": 13407.862, "restore_workers_time_ms": 0.015, "training_step_time_ms": 13407.825, "sample_time_ms": 1114.162, "learn_time_ms": 12281.555, "learn_throughput": 325.692, "synch_weights_time_ms": 11.691}, "counters": {"num_env_steps_sampled": 300000, "num_env_steps_trained": 300000, "num_agent_steps_sampled": 1200000, "num_agent_steps_trained": 1200000}, "done": false, "training_iteration": 75, "trial_id": "b72b3_00000", "date": "2024-08-08_15-49-23", "timestamp": 1723146563, "time_this_iter_s": 13.337391138076782, "time_total_s": 1085.6753401756287, "pid": 98177, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3175bab80>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1085.6753401756287, "iterations_since_restore": 75, "perf": {"cpu_util_percent": 29.71052631578948, "ram_util_percent": 82.63157894736842}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.7896534534792106, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.386702948063612, "policy_loss": -0.023324993072795525, "vf_loss": 5.408189034213622, "vf_explained_var": -0.062369312594334286, "kl": 0.00919438386531913, "entropy": 0.8672934347763658, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 72480.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6167756525548638, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.0715436182546276, "policy_loss": -0.019158621928208764, "vf_loss": 3.090028442643213, "vf_explained_var": -2.2262546187596963e-06, "kl": 0.006737968896442286, "entropy": 0.4516298458508566, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 212910.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 304000, "num_env_steps_trained": 304000, "num_agent_steps_sampled": 1216000, "num_agent_steps_trained": 1216000}, "env_runners": {"episode_reward_max": 214.80613025426754, "episode_reward_min": -29.346835794340386, "episode_reward_mean": 26.48699036645707, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 153, "episodes_timesteps_total": 3825, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -115.19386974573246}, "policy_reward_max": {"adversary_policy": 110.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 15.816993464052288, "agent_policy": -20.963990025699793}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-1.5810089894939128, 57.024184369605166, 26.76887698264118, -0.9129961305031076, -2.5688697503042928, 17.369684477975532, 60.0, -3.0562667586006964, 20.0, 118.46764615216344, 43.764416068147966, 100.0, -23.01356823464542, 36.73766170825608, -20.907937639799687, 59.541424248342736, -11.143505459501515, -13.180286453289467, -8.066461839032542, 58.911078449764084, 0.0, 19.79254688567039, 59.27967691562745, 18.429709152703428, -3.758426427356209, 0.0, 80.0, 19.578881135395797, 37.90229531832857, 60.0, 6.474089708381886, 36.92611587298649, 29.417553142591693, 0.0, -13.218903422070888, 59.61649732313679, -7.382056974157958, 20.0, -13.981320243621898, 46.03648828660669, 140.0, 0.0, -6.861285165788628, -6.882893434256448, -19.76486240039152, 40.0, 59.45791120835475, 60.0, 80.0, -0.20394946255046564, 0.0, 80.0, -3.875131123330057, -2.3754190144549456, -0.8521714993156682, -0.5159255968372212, -10.418513111842058, -19.538767657360214, -4.141569562434851, -3.559334637875472, 0.0, 12.067667117164504, 60.0, 160.0, -0.4822983115114432, 120.0, 54.13601030039667, 18.719022205292134, -0.27523392317149953, -6.484244694047745, 60.0, 0.0, 119.38366880555316, 40.0, -16.301413782929345, 0.0, -3.05019974799546, -21.049877129083022, -5.880770461755488, -4.58441775544987, -11.35447648147633, 40.0, 98.87896690327375, 0.0, -6.886287187682395, 214.80613025426754, -9.721677473745103, 39.92880502452215, -7.891332426900453, 149.8926287351431, 118.71099480414405, 37.2006378443845, 52.23498575737332, 0.0, -9.120381538990282, -18.880205521926825, 57.716421943168086, -6.825772221047228, 79.5742887066344, 60.0, 32.521326782271295, 50.14188469135482, -21.532348544048734, -23.62213017154997, -7.7333675569842235, -16.856144430977203, 16.705713829723692, -4.317404221698037, -0.3035721147017112, 24.062483571450333, 60.0, 0.0, -4.01709881703848, 0.0, 75.97387565486713, -14.799152825822212, -3.3274689806909254, 80.0, 24.21434753178879, 29.601511531785206, 0.0, -1.0331910022478685, 60.0, 0.0, -4.542185137983049, 33.49482413206077, 60.0, -1.297750137984932, 0.0, 28.254428375608242, -2.4530792288859473, -0.47697914879798686, 60.0, -8.331228974888987, -29.346835794340386, -0.696796530268724, -2.3620589842294493, -1.1505722230823234, 79.38826691597043, 60.0, 79.6005094533576, -0.05137387717043973, 20.0, 59.91429883656107, -2.1460895592908438, -20.39399901781554, 120.0, 35.427656470933954, 96.83732144518721, -11.185527931933546, 117.96598745217013, 56.1844984438027, 60.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 60.0, 60.0, 60.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 80.0, 80.0, 80.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 110.0, 110.0, 110.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 80.0, 80.0, 80.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0], "policy_agent_policy_reward": [-1.5810089894939128, -32.97581563039484, -33.231123017358826, -0.9129961305031076, -2.5688697503042928, -12.630315522024468, -30.0, -3.0562667586006964, -10.0, -61.53235384783656, -46.235583931852034, -50.0, -23.01356823464542, -23.26233829174392, -20.907937639799687, -30.458575751657264, -11.143505459501515, -13.180286453289467, -8.066461839032542, -31.088921550235924, 0.0, -10.207453114329612, -30.720323084372545, -11.570290847296572, -3.758426427356209, 0.0, -40.0, -10.421118864604203, -22.097704681671434, -30.0, -23.525910291618114, -23.073884127013507, -30.582446857408307, 0.0, -13.218903422070888, -30.383502676863213, -7.382056974157958, -10.0, -13.981320243621898, -43.9635117133933, -70.0, 0.0, -6.861285165788628, -6.882893434256448, -19.76486240039152, -20.0, -30.54208879164525, -30.0, -40.0, -0.20394946255046564, 0.0, -40.0, -3.875131123330057, -2.3754190144549456, -0.8521714993156682, -0.5159255968372212, -10.418513111842058, -19.538767657360214, -34.14156956243485, -3.559334637875472, 0.0, -47.932332882835496, -30.0, -80.0, -0.4822983115114432, -60.0, -35.863989699603316, -11.280977794707866, -0.27523392317149953, -6.484244694047745, -30.0, 0.0, -60.61633119444686, -20.0, -16.301413782929345, 0.0, -3.05019974799546, -21.049877129083022, -5.880770461755488, -4.58441775544987, -11.35447648147633, -20.0, -51.12103309672626, 0.0, -6.886287187682395, -115.19386974573246, -9.721677473745103, -20.071194975477855, -7.891332426900453, -90.10737126485691, -61.28900519585596, -22.799362155615498, -37.76501424262668, 0.0, -9.120381538990282, -18.880205521926825, -32.283578056831914, -6.825772221047228, -40.425711293365595, -30.0, -27.4786732177287, -39.85811530864518, -21.532348544048734, -23.62213017154997, -7.7333675569842235, -16.856144430977203, -13.29428617027631, -4.317404221698037, -0.3035721147017112, -35.93751642854968, -30.0, 0.0, -4.01709881703848, 0.0, -44.026124345132864, -14.799152825822212, -3.3274689806909254, -40.0, -35.78565246821121, -30.398488468214794, 0.0, -1.0331910022478685, -30.0, 0.0, -4.542185137983049, -26.50517586793923, -30.0, -1.297750137984932, 0.0, -31.74557162439177, -2.4530792288859473, -0.47697914879798686, -30.0, -8.331228974888987, -29.346835794340386, -0.696796530268724, -2.3620589842294493, -1.1505722230823234, -40.61173308402957, -30.0, -40.3994905466424, -0.05137387717043973, -10.0, -30.08570116343892, -2.1460895592908438, -20.39399901781554, -60.0, -24.572343529066053, -53.162678554812786, -11.185527931933546, -62.034012547829875, -33.81550155619729, -30.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6375755460921216, "mean_inference_ms": 1.0971756452186874, "mean_action_processing_ms": 0.2386992641872393, "mean_env_wait_ms": 0.4784424624411863, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004485385869842729, "StateBufferConnector_ms": 0.0036038604437136183, "ViewRequirementAgentConnector_ms": 0.08589956495496961}, "num_episodes": 153, "episode_return_max": 214.80613025426754, "episode_return_min": -29.346835794340386, "episode_return_mean": 26.48699036645707}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1216000, "num_agent_steps_trained": 1216000, "num_env_steps_sampled": 304000, "num_env_steps_trained": 304000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 295.1304489870763, "num_env_steps_trained_throughput_per_sec": 295.1304489870763, "timesteps_total": 304000, "num_env_steps_sampled_lifetime": 304000, "num_agent_steps_sampled_lifetime": 1216000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1216000, "timers": {"training_iteration_time_ms": 13406.276, "restore_workers_time_ms": 0.015, "training_step_time_ms": 13406.238, "sample_time_ms": 1110.627, "learn_time_ms": 12283.626, "learn_throughput": 325.637, "synch_weights_time_ms": 11.614}, "counters": {"num_env_steps_sampled": 304000, "num_env_steps_trained": 304000, "num_agent_steps_sampled": 1216000, "num_agent_steps_trained": 1216000}, "done": false, "training_iteration": 76, "trial_id": "b72b3_00000", "date": "2024-08-08_15-49-37", "timestamp": 1723146577, "time_this_iter_s": 13.558113098144531, "time_total_s": 1099.2334532737732, "pid": 98177, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3175baee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1099.2334532737732, "iterations_since_restore": 76, "perf": {"cpu_util_percent": 28.084210526315786, "ram_util_percent": 82.77894736842106}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.6430064967523017, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.95931976934274, "policy_loss": -0.022650844522286207, "vf_loss": 5.980347986022632, "vf_explained_var": -0.021608518871168294, "kl": 0.008113077910003973, "entropy": 0.8543797388051947, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 73440.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6368007102756635, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.4122222262071378, "policy_loss": -0.020714201899212355, "vf_loss": 3.4322731975122545, "vf_explained_var": -5.345183906825722e-07, "kl": 0.006632271979393047, "entropy": 0.47082991849446126, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 215730.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 308000, "num_env_steps_trained": 308000, "num_agent_steps_sampled": 1232000, "num_agent_steps_trained": 1232000}, "env_runners": {"episode_reward_max": 179.26387899805744, "episode_reward_min": -29.915806405887356, "episode_reward_mean": 26.02351451852898, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -90.73612100194258}, "policy_reward_max": {"adversary_policy": 90.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 15.925925925925926, "agent_policy": -21.754263259248802}, "custom_metrics": {}, "hist_stats": {"episode_reward": [59.663617042814245, 54.055450137253075, 0.0, -18.35162850164491, 0.0, 0.0, -3.6987832285698863, 38.964956518673326, 47.38955613741134, -19.47652008884028, 57.29352801930198, -0.6291815146543622, -2.8316899262431496, 120.0, -7.018886286053586, -4.881308334185938, 20.0, 59.148379228847205, 60.0, 48.17053820741607, -0.06329029500427241, 0.0, -0.24930154270064642, -18.72493186582623, 60.0, 0.0, 46.85259833087936, 22.462766200278786, 40.0, 40.0, -4.424043327483673, 51.89605022592508, -3.905231475218073, 100.0, 20.0, 100.0, 80.0, 60.0, 41.86656953648589, -10.315731648879158, 29.68995479178927, 0.0, -7.2915760430263985, -2.925689461044109, -7.084430094105832, 100.0, 15.343480486998285, -11.812496946248082, 57.121341474047085, 80.0, -0.17433546293575186, 100.0, -9.484908754464996, 1.775699656346216, 20.0, -3.6119701233221355, -13.830323176235295, -29.915806405887356, -17.214260574457683, -16.134496996913487, 0.0, 44.02413086981549, -1.150481144971004, 9.764743852563043, 39.45226671853587, 28.24693962440643, -17.463044749121718, 53.838323004251976, 47.022795175608756, -10.590692921239432, 55.683893840931816, 55.40404844814299, 39.7876433397839, 40.0, 60.0, 39.48172569898933, -6.305118410883747, -21.019286905629826, -9.408461169717397, -3.687323281686533, 78.45902106864462, -5.428260528090625, 160.0, 100.0, -3.997101178827612, 2.2889938223673654, 17.141871746322696, 0.0, 54.6536167130933, 0.0, -1.7081812959674214, 33.843522947038906, 80.0, 100.0, -0.7933558327241697, 20.0, -11.165595889041203, -12.338048216637732, 40.0, -6.607077786982953, 60.0, 59.103809743196024, 60.0, -1.8192176170187768, -2.16348510425612, 160.0, -10.244518255860221, 39.739420726310115, -21.993048263657496, 58.84680131296339, -29.37947634562167, 80.0, 0.0, 14.465985016764733, 100.0, -9.61014089904965, 16.950870829919847, -16.70344146724208, 39.69157581681621, 33.13414242848229, 39.93941953991478, 80.0, -10.14369570961754, 7.102060567013567, 23.755899887432406, -2.196990198398235, -13.717140388120072, 20.826780409416063, 20.18154430461501, 0.0, 0.0, 36.84826272765588, 0.0, 30.20810948546899, 179.26387899805744, 40.0, 0.0, 39.719273047958275, -18.659443623646045, 13.99235931274329, -7.42003315050631, -5.639749999480851, 0.0, 40.0, -3.3056286658471015, 9.138925695589515, 40.0, -2.004851280090797, 0.0, 17.790398005288765, 156.8463987228272, 57.77347499075506, -0.1444640084600246, 0.0, 28.424261013542484, 55.91248792972074, 40.0, 76.80576314450647, -1.212884659310025, -4.815586935407476, 95.44607343682905, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 80.0, 80.0, 80.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 80.0, 80.0, 80.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 90.0, 90.0, 90.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 80.0, 80.0, 80.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-30.33638295718576, -35.944549862746925, 0.0, -18.35162850164491, 0.0, 0.0, -3.6987832285698863, -21.035043481326674, -42.61044386258865, -19.47652008884028, -62.706471980698026, -0.6291815146543622, -2.8316899262431496, -60.0, -7.018886286053586, -4.881308334185938, -10.0, -30.851620771152795, -30.0, -41.82946179258393, -0.06329029500427241, 0.0, -30.249301542700643, -18.72493186582623, -30.0, 0.0, -43.14740166912064, -37.53723379972121, -20.0, -20.0, -4.424043327483673, -38.10394977407492, -3.905231475218073, -50.0, -10.0, -50.0, -40.0, -30.0, -48.13343046351412, -10.315731648879158, -30.310045208210735, 0.0, -7.2915760430263985, -2.925689461044109, -7.084430094105832, -50.0, -14.656519513001713, -11.812496946248082, -32.87865852595291, -40.0, -0.17433546293575186, -50.0, -9.484908754464996, -28.224300343653784, -10.0, -3.6119701233221355, -13.830323176235295, -29.915806405887356, -47.214260574457676, -16.134496996913487, 0.0, -45.97586913018452, -1.150481144971004, -20.235256147436957, -20.547733281464126, -31.75306037559357, -17.463044749121718, -36.161676995748024, -72.97720482439124, -10.590692921239432, -34.316106159068184, -34.595951551857006, -20.212356660216102, -20.0, -30.0, -20.518274301010663, -6.305118410883747, -21.019286905629826, -9.408461169717397, -3.687323281686533, -41.54097893135538, -5.428260528090625, -80.0, -50.0, -3.997101178827612, -27.711006177632637, -12.858128253677304, 0.0, -35.3463832869067, 0.0, -1.7081812959674214, -26.15647705296109, -40.0, -50.0, -0.7933558327241697, -10.0, -11.165595889041203, -12.338048216637732, -20.0, -6.607077786982953, -30.0, -30.896190256803973, -30.0, -1.8192176170187768, -2.16348510425612, -80.0, -10.244518255860221, -20.26057927368989, -21.993048263657496, -31.153198687036607, -29.37947634562167, -40.0, 0.0, -15.534014983235267, -50.0, -9.61014089904965, -13.049129170080155, -16.70344146724208, -20.308424183183792, -26.865857571517708, -20.06058046008522, -40.0, -10.14369570961754, -22.897939432986433, -36.244100112567594, -2.196990198398235, -13.717140388120072, -39.173219590583926, -39.81845569538499, 0.0, 0.0, -23.151737272344125, 0.0, -29.791890514530998, -90.73612100194258, -20.0, 0.0, -20.280726952041725, -18.659443623646045, -16.00764068725671, -7.42003315050631, -5.639749999480851, 0.0, -20.0, -3.3056286658471015, -20.861074304410483, -20.0, -2.004851280090797, 0.0, -12.209601994711235, -83.15360127717281, -32.226525009244945, -0.1444640084600246, 0.0, -31.575738986457516, -34.08751207027925, -20.0, -43.19423685549351, -1.212884659310025, -4.815586935407476, -54.55392656317095, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6372768133706174, "mean_inference_ms": 1.0967157045366096, "mean_action_processing_ms": 0.23840951290471898, "mean_env_wait_ms": 0.47837289919120257, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006431782687151873, "StateBufferConnector_ms": 0.0031644915357048127, "ViewRequirementAgentConnector_ms": 0.09248035925405997}, "num_episodes": 162, "episode_return_max": 179.26387899805744, "episode_return_min": -29.915806405887356, "episode_return_mean": 26.02351451852898}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1232000, "num_agent_steps_trained": 1232000, "num_env_steps_sampled": 308000, "num_env_steps_trained": 308000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 299.8871715185607, "num_env_steps_trained_throughput_per_sec": 299.8871715185607, "timesteps_total": 308000, "num_env_steps_sampled_lifetime": 308000, "num_agent_steps_sampled_lifetime": 1232000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1232000, "timers": {"training_iteration_time_ms": 13387.664, "restore_workers_time_ms": 0.017, "training_step_time_ms": 13387.625, "sample_time_ms": 1116.675, "learn_time_ms": 12258.558, "learn_throughput": 326.303, "synch_weights_time_ms": 11.643}, "counters": {"num_env_steps_sampled": 308000, "num_env_steps_trained": 308000, "num_agent_steps_sampled": 1232000, "num_agent_steps_trained": 1232000}, "done": false, "training_iteration": 77, "trial_id": "b72b3_00000", "date": "2024-08-08_15-49-50", "timestamp": 1723146590, "time_this_iter_s": 13.390761852264404, "time_total_s": 1112.6242151260376, "pid": 98177, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3280fc160>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1112.6242151260376, "iterations_since_restore": 77, "perf": {"cpu_util_percent": 29.92105263157894, "ram_util_percent": 82.76842105263158}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.579031317929427, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.71671842088302, "policy_loss": -0.023400818371737842, "vf_loss": 5.7384169980883595, "vf_explained_var": 0.025806119292974473, "kl": 0.008511165484698916, "entropy": 0.8621155655632416, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 74400.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6363467797002894, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.545647140513075, "policy_loss": -0.019690571262019008, "vf_loss": 3.5646793736633677, "vf_explained_var": 7.410210075107872e-07, "kl": 0.006583447821841355, "entropy": 0.44630201539249287, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 218550.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 312000, "num_env_steps_trained": 312000, "num_agent_steps_sampled": 1248000, "num_agent_steps_trained": 1248000}, "env_runners": {"episode_reward_max": 220.0, "episode_reward_min": -25.51756473075968, "episode_reward_mean": 31.3371124332539, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -110.0}, "policy_reward_max": {"adversary_policy": 110.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 17.901234567901234, "agent_policy": -22.366591270449803}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-25.51756473075968, 40.0, 97.64254651880407, 120.0, 40.0, -0.49644091125159195, 0.0, 60.0, -8.48761465615275, -10.83165973662706, 0.0, -5.901156948649184, 30.721576850951376, 49.25205955765476, -10.73349413013057, 0.0, 40.0, 46.93628339962986, 0.0, 58.052599682941135, -14.291599334675517, 56.745838523535, 20.0, 53.96300476667587, 60.0, 80.0, -6.581791591653534, 48.15868297810879, 78.84836596068727, 20.0, 60.0, 0.0, -7.4874333551926044, -4.151235368001175, 7.984300668271669, 20.0, 20.0, -7.713138174923345, 0.0, 20.0, 37.50648760674675, 0.0, -5.57159911399322, 120.0, 60.0, -9.367434981938606, 0.0, 0.0, 59.88573112167869, -6.096446369402599, 40.0, 0.0, 0.0, 60.0, 20.0, 0.0, -5.368348384656916, -8.614481883201643, -5.757452076628403, -8.10408174550976, 99.42770632534706, 29.722305175365186, 92.08184927921097, 49.18622727470806, 16.47676353945433, 39.95852329193814, 0.0, 17.061711343472716, 140.0, 20.0, -6.135116430949887, 120.0, 80.0, 5.7926200448229075, 0.0, 13.195877448045286, -1.391269507149825, 60.0, -15.099102564241743, 74.3193768259975, -3.29614941661199, 20.0, 75.65226302710579, 77.63480402565843, 18.773231450957713, 109.8979708997488, 33.43147922367633, 100.0, 0.0, 79.30537667810461, 20.0, 50.743217349224004, -0.6244721504727446, -6.74640354506661, 37.02186181922892, 0.0, 0.0, 0.0, -6.745347389206761, -9.571208183479234, 40.0, 60.0, -3.129889477287489, 35.926516380128994, 16.84488401437116, -6.239270711229774, -12.39314489278014, 220.0, 117.15998060441142, -0.38631119689806703, -18.826023636009566, 0.0, -18.67199426566994, 53.17085132018747, 60.0, 97.70450647524262, 20.0, 100.0, 34.60906223844515, 20.0, 60.0, 79.7452659499787, 19.36879283800506, 80.0, 0.0, -11.32788980098131, -1.3762255595516304, 43.871679986252566, 52.076314011470195, 51.30361798402359, 20.0, -16.420791681677024, 60.0, 32.92111070921037, 18.442527300348253, 60.0, -1.5699758968926634, 95.5982442601773, 99.43624476327173, 55.080502512440034, 42.915274742882005, 0.0, 40.0, 29.757111428055765, 0.0, -6.6117290334188095, 60.0, 71.97549908227145, -10.008567539674708, 160.0, 54.12056856199223, 0.0, 0.0, 19.152148854831474, 34.10457537523854, -1.2877159193374788, -0.3067205453922375, 16.42657793072555, 40.0, 8.75800704274614, 40.0, 60.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 70.0, 70.0, 70.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 110.0, 110.0, 110.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 80.0, 80.0, 80.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0], "policy_agent_policy_reward": [-25.51756473075968, -20.0, -52.357453481195925, -60.0, -20.0, -30.496440911251582, 0.0, -30.0, -8.48761465615275, -10.83165973662706, 0.0, -35.90115694864918, -29.278423149048617, -40.74794044234524, -10.73349413013057, 0.0, -20.0, -43.06371660037014, 0.0, -31.94740031705886, -14.291599334675517, -33.254161476465, -10.0, -36.036995233324134, -30.0, -40.0, -6.581791591653534, -41.84131702189121, -41.151634039312725, -10.0, -30.0, 0.0, -7.4874333551926044, -4.151235368001175, -22.01569933172833, -10.0, -10.0, -7.713138174923345, 0.0, -10.0, -22.493512393253244, 0.0, -5.57159911399322, -60.0, -30.0, -9.367434981938606, 0.0, 0.0, -30.114268878321315, -6.096446369402599, -20.0, 0.0, 0.0, -30.0, -10.0, 0.0, -5.368348384656916, -8.614481883201643, -5.757452076628403, -8.10408174550976, -50.57229367465294, -30.277694824634814, -57.91815072078906, -40.81377272529194, -13.523236460545668, -20.041476708061857, 0.0, -12.938288656527284, -70.0, -10.0, -6.135116430949887, -60.0, -40.0, -24.207379955177093, 0.0, -46.80412255195471, -1.391269507149825, -30.0, -15.099102564241743, -45.680623174002505, -3.29614941661199, -10.0, -74.34773697289423, -42.36519597434158, -11.226768549042287, -70.1020291002512, -26.56852077632367, -50.0, 0.0, -40.694623321895385, -10.0, -39.256782650775996, -0.6244721504727446, -6.74640354506661, -22.978138180771083, 0.0, 0.0, 0.0, -6.745347389206761, -9.571208183479234, -20.0, -30.0, -3.129889477287489, -24.073483619871002, -13.155115985628838, -6.239270711229774, -12.39314489278014, -110.0, -62.840019395588584, -0.38631119689806703, -18.826023636009566, 0.0, -18.67199426566994, -36.82914867981253, -30.0, -52.29549352475737, -10.0, -50.0, -25.390937761554863, -10.0, -30.0, -40.25473405002129, -10.63120716199494, -40.0, 0.0, -11.32788980098131, -1.3762255595516304, -46.128320013747434, -37.923685988529805, -38.69638201597641, -10.0, -16.420791681677024, -30.0, -27.078889290789636, -11.557472699651747, -30.0, -1.5699758968926634, -54.40175573982271, -50.56375523672827, -34.91949748755996, -47.084725257117995, 0.0, -20.0, -30.242888571944228, 0.0, -6.6117290334188095, -30.0, -48.02450091772857, -10.008567539674708, -80.0, -35.87943143800778, 0.0, 0.0, -10.847851145168525, -25.895424624761457, -1.2877159193374788, -30.306720545392242, -13.57342206927445, -20.0, -21.24199295725386, -20.0, -30.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6374763451758814, "mean_inference_ms": 1.0965349122418357, "mean_action_processing_ms": 0.23823759615797063, "mean_env_wait_ms": 0.4783998046147543, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004438779972217701, "StateBufferConnector_ms": 0.003298344435515227, "ViewRequirementAgentConnector_ms": 0.09213516741623114}, "num_episodes": 162, "episode_return_max": 220.0, "episode_return_min": -25.51756473075968, "episode_return_mean": 31.3371124332539}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1248000, "num_agent_steps_trained": 1248000, "num_env_steps_sampled": 312000, "num_env_steps_trained": 312000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 294.9521394144883, "num_env_steps_trained_throughput_per_sec": 294.9521394144883, "timesteps_total": 312000, "num_env_steps_sampled_lifetime": 312000, "num_agent_steps_sampled_lifetime": 1248000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1248000, "timers": {"training_iteration_time_ms": 13388.814, "restore_workers_time_ms": 0.016, "training_step_time_ms": 13388.774, "sample_time_ms": 1125.552, "learn_time_ms": 12250.87, "learn_throughput": 326.507, "synch_weights_time_ms": 11.601}, "counters": {"num_env_steps_sampled": 312000, "num_env_steps_trained": 312000, "num_agent_steps_sampled": 1248000, "num_agent_steps_trained": 1248000}, "done": false, "training_iteration": 78, "trial_id": "b72b3_00000", "date": "2024-08-08_15-50-04", "timestamp": 1723146604, "time_this_iter_s": 13.567485809326172, "time_total_s": 1126.1917009353638, "pid": 98177, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x328194b80>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1126.1917009353638, "iterations_since_restore": 78, "perf": {"cpu_util_percent": 29.985000000000003, "ram_util_percent": 82.67500000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.399863239377737, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.861288346846899, "policy_loss": -0.02560019823577022, "vf_loss": 5.885181303819021, "vf_explained_var": 0.011668147953848044, "kl": 0.008536260299071983, "entropy": 0.8527212859441836, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 75360.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6263294440000615, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.360660524909378, "policy_loss": -0.01987884305632204, "vf_loss": 3.3798851211443015, "vf_explained_var": 4.671989603245512e-07, "kl": 0.006542489909949134, "entropy": 0.44049742752355886, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 221370.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 316000, "num_env_steps_trained": 316000, "num_agent_steps_sampled": 1264000, "num_agent_steps_trained": 1264000}, "env_runners": {"episode_reward_max": 140.0, "episode_reward_min": -50.720715180372835, "episode_reward_mean": 23.870981355319458, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -85.4641012337825}, "policy_reward_max": {"adversary_policy": 70.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 14.753086419753087, "agent_policy": -20.388277903939798}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-10.90641754058145, 56.92109700004604, 54.07057987409868, 40.0, -7.065819306115053, 37.68779307315392, -7.706116077245678, 60.0, -6.174868717140939, -9.728089007292738, -7.977261107688048, 19.422545589950886, -16.61505411879007, -50.720715180372835, 39.74881365332485, 44.09249961348709, 28.144859910511794, -4.411361358523535, -0.1085081835058932, 58.32629005834198, 60.0, 38.87654268118555, -0.7589735822481003, 65.89292555838114, 0.0, 40.0, 0.0, 0.0, -8.442206346306595, 0.0, -17.910984275340688, 38.34596147141167, 0.0, -11.438910457343086, 4.430548199046964, -2.810911466412808, -1.3917534060878478, -25.720649255851885, -1.682175870013406, 0.0, 47.16525569717933, 57.466711312153805, -14.992630654474848, 11.7018257579067, 60.0, 20.0, 49.822663541954064, 11.486364228372544, -9.079744789666522, 32.78193409347092, -0.5444498409250687, 30.929355102070588, 20.0, 16.93713205227473, 56.670826214849704, -9.207245418022975, 60.0, -0.4058036462928105, -7.101137320283611, -0.0008829716154046263, -2.4378788224629586, -3.1212803195794683, 0.0, 40.0, 56.12257307090614, -11.092992136818651, 0.0, 58.92792013296815, 38.69054943372956, 78.32528796903961, -0.05472513904077214, 0.0, 76.6104132360469, 60.0, -1.2417193931548758, 40.0, 18.338549495227493, -16.280122237875357, 58.31802300884499, 40.0, 80.0, 0.0, 32.165032205771496, -8.480713994091236, -9.779482522321613, 20.0, 57.98834665432733, -18.503798862728562, -6.883928224587111, 80.0, 113.79226270631827, 60.0, 37.28304640455656, 99.53316356465123, 40.0, 19.888265007186625, 40.0, -16.702975667478324, 0.0, 59.51773843857785, 60.0, -10.211368772139776, -6.601622330407428, -12.46643943231204, 0.0, 50.82723797131905, 40.0, 0.0, 19.328530009480396, 0.0, 20.0, 37.041154673971526, -16.869309070833282, 40.0, 17.750000663939243, 40.0, 17.22331999158232, 19.931303848799097, 0.0, 20.0, 80.0, 54.08015013348238, -19.031617189963082, -15.194578791983478, -3.319271982188875, 80.0, -0.3488438466939736, 40.0, 119.31632278031881, 60.0, 100.0, 3.1569051435923785, 40.0, 30.582399675653832, 19.791112355677505, 24.979859394605, -1.687205494576215, -17.31562656246791, -27.30631594637596, 60.0, -10.13345044634991, 44.21130454902324, 80.0, 55.81533991402323, 120.0, -3.8643679921760166, 80.0, -26.55909324460034, 76.03981164923948, 0.0, -8.937574155019064, 94.53589876621751, 140.0, 0.0, 0.0, 0.0, -34.533380857935434, 17.03524403954379, 81.07346329272568, 19.96797143954253, 39.85030659199379, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 60.0, 60.0, 60.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 60.0, 60.0, 60.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-10.90641754058145, -33.078902999953954, -35.92942012590132, -20.0, -7.065819306115053, -22.31220692684608, -7.706116077245678, -30.0, -6.174868717140939, -9.728089007292738, -7.977261107688048, -10.577454410049116, -16.61505411879007, -50.720715180372835, -20.251186346675148, -45.90750038651289, -31.855140089488213, -4.411361358523535, -0.1085081835058932, -31.673709941658025, -30.0, -21.123457318814456, -0.7589735822481003, -54.107074441618856, 0.0, -20.0, 0.0, 0.0, -8.442206346306595, 0.0, -17.910984275340688, -21.654038528588334, 0.0, -11.438910457343086, -25.569451800953036, -2.810911466412808, -1.3917534060878478, -25.720649255851885, -1.682175870013406, 0.0, -42.834744302820674, -32.533288687846195, -14.992630654474848, -18.2981742420933, -30.0, -10.0, -40.177336458045936, -18.513635771627456, -9.079744789666522, -27.218065906529077, -0.5444498409250687, -29.070644897929416, -10.0, -13.06286794772527, -33.329173785150296, -9.207245418022975, -30.0, -0.4058036462928105, -7.101137320283611, -0.0008829716154046263, -32.43787882246296, -3.1212803195794683, 0.0, -20.0, -33.87742692909385, -11.092992136818651, 0.0, -31.072079867031853, -21.309450566270442, -41.67471203096041, -0.05472513904077214, 0.0, -43.3895867639531, -30.0, -31.241719393154877, -20.0, -11.661450504772507, -16.280122237875357, -31.68197699115501, -20.0, -40.0, 0.0, -27.83496779422851, -8.480713994091236, -9.779482522321613, -10.0, -32.01165334567268, -18.503798862728562, -6.883928224587111, -40.0, -66.20773729368173, -30.0, -52.71695359544344, -50.46683643534876, -20.0, -10.111734992813373, -20.0, -16.702975667478324, 0.0, -30.48226156142215, -30.0, -10.211368772139776, -6.601622330407428, -12.46643943231204, 0.0, -39.17276202868095, -20.0, 0.0, -10.671469990519599, 0.0, -10.0, -22.95884532602848, -16.869309070833282, -20.0, -12.249999336060757, -20.0, -12.776680008417681, -10.068696151200903, 0.0, -10.0, -40.0, -35.91984986651763, -19.031617189963082, -15.194578791983478, -3.319271982188875, -40.0, -0.3488438466939736, -20.0, -60.683677219681186, -30.0, -50.0, -26.843094856407625, -20.0, -29.417600324346168, -10.208887644322493, -35.02014060539499, -1.687205494576215, -17.31562656246791, -27.30631594637596, -30.0, -10.13345044634991, -45.78869545097676, -40.0, -34.18466008597677, -60.0, -3.8643679921760166, -40.0, -26.55909324460034, -43.96018835076052, 0.0, -8.937574155019064, -85.4641012337825, -70.0, 0.0, 0.0, 0.0, -34.533380857935434, -12.964755960456207, -68.9265367072743, -10.03202856045747, -20.149693408006208, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6370553472281333, "mean_inference_ms": 1.0956275000861984, "mean_action_processing_ms": 0.23793512249395252, "mean_env_wait_ms": 0.4780847433379231, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0041590796576605905, "StateBufferConnector_ms": 0.0032196810216079523, "ViewRequirementAgentConnector_ms": 0.08722013897365993}, "num_episodes": 162, "episode_return_max": 140.0, "episode_return_min": -50.720715180372835, "episode_return_mean": 23.870981355319458}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1264000, "num_agent_steps_trained": 1264000, "num_env_steps_sampled": 316000, "num_env_steps_trained": 316000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 297.8390833981303, "num_env_steps_trained_throughput_per_sec": 297.8390833981303, "timesteps_total": 316000, "num_env_steps_sampled_lifetime": 316000, "num_agent_steps_sampled_lifetime": 1264000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1264000, "timers": {"training_iteration_time_ms": 13340.842, "restore_workers_time_ms": 0.016, "training_step_time_ms": 13340.804, "sample_time_ms": 1124.658, "learn_time_ms": 12203.4, "learn_throughput": 327.778, "synch_weights_time_ms": 12.065}, "counters": {"num_env_steps_sampled": 316000, "num_env_steps_trained": 316000, "num_agent_steps_sampled": 1264000, "num_agent_steps_trained": 1264000}, "done": false, "training_iteration": 79, "trial_id": "b72b3_00000", "date": "2024-08-08_15-50-18", "timestamp": 1723146618, "time_this_iter_s": 13.435660123825073, "time_total_s": 1139.6273610591888, "pid": 98177, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3280fc790>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1139.6273610591888, "iterations_since_restore": 79, "perf": {"cpu_util_percent": 28.599999999999998, "ram_util_percent": 83.05263157894737}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.563696494946877, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.145577299098174, "policy_loss": -0.023796408004515494, "vf_loss": 6.167457885543505, "vf_explained_var": 0.04705306397130092, "kl": 0.009579214737362672, "entropy": 0.8283770574877659, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 76320.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6229932400351721, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.5027750194495453, "policy_loss": -0.020136285059860783, "vf_loss": 3.5222092935379514, "vf_explained_var": 4.0886249948055184e-07, "kl": 0.007020065305204756, "entropy": 0.4261589158299967, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 224190.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 320000, "num_env_steps_trained": 320000, "num_agent_steps_sampled": 1280000, "num_agent_steps_trained": 1280000}, "env_runners": {"episode_reward_max": 160.0, "episode_reward_min": -39.52266616097989, "episode_reward_mean": 23.030726559186498, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 157, "episodes_timesteps_total": 3925, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -80.88134357810387}, "policy_reward_max": {"adversary_policy": 80.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 14.840764331210192, "agent_policy": -21.491566434444074}, "custom_metrics": {}, "hist_stats": {"episode_reward": [28.728902799226994, 20.0, -2.2705322337453904, 37.25099107923719, 44.12499814771734, 0.0, 11.65392319953511, -8.719829750015627, 31.853034489200382, 49.50012052607599, -1.0468014239753942, 20.03561237441225, 20.0, 160.0, 140.0, 100.0, -3.8477735044537553, 60.0, -3.601595492185763, -5.6847864669759645, 79.98282959871807, 35.620388658118976, 0.0, 20.0, -0.3505135022302508, -13.048638449605868, 0.0, 57.559361176074944, 16.432096696634055, -39.52266616097989, 52.196999721186636, -4.444473105562035, 0.0, 0.0, -1.42528929800946, -24.744233134963768, -2.670615755799674, 47.78827631645683, 13.584029505233914, 15.27924903056328, -9.918568004516162, 20.0, 60.0, 2.237323073607243, 55.098359680034875, 77.07897583907581, 45.059145740307144, 40.0, -0.37436181915873834, -13.27247951987286, 33.1183662387047, 60.0, 59.860964796461545, -5.767988888336334, 18.2514872835281, 40.0, -32.08443137580744, -4.013502775095286, -2.6831004793550637, -13.568688984011413, -38.954700805553415, -22.185303136245725, 0.0, 53.43752104992381, 13.875457102464217, 0.0, 37.03964368814265, 89.39559379882584, 0.0, -0.42823708462934706, -22.649073627390713, 53.16547646215653, 60.0, 37.63853353657286, -6.708106251324921, 40.0, 20.0, 19.875220420062497, -9.303730841324702, 0.0, 40.0, 20.0, 17.61223059785158, 0.0, 41.258835814207245, -0.5195929651400077, 40.0, 159.11865642189613, -0.18875213559312654, -9.87142485037373, -3.6339860906160677, 0.0, 11.320329792942903, -20.40277398576209, 34.75728907269132, -11.830726977878202, 20.0, 77.29890624084261, 0.0, -22.204034073792208, 60.0, -6.1433274454448785, 96.67383516708436, 39.963043130861784, 6.802774312671227, -12.9636048946912, 0.0, 80.0, 40.0, 25.214996951054523, -21.346991980623837, 20.0, -16.21703039468446, 60.0, 59.97119953117335, -3.0407717982691236, 60.0, -3.3395521840757825, 0.0, 53.6916662437475, 36.45533947505544, 35.962559627008396, -0.10167796264318962, -5.049415264522385, -29.107665199327634, 78.27808339267543, 20.0, 5.517499606229442, 30.396725860250363, -16.227708053424198, -17.79882609409847, 60.0, 59.77441089990549, 0.0, 40.0, 39.23138045541273, 60.0, 36.45018074443108, -9.851074052963128, 39.544412274050444, -8.805184729570314, 80.0, -1.8097141879559708, 69.77432193026931, -28.019611847384617, 60.0, 34.16774063755563, 91.82676150386565, -7.318451589084072, 0.0, -26.155702828220434, 36.19046820767693, 33.888854045351906, 42.61893574481758, 100.0, 58.224620081325995, -17.647246541621783], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 80.0, 80.0, 80.0, 70.0, 70.0, 70.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 80.0, 80.0, 80.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-31.271097200773006, -10.0, -2.2705322337453904, -22.749008920762805, -45.87500185228266, 0.0, -18.346076800464896, -8.719829750015627, -28.146965510799614, -40.499879473924004, -1.0468014239753942, -39.96438762558775, -10.0, -80.0, -70.0, -50.0, -3.8477735044537553, -30.0, -3.601595492185763, -5.6847864669759645, -40.01717040128192, -54.379611341881024, 0.0, -10.0, -0.3505135022302508, -13.048638449605868, 0.0, -32.44063882392505, -43.567903303365945, -39.52266616097989, -37.803000278813364, -4.444473105562035, 0.0, 0.0, -1.42528929800946, -24.744233134963768, -2.670615755799674, -42.21172368354317, -16.415970494766086, -44.72075096943672, -9.918568004516162, -10.0, -30.0, -27.762676926392757, -34.901640319965125, -42.92102416092419, -44.940854259692856, -20.0, -0.37436181915873834, -13.27247951987286, -26.881633761295284, -30.0, -30.139035203538455, -5.767988888336334, -11.748512716471902, -20.0, -32.08443137580744, -4.013502775095286, -2.6831004793550637, -13.568688984011413, -38.954700805553415, -22.185303136245725, 0.0, -36.56247895007618, -16.124542897535783, 0.0, -22.960356311857353, -60.604406201174164, 0.0, -0.42823708462934706, -22.649073627390713, -36.83452353784347, -30.0, -22.361466463427142, -6.708106251324921, -20.0, -10.0, -10.124779579937506, -9.303730841324702, 0.0, -20.0, -10.0, -12.387769402148418, 0.0, -48.74116418579275, -0.5195929651400077, -20.0, -80.88134357810387, -0.18875213559312654, -9.87142485037373, -3.6339860906160677, 0.0, -18.6796702070571, -20.40277398576209, -25.24271092730868, -11.830726977878202, -10.0, -42.70109375915739, 0.0, -22.204034073792208, -30.0, -6.1433274454448785, -53.32616483291563, -20.036956869138216, -23.19722568732877, -12.9636048946912, 0.0, -40.0, -20.0, -34.78500304894548, -21.346991980623837, -10.0, -16.21703039468446, -30.0, -30.028800468826653, -3.0407717982691236, -30.0, -3.3395521840757825, 0.0, -36.3083337562525, -23.544660524944554, -24.037440372991604, -0.10167796264318962, -5.049415264522385, -29.107665199327634, -41.72191660732457, -10.0, -24.482500393770557, -29.60327413974964, -16.227708053424198, -17.79882609409847, -30.0, -30.22558910009451, 0.0, -20.0, -20.768619544587267, -30.0, -53.54981925556892, -9.851074052963128, -20.455587725949556, -8.805184729570314, -40.0, -1.8097141879559708, -50.225678069730705, -28.019611847384617, -30.0, -25.83225936244435, -58.17323849613433, -7.318451589084072, 0.0, -26.155702828220434, -23.80953179232306, -26.111145954648084, -47.38106425518243, -50.0, -31.775379918674002, -17.647246541621783]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6381298073480808, "mean_inference_ms": 1.097029302009965, "mean_action_processing_ms": 0.23802842689734866, "mean_env_wait_ms": 0.47873010509632746, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005824095124651672, "StateBufferConnector_ms": 0.004158278179776137, "ViewRequirementAgentConnector_ms": 0.09857287072831658}, "num_episodes": 157, "episode_return_max": 160.0, "episode_return_min": -39.52266616097989, "episode_return_mean": 23.030726559186498}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1280000, "num_agent_steps_trained": 1280000, "num_env_steps_sampled": 320000, "num_env_steps_trained": 320000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 286.6363114343642, "num_env_steps_trained_throughput_per_sec": 286.6363114343642, "timesteps_total": 320000, "num_env_steps_sampled_lifetime": 320000, "num_agent_steps_sampled_lifetime": 1280000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1280000, "timers": {"training_iteration_time_ms": 13407.733, "restore_workers_time_ms": 0.016, "training_step_time_ms": 13407.695, "sample_time_ms": 1156.94, "learn_time_ms": 12237.791, "learn_throughput": 326.856, "synch_weights_time_ms": 12.244}, "counters": {"num_env_steps_sampled": 320000, "num_env_steps_trained": 320000, "num_agent_steps_sampled": 1280000, "num_agent_steps_trained": 1280000}, "done": false, "training_iteration": 80, "trial_id": "b72b3_00000", "date": "2024-08-08_15-50-32", "timestamp": 1723146632, "time_this_iter_s": 13.961482048034668, "time_total_s": 1153.5888431072235, "pid": 98177, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3280fc9d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1153.5888431072235, "iterations_since_restore": 80, "perf": {"cpu_util_percent": 28.845000000000006, "ram_util_percent": 82.45500000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.514587828392784, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.483435319364071, "policy_loss": -0.02509415269450983, "vf_loss": 5.506764679650465, "vf_explained_var": 0.038735250818232696, "kl": 0.008823928594412162, "entropy": 0.8094356088588636, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 77280.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6007555515102461, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.4747773261780432, "policy_loss": -0.018428234801919147, "vf_loss": 3.4926030585106385, "vf_explained_var": 6.987904825954573e-07, "kl": 0.006025079323906738, "entropy": 0.4348442057768504, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 227010.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 324000, "num_env_steps_trained": 324000, "num_agent_steps_sampled": 1296000, "num_agent_steps_trained": 1296000}, "env_runners": {"episode_reward_max": 180.0, "episode_reward_min": -26.977515661056174, "episode_reward_mean": 25.479015253028678, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 158, "episodes_timesteps_total": 3950, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -90.0}, "policy_reward_max": {"adversary_policy": 90.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 15.126582278481013, "agent_policy": -19.90073158241436}, "custom_metrics": {}, "hist_stats": {"episode_reward": [52.54513575678213, 60.0, -3.3297212079245035, 57.434374906070175, -0.060554251784941115, 40.0, 17.972256840126676, 60.0, -13.658609128151003, -9.922991179676991, -6.078480408392279, 60.0, 38.87889025086633, 35.04242384973931, -4.560153134139847, -8.245565526357385, -2.7898706979900805, 86.41086030820064, -15.017046039865724, 39.649041002695085, 60.0, -2.4118211417984736, 26.367525232637796, 140.0, 100.0, 8.658679124639216, 39.80746794032842, 140.0, -14.588511471282889, -3.547429877546782, -1.5497390124946109, 20.0, 12.589807093520058, -0.0398085785393032, 34.567699391328546, 0.0, 39.242114633071346, 100.0, 0.0, 43.07543847106336, 58.91549956169564, -3.669811207100177, 49.91261848872267, 19.54221962661025, 0.0, 59.80706190990418, 37.708689993097465, -2.1855961597605313, 0.0, 80.0, 100.0, 20.0, 180.0, -3.1625908908793745, 0.0, 0.0, -18.89918406585536, -7.505006128883039, 18.56231223794457, -1.7257307554462842, 51.767255534003844, -1.0048108108060172, 60.0, -19.01626663243225, -5.4593473897011755, 160.0, 60.0, 0.0, 40.0, 19.52603841111504, -4.827248784985749, 30.395474834964304, 0.0, 0.0, -4.633681111333396, 32.856286077369255, 138.79310678371536, 20.0, -17.419453090341847, -21.96108578764598, 0.0, -7.832907075531667, 0.0, -4.1387788828140115, 160.0, 20.0, -4.870301114468335, 29.150616126631647, 58.538583648605496, 132.33587395341098, 40.0, 20.0, 34.37469675396842, 34.10948001656846, 60.0, -9.566268257745222, 0.0, -0.20813597646610504, 40.0, 39.02378769201603, -16.02140794079122, 9.18646965112444, -25.180477813457543, -14.278584123998455, 0.0, -7.649269567048522, 37.17296099907997, -6.237508276915998, 0.0, 19.901483095035502, 0.0, -8.052118158838736, -14.692695626182084, -0.780159966381001, 15.55328106956852, 12.338036890436339, -16.078604662906542, 36.77094905374628, -2.747058919913368, 8.231028229777225, 20.0, -1.207111879731333, -13.420268963868715, 39.60973033128608, 111.47842723719761, 39.65251637337753, -0.4456775823104908, 0.0, -2.293948488492563, -1.6356380305260043, 100.0, 20.0, 35.162316494427884, -15.288568376546628, 80.0, 60.0, 60.0, -1.591259026017946, -3.720203458544128, -1.4241035309643717, -6.599122295302465, 100.0, 20.0, -7.546947867553871, 0.0, 8.45421903396561, 17.123177237605134, 8.827579528857848, 0.0, 0.0, -26.977515661056174, -1.651891906258369, 107.65809894677498, 60.0, -0.091677102467278, 33.53022658285647, 51.99460721698052, 114.97631055923534], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 70.0, 70.0, 70.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 90.0, 90.0, 90.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 80.0, 80.0, 80.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 70.0, 70.0, 70.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 80.0, 80.0, 80.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 70.0, 70.0, 70.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 60.0, 60.0, 60.0], "policy_agent_policy_reward": [-37.454864243217855, -30.0, -3.3297212079245035, -32.56562509392983, -0.060554251784941115, -20.0, -12.027743159873324, -30.0, -13.658609128151003, -9.922991179676991, -6.078480408392279, -30.0, -21.12110974913367, -24.957576150260696, -4.560153134139847, -8.245565526357385, -2.7898706979900805, -63.589139691799346, -15.017046039865724, -20.350958997304915, -30.0, -2.4118211417984736, -33.632474767362204, -70.0, -50.0, -21.341320875360783, -20.192532059671578, -70.0, -14.588511471282889, -3.547429877546782, -1.5497390124946109, -10.0, -17.41019290647994, -0.0398085785393032, -25.432300608671454, 0.0, -20.757885366928654, -50.0, 0.0, -46.92456152893664, -31.084500438304353, -3.669811207100177, -40.08738151127733, -10.457780373389747, 0.0, -30.192938090095815, -22.291310006902535, -2.1855961597605313, 0.0, -40.0, -50.0, -10.0, -90.0, -3.1625908908793745, 0.0, 0.0, -18.89918406585536, -7.505006128883039, -11.437687762055429, -1.7257307554462842, -38.232744465996156, -1.0048108108060172, -30.0, -19.01626663243225, -5.4593473897011755, -80.0, -30.0, 0.0, -20.0, -10.473961588884963, -4.827248784985749, -29.6045251650357, 0.0, 0.0, -4.633681111333396, -27.143713922630745, -71.20689321628466, -10.0, -17.419453090341847, -21.96108578764598, 0.0, -7.832907075531667, 0.0, -4.1387788828140115, -80.0, -10.0, -4.870301114468335, -30.849383873368343, -31.461416351394504, -77.66412604658903, -20.0, -10.0, -25.625303246031574, -25.89051998343154, -30.0, -9.566268257745222, 0.0, -0.20813597646610504, -20.0, -20.976212307983968, -16.02140794079122, -20.813530348875563, -25.180477813457543, -14.278584123998455, 0.0, -7.649269567048522, -22.827039000920024, -6.237508276915998, 0.0, -10.098516904964496, 0.0, -8.052118158838736, -14.692695626182084, -0.780159966381001, -14.44671893043148, -17.66196310956366, -16.078604662906542, -23.22905094625372, -2.747058919913368, -21.76897177022277, -10.0, -1.207111879731333, -13.420268963868715, -20.390269668713923, -68.52157276280239, -20.34748362662247, -0.4456775823104908, 0.0, -2.293948488492563, -1.6356380305260043, -50.0, -10.0, -24.837683505572112, -15.288568376546628, -40.0, -30.0, -30.0, -1.591259026017946, -3.720203458544128, -31.42410353096438, -6.599122295302465, -50.0, -10.0, -7.546947867553871, 0.0, -51.5457809660344, -12.876822762394863, -21.17242047114215, 0.0, 0.0, -26.977515661056174, -1.651891906258369, -72.34190105322502, -30.0, -0.091677102467278, -56.46977341714353, -38.00539278301948, -65.02368944076466]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6373513976082383, "mean_inference_ms": 1.0958422356545898, "mean_action_processing_ms": 0.23769841451852217, "mean_env_wait_ms": 0.4782785679387845, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004339369037483312, "StateBufferConnector_ms": 0.003270635121985327, "ViewRequirementAgentConnector_ms": 0.08571442169479176}, "num_episodes": 158, "episode_return_max": 180.0, "episode_return_min": -26.977515661056174, "episode_return_mean": 25.479015253028678}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1296000, "num_agent_steps_trained": 1296000, "num_env_steps_sampled": 324000, "num_env_steps_trained": 324000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 287.26809996027237, "num_env_steps_trained_throughput_per_sec": 287.26809996027237, "timesteps_total": 324000, "num_env_steps_sampled_lifetime": 324000, "num_agent_steps_sampled_lifetime": 1296000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1296000, "timers": {"training_iteration_time_ms": 13499.198, "restore_workers_time_ms": 0.016, "training_step_time_ms": 13499.159, "sample_time_ms": 1156.144, "learn_time_ms": 12329.415, "learn_throughput": 324.427, "synch_weights_time_ms": 12.599}, "counters": {"num_env_steps_sampled": 324000, "num_env_steps_trained": 324000, "num_agent_steps_sampled": 1296000, "num_agent_steps_trained": 1296000}, "done": false, "training_iteration": 81, "trial_id": "b72b3_00000", "date": "2024-08-08_15-50-46", "timestamp": 1723146646, "time_this_iter_s": 13.939549922943115, "time_total_s": 1167.5283930301666, "pid": 98177, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3280fcdc0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1167.5283930301666, "iterations_since_restore": 81, "perf": {"cpu_util_percent": 31.105, "ram_util_percent": 82.51}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.497106172268589, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.819296009093523, "policy_loss": -0.02338873793099386, "vf_loss": 5.841182612876097, "vf_explained_var": 0.013345090858638286, "kl": 0.007510642513831793, "entropy": 0.8419102825224399, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 78240.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6337221238630038, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.2527958240069395, "policy_loss": -0.020252579488173945, "vf_loss": 3.2724770980523834, "vf_explained_var": -1.1005722884590744e-07, "kl": 0.005713025983959799, "entropy": 0.4560179065199608, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 229830.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 328000, "num_env_steps_trained": 328000, "num_agent_steps_sampled": 1312000, "num_agent_steps_trained": 1312000}, "env_runners": {"episode_reward_max": 160.0, "episode_reward_min": -40.20314492513834, "episode_reward_mean": 26.40262698011163, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -83.71387174359268}, "policy_reward_max": {"adversary_policy": 80.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 15.679012345679013, "agent_policy": -20.63441005692541}, "custom_metrics": {}, "hist_stats": {"episode_reward": [32.24762288032422, 80.0, 119.50772342794596, 0.0, 93.88672207474272, -0.3774814546557992, -10.288699681817494, -5.1502057000096855, 80.0, 46.13896228713945, 120.0, -3.6598302824444655, -21.361010879792232, 0.0, 19.813882190378134, 60.0, 0.0, 60.0, 118.28299338372584, 14.332465090577129, 99.22542210037363, 56.788445073263844, 114.78497052130844, 19.286219551185585, 5.617011434785011, 79.01243607967531, 60.0, 70.3677981501359, -0.9045429952497719, -14.26485892195982, -0.4123432560320728, 0.0, -0.40242102390731005, 58.17637429798779, 0.0, 59.830370160750846, 0.0, -0.2206012055297646, -0.12151491066220821, 0.0, 58.53579481930777, -2.0140593610968924, 0.0, 0.0, 40.0, 24.045469826496042, 47.64001249830807, 0.0, 0.0, 160.0, 0.0, 40.0, -0.10744702007755236, -15.830869576777527, -11.634768391372784, -3.271879219592929, 40.0, -5.334461960514742, -6.824109878405056, -18.81288241427574, 27.19906136757139, 20.0, 96.15639407979263, 12.410928535701121, 0.0, 54.46530526965721, -16.220276498384216, -5.8239399945069215, 17.053826934397563, -15.994376812345813, 57.96111780924879, 20.0, 20.0, 1.1474434828039544, -8.519139479600518, -1.3648974205624642, 39.508682267817264, 0.0, 140.0, 0.0, -15.918424951071355, 38.21526194135119, 15.737875888226453, 0.0, -6.5637881064440275, 57.73221999002003, -9.403096804957707, 38.330082419040295, 0.0, 9.698231414581919, 6.0222616916284535, 40.0, 111.10546202841412, 39.71459789189303, 27.99136042546214, -11.514475654786953, 23.868423059203682, 18.31161163240546, 53.24714392925528, 60.0, -4.918464790773504, 6.640826704691434, 0.0, 60.0, 40.0, 40.0, 34.11998415374721, 89.58959893494853, 80.0, -0.19913154283202172, 40.0, 20.0, 79.11880526180181, 20.0, -1.129397719858467, -0.5200932042707895, -17.127877202934307, 115.12788538070552, 0.0, 40.0, 0.0, 58.16718071787726, -5.12132102424684, 0.0, 0.0, 39.00526655353815, 37.87099222353594, -9.293997565217438, 60.0, 56.0307979739266, -24.164952559917637, 60.0, 60.0, -0.6642122631212455, 0.0, 0.0, 6.589646242653576, 0.0, 60.0, -40.20314492513834, -0.2509005783374585, 20.0, 0.0, 96.28612825640732, 28.982344295612293, 58.902252649720964, -13.187297083774931, 19.397794711860577, -0.3191940163863416, -0.04409514603132325, 35.118637040532015, 100.0, 20.0, -10.135484977428751, -1.0848175038955796, -7.437328551747544, -0.7482545373442973, 10.373322171272848, -8.335196519031612, 60.0, 99.70768516749033, 60.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 60.0, 60.0, 60.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 60.0, 60.0, 60.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 80.0, 80.0, 80.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0], "policy_agent_policy_reward": [-27.752377119675778, -40.0, -60.492276572054024, 0.0, -56.11327792525728, -0.3774814546557992, -10.288699681817494, -5.1502057000096855, -40.0, -43.86103771286055, -60.0, -3.6598302824444655, -21.361010879792232, 0.0, -10.186117809621866, -30.0, 0.0, -30.0, -61.71700661627416, -15.667534909422871, -50.774577899626365, -33.211554926736156, -65.21502947869156, -10.713780448814411, -24.382988565214987, -40.98756392032469, -30.0, -49.6322018498641, -0.9045429952497719, -14.26485892195982, -0.4123432560320728, 0.0, -0.40242102390731005, -31.823625702012208, 0.0, -30.169629839249147, 0.0, -0.2206012055297646, -0.12151491066220821, 0.0, -31.464205180692225, -2.0140593610968924, 0.0, 0.0, -20.0, -35.95453017350396, -42.35998750169194, 0.0, 0.0, -80.0, 0.0, -20.0, -0.10744702007755236, -15.830869576777527, -11.634768391372784, -3.271879219592929, -20.0, -5.334461960514742, -6.824109878405056, -18.81288241427574, -32.80093863242861, -10.0, -53.843605920207374, -17.58907146429888, 0.0, -35.53469473034279, -16.220276498384216, -5.8239399945069215, -12.946173065602437, -45.99437681234581, -32.03888219075121, -10.0, -10.0, -28.852556517196046, -8.519139479600518, -1.3648974205624642, -20.491317732182733, 0.0, -70.0, 0.0, -15.918424951071355, -21.784738058648816, -14.262124111773545, 0.0, -6.5637881064440275, -32.26778000997997, -9.403096804957707, -51.669917580959705, 0.0, -20.301768585418085, -23.977738308371542, -20.0, -68.89453797158588, -20.28540210810698, -32.00863957453786, -11.514475654786953, -36.13157694079633, -41.68838836759454, -36.75285607074472, -30.0, -4.918464790773504, -23.35917329530856, 0.0, -30.0, -20.0, -20.0, -25.880015846252782, -60.41040106505147, -40.0, -0.19913154283202172, -20.0, -10.0, -40.88119473819818, -10.0, -1.129397719858467, -0.5200932042707895, -17.127877202934307, -64.87211461929448, 0.0, -20.0, 0.0, -31.832819282122745, -5.12132102424684, 0.0, 0.0, -20.99473344646185, -22.129007776464054, -9.293997565217438, -30.0, -33.9692020260734, -24.164952559917637, -30.0, -30.0, -0.6642122631212455, 0.0, 0.0, -23.410353757346424, 0.0, -30.0, -40.20314492513834, -30.250900578337465, -10.0, 0.0, -83.71387174359268, -31.017655704387703, -31.097747350279036, -13.187297083774931, -40.60220528813943, -0.3191940163863416, -0.04409514603132325, -24.881362959467978, -50.0, -10.0, -10.135484977428751, -1.0848175038955796, -7.437328551747544, -0.7482545373442973, -19.626677828727157, -8.335196519031612, -30.0, -50.29231483250966, -30.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6373894732629781, "mean_inference_ms": 1.095893672988485, "mean_action_processing_ms": 0.2374944971914064, "mean_env_wait_ms": 0.4782812692281044, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004651958559766228, "StateBufferConnector_ms": 0.003268542113127532, "ViewRequirementAgentConnector_ms": 0.09339414996865356}, "num_episodes": 162, "episode_return_max": 160.0, "episode_return_min": -40.20314492513834, "episode_return_mean": 26.40262698011163}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1312000, "num_agent_steps_trained": 1312000, "num_env_steps_sampled": 328000, "num_env_steps_trained": 328000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 301.34005419991894, "num_env_steps_trained_throughput_per_sec": 301.34005419991894, "timesteps_total": 328000, "num_env_steps_sampled_lifetime": 328000, "num_agent_steps_sampled_lifetime": 1312000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1312000, "timers": {"training_iteration_time_ms": 13482.264, "restore_workers_time_ms": 0.016, "training_step_time_ms": 13482.224, "sample_time_ms": 1160.336, "learn_time_ms": 12307.873, "learn_throughput": 324.995, "synch_weights_time_ms": 12.916}, "counters": {"num_env_steps_sampled": 328000, "num_env_steps_trained": 328000, "num_agent_steps_sampled": 1312000, "num_agent_steps_trained": 1312000}, "done": false, "training_iteration": 82, "trial_id": "b72b3_00000", "date": "2024-08-08_15-50-59", "timestamp": 1723146659, "time_this_iter_s": 13.314898252487183, "time_total_s": 1180.8432912826538, "pid": 98177, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3175e1040>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1180.8432912826538, "iterations_since_restore": 82, "perf": {"cpu_util_percent": 29.731578947368426, "ram_util_percent": 82.81052631578947}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.33595582904915, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.020622504750888, "policy_loss": -0.0268310031206056, "vf_loss": 6.045652132729689, "vf_explained_var": -0.003042072554429372, "kl": 0.00900688491479259, "entropy": 0.8553426302348573, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 79200.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6333546981849569, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.792426000419238, "policy_loss": -0.020622050346796737, "vf_loss": 3.812370714989114, "vf_explained_var": -3.353923770552831e-07, "kl": 0.006773327413874143, "entropy": 0.43429873228495847, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 232650.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 332000, "num_env_steps_trained": 332000, "num_agent_steps_sampled": 1328000, "num_agent_steps_trained": 1328000}, "env_runners": {"episode_reward_max": 160.0, "episode_reward_min": -35.738919256922614, "episode_reward_mean": 28.812998909529927, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -80.0}, "policy_reward_max": {"adversary_policy": 80.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 16.97530864197531, "agent_policy": -22.112927016395997}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.0, -7.9948529340058885, -23.695905427712898, 60.0, -1.5135956407394813, 0.0, 79.8470564138141, 76.10172440117505, 60.0, -0.7185435061915046, 14.625158705129913, -4.4168990491073155, 36.826590718135265, 53.64677567248717, 139.97202643715548, -35.738919256922614, 160.0, 37.721277089796914, -6.861586978150509, -7.589589080817142, 36.90321040348982, -9.924565686054041, 39.39504889046276, 28.816379113300236, -1.628757169226781, 60.0, 20.0, 32.57677976394669, 27.404591514407286, 40.0, 79.91705158115812, 12.845214462217243, 0.0, 92.029000352549, 40.0, -18.218993627590923, 32.30128332949238, 100.0, 0.0, 39.139139095603596, 140.0, 56.93401198260031, 0.0, 80.0, 40.0, -8.090280978139736, 57.971425722519434, 61.19861582553161, 54.59714181055272, 20.0, 48.68608846896515, -3.5471485761892927, 35.097976833637006, -0.10061547366810863, 19.66056311240174, 47.936650293802145, -7.073567304214627, 59.55814082793712, -2.705714175460864, -9.097764697049016, 40.0, 40.0, -5.472497363744182, 40.0, 31.742492572735685, 0.0, 40.0, -5.396612271683296, 0.0, 18.156844077946403, 80.0, 19.545775144213565, -9.986744164143536, -0.28528530137005403, 40.0, 78.08067058210105, -2.2005300160543118, -13.990752504730425, 60.0, -8.223502730259087, -16.400334700796318, -8.850427740010145, -3.7581126676277385, 18.88844579490118, -0.1379707607638414, 120.0, 73.94300452780172, 39.4663550181108, 0.0, 76.62090871684805, 0.0, 40.0, -4.364072809497749, 60.0, 78.62704617070074, 60.0, -11.972643119825635, 118.18543775565038, 19.09940924010652, 14.071661755381822, -16.350212356320945, 20.0, -14.434417270444033, 38.693905100153835, 21.80383884689814, -21.416201872273064, 0.0, -6.78700743874947, 40.0, -2.102492106212498, 99.28033639160444, 0.0, 0.0, 100.0, 0.0, 117.11288750754548, 120.0, 80.0, 0.0, 112.04884856875515, -12.294484820312489, 20.0, -1.607207731260002, 29.161760693077156, 0.0, 33.53613513932099, -9.751009535026423, 20.0, 20.0, 98.39769271633644, 60.0, 0.0, 0.0, 60.0, -7.669765784684378, 40.0, 19.555930362090063, 38.69811839763563, -16.020045472103668, 0.0, -6.051572018875262, 16.608661536003343, 20.0, 80.0, -16.207276225064454, 39.94270743935009, 33.034658297651134, -3.304897544789478, -9.912070529711709, -0.4182025936079825, 60.0, -25.14250908098014, -2.5970823949690534, -0.08863414857678165, 46.24764223574799, 120.0, -15.757768058035285, 96.47019254968507, -3.949977477124076, 31.82922816774213, 0.0, -1.0340746136468404], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 80.0, 80.0, 80.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 70.0, 70.0, 70.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 60.0, 60.0, 60.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-20.0, -7.9948529340058885, -23.695905427712898, -30.0, -1.5135956407394813, 0.0, -40.152943586185906, -43.89827559882496, -30.0, -0.7185435061915046, -15.374841294870087, -4.4168990491073155, -23.173409281864732, -66.35322432751286, -70.02797356284452, -35.738919256922614, -80.0, -22.278722910203083, -6.861586978150509, -7.589589080817142, -53.09678959651018, -9.924565686054041, -20.60495110953724, -31.183620886699764, -1.628757169226781, -30.0, -10.0, -27.423220236053314, -32.59540848559271, -20.0, -40.08294841884187, -17.154785537782757, 0.0, -57.970999647450995, -20.0, -48.21899362759092, -27.698716670507615, -50.0, 0.0, -20.860860904396404, -70.0, -33.06598801739968, 0.0, -40.0, -20.0, -8.090280978139736, -32.02857427748057, -58.80138417446839, -35.40285818944729, -10.0, -41.31391153103485, -3.5471485761892927, -24.90202316636299, -0.10061547366810863, -10.33943688759826, -42.063349706197855, -7.073567304214627, -30.44185917206288, -2.705714175460864, -9.097764697049016, -20.0, -20.0, -5.472497363744182, -20.0, -58.25750742726433, 0.0, -20.0, -5.396612271683296, 0.0, -11.8431559220536, -40.0, -10.454224855786435, -9.986744164143536, -0.28528530137005403, -20.0, -41.91932941789895, -2.2005300160543118, -13.990752504730425, -30.0, -8.223502730259087, -16.400334700796318, -8.850427740010145, -3.7581126676277385, -11.111554205098814, -0.1379707607638414, -60.0, -46.056995472198295, -50.5336449818892, 0.0, -43.379091283151936, 0.0, -20.0, -4.364072809497749, -30.0, -41.37295382929927, -30.0, -11.972643119825635, -61.81456224434961, -40.90059075989348, -15.928338244618178, -16.350212356320945, -10.0, -14.434417270444033, -21.30609489984617, -38.19616115310186, -21.416201872273064, 0.0, -6.78700743874947, -20.0, -2.102492106212498, -50.719663608395564, 0.0, 0.0, -50.0, 0.0, -62.88711249245452, -60.0, -40.0, 0.0, -67.95115143124485, -12.294484820312489, -10.0, -1.607207731260002, -30.838239306922844, 0.0, -26.463864860679003, -9.751009535026423, -10.0, -10.0, -51.602307283663556, -30.0, 0.0, 0.0, -30.0, -7.669765784684378, -20.0, -10.444069637909937, -21.301881602364368, -16.020045472103668, 0.0, -6.051572018875262, -43.391338463996654, -10.0, -40.0, -16.207276225064454, -20.057292560649916, -26.965341702348862, -3.304897544789478, -9.912070529711709, -0.4182025936079825, -30.0, -25.14250908098014, -2.5970823949690534, -0.08863414857678165, -43.75235776425201, -60.0, -15.757768058035285, -53.529807450314934, -3.949977477124076, -28.170771832257877, 0.0, -1.0340746136468404]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6371538992274157, "mean_inference_ms": 1.0955203249881886, "mean_action_processing_ms": 0.23725033130078696, "mean_env_wait_ms": 0.47823716185998677, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00425223950986509, "StateBufferConnector_ms": 0.003317182446703499, "ViewRequirementAgentConnector_ms": 0.08854608476897817}, "num_episodes": 162, "episode_return_max": 160.0, "episode_return_min": -35.738919256922614, "episode_return_mean": 28.812998909529927}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1328000, "num_agent_steps_trained": 1328000, "num_env_steps_sampled": 332000, "num_env_steps_trained": 332000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 286.2331834624966, "num_env_steps_trained_throughput_per_sec": 286.2331834624966, "timesteps_total": 332000, "num_env_steps_sampled_lifetime": 332000, "num_agent_steps_sampled_lifetime": 1328000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1328000, "timers": {"training_iteration_time_ms": 13578.76, "restore_workers_time_ms": 0.016, "training_step_time_ms": 13578.721, "sample_time_ms": 1164.438, "learn_time_ms": 12400.222, "learn_throughput": 322.575, "synch_weights_time_ms": 12.963}, "counters": {"num_env_steps_sampled": 332000, "num_env_steps_trained": 332000, "num_agent_steps_sampled": 1328000, "num_agent_steps_trained": 1328000}, "done": false, "training_iteration": 83, "trial_id": "b72b3_00000", "date": "2024-08-08_15-51-14", "timestamp": 1723146674, "time_this_iter_s": 14.025076150894165, "time_total_s": 1194.868367433548, "pid": 98177, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3175e1160>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1194.868367433548, "iterations_since_restore": 83, "perf": {"cpu_util_percent": 30.880000000000006, "ram_util_percent": 82.88}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.7089029966543117, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.4672719640036425, "policy_loss": -0.0249072748318819, "vf_loss": 5.490490859746933, "vf_explained_var": 0.026442388134698073, "kl": 0.008441869545127526, "entropy": 0.87696894860516, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 80160.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6153157949553314, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.165775394270606, "policy_loss": -0.02031529382210149, "vf_loss": 3.185403737954214, "vf_explained_var": -1.1079700280588569e-07, "kl": 0.00686950261084584, "entropy": 0.4412646143783069, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 235470.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 336000, "num_env_steps_trained": 336000, "num_agent_steps_sampled": 1344000, "num_agent_steps_trained": 1344000}, "env_runners": {"episode_reward_max": 140.0, "episode_reward_min": -32.63512640966299, "episode_reward_mean": 25.179746706717335, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 157, "episodes_timesteps_total": 3925, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -75.7751645769013}, "policy_reward_max": {"adversary_policy": 70.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 15.222929936305732, "agent_policy": -20.48904310219986}, "custom_metrics": {}, "hist_stats": {"episode_reward": [32.50126848746174, 37.65582610726034, 94.88705916398031, 0.0, 60.0, 37.71482529029272, -12.721161629607973, -0.38606199273329644, 40.0, -1.9939399342316622, 100.0, 33.96270095351767, 40.0, 0.0, 20.0, 0.0, 37.75486992681782, -9.779567042713827, 46.203036721031324, 59.960725261403596, -3.2644363214639873, 33.97843471411481, -2.429892522984364, 0.0, -6.629407834900778, 57.02914819126514, 0.0, -18.569035633864807, 100.0, 60.0, 20.0, 100.0, 38.89760652333501, 78.7302577778388, 20.0, -3.1953602187322083, -6.53109037780126, 40.0, -1.7967259009879515, 35.422759065848375, 0.0, 0.0, 0.0, 39.44930843234096, -7.681464375388594, -1.892390633343699, 16.703921333427576, 44.435289257401095, -0.03563922395532826, -2.9437091724708164, 40.0, 17.04145708053899, -9.317038218442349, -12.824660542387926, 80.0, 79.5395254945851, 53.64022437652515, -7.800883802088129, -27.687385866404725, 140.0, 80.0, 0.0, 16.847874268893566, 40.0, -2.6916788904240505, 100.0, -3.279078686419157, 39.95829741841469, -8.043687263414073, 56.324217309580675, -15.914256311719111, 20.0, -22.792670668300367, 0.0, 80.0, -4.24561811724065, -5.306572719039918, 0.0, -11.164709843210035, 9.356374656765789, 40.0, 0.0, 44.60548980952423, -32.63512640966299, -0.7920022364762547, 59.87009641866681, 111.39281717897587, 59.53445261276434, 74.0455772131925, 80.0, 0.0, 0.0, -12.557164045480784, 0.0, -19.01506514016485, -17.029970458523067, -12.34005864369451, 60.0, 14.821278954088811, 18.873053259409204, 19.34184435400158, -6.837938175028863, 35.94948553388759, -0.1454730390935255, 0.0, 72.71136288329213, 40.0, 0.0, -11.763321143602118, 54.277272737853366, 23.901379636284336, -4.461949389885338, 80.0, 0.0, 0.0, -2.66454821716377, 60.0, 20.0, 26.888662508904346, -10.134193217911873, 60.0, 60.0, 60.0, 100.0, -12.800545969549967, -3.734263079952309, 80.0, 32.4990210682661, 20.0, 19.401020513902118, -14.780134565901593, -3.783620566451506, -1.160061202716538, 20.0, 60.0, 77.31591401491501, 39.5353835048493, -17.2967332471039, 94.53006450566981, -2.2671575112420204, 60.0, 20.0, -5.87990187769556, -16.383560727214995, -1.1689276807545026, -15.229295874324489, -21.880295481173178, 28.072291941584947, 134.2248354230987, 7.90536411724395, -11.542257339794487, -17.175512268823734, 60.0, 78.1518773952283, 119.62188859408366, 58.707377397434946, -24.57538518148392], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 60.0, 60.0, 60.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 70.0, 70.0, 70.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 60.0, 60.0, 60.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-27.49873151253826, -22.34417389273966, -55.112940836019696, 0.0, -30.0, -22.285174709707274, -12.721161629607973, -0.38606199273329644, -20.0, -1.9939399342316622, -50.0, -26.03729904648233, -20.0, 0.0, -10.0, 0.0, -22.245130073182178, -9.779567042713827, -43.796963278968676, -30.0392747385964, -3.2644363214639873, -26.021565285885195, -2.429892522984364, 0.0, -6.629407834900778, -32.970851808734864, 0.0, -18.569035633864807, -50.0, -30.0, -10.0, -50.0, -21.102393476664993, -41.269742222161206, -10.0, -3.1953602187322083, -6.53109037780126, -20.0, -1.7967259009879515, -24.577240934151625, 0.0, 0.0, 0.0, -20.550691567659037, -7.681464375388594, -1.892390633343699, -13.296078666572422, -45.564710742598905, -0.03563922395532826, -2.9437091724708164, -20.0, -12.958542919461006, -9.317038218442349, -42.82466054238793, -40.0, -40.460474505414886, -36.35977562347486, -7.800883802088129, -27.687385866404725, -70.0, -40.0, 0.0, -73.15212573110644, -20.0, -2.6916788904240505, -50.0, -3.279078686419157, -20.041702581585312, -8.043687263414073, -33.675782690419325, -15.914256311719111, -10.0, -22.792670668300367, 0.0, -40.0, -4.24561811724065, -5.306572719039918, 0.0, -11.164709843210035, -20.643625343234213, -20.0, 0.0, -45.39451019047577, -32.63512640966299, -0.7920022364762547, -30.129903581333192, -68.60718282102413, -30.465547387235656, -45.95442278680751, -40.0, 0.0, 0.0, -12.557164045480784, 0.0, -19.01506514016485, -17.029970458523067, -12.34005864369451, -30.0, -15.17872104591119, -11.126946740590798, -10.658155645998416, -6.837938175028863, -24.050514466112407, -0.1454730390935255, 0.0, -47.288637116707875, -20.0, 0.0, -11.763321143602118, -35.722727262146634, -36.09862036371567, -4.461949389885338, -40.0, 0.0, 0.0, -2.66454821716377, -30.0, -10.0, -33.111337491095654, -10.134193217911873, -30.0, -30.0, -30.0, -50.0, -12.800545969549967, -3.734263079952309, -40.0, -27.500978931733886, -10.0, -10.598979486097884, -14.780134565901593, -3.783620566451506, -1.160061202716538, -10.0, -30.0, -42.684085985085, -20.4646164951507, -17.2967332471039, -55.4699354943302, -2.2671575112420204, -30.0, -10.0, -5.87990187769556, -16.383560727214995, -1.1689276807545026, -45.22929587432449, -21.880295481173178, -31.927708058415053, -75.7751645769013, -22.09463588275605, -11.542257339794487, -17.175512268823734, -30.0, -41.84812260477172, -60.37811140591635, -31.292622602565054, -24.57538518148392]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6374486394419167, "mean_inference_ms": 1.0963269016048793, "mean_action_processing_ms": 0.23714063700583204, "mean_env_wait_ms": 0.4785092717284415, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004470955794024619, "StateBufferConnector_ms": 0.003258437867377214, "ViewRequirementAgentConnector_ms": 0.09573743601513517}, "num_episodes": 157, "episode_return_max": 140.0, "episode_return_min": -32.63512640966299, "episode_return_mean": 25.179746706717335}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1344000, "num_agent_steps_trained": 1344000, "num_env_steps_sampled": 336000, "num_env_steps_trained": 336000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 294.73040174783404, "num_env_steps_trained_throughput_per_sec": 294.73040174783404, "timesteps_total": 336000, "num_env_steps_sampled_lifetime": 336000, "num_agent_steps_sampled_lifetime": 1344000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1344000, "timers": {"training_iteration_time_ms": 13591.485, "restore_workers_time_ms": 0.016, "training_step_time_ms": 13591.444, "sample_time_ms": 1171.525, "learn_time_ms": 12405.972, "learn_throughput": 322.425, "synch_weights_time_ms": 12.79}, "counters": {"num_env_steps_sampled": 336000, "num_env_steps_trained": 336000, "num_agent_steps_sampled": 1344000, "num_agent_steps_trained": 1344000}, "done": false, "training_iteration": 84, "trial_id": "b72b3_00000", "date": "2024-08-08_15-51-27", "timestamp": 1723146687, "time_this_iter_s": 13.577811241149902, "time_total_s": 1208.4461786746979, "pid": 98177, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3175e1700>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1208.4461786746979, "iterations_since_restore": 84, "perf": {"cpu_util_percent": 31.863157894736847, "ram_util_percent": 83.22105263157894}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.686896734312177, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.058745951453845, "policy_loss": -0.027875496458727868, "vf_loss": 5.084553473442793, "vf_explained_var": 0.08198719726254543, "kl": 0.01033994695016387, "entropy": 0.8620017901062965, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 81120.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6194743269037271, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.745698034763336, "policy_loss": -0.01982825061897516, "vf_loss": 2.7649046985392873, "vf_explained_var": 2.741179567702273e-07, "kl": 0.006215884239091512, "entropy": 0.4352043486021935, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 238290.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 340000, "num_env_steps_trained": 340000, "num_agent_steps_sampled": 1360000, "num_agent_steps_trained": 1360000}, "env_runners": {"episode_reward_max": 149.8222680884661, "episode_reward_min": -53.44625154267835, "episode_reward_mean": 21.456634456204664, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -90.17773191153393}, "policy_reward_max": {"adversary_policy": 80.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 13.518518518518519, "agent_policy": -19.098921099350893}, "custom_metrics": {}, "hist_stats": {"episode_reward": [20.0, 0.0, 0.0, 0.0, 0.0, -4.451054114356163, 0.0, -17.374390557383208, 103.78684201758352, 0.0, 80.0, 60.0, -0.02766889376346393, 60.0, -3.3385500997198436, 32.3629640536542, -2.3436917074829067, -0.23658992126032485, 0.0, 36.528626892444045, 80.0, 0.0, -5.386418432198374, 0.0, 57.529065781417025, -13.932119751651767, 0.0, -0.10841052087002478, 91.15898596059226, 39.464925637895874, 116.10581720247211, -3.3635446834210825, 25.50318418829931, -10.967084922580339, 20.0, -0.842014271148469, 0.0, -9.527452442569352, -16.05698184607845, 49.45979433702136, 0.0, 34.584589565820295, 0.0, 111.42468486272205, -11.792322278876986, -6.296185279296915, 12.00946375569209, -2.214976962036811, -0.2472058448788128, -3.7260048279111366, 6.8963190993607215, 25.61744628267447, 58.925376712614806, -1.946966407100602, 0.0, 54.96861643010454, -1.8175450108818458, 80.0, -0.47769415241436297, -37.065275172861824, -14.163887537555476, 0.0, 149.8222680884661, 0.0, 46.55479676297398, 0.0, 0.0, -5.15587313848875, 37.914086787972494, 60.0, 80.0, 20.0, -8.229168942044765, -2.9118236603170917, -53.44625154267835, 53.63175746138547, 0.0, 0.0, 40.0, -4.249991879182894, 11.740209156901045, 60.0, 139.67730749412857, 120.0, 0.0, 1.8983715029693067, 40.0, 40.0, 140.0, -7.3184232545261425, 0.0, -25.061525619051537, 39.722798723185754, -24.18528406213884, -13.774160749148038, -12.878619408080642, -1.2098279604014142, -7.785133392615379, 0.0, 73.40298643797266, 60.0, 40.0, 40.0, 21.489963012594508, 10.966462732141311, 0.0, 20.0, 40.0, 39.017975306356725, -2.1999136233041074, -20.29200586153305, -2.9025048907745097, 28.788806649398907, 60.0, 32.24191699471675, 0.0, -25.759313475287883, 76.15546462835277, -7.4571145709747695, 60.0, 137.62196321345525, -16.414821823404527, -11.102897877671065, 67.96933078951854, -0.1916336626576698, -0.4378465197338921, 0.0, 34.46181255717726, -4.565609806653404, -10.396004349481432, 16.853341509407663, 51.06123019017586, 32.27367662117567, 80.0, 60.0, 0.0, -10.195966189827924, 60.0, -3.337350701094596, 23.382560115818126, -12.19759069035602, 58.00030611012881, 0.0, 60.0, 24.570392145443, 78.12654000643136, 57.637870970807, -1.075874801771628, 60.0, -0.7758850491740277, 58.45996935792099, -21.47339211737367, 0.0, 0.0, -4.486668987321294, 74.50266694521245, -8.486753855618618, -10.461443384512217, -7.225637192892606, 17.898203141816534, 0.0, -0.8506076108270777], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 80.0, 80.0, 80.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 70.0, 70.0, 70.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-10.0, 0.0, 0.0, 0.0, 0.0, -4.451054114356163, 0.0, -17.374390557383208, -76.21315798241648, 0.0, -40.0, -30.0, -0.02766889376346393, -30.0, -3.3385500997198436, -27.637035946345797, -2.3436917074829067, -30.236589921260325, 0.0, -53.47137310755597, -40.0, 0.0, -5.386418432198374, 0.0, -32.470934218582975, -13.932119751651767, 0.0, -0.10841052087002478, -58.84101403940773, -20.53507436210413, -63.89418279752789, -3.3635446834210825, -34.49681581170069, -10.967084922580339, -10.0, -0.842014271148469, 0.0, -9.527452442569352, -16.05698184607845, -40.54020566297865, 0.0, -25.4154104341797, 0.0, -68.57531513727795, -11.792322278876986, -6.296185279296915, -17.990536244307908, -2.214976962036811, -0.2472058448788128, -3.7260048279111366, -23.103680900639276, -34.382553717325536, -31.07462328738519, -1.946966407100602, 0.0, -35.03138356989546, -1.8175450108818458, -40.0, -0.47769415241436297, -37.065275172861824, -14.163887537555476, 0.0, -90.17773191153393, 0.0, -43.445203237026014, 0.0, 0.0, -5.15587313848875, -22.085913212027506, -30.0, -40.0, -10.0, -8.229168942044765, -2.9118236603170917, -53.44625154267835, -36.36824253861454, 0.0, 0.0, -20.0, -4.249991879182894, -18.259790843098955, -30.0, -70.32269250587143, -60.0, 0.0, -28.101628497030696, -20.0, -20.0, -70.0, -7.3184232545261425, 0.0, -25.061525619051537, -20.277201276814246, -24.18528406213884, -13.774160749148038, -12.878619408080642, -1.2098279604014142, -7.785133392615379, 0.0, -46.59701356202734, -30.0, -20.0, -20.0, -38.5100369874055, -19.03353726785869, 0.0, -10.0, -20.0, -20.982024693643275, -2.1999136233041074, -20.29200586153305, -2.9025048907745097, -31.211193350601093, -30.0, -27.75808300528326, 0.0, -25.759313475287883, -43.844535371647204, -7.4571145709747695, -30.0, -72.37803678654475, -16.414821823404527, -11.102897877671065, -82.03066921048148, -0.1916336626576698, -0.4378465197338921, 0.0, -25.53818744282274, -4.565609806653404, -10.396004349481432, -13.146658490592337, -38.93876980982414, -27.726323378824333, -40.0, -30.0, 0.0, -10.195966189827924, -30.0, -3.337350701094596, -36.61743988418187, -12.19759069035602, -31.999693889871196, 0.0, -30.0, -35.429607854557, -41.87345999356865, -32.362129029193, -1.075874801771628, -30.0, -0.7758850491740277, -31.54003064207901, -21.47339211737367, 0.0, 0.0, -4.486668987321294, -45.497333054787546, -8.486753855618618, -10.461443384512217, -7.225637192892606, -12.101796858183466, 0.0, -0.8506076108270777]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6369104562266689, "mean_inference_ms": 1.095389985932916, "mean_action_processing_ms": 0.2368625949853692, "mean_env_wait_ms": 0.4782569140729098, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004243556364082995, "StateBufferConnector_ms": 0.003367441671865958, "ViewRequirementAgentConnector_ms": 0.08770580644960757}, "num_episodes": 162, "episode_return_max": 149.8222680884661, "episode_return_min": -53.44625154267835, "episode_return_mean": 21.456634456204664}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1360000, "num_agent_steps_trained": 1360000, "num_env_steps_sampled": 340000, "num_env_steps_trained": 340000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 301.5525342974071, "num_env_steps_trained_throughput_per_sec": 301.5525342974071, "timesteps_total": 340000, "num_env_steps_sampled_lifetime": 340000, "num_agent_steps_sampled_lifetime": 1360000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1360000, "timers": {"training_iteration_time_ms": 13584.767, "restore_workers_time_ms": 0.016, "training_step_time_ms": 13584.725, "sample_time_ms": 1176.314, "learn_time_ms": 12394.564, "learn_throughput": 322.722, "synch_weights_time_ms": 12.673}, "counters": {"num_env_steps_sampled": 340000, "num_env_steps_trained": 340000, "num_agent_steps_sampled": 1360000, "num_agent_steps_trained": 1360000}, "done": false, "training_iteration": 85, "trial_id": "b72b3_00000", "date": "2024-08-08_15-51-41", "timestamp": 1723146701, "time_this_iter_s": 13.273675918579102, "time_total_s": 1221.719854593277, "pid": 98177, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3175e1940>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1221.719854593277, "iterations_since_restore": 85, "perf": {"cpu_util_percent": 28.35263157894737, "ram_util_percent": 83.0263157894737}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.4153634160757065, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.725478499631087, "policy_loss": -0.022345593724700543, "vf_loss": 5.746149989465873, "vf_explained_var": -0.022203452388445535, "kl": 0.0083705022681701, "entropy": 0.8297606692338984, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 82080.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6504531472498644, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.702282375224093, "policy_loss": -0.021231579545601304, "vf_loss": 3.7228224731506185, "vf_explained_var": -7.906069992281866e-07, "kl": 0.006914839443310325, "entropy": 0.44212798347287147, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 241110.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 344000, "num_env_steps_trained": 344000, "num_agent_steps_sampled": 1376000, "num_agent_steps_trained": 1376000}, "env_runners": {"episode_reward_max": 200.0, "episode_reward_min": -38.76263831413983, "episode_reward_mean": 28.22197973337186, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 158, "episodes_timesteps_total": 3950, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -100.0}, "policy_reward_max": {"adversary_policy": 100.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 16.582278481012658, "agent_policy": -21.52485570966612}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 39.14087778565412, 59.87820926764584, -7.1050474420536425, 36.17319854079795, -0.6301509648571924, 31.330498961333618, 40.0, -1.8621470673969343, 100.0, -13.276276802904592, 20.0, -10.44907858127819, 60.0, 8.883781453664833, -3.0397012139736916, 20.0, 39.773002606010984, 99.86354718286134, 0.0, 19.654487155679863, 36.34950962957115, 0.0, -5.6046624622989505, 60.0, 0.0, 60.0, 0.0, 117.51625841142842, 80.0, 0.0, -12.674631576490919, -2.63247204104227, 0.0, 0.0, 59.25491569122671, -20.99264483876393, 15.06248196434115, 100.0, 0.0, 0.0, 57.47987255019566, 94.9881356343594, 0.0, 36.4900351332338, 0.0, -5.252360417166521, 17.925653616014724, 0.0, 10.807087989113866, 39.92795555067083, 0.0, 50.44121414980764, -13.758346329865466, -0.5811983874174531, 40.0, 80.0, 25.832269663547812, 44.762123360358565, 59.856522584280526, 0.0, -10.950670506721389, -10.02071530043738, -2.791016775079566, -6.364557591798423, 15.642965601596897, 20.0, -0.8299287101001906, -12.059825264127358, 94.22029936626454, 200.0, 119.96835923430092, -4.470004715941723, 58.821690601660734, 0.0, -6.428125253846824, 17.001418232799526, 43.659898424389674, 98.98382978363642, -24.922338863469385, -3.578972873792094, 80.0, 68.11443150729148, 100.0, 60.0, -0.6117114420911329, -5.949830947107195, 0.0, 47.79265744218503, 56.32561530651529, 50.22423866320724, -1.0714412606566182, 120.0, 36.66628902503505, 20.0, 52.90389693791782, 34.9338960089237, 80.0, 60.0, -2.238307376401729, 0.0, 49.75235764454582, 33.19993977971918, 80.0, -1.8386459859631954, -0.5871675075779614, -5.825236234457907, 73.10701558894995, 19.63281480757632, 79.96847912429826, 58.53038435582977, 34.208967828751064, 19.858764786425233, -12.087028970014476, 0.0, 75.34509949486562, 36.601721601071226, 0.0, 60.0, 19.362522311058118, -38.76263831413983, -10.064612326126344, 0.0, -8.297027067672467, 0.0, 31.815137780740187, 0.0, 117.34266148988164, 20.0, 33.40169366376177, 38.5793132765395, 58.468317860834816, 40.0, 40.0, -2.02940537604123, -7.121746642760646, 60.0, -15.326794166270867, 39.98638213124505, 72.72748636790358, 36.85573653233069, 92.4340674102275, 38.101015983926224, -0.10110932742824152, 3.0508491856069315, 20.0, 14.976710759117488, 0.0, 0.0, -13.369939855396968, 47.790039153489644, 40.0, -0.5515768290063616, 20.891092163255706, -14.727012743008432, 19.954559524571355, 29.009534918841215, 28.30511368281199], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 100.0, 100.0, 100.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0], "policy_agent_policy_reward": [0.0, -20.85912221434588, -30.121790732354164, -7.1050474420536425, -23.826801459202056, -0.6301509648571924, -28.66950103866639, -20.0, -1.8621470673969343, -50.0, -13.276276802904592, -10.0, -40.449078581278194, -30.0, -21.11621854633517, -3.0397012139736916, -10.0, -20.226997393989016, -50.13645281713866, 0.0, -10.345512844320137, -23.65049037042885, 0.0, -5.6046624622989505, -30.0, 0.0, -30.0, 0.0, -62.48374158857158, -40.0, 0.0, -12.674631576490919, -2.63247204104227, 0.0, 0.0, -30.745084308773293, -20.99264483876393, -14.937518035658853, -50.0, 0.0, 0.0, -32.52012744980434, -55.011864365640584, 0.0, -23.509964866766197, 0.0, -5.252360417166521, -12.074346383985276, 0.0, -19.192912010886133, -20.072044449329173, 0.0, -39.55878585019236, -13.758346329865466, -0.5811983874174531, -20.0, -40.0, -34.167730336452195, -45.237876639641435, -30.143477415719474, 0.0, -10.950670506721389, -10.02071530043738, -2.791016775079566, -36.36455759179842, -14.357034398403103, -10.0, -0.8299287101001906, -12.059825264127358, -55.77970063373546, -100.0, -60.031640765699095, -4.470004715941723, -31.178309398339266, 0.0, -6.428125253846824, -12.998581767200474, -46.34010157561032, -51.01617021636358, -24.922338863469385, -3.578972873792094, -40.0, -51.885568492708494, -50.0, -30.0, -0.6117114420911329, -5.949830947107195, 0.0, -42.20734255781497, -33.67438469348471, -39.77576133679276, -1.0714412606566182, -60.0, -23.333710974964944, -10.0, -37.09610306208218, -25.066103991076297, -40.0, -30.0, -2.238307376401729, 0.0, -40.24764235545418, -26.80006022028082, -40.0, -1.8386459859631954, -0.5871675075779614, -35.825236234457904, -46.89298441105006, -10.367185192423678, -40.031520875701744, -31.469615644170233, -25.791032171248943, -10.141235213574767, -12.087028970014476, 0.0, -44.65490050513436, -23.398278398928774, 0.0, -30.0, -10.637477688941882, -38.76263831413983, -10.064612326126344, 0.0, -8.297027067672467, 0.0, -58.18486221925982, 0.0, -62.65733851011835, -10.0, -56.59830633623823, -21.4206867234605, -31.531682139165177, -20.0, -20.0, -2.02940537604123, -7.121746642760646, -30.0, -15.326794166270867, -20.01361786875495, -47.272513632096455, -23.14426346766931, -57.56593258977248, -21.89898401607378, -0.10110932742824152, -26.949150814393064, -10.0, -45.02328924088251, 0.0, 0.0, -13.369939855396968, -42.209960846510356, -20.0, -0.5515768290063616, -39.108907836744294, -14.727012743008432, -10.045440475428645, -30.99046508115879, -31.694886317188008]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6364629036969938, "mean_inference_ms": 1.094543313468034, "mean_action_processing_ms": 0.23659246691805966, "mean_env_wait_ms": 0.47794239096179425, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004156556310532968, "StateBufferConnector_ms": 0.0032181226754490334, "ViewRequirementAgentConnector_ms": 0.09055167813844318}, "num_episodes": 158, "episode_return_max": 200.0, "episode_return_min": -38.76263831413983, "episode_return_mean": 28.22197973337186}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1376000, "num_agent_steps_trained": 1376000, "num_env_steps_sampled": 344000, "num_env_steps_trained": 344000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 282.35748245520983, "num_env_steps_trained_throughput_per_sec": 282.35748245520983, "timesteps_total": 344000, "num_env_steps_sampled_lifetime": 344000, "num_agent_steps_sampled_lifetime": 1376000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1376000, "timers": {"training_iteration_time_ms": 13646.078, "restore_workers_time_ms": 0.021, "training_step_time_ms": 13646.021, "sample_time_ms": 1177.935, "learn_time_ms": 12454.01, "learn_throughput": 321.182, "synch_weights_time_ms": 12.876}, "counters": {"num_env_steps_sampled": 344000, "num_env_steps_trained": 344000, "num_agent_steps_sampled": 1376000, "num_agent_steps_trained": 1376000}, "done": false, "training_iteration": 86, "trial_id": "b72b3_00000", "date": "2024-08-08_15-51-55", "timestamp": 1723146715, "time_this_iter_s": 14.196837186813354, "time_total_s": 1235.9166917800903, "pid": 98177, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3280fc3a0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1235.9166917800903, "iterations_since_restore": 86, "perf": {"cpu_util_percent": 35.86500000000001, "ram_util_percent": 82.775}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.395039847989877, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.768875318268935, "policy_loss": -0.022973237677554912, "vf_loss": 5.790450789531072, "vf_explained_var": 0.05377462028215329, "kl": 0.006988816118347938, "entropy": 0.8727572677657008, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 83040.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6092797993979555, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.225508200234555, "policy_loss": -0.01986704038783036, "vf_loss": 3.244745493696091, "vf_explained_var": 5.058785702319856e-07, "kl": 0.006297467592444199, "entropy": 0.42622753011842146, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 243930.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 348000, "num_env_steps_trained": 348000, "num_agent_steps_sampled": 1392000, "num_agent_steps_trained": 1392000}, "env_runners": {"episode_reward_max": 160.0, "episode_reward_min": -29.713495080744863, "episode_reward_mean": 23.11297720952993, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -80.0}, "policy_reward_max": {"adversary_policy": 80.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 14.074074074074074, "agent_policy": -19.109245012692295}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.035367985783945066, 38.82320172198327, -1.0200385708637194, 80.0, -9.00218053250938, 60.0, 40.0, -12.07745994048498, -0.16104246888445695, 60.0, -5.055704341971726, 57.93757596149834, 72.96092430130926, 0.0, 80.0, 29.488863909505806, 18.074556663006454, 75.59156811539236, 100.0, 20.0, -0.1071171951045713, -15.511076103006522, -15.644575280001646, 0.0, 12.50483383360217, 0.0, 80.0, -4.697602333051231, 100.0, 14.394089770059118, -2.434775099865174, 100.0, 0.0, 40.0, -12.302033951592579, -14.27458096435088, 40.0, -1.8842237707947183, -29.713495080744863, 60.0, 59.04563355492283, 80.0, 80.0, 0.0, 0.0, 20.0, -0.43010482109784975, -0.6706223520040466, 33.525676826307766, -5.607794749462248, 0.0, -11.442402919140179, 0.0, -5.408463267987894, 70.23530313026103, 60.0, 76.53722229359738, -7.7554740927497035, -2.479643329108467, -11.090614971835628, 60.0, 51.58187198441005, -20.618214800115414, 107.89567110547154, 20.0, 20.0, 35.74273090573571, 20.0, 58.95088961686939, 80.0, 0.0, 29.2337540976188, -7.982764180800016, 60.0, 0.0, 63.89072024177282, 0.0, 51.725312769978856, 53.367242759671704, 40.0, 60.0, 13.060412925927087, 160.0, -16.813725785456867, 0.0, -2.9730377433191677, -13.593645132394988, -2.2106077536531545, -1.8261965498150967, -27.93829047562826, 33.42071954891718, -0.32700397151293914, -0.7768718432812771, -1.5585215028132482, 36.16437870603998, 0.0, 52.57856067521344, 19.909602980763953, 20.0, -10.837720593621178, 58.64990838302796, -21.30549916431908, 100.0, 14.950898964252488, 60.0, 13.757062095100563, 20.0, 0.0, 39.76329576800751, -16.538777508709554, 19.348272845134638, 40.0, 80.0, 0.0, 100.0, 0.0, 15.1932685461428, 20.0, -11.621211275010271, 38.6813202856452, 53.131204036237975, 0.0, -29.594761455982855, 0.7476460430224132, 40.0, 59.698804384620225, -3.557657648370281, -0.6302834294619031, -27.676491632552562, -22.413999087818663, 99.18660166897963, 31.356860838685215, -13.493233664542508, -13.61115526360385, -18.796866139633416, 5.236619878298518, 40.0, 22.367959336776785, 14.330307820736243, 0.0, 40.0, 40.0, 31.82082763368801, -18.91717702161787, 0.0, 60.0, -1.9121931285209504, 40.0, -0.0172392299259283, -4.082228862850948, 130.91773825806558, -10.949567993226303, 0.0, -2.3774732253226016, 0.0, -0.08206440041988894, -4.182934463092742, 60.0, 57.95590574207324, -0.674288615161931, 0.0, -10.735415319530379], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 80.0, 80.0, 80.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-0.035367985783945066, -21.176798278016726, -1.0200385708637194, -40.0, -9.00218053250938, -30.0, -20.0, -12.07745994048498, -0.16104246888445695, -30.0, -5.055704341971726, -32.06242403850167, -47.03907569869074, 0.0, -40.0, -30.511136090494194, -11.925443336993546, -44.40843188460765, -50.0, -10.0, -0.1071171951045713, -15.511076103006522, -15.644575280001646, 0.0, -17.49516616639783, 0.0, -40.0, -4.697602333051231, -50.0, -15.605910229940884, -2.434775099865174, -50.0, 0.0, -20.0, -12.302033951592579, -14.27458096435088, -20.0, -1.8842237707947183, -29.713495080744863, -30.0, -30.95436644507717, -40.0, -40.0, 0.0, 0.0, -10.0, -0.43010482109784975, -0.6706223520040466, -26.47432317369223, -35.60779474946224, 0.0, -11.442402919140179, 0.0, -5.408463267987894, -49.76469686973896, -30.0, -43.462777706402626, -7.7554740927497035, -2.479643329108467, -11.090614971835628, -30.0, -38.41812801558995, -20.618214800115414, -72.10432889452848, -10.0, -10.0, -24.257269094264284, -10.0, -31.04911038313061, -40.0, 0.0, -30.7662459023812, -7.982764180800016, -30.0, 0.0, -56.10927975822717, 0.0, -38.274687230021144, -36.632757240328296, -20.0, -30.0, -16.93958707407291, -80.0, -16.813725785456867, 0.0, -2.9730377433191677, -13.593645132394988, -2.2106077536531545, -1.8261965498150967, -27.93829047562826, -26.579280451082827, -0.32700397151293914, -0.7768718432812771, -1.5585215028132482, -23.835621293960013, 0.0, -37.42143932478657, -10.090397019236047, -10.0, -10.837720593621178, -31.350091616972048, -21.30549916431908, -50.0, -15.049101035747508, -30.0, -46.242937904899435, -10.0, 0.0, -20.236704231992498, -16.538777508709554, -10.65172715486536, -20.0, -40.0, 0.0, -50.0, 0.0, -14.8067314538572, -10.0, -11.621211275010271, -21.3186797143548, -36.868795963762025, 0.0, -29.594761455982855, -29.252353956977586, -20.0, -30.30119561537977, -3.557657648370281, -0.6302834294619031, -27.676491632552562, -22.413999087818663, -50.813398331020366, -28.643139161314785, -13.493233664542508, -13.61115526360385, -18.796866139633416, -24.76338012170148, -20.0, -37.632040663223215, -15.669692179263759, 0.0, -20.0, -20.0, -28.17917236631199, -18.91717702161787, 0.0, -30.0, -1.9121931285209504, -20.0, -0.0172392299259283, -4.082228862850948, -79.08226174193443, -10.949567993226303, 0.0, -2.3774732253226016, 0.0, -0.08206440041988894, -4.182934463092742, -30.0, -32.04409425792676, -0.674288615161931, 0.0, -10.735415319530379]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6365708440195296, "mean_inference_ms": 1.0946018817479883, "mean_action_processing_ms": 0.23641667595609062, "mean_env_wait_ms": 0.47796249568573873, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00580379992355535, "StateBufferConnector_ms": 0.0035670804388729144, "ViewRequirementAgentConnector_ms": 0.09334153599209255}, "num_episodes": 162, "episode_return_max": 160.0, "episode_return_min": -29.713495080744863, "episode_return_mean": 23.11297720952993}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1392000, "num_agent_steps_trained": 1392000, "num_env_steps_sampled": 348000, "num_env_steps_trained": 348000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 304.7288026675279, "num_env_steps_trained_throughput_per_sec": 304.7288026675279, "timesteps_total": 348000, "num_env_steps_sampled_lifetime": 348000, "num_agent_steps_sampled_lifetime": 1392000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1392000, "timers": {"training_iteration_time_ms": 13624.886, "restore_workers_time_ms": 0.019, "training_step_time_ms": 13624.831, "sample_time_ms": 1179.394, "learn_time_ms": 12431.707, "learn_throughput": 321.758, "synch_weights_time_ms": 12.902}, "counters": {"num_env_steps_sampled": 348000, "num_env_steps_trained": 348000, "num_agent_steps_sampled": 1392000, "num_agent_steps_trained": 1392000}, "done": false, "training_iteration": 87, "trial_id": "b72b3_00000", "date": "2024-08-08_15-52-08", "timestamp": 1723146728, "time_this_iter_s": 13.133228063583374, "time_total_s": 1249.0499198436737, "pid": 98177, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3281180d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1249.0499198436737, "iterations_since_restore": 87, "perf": {"cpu_util_percent": 28.336842105263155, "ram_util_percent": 81.9684210526316}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.462169094880422, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.8096161633729935, "policy_loss": -0.028332525057097276, "vf_loss": 5.836036042869091, "vf_explained_var": -0.00183618584026893, "kl": 0.009563130633816157, "entropy": 0.8155526841059327, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 84000.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6343815491554585, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.587924899784386, "policy_loss": -0.02044172971003692, "vf_loss": 3.607749704435362, "vf_explained_var": -4.617669058184252e-07, "kl": 0.006169234250081059, "entropy": 0.4261754593105181, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 246750.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 352000, "num_env_steps_trained": 352000, "num_agent_steps_sampled": 1408000, "num_agent_steps_trained": 1408000}, "env_runners": {"episode_reward_max": 179.85565570329354, "episode_reward_min": -37.8883932324589, "episode_reward_mean": 26.786341378313814, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 157, "episodes_timesteps_total": 3925, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -90.2125221483285}, "policy_reward_max": {"adversary_policy": 90.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 15.987261146496815, "agent_policy": -21.175442061176636}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-12.668158336298486, 40.0, 20.0, 0.0, 59.69731238878746, 17.18964561399936, 80.0, -8.552184699060838, 20.0, 20.0, 6.949296711952888, -15.647542124919232, 52.379093748961445, 60.0, -23.813159240314913, 80.0, 53.05215022962227, -0.38080046979572235, 0.0, -21.25852845820935, 0.0, -16.93143524958196, 80.0, 40.0, -21.5789646547186, -5.355999799309503, -3.08598904239578, 20.0, 0.0, 28.169003974319352, 59.689412146089886, 39.70822845918973, 119.92773634659676, 40.0, 14.726954808235114, 26.163034380164277, 140.0, -7.373793749670344, 100.0, -5.305589599334305, 100.0, -4.371255840889028, -3.704897486364506, 44.58893912171396, 179.85565570329354, 19.86306096567492, 76.36917796303814, 58.54764667021533, -3.6447926576308696, -7.150793037610287, -2.158001652736359, -2.777717624073852, 0.0, 0.0, 0.0, 60.0, -22.379595304850184, 19.35078996467035, 80.0, 20.0, -2.1813921337468005, -9.067704459394125, 0.0, 28.82284165198189, -5.524812227505363, 55.69010070349646, 60.0, 60.0, 19.546284466721435, -13.408099814438676, -0.10685671157854348, 40.0, -0.8415813666703509, 50.593058927707744, 0.0, 60.0, 12.446445399258437, 53.16800690250985, -15.747040182254896, 36.45709480189223, 47.524233350566945, 36.441476056305774, 77.16779394916347, -5.62942997373743, 100.0, -5.445485341548069, 60.0, -2.8614961893190687, 13.414008458217234, -15.349312830657393, 58.297084193619625, -0.44371297085986305, -5.0396953874594725, -3.9739617893980066, 39.4519359344593, -3.1305042351565717, 59.906180130940406, 40.0, 75.79871486308352, -2.7685721464674478, 0.0, 37.75675782897791, 80.0, -18.017469835366143, -12.499883849171802, 12.595411991682429, -1.6510816101643955, -37.8883932324589, 73.68166232166504, -2.192907764647571, 114.94671229905327, 79.44608079866592, -15.564350925401452, 37.308535950961605, 16.92015704278484, 26.692850547682745, -13.226574950046624, -12.116116965270677, -4.686011276800526, 20.0, 179.78747785167147, 60.0, 79.54914017177504, 60.0, -10.195724210278557, 90.27148809091587, -24.667597324817194, -16.434099747934777, 140.0, 0.0, 56.24201528303578, -4.989005012907641, -0.7146977442351266, 0.0, 60.0, -2.0817668267824416, 0.0, -0.1450187123186697, 114.7800335529832, 20.0, 40.0, 19.12300001960445, 18.439255728267838, -20.017910659219634, -0.9189646544944752, 0.0, 15.240894115514406, -3.9168484908135666, 57.86388262982106, -1.0888081998938004, 21.847683509929112, 40.0, 80.0, 40.0, 20.0, 20.0, -5.317753545192305], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 90.0, 90.0, 90.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 90.0, 90.0, 90.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-12.668158336298486, -20.0, -10.0, 0.0, -30.302687611212537, -12.810354386000641, -40.0, -8.552184699060838, -10.0, -10.0, -23.050703288047114, -15.647542124919232, -37.620906251038555, -30.0, -23.813159240314913, -40.0, -36.94784977037773, -0.38080046979572235, 0.0, -51.25852845820936, 0.0, -16.93143524958196, -40.0, -20.0, -21.5789646547186, -5.355999799309503, -3.08598904239578, -10.0, 0.0, -61.83099602568064, -30.310587853910114, -20.291771540810267, -60.07226365340324, -20.0, -15.273045191764886, -33.83696561983572, -70.0, -7.373793749670344, -50.0, -5.305589599334305, -50.0, -4.371255840889028, -3.704897486364506, -45.41106087828604, -90.14434429670646, -10.13693903432508, -43.63082203696186, -31.452353329784664, -3.6447926576308696, -7.150793037610287, -2.158001652736359, -2.777717624073852, 0.0, 0.0, 0.0, -30.0, -22.379595304850184, -10.649210035329649, -40.0, -10.0, -2.1813921337468005, -9.067704459394125, 0.0, -31.177158348018104, -5.524812227505363, -34.309899296503545, -30.0, -30.0, -40.45371553327857, -13.408099814438676, -0.10685671157854348, -20.0, -0.8415813666703509, -39.406941072292256, 0.0, -30.0, -17.553554600741563, -36.83199309749015, -15.747040182254896, -23.54290519810776, -42.47576664943306, -23.558523943694226, -42.832206050836525, -5.62942997373743, -50.0, -5.445485341548069, -30.0, -2.8614961893190687, -16.58599154178276, -15.349312830657393, -31.702915806380375, -0.44371297085986305, -5.0396953874594725, -3.9739617893980066, -20.5480640655407, -3.1305042351565717, -30.09381986905959, -20.0, -44.20128513691651, -2.7685721464674478, 0.0, -22.24324217102209, -40.0, -18.017469835366143, -12.499883849171802, -17.40458800831757, -1.6510816101643955, -37.8883932324589, -46.318337678334984, -2.192907764647571, -65.05328770094674, -40.55391920133408, -15.564350925401452, -22.6914640490384, -13.079842957215156, -33.307149452317255, -13.226574950046624, -12.116116965270677, -4.686011276800526, -10.0, -90.2125221483285, -30.0, -40.45085982822497, -30.0, -40.195724210278556, -59.72851190908413, -24.667597324817194, -16.434099747934777, -70.0, 0.0, -33.75798471696423, -4.989005012907641, -0.7146977442351266, 0.0, -30.0, -2.0817668267824416, 0.0, -0.1450187123186697, -65.2199664470168, -10.0, -20.0, -10.87699998039555, -11.560744271732162, -20.017910659219634, -0.9189646544944752, 0.0, -14.759105884485594, -3.9168484908135666, -32.13611737017894, -1.0888081998938004, -38.152316490070874, -20.0, -40.0, -20.0, -10.0, -10.0, -5.317753545192305]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6360943427080697, "mean_inference_ms": 1.0938369482548835, "mean_action_processing_ms": 0.23613751317113013, "mean_env_wait_ms": 0.477754103462285, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004201633915020402, "StateBufferConnector_ms": 0.0030043778146148486, "ViewRequirementAgentConnector_ms": 0.08580707440710371}, "num_episodes": 157, "episode_return_max": 179.85565570329354, "episode_return_min": -37.8883932324589, "episode_return_mean": 26.786341378313814}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1408000, "num_agent_steps_trained": 1408000, "num_env_steps_sampled": 352000, "num_env_steps_trained": 352000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 298.40992087712215, "num_env_steps_trained_throughput_per_sec": 298.40992087712215, "timesteps_total": 352000, "num_env_steps_sampled_lifetime": 352000, "num_agent_steps_sampled_lifetime": 1408000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1408000, "timers": {"training_iteration_time_ms": 13609.172, "restore_workers_time_ms": 0.019, "training_step_time_ms": 13609.117, "sample_time_ms": 1174.222, "learn_time_ms": 12420.843, "learn_throughput": 322.039, "synch_weights_time_ms": 13.168}, "counters": {"num_env_steps_sampled": 352000, "num_env_steps_trained": 352000, "num_agent_steps_sampled": 1408000, "num_agent_steps_trained": 1408000}, "done": false, "training_iteration": 88, "trial_id": "b72b3_00000", "date": "2024-08-08_15-52-22", "timestamp": 1723146742, "time_this_iter_s": 13.448050260543823, "time_total_s": 1262.4979701042175, "pid": 98177, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x328118430>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1262.4979701042175, "iterations_since_restore": 88, "perf": {"cpu_util_percent": 29.642105263157884, "ram_util_percent": 82.01052631578946}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.5105482747157413, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.890288198490937, "policy_loss": -0.027829380922291116, "vf_loss": 5.91628815283378, "vf_explained_var": 0.020912480043868222, "kl": 0.00914709051461126, "entropy": 0.8337358459209402, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 84960.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6131705114816097, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.3849436806448807, "policy_loss": -0.02076796555477987, "vf_loss": 3.405012559045291, "vf_explained_var": -2.8576411254017067e-07, "kl": 0.006990809744932541, "entropy": 0.4405924684084054, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 249570.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 356000, "num_env_steps_trained": 356000, "num_agent_steps_sampled": 1424000, "num_agent_steps_trained": 1424000}, "env_runners": {"episode_reward_max": 179.63452578991638, "episode_reward_min": -66.35918116386812, "episode_reward_mean": 25.497627260120197, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -90.84538701751973}, "policy_reward_max": {"adversary_policy": 90.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 15.555555555555555, "agent_policy": -21.16903940654647}, "custom_metrics": {}, "hist_stats": {"episode_reward": [80.0, 74.87579281366484, 58.87123603328286, 18.448127250122745, -10.030464481470014, -0.3928609168955133, -10.945927872522994, 80.0, -13.597453933214705, 38.76381249099814, -10.188978715459884, 15.21631036006103, -1.1294361888696436, 0.0, 73.83987337656899, 0.0, -11.768594994036699, 37.3288516140479, 20.0, 40.0, -8.995947065212116, 17.017413126961696, 60.0, 38.33198075906137, 37.1252768298562, 59.98288765731509, -22.1056528532265, 33.71174819529185, 80.0, -1.2681834789904656, 0.0, 40.0, -16.942930000517066, 15.249785091040934, -13.856701584319339, 78.20407567964085, -11.614275912952335, 40.0, 40.0, 40.0, -0.4104913574253122, 110.76233839801202, 13.94395577464542, 0.0, 111.25319388213921, 18.023457695331174, 20.0, -1.0016375486028206, 20.1081456784457, -10.308991409066124, 100.0, 12.062965309401, 120.0, 51.64214178716718, 80.0, 0.0, -12.09058012396319, 80.0, -0.7284740515575283, 19.975167184154298, 0.0, -6.613237139096933, -3.343465213149355, -8.902998741075393, 75.38891310112487, -5.771696544018457, 19.248461609302094, -4.754644168717864, 35.75747150359801, 60.0, 24.820835260877768, 0.0, -0.7248932796210306, -12.598577808218991, 56.08751417391015, 36.51191305601317, -17.729603100983343, 40.0, -11.70768155560185, -1.4787217486680757, -8.278337927396475, 38.678272232850716, 40.0, -13.574621857984951, -6.751337450658736, -3.176357784923993, 60.0, 60.0, -14.107938734157516, -32.10553729879993, 80.0, 37.27086079360759, 11.10391601756981, 60.0, 80.0, 179.63452578991638, -16.82853276096099, 19.150695138297472, -20.379830572817394, 17.45060797555146, 0.0, 19.849285722936315, 0.0, 0.0, -31.768682539647163, 84.43567359984536, 100.0, 20.0, 158.40270269389097, -7.461492883603334, 40.0, 56.89712105041167, 0.0, 149.15461298248022, 100.0, 18.531493222499805, 32.154647962790555, 18.928194631672465, -9.958614004712244, 36.14003427432835, -9.519096388274955, 0.0, 19.858842321062156, -5.81163078610178, 36.45017620784007, 0.0, 120.0, -66.35918116386812, 0.0, -14.948588146818526, -7.160313295560456, 20.0, 46.14477279873426, 0.19589485503191106, 0.0, -2.7127318021481797, -15.658242312736347, 0.0, 29.541297939983522, -3.394864640565981, 16.502125767913235, 60.0, 54.10165840757806, -0.16604400870529612, 56.664264639127644, 60.0, 136.1951305903391, 57.12559066706976, 35.676295241859435, 19.596031464972455, -2.502132776909784, 3.738582007158957, 79.12166579284722, 0.0, -7.66468933109323, -1.5476476395218353, 0.0, -7.6166291451379005, -15.514617592427474, 55.33779229025429, 0.0, 40.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 60.0, 60.0, 60.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 90.0, 90.0, 90.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 80.0, 80.0, 80.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 80.0, 80.0, 80.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 70.0, 70.0, 70.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0], "policy_agent_policy_reward": [-40.0, -45.12420718633517, -31.12876396671714, -11.551872749877253, -10.030464481470014, -0.3928609168955133, -10.945927872522994, -40.0, -13.597453933214705, -21.23618750900186, -10.188978715459884, -14.78368963993897, -1.1294361888696436, 0.0, -46.160126623431005, 0.0, -11.768594994036699, -22.671148385952087, -10.0, -20.0, -8.995947065212116, -12.982586873038302, -30.0, -21.66801924093863, -22.874723170143803, -30.01711234268491, -22.1056528532265, -26.288251804708157, -40.0, -1.2681834789904656, 0.0, -20.0, -16.942930000517066, -14.75021490895907, -13.856701584319339, -41.795924320359156, -11.614275912952335, -20.0, -20.0, -20.0, -0.4104913574253122, -69.23766160198798, -16.056044225354583, 0.0, -68.74680611786077, -71.97654230466881, -10.0, -1.0016375486028206, -39.89185432155429, -10.308991409066124, -50.0, -17.937034690599003, -60.0, -38.35785821283282, -40.0, 0.0, -12.09058012396319, -40.0, -0.7284740515575283, -10.024832815845702, 0.0, -6.613237139096933, -3.343465213149355, -8.902998741075393, -44.61108689887512, -5.771696544018457, -10.751538390697906, -4.754644168717864, -24.24252849640199, -30.0, -35.17916473912223, 0.0, -0.7248932796210306, -12.598577808218991, -33.91248582608985, -23.48808694398683, -17.729603100983343, -20.0, -11.70768155560185, -1.4787217486680757, -8.278337927396475, -21.321727767149287, -20.0, -13.574621857984951, -6.751337450658736, -3.176357784923993, -30.0, -30.0, -14.107938734157516, -32.10553729879993, -40.0, -22.72913920639241, -18.89608398243019, -30.0, -40.0, -90.36547421008362, -16.82853276096099, -10.849304861702526, -20.379830572817394, -12.54939202444854, 0.0, -10.150714277063683, 0.0, 0.0, -31.768682539647163, -65.56432640015464, -50.0, -10.0, -81.59729730610903, -7.461492883603334, -20.0, -33.10287894958833, 0.0, -90.84538701751973, -50.0, -11.468506777500194, -27.845352037209434, -41.071805368327524, -9.958614004712244, -23.859965725671646, -9.519096388274955, 0.0, -10.141157678937846, -5.81163078610178, -23.54982379215993, 0.0, -60.0, -66.35918116386812, 0.0, -14.948588146818526, -7.160313295560456, -10.0, -43.85522720126574, -29.80410514496808, 0.0, -2.7127318021481797, -15.658242312736347, 0.0, -30.45870206001649, -3.394864640565981, -13.497874232086767, -30.0, -35.89834159242194, -0.16604400870529612, -33.335735360872356, -30.0, -73.80486940966091, -32.87440933293024, -24.32370475814057, -10.403968535027543, -2.502132776909784, -26.261417992841057, -40.87833420715277, 0.0, -7.66468933109323, -1.5476476395218353, 0.0, -7.6166291451379005, -15.514617592427474, -34.66220770974571, 0.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6359149259904122, "mean_inference_ms": 1.093651231473097, "mean_action_processing_ms": 0.23589699341664852, "mean_env_wait_ms": 0.47762452435196356, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005154182881484797, "StateBufferConnector_ms": 0.003977322284086251, "ViewRequirementAgentConnector_ms": 0.09450353222128785}, "num_episodes": 162, "episode_return_max": 179.63452578991638, "episode_return_min": -66.35918116386812, "episode_return_mean": 25.497627260120197}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1424000, "num_agent_steps_trained": 1424000, "num_env_steps_sampled": 356000, "num_env_steps_trained": 356000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 299.8619691124522, "num_env_steps_trained_throughput_per_sec": 299.8619691124522, "timesteps_total": 356000, "num_env_steps_sampled_lifetime": 356000, "num_agent_steps_sampled_lifetime": 1424000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1424000, "timers": {"training_iteration_time_ms": 13600.112, "restore_workers_time_ms": 0.02, "training_step_time_ms": 13600.057, "sample_time_ms": 1174.594, "learn_time_ms": 12411.941, "learn_throughput": 322.27, "synch_weights_time_ms": 12.599}, "counters": {"num_env_steps_sampled": 356000, "num_env_steps_trained": 356000, "num_agent_steps_sampled": 1424000, "num_agent_steps_trained": 1424000}, "done": false, "training_iteration": 89, "trial_id": "b72b3_00000", "date": "2024-08-08_15-52-36", "timestamp": 1723146756, "time_this_iter_s": 13.346006870269775, "time_total_s": 1275.8439769744873, "pid": 98177, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3280fc3a0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1275.8439769744873, "iterations_since_restore": 89, "perf": {"cpu_util_percent": 28.773684210526312, "ram_util_percent": 81.91052631578947}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.4791799946377675, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.752144927283128, "policy_loss": -0.025075816117896464, "vf_loss": 5.7755785192052524, "vf_explained_var": 0.03336651567369699, "kl": 0.008211148179782059, "entropy": 0.8143336849287153, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 85920.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6195489372344727, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.369699289020917, "policy_loss": -0.020763397772618115, "vf_loss": 3.3899139329051295, "vf_explained_var": -3.4600284928125693e-07, "kl": 0.005487593060735973, "entropy": 0.4120272574483926, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 252390.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 360000, "num_env_steps_trained": 360000, "num_agent_steps_sampled": 1440000, "num_agent_steps_trained": 1440000}, "env_runners": {"episode_reward_max": 160.0, "episode_reward_min": -39.36044501562044, "episode_reward_mean": 24.75289301730238, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -80.0}, "policy_reward_max": {"adversary_policy": 80.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 15.185185185185185, "agent_policy": -20.802662538253177}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-1.2497063203165715, -10.260694511953652, 60.0, 59.26178131698751, 40.0, 0.0, 57.706060566399955, 10.34907204854084, 10.589086208820563, -34.023869806589, -30.985318673062487, 58.30341937878638, 18.51165747770179, -4.493270614532605, -9.070802813343974, 55.73600907003812, -12.086175536173249, 29.898092000857275, 56.35390168708294, 0.0, -0.12393829156944758, 20.0, 26.021642439465744, 68.00195471135633, 37.76159286744352, 58.46565125997182, -10.937223495728452, 65.22958284614857, 89.66300821810074, -0.10057309497111255, 80.0, 0.0, -1.2669199303614398, 0.0, 118.40364662669876, 0.0, 39.48345172251571, 80.0, 100.0, 0.0, 39.093871744460344, -6.979034063697646, 0.0, -4.466491854980938, 0.0, 40.0, 0.0, -9.194395887649907, 32.894195483507794, -4.50830264879227, 81.66617755822375, -8.591210365026013, 4.582366640448733, -2.347580967986845, 160.0, 20.0, 50.98190550004379, -22.274008451713797, 39.24710715467819, -3.2707675265348364, 14.580626001944292, -11.74346213818789, 58.57844653419738, -1.9657799295537715, -9.910662969739144, 60.4975485982673, 0.0, 40.0, 115.580742009946, 40.0, -11.976589846558092, -0.09941686799354144, 20.0, 78.01927595963454, -12.045184804868478, -39.36044501562044, -7.769121137665266, 57.066521987496444, 32.856821655378354, 6.298776415632903, 22.72392571868158, -18.00072591068509, -3.1166774297011486, 31.939808069849427, -3.488141838673727, 18.58681403244777, -5.530858119136631, 40.0, 58.85573027270317, 136.2799795634466, -9.702126465593572, 44.20875831159112, 29.77412048850671, 40.0, -3.333763984851495, 0.0, 74.1426024756535, 60.0, 112.8514350935149, -9.744088592421953, 58.08804593724626, 0.0, 20.0, 40.53676965059121, 0.0, -25.577469314338327, -3.3715977117056326, 40.0, 20.0, 40.0, 40.0, 60.0, -7.895703676502073, -0.2366278889988871, -8.881210010692657, 40.0, 36.30736719728037, -10.415018303636376, 65.72575653413472, 0.0, 0.0, 60.0, -11.139406736988985, -2.7684283922048456, 60.0, -0.2049208134744307, 20.0, 39.54321705301726, -10.339357180909321, 17.391083658976008, 9.817229447967515, 49.605631861431185, 40.0, 58.63794328301655, -0.06289107180086906, 19.645326650422362, 27.540213667662705, 29.935787915362074, -10.66535184442098, -2.677222223023322, -1.8173812379038345, -14.003154973070107, -1.309983188990106, 20.0, 79.31589003275045, 59.9455035698212, -7.3454629233546544, 69.9800705464871, 20.0, 14.187881411343394, 19.877740455863112, -1.1598926649040342, 31.520878776739472, -3.282694351382259, 118.3241102945801, 39.89498053844663, -1.253570201936255, 33.47032922334467, 60.91353629396659, 0.4364012968452047, -1.8978798360869442, 98.60236024107769], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 80.0, 80.0, 80.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0], "policy_agent_policy_reward": [-1.2497063203165715, -10.260694511953652, -30.0, -30.738218683012498, -20.0, 0.0, -32.293939433600045, -19.650927951459156, -19.410913791179436, -34.023869806589, -30.985318673062487, -31.69658062121363, -11.488342522298208, -4.493270614532605, -9.070802813343974, -34.26399092996188, -12.086175536173249, -30.10190799914271, -33.64609831291706, 0.0, -0.12393829156944758, -10.0, -33.978357560534256, -51.99804528864369, -22.238407132556475, -31.53434874002818, -10.937223495728452, -54.77041715385143, -60.33699178189925, -0.10057309497111255, -40.0, 0.0, -1.2669199303614398, 0.0, -61.59635337330125, 0.0, -20.51654827748429, -40.0, -50.0, 0.0, -20.906128255539652, -6.979034063697646, 0.0, -4.466491854980938, 0.0, -20.0, 0.0, -9.194395887649907, -27.10580451649221, -4.50830264879227, -68.33382244177626, -8.591210365026013, -25.41763335955126, -2.347580967986845, -80.0, -10.0, -39.01809449995621, -22.274008451713797, -20.75289284532181, -3.2707675265348364, -15.419373998055708, -11.74346213818789, -31.421553465802617, -1.9657799295537715, -9.910662969739144, -59.502451401732685, 0.0, -20.0, -64.419257990054, -20.0, -11.976589846558092, -0.09941686799354144, -10.0, -41.980724040365466, -12.045184804868478, -39.36044501562044, -7.769121137665266, -32.933478012503556, -27.143178344621646, -23.701223584367096, -37.27607428131841, -18.00072591068509, -3.1166774297011486, -28.060191930150573, -3.488141838673727, -11.413185967552232, -5.530858119136631, -20.0, -31.144269727296837, -73.7200204365534, -9.702126465593572, -45.79124168840888, -30.225879511493286, -20.0, -3.333763984851495, 0.0, -45.85739752434649, -30.0, -67.14856490648512, -9.744088592421953, -31.91195406275374, 0.0, -10.0, -49.46323034940879, 0.0, -25.577469314338327, -3.3715977117056326, -20.0, -10.0, -20.0, -20.0, -30.0, -7.895703676502073, -0.2366278889988871, -8.881210010692657, -20.0, -23.69263280271963, -10.415018303636376, -54.2742434658653, 0.0, 0.0, -30.0, -11.139406736988985, -2.7684283922048456, -30.0, -0.2049208134744307, -10.0, -20.456782946982745, -10.339357180909321, -42.60891634102399, -20.182770552032483, -40.39436813856882, -20.0, -31.36205671698345, -0.06289107180086906, -10.354673349577638, -32.45978633233729, -30.064212084637926, -10.66535184442098, -2.677222223023322, -1.8173812379038345, -14.003154973070107, -1.309983188990106, -10.0, -40.684109967249555, -30.0544964301788, -7.3454629233546544, -50.01992945351289, -10.0, -15.812118588656602, -10.122259544136886, -1.1598926649040342, -28.479121223260528, -3.282694351382259, -61.675889705419905, -20.10501946155337, -1.253570201936255, -26.52967077665533, -59.086463706033406, -29.563598703154806, -1.8978798360869442, -51.39763975892231]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6354903296371551, "mean_inference_ms": 1.092771913598954, "mean_action_processing_ms": 0.23563811686177222, "mean_env_wait_ms": 0.4773569978684086, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004042372291470751, "StateBufferConnector_ms": 0.0030689769321017796, "ViewRequirementAgentConnector_ms": 0.08711873749156057}, "num_episodes": 162, "episode_return_max": 160.0, "episode_return_min": -39.36044501562044, "episode_return_mean": 24.75289301730238}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1440000, "num_agent_steps_trained": 1440000, "num_env_steps_sampled": 360000, "num_env_steps_trained": 360000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 307.6036471785205, "num_env_steps_trained_throughput_per_sec": 307.6036471785205, "timesteps_total": 360000, "num_env_steps_sampled_lifetime": 360000, "num_agent_steps_sampled_lifetime": 1440000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1440000, "timers": {"training_iteration_time_ms": 13504.99, "restore_workers_time_ms": 0.02, "training_step_time_ms": 13504.935, "sample_time_ms": 1135.581, "learn_time_ms": 12356.107, "learn_throughput": 323.727, "synch_weights_time_ms": 12.368}, "counters": {"num_env_steps_sampled": 360000, "num_env_steps_trained": 360000, "num_agent_steps_sampled": 1440000, "num_agent_steps_trained": 1440000}, "done": false, "training_iteration": 90, "trial_id": "b72b3_00000", "date": "2024-08-08_15-52-49", "timestamp": 1723146769, "time_this_iter_s": 13.009782075881958, "time_total_s": 1288.8537590503693, "pid": 98177, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x328118af0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1288.8537590503693, "iterations_since_restore": 90, "perf": {"cpu_util_percent": 28.373684210526324, "ram_util_percent": 81.68947368421053}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.597877098992467, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.784070173402627, "policy_loss": -0.02421499456880459, "vf_loss": 5.8066785633563995, "vf_explained_var": 0.026882136861483257, "kl": 0.008033082859370773, "entropy": 0.7928028974061211, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 86880.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5800932473324715, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.1758305449012325, "policy_loss": -0.01977868203349504, "vf_loss": 3.1949523492062344, "vf_explained_var": -4.0042907633679976e-07, "kl": 0.006568749398422819, "entropy": 0.4115691229912406, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 255210.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 364000, "num_env_steps_trained": 364000, "num_agent_steps_sampled": 1456000, "num_agent_steps_trained": 1456000}, "env_runners": {"episode_reward_max": 184.8819494198528, "episode_reward_min": -35.26193762968275, "episode_reward_mean": 21.669046083522296, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 158, "episodes_timesteps_total": 3950, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -115.11805058014721}, "policy_reward_max": {"adversary_policy": 100.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 13.924050632911392, "agent_policy": -20.10310581521188}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.843666360016755, 20.0, 40.0, -24.44172101686829, 49.675286580541595, -2.62773029228547, 56.31677402656247, 0.0, 40.0, 60.0, -12.092253944197292, 57.106728921287534, -7.032051854941165, 60.0, -13.843812435432007, 70.194582814079, 40.0, 40.0, -13.230516425049306, 1.8491622004241774, -13.335016088295426, 155.40446973504683, 79.52902778421594, -0.12408345365513163, 54.45354024499197, 11.314378955583472, 24.68150073313387, -9.208438354421789, 120.0, 42.094223079618125, -0.06156616872955989, 34.20745646360025, -12.852260143661, 60.0, 39.26538520599352, 60.0, 0.0, 0.0, -5.299063207378409, 59.312405188314614, -21.4889102049808, -12.630961750317729, -11.183433766913804, 18.749663033546422, 106.39600352378079, 59.713666423818324, -6.071611904967579, -26.85776785402849, 184.8819494198528, -22.969765862798845, 39.18063982013167, 0.0, -2.4598652256845943, 97.492337092451, 59.42644163533066, -5.197032026223999, -17.604092495001417, 24.038721927653356, -7.249645239806272, -10.71320381212296, 20.0, -3.9127720914499324, 82.98366718245445, -35.26193762968275, 34.26743211387641, 59.3300053015256, -1.5628290327852146, -8.408098056336078, 40.0, 18.999316106623482, 58.64380564334704, 0.0, 20.0, 14.223167407491568, -2.5318298052575186, 0.0, 34.46332793248134, 100.0, -0.3443262074888098, -11.598692273950505, 38.80772280884506, -12.025789969375898, -2.493907240572711, -26.827186962270616, 18.174098292836458, 37.88453414600804, 19.7460159085261, -1.6880674302154908, 40.0, 18.479532835768662, 60.0, 51.150363820750236, 64.8716310890797, 19.90600978032959, 40.0, -11.34950201703198, 39.419188300914996, 100.0, 40.0, -8.350085755495778, -0.28238495752671344, -10.124600552830865, -19.302749970473254, 0.0, -27.121982585505783, 40.0, -9.359532278420879, 60.0, 45.28342739918742, -5.974043486480496, 10.58221318148436, -1.4359008959314468, -8.456806957042641, -0.003771978215058036, -0.9390545325312905, 60.0, -4.907060938278455, 15.721588721265308, 0.0, 58.94918650534662, -1.1037351056027256, 0.0, 75.86784702201608, 18.678523531024226, 39.30020270800296, 99.18778633383985, 20.0, 0.0, 16.536574182477658, -0.20361432264657697, -5.001748051446878, 0.0, -0.32441479758371083, -19.892698511162067, -8.733881494404264, 119.69032391444867, 18.729596791377407, -2.6934702351141935, 0.0, 119.64776086626782, 30.267096789184272, -29.669792190521953, -0.4847461024957811, 0.0, 15.004134073669688, -9.436413919785096, -12.505134877207, 49.80584707500293, 0.0, 19.951701099497978, -15.244391376860914, 6.815340020453845, 59.07072860222871, -0.32836987575307175, 40.0, -10.543889230587231, 0.0, -1.8544102370035276], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 80.0, 80.0, 80.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 60.0, 60.0, 60.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 100.0, 100.0, 100.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-21.15633363998325, -10.0, -20.0, -24.44172101686829, -40.324713419458405, -2.62773029228547, -33.68322597343753, 0.0, -20.0, -30.0, -12.092253944197292, -32.89327107871246, -7.032051854941165, -30.0, -13.843812435432007, -49.80541718592099, -20.0, -20.0, -13.230516425049306, -28.150837799575825, -13.335016088295426, -84.59553026495314, -40.47097221578406, -0.12408345365513163, -35.54645975500803, -18.68562104441653, -35.31849926686613, -9.208438354421789, -60.0, -47.905776920381875, -0.06156616872955989, -25.792543536399755, -12.852260143661, -30.0, -20.73461479400648, -30.0, 0.0, 0.0, -5.299063207378409, -30.68759481168538, -21.4889102049808, -12.630961750317729, -11.183433766913804, -11.250336966453578, -73.60399647621918, -30.28633357618167, -6.071611904967579, -26.85776785402849, -115.11805058014721, -22.969765862798845, -20.819360179868337, 0.0, -2.4598652256845943, -52.507662907549, -30.57355836466933, -5.197032026223999, -17.604092495001417, -35.961278072346644, -7.249645239806272, -10.71320381212296, -10.0, -3.9127720914499324, -67.01633281754555, -35.26193762968275, -25.732567886123583, -30.669994698474394, -1.5628290327852146, -8.408098056336078, -20.0, -11.000683893376523, -31.356194356652967, 0.0, -10.0, -15.776832592508434, -32.53182980525752, 0.0, -25.536672067518648, -50.0, -0.3443262074888098, -11.598692273950505, -21.192277191154936, -12.025789969375898, -2.493907240572711, -26.827186962270616, -11.825901707163544, -52.11546585399196, -10.253984091473898, -1.6880674302154908, -20.0, -11.520467164231338, -30.0, -38.84963617924975, -55.1283689109203, -10.093990219670411, -20.0, -11.34950201703198, -20.580811699085004, -50.0, -20.0, -8.350085755495778, -0.28238495752671344, -10.124600552830865, -19.302749970473254, 0.0, -27.121982585505783, -20.0, -9.359532278420879, -30.0, -44.71657260081258, -5.974043486480496, -19.417786818515648, -1.4359008959314468, -8.456806957042641, -0.003771978215058036, -0.9390545325312905, -30.0, -4.907060938278455, -14.278411278734698, 0.0, -31.050813494653383, -1.1037351056027256, 0.0, -44.13215297798393, -11.321476468975774, -20.69979729199704, -50.81221366616014, -10.0, 0.0, -13.463425817522342, -0.20361432264657697, -5.001748051446878, 0.0, -0.32441479758371083, -19.892698511162067, -8.733881494404264, -60.30967608555134, -71.2704032086226, -2.6934702351141935, 0.0, -60.35223913373218, -29.732903210815724, -29.669792190521953, -0.4847461024957811, 0.0, -14.995865926330312, -9.436413919785096, -12.505134877207, -40.19415292499707, 0.0, -10.048298900502022, -15.244391376860914, -23.184659979546154, -30.929271397771295, -0.32836987575307175, -20.0, -10.543889230587231, 0.0, -1.8544102370035276]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6444385773279964, "mean_inference_ms": 1.0932935532760744, "mean_action_processing_ms": 0.2355923828304346, "mean_env_wait_ms": 0.4774862253545596, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004888259911838966, "StateBufferConnector_ms": 0.003237211251560646, "ViewRequirementAgentConnector_ms": 0.09495472606224349}, "num_episodes": 158, "episode_return_max": 184.8819494198528, "episode_return_min": -35.26193762968275, "episode_return_mean": 21.669046083522296}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1456000, "num_agent_steps_trained": 1456000, "num_env_steps_sampled": 364000, "num_env_steps_trained": 364000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 292.1372982002749, "num_env_steps_trained_throughput_per_sec": 292.1372982002749, "timesteps_total": 364000, "num_env_steps_sampled_lifetime": 364000, "num_agent_steps_sampled_lifetime": 1456000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1456000, "timers": {"training_iteration_time_ms": 13481.782, "restore_workers_time_ms": 0.02, "training_step_time_ms": 13481.727, "sample_time_ms": 1188.814, "learn_time_ms": 12280.338, "learn_throughput": 325.724, "synch_weights_time_ms": 11.953}, "counters": {"num_env_steps_sampled": 364000, "num_env_steps_trained": 364000, "num_agent_steps_sampled": 1456000, "num_agent_steps_trained": 1456000}, "done": false, "training_iteration": 91, "trial_id": "b72b3_00000", "date": "2024-08-08_15-53-03", "timestamp": 1723146783, "time_this_iter_s": 13.739729881286621, "time_total_s": 1302.5934889316559, "pid": 98177, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x328118d30>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1302.5934889316559, "iterations_since_restore": 91, "perf": {"cpu_util_percent": 30.585, "ram_util_percent": 81.49}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.8493255853652952, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.262609375764926, "policy_loss": -0.024250222664462247, "vf_loss": 6.285172322392464, "vf_explained_var": -0.028988571589191756, "kl": 0.008436314031768295, "entropy": 0.838526402413845, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 87840.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6345107523790487, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.346953835132274, "policy_loss": -0.021130132325512113, "vf_loss": 3.3674645390070923, "vf_explained_var": -1.043694239136175e-06, "kl": 0.006194242202566976, "entropy": 0.41209240902400185, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 258030.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 368000, "num_env_steps_trained": 368000, "num_agent_steps_sampled": 1472000, "num_agent_steps_trained": 1472000}, "env_runners": {"episode_reward_max": 120.0, "episode_reward_min": -31.870443732055517, "episode_reward_mean": 24.36545079051713, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 157, "episodes_timesteps_total": 3925, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -76.10664614348367}, "policy_reward_max": {"adversary_policy": 60.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 15.35031847133758, "agent_policy": -21.685504623495607}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-6.204904504861271, -31.870443732055517, 40.0, -0.9887147127007678, 120.0, -6.170781223941077, 20.0, 81.6236948703401, 0.0, -2.680519082593502, 0.0, 60.0, 0.0, 60.0, -10.884861169305106, 37.359186142139094, 104.07359172743705, -21.34264252496232, -5.371246713597307, 0.0, 0.0, 58.34846034815648, -1.400013599522273, -7.221153469629119, -2.0491848343193118, -5.579492686362949, 89.42758383283525, 120.0, 0.0, -7.053170739436116, 56.855076436132805, -0.32741105494382805, 0.0, -17.014985454304615, 43.43320760627548, 20.0, 76.59872292792772, 60.0, 114.70524558412984, 27.04374511699577, -2.2054089405950994, -0.5288053059731812, -12.791716331724224, -3.9026529982993505, -15.711600687472046, -2.689876928919319, 119.27767071553338, 120.0, 72.05575721509051, -3.0703498094690573, 60.0, 37.22130733158548, 17.3686826548991, 0.0, -8.318488227711878, 0.0, 9.182095346031984, 99.8870360798864, -21.81442430427629, 73.89335385651633, 52.47288652716374, -12.737420872457397, 40.0, 0.0, -0.7772638011795618, -25.607072232827186, 38.74515708407015, 36.50027079761085, -0.4121235127516043, 80.0, 58.71958213076918, -20.308834949429954, 39.682149312192614, -4.3040860742065306, 31.941508240161504, 60.0, 56.50404514211805, 56.865210505733415, -6.836028677197839, -1.95192155768947, 39.57397950133311, 51.24636227817185, 80.0, 99.62086632498104, 60.0, 40.0, 0.0, -9.861251780304125, -3.588580398453133, 8.203629297028666, 0.0, 20.0, 60.0, 40.0, 20.0, -17.24032664049727, 0.0, 15.588325360967437, 9.309041366310415, 80.0, 38.69398426346705, -0.014149300519256114, 13.600230574761438, 33.674877768604595, 120.0, 20.0, -16.626689197577683, 34.56506104059276, 17.60968888464291, -3.60136480413414, 0.0, 59.667696537964495, 52.36284107809195, 5.9616887651393995, -11.253518967009715, 20.0, -23.801286493201083, 28.175054848801164, 21.820925334739243, -0.6172659358776211, 56.84085974631799, 30.13640588650865, 20.0, 118.14041201428472, -2.5547364113406648, 40.0, -17.645278537408114, -1.750407453174867, -20.215547222214273, 18.934700021779335, 5.730250587190866, -16.177057446004213, -11.185498553954695, 59.09283605435349, 39.83157292227551, 37.46484834663423, -14.365148510063472, 11.64113651703158, 20.0, -6.626651267426991, -6.122061650246977, -5.751611343569605, -14.807831718502273, 13.452264928731857, 94.28181261428638, 34.99323628747256, -6.5590700990585, -6.353826748881332, 119.64186080697561, 60.0, 19.32349857686454, 0.0, -8.826231015786302, -8.72809354588116, 39.19953778210656, 55.662638334149875, -4.050492317301728], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 60.0, 60.0, 60.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 60.0, 60.0, 60.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-36.20490450486127, -31.870443732055517, -20.0, -0.9887147127007678, -60.0, -6.170781223941077, -10.0, -68.3763051296599, 0.0, -2.680519082593502, 0.0, -30.0, 0.0, -30.0, -10.884861169305106, -22.640813857860906, -75.92640827256295, -21.34264252496232, -35.37124671359731, 0.0, 0.0, -31.651539651843525, -1.400013599522273, -7.221153469629119, -2.0491848343193118, -5.579492686362949, -60.57241616716477, -60.0, 0.0, -7.053170739436116, -33.14492356386719, -0.32741105494382805, 0.0, -17.014985454304615, -46.56679239372452, -10.0, -43.40127707207229, -30.0, -65.29475441587019, -32.95625488300423, -2.2054089405950994, -0.5288053059731812, -12.791716331724224, -3.9026529982993505, -15.711600687472046, -2.689876928919319, -60.72232928446661, -60.0, -47.94424278490949, -3.0703498094690573, -30.0, -52.77869266841452, -12.6313173451009, 0.0, -8.318488227711878, 0.0, -20.817904653968014, -50.1129639201136, -21.81442430427629, -76.10664614348367, -37.52711347283626, -12.737420872457397, -20.0, 0.0, -0.7772638011795618, -25.607072232827186, -21.25484291592985, -23.499729202389148, -0.4121235127516043, -40.0, -31.280417869230817, -20.308834949429954, -20.317850687807386, -4.3040860742065306, -28.058491759838496, -30.0, -33.495954857881955, -33.13478949426658, -6.836028677197839, -1.95192155768947, -20.426020498666887, -38.753637721828134, -40.0, -50.37913367501896, -30.0, -20.0, 0.0, -9.861251780304125, -3.588580398453133, -21.796370702971338, 0.0, -10.0, -30.0, -20.0, -10.0, -17.24032664049727, 0.0, -14.411674639032567, -20.690958633689583, -40.0, -21.306015736532945, -0.014149300519256114, -16.39976942523856, -26.325122231395397, -60.0, -10.0, -16.626689197577683, -25.43493895940724, -42.39031111535709, -3.60136480413414, 0.0, -30.332303462035515, -37.63715892190805, -24.0383112348606, -11.253518967009715, -10.0, -23.801286493201083, -31.824945151198847, -38.17907466526074, -0.6172659358776211, -33.15914025368201, -29.863594113491345, -10.0, -61.859587985715265, -2.5547364113406648, -20.0, -17.645278537408114, -1.750407453174867, -20.215547222214273, -11.065299978220665, -24.269749412809134, -16.177057446004213, -11.185498553954695, -60.9071639456465, -20.16842707772448, -52.53515165336577, -14.365148510063472, -18.358863482968424, -10.0, -6.626651267426991, -6.122061650246977, -5.751611343569605, -14.807831718502273, -46.547735071268136, -55.71818738571361, -25.006763712527444, -6.5590700990585, -6.353826748881332, -60.35813919302437, -30.0, -10.67650142313546, 0.0, -8.826231015786302, -8.72809354588116, -20.800462217893433, -34.33736166585012, -4.050492317301728]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6441803813846387, "mean_inference_ms": 1.0932147686895317, "mean_action_processing_ms": 0.23536756816117396, "mean_env_wait_ms": 0.47745541930643715, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005027367051239986, "StateBufferConnector_ms": 0.003106730758764182, "ViewRequirementAgentConnector_ms": 0.08972822480900272}, "num_episodes": 157, "episode_return_max": 120.0, "episode_return_min": -31.870443732055517, "episode_return_mean": 24.36545079051713}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1472000, "num_agent_steps_trained": 1472000, "num_env_steps_sampled": 368000, "num_env_steps_trained": 368000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 293.1618318798213, "num_env_steps_trained_throughput_per_sec": 293.1618318798213, "timesteps_total": 368000, "num_env_steps_sampled_lifetime": 368000, "num_agent_steps_sampled_lifetime": 1472000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1472000, "timers": {"training_iteration_time_ms": 13518.812, "restore_workers_time_ms": 0.019, "training_step_time_ms": 13518.758, "sample_time_ms": 1186.113, "learn_time_ms": 12320.629, "learn_throughput": 324.659, "synch_weights_time_ms": 11.497}, "counters": {"num_env_steps_sampled": 368000, "num_env_steps_trained": 368000, "num_agent_steps_sampled": 1472000, "num_agent_steps_trained": 1472000}, "done": false, "training_iteration": 92, "trial_id": "b72b3_00000", "date": "2024-08-08_15-53-16", "timestamp": 1723146796, "time_this_iter_s": 13.65090012550354, "time_total_s": 1316.2443890571594, "pid": 98177, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3280fc3a0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1316.2443890571594, "iterations_since_restore": 92, "perf": {"cpu_util_percent": 28.99473684210527, "ram_util_percent": 81.91052631578948}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.675411660845081, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.874418589721123, "policy_loss": -0.026319923101497503, "vf_loss": 5.8989864458640415, "vf_explained_var": 0.05706553906202316, "kl": 0.008760407291869566, "entropy": 0.7822204772382975, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 88800.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6270217735293909, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.6043740806850137, "policy_loss": -0.021345199542681534, "vf_loss": 3.6250092344081146, "vf_explained_var": 2.337051621565582e-07, "kl": 0.007100444233276652, "entropy": 0.4213826275040917, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 260850.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 372000, "num_env_steps_trained": 372000, "num_agent_steps_sampled": 1488000, "num_agent_steps_trained": 1488000}, "env_runners": {"episode_reward_max": 135.80734341701645, "episode_reward_min": -29.618002378419355, "episode_reward_mean": 22.572867245659012, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -74.19265658298355}, "policy_reward_max": {"adversary_policy": 70.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 14.382716049382717, "agent_policy": -20.575280902489137}, "custom_metrics": {}, "hist_stats": {"episode_reward": [91.83271729369508, 36.70722102144471, 58.96188920421365, 13.918318074920094, 56.830933798313495, 36.63749855929019, -1.3811546416820497, -9.312248316630598, 0.0, 49.764828157032085, -5.655517788905531, -2.3487617926003557, -0.4353460336627557, 40.0, 100.0, 80.0, 38.02849038425332, -1.4219315305528357, -8.642694634596818, 58.84683813149029, 38.558328991689706, 99.75192198461647, 1.1484403835034414, -0.3735579933298605, 59.935083653661394, -2.560363160611213, 112.15904493030415, -13.738185725987181, 97.88194901546044, 15.529620072966864, 73.33945209925315, -8.310569558858672, -1.4783796106238345, -6.342751539889896, -0.9572706020456023, -6.897328056643263, -4.0503624449323175, 60.0, 58.14675420133347, 0.0, -1.883137218524728, 30.008508968456646, 0.887696767822959, -13.470378573138978, 120.0, 76.1305850100607, 20.0, -7.858943491332486, -2.9354324396304645, 38.56408983288859, 58.47424860470781, 37.48732044684077, 0.0, 20.0, 59.5757623081321, -7.15575893093311, 40.0, 17.10174860846062, 19.083638031252622, -8.894291333297419, -5.354529765345639, -0.20489853240796996, -26.08941064976058, 9.45940165345305, -13.20731040936094, 37.138284563438276, 40.0, 68.02900639493153, 80.0, -0.6764545555245893, 0.0, 34.40126854761895, -7.293162186074445, 57.88334042519523, 38.24874085943264, -1.3271319508895374, -7.377147350826846, 11.953550413037048, -27.375492980593883, 89.969959913101, 50.51154694298712, 0.0, 36.611792199983256, 60.0, 20.0, 0.0, 135.80734341701645, -25.35136502266684, -20.850477840527724, 81.51748952037981, -1.3933643994833145, -28.94714723151266, -8.671695796248768, 80.0, -6.673662617401355, -15.342402436651538, 16.996575015215377, 60.0, 92.02193630788966, 0.0, -3.6093804483325567, 16.182090308145064, 0.0, -17.487691177645967, -1.4514337806763056, 60.0, 18.350859073329243, 20.0, -16.210791467389384, -0.05556080693607246, 80.0, 37.49013809127469, 19.975740596297392, -6.19206043977181, 20.0, 0.0, 71.76152452056914, -8.681364071534905, 0.0, 39.56755202449864, 15.845294465197485, -7.011297769539988, 31.082079791105546, 31.773181175422064, 55.602807226207545, 37.72600565051982, -13.215591101431388, 79.26666493296578, 56.89752553984016, 120.0, -1.7912205565924244, 18.484531335257113, 58.908546628252246, -1.7930103932424302, -8.551678839572823, 15.721897976553226, 0.0, 7.267680044614, 44.50282334071233, -10.913592139313259, 20.0, -29.618002378419355, -28.618797160869875, -0.5458515305434175, 0.0, 14.219876361692458, 58.72476433295737, 45.309367113185985, 0.0, 18.819084786041515, 0.0, -3.854037989593638, -4.838105350826689, -21.21667824068313, 19.82823027950028, 19.008861382818935, 20.0, 12.762073301687023, -18.565276288102456, -24.34575134156539, 80.0, 16.689321224640366], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0], "policy_agent_policy_reward": [-58.167282706304924, -23.292778978555294, -31.038110795786356, -16.081681925079906, -33.169066201686505, -23.362501440709813, -1.3811546416820497, -9.312248316630598, 0.0, -40.235171842967915, -5.655517788905531, -2.3487617926003557, -0.4353460336627557, -20.0, -50.0, -40.0, -21.971509615746687, -1.4219315305528357, -8.642694634596818, -31.153161868509716, -21.441671008310294, -50.24807801538352, -28.85155961649656, -0.3735579933298605, -30.064916346338606, -2.560363160611213, -67.84095506969587, -13.738185725987181, -52.118050984539565, -14.47037992703314, -46.66054790074684, -8.310569558858672, -1.4783796106238345, -6.342751539889896, -0.9572706020456023, -6.897328056643263, -4.0503624449323175, -30.0, -61.85324579866651, 0.0, -31.88313721852473, -29.99149103154336, -29.11230323217704, -13.470378573138978, -60.0, -43.8694149899393, -10.0, -7.858943491332486, -2.9354324396304645, -21.43591016711141, -31.525751395292197, -22.512679553159234, 0.0, -10.0, -30.424237691867898, -7.15575893093311, -20.0, -12.898251391539379, -40.91636196874738, -8.894291333297419, -5.354529765345639, -0.20489853240796996, -26.08941064976058, -20.54059834654695, -13.20731040936094, -22.861715436561727, -20.0, -51.97099360506849, -40.0, -0.6764545555245893, 0.0, -25.598731452381053, -7.293162186074445, -32.11665957480477, -21.751259140567363, -1.3271319508895374, -7.377147350826846, -18.046449586962954, -27.375492980593883, -60.03004008689901, -39.488453057012876, 0.0, -23.38820780001674, -30.0, -10.0, 0.0, -74.19265658298355, -25.35136502266684, -20.850477840527724, -68.48251047962019, -1.3933643994833145, -28.94714723151266, -8.671695796248768, -40.0, -6.673662617401355, -15.342402436651538, -43.00342498478462, -30.0, -57.97806369211035, 0.0, -3.6093804483325567, -13.817909691854934, 0.0, -17.487691177645967, -1.4514337806763056, -30.0, -41.64914092667075, -10.0, -16.210791467389384, -0.05556080693607246, -40.0, -22.509861908725313, -10.024259403702608, -6.19206043977181, -10.0, 0.0, -48.238475479430875, -8.681364071534905, 0.0, -20.43244797550137, -14.154705534802513, -7.011297769539988, -28.917920208894472, -28.226818824577943, -34.397192773792455, -22.273994349480184, -13.215591101431388, -40.73333506703422, -33.10247446015985, -60.0, -1.7912205565924244, -41.51546866474289, -31.09145337174776, -1.7930103932424302, -8.551678839572823, -14.278102023446776, 0.0, -22.732319955386, -45.497176659287675, -10.913592139313259, -10.0, -29.618002378419355, -28.618797160869875, -0.5458515305434175, 0.0, -15.780123638307543, -31.27523566704263, -44.69063288681402, 0.0, -11.180915213958485, 0.0, -3.854037989593638, -4.838105350826689, -21.21667824068313, -10.17176972049972, -10.991138617181067, -10.0, -17.237926698312982, -18.565276288102456, -24.34575134156539, -40.0, -13.310678775359635]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6436471628800166, "mean_inference_ms": 1.0923828299860119, "mean_action_processing_ms": 0.2351317472474367, "mean_env_wait_ms": 0.47717827862905454, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004066214149380907, "StateBufferConnector_ms": 0.003042559564849477, "ViewRequirementAgentConnector_ms": 0.08493978300212342}, "num_episodes": 162, "episode_return_max": 135.80734341701645, "episode_return_min": -29.618002378419355, "episode_return_mean": 22.572867245659012}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1488000, "num_agent_steps_trained": 1488000, "num_env_steps_sampled": 372000, "num_env_steps_trained": 372000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 294.4725750253437, "num_env_steps_trained_throughput_per_sec": 294.4725750253437, "timesteps_total": 372000, "num_env_steps_sampled_lifetime": 372000, "num_agent_steps_sampled_lifetime": 1488000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1488000, "timers": {"training_iteration_time_ms": 13479.71, "restore_workers_time_ms": 0.019, "training_step_time_ms": 13479.657, "sample_time_ms": 1176.341, "learn_time_ms": 12291.333, "learn_throughput": 325.433, "synch_weights_time_ms": 11.46}, "counters": {"num_env_steps_sampled": 372000, "num_env_steps_trained": 372000, "num_agent_steps_sampled": 1488000, "num_agent_steps_trained": 1488000}, "done": false, "training_iteration": 93, "trial_id": "b72b3_00000", "date": "2024-08-08_15-53-30", "timestamp": 1723146810, "time_this_iter_s": 13.625042200088501, "time_total_s": 1329.869431257248, "pid": 98177, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3280ea4c0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1329.869431257248, "iterations_since_restore": 93, "perf": {"cpu_util_percent": 33.905, "ram_util_percent": 82.52999999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.9481984550754228, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.571688950061798, "policy_loss": -0.02588797579810489, "vf_loss": 5.595874568323294, "vf_explained_var": 0.03130669922878345, "kl": 0.008511882484232283, "entropy": 0.7925019240627686, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 89760.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.612688022851944, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.9807975546265326, "policy_loss": -0.019947388568225956, "vf_loss": 3.0001477539962065, "vf_explained_var": 2.58582703610684e-07, "kl": 0.005971855038151843, "entropy": 0.4124453326172017, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 263670.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 376000, "num_env_steps_trained": 376000, "num_agent_steps_sampled": 1504000, "num_agent_steps_trained": 1504000}, "env_runners": {"episode_reward_max": 139.72232581758257, "episode_reward_min": -34.56394847729544, "episode_reward_mean": 21.31455633739036, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -76.82785262455016}, "policy_reward_max": {"adversary_policy": 70.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 13.271604938271604, "agent_policy": -18.500258477424453}, "custom_metrics": {}, "hist_stats": {"episode_reward": [100.0, 39.3179966236066, -11.110694343694828, 6.794895526005616, -4.277447945029381, -0.6609945593648325, 28.547834739407, 20.0, -3.0427041369947716, -1.998851911252554, -10.67143307554025, -8.834400156876558, -2.492075020312937, 14.726233811058641, 0.0, 0.0, -2.2491217252502516, 40.0, 38.23832192443294, 0.0, -20.873004586921535, 57.7305456056459, 78.82276695502718, -32.14665451981895, 56.800437029467446, 0.0, 79.97619933386116, 100.0, 20.0, -12.294901708310228, -9.585689826155823, 0.0, -0.15607489181149625, 57.593839471427714, 39.0477276654919, -13.808267994684865, 0.0, 33.689077759293774, 0.0, 20.0, 40.0, -20.77576664686542, 118.33016514022958, 73.69602837136966, 0.0, 0.0, 59.97066651406875, 36.48851761176532, 11.117237125454253, -4.548422393603219, 56.34893859771812, -10.154770000746247, -0.5597363651662257, -21.051215900803726, -16.887025109355754, 40.0, 51.66998089032431, -6.182495939205336, 100.0, -3.1717989030626104, -17.036352897518952, 51.5809765416053, 20.0, -0.23234854042207043, -12.965463231795932, 30.83501155267733, 40.0, 57.73318295472497, 60.0, 1.6484113074833835, 120.0, 0.0, 9.663056256002065, -13.674437700465475, -6.233919117490453, 0.0, 0.0, 0.0, -7.284603637016438, 26.092501874964867, -17.214283330987357, 36.70071955773233, -3.2448378120206764, 40.0, 40.0, 1.676718300085515, -10.472320430901366, -1.5454706986840268, -12.252638369945842, 40.0, -0.46240811858499375, 119.82164322725033, -18.684634110452603, 0.0, -0.9095931201704233, 0.0, 0.0, 80.0, 40.0, 60.0, -13.527979833530871, 60.0, 56.31214028077675, 37.403974061844075, 0.0, 17.643799205578706, -12.928733083746083, 20.0, 33.25609452148703, 40.0, -0.1696064798177832, -8.352563077663092, 119.54134572627389, 0.0, 71.45246138057027, -34.56394847729544, -2.7596347668470873, -1.664609833417704, 31.296196867671895, 20.0, 12.501760804499241, 39.098495317983314, 17.667203091948306, 0.0, 52.966298616305956, 48.93985035082778, 18.71949671650519, -3.633835584510693, -14.293989827488575, -3.191452220295865, 103.17214737544985, -0.2257257476259078, -4.853376947360868, 139.5091655787793, -1.5039182716696298, -9.609114786966616, -8.288836242062953, 16.47975584135259, -8.819658840260848, 0.0, 56.72104262641817, 40.0, 44.064345349403474, 93.2994908439807, 139.72232581758257, -3.564916345255023, 58.572340702580625, 0.0, -5.634564045363632, -0.7098102968092301, 60.0, 60.0, -12.113326437056148, 0.0, 31.3059564737771, 0.0, 40.0, -3.2459430653014083, -19.202654382168575, -10.634731747587619, 68.95719507532814, 32.935400879517765], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0], "policy_agent_policy_reward": [-50.0, -20.682003376393403, -11.110694343694828, -23.205104473994382, -4.277447945029381, -0.6609945593648325, -31.452165260593, -10.0, -3.0427041369947716, -1.998851911252554, -10.67143307554025, -8.834400156876558, -2.492075020312937, -15.273766188941364, 0.0, 0.0, -2.2491217252502516, -20.0, -21.76167807556706, 0.0, -20.873004586921535, -32.2694543943541, -41.17723304497283, -32.14665451981895, -33.199562970532554, 0.0, -40.02380066613885, -50.0, -10.0, -12.294901708310228, -9.585689826155823, 0.0, -0.15607489181149625, -32.406160528572286, -20.95227233450811, -13.808267994684865, 0.0, -26.31092224070622, 0.0, -10.0, -20.0, -20.77576664686542, -61.669834859770425, -46.30397162863034, 0.0, 0.0, -30.029333485931243, -23.511482388234683, -18.882762874545747, -4.548422393603219, -33.651061402281876, -10.154770000746247, -0.5597363651662257, -21.051215900803726, -16.887025109355754, -20.0, -38.330019109675696, -6.182495939205336, -50.0, -3.1717989030626104, -17.036352897518952, -38.4190234583947, -10.0, -0.23234854042207043, -12.965463231795932, -29.164988447322674, -20.0, -32.26681704527503, -30.0, -28.35158869251662, -60.0, 0.0, -20.336943743997935, -13.674437700465475, -6.233919117490453, 0.0, 0.0, 0.0, -7.284603637016438, -33.90749812503513, -17.214283330987357, -23.299280442267676, -3.2448378120206764, -20.0, -20.0, -58.323281699914496, -10.472320430901366, -1.5454706986840268, -12.252638369945842, -20.0, -0.46240811858499375, -60.178356772749666, -18.684634110452603, 0.0, -0.9095931201704233, 0.0, 0.0, -40.0, -20.0, -30.0, -13.527979833530871, -30.0, -33.687859719223255, -22.596025938155925, 0.0, -12.356200794421296, -12.928733083746083, -10.0, -26.74390547851297, -20.0, -0.1696064798177832, -8.352563077663092, -60.458654273726104, 0.0, -48.54753861942975, -34.56394847729544, -2.7596347668470873, -1.664609833417704, -28.703803132328108, -10.0, -17.49823919550076, -20.901504682016686, -12.332796908051694, 0.0, -37.03370138369405, -41.06014964917221, -11.280503283494808, -3.633835584510693, -14.293989827488575, -3.191452220295865, -76.82785262455016, -0.2257257476259078, -4.853376947360868, -70.49083442122071, -1.5039182716696298, -9.609114786966616, -8.288836242062953, -13.520244158647412, -8.819658840260848, 0.0, -33.27895737358183, -20.0, -45.935654650596526, -56.700509156019294, -70.27767418241741, -3.564916345255023, -31.427659297419382, 0.0, -5.634564045363632, -0.7098102968092301, -30.0, -30.0, -12.113326437056148, 0.0, -28.6940435262229, 0.0, -20.0, -3.2459430653014083, -19.202654382168575, -10.634731747587619, -51.042804924671834, -27.06459912048224]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6432945394696794, "mean_inference_ms": 1.0919287715524375, "mean_action_processing_ms": 0.2348772144678427, "mean_env_wait_ms": 0.4769461535692029, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005423066056804892, "StateBufferConnector_ms": 0.0035617086622450086, "ViewRequirementAgentConnector_ms": 0.09066249117439176}, "num_episodes": 162, "episode_return_max": 139.72232581758257, "episode_return_min": -34.56394847729544, "episode_return_mean": 21.31455633739036}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1504000, "num_agent_steps_trained": 1504000, "num_env_steps_sampled": 376000, "num_env_steps_trained": 376000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 299.6886204406658, "num_env_steps_trained_throughput_per_sec": 299.6886204406658, "timesteps_total": 376000, "num_env_steps_sampled_lifetime": 376000, "num_agent_steps_sampled_lifetime": 1504000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1504000, "timers": {"training_iteration_time_ms": 13457.257, "restore_workers_time_ms": 0.019, "training_step_time_ms": 13457.203, "sample_time_ms": 1172.621, "learn_time_ms": 12272.283, "learn_throughput": 325.938, "synch_weights_time_ms": 11.836}, "counters": {"num_env_steps_sampled": 376000, "num_env_steps_trained": 376000, "num_agent_steps_sampled": 1504000, "num_agent_steps_trained": 1504000}, "done": false, "training_iteration": 94, "trial_id": "b72b3_00000", "date": "2024-08-08_15-53-44", "timestamp": 1723146824, "time_this_iter_s": 13.352267980575562, "time_total_s": 1343.2216992378235, "pid": 98177, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3280ea700>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1343.2216992378235, "iterations_since_restore": 94, "perf": {"cpu_util_percent": 29.710526315789473, "ram_util_percent": 82.47894736842106}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.90162204913795, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.279897101471821, "policy_loss": -0.026954638302656046, "vf_loss": 5.305249880750974, "vf_explained_var": 0.03911682137598594, "kl": 0.008009344479166814, "entropy": 0.7696768218651414, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 90720.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5969358169969092, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.070791601416067, "policy_loss": -0.020248247495545272, "vf_loss": 3.090388593098796, "vf_explained_var": 3.9254519956331726e-07, "kl": 0.006512620318665098, "entropy": 0.4119610963772375, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 266490.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 380000, "num_env_steps_trained": 380000, "num_agent_steps_sampled": 1520000, "num_agent_steps_trained": 1520000}, "env_runners": {"episode_reward_max": 140.0, "episode_reward_min": -28.17320466462476, "episode_reward_mean": 22.423162014182545, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -70.0}, "policy_reward_max": {"adversary_policy": 70.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 13.703703703703704, "agent_policy": -18.687949096928563}, "custom_metrics": {}, "hist_stats": {"episode_reward": [32.7178936848439, 112.1324971704426, -5.771019191001098, -12.31208884464295, -10.963929723629423, 120.0, 59.791031888978964, 74.51233714393854, 100.0, -0.15204687091532, 70.93880929258142, 38.65666653469086, 26.61274091654145, -8.160085037346215, -3.3397077360803715, 30.099911785507395, -0.7923474688869936, -0.6007992516729632, -12.607818985274166, 36.80703827940817, 49.64560344786317, -0.13981330180034002, 0.0, 0.0, -5.259535306465988, 60.0, -13.235221228926829, 0.0, -0.2448776907778738, 52.53703828814908, -3.5441771916521443, 0.0, 0.0, -3.9065643265667696, 60.0, 0.0, 80.0, 100.0, 0.0, 19.73585102910606, -0.23984140838762213, 24.192336960253954, 6.6407070336425456, -2.4008933913412345, 99.73168849831676, 96.8755372069082, 0.0, -5.0057812172966765, 0.0, -0.3952949949162976, 0.0, -11.45563895631157, 46.93418031256514, 35.18779786212191, 17.943573770681965, 54.757016879980256, 60.0, -0.785493913174804, 20.0, -7.042100560842711, 19.43811686883654, 0.0, -9.64814957367193, 58.8279421982027, 0.0, 37.46984357593762, 40.0, -9.55514723966565, 0.0, 60.0, 0.0, -0.8019444306693413, 73.25206494002525, 140.0, 97.04598281690338, -9.478170188384654, -1.2685167247821816, 49.040757788257174, -18.34426941962876, -9.153179951449228, 0.0, 0.0, -2.7611711731430466, -2.1798599623733503, -1.7156289290190574, 74.26208437284211, 80.0, 100.0, 57.21952254285134, 90.27497527067663, -24.331182445710255, -0.6943444237361973, -1.086051835299734, -9.87206706523156, -12.985215383005112, 119.9062064206878, 31.62651154229927, 56.50382044685096, -0.5425068343853934, 39.99178692112753, 79.86070972339422, 20.0, 34.531151275110716, 18.265568000293623, -16.63204742814608, 39.234409673612205, -1.1696584787376285, 15.805782076279694, -6.182743960931993, 0.0, -8.588048886866295, 79.94391416618181, -3.2250136983595077, 0.0, 34.20298018849042, -1.3533039644825162, 60.0, 33.97145607219712, -14.272318397181737, 56.8290538205402, 56.73859623731028, 0.0, 120.0, 39.988625606445495, 0.0, -6.000366455939366, 42.46582767401208, 53.31107722441996, 40.0, 38.521511356661875, 40.0, 21.421360910204218, 0.0, 77.35139195581574, -6.535731613277788, 20.0, -1.3412315706124212, -1.2327961867518922, 25.147338990986096, 0.0, -23.27359626198475, 58.764389723518704, -21.061521999185935, -2.4775796129397154, 0.0, -1.13875696894839, -27.69955648570124, -1.7090366115475775, -0.014964872453829825, -8.064177243895843, -7.972587535906999, -2.2376052101234913, -0.29313575720775087, 23.727026833332094, 20.0, 4.4633934503905905, -28.17320466462476, -2.533328386890063, 20.0, 74.69811088167819, -0.6912833418658559, -11.355225462694197], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [20.0, 20.0, 20.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 70.0, 70.0, 70.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-27.282106315156096, -67.8675028295574, -5.771019191001098, -12.31208884464295, -10.963929723629423, -60.0, -30.208968111021033, -45.48766285606146, -50.0, -0.15204687091532, -49.061190707418575, -21.343333465309147, -33.387259083458545, -8.160085037346215, -3.3397077360803715, -29.9000882144926, -0.7923474688869936, -0.6007992516729632, -12.607818985274166, -23.192961720591832, -40.35439655213684, -0.13981330180034002, 0.0, 0.0, -5.259535306465988, -30.0, -13.235221228926829, 0.0, -0.2448776907778738, -37.46296171185092, -3.5441771916521443, 0.0, 0.0, -3.9065643265667696, -30.0, 0.0, -40.0, -50.0, 0.0, -10.264148970893944, -0.23984140838762213, -35.807663039746046, -23.359292966357454, -2.4008933913412345, -50.26831150168325, -53.1244627930918, 0.0, -5.0057812172966765, 0.0, -0.3952949949162976, 0.0, -11.45563895631157, -43.06581968743486, -24.81220213787807, -12.056426229318035, -35.242983120019744, -30.0, -0.785493913174804, -10.0, -7.042100560842711, -40.56188313116345, 0.0, -9.64814957367193, -31.172057801797312, 0.0, -52.53015642406238, -20.0, -9.55514723966565, 0.0, -30.0, 0.0, -0.8019444306693413, -46.74793505997474, -70.0, -52.95401718309662, -9.478170188384654, -1.2685167247821816, -40.95924221174282, -18.34426941962876, -9.153179951449228, 0.0, 0.0, -2.7611711731430466, -2.1798599623733503, -1.7156289290190574, -45.73791562715788, -40.0, -50.0, -32.780477457148656, -59.725024729323366, -24.331182445710255, -0.6943444237361973, -1.086051835299734, -9.87206706523156, -12.985215383005112, -60.09379357931219, -28.37348845770074, -33.49617955314904, -0.5425068343853934, -20.008213078872473, -40.13929027660578, -10.0, -25.468848724889284, -11.734431999706379, -16.63204742814608, -20.765590326387795, -1.1696584787376285, -14.194217923720302, -6.182743960931993, 0.0, -8.588048886866295, -40.05608583381819, -3.2250136983595077, 0.0, -25.79701981150958, -1.3533039644825162, -30.0, -26.028543927802886, -14.272318397181737, -33.170946179459804, -33.26140376268972, 0.0, -60.0, -20.0113743935545, 0.0, -6.000366455939366, -47.53417232598792, -36.68892277558003, -20.0, -21.478488643338125, -20.0, -38.578639089795786, 0.0, -42.64860804418426, -6.535731613277788, -10.0, -1.3412315706124212, -1.2327961867518922, -34.8526610090139, 0.0, -23.27359626198475, -31.235610276481296, -21.061521999185935, -2.4775796129397154, 0.0, -1.13875696894839, -27.69955648570124, -1.7090366115475775, -0.014964872453829825, -8.064177243895843, -7.972587535906999, -2.2376052101234913, -0.29313575720775087, -66.27297316666791, -10.0, -25.53660654960941, -28.17320466462476, -2.533328386890063, -10.0, -45.3018891183218, -0.6912833418658559, -11.355225462694197]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6430283992313278, "mean_inference_ms": 1.091731999707034, "mean_action_processing_ms": 0.2347014817684921, "mean_env_wait_ms": 0.47688964651441035, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004469686084323459, "StateBufferConnector_ms": 0.0032806838000262223, "ViewRequirementAgentConnector_ms": 0.09017925203582387}, "num_episodes": 162, "episode_return_max": 140.0, "episode_return_min": -28.17320466462476, "episode_return_mean": 22.423162014182545}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1520000, "num_agent_steps_trained": 1520000, "num_env_steps_sampled": 380000, "num_env_steps_trained": 380000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 294.56469211898514, "num_env_steps_trained_throughput_per_sec": 294.56469211898514, "timesteps_total": 380000, "num_env_steps_sampled_lifetime": 380000, "num_agent_steps_sampled_lifetime": 1520000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1520000, "timers": {"training_iteration_time_ms": 13488.724, "restore_workers_time_ms": 0.019, "training_step_time_ms": 13488.67, "sample_time_ms": 1171.303, "learn_time_ms": 12304.974, "learn_throughput": 325.072, "synch_weights_time_ms": 11.938}, "counters": {"num_env_steps_sampled": 380000, "num_env_steps_trained": 380000, "num_agent_steps_sampled": 1520000, "num_agent_steps_trained": 1520000}, "done": false, "training_iteration": 95, "trial_id": "b72b3_00000", "date": "2024-08-08_15-53-57", "timestamp": 1723146837, "time_this_iter_s": 13.602477073669434, "time_total_s": 1356.824176311493, "pid": 98177, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3280eaa60>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1356.824176311493, "iterations_since_restore": 95, "perf": {"cpu_util_percent": 28.20526315789473, "ram_util_percent": 82.03684210526316}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.937833305820823, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.782955754548311, "policy_loss": -0.02175076288161411, "vf_loss": 5.803158665200074, "vf_explained_var": 0.02861066392312447, "kl": 0.0077392747082330295, "entropy": 0.7414935218791167, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 91680.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5906881164574455, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.085457127821361, "policy_loss": -0.02021170884737388, "vf_loss": 3.1049977836033977, "vf_explained_var": -3.1252279349252686e-07, "kl": 0.006710517739828207, "entropy": 0.41593848176247683, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 269310.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 384000, "num_env_steps_trained": 384000, "num_agent_steps_sampled": 1536000, "num_agent_steps_trained": 1536000}, "env_runners": {"episode_reward_max": 200.0, "episode_reward_min": -30.517761933453023, "episode_reward_mean": 21.55287334830038, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 153, "episodes_timesteps_total": 3825, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -100.0}, "policy_reward_max": {"adversary_policy": 100.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 13.333333333333334, "agent_policy": -18.44712665169962}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-7.221559272768113, -9.481584558513982, -8.349892686081615, -0.6609719629598754, 109.08920892012206, 40.0, 57.04716782621419, 36.96979946779888, -7.468363825924188, 20.0, 60.0, 52.23585173457666, -1.3731589089613339, 200.0, -0.09754410226971211, 16.0585074040816, 35.94776160016416, -10.3807470357786, 60.0, 38.974498706114176, 32.624158735771424, 60.0, 0.0, 40.0, -4.510038102608914, -2.9201871988272847, -1.540933060201689, 8.150306191011616, -2.2603775848487793, 79.35315213976395, -8.085769565683787, -2.2996290785114506, 0.0, -0.04177977890185813, -5.039716949244127, 49.98752195522927, -10.92113385164511, -8.543948243196153, -6.87173899733522, 34.92677274717903, 0.0, 60.0, 58.53848565980665, -3.4105202617043355, -11.995322660263938, 40.0, 0.0, 60.0, 8.176528016989304, 0.0, 20.0, 60.0, 0.0, -0.6651399188300289, -0.45556335406784165, 0.0, -4.942827537821801, 0.0, 40.0, 77.75450981083553, 40.0, 60.0, 1.5377272430428732, 160.0, 17.61987152968745, 0.0, 40.0, 17.77391885474991, 13.744768777330105, 0.0, 40.0, 40.0, 58.64755214842083, 32.8708780667871, -1.464469142924253, 51.592809989938516, -19.062864394051182, -4.164441450734231, 179.98362235257264, 0.0, 118.67058194639716, 33.252092374772516, 20.0, -7.505510718879731, -5.306181792333685, 47.44780245099169, -15.001914946172517, 20.0, 40.0, -17.97532923656494, -0.2498133771902633, -4.283228836461568, -5.660554347572731, 0.0, 30.71720072959441, -17.288764806074166, 77.21201560544131, 68.84324438566608, 20.0, 20.0, -24.840542431580516, -13.787164126939915, 13.003460656260017, 39.55338042924975, -2.7610881375680156, 100.0, 0.0, 100.0, -9.20405899822847, 5.720669978319486, 134.46665202970797, 16.639772460700456, -19.68144844124164, 0.0, -3.6706654899170763, 70.06629830024256, -7.613471556429068, 28.308801745335415, 18.757282795741524, -0.981373913026633, 77.40669760933558, 0.0, 60.0, 47.55911109590205, 14.705637137100155, 18.77771519773314, -15.279796994832363, 20.0, 15.071493932553727, -3.115008589483214, 19.963564058632123, 55.80631409498441, -7.889694276110655, 0.0, 18.606751515158273, -5.403065557316872, -10.158473915946026, 0.0, -7.028992055337928, -11.772675805567042, 0.0, -0.7726093971949977, 49.75962603981381, -15.076445604199549, -5.899743768361786, 60.0, 57.104149927557536, -15.800162971355727, -2.4983035279827472, -1.9502701650069298, -15.069239069902997, -1.1624958125288631, -30.517761933453023], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 100.0, 100.0, 100.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 80.0, 80.0, 80.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 90.0, 90.0, 90.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 70.0, 70.0, 70.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-7.221559272768113, -9.481584558513982, -8.349892686081615, -0.6609719629598754, -70.91079107987794, -20.0, -62.952832173785794, -23.03020053220112, -7.468363825924188, -10.0, -30.0, -37.764148265423344, -1.3731589089613339, -100.0, -0.09754410226971211, -13.9414925959184, -24.052238399835844, -10.3807470357786, -30.0, -21.025501293885824, -27.37584126422858, -30.0, 0.0, -20.0, -4.510038102608914, -2.9201871988272847, -1.540933060201689, -21.849693808988384, -2.2603775848487793, -40.64684786023604, -8.085769565683787, -2.2996290785114506, 0.0, -0.04177977890185813, -5.039716949244127, -40.01247804477073, -10.92113385164511, -8.543948243196153, -6.87173899733522, -25.073227252820978, 0.0, -30.0, -31.461514340193347, -3.4105202617043355, -11.995322660263938, -20.0, 0.0, -30.0, -21.823471983010695, 0.0, -10.0, -30.0, 0.0, -0.6651399188300289, -0.45556335406784165, 0.0, -4.942827537821801, 0.0, -20.0, -42.245490189164464, -20.0, -30.0, -28.462272756957127, -80.0, -12.380128470312547, 0.0, -20.0, -12.226081145250095, -16.255231222669895, 0.0, -20.0, -20.0, -31.352447851579164, -27.1291219332129, -1.464469142924253, -38.407190010061484, -19.062864394051182, -4.164441450734231, -90.01637764742736, 0.0, -61.329418053602836, -26.747907625227466, -10.0, -7.505510718879731, -5.306181792333685, -42.552197549008305, -15.001914946172517, -10.0, -20.0, -17.97532923656494, -0.2498133771902633, -4.283228836461568, -5.660554347572731, 0.0, -29.28279927040559, -17.288764806074166, -42.78798439455869, -51.1567556143339, -10.0, -10.0, -24.840542431580516, -13.787164126939915, -16.996539343739983, -20.446619570750254, -2.7610881375680156, -50.0, 0.0, -50.0, -9.20405899822847, -24.279330021680515, -75.53334797029203, -43.360227539299544, -19.68144844124164, 0.0, -3.6706654899170763, -49.933701699757435, -7.613471556429068, -31.69119825466459, -11.242717204258476, -0.981373913026633, -42.59330239066442, 0.0, -30.0, -42.440888904097946, -45.29436286289984, -11.222284802266863, -15.279796994832363, -10.0, -14.928506067446273, -3.115008589483214, -10.036435941367877, -34.19368590501559, -7.889694276110655, 0.0, -11.393248484841727, -5.403065557316872, -10.158473915946026, 0.0, -7.028992055337928, -11.772675805567042, 0.0, -0.7726093971949977, -40.24037396018619, -15.076445604199549, -5.899743768361786, -30.0, -32.89585007244246, -15.800162971355727, -2.4983035279827472, -1.9502701650069298, -15.069239069902997, -1.1624958125288631, -30.517761933453023]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6425765758353703, "mean_inference_ms": 1.0911113489655282, "mean_action_processing_ms": 0.23444866859443828, "mean_env_wait_ms": 0.47663197901198445, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004045636046166513, "StateBufferConnector_ms": 0.0032075869491676877, "ViewRequirementAgentConnector_ms": 0.08629007277145885}, "num_episodes": 153, "episode_return_max": 200.0, "episode_return_min": -30.517761933453023, "episode_return_mean": 21.55287334830038}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1536000, "num_agent_steps_trained": 1536000, "num_env_steps_sampled": 384000, "num_env_steps_trained": 384000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 302.8466186735778, "num_env_steps_trained_throughput_per_sec": 302.8466186735778, "timesteps_total": 384000, "num_env_steps_sampled_lifetime": 384000, "num_agent_steps_sampled_lifetime": 1536000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1536000, "timers": {"training_iteration_time_ms": 13392.88, "restore_workers_time_ms": 0.014, "training_step_time_ms": 13392.843, "sample_time_ms": 1167.919, "learn_time_ms": 12212.539, "learn_throughput": 327.532, "synch_weights_time_ms": 11.952}, "counters": {"num_env_steps_sampled": 384000, "num_env_steps_trained": 384000, "num_agent_steps_sampled": 1536000, "num_agent_steps_trained": 1536000}, "done": false, "training_iteration": 96, "trial_id": "b72b3_00000", "date": "2024-08-08_15-54-11", "timestamp": 1723146851, "time_this_iter_s": 13.213762998580933, "time_total_s": 1370.0379393100739, "pid": 98177, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3280eaca0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1370.0379393100739, "iterations_since_restore": 96, "perf": {"cpu_util_percent": 27.115789473684206, "ram_util_percent": 81.91578947368421}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.9273274185756843, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.13443872431914, "policy_loss": -0.025769159006934692, "vf_loss": 6.158552388350169, "vf_explained_var": -0.004893803286055724, "kl": 0.008277366013085354, "entropy": 0.7693964010725419, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 92640.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6232295357377816, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.429634216068484, "policy_loss": -0.021061585605861157, "vf_loss": 3.4500129284588157, "vf_explained_var": -9.397454295598023e-07, "kl": 0.006828681977279839, "entropy": 0.3961262365710651, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 272130.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 388000, "num_env_steps_trained": 388000, "num_agent_steps_sampled": 1552000, "num_agent_steps_trained": 1552000}, "env_runners": {"episode_reward_max": 140.0, "episode_reward_min": -43.07380483947251, "episode_reward_mean": 23.298327764704126, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -89.54794392086906}, "policy_reward_max": {"adversary_policy": 70.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 14.876543209876543, "agent_policy": -21.331301864925504}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 19.54333399972751, 10.995260098086922, -2.4242069673634994, 37.84015352861245, 40.0, 19.434594766335117, -0.6698336448064979, -21.680341694532416, -20.73974465771684, -1.687051649859257, -9.125953852874215, 36.03269792910264, 28.733871443579577, 26.06421763645435, -7.02512144504276, 114.91104217687143, 120.0, -0.4120914907705864, -4.87094295892926, 40.153109907228924, 71.18399938974812, 11.08449298359302, 59.28516802482858, 0.6654255524942467, 29.277910974622465, -2.8231795212274644, 23.992270062545387, -10.853341154382385, -13.64537660857015, 14.794150319123613, 20.0, 78.56197317378715, -2.4931008626450057, 60.45205607913094, 84.41621294983781, 40.0, 0.0, 0.0, 80.0, -4.426277067209606, -9.103601217767908, -12.715009535182501, 0.0, -0.5060219608053651, 59.13323870610717, -7.001191480677371, -15.625859799480631, 20.0, -14.291019848558019, -3.384081457852114, -0.42894165307507226, -10.38548876262659, -0.4837951924313244, 39.37076743312984, 58.91363871569499, -13.315541132030605, -30.151868450305766, 29.8010224012349, 40.0, 20.0, 0.0, -43.07380483947251, 0.0, -11.980373777242187, -10.510259367886349, 48.77644886290326, 51.48364786333234, 11.085302309171919, 112.6308314070732, 4.813251119034571, 20.0, 120.0, 60.0, 117.70398380564504, 38.32993607610324, 20.0, 7.703825974507346, 100.0, 19.95213921451461, 60.0, 70.89222926493807, 80.0, 75.37192428560714, 78.76641398971951, -8.643179792738763, -0.12291008841859519, 90.49292671934614, 52.85393082406645, -0.005828960067691957, 0.0, 40.0, 140.0, 10.411161420281653, 0.0, 50.81740654310373, -1.9308101385191656, -3.6196607042003803, 34.0164347194719, 93.83560806818981, -1.5724646587903615, 39.22767915955709, 59.415110992998706, 8.86801582884668, 48.94616674238072, -11.934221002241754, -2.756828541659406, 20.0, -20.624425901145848, 99.1396157578788, 30.97227906273167, -37.24786812403494, -6.202168561519349, 18.306530530556003, 55.86132425324635, 100.0, -7.703926498949244, 40.0, 58.81101554559591, 19.900365754605534, -19.066112306232426, -9.843545220811261, 100.0, -15.891608384383035, 100.0, 72.68489109018549, -20.853560700427046, -6.628939154948968, -0.6068877004408324, 0.0, 19.64609732584336, -2.0993665436723594, 0.0, 60.0, 80.0, 0.0, 30.238119988916214, 59.44208539863101, 10.23222277818055, -15.631650165844988, -2.143448663328539, -0.13277694750878033, -8.344547734192847, 20.0, 1.10117489054962, -1.376230250544096, 0.0, 0.0, -2.110928738647642, -0.10765952869818407, 40.0, -1.4157243397573471, -18.489184741702456, 58.53181281757549, -0.092943889290803, 20.0, 0.0, -7.423143474763525, 0.0, -5.249060057899222, 54.216830944569764, 29.91478186703651], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 60.0, 60.0, 60.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 60.0, 60.0, 60.0, 30.0, 30.0, 30.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 50.0, 50.0, 50.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 70.0, 70.0, 70.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0], "policy_agent_policy_reward": [0.0, -10.456666000272492, -19.004739901913076, -2.4242069673634994, -52.15984647138755, -20.0, -10.565405233664881, -0.6698336448064979, -21.680341694532416, -20.73974465771684, -1.687051649859257, -9.125953852874215, -23.96730207089736, -31.26612855642042, -63.93578236354564, -7.02512144504276, -65.08895782312857, -60.0, -0.4120914907705864, -4.87094295892926, -49.846890092771076, -48.816000610251876, -18.91550701640698, -30.714831975171414, -29.33457444750575, -30.722089025377542, -2.8231795212274644, -36.00772993745461, -10.853341154382385, -13.64537660857015, -15.205849680876387, -10.0, -41.43802682621285, -2.4931008626450057, -89.54794392086906, -65.58378705016219, -20.0, 0.0, 0.0, -40.0, -4.426277067209606, -9.103601217767908, -12.715009535182501, 0.0, -0.5060219608053651, -30.86676129389283, -7.001191480677371, -15.625859799480631, -10.0, -14.291019848558019, -3.384081457852114, -0.42894165307507226, -10.38548876262659, -0.4837951924313244, -20.629232566870154, -31.086361284305017, -13.315541132030605, -30.151868450305766, -30.19897759876511, -20.0, -10.0, 0.0, -43.07380483947251, 0.0, -11.980373777242187, -10.510259367886349, -41.22355113709674, -38.51635213666766, -18.914697690828085, -67.3691685929268, -25.18674888096543, -10.0, -60.0, -30.0, -62.29601619435496, -21.670063923896763, -10.0, -22.296174025492654, -50.0, -10.047860785485392, -30.0, -49.10777073506193, -40.0, -74.62807571439285, -41.23358601028049, -8.643179792738763, -0.12291008841859519, -59.507073280653835, -37.146069175933555, -0.005828960067691957, 0.0, -20.0, -70.0, -19.588838579718352, 0.0, -39.18259345689628, -1.9308101385191656, -3.6196607042003803, -25.98356528052809, -56.16439193181019, -31.572464658790363, -20.77232084044291, -30.5848890070013, -21.13198417115332, -41.05383325761928, -11.934221002241754, -2.756828541659406, -10.0, -20.624425901145848, -50.86038424212121, -29.027720937268324, -37.24786812403494, -6.202168561519349, -11.693469469443999, -34.138675746753655, -50.0, -7.703926498949244, -20.0, -31.18898445440409, -10.099634245394464, -19.066112306232426, -9.843545220811261, -50.0, -15.891608384383035, -50.0, -47.315108909814505, -20.853560700427046, -6.628939154948968, -0.6068877004408324, 0.0, -10.35390267415664, -2.0993665436723594, 0.0, -30.0, -40.0, 0.0, -29.761880011083786, -30.557914601368992, -19.76777722181945, -15.631650165844988, -2.143448663328539, -0.13277694750878033, -8.344547734192847, -10.0, -28.898825109450378, -1.376230250544096, 0.0, 0.0, -2.110928738647642, -0.10765952869818407, -20.0, -1.4157243397573471, -18.489184741702456, -31.468187182424508, -0.092943889290803, -10.0, 0.0, -7.423143474763525, 0.0, -5.249060057899222, -35.783169055430236, -30.085218132963487]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6421256182854267, "mean_inference_ms": 1.090377107502325, "mean_action_processing_ms": 0.23421250229245025, "mean_env_wait_ms": 0.47637583794333394, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004329725548073098, "StateBufferConnector_ms": 0.0033597887298207224, "ViewRequirementAgentConnector_ms": 0.08974443247288834}, "num_episodes": 162, "episode_return_max": 140.0, "episode_return_min": -43.07380483947251, "episode_return_mean": 23.298327764704126}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1552000, "num_agent_steps_trained": 1552000, "num_env_steps_sampled": 388000, "num_env_steps_trained": 388000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 299.9911614876316, "num_env_steps_trained_throughput_per_sec": 299.9911614876316, "timesteps_total": 388000, "num_env_steps_sampled_lifetime": 388000, "num_agent_steps_sampled_lifetime": 1552000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1552000, "timers": {"training_iteration_time_ms": 13413.61, "restore_workers_time_ms": 0.014, "training_step_time_ms": 13413.573, "sample_time_ms": 1161.374, "learn_time_ms": 12240.0, "learn_throughput": 326.797, "synch_weights_time_ms": 11.817}, "counters": {"num_env_steps_sampled": 388000, "num_env_steps_trained": 388000, "num_agent_steps_sampled": 1552000, "num_agent_steps_trained": 1552000}, "done": false, "training_iteration": 97, "trial_id": "b72b3_00000", "date": "2024-08-08_15-54-24", "timestamp": 1723146864, "time_this_iter_s": 13.339935064315796, "time_total_s": 1383.3778743743896, "pid": 98177, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3280ea310>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1383.3778743743896, "iterations_since_restore": 97, "perf": {"cpu_util_percent": 27.578947368421048, "ram_util_percent": 82.09999999999998}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.787167887886365, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.718194094051918, "policy_loss": -0.02267155020235805, "vf_loss": 5.73945725162824, "vf_explained_var": 0.018145658758779368, "kl": 0.0070420243331355435, "entropy": 0.7616153982157509, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 93600.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5937866534852813, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.4828218675674276, "policy_loss": -0.02022698353298986, "vf_loss": 3.5024010046999505, "vf_explained_var": -8.737153195320292e-07, "kl": 0.00647842849422864, "entropy": 0.40736542442377577, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 274950.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 392000, "num_env_steps_trained": 392000, "num_agent_steps_sampled": 1568000, "num_agent_steps_trained": 1568000}, "env_runners": {"episode_reward_max": 160.0, "episode_reward_min": -35.29977719365241, "episode_reward_mean": 28.03278002183554, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -86.01483170383369}, "policy_reward_max": {"adversary_policy": 80.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 16.11111111111111, "agent_policy": -20.30055331149779}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-1.9879596564739122, 13.0429643237872, -13.737629221100642, -1.3289326957018843, 38.965545357425285, 56.94847407980939, -1.598430767847695, 0.0, 98.16294696174371, 40.0, 15.01875301196442, 40.0, 17.054351396764062, 59.987572116818825, 0.0, 20.0, -6.543425997211804, 59.12102171751406, 100.0, 0.0, 100.0, 160.0, 120.0, 58.70192099547972, 0.0, 0.0, 120.0, -6.177944207975297, -2.1568808572684137, 0.0, 80.0, 99.67183455273371, -11.42768131408224, 60.0, 120.0, 18.46710533769936, -11.190458941263019, 139.86633425541106, 20.0, -0.14327791776169052, 50.34396408032781, -7.652749721590734, 20.0, -8.073346304051892, 0.0, 55.53165582020089, -35.29977719365241, 0.0, 86.12280254843857, 40.0, -1.5290018798918081, -6.858201866603543, 58.65024386700986, 30.752006415025235, 79.85323716022722, 23.73748815843838, 0.0, 80.0, 60.0, 60.0, -5.316650864363731, -8.876849468868928, 0.0, 20.0, -4.379202050338364, -14.930326107839756, 57.662835179486464, 0.0, -1.4886407038379523, -5.805751084261996, 50.3745526129098, 6.698775018335084, 0.0, 40.0, 40.0, -9.692944415905437, 53.70194494141387, 0.0, 49.81054836324308, -6.212979748883113, 56.73015825207419, 94.16078326402814, 37.03389553287848, 75.64162778360102, 153.9851682961663, 120.0, -21.53620289261768, 59.05494148332659, -1.5970660127860712, 51.28272017810315, 55.94239984193926, 60.0, 0.0, 18.6308233230375, 80.0, -0.033628464116789436, 100.0, 99.13270983754182, -12.676908396985995, 0.0, -0.7203738816442151, 20.0, 44.41771538248172, 0.0, 20.0, 0.0, 0.0, 13.181306408027238, -0.09871796444388958, 19.959238250104768, -9.571935033989373, 0.0, 0.0, 29.38618986133782, 60.0, 0.0, -0.58591454389058, 0.0, -20.2546497928536, 40.0, 76.37523660780812, 0.0, 33.68638712599914, 0.0, 20.0, -3.0593086033868158, -1.3778032392775497, 0.0, 6.357906071940929, -1.6424179588553178, 39.00600811000383, 0.0, 52.233946199630935, -12.142140713293223, 0.0, 60.0, 23.954620802470778, 53.41971738040657, 39.518863799364375, 112.1158929729636, -25.605950766935912, 19.94296139576221, 0.0, -1.0172259780142079, 12.620385035271317, 38.01324063212362, 40.241263061684606, 20.0, -14.13300012778026, 0.0, 18.01801596711009, 40.0, 74.06793009637857, 120.0, 0.0, 0.0, -1.5037548363800424, -12.439416591944699, -11.456899660587691, -6.1169518444364135, 60.0, -15.071257397419055], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 80.0, 80.0, 80.0, 60.0, 60.0, 60.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 60.0, 60.0, 60.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 80.0, 80.0, 80.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-1.9879596564739122, -16.9570356762128, -13.737629221100642, -1.3289326957018843, -21.034454642574705, -33.05152592019061, -1.598430767847695, 0.0, -51.837053038256286, -20.0, -44.98124698803558, -20.0, -12.945648603235936, -30.012427883181175, 0.0, -10.0, -6.543425997211804, -30.87897828248594, -50.0, 0.0, -50.0, -80.0, -60.0, -31.298079004520275, 0.0, 0.0, -60.0, -6.177944207975297, -2.1568808572684137, 0.0, -40.0, -50.32816544726629, -11.42768131408224, -30.0, -60.0, -11.53289466230064, -11.190458941263019, -70.13366574458894, -10.0, -0.14327791776169052, -39.65603591967219, -7.652749721590734, -10.0, -8.073346304051892, 0.0, -34.4683441797991, -35.29977719365241, 0.0, -63.877197451561415, -20.0, -1.5290018798918081, -6.858201866603543, -31.34975613299014, -29.247993584974765, -40.146762839772784, -36.262511841561626, 0.0, -40.0, -30.0, -30.0, -5.316650864363731, -8.876849468868928, 0.0, -10.0, -4.379202050338364, -14.930326107839756, -32.337164820513536, 0.0, -1.4886407038379523, -5.805751084261996, -39.6254473870902, -23.301224981664916, 0.0, -20.0, -20.0, -9.692944415905437, -36.29805505858612, 0.0, -40.18945163675692, -6.212979748883113, -33.26984174792581, -55.839216735971846, -22.966104467121518, -44.35837221639896, -86.01483170383369, -60.0, -21.53620289261768, -30.945058516673406, -1.5970660127860712, -38.71727982189685, -34.05760015806073, -30.0, 0.0, -11.3691766769625, -40.0, -0.033628464116789436, -50.0, -50.86729016245818, -12.676908396985995, 0.0, -0.7203738816442151, -10.0, -45.58228461751828, 0.0, -10.0, 0.0, 0.0, -16.81869359197276, -0.09871796444388958, -10.04076174989523, -9.571935033989373, 0.0, 0.0, -30.61381013866218, -30.0, 0.0, -0.58591454389058, 0.0, -20.2546497928536, -20.0, -43.62476339219188, 0.0, -26.31361287400086, 0.0, -10.0, -3.0593086033868158, -1.3778032392775497, 0.0, -23.642093928059065, -1.6424179588553178, -20.993991889996167, 0.0, -37.766053800369065, -12.142140713293223, 0.0, -30.0, -36.04537919752922, -36.58028261959343, -20.481136200635632, -67.8841070270364, -25.605950766935912, -10.057038604237787, 0.0, -1.0172259780142079, -17.37961496472868, -21.98675936787638, -49.758736938315394, -10.0, -14.13300012778026, 0.0, -11.981984032889905, -20.0, -45.932069903621425, -60.0, 0.0, 0.0, -1.5037548363800424, -42.4394165919447, -11.456899660587691, -6.1169518444364135, -30.0, -15.071257397419055]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6415377957612355, "mean_inference_ms": 1.0896852962487438, "mean_action_processing_ms": 0.23399771946256404, "mean_env_wait_ms": 0.47619092084845427, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004286015475237811, "StateBufferConnector_ms": 0.0030468275517593194, "ViewRequirementAgentConnector_ms": 0.08580846551023884}, "num_episodes": 162, "episode_return_max": 160.0, "episode_return_min": -35.29977719365241, "episode_return_mean": 28.03278002183554}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1568000, "num_agent_steps_trained": 1568000, "num_env_steps_sampled": 392000, "num_env_steps_trained": 392000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 304.1963892859339, "num_env_steps_trained_throughput_per_sec": 304.1963892859339, "timesteps_total": 392000, "num_env_steps_sampled_lifetime": 392000, "num_agent_steps_sampled_lifetime": 1568000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1568000, "timers": {"training_iteration_time_ms": 13388.112, "restore_workers_time_ms": 0.014, "training_step_time_ms": 13388.076, "sample_time_ms": 1157.552, "learn_time_ms": 12218.452, "learn_throughput": 327.374, "synch_weights_time_ms": 11.749}, "counters": {"num_env_steps_sampled": 392000, "num_env_steps_trained": 392000, "num_agent_steps_sampled": 1568000, "num_agent_steps_trained": 1568000}, "done": false, "training_iteration": 98, "trial_id": "b72b3_00000", "date": "2024-08-08_15-54-38", "timestamp": 1723146878, "time_this_iter_s": 13.15747880935669, "time_total_s": 1396.5353531837463, "pid": 98177, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x328251430>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1396.5353531837463, "iterations_since_restore": 98, "perf": {"cpu_util_percent": 28.0, "ram_util_percent": 82.26315789473685}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.930775286257267, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.4418897206584615, "policy_loss": -0.025410274346601605, "vf_loss": 5.465444824844599, "vf_explained_var": 0.007809259494145711, "kl": 0.009276018921903936, "entropy": 0.7790107259526848, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 94560.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5648193984801042, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.0294956944090257, "policy_loss": -0.018877616401077314, "vf_loss": 3.047761524822695, "vf_explained_var": 2.748788671290621e-07, "kl": 0.0061178223433525115, "entropy": 0.3967619297352243, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 277770.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 396000, "num_env_steps_trained": 396000, "num_agent_steps_sampled": 1584000, "num_agent_steps_trained": 1584000}, "env_runners": {"episode_reward_max": 252.77988393470764, "episode_reward_min": -31.750142125967493, "episode_reward_mean": 22.119099458908718, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -137.22011606529236}, "policy_reward_max": {"adversary_policy": 130.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 13.271604938271604, "agent_policy": -17.6957153559061}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.0, 0.0, 32.02906886135609, 60.0, -0.1510119013864597, 100.0, 33.13913824240917, -11.912338698113444, 0.0, 92.48490049431476, 38.19230359222463, -12.789386129494197, 18.96146396902243, 0.0, 59.683672808295796, -16.218104973158873, 0.0, 40.0, -2.0829486652868114, 36.94377630590549, 18.81206089165482, -0.9288910778794968, 0.0, 20.0, -8.738039602050275, 144.74951185313034, -19.63766803857749, 60.0, -3.2464549450538724, 27.620779254139038, 19.171665572486507, 40.0, 40.0, 85.4091833585058, 0.0, 40.0, 0.0, 37.102257727646226, 60.0, -0.922941045669815, 0.0, -23.339239517585906, 59.3051671768752, 0.0, -17.16738988361125, 120.0, -3.7580263581092, 0.0, -3.3009857520524712, -7.826047799671134, 40.0, 100.0, 0.0, -1.4966773695363589, -31.750142125967493, 0.0, 0.0, -0.7417003717663884, -7.946093062752496, 60.0, -7.019901789446496, 60.0, -0.6914971198560627, 70.20351165739704, 0.0, 6.6133104871990085, 38.440820558697, -9.498959917963669, 252.77988393470764, 36.14793450060789, 20.0, 19.811522047327934, 0.0, 39.86753147105303, 10.600881880277033, 13.555944040743668, 79.34723056650266, 36.559847349337055, -0.06649633213415718, -0.10172236656642908, 19.152090255165042, 40.0, 15.374066002417473, -7.290515923076661, 40.0, 36.42475895904192, -11.900338766847776, -3.2060924553455648, 14.071544646939948, 0.0, 0.0, 48.38814420647543, -0.051790195651614246, 20.0, 69.9521515871974, 42.93020790287837, 60.0, 80.0, -0.2781870352981419, 40.0, -6.864913200155473, -4.131609387657337, 0.0, 13.794464230259763, -7.749695304312193, -7.434249794640811, -16.548527731403862, 60.0, 0.0, 38.896342368722095, 17.378881326269244, 38.37281599891511, 14.985830945198213, -1.7511927292499319, 80.0, 16.70848849832579, -0.5646736975167455, -3.6887108931593353, -8.12647462182665, -7.679128719269695, -13.35489948119353, 60.0, 40.0, -0.4432004716449045, -3.4933008560128913, 19.25807068446058, 0.0, 0.0, -2.349992292870118, 80.0, 19.908495990762766, 120.0, -6.590866633938938, 40.0, 0.0, 0.0, 60.0, -6.190124408057429, 0.0, -5.390879399126463, -10.30177763916339, 31.8605887895337, -0.4108480624012212, 122.56895878892823, 15.798814415185864, 15.134602807053687, 50.31714691853413, 40.0, 17.489632849487926, 40.0, 60.0, -10.577218485733868, 36.1442250871011, -0.6035764002673949, 0.0, 0.0, 0.0, 39.74718032156433, -12.99467169925407, 0.0, 0.0, 12.403361289744137], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 80.0, 80.0, 80.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 130.0, 130.0, 130.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0], "policy_agent_policy_reward": [-20.0, 0.0, -27.970931138643923, -30.0, -0.1510119013864597, -50.0, -26.86086175759082, -11.912338698113444, 0.0, -57.51509950568525, -21.807696407775364, -12.789386129494197, -11.03853603097757, 0.0, -30.3163271917042, -16.218104973158873, 0.0, -20.0, -2.0829486652868114, -53.05622369409451, -11.187939108345184, -0.9288910778794968, 0.0, -10.0, -8.738039602050275, -95.25048814686966, -19.63766803857749, -30.0, -3.2464549450538724, -32.37922074586096, -10.828334427513493, -20.0, -20.0, -64.5908166414942, 0.0, -20.0, 0.0, -22.89774227235377, -30.0, -0.922941045669815, 0.0, -23.339239517585906, -30.694832823124802, 0.0, -17.16738988361125, -60.0, -3.7580263581092, 0.0, -3.3009857520524712, -7.826047799671134, -20.0, -50.0, 0.0, -1.4966773695363589, -31.750142125967493, 0.0, 0.0, -0.7417003717663884, -7.946093062752496, -30.0, -7.019901789446496, -30.0, -0.6914971198560627, -49.79648834260296, 0.0, -23.38668951280099, -21.559179441303, -9.498959917963669, -137.22011606529236, -23.852065499392115, -10.0, -10.188477952672065, 0.0, -20.132468528946973, -19.399118119722967, -46.44405595925634, -40.65276943349735, -53.44015265066294, -0.06649633213415718, -0.10172236656642908, -10.847909744834958, -20.0, -14.625933997582523, -7.290515923076661, -20.0, -23.575241040958083, -11.900338766847776, -3.2060924553455648, -15.928455353060055, 0.0, 0.0, -41.61185579352456, -0.051790195651614246, -10.0, -50.04784841280257, -47.06979209712163, -30.0, -40.0, -0.2781870352981419, -20.0, -6.864913200155473, -4.131609387657337, 0.0, -16.205535769740237, -7.749695304312193, -7.434249794640811, -16.548527731403862, -30.0, 0.0, -21.103657631277905, -12.621118673730756, -21.627184001084892, -15.01416905480179, -1.7511927292499319, -40.0, -13.291511501674211, -0.5646736975167455, -3.6887108931593353, -8.12647462182665, -37.679128719269684, -13.35489948119353, -30.0, -20.0, -0.4432004716449045, -3.4933008560128913, -10.741929315539421, 0.0, 0.0, -2.349992292870118, -40.0, -40.09150400923724, -60.0, -6.590866633938938, -20.0, 0.0, 0.0, -30.0, -6.190124408057429, 0.0, -5.390879399126463, -10.30177763916339, -28.139411210466307, -0.4108480624012212, -87.43104121107177, -14.20118558481413, -14.865397192946315, -39.682853081465865, -20.0, -12.510367150512074, -20.0, -30.0, -10.577218485733868, -23.8557749128989, -0.6035764002673949, 0.0, 0.0, 0.0, -20.25281967843567, -12.99467169925407, 0.0, 0.0, -17.596638710255863]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6414776977065992, "mean_inference_ms": 1.089619324559031, "mean_action_processing_ms": 0.23390494190191688, "mean_env_wait_ms": 0.4762327921983698, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004293594831301842, "StateBufferConnector_ms": 0.003406736585828993, "ViewRequirementAgentConnector_ms": 0.09080465929007825}, "num_episodes": 162, "episode_return_max": 252.77988393470764, "episode_return_min": -31.750142125967493, "episode_return_mean": 22.119099458908718}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1584000, "num_agent_steps_trained": 1584000, "num_env_steps_sampled": 396000, "num_env_steps_trained": 396000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 293.77112377521064, "num_env_steps_trained_throughput_per_sec": 293.77112377521064, "timesteps_total": 396000, "num_env_steps_sampled_lifetime": 396000, "num_agent_steps_sampled_lifetime": 1584000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1584000, "timers": {"training_iteration_time_ms": 13415.768, "restore_workers_time_ms": 0.014, "training_step_time_ms": 13415.733, "sample_time_ms": 1160.972, "learn_time_ms": 12242.495, "learn_throughput": 326.731, "synch_weights_time_ms": 11.976}, "counters": {"num_env_steps_sampled": 396000, "num_env_steps_trained": 396000, "num_agent_steps_sampled": 1584000, "num_agent_steps_trained": 1584000}, "done": false, "training_iteration": 99, "trial_id": "b72b3_00000", "date": "2024-08-08_15-54-51", "timestamp": 1723146891, "time_this_iter_s": 13.623478174209595, "time_total_s": 1410.158831357956, "pid": 98177, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x328251040>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1410.158831357956, "iterations_since_restore": 99, "perf": {"cpu_util_percent": 28.668421052631583, "ram_util_percent": 81.94210526315788}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.335619414846103, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.784899159272512, "policy_loss": -0.030418717087377443, "vf_loss": 5.813142135242621, "vf_explained_var": 0.03333773526052634, "kl": 0.010878779102568596, "entropy": 0.7828088295956452, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 95520.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}, "adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5982089839294447, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.173170185385021, "policy_loss": -0.02004536814221465, "vf_loss": 3.1925513444217386, "vf_explained_var": 2.698061314034969e-07, "kl": 0.006642051585318092, "entropy": 0.41066262873140635, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 280590.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}}, "num_env_steps_sampled": 400000, "num_env_steps_trained": 400000, "num_agent_steps_sampled": 1600000, "num_agent_steps_trained": 1600000}, "env_runners": {"episode_reward_max": 220.0, "episode_reward_min": -45.71268667074656, "episode_reward_mean": 22.644395396505594, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -110.0}, "policy_reward_max": {"adversary_policy": 110.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 13.82716049382716, "agent_policy": -18.837086084975887}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-6.461632142337607, 60.0, -0.5146270794508268, 60.0, 20.0, -15.259968823782446, -9.988059206946986, 0.0, 60.0, 40.0, 0.0, 27.34167791605661, 40.0, 0.0, -2.362075487774811, 32.78201610125762, 58.174675711405875, 0.0, 16.673076707248793, 20.0, 59.798967074541196, 80.0, 20.0, 220.0, -3.234349316144932, -4.047665184310262, 60.0, 60.0, -4.084569058854147, -17.720747533221875, -5.208042283518126, 119.73265499237499, 59.22069517333051, -9.684496401558055, 60.0, 0.0, 79.51046097591154, 180.0, 93.12743622287157, -6.057147511709579, 55.899017766725066, -7.7085195011057435, 0.0, -1.5102422108284963, 3.1477209792524965, 0.0, -9.426906480059086, -14.216451650126817, 40.0, 17.938751194451953, 20.0, 40.0, 20.0, -2.8533224266295902, 39.95015081609562, -5.151407588493501, -2.4056114312283583, -45.71268667074656, -20.29790849869064, -4.201110896989365, 40.0, 0.0, 48.222665365302504, 47.25292973513982, -3.1323180216160162, 80.0, -30.784601912207716, 0.0, -3.8724789499730035, 37.23688380002038, -0.6574779465581526, -1.2317938601839515, -0.14786243108795616, 0.0, 160.0, 72.50512983322267, 60.0, -0.7794929459427691, -15.027023765063683, 0.0, -7.458642953775184, -10.75522766611359, 20.0, 43.601005791434915, 60.0, -0.3185450051223393, 0.0, 27.186999672144818, 40.0, -23.65393869767632, 48.280775865724195, 18.439745959320096, 140.0, -0.40922833576073625, 0.0, 11.979099005873286, 20.0, 21.658066484221415, -6.469632091517353, 20.0, -1.3870825940294351, -8.80712956807329, 19.59090908295225, 38.0604982151734, 36.93784307573672, 49.618917649934716, 60.0, -0.330075811667484, -7.05714882977334, 59.94222081180402, -4.811969356134345, -7.510512209117904, -1.3875110759557974, 15.751446223576377, 39.94340579807519, 29.937659124188578, -2.399518882779187, 0.0, -6.098624284829579, 39.60908030798197, 19.326084123199635, -3.3971778742759637, -12.841949173416387, 20.0, -5.691954645699641, -5.148652783995672, 65.42990031887965, 37.17417198804999, 27.00026891450614, 40.0, 60.0, 0.0, 40.0, 4.434845287349162, 0.37287139697967, 36.57663645622414, 57.38196038982459, 55.6138334348061, 0.0, 57.19759505796509, 60.0, -2.133239660606944, -7.21664974921346, 39.89802101072566, -12.4978137925414, 0.0, -3.3744274933069187, 0.0, 0.0, 32.74358825777248, -6.965353655503282, 39.97794308953472, 1.2437331061208055, 40.0, 80.0, 60.0, -0.651519026202837, 20.0, -5.318398224814199, -15.825932588907511, 38.25122200264997, -9.624750786081364], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 110.0, 110.0, 110.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 90.0, 90.0, 90.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 80.0, 80.0, 80.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-6.461632142337607, -30.0, -30.514627079450833, -30.0, -10.0, -15.259968823782446, -9.988059206946986, 0.0, -30.0, -20.0, 0.0, -32.658322083943396, -20.0, 0.0, -2.362075487774811, -27.217983898742386, -31.825324288594125, 0.0, -13.326923292751207, -10.0, -30.201032925458804, -40.0, -10.0, -110.0, -3.234349316144932, -4.047665184310262, -30.0, -30.0, -4.084569058854147, -17.720747533221875, -5.208042283518126, -60.26734500762502, -30.77930482666949, -9.684496401558055, -30.0, 0.0, -40.489539024088465, -90.0, -56.872563777128434, -6.057147511709579, -34.10098223327493, -7.7085195011057435, 0.0, -1.5102422108284963, -26.852279020747503, 0.0, -9.426906480059086, -14.216451650126817, -20.0, -12.061248805548047, -10.0, -20.0, -10.0, -2.8533224266295902, -20.049849183904374, -5.151407588493501, -2.4056114312283583, -45.71268667074656, -20.29790849869064, -4.201110896989365, -20.0, 0.0, -41.777334634697496, -42.74707026486018, -3.1323180216160162, -40.0, -30.784601912207716, 0.0, -3.8724789499730035, -22.763116199979617, -0.6574779465581526, -1.2317938601839515, -0.14786243108795616, 0.0, -80.0, -47.49487016677734, -30.0, -0.7794929459427691, -15.027023765063683, 0.0, -7.458642953775184, -10.75522766611359, -10.0, -46.398994208565085, -30.0, -0.3185450051223393, 0.0, -32.81300032785518, -20.0, -23.65393869767632, -41.719224134275805, -41.56025404067991, -70.0, -0.40922833576073625, 0.0, -48.02090099412672, -10.0, -68.34193351577858, -6.469632091517353, -10.0, -1.3870825940294351, -8.80712956807329, -10.409090917047749, -21.939501784826597, -23.062156924263288, -40.381082350065284, -30.0, -0.330075811667484, -7.05714882977334, -30.057779188195976, -4.811969356134345, -7.510512209117904, -1.3875110759557974, -14.248553776423622, -20.05659420192481, -30.062340875811422, -2.399518882779187, 0.0, -6.098624284829579, -20.390919692018027, -10.673915876800365, -3.3971778742759637, -12.841949173416387, -10.0, -5.691954645699641, -5.148652783995672, -54.570099681120375, -22.825828011950016, -32.99973108549385, -20.0, -30.0, 0.0, -20.0, -25.565154712650838, -29.627128603020328, -23.423363543775856, -32.618039610175416, -34.3861665651939, 0.0, -32.80240494203492, -30.0, -2.133239660606944, -7.21664974921346, -20.101978989274343, -12.4978137925414, 0.0, -3.3744274933069187, 0.0, 0.0, -27.25641174222752, -6.965353655503282, -20.02205691046528, -28.756266893879193, -20.0, -40.0, -30.0, -0.651519026202837, -10.0, -5.318398224814199, -15.825932588907511, -21.74877799735003, -9.624750786081364]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6410499509559554, "mean_inference_ms": 1.0891765950917218, "mean_action_processing_ms": 0.23373269903631377, "mean_env_wait_ms": 0.47615546707381745, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004523403850602515, "StateBufferConnector_ms": 0.0032648628140673226, "ViewRequirementAgentConnector_ms": 0.08672380153043771}, "num_episodes": 162, "episode_return_max": 220.0, "episode_return_min": -45.71268667074656, "episode_return_mean": 22.644395396505594}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1600000, "num_agent_steps_trained": 1600000, "num_env_steps_sampled": 400000, "num_env_steps_trained": 400000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 310.32614956443916, "num_env_steps_trained_throughput_per_sec": 310.32614956443916, "timesteps_total": 400000, "num_env_steps_sampled_lifetime": 400000, "num_agent_steps_sampled_lifetime": 1600000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1600000, "timers": {"training_iteration_time_ms": 13404.361, "restore_workers_time_ms": 0.015, "training_step_time_ms": 13404.324, "sample_time_ms": 1159.473, "learn_time_ms": 12232.303, "learn_throughput": 327.003, "synch_weights_time_ms": 12.195}, "counters": {"num_env_steps_sampled": 400000, "num_env_steps_trained": 400000, "num_agent_steps_sampled": 1600000, "num_agent_steps_trained": 1600000}, "done": true, "training_iteration": 100, "trial_id": "b72b3_00000", "date": "2024-08-08_15-55-04", "timestamp": 1723146904, "time_this_iter_s": 12.896683931350708, "time_total_s": 1423.0555152893066, "pid": 98177, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x328251790>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1423.0555152893066, "iterations_since_restore": 100, "perf": {"cpu_util_percent": 27.705263157894734, "ram_util_percent": 81.97368421052632}}
