{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5507659613399218, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.916483101396696, "policy_loss": -0.007624530105303365, "vf_loss": 0.9223188998164438, "vf_explained_var": 4.253305019216335e-05, "kl": 0.008943611227069236, "entropy": 1.6005600678159835, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 1410.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9740323447311918, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.159705979873737, "policy_loss": -0.016945951061158364, "vf_loss": 5.174273252735535, "vf_explained_var": -0.0033271266768376035, "kl": 0.011893423195187504, "entropy": 1.597853637735049, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 480.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 4000, "num_env_steps_trained": 4000, "num_agent_steps_sampled": 16000, "num_agent_steps_trained": 16000}, "env_runners": {"episode_reward_max": 139.1202806659997, "episode_reward_min": -70.47785834540169, "episode_reward_mean": -1.8492842371357914, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 153, "episodes_timesteps_total": 3825, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -129.78726137853315}, "policy_reward_max": {"adversary_policy": 70.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 4.57516339869281, "agent_policy": -15.574774433214223}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-7.425186726502882, 40.0, 0.0, 0.0, -4.786100783814376, -28.658133997181917, -12.010799773240018, -17.16918659197681, -23.429283859868928, 0.0, -8.968087034358033, -5.7781578276542955, 0.0, 60.0, 0.0, -2.315516385736995, 60.0, -0.5305856186649005, -70.47785834540169, 0.0, 19.831698215627565, -8.387318719947475, 0.0, -20.877414732318115, 0.0, -0.8201364558187141, -1.4599997903265638, -36.88895091049565, -8.253278930585187, -18.218905960672767, -23.03497705999854, -7.431215407154514, -6.580844213591138, -30.842459462508433, -3.319034706299536, 0.0, -34.27215352244692, 0.0, 0.0, -7.11110810785899, 40.0, 20.0, -7.841470125191842, 0.0, 20.0, -4.31442492369125, -25.433847714878198, -16.681633566823773, -5.890915265890815, 40.0, -0.09842424244993153, -23.312618165531227, 59.848139157779556, -6.56925912959939, 60.0, 60.0, 0.0, 0.0, -39.69369479818675, 60.0, -20.48941437070649, 40.0, 0.0, 0.0, 0.0, 0.0, -31.525963798782545, 0.0, -7.558152366012402, 0.0, 0.0, -39.3048325962511, -30.874096993979276, 40.0, 0.0, 0.0, 22.20869873513116, 0.0, -0.1467120625381546, -1.6378929818557808, -39.37030222437241, -1.253541326723212, 0.0, -35.0078583251452, 0.0, -24.343673858642052, -0.06488906169729636, 0.0, -69.78726137853316, 0.0, -4.532134946420276, -49.818128889402246, -17.18151898775092, -1.7806714983966598, -12.516456603638751, -2.875592635562268, 0.0, -0.05576870768339348, 0.0, -66.4503041144559, -9.206425478082744, -12.300690811551805, -28.635597466848502, -40.155716076179004, -11.236644574730443, 20.0, 0.0, -35.73615914994425, -21.218119277107597, -2.600422566923849, -4.703056543803635, 40.0, 0.0, -5.680303945719992, -10.420283103796185, 0.0, -8.77571751742322, 40.0, -20.312058986912618, -21.350879105927064, -39.41063361490261, 77.09456486526307, -9.97553825521773, -9.310036441215154, 0.0, -9.091853718546169, 139.1202806659997, -8.561378599022202, -31.063024671986852, 0.0, 11.229187648233172, 60.0, -46.52937104207837, 60.0, -11.150755857219034, 0.0, 0.0, -3.952919210743884, -34.14849002273, 60.0, -25.392642783864034, 60.0, 0.0, -12.574404647122282, -5.326543208361143, -29.14963751627256, -0.08597162470908137, -0.5116843007647376, 0.0, 0.0, 0.0, 0.0, -8.247946864887505], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-7.425186726502882, -20.0, 0.0, 0.0, -4.786100783814376, -28.658133997181917, -12.010799773240018, -17.16918659197681, -23.429283859868928, 0.0, -8.968087034358033, -5.7781578276542955, 0.0, -30.0, 0.0, -32.315516385737, -30.0, -0.5305856186649005, -70.47785834540169, 0.0, -10.168301784372437, -8.387318719947475, 0.0, -50.87741473231812, 0.0, -0.8201364558187141, -1.4599997903265638, -36.88895091049565, -8.253278930585187, -18.218905960672767, -23.03497705999854, -7.431215407154514, -6.580844213591138, -30.842459462508433, -3.319034706299536, 0.0, -34.27215352244692, 0.0, 0.0, -7.11110810785899, -20.0, -10.0, -7.841470125191842, 0.0, -10.0, -4.31442492369125, -25.433847714878198, -16.681633566823773, -5.890915265890815, -20.0, -0.09842424244993153, -23.312618165531227, -30.151860842220447, -6.56925912959939, -30.0, -30.0, 0.0, 0.0, -39.69369479818675, -30.0, -20.48941437070649, -20.0, 0.0, 0.0, 0.0, 0.0, -31.525963798782545, 0.0, -7.558152366012402, 0.0, 0.0, -39.3048325962511, -30.874096993979276, -20.0, 0.0, 0.0, -37.79130126486884, 0.0, -0.1467120625381546, -1.6378929818557808, -39.37030222437241, -1.253541326723212, 0.0, -35.0078583251452, 0.0, -24.343673858642052, -0.06488906169729636, 0.0, -129.78726137853315, 0.0, -4.532134946420276, -49.818128889402246, -17.18151898775092, -1.7806714983966598, -102.51645660363872, -2.875592635562268, 0.0, -0.05576870768339348, 0.0, -66.4503041144559, -9.206425478082744, -12.300690811551805, -28.635597466848502, -40.155716076179004, -11.236644574730443, -10.0, 0.0, -35.73615914994425, -21.218119277107597, -2.600422566923849, -4.703056543803635, -20.0, 0.0, -5.680303945719992, -10.420283103796185, 0.0, -8.77571751742322, -20.0, -20.312058986912618, -21.350879105927064, -39.41063361490261, -42.90543513473694, -9.97553825521773, -9.310036441215154, 0.0, -9.091853718546169, -70.87971933400028, -8.561378599022202, -31.063024671986852, 0.0, -48.770812351766835, -30.0, -46.52937104207837, -30.0, -11.150755857219034, 0.0, 0.0, -3.952919210743884, -34.14849002273, -30.0, -25.392642783864034, -30.0, 0.0, -12.574404647122282, -5.326543208361143, -29.14963751627256, -0.08597162470908137, -0.5116843007647376, 0.0, 0.0, 0.0, 0.0, -8.247946864887505]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6614011602155657, "mean_inference_ms": 1.175580014681854, "mean_action_processing_ms": 0.235120803128597, "mean_env_wait_ms": 0.49738435453247476, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005243027132321027, "StateBufferConnector_ms": 0.0032484141829746222, "ViewRequirementAgentConnector_ms": 0.09475494521895265}, "num_episodes": 153, "episode_return_max": 139.1202806659997, "episode_return_min": -70.47785834540169, "episode_return_mean": -1.8492842371357914}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 16000, "num_agent_steps_trained": 16000, "num_env_steps_sampled": 4000, "num_env_steps_trained": 4000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 311.87646423157435, "num_env_steps_trained_throughput_per_sec": 311.87646423157435, "timesteps_total": 4000, "num_env_steps_sampled_lifetime": 4000, "num_agent_steps_sampled_lifetime": 16000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 16000, "timers": {"training_iteration_time_ms": 12825.599, "restore_workers_time_ms": 0.016, "training_step_time_ms": 12825.551, "sample_time_ms": 1237.976, "learn_time_ms": 11572.877, "learn_throughput": 345.636, "synch_weights_time_ms": 12.458}, "counters": {"num_env_steps_sampled": 4000, "num_env_steps_trained": 4000, "num_agent_steps_sampled": 16000, "num_agent_steps_trained": 16000}, "done": false, "training_iteration": 1, "trial_id": "86f16_00000", "date": "2024-08-08_16-12-47", "timestamp": 1723147967, "time_this_iter_s": 12.862355947494507, "time_total_s": 12.862355947494507, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3acf00700>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 12.862355947494507, "iterations_since_restore": 1, "perf": {"cpu_util_percent": 40.23157894736842, "ram_util_percent": 83.29473684210525}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5706280493620017, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.8670743917108428, "policy_loss": -0.009749195328583373, "vf_loss": 0.8750650410480956, "vf_explained_var": 3.595998946656572e-05, "kl": 0.00879265147480586, "entropy": 1.5820937563764288, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 4230.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.0706236029664675, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.652339504783352, "policy_loss": -0.014854204952522801, "vf_loss": 3.6647538005063933, "vf_explained_var": -7.20423956712087e-05, "kl": 0.012199536268653924, "entropy": 1.5741360573718945, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 1440.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 8000, "num_env_steps_trained": 8000, "num_agent_steps_sampled": 32000, "num_agent_steps_trained": 32000}, "env_runners": {"episode_reward_max": 160.0, "episode_reward_min": -50.042004489726175, "episode_reward_mean": 2.55872472986751, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -80.0}, "policy_reward_max": {"adversary_policy": 80.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 4.444444444444445, "agent_policy": -10.774608603465822}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-23.646341827785502, -20.617932804612668, -3.249156975283166, -2.4869935950884248, -28.968269283976486, -2.5345733672897963, -0.5114530280712537, 0.0, 0.0, 0.0, -4.006120457203691, 0.0, 0.0, -50.042004489726175, -9.914744252642338, -29.58884189219983, 0.0, 0.0, -8.31196552170762, 0.0, 60.0, -13.78596005664307, -0.220382240075796, 0.0, -4.516482413283961, -5.58692603076675, -15.709306199759467, 0.0, 20.0, 40.0, 0.0, -9.608241193318838, -6.365806030002558, 19.841135796909356, 60.0, 0.0, -16.856237469922394, -2.2390504769253745, 0.0, -11.04223258452638, 0.0, 0.0, 0.0, -7.149106178043857, 40.0, -14.932851105831755, 0.0, 0.0, 4.76773023807351, -16.35629652380579, -4.700744914859361, -6.617357276180728, 0.0, 0.0, -22.537728773771327, 0.0, 0.0, 0.0, 60.0, -0.11748128069219765, 0.0, 59.155555218374886, 0.0, -6.146372324102788, 68.38911559584373, 0.0, -21.127406154837395, 0.0, -36.93056083584372, 60.0, 0.0, -15.278171261884813, 0.0, 0.0, 0.0, 0.0, -2.8780338742962046, 40.0, 43.94636575841534, 0.0, -11.87357603125071, -9.396707773895308, -25.718019423318243, 0.0, 0.0, 40.0, -35.185454764761765, 0.0, 0.0, 0.0, -26.047665517302654, 0.0, 0.0, -2.0815233004163582, 0.0, 0.0, -28.394444793812774, -30.23912487958146, 0.0, 0.0, 0.0, 0.0, 138.5280741379828, -0.4499896444788587, 160.0, -21.906970192162316, 0.0, -1.2377859219857024, 0.0, -1.899024742735721, 0.0, -4.737539496307836, -26.03078801148622, -20.955823541780596, 0.0, 80.0, 0.0, -22.005104115030626, -11.244117019249591, 13.528501820615979, -3.4943719017438455, -18.657143626691592, -31.60481684539852, 0.0, -8.426860761550762, 59.875659996481716, -26.61488732844497, -18.51971251213262, 0.0, -14.413703980559564, -0.3116182653394628, 0.0, -15.069737198549257, 0.0, 0.0, 0.0, -5.414985483182874, 0.0, 0.0, 32.22766756341853, -24.37646935208057, 0.0, 0.0, 0.0, 100.0, 59.760308998523826, 0.0, -30.382741080009826, -3.98618516047702, 0.0, 0.0, -14.313610156688473, -1.2473619895016874, -6.0580586407869, 0.0, 20.0, 0.0, 40.0, 40.0, -18.629652738446925, 0.0, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 80.0, 80.0, 80.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-23.646341827785502, -20.617932804612668, -3.249156975283166, -2.4869935950884248, -28.968269283976486, -2.5345733672897963, -0.5114530280712537, 0.0, 0.0, 0.0, -4.006120457203691, 0.0, 0.0, -50.042004489726175, -9.914744252642338, -29.58884189219983, 0.0, 0.0, -8.31196552170762, 0.0, -30.0, -13.78596005664307, -0.220382240075796, 0.0, -4.516482413283961, -5.58692603076675, -15.709306199759467, 0.0, -10.0, -20.0, 0.0, -9.608241193318838, -6.365806030002558, -10.158864203090646, -30.0, 0.0, -16.856237469922394, -2.2390504769253745, 0.0, -11.04223258452638, 0.0, 0.0, 0.0, -7.149106178043857, -20.0, -14.932851105831755, 0.0, 0.0, -25.232269761926496, -16.35629652380579, -4.700744914859361, -6.617357276180728, 0.0, 0.0, -22.537728773771327, 0.0, 0.0, 0.0, -30.0, -0.11748128069219765, 0.0, -30.844444781625114, 0.0, -6.146372324102788, -51.61088440415626, 0.0, -21.127406154837395, 0.0, -36.93056083584372, -30.0, 0.0, -15.278171261884813, 0.0, 0.0, 0.0, 0.0, -2.8780338742962046, -20.0, -46.05363424158466, 0.0, -11.87357603125071, -9.396707773895308, -25.718019423318243, 0.0, 0.0, -20.0, -35.185454764761765, 0.0, 0.0, 0.0, -26.047665517302654, 0.0, 0.0, -2.0815233004163582, 0.0, 0.0, -28.394444793812774, -30.23912487958146, 0.0, 0.0, 0.0, 0.0, -71.47192586201722, -0.4499896444788587, -80.0, -21.906970192162316, 0.0, -1.2377859219857024, 0.0, -1.899024742735721, 0.0, -4.737539496307836, -26.03078801148622, -20.955823541780596, 0.0, -40.0, 0.0, -22.005104115030626, -11.244117019249591, -46.47149817938403, -3.4943719017438455, -18.657143626691592, -31.60481684539852, 0.0, -8.426860761550762, -30.124340003518288, -26.61488732844497, -18.51971251213262, 0.0, -14.413703980559564, -0.3116182653394628, 0.0, -15.069737198549257, 0.0, 0.0, 0.0, -5.414985483182874, 0.0, 0.0, -27.772332436581465, -24.37646935208057, 0.0, 0.0, 0.0, -50.0, -30.23969100147617, 0.0, -30.382741080009826, -3.98618516047702, 0.0, 0.0, -14.313610156688473, -1.2473619895016874, -6.0580586407869, 0.0, -10.0, 0.0, -20.0, -20.0, -18.629652738446925, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6780266470365556, "mean_inference_ms": 1.2027196457860752, "mean_action_processing_ms": 0.23612782890345518, "mean_env_wait_ms": 0.5058626440617341, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005804388611404984, "StateBufferConnector_ms": 0.004152456919352214, "ViewRequirementAgentConnector_ms": 0.10698091836623204}, "num_episodes": 162, "episode_return_max": 160.0, "episode_return_min": -50.042004489726175, "episode_return_mean": 2.55872472986751}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 32000, "num_agent_steps_trained": 32000, "num_env_steps_sampled": 8000, "num_env_steps_trained": 8000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 319.70014696070393, "num_env_steps_trained_throughput_per_sec": 319.70014696070393, "timesteps_total": 8000, "num_env_steps_sampled_lifetime": 8000, "num_agent_steps_sampled_lifetime": 32000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 32000, "timers": {"training_iteration_time_ms": 12668.665, "restore_workers_time_ms": 0.014, "training_step_time_ms": 12668.622, "sample_time_ms": 1246.281, "learn_time_ms": 11409.267, "learn_throughput": 350.592, "synch_weights_time_ms": 11.798}, "counters": {"num_env_steps_sampled": 8000, "num_env_steps_trained": 8000, "num_agent_steps_sampled": 32000, "num_agent_steps_trained": 32000}, "done": false, "training_iteration": 2, "trial_id": "86f16_00000", "date": "2024-08-08_16-12-59", "timestamp": 1723147979, "time_this_iter_s": 12.55395793914795, "time_total_s": 25.416313886642456, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3acae0d30>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 25.416313886642456, "iterations_since_restore": 2, "perf": {"cpu_util_percent": 42.42777777777778, "ram_util_percent": 83.20555555555556}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5851157502660937, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.2614374686428842, "policy_loss": -0.010287514359835562, "vf_loss": 1.2696053820510282, "vf_explained_var": 2.7067124420869434e-05, "kl": 0.010597691282862585, "entropy": 1.567769906875935, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 7050.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9671030497178436, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.3149312981714805, "policy_loss": -0.022833641597632473, "vf_loss": 3.334896420314908, "vf_explained_var": 0.0022210435941815375, "kl": 0.014342595250847905, "entropy": 1.5396691614141067, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 2400.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 12000, "num_env_steps_trained": 12000, "num_agent_steps_sampled": 48000, "num_agent_steps_trained": 48000}, "env_runners": {"episode_reward_max": 140.0, "episode_reward_min": -55.767842013183916, "episode_reward_mean": 8.717263164146647, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -70.0}, "policy_reward_max": {"adversary_policy": 70.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 7.037037037037037, "agent_policy": -12.393847946964463}, "custom_metrics": {}, "hist_stats": {"episode_reward": [60.0, -10.126111186269682, 20.0, -8.11171852298676, -12.2456731197624, -30.581991305882816, -2.4403396781433937, 80.0, -1.6301478749724152, 0.0, 0.0, 0.0, 40.0, -9.197326730930628, 0.0, 40.0, -3.448592594719914, 0.0, -11.589134794684625, 5.065527802498865, -0.04885394597445636, 50.774897735885084, 0.0, 0.0, -38.53061739611833, 0.0, -0.02998022548668544, 0.0, 0.0, 60.0, 0.0, 0.0, 140.0, -32.49872033599949, 40.0, -11.918048311089013, -0.43212070751381004, 40.0, 0.0, 0.0, 0.0, 60.0, -8.432304393949742, 0.0, 0.0, 37.16214307921207, -3.3044536548150933, 40.0, 0.0, -4.8194911735130805, -17.833568750476754, 0.0, 0.0, 0.0, -43.48664237647815, -0.008926569917473426, 40.0, 39.575875878996676, 33.81474409877296, 0.0, 0.0, 52.119752670854936, 60.0, 60.0, 0.0, -24.466071035466054, -32.39601356956809, -35.75266914480135, 40.0, 0.0, 0.0, -4.354121904129403, -12.613830440882664, 0.0, 20.0, 20.0, -4.584526865607332, 0.0, 0.0, 0.0, 20.0, -5.085475783074433, 0.0, -7.862327694606641, 0.0, 39.63616995501082, -2.1965297010208458, 0.0, 40.0, -1.8266057657410428, 0.0, 60.0, -0.24074848881156186, -2.4375760071627495, 28.614992269323775, 0.0, -1.0715339162202275, 0.0, -48.5683871013739, 40.0, 60.0, 0.0, 0.0, -17.74292527022933, 28.59171437289013, -0.32080277544758173, 13.273667606124913, 33.097637551419005, 31.48699350694078, 0.0, 0.0, 60.90852046562581, 40.0, 0.0, -9.808872058998011, 17.104352869891784, 0.0, 0.0, 0.0, 19.41736330410142, -0.04693179390129365, 33.27671815956841, -5.715193231945257, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -9.343273476310083, 0.0, 0.0, -7.163456726815363, -0.26411508777440695, 0.0, -26.94977222960481, 40.0, 0.0, 0.0, 0.0, -14.83093718462004, 0.0, 0.0, -1.4386642119583426, -27.607024505579798, 0.0, 0.0, 0.0, 80.0, 0.0, 140.0, 0.0, -55.767842013183916, 40.0, 0.0, 20.0, 40.0, -14.933237335161369, 40.0, -1.260328301575765, 0.0, -4.359881464104063], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-30.0, -10.126111186269682, -10.0, -38.11171852298675, -12.2456731197624, -30.581991305882816, -2.4403396781433937, -40.0, -1.6301478749724152, 0.0, 0.0, 0.0, -20.0, -9.197326730930628, 0.0, -20.0, -3.448592594719914, 0.0, -11.589134794684625, -54.934472197501144, -0.04885394597445636, -39.22510226411492, 0.0, 0.0, -38.53061739611833, 0.0, -0.02998022548668544, 0.0, 0.0, -30.0, 0.0, 0.0, -70.0, -32.49872033599949, -20.0, -11.918048311089013, -0.43212070751381004, -20.0, 0.0, 0.0, 0.0, -30.0, -8.432304393949742, 0.0, 0.0, -22.837856920787928, -3.3044536548150933, -20.0, 0.0, -4.8194911735130805, -17.833568750476754, 0.0, 0.0, 0.0, -43.48664237647815, -0.008926569917473426, -20.0, -20.424124121003327, -56.18525590122703, 0.0, 0.0, -37.88024732914506, -30.0, -30.0, 0.0, -24.466071035466054, -32.39601356956809, -35.75266914480135, -20.0, 0.0, 0.0, -4.354121904129403, -12.613830440882664, 0.0, -10.0, -10.0, -4.584526865607332, 0.0, 0.0, 0.0, -10.0, -5.085475783074433, 0.0, -7.862327694606641, 0.0, -20.36383004498918, -2.1965297010208458, 0.0, -20.0, -1.8266057657410428, 0.0, -30.0, -0.24074848881156186, -2.4375760071627495, -31.385007730676232, 0.0, -1.0715339162202275, 0.0, -48.5683871013739, -20.0, -30.0, 0.0, 0.0, -17.74292527022933, -61.40828562710987, -0.32080277544758173, -16.72633239387509, -26.902362448581002, -28.51300649305922, 0.0, 0.0, -59.0914795343742, -20.0, 0.0, -9.808872058998011, -42.895647130108216, 0.0, 0.0, 0.0, -10.582636695898582, -0.04693179390129365, -56.72328184043159, -5.715193231945257, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -9.343273476310083, 0.0, 0.0, -7.163456726815363, -0.26411508777440695, 0.0, -26.94977222960481, -20.0, 0.0, 0.0, 0.0, -14.83093718462004, 0.0, 0.0, -1.4386642119583426, -27.607024505579798, 0.0, 0.0, 0.0, -40.0, 0.0, -70.0, 0.0, -55.767842013183916, -20.0, 0.0, -10.0, -20.0, -14.933237335161369, -20.0, -1.260328301575765, 0.0, -4.359881464104063]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6716652064116438, "mean_inference_ms": 1.1739421233525316, "mean_action_processing_ms": 0.23265910926209468, "mean_env_wait_ms": 0.4992800602042236, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004668368233574761, "StateBufferConnector_ms": 0.0035436800968499833, "ViewRequirementAgentConnector_ms": 0.09524174678472826}, "num_episodes": 162, "episode_return_max": 140.0, "episode_return_min": -55.767842013183916, "episode_return_mean": 8.717263164146647}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 48000, "num_agent_steps_trained": 48000, "num_env_steps_sampled": 12000, "num_env_steps_trained": 12000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 280.49650971336024, "num_env_steps_trained_throughput_per_sec": 280.49650971336024, "timesteps_total": 12000, "num_env_steps_sampled_lifetime": 12000, "num_agent_steps_sampled_lifetime": 48000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 48000, "timers": {"training_iteration_time_ms": 13199.256, "restore_workers_time_ms": 0.015, "training_step_time_ms": 13199.143, "sample_time_ms": 1232.78, "learn_time_ms": 11943.245, "learn_throughput": 334.917, "synch_weights_time_ms": 20.244}, "counters": {"num_env_steps_sampled": 12000, "num_env_steps_trained": 12000, "num_agent_steps_sampled": 48000, "num_agent_steps_trained": 48000}, "done": false, "training_iteration": 3, "trial_id": "86f16_00000", "date": "2024-08-08_16-13-14", "timestamp": 1723147994, "time_this_iter_s": 14.279911756515503, "time_total_s": 39.69622564315796, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3acf000d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 39.69622564315796, "iterations_since_restore": 3, "perf": {"cpu_util_percent": 45.63000000000001, "ram_util_percent": 81.69500000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6278829714824967, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.6207336665890741, "policy_loss": -0.007989932409593347, "vf_loss": 1.627050163993176, "vf_explained_var": 9.235380389166216e-06, "kl": 0.008366619028230477, "entropy": 1.5601470111955142, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 9870.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9750159760937095, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.7184840261315304, "policy_loss": -0.014934202728666909, "vf_loss": 2.731345633044839, "vf_explained_var": 0.012384411009649435, "kl": 0.010363000284483531, "entropy": 1.522477134813865, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 3360.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 16000, "num_env_steps_trained": 16000, "num_agent_steps_sampled": 64000, "num_agent_steps_trained": 64000}, "env_runners": {"episode_reward_max": 128.42502170597805, "episode_reward_min": -55.542044996446286, "episode_reward_mean": 11.810088696573033, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -81.57497829402195}, "policy_reward_max": {"adversary_policy": 70.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 7.283950617283951, "agent_policy": -10.041763155278822}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, -10.611954306116418, 40.0, 0.0, 20.0, -0.5035516455363109, 0.0, 40.0, 0.0, 0.0, -0.1771258739148751, 80.0, 0.0, 0.0, 0.0, 0.0, -21.60475234331436, 39.6293596366536, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, -11.899050937914039, 0.0, 19.430855009179876, 20.0, -2.096611193024833, 0.0, 0.0, 0.0, -5.491616375180757, 20.0, -0.699048034318136, -3.46418057289186, 20.0, 0.0, 40.0, -1.1843934527282385, 33.1875145738544, -2.9306621844861125, 0.0, 20.0, -6.219407842723259, 0.0, 0.0, 0.0, -14.260045896619797, 40.0, 20.0, 0.0, 31.40289058437855, -0.22300229426075013, 55.98287313958551, -8.970504026161986, 0.0, -0.7291337784350449, 0.0, 0.0, -0.5567022284718737, 60.0, 20.0, 0.0, 39.49428119621044, 0.0, -10.91389226236777, 80.0, -34.6763216572145, 0.0, 0.0, 40.0, -4.007830185584881, 0.0, 60.0, -0.09516332229947855, 0.0, 80.0, -0.16943497559813392, 0.0, 60.0, -14.581280286069102, -2.614309799740039, 0.0, 0.0, -1.2594198279612223, 0.0, -1.0760264857141821, 0.0, 0.0, -55.542044996446286, -24.227695769896687, -1.3405249388661555, 18.139142584388683, 0.0, -15.988282710480005, 0.0, 0.0, -0.8671044663036187, -4.756014072670797, 120.0, 0.0, 72.79453271376087, -0.30996746808580555, 0.0, -11.580037695910187, 40.0, 0.0, -6.944162131190755, 40.0, 0.0, 0.0, 0.0, 80.0, 40.0, -0.4474563269842746, 46.95715496847789, 0.0, 60.0, 60.0, 0.0, 20.0, -1.0816954851354676, 40.0, 0.0, 0.0, 60.0, -0.023704523766528984, -0.5846335345627585, 35.52428305525244, 20.0, 24.359140395756594, 0.0, 40.0, 0.0, -24.374521853829943, 0.0, 0.0, -2.5774408273222917, 0.0, 128.42502170597805, -0.06646304383667201, 39.95639837272364, -3.019088082438036, 17.643791651777622, 0.0, 78.81544200180296, 20.0, -6.2890005676704295, 0.0, -12.08015944380608, 11.110060026538523, 80.0, 0.0, 0.0, 20.0, 0.0, 0.0, -0.1218220260417191, -6.381131017596198], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [0.0, 0.0, 0.0, -10.611954306116418, -20.0, 0.0, -10.0, -0.5035516455363109, 0.0, -20.0, 0.0, 0.0, -0.1771258739148751, -40.0, 0.0, 0.0, 0.0, 0.0, -21.60475234331436, -20.370640363346403, 0.0, 0.0, 0.0, 0.0, 0.0, -30.0, -11.899050937914039, 0.0, -10.569144990820124, -10.0, -2.096611193024833, 0.0, 0.0, 0.0, -5.491616375180757, -10.0, -0.699048034318136, -3.46418057289186, -10.0, 0.0, -20.0, -1.1843934527282385, -26.812485426145603, -2.9306621844861125, 0.0, -10.0, -6.219407842723259, 0.0, 0.0, 0.0, -14.260045896619797, -20.0, -10.0, 0.0, -28.597109415621457, -0.22300229426075013, -34.01712686041449, -8.970504026161986, 0.0, -0.7291337784350449, 0.0, 0.0, -0.5567022284718737, -30.0, -10.0, 0.0, -20.505718803789563, 0.0, -10.91389226236777, -40.0, -34.6763216572145, 0.0, 0.0, -20.0, -4.007830185584881, 0.0, -30.0, -0.09516332229947855, 0.0, -40.0, -0.16943497559813392, 0.0, -30.0, -14.581280286069102, -2.614309799740039, 0.0, 0.0, -1.2594198279612223, 0.0, -1.0760264857141821, 0.0, 0.0, -55.542044996446286, -24.227695769896687, -1.3405249388661555, -11.860857415611317, 0.0, -15.988282710480005, 0.0, 0.0, -0.8671044663036187, -4.756014072670797, -60.0, 0.0, -47.205467286239134, -0.30996746808580555, 0.0, -11.580037695910187, -20.0, 0.0, -6.944162131190755, -20.0, 0.0, 0.0, 0.0, -40.0, -20.0, -0.4474563269842746, -43.04284503152211, 0.0, -30.0, -30.0, 0.0, -10.0, -1.0816954851354676, -20.0, 0.0, 0.0, -30.0, -0.023704523766528984, -0.5846335345627585, -54.47571694474756, -10.0, -35.64085960424341, 0.0, -20.0, 0.0, -24.374521853829943, 0.0, 0.0, -2.5774408273222917, 0.0, -81.57497829402195, -0.06646304383667201, -20.043601627276356, -3.019088082438036, -12.35620834822238, 0.0, -41.184557998197036, -10.0, -6.2890005676704295, 0.0, -12.08015944380608, -18.889939973461477, -40.0, 0.0, 0.0, -10.0, 0.0, 0.0, -0.1218220260417191, -6.381131017596198]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6909271532359076, "mean_inference_ms": 1.208923940666612, "mean_action_processing_ms": 0.2390366386186864, "mean_env_wait_ms": 0.5155415114012813, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005793277128243152, "StateBufferConnector_ms": 0.00446372561984592, "ViewRequirementAgentConnector_ms": 0.10365843772888184}, "num_episodes": 162, "episode_return_max": 128.42502170597805, "episode_return_min": -55.542044996446286, "episode_return_mean": 11.810088696573033}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 64000, "num_agent_steps_trained": 64000, "num_env_steps_sampled": 16000, "num_env_steps_trained": 16000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 206.64877753677754, "num_env_steps_trained_throughput_per_sec": 206.64877753677754, "timesteps_total": 16000, "num_env_steps_sampled_lifetime": 16000, "num_agent_steps_sampled_lifetime": 64000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 64000, "timers": {"training_iteration_time_ms": 14738.574, "restore_workers_time_ms": 0.015, "training_step_time_ms": 14738.472, "sample_time_ms": 1291.426, "learn_time_ms": 13422.269, "learn_throughput": 298.012, "synch_weights_time_ms": 21.242}, "counters": {"num_env_steps_sampled": 16000, "num_env_steps_trained": 16000, "num_agent_steps_sampled": 64000, "num_agent_steps_trained": 64000}, "done": false, "training_iteration": 4, "trial_id": "86f16_00000", "date": "2024-08-08_16-13-33", "timestamp": 1723148013, "time_this_iter_s": 19.45686411857605, "time_total_s": 59.15308976173401, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3aca984c0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 59.15308976173401, "iterations_since_restore": 4, "perf": {"cpu_util_percent": 69.65714285714287, "ram_util_percent": 82.8392857142857}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6385586708995468, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.576024800919472, "policy_loss": -0.008133582363618498, "vf_loss": 1.5825206995010377, "vf_explained_var": -1.2908041054475392e-05, "kl": 0.008187920176620685, "entropy": 1.5452180128993718, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 12690.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7906050633639097, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.2387055402621625, "policy_loss": -0.015858518028593, "vf_loss": 2.2521340775613985, "vf_explained_var": 0.004452386436363061, "kl": 0.01214990695103219, "entropy": 1.5247841417789458, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 4320.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 20000, "num_env_steps_trained": 20000, "num_agent_steps_sampled": 80000, "num_agent_steps_trained": 80000}, "env_runners": {"episode_reward_max": 220.0, "episode_reward_min": -24.412454284547035, "episode_reward_mean": 13.874201250294975, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 157, "episodes_timesteps_total": 3925, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -110.0}, "policy_reward_max": {"adversary_policy": 110.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 7.579617834394904, "agent_policy": -8.864652252889737}, "custom_metrics": {}, "hist_stats": {"episode_reward": [59.60574687422485, 0.0, 0.0, 60.0, 39.544906759821004, 0.0, 0.0, -5.891809677119329, 0.0, 0.0, 0.0, -0.1983574118591469, 0.0, 31.68249384386668, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 0.0, -2.230854029806629, 58.65272133060566, 60.0, -0.7044609658670542, 0.0, -0.6669529859390644, 0.0, -4.460664105721959, -1.9134471110580276, 0.0, -0.016377161498779547, 0.0, 0.0, 0.0, -1.9237462998947563, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 20.0, 40.0, 60.0, -6.945331998489749, 100.0, 0.0, -1.8423134521929696, -1.7576040620565914, 60.0, 100.0, -5.841495405677055, 0.0, 220.0, -1.5083909729751555, 0.0, -7.945505065580918, 0.0, 0.0, 0.0, 0.0, 0.0, 100.0, 0.0, 40.0, -14.645598349468695, -2.973134201295574, -3.539768096279481, 0.0, 0.0, -1.138069714369051, 0.0, 20.0, -3.6660464977767635, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -2.2688097983360507, -3.6333630047969, 0.0, -1.2439881847972545, 0.0, 59.74009509003392, -0.8505307024902931, 0.0, 0.0, 0.0, 40.0, 60.0, 0.0, 49.13242066577085, 40.0, 8.59881829604362, -4.366932543003951, 0.0, 0.0, -0.3264469342927334, -8.267083972205903, -0.7721216771775707, 0.0, 39.834204523526765, 40.0, 20.0, -0.08712775801463901, 0.0, -5.154904810524188, 20.0, 0.0, 0.0, -0.5421109108494826, 0.0, -0.8798935682530995, 20.0, -0.38314473246326197, 0.0, 0.0, 20.0, 0.0, -24.363710525696757, 59.13781907536199, 0.0, 0.0, 100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 80.0, 0.0, -2.3410330721670807, 80.0, 0.0, 0.0, 20.0, 57.25818751864978, -24.412454284547035, 0.0, 0.0, 59.06526350795377, 80.0, 60.0, -9.179444020856138, 20.0, 0.0, 80.0, 0.0, 0.0, -5.1200531241486065, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 110.0, 110.0, 110.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-30.39425312577516, 0.0, 0.0, -30.0, -20.455093240178996, 0.0, 0.0, -5.891809677119329, 0.0, 0.0, 0.0, -0.1983574118591469, 0.0, -28.31750615613332, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -30.0, -30.0, 0.0, -2.230854029806629, -31.347278669394342, -30.0, -0.7044609658670542, 0.0, -0.6669529859390644, 0.0, -4.460664105721959, -1.9134471110580276, 0.0, -0.016377161498779547, 0.0, 0.0, 0.0, -1.9237462998947563, 0.0, 0.0, 0.0, 0.0, 0.0, -20.0, -10.0, -20.0, -30.0, -6.945331998489749, -50.0, 0.0, -1.8423134521929696, -1.7576040620565914, -30.0, -50.0, -5.841495405677055, 0.0, -110.0, -1.5083909729751555, 0.0, -7.945505065580918, 0.0, 0.0, 0.0, 0.0, 0.0, -50.0, 0.0, -20.0, -14.645598349468695, -2.973134201295574, -3.539768096279481, 0.0, 0.0, -1.138069714369051, 0.0, -10.0, -3.6660464977767635, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -2.2688097983360507, -3.6333630047969, 0.0, -1.2439881847972545, 0.0, -30.25990490996608, -0.8505307024902931, 0.0, 0.0, 0.0, -20.0, -30.0, 0.0, -40.867579334229134, -20.0, -21.401181703956386, -4.366932543003951, 0.0, 0.0, -0.3264469342927334, -8.267083972205903, -0.7721216771775707, 0.0, -20.165795476473235, -20.0, -10.0, -0.08712775801463901, 0.0, -5.154904810524188, -10.0, 0.0, 0.0, -0.5421109108494826, 0.0, -0.8798935682530995, -10.0, -0.38314473246326197, 0.0, 0.0, -10.0, 0.0, -24.363710525696757, -30.86218092463801, 0.0, 0.0, -50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -40.0, 0.0, -2.3410330721670807, -40.0, 0.0, 0.0, -10.0, -32.74181248135023, -24.412454284547035, 0.0, 0.0, -30.934736492046227, -40.0, -30.0, -9.179444020856138, -10.0, 0.0, -40.0, 0.0, 0.0, -5.1200531241486065, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7024285202783838, "mean_inference_ms": 1.2257072628729073, "mean_action_processing_ms": 0.24321718596104158, "mean_env_wait_ms": 0.523973032960584, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005281730821937512, "StateBufferConnector_ms": 0.0048312411946096236, "ViewRequirementAgentConnector_ms": 0.10597956408360962}, "num_episodes": 157, "episode_return_max": 220.0, "episode_return_min": -24.412454284547035, "episode_return_mean": 13.874201250294975}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 80000, "num_agent_steps_trained": 80000, "num_env_steps_sampled": 20000, "num_env_steps_trained": 20000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 237.06434776435668, "num_env_steps_trained_throughput_per_sec": 237.06434776435668, "timesteps_total": 20000, "num_env_steps_sampled_lifetime": 20000, "num_agent_steps_sampled_lifetime": 80000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 80000, "timers": {"training_iteration_time_ms": 15165.473, "restore_workers_time_ms": 0.015, "training_step_time_ms": 15165.382, "sample_time_ms": 1313.448, "learn_time_ms": 13826.117, "learn_throughput": 289.308, "synch_weights_time_ms": 22.787}, "counters": {"num_env_steps_sampled": 20000, "num_env_steps_trained": 20000, "num_agent_steps_sampled": 80000, "num_agent_steps_trained": 80000}, "done": false, "training_iteration": 5, "trial_id": "86f16_00000", "date": "2024-08-08_16-13-50", "timestamp": 1723148030, "time_this_iter_s": 16.942729949951172, "time_total_s": 76.09581971168518, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3acf3f790>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 76.09581971168518, "iterations_since_restore": 5, "perf": {"cpu_util_percent": 61.708333333333336, "ram_util_percent": 81.85416666666667}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6419613454570161, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.144743412352623, "policy_loss": -0.009698263633705623, "vf_loss": 2.1524730363636153, "vf_explained_var": -1.3817033023698956e-05, "kl": 0.009842726255193527, "entropy": 1.5259301262544402, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 15510.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8717522202370067, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.6650227206138273, "policy_loss": -0.017137016899262867, "vf_loss": 2.679818183245758, "vf_explained_var": 0.005960728724797567, "kl": 0.01170780799804101, "entropy": 1.509609030559659, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 5280.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 24000, "num_env_steps_trained": 24000, "num_agent_steps_sampled": 96000, "num_agent_steps_trained": 96000}, "env_runners": {"episode_reward_max": 140.0, "episode_reward_min": -40.66602256767716, "episode_reward_mean": 15.771934141006344, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 158, "episodes_timesteps_total": 3950, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -70.0}, "policy_reward_max": {"adversary_policy": 70.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 8.670886075949367, "agent_policy": -10.240724086841757}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, -3.36430032230422, 0.0, -3.780221725811624, -11.303811607482924, 20.0, 39.04913269389898, 0.0, -27.794862326405838, 0.0, -6.678291985384055, 0.0, 0.0, 0.0, 58.72349440583082, 0.0, 0.0, 0.0, -2.2020125959694665, 60.0, 0.0, 60.0, 60.0, 0.0, -0.4526537076517001, 18.846931689789137, 0.0, 0.0, 40.0, 0.0, 80.0, 0.0, 0.0, 0.0, 40.0, 0.0, 0.0, -0.1097467009116826, 0.0, 60.0, 0.0, 56.55435510494769, -11.963943903858837, 40.0, -1.99521912698162, 0.0, 20.0, -0.1440803846492611, 140.0, -16.631907760282296, 0.0, 0.0, 0.0, 60.0, 56.394554666584725, 0.0, 39.28691386101461, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 59.518831915199655, 0.0, 0.0, 20.0, -40.66602256767716, 0.0, -1.703093453297977, 0.0, 0.0, 0.0, 60.0, 20.0, 0.0, 55.19405950550663, 0.0, 0.0, 0.0, 40.0, 0.0, 17.08486860072716, 60.0, 0.0, 0.0, 0.0, 0.0, 60.0, 0.0, 0.0, -1.2229763978383423, 0.0, 60.0, 60.0, 0.0, 0.0, 0.0, -13.145942031078768, -10.23270950646678, -5.169960626120545, 100.0, 0.0, 0.0, 0.0, 0.0, -2.209177691771226, 0.0, 0.0, 0.0, 0.0, 40.0, 0.0, 0.0, -4.1715788456066, 58.892806544355096, -2.636401735146488, 40.0, 59.40088691571273, 0.0, 60.0, 40.0, 100.0, 0.0, 20.0, -0.5766384033631999, 0.0, 0.0, -3.1002050799250878, 100.0, -1.4290475988018714, 60.0, 0.0, 59.26903885541935, 0.0, 40.0, 0.0, 0.0, 0.0, -12.328487380390333, 0.0, 0.0, 60.0, 0.0, -19.645386569169215, 20.0, 0.0, 0.0, 20.0, 100.0, 40.0, 0.0, 20.0, -1.4984253772772427, 100.0, 0.0, 0.0, 39.906824931640145], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0], "policy_agent_policy_reward": [0.0, -3.36430032230422, 0.0, -3.780221725811624, -11.303811607482924, -10.0, -20.950867306101017, 0.0, -27.794862326405838, 0.0, -6.678291985384055, 0.0, 0.0, 0.0, -31.27650559416918, 0.0, 0.0, 0.0, -2.2020125959694665, -30.0, 0.0, -30.0, -30.0, 0.0, -0.4526537076517001, -11.15306831021086, 0.0, 0.0, -20.0, 0.0, -40.0, 0.0, 0.0, 0.0, -20.0, 0.0, 0.0, -0.1097467009116826, 0.0, -30.0, 0.0, -33.44564489505231, -11.963943903858837, -20.0, -1.99521912698162, 0.0, -10.0, -0.1440803846492611, -70.0, -16.631907760282296, 0.0, 0.0, 0.0, -30.0, -33.60544533341529, 0.0, -20.71308613898539, -30.0, 0.0, 0.0, 0.0, 0.0, 0.0, -30.481168084800338, 0.0, 0.0, -10.0, -40.66602256767716, 0.0, -1.703093453297977, 0.0, 0.0, 0.0, -30.0, -10.0, 0.0, -34.80594049449338, 0.0, 0.0, 0.0, -20.0, 0.0, -12.915131399272841, -30.0, 0.0, 0.0, 0.0, 0.0, -30.0, 0.0, 0.0, -1.2229763978383423, 0.0, -30.0, -30.0, 0.0, 0.0, 0.0, -43.14594203107877, -10.23270950646678, -5.169960626120545, -50.0, 0.0, 0.0, 0.0, 0.0, -2.209177691771226, 0.0, 0.0, 0.0, 0.0, -20.0, 0.0, 0.0, -4.1715788456066, -31.107193455644904, -2.636401735146488, -20.0, -30.599113084287275, 0.0, -30.0, -20.0, -50.0, 0.0, -10.0, -0.5766384033631999, 0.0, 0.0, -3.1002050799250878, -50.0, -1.4290475988018714, -30.0, 0.0, -30.730961144580647, 0.0, -20.0, 0.0, 0.0, 0.0, -12.328487380390333, 0.0, 0.0, -30.0, 0.0, -19.645386569169215, -10.0, 0.0, 0.0, -10.0, -50.0, -20.0, 0.0, -10.0, -1.4984253772772427, -50.0, 0.0, 0.0, -20.09317506835985]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7083323295833877, "mean_inference_ms": 1.2270223378633869, "mean_action_processing_ms": 0.244140993201431, "mean_env_wait_ms": 0.5254072470062353, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005310924747322179, "StateBufferConnector_ms": 0.0035009806669211085, "ViewRequirementAgentConnector_ms": 0.11177553406244592}, "num_episodes": 158, "episode_return_max": 140.0, "episode_return_min": -40.66602256767716, "episode_return_mean": 15.771934141006344}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 96000, "num_agent_steps_trained": 96000, "num_env_steps_sampled": 24000, "num_env_steps_trained": 24000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 266.81544652772084, "num_env_steps_trained_throughput_per_sec": 266.81544652772084, "timesteps_total": 24000, "num_env_steps_sampled_lifetime": 24000, "num_agent_steps_sampled_lifetime": 96000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 96000, "timers": {"training_iteration_time_ms": 15136.502, "restore_workers_time_ms": 0.015, "training_step_time_ms": 15136.419, "sample_time_ms": 1338.117, "learn_time_ms": 13774.113, "learn_throughput": 290.4, "synch_weights_time_ms": 21.585}, "counters": {"num_env_steps_sampled": 24000, "num_env_steps_trained": 24000, "num_agent_steps_sampled": 96000, "num_agent_steps_trained": 96000}, "done": false, "training_iteration": 6, "trial_id": "86f16_00000", "date": "2024-08-08_16-14-06", "timestamp": 1723148046, "time_this_iter_s": 15.004966735839844, "time_total_s": 91.10078644752502, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3aca40dc0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 91.10078644752502, "iterations_since_restore": 6, "perf": {"cpu_util_percent": 52.999999999999986, "ram_util_percent": 80.72380952380952}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6635412859948392, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.4450631737497681, "policy_loss": -0.00902918383849831, "vf_loss": 1.4524416401453897, "vf_explained_var": 1.0783685014602986e-05, "kl": 0.008253218602503571, "entropy": 1.506284761006105, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 18330.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8786604563705623, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.245085890653233, "policy_loss": -0.015964351335909063, "vf_loss": 2.258672063735624, "vf_explained_var": 0.0030895976970593134, "kl": 0.011890907431695914, "entropy": 1.4784805485357841, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 6240.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 28000, "num_env_steps_trained": 28000, "num_agent_steps_sampled": 112000, "num_agent_steps_trained": 112000}, "env_runners": {"episode_reward_max": 180.0, "episode_reward_min": -37.216035391780515, "episode_reward_mean": 13.777314472408898, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -113.63443730222271}, "policy_reward_max": {"adversary_policy": 90.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 8.08641975308642, "agent_policy": -10.48194478685036}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 120.0, 20.0, 40.0, 0.0, 0.0, -13.29698216699631, 60.0, 20.0, -26.071886881002886, 20.0, -37.216035391780515, 0.0, 0.0, 180.0, 0.0, 0.0, -8.42682227570047, 0.0, 0.0, -6.885357193379425, 0.0, -2.490047590831365, 100.0, 20.0, 20.0, 40.0, -0.3993982324358891, 0.0, 0.0, 20.0, -0.36111610834951513, 0.0, 0.0, 0.0, -6.925756046699337, -4.7543754330942365, 0.0, 0.0, 0.0, 0.0, 20.0, 0.0, -30.986394839394606, -6.353201636553388, 40.0, 100.0, -3.5042836024576447, 0.0, -0.8745623366118527, 0.0, 0.0, 0.0, 117.90043165430416, 0.0, -0.7853201754111006, 0.0, 100.0, 80.0, 0.0, 51.34502663432046, 0.0, -4.464108348454842, -1.68150974935514, 0.0, 60.0, -2.3811563307224968, 0.0, -0.29911468888866866, 40.0, 0.0, -3.7947813042944443, 0.0, -17.021619458731152, 60.0, 118.25286076817574, 0.0, -0.4715520620871705, 0.0, 0.0, -2.1417099238939263, 0.0, 60.0, 0.0, 120.0, 66.36556269777726, 0.0, 0.0, 20.0, 0.0, 0.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 49.19129178412731, 60.0, -0.2244560388858563, 0.0, 0.0, 40.0, -1.262312051108233, 0.0, 0.0, -6.786884601941051, 60.0, -11.913691376965346, 80.0, 0.0, 0.0, 0.0, 0.0, 20.0, -22.70789289590189, -20.51896285242223, -2.5211928097341603, 80.0, -6.804869703016145, 0.0, -1.447084242917217, 0.0, 60.0, 0.0, 0.0, 0.0, 100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, -0.8139494437910721, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, -4.710745128459501, 0.0, 0.0, 60.0, 0.0, 0.0, -0.03533173857158567, 0.0, 0.0, 0.0, 20.0, 0.0, -9.795764347622764, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 90.0, 90.0, 90.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [0.0, 0.0, 0.0, -60.0, -10.0, -20.0, 0.0, 0.0, -13.29698216699631, -30.0, -10.0, -26.071886881002886, -10.0, -37.216035391780515, 0.0, 0.0, -90.0, 0.0, 0.0, -8.42682227570047, 0.0, 0.0, -6.885357193379425, 0.0, -2.490047590831365, -50.0, -10.0, -10.0, -20.0, -0.3993982324358891, 0.0, 0.0, -10.0, -0.36111610834951513, 0.0, 0.0, 0.0, -6.925756046699337, -4.7543754330942365, 0.0, 0.0, 0.0, 0.0, -10.0, 0.0, -30.986394839394606, -6.353201636553388, -20.0, -50.0, -3.5042836024576447, 0.0, -0.8745623366118527, 0.0, 0.0, 0.0, -92.09956834569581, 0.0, -0.7853201754111006, 0.0, -50.0, -40.0, 0.0, -38.65497336567954, 0.0, -4.464108348454842, -1.68150974935514, 0.0, -30.0, -2.3811563307224968, 0.0, -0.29911468888866866, -20.0, 0.0, -3.7947813042944443, 0.0, -17.021619458731152, -30.0, -61.747139231824264, 0.0, -0.4715520620871705, 0.0, 0.0, -2.1417099238939263, 0.0, -30.0, 0.0, -60.0, -113.63443730222271, 0.0, 0.0, -10.0, 0.0, 0.0, -30.0, 0.0, 0.0, 0.0, 0.0, 0.0, -40.80870821587269, -30.0, -0.2244560388858563, 0.0, 0.0, -20.0, -1.262312051108233, 0.0, 0.0, -6.786884601941051, -30.0, -41.913691376965346, -40.0, 0.0, 0.0, 0.0, 0.0, -10.0, -22.70789289590189, -20.51896285242223, -2.5211928097341603, -40.0, -6.804869703016145, 0.0, -1.447084242917217, 0.0, -30.0, 0.0, 0.0, 0.0, -50.0, 0.0, 0.0, 0.0, 0.0, 0.0, -20.0, -0.8139494437910721, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -30.0, -4.710745128459501, 0.0, 0.0, -30.0, 0.0, 0.0, -0.03533173857158567, 0.0, 0.0, 0.0, -10.0, 0.0, -9.795764347622764, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7048058607002372, "mean_inference_ms": 1.2179259479023081, "mean_action_processing_ms": 0.24249641213267847, "mean_env_wait_ms": 0.5227746801888847, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005038800062956633, "StateBufferConnector_ms": 0.0034263840428105105, "ViewRequirementAgentConnector_ms": 0.0957331539672098}, "num_episodes": 162, "episode_return_max": 180.0, "episode_return_min": -37.216035391780515, "episode_return_mean": 13.777314472408898}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 112000, "num_agent_steps_trained": 112000, "num_env_steps_sampled": 28000, "num_env_steps_trained": 28000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 299.0396844811007, "num_env_steps_trained_throughput_per_sec": 299.0396844811007, "timesteps_total": 28000, "num_env_steps_sampled_lifetime": 28000, "num_agent_steps_sampled_lifetime": 112000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 112000, "timers": {"training_iteration_time_ms": 14885.025, "restore_workers_time_ms": 0.015, "training_step_time_ms": 14884.947, "sample_time_ms": 1320.182, "learn_time_ms": 13541.942, "learn_throughput": 295.379, "synch_weights_time_ms": 20.389}, "counters": {"num_env_steps_sampled": 28000, "num_env_steps_trained": 28000, "num_agent_steps_sampled": 112000, "num_agent_steps_trained": 112000}, "done": false, "training_iteration": 7, "trial_id": "86f16_00000", "date": "2024-08-08_16-14-19", "timestamp": 1723148059, "time_this_iter_s": 13.40764594078064, "time_total_s": 104.50843238830566, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3acf3d040>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 104.50843238830566, "iterations_since_restore": 7, "perf": {"cpu_util_percent": 45.347368421052636, "ram_util_percent": 81.34210526315789}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6665347975936342, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.5677949461319767, "policy_loss": -0.01182221937165034, "vf_loss": 1.5777740840159409, "vf_explained_var": 6.085274912786822e-06, "kl": 0.009215100095940695, "entropy": 1.4986194355268005, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 21150.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8033810475220283, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.1927225064796705, "policy_loss": -0.014708741612169736, "vf_loss": 2.2054044036815563, "vf_explained_var": 0.0003478318452835083, "kl": 0.010134240474953878, "entropy": 1.4840643988301356, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 7200.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 32000, "num_env_steps_trained": 32000, "num_agent_steps_sampled": 128000, "num_agent_steps_trained": 128000}, "env_runners": {"episode_reward_max": 120.0, "episode_reward_min": -31.470421422483945, "episode_reward_mean": 14.118691350987122, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -72.2999117806105}, "policy_reward_max": {"adversary_policy": 60.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 7.839506172839506, "agent_policy": -9.399827167531395}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 20.0, 0.0, -5.707185914545457, 40.0, -0.40570225253965697, -5.895148467716293, -8.746705140100632, 0.0, 60.0, -2.5685397743643845, 0.0, 0.0, 0.0, -2.5118331799404983, 80.0, 80.0, 0.0, 60.0, -0.12242997379568687, -0.7173780933196316, 0.0, -0.35713946194181334, 60.0, 107.7000882193895, 60.0, -19.219150063227033, 80.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 0.0, 0.0, -6.994254331022637, 0.0, 60.0, 0.0, 0.0, 0.0, 0.0, -1.7905152392586787, 0.0, 80.0, -9.294491104512229, 40.0, 0.0, 19.42824039980842, 0.0, 0.0, 120.0, 0.0, 35.07636912265343, 60.0, 0.0, 0.0, 0.0, 20.0, -1.1091674222881864, -8.21485931143432, 36.85338333916056, 0.0, -3.9428052734684966, 0.0, 40.0, 60.0, 39.89711603329477, 0.0, 0.0, -0.9940354125750483, 0.0, -31.470421422483945, 60.0, 20.0, 0.0, 60.0, 20.0, 0.0, 0.0, 0.0, 100.0, -0.1545700634198932, 0.0, 0.0, 0.0, -5.476482758693916, 0.0, -1.264511818098668, -2.4809185839594514, 0.0, 0.0, 40.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 0.0, -5.158272303295394, 0.0, -13.176633563431398, -20.35892130711806, 20.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -6.56892522144929, -0.16075945470493513, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.5205713584133276, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 29.187276981211852, 60.0, -0.5047987369069218, 0.0, 120.0, -5.417629946909551, 60.0, 0.0, 0.0, 60.0, 0.0, 0.0, 0.0, 37.770563040951664, 0.0, 20.0, -0.1047951216244003, 0.0, -2.472427460504073, 37.4190446615725, 78.45555190148865, 0.0, 0.0, 0.0, 0.0, 100.0, 0.0, 59.32234469744674], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 60.0, 60.0, 60.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0], "policy_agent_policy_reward": [0.0, 0.0, -10.0, 0.0, -5.707185914545457, -20.0, -0.40570225253965697, -5.895148467716293, -8.746705140100632, 0.0, -30.0, -2.5685397743643845, 0.0, 0.0, 0.0, -2.5118331799404983, -40.0, -40.0, 0.0, -30.0, -0.12242997379568687, -0.7173780933196316, 0.0, -0.35713946194181334, -30.0, -72.2999117806105, -30.0, -19.219150063227033, -40.0, 0.0, 0.0, 0.0, 0.0, 0.0, -20.0, 0.0, 0.0, -6.994254331022637, 0.0, -30.0, 0.0, 0.0, 0.0, 0.0, -1.7905152392586787, 0.0, -40.0, -9.294491104512229, -20.0, 0.0, -10.571759600191582, 0.0, 0.0, -60.0, 0.0, -24.923630877346564, -30.0, 0.0, 0.0, 0.0, -10.0, -1.1091674222881864, -8.21485931143432, -23.146616660839445, 0.0, -3.9428052734684966, 0.0, -20.0, -30.0, -20.102883966705228, 0.0, 0.0, -0.9940354125750483, 0.0, -31.470421422483945, -30.0, -10.0, 0.0, -30.0, -10.0, 0.0, 0.0, 0.0, -50.0, -0.1545700634198932, 0.0, 0.0, 0.0, -5.476482758693916, 0.0, -1.264511818098668, -2.4809185839594514, 0.0, 0.0, -20.0, -30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -20.0, 0.0, -5.158272303295394, 0.0, -13.176633563431398, -20.35892130711806, -10.0, -20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -6.56892522144929, -0.16075945470493513, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.5205713584133276, 0.0, 0.0, 0.0, 0.0, 0.0, -20.0, -60.81272301878815, -30.0, -0.5047987369069218, 0.0, -60.0, -5.417629946909551, -30.0, 0.0, 0.0, -30.0, 0.0, 0.0, 0.0, -52.229436959048336, 0.0, -10.0, -0.1047951216244003, 0.0, -2.472427460504073, -22.5809553384275, -41.54444809851135, 0.0, 0.0, 0.0, 0.0, -50.0, 0.0, -30.677655302553262]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6950685546117062, "mean_inference_ms": 1.2003921108636235, "mean_action_processing_ms": 0.23924056195282783, "mean_env_wait_ms": 0.5165181886825745, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0044604142506917315, "StateBufferConnector_ms": 0.0041595947595290195, "ViewRequirementAgentConnector_ms": 0.0879278153549006}, "num_episodes": 162, "episode_return_max": 120.0, "episode_return_min": -31.470421422483945, "episode_return_mean": 14.118691350987122}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 128000, "num_agent_steps_trained": 128000, "num_env_steps_sampled": 32000, "num_env_steps_trained": 32000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 334.68333373662915, "num_env_steps_trained_throughput_per_sec": 334.68333373662915, "timesteps_total": 32000, "num_env_steps_sampled_lifetime": 32000, "num_agent_steps_sampled_lifetime": 128000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 128000, "timers": {"training_iteration_time_ms": 14518.347, "restore_workers_time_ms": 0.014, "training_step_time_ms": 14518.274, "sample_time_ms": 1293.259, "learn_time_ms": 13203.822, "learn_throughput": 302.943, "synch_weights_time_ms": 19.035}, "counters": {"num_env_steps_sampled": 32000, "num_env_steps_trained": 32000, "num_agent_steps_sampled": 128000, "num_agent_steps_trained": 128000}, "done": false, "training_iteration": 8, "trial_id": "86f16_00000", "date": "2024-08-08_16-14-31", "timestamp": 1723148071, "time_this_iter_s": 11.955332040786743, "time_total_s": 116.46376442909241, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3aca8a5e0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 116.46376442909241, "iterations_since_restore": 8, "perf": {"cpu_util_percent": 33.39444444444444, "ram_util_percent": 80.20555555555555}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6684113451246674, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.847061733700705, "policy_loss": -0.012096076402961812, "vf_loss": 1.8573064419817418, "vf_explained_var": 1.7975429271129853e-05, "kl": 0.009256557285801346, "entropy": 1.4826276680256458, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 23970.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8480976510172089, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.521126747628053, "policy_loss": -0.018696473663051924, "vf_loss": 2.53732279073447, "vf_explained_var": 0.004181337046126525, "kl": 0.012502196866141964, "entropy": 1.4616350300610066, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 8160.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 36000, "num_env_steps_trained": 36000, "num_agent_steps_sampled": 144000, "num_agent_steps_trained": 144000}, "env_runners": {"episode_reward_max": 180.0, "episode_reward_min": -47.636168116706195, "episode_reward_mean": 15.021648008172363, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 157, "episodes_timesteps_total": 3925, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -90.0}, "policy_reward_max": {"adversary_policy": 90.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 8.535031847133759, "agent_policy": -10.58344753322891}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 20.0, 40.0, 0.0, -15.460839069310174, 0.0, 180.0, 0.0, 0.0, 0.0, 112.28777286927836, 18.86802343374024, 0.0, -0.9596259137161522, 20.0, -9.314561185820079, -0.26751774806981765, -0.9525538931812361, 0.0, 37.66203211549406, 0.0, 100.0, 0.0, -7.981881814553995, 0.0, 40.0, 60.0, 0.0, -3.9248474647295652, 0.0, 0.0, 60.0, 40.0, 0.0, 0.0, 0.0, 33.55702188683413, 0.0, 10.94143212296346, 0.0, -28.187721299030425, 20.0, -1.2180793205913287, 0.0, -3.2148273945232066, 60.0, -0.666623400603128, -0.2436499070540843, 0.0, 52.07938290343113, -18.685781726338924, -2.148302251282092, 0.0, 0.0, -1.8882504358143404, -2.039591476395622, 60.0, -47.636168116706195, 0.0, 60.0, 40.0, -0.9668368965259355, 40.0, 0.0, 0.0, 60.0, 20.0, 0.0, 0.0, -0.648790860876145, 0.0, 0.0, 0.0, 80.0, 40.0, -5.34026894177066, 0.0, 0.0, 40.0, 0.0, -0.08963355587790822, -0.1991468851625644, 0.0, 20.0, 0.0, 0.0, 0.0, -1.2357456586609616, 20.0, -0.6227000677227368, -0.4974665666049227, 40.0, -0.916259654445507, 0.0, 0.0, 0.0, 100.0, -3.5919574620204124, 0.0, 40.0, 0.0, -0.3273156422706913, 0.0, 0.0, 0.0, 60.0, 20.0, 57.69796244966457, 39.56779556866996, 20.0, 0.0, 0.0, 57.53930894199935, -19.299285835013862, 0.0, -3.201951531289687, 0.0, 0.0, -0.7449076418731182, 40.0, 0.0, 0.0, -10.645281755720587, 69.99926366275228, 60.0, 0.0, 39.52426408909066, 0.0, 100.0, -5.353668582079455, 0.0, -0.7588280028403882, 55.34510042236977, 0.0, 60.0, 0.0, -6.297909044659717, -10.716066122409357, 0.0, -8.308710196231962, 20.0, 0.0, 40.0, -0.8157047017840191, 0.0, 0.0, 0.0, 159.569336025785, 0.0, 60.0, -0.8707011854509905, 0.0, 60.0, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 90.0, 90.0, 90.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 80.0, 80.0, 80.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [0.0, 0.0, 0.0, 0.0, -10.0, -20.0, 0.0, -15.460839069310174, 0.0, -90.0, 0.0, 0.0, 0.0, -67.71222713072164, -11.131976566259759, 0.0, -0.9596259137161522, -10.0, -9.314561185820079, -0.26751774806981765, -0.9525538931812361, 0.0, -22.337967884505943, 0.0, -50.0, 0.0, -7.981881814553995, 0.0, -20.0, -30.0, 0.0, -33.924847464729574, 0.0, 0.0, -30.0, -20.0, 0.0, 0.0, 0.0, -26.44297811316587, 0.0, -19.058567877036538, 0.0, -28.187721299030425, -10.0, -1.2180793205913287, 0.0, -3.2148273945232066, -30.0, -0.666623400603128, -0.2436499070540843, 0.0, -37.92061709656887, -18.685781726338924, -2.148302251282092, 0.0, 0.0, -1.8882504358143404, -2.039591476395622, -30.0, -77.63616811670617, 0.0, -30.0, -20.0, -0.9668368965259355, -20.0, 0.0, 0.0, -30.0, -10.0, 0.0, 0.0, -0.648790860876145, 0.0, 0.0, 0.0, -40.0, -20.0, -5.34026894177066, 0.0, 0.0, -20.0, 0.0, -0.08963355587790822, -0.1991468851625644, 0.0, -10.0, 0.0, 0.0, 0.0, -1.2357456586609616, -10.0, -0.6227000677227368, -0.4974665666049227, -20.0, -0.916259654445507, 0.0, 0.0, 0.0, -50.0, -3.5919574620204124, 0.0, -20.0, 0.0, -0.3273156422706913, 0.0, 0.0, 0.0, -30.0, -10.0, -32.302037550335434, -20.432204431330042, -10.0, 0.0, 0.0, -32.46069105800065, -19.299285835013862, 0.0, -3.201951531289687, 0.0, 0.0, -0.7449076418731182, -20.0, 0.0, 0.0, -10.645281755720587, -50.00073633724771, -30.0, 0.0, -20.475735910909343, 0.0, -50.0, -5.353668582079455, 0.0, -0.7588280028403882, -34.654899577630225, 0.0, -30.0, 0.0, -6.297909044659717, -10.716066122409357, 0.0, -8.308710196231962, -10.0, 0.0, -20.0, -0.8157047017840191, 0.0, 0.0, 0.0, -80.43066397421501, 0.0, -30.0, -0.8707011854509905, 0.0, -30.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6826121405319017, "mean_inference_ms": 1.1802193862160522, "mean_action_processing_ms": 0.23599654303053294, "mean_env_wait_ms": 0.5085244357790069, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0042913825648605445, "StateBufferConnector_ms": 0.0034484893653043518, "ViewRequirementAgentConnector_ms": 0.0816987578276616}, "num_episodes": 157, "episode_return_max": 180.0, "episode_return_min": -47.636168116706195, "episode_return_mean": 15.021648008172363}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 144000, "num_agent_steps_trained": 144000, "num_env_steps_sampled": 36000, "num_env_steps_trained": 36000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 315.9337021934691, "num_env_steps_trained_throughput_per_sec": 315.9337021934691, "timesteps_total": 36000, "num_env_steps_sampled_lifetime": 36000, "num_agent_steps_sampled_lifetime": 144000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 144000, "timers": {"training_iteration_time_ms": 14311.963, "restore_workers_time_ms": 0.014, "training_step_time_ms": 14311.894, "sample_time_ms": 1269.972, "learn_time_ms": 13020.961, "learn_throughput": 307.197, "synch_weights_time_ms": 18.873}, "counters": {"num_env_steps_sampled": 36000, "num_env_steps_trained": 36000, "num_agent_steps_sampled": 144000, "num_agent_steps_trained": 144000}, "done": false, "training_iteration": 9, "trial_id": "86f16_00000", "date": "2024-08-08_16-14-44", "timestamp": 1723148084, "time_this_iter_s": 12.683841705322266, "time_total_s": 129.14760613441467, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3aca39e50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 129.14760613441467, "iterations_since_restore": 9, "perf": {"cpu_util_percent": 37.82222222222222, "ram_util_percent": 80.47222222222223}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6772826079992538, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.388540090102676, "policy_loss": -0.011191831742651126, "vf_loss": 2.397791075495118, "vf_explained_var": -2.966028578737949e-06, "kl": 0.009704037895338309, "entropy": 1.4543873150297937, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 26790.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8825471010059118, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.8897280847964186, "policy_loss": -0.016732169565026805, "vf_loss": 2.9042917021860677, "vf_explained_var": -0.006765205971896648, "kl": 0.010842802112336377, "entropy": 1.4459518729398648, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 9120.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 40000, "num_env_steps_trained": 40000, "num_agent_steps_sampled": 160000, "num_agent_steps_trained": 160000}, "env_runners": {"episode_reward_max": 140.0, "episode_reward_min": -37.3077961621441, "episode_reward_mean": 19.502658219274544, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -70.0}, "policy_reward_max": {"adversary_policy": 70.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 10.679012345679013, "agent_policy": -12.534378817762493}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, -3.291292235347676, -4.453687300209698, -2.566380681319934, 0.0, -0.7618453530979408, 56.11079837933997, 0.0, -0.42830921781942477, 60.0, 68.95145903677036, 0.0, -3.23062630433847, 0.0, 60.0, 20.0, 0.0, 60.0, 0.0, 0.0, 38.61107655918954, 0.0, 40.0, -0.7798752601367398, 20.0, 0.0, -2.3771689700898575, 80.0, 80.0, 40.0, 60.0, -1.631463361095914, 120.0, 0.0, 26.37352656238931, 0.0, 0.0, 20.0, 39.85530597413336, 0.0, 20.0, -15.289763696178355, 80.0, 0.0, 11.974904786365599, 20.0, 0.0, 20.0, 100.0, -27.364240476435292, -16.695716602543662, 60.0, 0.0, 38.29879520491251, 19.656447953514846, 0.0, 0.0, 59.06117673135219, -32.13461238506623, 40.0, 59.46916737267945, 0.0, 20.0, -1.4237731023176015, -3.4666887537647373, 40.0, 0.0, 0.0, 40.0, -37.3077961621441, 0.0, 0.0, 0.0, -1.468635325183153, 0.0, 0.0, 60.0, 0.0, 80.0, 0.0, 0.0, 0.0, 60.0, 0.0, -3.523349637981158, 0.0, 0.0, 0.0, 0.0, 31.432783327101973, 40.0, 0.0, 80.0, -0.03711068598747036, 0.0, -30.279534082692454, -1.2495294742420582, 40.0, 40.0, 59.909412479468145, 0.0, 0.0, 26.883402540433337, 0.0, 20.0, 0.0, 74.58587452838634, 0.0, -1.775488813288817, 20.0, 0.0, 100.0, 0.0, 0.0, -0.1319392101259309, 0.0, 120.0, -9.28995401367632, 0.0, 60.0, 0.0, 0.0, 0.0, 0.0, 19.73504581005242, 0.0, 0.0, 0.0, 19.483753515064137, 80.0, 0.0, 39.830441134977875, 38.90249089781875, -0.858869907703752, 78.26159758316699, 0.0, 0.0, 100.0, 12.838287570424008, -0.9272908161604754, 60.0, 54.6379182225158, 0.0, 40.0, 0.0, -3.6817437386147365, 60.0, 20.0, 0.0, 40.0, 0.0, 0.0, 36.43545211613781, -1.383466655379928, -2.962377222257397, 0.0, 0.0, -0.012902461162481726, 0.0, 140.0, 98.9169451426433, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [0.0, -3.291292235347676, -4.453687300209698, -2.566380681319934, 0.0, -0.7618453530979408, -33.889201620660025, 0.0, -0.42830921781942477, -30.0, -51.04854096322964, 0.0, -3.23062630433847, 0.0, -30.0, -10.0, 0.0, -30.0, 0.0, 0.0, -21.38892344081046, 0.0, -20.0, -0.7798752601367398, -10.0, 0.0, -2.3771689700898575, -40.0, -40.0, -20.0, -30.0, -1.631463361095914, -60.0, 0.0, -33.6264734376107, 0.0, 0.0, -10.0, -20.14469402586664, 0.0, -10.0, -15.289763696178355, -40.0, 0.0, -18.0250952136344, -10.0, 0.0, -10.0, -50.0, -27.364240476435292, -16.695716602543662, -30.0, 0.0, -21.701204795087488, -10.343552046485154, 0.0, 0.0, -30.938823268647816, -32.13461238506623, -20.0, -30.530832627320553, 0.0, -10.0, -1.4237731023176015, -3.4666887537647373, -20.0, 0.0, 0.0, -20.0, -37.3077961621441, 0.0, 0.0, 0.0, -1.468635325183153, 0.0, 0.0, -30.0, 0.0, -40.0, 0.0, 0.0, 0.0, -30.0, 0.0, -3.523349637981158, 0.0, 0.0, 0.0, 0.0, -28.567216672898027, -20.0, 0.0, -40.0, -0.03711068598747036, 0.0, -30.279534082692454, -1.2495294742420582, -20.0, -20.0, -30.090587520531855, 0.0, 0.0, -33.11659745956666, 0.0, -10.0, 0.0, -45.41412547161365, 0.0, -1.775488813288817, -10.0, 0.0, -50.0, 0.0, 0.0, -0.1319392101259309, 0.0, -60.0, -9.28995401367632, 0.0, -30.0, 0.0, 0.0, 0.0, 0.0, -10.264954189947579, 0.0, 0.0, 0.0, -10.516246484935861, -40.0, 0.0, -20.169558865022122, -21.09750910218125, -0.858869907703752, -41.73840241683301, 0.0, 0.0, -50.0, -17.161712429575992, -0.9272908161604754, -30.0, -35.36208177748419, 0.0, -20.0, 0.0, -3.6817437386147365, -30.0, -10.0, 0.0, -20.0, 0.0, 0.0, -23.564547883862193, -1.383466655379928, -2.962377222257397, 0.0, 0.0, -0.012902461162481726, 0.0, -70.0, -51.08305485735669, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6816591880436097, "mean_inference_ms": 1.176620472323322, "mean_action_processing_ms": 0.23558286629568279, "mean_env_wait_ms": 0.5068833709991574, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005216215863639926, "StateBufferConnector_ms": 0.004351654170471945, "ViewRequirementAgentConnector_ms": 0.09686424408429935}, "num_episodes": 162, "episode_return_max": 140.0, "episode_return_min": -37.3077961621441, "episode_return_mean": 19.502658219274544}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 160000, "num_agent_steps_trained": 160000, "num_env_steps_sampled": 40000, "num_env_steps_trained": 40000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 306.54677322426886, "num_env_steps_trained_throughput_per_sec": 306.54677322426886, "timesteps_total": 40000, "num_env_steps_sampled_lifetime": 40000, "num_agent_steps_sampled_lifetime": 160000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 160000, "timers": {"training_iteration_time_ms": 14185.626, "restore_workers_time_ms": 0.014, "training_step_time_ms": 14185.558, "sample_time_ms": 1263.003, "learn_time_ms": 12902.166, "learn_throughput": 310.025, "synch_weights_time_ms": 18.465}, "counters": {"num_env_steps_sampled": 40000, "num_env_steps_trained": 40000, "num_agent_steps_sampled": 160000, "num_agent_steps_trained": 160000}, "done": false, "training_iteration": 10, "trial_id": "86f16_00000", "date": "2024-08-08_16-14-57", "timestamp": 1723148097, "time_this_iter_s": 13.061983823776245, "time_total_s": 142.20958995819092, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3aca92d30>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 142.20958995819092, "iterations_since_restore": 10, "perf": {"cpu_util_percent": 37.48888888888889, "ram_util_percent": 80.55555555555556}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7071164835640724, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.5358432507684046, "policy_loss": -0.011011522536296876, "vf_loss": 2.5451111848049974, "vf_explained_var": -1.1590757268540403e-05, "kl": 0.008717691273886158, "entropy": 1.4346792369024128, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 29610.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8814439453495045, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.997287019590537, "policy_loss": -0.018006466987814444, "vf_loss": 3.0128616226216156, "vf_explained_var": -0.0030217785388231277, "kl": 0.012159312058257845, "entropy": 1.451860153178374, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 10080.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 44000, "num_env_steps_trained": 44000, "num_agent_steps_sampled": 176000, "num_agent_steps_trained": 176000}, "env_runners": {"episode_reward_max": 200.0, "episode_reward_min": -23.12549756255609, "episode_reward_mean": 19.710666736113602, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 158, "episodes_timesteps_total": 3950, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -100.0}, "policy_reward_max": {"adversary_policy": 100.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 10.632911392405063, "agent_policy": -12.18806744110159}, "custom_metrics": {}, "hist_stats": {"episode_reward": [79.62561222142548, 60.0, 0.0, 40.0, 40.0, 0.0, 0.0, 0.0, 95.29730805562907, 60.0, 71.55666169705844, 20.0, 59.25894637638552, 0.0, 0.0, 60.0, 80.0, 0.0, 0.0, -1.8094795904457894, 0.0, 0.0, 0.0, 60.0, -3.3944173809268174, 0.0, 20.0, 19.950157949844687, 0.0, 0.0, -3.954145942253562, 200.0, 0.0, 0.0, 0.0, -0.8046404077140046, 0.0, 0.0, 40.0, 20.0, 37.805884840704586, 0.0, 40.0, 79.77319753731027, -8.129711431403125, 0.0, -23.12549756255609, 0.0, 30.96795764740783, 0.0, 0.0, -1.0198518609164986, 38.428649489019236, 39.2884014091843, 0.0, -0.257206085733237, 40.0, 0.0, 0.0, 60.0, 0.0, 40.0, -0.12109118077440528, 80.0, 58.954751599019545, 0.0, 0.0, -19.87361087529016, -11.055982377072674, -10.056945538561834, 20.0, 0.0, 0.0, 100.0, -0.45287990909453457, 0.0, 0.0, 0.0, 58.29575845384435, 40.0, -4.011273718658067, 40.0, 40.0, 0.0, -1.7400486646930358, 79.89321839420549, 0.0, 0.0, -1.6175845512172449, 0.0, -0.2673856117036144, -0.08737511626243366, 0.0, 0.0, 0.0, 60.0, -3.673045474677296, 0.0, 58.75338574645177, 0.0, 100.0, 40.0, -0.6924568799381159, 38.27010615388363, 0.0, -22.242182930200222, 0.0, 0.0, 54.16439346961131, 0.0, -14.625114415386026, 0.0, 0.0, 40.0, -2.0120865129703303, -2.0862474826044517, 0.0, 58.49920382165439, 60.0, 40.0, -3.3991103971541206, 38.395679160758064, 60.0, 20.0, -20.262968952424636, -6.4602911860418075, -0.6072563174429813, 40.0, -0.7842683525706584, 0.0, 0.0, 60.0, 59.55981838429673, 56.12612628248526, 0.0, 0.0, 0.0, 0.0, 80.0, 60.0, -0.4740341786256519, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 100.0, 0.0, 40.0, 40.0, -1.39785047701803, 20.0, 0.0, 16.390563285494743, 0.0, 37.07996761136524, 58.44563608124052], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 100.0, 100.0, 100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0], "policy_agent_policy_reward": [-40.374387778574516, -30.0, 0.0, -20.0, -20.0, 0.0, 0.0, 0.0, -54.702691944370926, -30.0, -48.443338302941555, -10.0, -30.74105362361447, 0.0, 0.0, -30.0, -40.0, 0.0, 0.0, -1.8094795904457894, 0.0, 0.0, 0.0, -30.0, -3.3944173809268174, 0.0, -10.0, -10.049842050155311, 0.0, 0.0, -3.954145942253562, -100.0, 0.0, 0.0, 0.0, -0.8046404077140046, 0.0, 0.0, -20.0, -10.0, -22.194115159295414, 0.0, -20.0, -40.22680246268973, -8.129711431403125, 0.0, -23.12549756255609, 0.0, -29.03204235259217, 0.0, 0.0, -1.0198518609164986, -21.571350510980768, -20.711598590815697, 0.0, -0.257206085733237, -20.0, 0.0, 0.0, -30.0, 0.0, -20.0, -0.12109118077440528, -40.0, -31.045248400980455, 0.0, 0.0, -19.87361087529016, -11.055982377072674, -10.056945538561834, -10.0, 0.0, 0.0, -50.0, -0.45287990909453457, 0.0, 0.0, 0.0, -31.70424154615565, -20.0, -4.011273718658067, -20.0, -20.0, 0.0, -1.7400486646930358, -40.10678160579452, 0.0, 0.0, -1.6175845512172449, 0.0, -0.2673856117036144, -0.08737511626243366, 0.0, 0.0, 0.0, -30.0, -3.673045474677296, 0.0, -31.246614253548234, 0.0, -50.0, -20.0, -0.6924568799381159, -21.72989384611637, 0.0, -52.24218293020022, 0.0, 0.0, -35.83560653038869, 0.0, -14.625114415386026, 0.0, 0.0, -20.0, -2.0120865129703303, -2.0862474826044517, 0.0, -31.500796178345603, -30.0, -20.0, -3.3991103971541206, -21.604320839241936, -30.0, -10.0, -20.262968952424636, -6.4602911860418075, -0.6072563174429813, -20.0, -0.7842683525706584, 0.0, 0.0, -30.0, -30.440181615703274, -33.87387371751474, 0.0, 0.0, 0.0, 0.0, -40.0, -30.0, -0.4740341786256519, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -50.0, 0.0, -20.0, -20.0, -1.39785047701803, -10.0, 0.0, -13.609436714505257, 0.0, -22.920032388634755, -31.55436391875948]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6825774877915832, "mean_inference_ms": 1.1780906954767167, "mean_action_processing_ms": 0.23650024272998335, "mean_env_wait_ms": 0.5074487022476438, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0047825559785094444, "StateBufferConnector_ms": 0.003630677355995661, "ViewRequirementAgentConnector_ms": 0.1017088377023045}, "num_episodes": 158, "episode_return_max": 200.0, "episode_return_min": -23.12549756255609, "episode_return_mean": 19.710666736113602}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 176000, "num_agent_steps_trained": 176000, "num_env_steps_sampled": 44000, "num_env_steps_trained": 44000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 294.0425076902334, "num_env_steps_trained_throughput_per_sec": 294.0425076902334, "timesteps_total": 44000, "num_env_steps_sampled_lifetime": 44000, "num_agent_steps_sampled_lifetime": 176000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 176000, "timers": {"training_iteration_time_ms": 14263.415, "restore_workers_time_ms": 0.014, "training_step_time_ms": 14263.347, "sample_time_ms": 1265.12, "learn_time_ms": 12977.656, "learn_throughput": 308.222, "synch_weights_time_ms": 18.836}, "counters": {"num_env_steps_sampled": 44000, "num_env_steps_trained": 44000, "num_agent_steps_sampled": 176000, "num_agent_steps_trained": 176000}, "done": false, "training_iteration": 11, "trial_id": "86f16_00000", "date": "2024-08-08_16-15-11", "timestamp": 1723148111, "time_this_iter_s": 13.673040866851807, "time_total_s": 155.88263082504272, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3aca92f70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 155.88263082504272, "iterations_since_restore": 11, "perf": {"cpu_util_percent": 51.464999999999996, "ram_util_percent": 80.075}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7080986996703114, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.593264742142765, "policy_loss": -0.01096522002233232, "vf_loss": 2.6025136672435925, "vf_explained_var": 1.1214825278478312e-05, "kl": 0.0085813027488161, "entropy": 1.424871388563873, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 32430.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.903200504463166, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.373711226073404, "policy_loss": -0.016209970678028186, "vf_loss": 3.387707195927699, "vf_explained_var": -0.004051126539707184, "kl": 0.011069980251530168, "entropy": 1.436225108553966, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 11040.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 48000, "num_env_steps_trained": 48000, "num_agent_steps_sampled": 192000, "num_agent_steps_trained": 192000}, "env_runners": {"episode_reward_max": 140.0, "episode_reward_min": -42.472185643961595, "episode_reward_mean": 19.887286961196846, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -70.0}, "policy_reward_max": {"adversary_policy": 70.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 10.987654320987655, "agent_policy": -13.07567600176612}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 20.0, 0.0, -0.48114461847913903, 80.0, 59.52123874126815, 40.0, 55.48053588842171, 60.0, 0.0, 39.014214186652815, 60.0, 20.0, -26.61968594397173, -0.1697261216331436, 43.8536734508749, 0.0, 80.0, -0.16895062496781965, 81.72484297222563, 0.0, 60.0, 60.0, 20.0, 40.0, -5.945765383273353, 100.0, -0.26728013783764104, -0.18096611163845866, 59.46769129969924, -0.5558322389701043, 20.0, 0.0, -2.495471670123929, 0.0, 40.0, 20.0, -3.950299334327989, -26.40163634090039, 7.7497460767660336, 0.0, 40.0, 0.0, 0.0, 0.0, -0.08363217800224754, 100.0, -10.258287985078217, 80.0, 59.720015476321905, 20.0, 59.99077050246373, 40.0, 40.0, 0.0, 0.0, -0.33114785042635875, 40.0, 40.0, 32.566536198521035, 0.0, 0.0, 40.0, -12.164283484099887, 0.0, -1.9324312644969943, 80.0, -42.472185643961595, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -2.8678160258169587, 0.0, 0.0, 0.0, 0.0, 0.0, -2.9456443734943303, 0.0, 60.0, -4.361656922538013, -1.4108993321993202, 40.0, -6.073971291611828, 0.0, 40.0, 0.0, 0.0, 0.0, 120.0, 0.0, -0.24138513586116184, 0.0, -10.268051474713253, 0.0, 20.0, -6.974804790487222, -13.345701406964515, 0.0, 60.0, 60.0, 20.0, 60.0, 20.0, 0.0, 0.0, 80.0, -3.5220419248729193, 39.352722022609015, 0.0, 0.0, 59.87189690281158, -1.5021421042873389, 0.0, 20.0, 0.0, 0.0, 40.0, 0.0, -7.456916893189993, 0.0, -20.749832239648065, -1.6168943202022101, 0.0, 0.0, 60.0, 57.99564745224147, 0.0, 60.0, 39.06815000369518, 60.0, 0.0, 20.0, 0.0, 0.0, 0.0, 40.0, 60.0, 0.0, 140.0, 60.0, 0.0, 118.06195651226085, 0.0, 0.0, -5.35634128164817, 0.0, 60.0, 0.0, 57.80636364041345, -0.1026330635107009, 20.0, 80.0, -0.9153165238252803, 0.0, -5.3147375762973, 0.0, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [0.0, -10.0, 0.0, -0.48114461847913903, -40.0, -30.47876125873185, -20.0, -34.51946411157828, -30.0, 0.0, -20.985785813347192, -30.0, -10.0, -26.61968594397173, -0.1697261216331436, -46.1463265491251, 0.0, -40.0, -0.16895062496781965, -68.27515702777437, 0.0, -30.0, -30.0, -10.0, -20.0, -5.945765383273353, -50.0, -0.26728013783764104, -0.18096611163845866, -30.532308700300764, -0.5558322389701043, -10.0, 0.0, -2.495471670123929, 0.0, -20.0, -10.0, -3.950299334327989, -26.40163634090039, -22.250253923233974, 0.0, -20.0, 0.0, 0.0, 0.0, -0.08363217800224754, -50.0, -10.258287985078217, -40.0, -30.2799845236781, -10.0, -30.009229497536275, -20.0, -20.0, 0.0, 0.0, -0.33114785042635875, -20.0, -20.0, -27.43346380147896, 0.0, 0.0, -20.0, -12.164283484099887, 0.0, -1.9324312644969943, -40.0, -42.472185643961595, -20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -2.8678160258169587, 0.0, 0.0, 0.0, 0.0, 0.0, -2.9456443734943303, 0.0, -30.0, -4.361656922538013, -1.4108993321993202, -20.0, -6.073971291611828, 0.0, -20.0, 0.0, 0.0, 0.0, -60.0, 0.0, -0.24138513586116184, 0.0, -10.268051474713253, 0.0, -10.0, -6.974804790487222, -13.345701406964515, 0.0, -30.0, -30.0, -10.0, -30.0, -10.0, 0.0, 0.0, -40.0, -3.5220419248729193, -20.64727797739099, 0.0, 0.0, -30.128103097188426, -31.502142104287337, 0.0, -10.0, 0.0, 0.0, -20.0, 0.0, -7.456916893189993, 0.0, -20.749832239648065, -1.6168943202022101, 0.0, 0.0, -30.0, -32.00435254775853, 0.0, -30.0, -50.93184999630481, -30.0, 0.0, -10.0, 0.0, 0.0, 0.0, -20.0, -30.0, 0.0, -70.0, -30.0, 0.0, -61.93804348773914, 0.0, 0.0, -5.35634128164817, 0.0, -30.0, 0.0, -32.19363635958654, -0.1026330635107009, -10.0, -40.0, -0.9153165238252803, 0.0, -5.3147375762973, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6803265721084646, "mean_inference_ms": 1.1723261877853757, "mean_action_processing_ms": 0.23513717904603754, "mean_env_wait_ms": 0.5048191595430648, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004350108864866657, "StateBufferConnector_ms": 0.003354122609268, "ViewRequirementAgentConnector_ms": 0.0907493962181939}, "num_episodes": 162, "episode_return_max": 140.0, "episode_return_min": -42.472185643961595, "episode_return_mean": 19.887286961196846}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 192000, "num_agent_steps_trained": 192000, "num_env_steps_sampled": 48000, "num_env_steps_trained": 48000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 327.0482284173512, "num_env_steps_trained_throughput_per_sec": 327.0482284173512, "timesteps_total": 48000, "num_env_steps_sampled_lifetime": 48000, "num_agent_steps_sampled_lifetime": 192000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 192000, "timers": {"training_iteration_time_ms": 14235.304, "restore_workers_time_ms": 0.015, "training_step_time_ms": 14235.236, "sample_time_ms": 1256.393, "learn_time_ms": 12958.332, "learn_throughput": 308.682, "synch_weights_time_ms": 18.783}, "counters": {"num_env_steps_sampled": 48000, "num_env_steps_trained": 48000, "num_agent_steps_sampled": 192000, "num_agent_steps_trained": 192000}, "done": false, "training_iteration": 12, "trial_id": "86f16_00000", "date": "2024-08-08_16-15-24", "timestamp": 1723148124, "time_this_iter_s": 12.234947204589844, "time_total_s": 168.11757802963257, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3acdc43a0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 168.11757802963257, "iterations_since_restore": 12, "perf": {"cpu_util_percent": 35.33888888888889, "ram_util_percent": 81.47222222222223}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7192334659450443, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.5356196847367793, "policy_loss": -0.013275954117981967, "vf_loss": 2.5470504578123703, "vf_explained_var": 1.1286689034590484e-05, "kl": 0.009225729491003688, "entropy": 1.4238705610552578, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 35250.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.028002311848104, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.2863804712270697, "policy_loss": -0.016364066596725024, "vf_loss": 3.300719950348139, "vf_explained_var": 0.002295484021306038, "kl": 0.010122885760425176, "entropy": 1.3989456240087748, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 12000.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 52000, "num_env_steps_trained": 52000, "num_agent_steps_sampled": 208000, "num_agent_steps_trained": 208000}, "env_runners": {"episode_reward_max": 140.0, "episode_reward_min": -23.66203521682788, "episode_reward_mean": 20.26678925957404, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 157, "episodes_timesteps_total": 3925, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -70.0}, "policy_reward_max": {"adversary_policy": 70.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 11.019108280254777, "agent_policy": -12.790535581190293}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, -2.5410584726346013, -0.5241310343222716, -9.190277734604186, 40.0, 80.0, 0.0, 60.0, 60.0, 120.0, 0.0, 0.0, 0.0, -3.6298165647746563, -3.0313908360416866, 40.0, 140.0, 0.0, 0.0, -7.766922305329327, 60.0, 0.0, -23.66203521682788, 0.0, 0.0, 0.0, 0.0, 20.0, 80.0, 0.0, 77.6607268767333, 40.0, -18.576809939467633, 0.0, 58.68886217667979, -0.2013504198806626, -0.8992595429002037, 59.64720968459248, 0.0, 13.976756280269766, 0.0, 40.0, -17.11126011986607, 40.0, 0.0, 100.0, 0.0, 60.0, 0.0, 118.48167712503522, 0.0, 0.0, 60.0, -0.19888472775015376, 0.0, -5.6801568132244915, 11.557393146235944, 80.0, 40.0, 0.0, 0.0, -19.33428673692403, 140.0, -12.372752444264357, 0.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.8084072652226437, 20.0, 0.0, 38.66793912802014, 0.0, 0.0, 0.0, -1.5034717509049134, 58.11836043719421, 0.0, -3.0702529119919753, 59.30186869029177, 0.0, 39.62152746089831, 91.82015142672837, 0.0, -6.47570886804988, 39.23824204301812, -1.6218651905308445, 40.0, 20.0, 0.0, 40.0, 40.0, 99.9540902500744, 40.0, 0.0, 20.0, 100.0, 99.44864021134633, 0.0, -1.8440252359346387, 0.0, 0.0, 0.0, 40.0, 60.0, 60.0, -14.251125087616956, 17.72130781474932, -6.702388466580925, -0.4131401657466216, -1.0465343752713707, 40.0, 39.466184281620585, -7.708584424266149, 0.0, 0.0, 60.0, 0.0, -5.6401866421418525, 0.0, -11.170261962039412, -6.3895946031160324, -2.3520758346052544, -3.4946889578211637, 60.0, 39.203904747727066, 0.0, -1.3311642367291021, 37.124630983652246, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, -4.34919875874786, 0.0, 40.0, 20.0, 40.0, 9.006230054935013, 60.0, 59.06975931781295, 0.0, 38.911636213758136, 0.0, -17.114332623696427, -1.572999768027652, 100.0, 20.0, 0.0, 0.0, 0.0, 38.779215439604585], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0], "policy_agent_policy_reward": [0.0, -2.5410584726346013, -0.5241310343222716, -9.190277734604186, -20.0, -40.0, 0.0, -30.0, -30.0, -60.0, 0.0, 0.0, 0.0, -3.6298165647746563, -3.0313908360416866, -20.0, -70.0, 0.0, 0.0, -7.766922305329327, -30.0, 0.0, -23.66203521682788, 0.0, 0.0, 0.0, 0.0, -10.0, -40.0, 0.0, -42.33927312326668, -20.0, -18.576809939467633, 0.0, -31.31113782332021, -0.2013504198806626, -0.8992595429002037, -30.35279031540752, 0.0, -16.02324371973023, 0.0, -20.0, -17.11126011986607, -20.0, 0.0, -50.0, 0.0, -30.0, 0.0, -61.518322874964795, 0.0, 0.0, -30.0, -0.19888472775015376, 0.0, -5.6801568132244915, -18.442606853764055, -40.0, -20.0, 0.0, 0.0, -19.33428673692403, -70.0, -12.372752444264357, 0.0, -10.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.8084072652226437, -10.0, 0.0, -21.332060871979863, 0.0, 0.0, 0.0, -1.5034717509049134, -31.881639562805788, 0.0, -3.0702529119919753, -30.698131309708238, 0.0, -20.378472539101693, -58.17984857327163, 0.0, -6.47570886804988, -20.76175795698188, -1.6218651905308445, -20.0, -10.0, 0.0, -20.0, -20.0, -50.04590974992559, -20.0, 0.0, -10.0, -50.0, -50.55135978865367, 0.0, -1.8440252359346387, 0.0, 0.0, 0.0, -20.0, -30.0, -30.0, -14.251125087616956, -12.27869218525068, -6.702388466580925, -0.4131401657466216, -1.0465343752713707, -20.0, -20.53381571837942, -7.708584424266149, 0.0, 0.0, -30.0, 0.0, -5.6401866421418525, 0.0, -11.170261962039412, -6.3895946031160324, -2.3520758346052544, -3.4946889578211637, -30.0, -20.79609525227293, 0.0, -1.3311642367291021, -22.875369016347754, 0.0, 0.0, 0.0, 0.0, 0.0, -10.0, -4.34919875874786, 0.0, -20.0, -10.0, -20.0, -20.993769945064983, -30.0, -30.930240682187048, 0.0, -21.088363786241864, 0.0, -17.114332623696427, -1.572999768027652, -50.0, -10.0, 0.0, 0.0, 0.0, -21.220784560395415]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6850931882239399, "mean_inference_ms": 1.1815718957455374, "mean_action_processing_ms": 0.23690023706152033, "mean_env_wait_ms": 0.5074114358339821, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004765030684744476, "StateBufferConnector_ms": 0.0032965544682399483, "ViewRequirementAgentConnector_ms": 0.10144520717062008}, "num_episodes": 157, "episode_return_max": 140.0, "episode_return_min": -23.66203521682788, "episode_return_mean": 20.26678925957404}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 208000, "num_agent_steps_trained": 208000, "num_env_steps_sampled": 52000, "num_env_steps_trained": 52000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 219.34840334342962, "num_env_steps_trained_throughput_per_sec": 219.34840334342962, "timesteps_total": 52000, "num_env_steps_sampled_lifetime": 52000, "num_agent_steps_sampled_lifetime": 208000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 208000, "timers": {"training_iteration_time_ms": 14632.844, "restore_workers_time_ms": 0.014, "training_step_time_ms": 14632.783, "sample_time_ms": 1270.619, "learn_time_ms": 13344.265, "learn_throughput": 299.754, "synch_weights_time_ms": 16.748}, "counters": {"num_env_steps_sampled": 52000, "num_env_steps_trained": 52000, "num_agent_steps_sampled": 208000, "num_agent_steps_trained": 208000}, "done": false, "training_iteration": 13, "trial_id": "86f16_00000", "date": "2024-08-08_16-15-42", "timestamp": 1723148142, "time_this_iter_s": 18.25082802772522, "time_total_s": 186.3684060573578, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3acdc4af0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 186.3684060573578, "iterations_since_restore": 13, "perf": {"cpu_util_percent": 64.08461538461538, "ram_util_percent": 82.55000000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7131317186228773, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.6512281175200823, "policy_loss": -0.012708792469880366, "vf_loss": 2.662104757711397, "vf_explained_var": -5.025495874120834e-06, "kl": 0.00916059682929543, "entropy": 1.3952938653053122, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 38070.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.0907643477121989, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.62667143928508, "policy_loss": -0.01715591492150755, "vf_loss": 3.641434609144926, "vf_explained_var": -0.0022268875191609064, "kl": 0.011963735082960496, "entropy": 1.404641922811667, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 12960.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 56000, "num_env_steps_trained": 56000, "num_agent_steps_sampled": 224000, "num_agent_steps_trained": 224000}, "env_runners": {"episode_reward_max": 140.0, "episode_reward_min": -29.041902622047512, "episode_reward_mean": 20.432279482921338, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -70.0}, "policy_reward_max": {"adversary_policy": 70.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 11.17283950617284, "agent_policy": -13.08623903559718}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-1.903585577091923, 40.0, 0.0, 0.0, 80.0, 0.0, 0.0, 60.0, 0.0, 0.0, 100.0, 60.0, 0.0, 40.0, 0.0, -12.665648397550822, 57.52927469160855, -10.313238864919096, 60.0, 40.0, 0.0, 40.0, 0.0, -19.766236820257156, -1.0949529368251565, 40.0, 0.0, 40.0, 19.653536424744146, 120.0, -7.9257623547254425, 39.233423305813474, 0.0, 0.0, 60.0, 20.0, 0.0, 59.76767500269922, 0.0, -2.6306679527357604, 59.45827510654656, 0.0, 60.0, 0.0, 60.0, 40.0, -2.1896406300142326, 60.0, 40.0, 0.0, 0.0, 0.0, 60.0, 0.0, 40.0, 0.0, 40.0, -0.9876638199550258, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0091589718547833, 20.0, 59.23273171413523, 80.0, -22.579960170597435, -9.611407119877317, 0.0, 0.0, 0.0, 0.0, 0.0, 58.6801913464935, -3.9691073102796954, 60.0, -3.7202618427662317, 10.80653761228687, 40.0, 0.0, 0.0, -7.76221190607996, -17.633789993917386, 0.0, 0.0, 0.0, -26.69733744909805, 118.58060825813223, 0.0, 0.0, 100.0, 20.0, 78.64196684503959, 20.0, 59.15621034042657, -17.133265907765725, -3.291325252002859, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 17.581215113491282, -17.144741285554485, 60.0, 40.0, 0.0, -4.458853244802808, 140.0, 40.0, 0.0, -1.5293937350722986, -14.60712520134289, 0.0, 120.0, -2.2264694658210447, 20.0, 59.83396564801836, -1.6351968543444728, 0.0, 0.0, -13.558556808531804, 60.0, 0.0, 40.0, 60.0, 79.13789252255862, 40.0, 0.0, 0.0, 0.0, 40.0, 0.0, 17.700221707513613, -4.2742963269725545, -29.041902622047512, 40.0, -3.453623002430165, -0.011992699226264225, -12.88410483146673, -2.5749247598252882, 0.0, 0.0, -0.5660131723266892, 80.0, 60.0, 0.0, 60.0, 0.0, 60.0, 0.0, -3.4454324330559816, 0.0, 80.0, 40.0, 40.0, 0.0, -0.6665996851155587, 0.0, 100.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0], "policy_agent_policy_reward": [-1.903585577091923, -20.0, 0.0, 0.0, -40.0, 0.0, 0.0, -30.0, 0.0, 0.0, -50.0, -30.0, 0.0, -20.0, 0.0, -12.665648397550822, -32.47072530839145, -10.313238864919096, -30.0, -20.0, 0.0, -20.0, 0.0, -19.766236820257156, -1.0949529368251565, -20.0, 0.0, -20.0, -10.346463575255852, -60.0, -7.9257623547254425, -20.766576694186522, 0.0, 0.0, -30.0, -10.0, 0.0, -30.232324997300783, 0.0, -2.6306679527357604, -30.54172489345344, 0.0, -30.0, 0.0, -30.0, -20.0, -2.1896406300142326, -30.0, -20.0, 0.0, 0.0, 0.0, -30.0, 0.0, -20.0, 0.0, -20.0, -0.9876638199550258, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0091589718547833, -10.0, -30.767268285864773, -40.0, -22.579960170597435, -9.611407119877317, 0.0, 0.0, 0.0, 0.0, 0.0, -31.319808653506506, -3.9691073102796954, -30.0, -3.7202618427662317, -19.19346238771313, -20.0, 0.0, 0.0, -7.76221190607996, -17.633789993917386, 0.0, 0.0, 0.0, -26.69733744909805, -61.41939174186776, 0.0, 0.0, -50.0, -10.0, -41.35803315496041, -10.0, -30.843789659573442, -17.133265907765725, -3.291325252002859, -20.0, 0.0, 0.0, 0.0, 0.0, 0.0, -12.41878488650872, -17.144741285554485, -30.0, -20.0, 0.0, -4.458853244802808, -70.0, -20.0, 0.0, -1.5293937350722986, -14.60712520134289, 0.0, -60.0, -2.2264694658210447, -10.0, -30.166034351981644, -1.6351968543444728, 0.0, 0.0, -13.558556808531804, -30.0, 0.0, -20.0, -30.0, -40.86210747744138, -20.0, 0.0, 0.0, 0.0, -20.0, 0.0, -12.299778292486389, -4.2742963269725545, -29.041902622047512, -20.0, -3.453623002430165, -0.011992699226264225, -12.88410483146673, -2.5749247598252882, 0.0, 0.0, -0.5660131723266892, -40.0, -30.0, 0.0, -30.0, 0.0, -30.0, 0.0, -3.4454324330559816, 0.0, -40.0, -20.0, -20.0, 0.0, -0.6665996851155587, 0.0, -50.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.689480046211345, "mean_inference_ms": 1.1895411361093144, "mean_action_processing_ms": 0.23853711852704196, "mean_env_wait_ms": 0.5106034581529946, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005495327490347403, "StateBufferConnector_ms": 0.00514439594598464, "ViewRequirementAgentConnector_ms": 0.11341056705992898}, "num_episodes": 162, "episode_return_max": 140.0, "episode_return_min": -29.041902622047512, "episode_return_mean": 20.432279482921338}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 224000, "num_agent_steps_trained": 224000, "num_env_steps_sampled": 56000, "num_env_steps_trained": 56000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 306.8297330697988, "num_env_steps_trained_throughput_per_sec": 306.8297330697988, "timesteps_total": 56000, "num_env_steps_sampled_lifetime": 56000, "num_agent_steps_sampled_lifetime": 224000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 224000, "timers": {"training_iteration_time_ms": 14000.847, "restore_workers_time_ms": 0.014, "training_step_time_ms": 14000.787, "sample_time_ms": 1265.258, "learn_time_ms": 12718.296, "learn_throughput": 314.508, "synch_weights_time_ms": 16.569}, "counters": {"num_env_steps_sampled": 56000, "num_env_steps_trained": 56000, "num_agent_steps_sampled": 224000, "num_agent_steps_trained": 224000}, "done": false, "training_iteration": 14, "trial_id": "86f16_00000", "date": "2024-08-08_16-15-55", "timestamp": 1723148155, "time_this_iter_s": 13.067404747009277, "time_total_s": 199.43581080436707, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3acdc4820>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 199.43581080436707, "iterations_since_restore": 14, "perf": {"cpu_util_percent": 42.900000000000006, "ram_util_percent": 82.34444444444445}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6894074079838205, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.7018981951348326, "policy_loss": -0.012591461682401545, "vf_loss": 2.7126366725627413, "vf_explained_var": 1.618244969252999e-06, "kl": 0.0092647988856537, "entropy": 1.367230659681009, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 40890.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1113439206033946, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.414717147499323, "policy_loss": -0.013805589586991119, "vf_loss": 3.4267031957705814, "vf_explained_var": -0.0033025513713558514, "kl": 0.009097718160774804, "entropy": 1.42513755025963, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 13920.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 60000, "num_env_steps_trained": 60000, "num_agent_steps_sampled": 240000, "num_agent_steps_trained": 240000}, "env_runners": {"episode_reward_max": 240.0, "episode_reward_min": -32.531572492371936, "episode_reward_mean": 22.93712803824788, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -120.0}, "policy_reward_max": {"adversary_policy": 120.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 12.345679012345679, "agent_policy": -14.099908998789157}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 60.0, 40.0, -6.520564210485323, -14.274424796653728, 80.0, 0.0, 0.0, -32.531572492371936, 80.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, -1.0633856551992105, 38.70306915942435, 0.0, -0.09360909892026537, 40.0, 60.0, 40.0, 159.32343040740693, 60.0, 43.75910091851947, 0.0, 0.0, 60.0, -7.272024622017245, 0.0, -2.168383541425558, 0.0, 0.0, 60.0, 40.0, 0.0, 60.0, -5.58732492351419, 0.0, 0.0, 49.37768431271825, 80.0, 0.0, 0.0, -28.026670827546475, 0.0, 0.0, -7.001029909104931, 37.78633445202231, 60.0, 0.0, 77.9165322251085, 0.0, 0.0, 120.0, 0.0, 220.0, -14.887521951102528, 40.0, 40.0, 60.0, 0.0, 59.91457014209914, 0.0, 0.0, 60.0, 0.0, 0.0, -4.093358577537877, 0.0, 60.0, -1.9078164897105787, 20.0, 0.0, -0.4510741924641537, 60.0, 0.0, 40.0, 0.0, 0.0, 60.0, 60.0, 0.0, 0.0, -0.9093233370726561, 60.0, 60.0, 40.0, 0.0, 0.0, 40.0, 0.0, 0.0, 0.0, -0.4393603905376964, 40.0, 20.0, 0.0, 0.0, 60.0, 40.0, 0.0, 240.0, 20.0, -0.23140324731797168, 0.0, 0.0, 60.0, -0.41971756365448587, 60.0, 0.0, -7.658902874759373, 0.0, 80.0, 59.71737570788676, 19.251860515978382, 40.0, 0.0, 0.0, 0.0, 70.02508935119904, 20.0, 60.0, 60.0, -2.68970726598193, 56.83180220623177, -27.5667260132447, 0.0, 80.0, 0.0, 0.0, 0.0, -4.7149133026901175, 0.0, -7.907572884781453, 0.0, 0.0, 40.0, 120.0, 60.0, 0.0, -2.592521515579928, -3.98395872197987, 60.0, 60.0, 80.0, 0.0, -0.9945984418836029, 0.0, 40.0, -0.45121839680440146, 20.0, -2.413951232152166, -26.57379377528537, -0.2628269063503397, 20.0, 0.0, -1.1028500443080869], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 80.0, 80.0, 80.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 110.0, 110.0, 110.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 120.0, 120.0, 120.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 60.0, 60.0, 60.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [0.0, 0.0, 0.0, -30.0, -20.0, -36.520564210485325, -14.274424796653728, -40.0, 0.0, 0.0, -32.531572492371936, -40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -10.0, -1.0633856551992105, -21.296930840575648, 0.0, -0.09360909892026537, -20.0, -30.0, -20.0, -80.67656959259308, -30.0, -46.24089908148053, 0.0, 0.0, -30.0, -7.272024622017245, 0.0, -2.168383541425558, 0.0, 0.0, -30.0, -20.0, 0.0, -30.0, -5.58732492351419, 0.0, 0.0, -40.62231568728175, -40.0, 0.0, 0.0, -28.026670827546475, 0.0, 0.0, -7.001029909104931, -22.21366554797769, -30.0, 0.0, -42.083467774891496, 0.0, 0.0, -60.0, 0.0, -110.0, -14.887521951102528, -20.0, -20.0, -30.0, 0.0, -30.08542985790087, 0.0, 0.0, -30.0, 0.0, 0.0, -4.093358577537877, 0.0, -30.0, -1.9078164897105787, -10.0, 0.0, -0.4510741924641537, -30.0, 0.0, -20.0, 0.0, 0.0, -30.0, -30.0, 0.0, 0.0, -0.9093233370726561, -30.0, -30.0, -20.0, 0.0, 0.0, -20.0, 0.0, 0.0, 0.0, -0.4393603905376964, -20.0, -10.0, 0.0, 0.0, -30.0, -20.0, 0.0, -120.0, -10.0, -0.23140324731797168, 0.0, 0.0, -30.0, -0.41971756365448587, -30.0, 0.0, -7.658902874759373, 0.0, -40.0, -30.282624292113248, -10.74813948402162, -20.0, 0.0, 0.0, 0.0, -49.97491064880096, -10.0, -30.0, -30.0, -2.68970726598193, -33.168197793768236, -27.5667260132447, 0.0, -40.0, 0.0, 0.0, 0.0, -4.7149133026901175, 0.0, -7.907572884781453, 0.0, 0.0, -20.0, -60.0, -30.0, 0.0, -2.592521515579928, -3.98395872197987, -30.0, -30.0, -40.0, 0.0, -0.9945984418836029, 0.0, -20.0, -0.45121839680440146, -10.0, -2.413951232152166, -26.57379377528537, -0.2628269063503397, -10.0, 0.0, -1.1028500443080869]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6882576458431944, "mean_inference_ms": 1.1896909662993302, "mean_action_processing_ms": 0.2380527251244739, "mean_env_wait_ms": 0.5102524804913569, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005238070900057569, "StateBufferConnector_ms": 0.0034786300894654827, "ViewRequirementAgentConnector_ms": 0.09932878576678994}, "num_episodes": 162, "episode_return_max": 240.0, "episode_return_min": -32.531572492371936, "episode_return_mean": 22.93712803824788}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 240000, "num_agent_steps_trained": 240000, "num_env_steps_sampled": 60000, "num_env_steps_trained": 60000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 310.3026687332037, "num_env_steps_trained_throughput_per_sec": 310.3026687332037, "timesteps_total": 60000, "num_env_steps_sampled_lifetime": 60000, "num_agent_steps_sampled_lifetime": 240000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 240000, "timers": {"training_iteration_time_ms": 13602.605, "restore_workers_time_ms": 0.014, "training_step_time_ms": 13602.546, "sample_time_ms": 1249.752, "learn_time_ms": 12334.251, "learn_throughput": 324.3, "synch_weights_time_ms": 17.816}, "counters": {"num_env_steps_sampled": 60000, "num_env_steps_trained": 60000, "num_agent_steps_sampled": 240000, "num_agent_steps_trained": 240000}, "done": false, "training_iteration": 15, "trial_id": "86f16_00000", "date": "2024-08-08_16-16-08", "timestamp": 1723148168, "time_this_iter_s": 13.040357828140259, "time_total_s": 212.47616863250732, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3aca541f0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 212.47616863250732, "iterations_since_restore": 15, "perf": {"cpu_util_percent": 37.04736842105263, "ram_util_percent": 81.60526315789474}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7248636956121904, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.191267575059377, "policy_loss": -0.013276410803317706, "vf_loss": 2.2026817375886525, "vf_explained_var": -2.3146259023788126e-06, "kl": 0.009311143436244453, "entropy": 1.3715058403657683, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 43710.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.0674126978342733, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.511639000599583, "policy_loss": -0.0176732935734132, "vf_loss": 3.527373877167702, "vf_explained_var": -0.0053763406351208685, "kl": 0.00969205411512502, "entropy": 1.419502401103576, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 14880.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 64000, "num_env_steps_trained": 64000, "num_agent_steps_sampled": 256000, "num_agent_steps_trained": 256000}, "env_runners": {"episode_reward_max": 220.0, "episode_reward_min": -26.82230962273306, "episode_reward_mean": 18.81207299420648, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 158, "episodes_timesteps_total": 3950, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -110.0}, "policy_reward_max": {"adversary_policy": 110.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 10.50632911392405, "agent_policy": -12.70691434756567}, "custom_metrics": {}, "hist_stats": {"episode_reward": [60.0, 0.0, -11.785754352181854, 0.0, 0.0, 20.0, 60.0, 20.0, 55.203730646482256, -7.194515350183524, 0.0, -15.198142739612479, 0.0, 60.0, 59.71669530177272, -2.111081413250444, -12.245285949025199, 0.0, 0.0, 220.0, 60.0, 60.0, -26.82230962273306, 60.0, 60.0, 40.0, -7.526539737895373, -2.703715387782358, 20.0, 0.0, -1.1263756014762416, 40.0, 37.210358924303, 0.0, 0.0, -0.30332001381694007, 100.0, 60.0, 0.0, -15.997861168645922, 40.0, 0.0, -12.322437211677661, 60.0, -11.892782171692494, 60.0, 0.0, 0.0, 60.0, 0.0, 40.0, 0.0, 0.0, 0.0, 0.0, 58.80974802865049, 0.0, 0.0, 60.0, 60.0, 0.0, 71.34477928606644, -5.004303634047123, 160.0, 0.0, 0.0, 0.0, -13.609627412426795, 0.0, 0.0, 0.0, 20.0, 40.0, 66.96832309469126, -12.315370489915516, 0.0, 60.0, 120.0, -5.390683886442408, 0.0, -4.209593208474001, 0.0, 60.0, -0.4497083227101728, 59.378355236288826, 0.0, 0.0, 0.0, -0.7097830790818027, -0.5002814863663319, 40.0, 60.0, 0.0, -0.9118476122495944, 0.0, -19.631095858671912, -0.06814511091807085, -17.79885835119487, 60.0, 0.0, -9.909567335727276, 0.0, 0.0, 0.0, 60.0, 80.0, -1.750816384920526, 99.31350913367004, 0.0, 0.0, 0.0, 0.0, -1.2744288446151442, 60.0, 0.0, 0.0, -23.391730275416233, 60.0, 110.85013072194954, 0.0, -5.666176243364415, 0.0, -0.08813288458058732, -2.778705187607972, 40.0, -5.1318859287951435, 0.0, 0.0, 20.0, -0.05264805437011355, 20.0, -13.030352526839819, 40.0, 0.0, 60.0, 0.0, 0.0, -12.646259576601386, 0.0, 120.0, 0.0, 0.0, 0.0, -2.1337574303464635, 0.0, 80.0, -8.065422168722975, 0.0, 0.0, 20.0, -4.3836817648072754, -0.7090347931352847, 60.0, 0.0, -2.6323071910192564, -5.013771525908386, 0.0, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 110.0, 110.0, 110.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 80.0, 80.0, 80.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-30.0, 0.0, -11.785754352181854, 0.0, 0.0, -10.0, -30.0, -10.0, -34.79626935351775, -7.194515350183524, 0.0, -15.198142739612479, 0.0, -30.0, -30.283304698227276, -2.111081413250444, -12.245285949025199, 0.0, 0.0, -110.0, -30.0, -30.0, -26.82230962273306, -30.0, -30.0, -20.0, -7.526539737895373, -2.703715387782358, -10.0, 0.0, -1.1263756014762416, -20.0, -22.789641075696995, 0.0, 0.0, -0.30332001381694007, -50.0, -30.0, 0.0, -15.997861168645922, -20.0, 0.0, -12.322437211677661, -30.0, -11.892782171692494, -30.0, 0.0, 0.0, -30.0, 0.0, -20.0, 0.0, 0.0, 0.0, 0.0, -31.19025197134951, 0.0, 0.0, -30.0, -30.0, 0.0, -48.655220713933545, -5.004303634047123, -80.0, 0.0, 0.0, 0.0, -13.609627412426795, 0.0, 0.0, 0.0, -10.0, -20.0, -53.03167690530872, -12.315370489915516, 0.0, -30.0, -60.0, -5.390683886442408, 0.0, -4.209593208474001, 0.0, -30.0, -0.4497083227101728, -30.621644763711167, 0.0, 0.0, 0.0, -0.7097830790818027, -0.5002814863663319, -20.0, -30.0, 0.0, -0.9118476122495944, 0.0, -19.631095858671912, -0.06814511091807085, -17.79885835119487, -30.0, 0.0, -9.909567335727276, 0.0, 0.0, 0.0, -30.0, -40.0, -1.750816384920526, -50.686490866329954, 0.0, 0.0, 0.0, 0.0, -1.2744288446151442, -30.0, 0.0, 0.0, -23.391730275416233, -30.0, -69.14986927805046, 0.0, -5.666176243364415, 0.0, -0.08813288458058732, -2.778705187607972, -20.0, -5.1318859287951435, 0.0, 0.0, -10.0, -0.05264805437011355, -10.0, -13.030352526839819, -20.0, 0.0, -30.0, 0.0, 0.0, -12.646259576601386, 0.0, -60.0, 0.0, 0.0, 0.0, -2.1337574303464635, 0.0, -40.0, -8.065422168722975, 0.0, 0.0, -10.0, -4.3836817648072754, -0.7090347931352847, -30.0, 0.0, -2.6323071910192564, -5.013771525908386, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6892653755423717, "mean_inference_ms": 1.1927088564411217, "mean_action_processing_ms": 0.23807829392681165, "mean_env_wait_ms": 0.5119052161373187, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00535921205448199, "StateBufferConnector_ms": 0.0034693675705149206, "ViewRequirementAgentConnector_ms": 0.09806133523772034}, "num_episodes": 158, "episode_return_max": 220.0, "episode_return_min": -26.82230962273306, "episode_return_mean": 18.81207299420648}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 256000, "num_agent_steps_trained": 256000, "num_env_steps_sampled": 64000, "num_env_steps_trained": 64000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 321.819719478175, "num_env_steps_trained_throughput_per_sec": 321.819719478175, "timesteps_total": 64000, "num_env_steps_sampled_lifetime": 64000, "num_agent_steps_sampled_lifetime": 256000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 256000, "timers": {"training_iteration_time_ms": 13346.373, "restore_workers_time_ms": 0.014, "training_step_time_ms": 13346.314, "sample_time_ms": 1234.111, "learn_time_ms": 12093.988, "learn_throughput": 330.743, "synch_weights_time_ms": 17.495}, "counters": {"num_env_steps_sampled": 64000, "num_env_steps_trained": 64000, "num_agent_steps_sampled": 256000, "num_agent_steps_trained": 256000}, "done": false, "training_iteration": 16, "trial_id": "86f16_00000", "date": "2024-08-08_16-16-21", "timestamp": 1723148181, "time_this_iter_s": 12.477521896362305, "time_total_s": 224.95369052886963, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3aca54430>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 224.95369052886963, "iterations_since_restore": 16, "perf": {"cpu_util_percent": 39.36666666666667, "ram_util_percent": 82.73888888888888}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7471375754327638, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.4924180655614703, "policy_loss": -0.011821460467763245, "vf_loss": 2.502687278241976, "vf_explained_var": -6.80824543567414e-06, "kl": 0.0077611270104150165, "entropy": 1.343650445236382, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 46530.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.0738305001209179, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.060790086040894, "policy_loss": -0.013733533837754901, "vf_loss": 4.072467629611492, "vf_explained_var": 0.0063510807851950325, "kl": 0.01027992602180744, "entropy": 1.3847494346400102, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 15840.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 68000, "num_env_steps_trained": 68000, "num_agent_steps_sampled": 272000, "num_agent_steps_trained": 272000}, "env_runners": {"episode_reward_max": 160.0, "episode_reward_min": -59.81114519261135, "episode_reward_mean": 17.191455951684247, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 157, "episodes_timesteps_total": 3925, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -80.0}, "policy_reward_max": {"adversary_policy": 80.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 10.445859872611464, "agent_policy": -14.146123666150142}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.0, 47.162000316682196, -7.88781382712087, 20.0, 40.0, 0.0, 60.0, 0.0, -1.4732545067316083, 52.51083884568974, -16.141215167197167, -4.206113845211133, -23.075591391589867, 0.0, 58.43761093434712, -0.3033893742050475, -14.275859367912089, -15.200473220550341, -15.960989311986976, 20.0, 60.0, 40.0, 0.0, 0.0, 0.0, 0.0, -21.58635541786847, 40.0, -6.746596465723249, 79.6402691130578, 0.0, -0.3353712628562777, 40.0, -10.015908041781348, 0.0, 0.0, 80.0, 70.26839577425729, 0.0, 0.0, -4.067347995135053, -0.4104729500216464, 40.0, -12.056935795065396, 58.857967363104734, 80.0, 0.0, 60.0, 0.0, 0.0, 0.0, 60.0, 0.0, 10.565279294904613, 33.022042406956295, 20.0, 0.0, 0.0, 60.0, -10.493695257541393, 0.0, 0.0, 40.0, 0.0, 50.33356447193476, 140.0, 60.0, 40.0, 60.0, -0.12707985017179957, 60.0, 0.0, 0.0, 0.0, -8.149992951273624, 0.0, 0.0, -17.916821161569317, -21.3139262054963, 0.0, 17.961622021345477, 0.0, 100.0, 60.0, 60.0, 0.0, 60.0, 0.0, -59.81114519261135, -12.107556538435363, 0.0, 80.0, 0.0, 40.0, 60.0, 60.0, -10.851702097841361, -15.082018554680964, 0.0, 0.0, 79.47352844739365, 0.0, 28.91231131754185, 0.0, 20.0, 0.0, 0.0, 38.50823411359815, 0.0, -11.610211203402994, 0.0, 40.0, 0.0, -5.542779931835308, 0.0, -14.45888838467169, 0.0, 32.07245478830348, 40.0, -10.000116992858189, -0.5810571793384245, 20.0, 20.0, 0.0, 40.0, 0.0, -5.542019785093072, 0.0, 80.0, 0.0, 20.0, 0.0, 0.0, 0.0, 120.0, -34.02364948456952, -0.3041869988717161, 14.448258799842495, -27.970367624851942, 0.0, -20.589084118348612, 40.0, 160.0, 0.0, 0.0, 0.0, 40.0, 78.72873302897636, 0.0, -7.5823718231630615, 40.0, -9.27127913348823, 0.0, -5.448962863376119, 0.0, 50.67807465093851, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 70.0, 70.0, 70.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 80.0, 80.0, 80.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-20.0, -42.837999683317804, -7.88781382712087, -10.0, -20.0, 0.0, -30.0, 0.0, -1.4732545067316083, -37.48916115431026, -16.141215167197167, -4.206113845211133, -23.075591391589867, 0.0, -31.56238906565288, -0.3033893742050475, -14.275859367912089, -15.200473220550341, -15.960989311986976, -10.0, -30.0, -20.0, 0.0, 0.0, 0.0, 0.0, -21.58635541786847, -20.0, -6.746596465723249, -40.3597308869422, 0.0, -0.3353712628562777, -20.0, -10.015908041781348, 0.0, 0.0, -40.0, -49.73160422574271, 0.0, 0.0, -4.067347995135053, -0.4104729500216464, -20.0, -12.056935795065396, -31.142032636895266, -40.0, 0.0, -30.0, 0.0, 0.0, 0.0, -30.0, 0.0, -19.434720705095387, -26.97795759304371, -10.0, 0.0, 0.0, -30.0, -10.493695257541393, 0.0, 0.0, -20.0, 0.0, -39.666435528065236, -70.0, -30.0, -20.0, -30.0, -0.12707985017179957, -30.0, 0.0, 0.0, 0.0, -8.149992951273624, 0.0, 0.0, -17.916821161569317, -21.3139262054963, 0.0, -12.038377978654522, 0.0, -50.0, -30.0, -30.0, 0.0, -30.0, 0.0, -59.81114519261135, -12.107556538435363, 0.0, -40.0, 0.0, -20.0, -30.0, -30.0, -10.851702097841361, -15.082018554680964, 0.0, 0.0, -40.526471552606345, 0.0, -31.08768868245815, 0.0, -10.0, 0.0, 0.0, -21.49176588640185, 0.0, -11.610211203402994, 0.0, -20.0, 0.0, -5.542779931835308, 0.0, -14.45888838467169, 0.0, -27.927545211696515, -20.0, -10.000116992858189, -0.5810571793384245, -10.0, -10.0, 0.0, -20.0, 0.0, -5.542019785093072, 0.0, -40.0, 0.0, -10.0, 0.0, 0.0, 0.0, -60.0, -34.02364948456952, -0.3041869988717161, -45.5517412001575, -27.970367624851942, 0.0, -20.589084118348612, -20.0, -80.0, 0.0, 0.0, 0.0, -20.0, -41.271266971023636, 0.0, -7.5823718231630615, -20.0, -9.27127913348823, 0.0, -5.448962863376119, 0.0, -39.32192534906149, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6884516016202739, "mean_inference_ms": 1.1903462823504831, "mean_action_processing_ms": 0.2378502278801158, "mean_env_wait_ms": 0.5109359186796313, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006293263404991976, "StateBufferConnector_ms": 0.0033280652040129253, "ViewRequirementAgentConnector_ms": 0.09807834200039031}, "num_episodes": 157, "episode_return_max": 160.0, "episode_return_min": -59.81114519261135, "episode_return_mean": 17.191455951684247}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 272000, "num_agent_steps_trained": 272000, "num_env_steps_sampled": 68000, "num_env_steps_trained": 68000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 315.41415345497194, "num_env_steps_trained_throughput_per_sec": 315.41415345497194, "timesteps_total": 68000, "num_env_steps_sampled_lifetime": 68000, "num_agent_steps_sampled_lifetime": 272000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 272000, "timers": {"training_iteration_time_ms": 13276.936, "restore_workers_time_ms": 0.017, "training_step_time_ms": 13276.87, "sample_time_ms": 1233.571, "learn_time_ms": 12025.389, "learn_throughput": 332.63, "synch_weights_time_ms": 17.299}, "counters": {"num_env_steps_sampled": 68000, "num_env_steps_trained": 68000, "num_agent_steps_sampled": 272000, "num_agent_steps_trained": 272000}, "done": false, "training_iteration": 17, "trial_id": "86f16_00000", "date": "2024-08-08_16-16-34", "timestamp": 1723148194, "time_this_iter_s": 12.686332941055298, "time_total_s": 237.64002346992493, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3aca54550>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 237.64002346992493, "iterations_since_restore": 17, "perf": {"cpu_util_percent": 36.77777777777778, "ram_util_percent": 82.62222222222222}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7256768551595667, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.0064448721442663, "policy_loss": -0.01293221423105198, "vf_loss": 2.017536568979845, "vf_explained_var": -2.4139881134033203e-06, "kl": 0.009202534399728084, "entropy": 1.3283019475480344, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 49350.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2238446704422434, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.1164122175425293, "policy_loss": -0.01956426916149212, "vf_loss": 3.133435839911302, "vf_explained_var": -0.0006339443226655324, "kl": 0.012703247352710943, "entropy": 1.3920554825415214, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 16800.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 72000, "num_env_steps_trained": 72000, "num_agent_steps_sampled": 288000, "num_agent_steps_trained": 288000}, "env_runners": {"episode_reward_max": 240.0, "episode_reward_min": -47.43071357320229, "episode_reward_mean": 19.23315927701399, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -120.0}, "policy_reward_max": {"adversary_policy": 120.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 11.049382716049383, "agent_policy": -13.914988871134158}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 100.0, 0.0, 80.0, 0.0, 0.0, -0.5071056699947196, -31.099277210354494, 40.0, -2.8344204993780666, -0.6550878116369474, 80.0, 79.97610717248286, 0.0, -47.43071357320229, 0.0, 40.0, 0.0, 0.0, 0.0, -15.443800916304015, 0.0, -0.26378943530646737, 0.0, 0.0, -1.125377342601267, 50.63656803222009, 40.0, -2.044069204171067, 80.0, -5.313451664437259, 0.0, 40.0, 0.0, -0.055012704401222745, 38.00827761756512, 60.0, -25.781387642940746, 0.0, 0.0, 0.0, 40.0, 0.0, 60.0, 60.0, 0.0, 0.0, 0.0, -10.062327693364052, 37.634119822254945, 0.0, 20.0, 0.0, 0.0, -21.05315150595716, 178.39647580042714, 0.0, 0.0, 0.0, 34.07224986329625, 0.0, 44.197145513456235, -11.24096147734408, -10.790530476662514, 39.90918939215065, -29.809658573625562, -4.078614673170277, 0.0, 80.0, -6.088886076097572, 20.0, 0.0, 60.0, -1.3550519904144431, 60.0, 60.0, 40.0, -0.4343897371209293, -1.0748171547842778, 20.0, 40.0, 60.0, 0.0, 36.86975382103378, 80.0, -7.086227369196428, 0.0, -22.907313096441737, 14.25777593074488, 0.0, 0.0, 100.0, 0.0, 40.0, 40.05359806689918, 0.0, 0.0, 0.0, 0.0, 0.0, -5.1825616697126575, -0.1999125199210916, 0.0, 60.0, -15.53390022916713, 0.0, 60.0, -3.7112261339191153, 20.749022605022077, 60.0, 120.0, 240.0, 0.0, 0.0, 0.0, 0.0, 0.0, 80.0, 40.0, 0.0, 60.0, 0.0, 80.0, 0.0, 0.0, 0.0, 60.0, 0.0, -26.560986577812223, 14.640480240484747, 0.0, 19.885539578655596, -4.668683324385456, -6.613239328836876, 0.0, 59.753224082519864, 20.0, 60.0, -15.519619123109285, -5.4622367408219485, 60.0, 0.0, -14.91587445378449, 134.94950134580048, 60.0, 0.0, 140.0, -1.990576833840988, 0.0, 0.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -9.322985574528738, 0.0, 0.0, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 90.0, 90.0, 90.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 60.0, 60.0, 60.0, 120.0, 120.0, 120.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [0.0, -50.0, 0.0, -40.0, 0.0, 0.0, -0.5071056699947196, -31.099277210354494, -20.0, -2.8344204993780666, -0.6550878116369474, -40.0, -40.023892827517145, 0.0, -47.43071357320229, 0.0, -20.0, 0.0, 0.0, 0.0, -15.443800916304015, 0.0, -0.26378943530646737, 0.0, 0.0, -1.125377342601267, -39.36343196777991, -20.0, -2.044069204171067, -40.0, -5.313451664437259, 0.0, -20.0, 0.0, -0.055012704401222745, -21.99172238243488, -30.0, -25.781387642940746, 0.0, 0.0, 0.0, -20.0, 0.0, -30.0, -30.0, 0.0, 0.0, 0.0, -10.062327693364052, -22.365880177745048, 0.0, -10.0, 0.0, 0.0, -21.05315150595716, -91.60352419957286, 0.0, 0.0, 0.0, -25.92775013670375, 0.0, -45.802854486543765, -11.24096147734408, -10.790530476662514, -20.09081060784935, -29.809658573625562, -4.078614673170277, 0.0, -40.0, -6.088886076097572, -10.0, 0.0, -30.0, -1.3550519904144431, -30.0, -30.0, -20.0, -0.4343897371209293, -1.0748171547842778, -10.0, -20.0, -30.0, 0.0, -23.130246178966217, -40.0, -7.086227369196428, 0.0, -22.907313096441737, -15.74222406925512, 0.0, 0.0, -50.0, 0.0, -20.0, -49.94640193310083, 0.0, 0.0, 0.0, 0.0, 0.0, -5.1825616697126575, -0.1999125199210916, 0.0, -30.0, -15.53390022916713, 0.0, -30.0, -3.7112261339191153, -39.25097739497792, -30.0, -60.0, -120.0, 0.0, 0.0, 0.0, 0.0, 0.0, -40.0, -20.0, 0.0, -30.0, 0.0, -40.0, 0.0, 0.0, 0.0, -30.0, 0.0, -26.560986577812223, -15.359519759515253, 0.0, -10.114460421344404, -4.668683324385456, -6.613239328836876, 0.0, -30.246775917480143, -10.0, -30.0, -15.519619123109285, -5.4622367408219485, -30.0, 0.0, -14.91587445378449, -75.0504986541995, -30.0, 0.0, -70.0, -1.990576833840988, 0.0, 0.0, -20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -9.322985574528738, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.684943527707648, "mean_inference_ms": 1.1840797322403342, "mean_action_processing_ms": 0.23704826747543198, "mean_env_wait_ms": 0.5091844186778614, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004506479074925553, "StateBufferConnector_ms": 0.003302759594387478, "ViewRequirementAgentConnector_ms": 0.0908513128021617}, "num_episodes": 162, "episode_return_max": 240.0, "episode_return_min": -47.43071357320229, "episode_return_mean": 19.23315927701399}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 288000, "num_agent_steps_trained": 288000, "num_env_steps_sampled": 72000, "num_env_steps_trained": 72000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 272.76482734624926, "num_env_steps_trained_throughput_per_sec": 272.76482734624926, "timesteps_total": 72000, "num_env_steps_sampled_lifetime": 72000, "num_agent_steps_sampled_lifetime": 288000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 288000, "timers": {"training_iteration_time_ms": 13548.241, "restore_workers_time_ms": 0.017, "training_step_time_ms": 13548.175, "sample_time_ms": 1242.347, "learn_time_ms": 12287.604, "learn_throughput": 325.531, "synch_weights_time_ms": 17.598}, "counters": {"num_env_steps_sampled": 72000, "num_env_steps_trained": 72000, "num_agent_steps_sampled": 288000, "num_agent_steps_trained": 288000}, "done": false, "training_iteration": 18, "trial_id": "86f16_00000", "date": "2024-08-08_16-16-49", "timestamp": 1723148209, "time_this_iter_s": 14.680453062057495, "time_total_s": 252.32047653198242, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3aca54c10>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 252.32047653198242, "iterations_since_restore": 18, "perf": {"cpu_util_percent": 48.504761904761914, "ram_util_percent": 81.13809523809525}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7557594209803757, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.450298854095716, "policy_loss": -0.013771659038888277, "vf_loss": 2.4625258567485404, "vf_explained_var": 8.137302195772212e-07, "kl": 0.007723234211754426, "entropy": 1.3005421611856907, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 52170.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2577200962851445, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.3013527539869147, "policy_loss": -0.015079196076840162, "vf_loss": 3.3145629998296497, "vf_explained_var": 0.0023930992310245832, "kl": 0.00934470834114471, "entropy": 1.3980340740333002, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 17760.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 76000, "num_env_steps_trained": 76000, "num_agent_steps_sampled": 304000, "num_agent_steps_trained": 304000}, "env_runners": {"episode_reward_max": 140.0, "episode_reward_min": -48.34269366049065, "episode_reward_mean": 19.59460212787482, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -70.0}, "policy_reward_max": {"adversary_policy": 70.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 10.74074074074074, "agent_policy": -12.627620094347403}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 58.49860373013414, 0.0, 0.0, -0.03933718777890394, 0.0, 60.0, 0.0, 0.0, 41.06835207392824, -10.70963196457078, 0.0, 0.0, -0.5571289577561067, 46.572117971848975, 40.0, -5.47300738594433, -0.3854695354271187, 19.919927445826815, 0.0, 120.0, 60.0, 0.0, 100.0, 59.986791406416216, 60.0, 0.0, 58.48784975251105, -2.110616126867476, -3.200109005272128, 0.0, 0.0, 59.41670738616132, 0.0, 60.0, 0.0, 0.0, 0.0, 0.0, 120.0, -9.668309793156457, 84.55061075586153, -11.938220498164425, 0.0, 0.0, 80.0, 80.0, 0.0, 120.0, 60.0, 78.3045883009926, 80.0, 20.0, 0.0, 0.0, 40.0, 20.0, 20.0, 40.0, 0.0, 0.0, 20.0, 40.0, 40.0, -7.39355036642733, -8.798542460646024, 0.0, -0.17740284214139979, 0.0, 40.0, 59.24394590950786, 40.0, 59.0811093884589, 120.0, -11.358615899802418, 0.0, 37.44167802169468, -8.544012867273496, 0.0, 0.0, -0.3151145984450987, 60.0, -2.7873336732093543, 0.0, 140.0, 0.0, 80.0, 0.0, 0.0, -18.589622764861986, -1.6039120369692805, -6.394421244865045, -4.069193134262781, 0.0, -2.6633594596725185, 56.481985782451666, 0.0, 0.0, 0.0, 60.0, 0.0, -6.105621902918809, -2.654678115980462, 0.0, -48.34269366049065, 120.0, 0.0, 120.0, 20.0, -0.0718224215527008, 0.0, 0.0, -3.548249700674516, 39.68251820852769, -6.574090400741567, -1.5334355448791215, -0.268909968826061, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 40.0, 19.99560792738731, 0.0, -1.420892734257605, 40.0, 99.64760856235114, -24.68585723451963, -4.029009658911068, 0.0, 40.0, 0.0, 40.0, 0.0, -4.165901660576518, 37.170139078633255, 78.9627576131515, -11.35810417458119, 0.0, -3.2667180563403786, -1.7901919599130312, 0.0, -1.4807113875213074, 0.0, 20.0, -1.8247715426305111, 59.71121732870553, 0.0, 0.0, 60.0, 0.0, 20.0, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -31.501396269865854, 0.0, 0.0, -0.03933718777890394, 0.0, -30.0, 0.0, 0.0, -48.93164792607176, -10.70963196457078, 0.0, 0.0, -0.5571289577561067, -43.427882028151025, -20.0, -5.47300738594433, -0.3854695354271187, -10.080072554173187, 0.0, -60.0, -30.0, 0.0, -50.0, -30.013208593583784, -30.0, 0.0, -31.512150247488947, -2.110616126867476, -3.200109005272128, 0.0, 0.0, -30.58329261383868, 0.0, -30.0, 0.0, 0.0, 0.0, 0.0, -60.0, -9.668309793156457, -65.44938924413847, -11.938220498164425, 0.0, 0.0, -40.0, -40.0, 0.0, -60.0, -30.0, -41.6954116990074, -40.0, -10.0, 0.0, 0.0, -20.0, -10.0, -10.0, -20.0, 0.0, 0.0, -10.0, -20.0, -20.0, -7.39355036642733, -8.798542460646024, 0.0, -0.17740284214139979, 0.0, -20.0, -30.756054090492135, -20.0, -30.918890611541098, -60.0, -11.358615899802418, 0.0, -22.558321978305322, -8.544012867273496, 0.0, 0.0, -0.3151145984450987, -30.0, -2.7873336732093543, 0.0, -70.0, 0.0, -40.0, 0.0, 0.0, -18.589622764861986, -1.6039120369692805, -6.394421244865045, -4.069193134262781, 0.0, -2.6633594596725185, -33.51801421754833, 0.0, 0.0, 0.0, -30.0, 0.0, -6.105621902918809, -2.654678115980462, 0.0, -48.34269366049065, -60.0, 0.0, -60.0, -10.0, -0.0718224215527008, 0.0, 0.0, -3.548249700674516, -20.31748179147231, -6.574090400741567, -1.5334355448791215, -0.268909968826061, 0.0, 0.0, 0.0, 0.0, 0.0, -10.0, -20.0, -10.00439207261269, 0.0, -1.420892734257605, -20.0, -50.35239143764887, -24.68585723451963, -4.029009658911068, 0.0, -20.0, 0.0, -20.0, 0.0, -4.165901660576518, -22.829860921366745, -41.0372423868485, -11.35810417458119, 0.0, -3.2667180563403786, -1.7901919599130312, 0.0, -1.4807113875213074, 0.0, -10.0, -1.8247715426305111, -30.28878267129447, 0.0, 0.0, -30.0, 0.0, -10.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6863632511568305, "mean_inference_ms": 1.1871833077276894, "mean_action_processing_ms": 0.2374841727980866, "mean_env_wait_ms": 0.5107218358721611, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005488704752039026, "StateBufferConnector_ms": 0.004384767862013829, "ViewRequirementAgentConnector_ms": 0.10323355227340887}, "num_episodes": 162, "episode_return_max": 140.0, "episode_return_min": -48.34269366049065, "episode_return_mean": 19.59460212787482}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 304000, "num_agent_steps_trained": 304000, "num_env_steps_sampled": 76000, "num_env_steps_trained": 76000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 224.5639584104926, "num_env_steps_trained_throughput_per_sec": 224.5639584104926, "timesteps_total": 76000, "num_env_steps_sampled_lifetime": 76000, "num_agent_steps_sampled_lifetime": 304000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 304000, "timers": {"training_iteration_time_ms": 14063.383, "restore_workers_time_ms": 0.018, "training_step_time_ms": 14063.315, "sample_time_ms": 1270.795, "learn_time_ms": 12774.257, "learn_throughput": 313.13, "synch_weights_time_ms": 17.674}, "counters": {"num_env_steps_sampled": 76000, "num_env_steps_trained": 76000, "num_agent_steps_sampled": 304000, "num_agent_steps_trained": 304000}, "done": false, "training_iteration": 19, "trial_id": "86f16_00000", "date": "2024-08-08_16-17-07", "timestamp": 1723148227, "time_this_iter_s": 17.842655897140503, "time_total_s": 270.1631324291229, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3aca54f70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 270.1631324291229, "iterations_since_restore": 19, "perf": {"cpu_util_percent": 61.900000000000006, "ram_util_percent": 81.23461538461538}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7433344988852528, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.802184739645491, "policy_loss": -0.015124024516004567, "vf_loss": 2.815464317502705, "vf_explained_var": -3.3360846499179273e-06, "kl": 0.00922217132663876, "entropy": 1.3008512521466464, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 54990.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.319972665483753, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.165685515850782, "policy_loss": -0.015600047509845656, "vf_loss": 4.179251398394505, "vf_explained_var": -0.004964842647314072, "kl": 0.010170923321422125, "entropy": 1.4109885069231192, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 18720.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 80000, "num_env_steps_trained": 80000, "num_agent_steps_sampled": 320000, "num_agent_steps_trained": 320000}, "env_runners": {"episode_reward_max": 239.34475474016108, "episode_reward_min": -27.11590887747599, "episode_reward_mean": 24.670986864713694, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -120.65524525983895}, "policy_reward_max": {"adversary_policy": 120.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 13.82716049382716, "agent_policy": -16.810494616767787}, "custom_metrics": {}, "hist_stats": {"episode_reward": [100.0, -7.4888617244431925, 0.0, 140.0, 0.0, 40.0, 60.0, 39.36397104143049, -19.71453945123394, 0.0, 0.0, -19.986444854678965, 20.0, 20.0, 0.0, -10.458737081346314, 60.0, 20.0, -13.371590597890265, 0.0, -27.11590887747599, 60.0, 20.0, 0.0, 60.0, 57.73159890778638, -8.671617709139737, 0.0, 20.0, -9.722929735587625, 60.0, 0.0, 55.6125817022207, 0.0, 12.417960654320787, 0.0, 140.0, -3.198191981306815, 40.0, -2.476886566266616, 40.0, 120.0, 20.0, -20.261357286848916, 0.0, 0.0, 0.0, 0.0, 98.49228421135979, 38.91677376755502, 0.0, -4.502727269416255, 0.0, 8.054360990781, 40.0, 38.53425330619666, 60.0, 60.0, -23.4385309980255, 140.0, 0.0, 59.82187131856857, 0.0, -6.312261226452681, 40.0, 58.214112107326514, 0.0, 0.0, 69.27834670052818, -18.47616544707752, 40.0, -22.213342040992313, 0.0, 100.0, 80.0, 0.0, 80.0, 0.0, 0.0, 0.0, -10.790504848359921, 0.0, 120.0, 18.078659765224863, -1.1581056585242422, 0.0, -7.936318778472151, 0.0, 100.0, -20.843342386443915, 0.0, -0.05574431743756714, 0.0, 40.0, 0.0, 20.0, 0.0, 0.0, 40.0, 0.0, 20.0, 0.0, 0.0, -5.6391840401435624, -0.7610281657004703, -0.9896001987045566, 33.44479847057706, 0.0, 140.0, 0.0, 0.0, -0.2510644584510413, -7.8475645703673855, 0.0, -23.381536450175066, 100.0, 0.0, 60.0, -14.653807295821041, 0.0, 0.0, 60.0, -2.221384408362593, -16.54437228224431, 60.0, 39.551930896126315, -14.875438922287767, -5.701224596586829, 60.0, 0.0, 20.0, 39.234380436070836, 5.834432430848667, 30.745726277821873, 59.06799014466071, 60.0, 0.0, 20.0, 0.0, -6.472486246069481, 78.00585481958537, -2.3934254362083784, 239.34475474016108, 20.0, 59.60084849179714, 80.0, 20.0, 80.0, 40.0, 0.0, 0.0, 98.59799195650592, 100.0, 0.0, 0.0, 40.0, 0.0, 40.0, -21.168467825076583, 0.0, 120.0, -0.15091732021603854], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 60.0, 60.0, 60.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 120.0, 120.0, 120.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-50.0, -7.4888617244431925, 0.0, -70.0, 0.0, -20.0, -30.0, -20.63602895856951, -19.71453945123394, 0.0, 0.0, -19.986444854678965, -10.0, -10.0, 0.0, -10.458737081346314, -30.0, -10.0, -13.371590597890265, 0.0, -27.11590887747599, -30.0, -10.0, 0.0, -30.0, -32.26840109221362, -8.671617709139737, 0.0, -10.0, -9.722929735587625, -30.0, 0.0, -34.3874182977793, 0.0, -17.582039345679213, 0.0, -70.0, -3.198191981306815, -20.0, -2.476886566266616, -20.0, -60.0, -10.0, -20.261357286848916, 0.0, 0.0, 0.0, 0.0, -51.50771578864021, -21.083226232444982, 0.0, -4.502727269416255, 0.0, -21.945639009219, -20.0, -21.46574669380334, -30.0, -30.0, -23.4385309980255, -70.0, 0.0, -30.178128681431428, 0.0, -6.312261226452681, -20.0, -31.785887892673493, 0.0, 0.0, -50.72165329947182, -18.47616544707752, -20.0, -22.213342040992313, 0.0, -50.0, -40.0, 0.0, -40.0, 0.0, 0.0, 0.0, -10.790504848359921, 0.0, -60.0, -11.921340234775135, -1.1581056585242422, 0.0, -7.936318778472151, 0.0, -50.0, -20.843342386443915, 0.0, -0.05574431743756714, 0.0, -20.0, 0.0, -10.0, 0.0, 0.0, -20.0, 0.0, -10.0, 0.0, 0.0, -5.6391840401435624, -0.7610281657004703, -0.9896001987045566, -56.55520152942294, 0.0, -70.0, 0.0, 0.0, -0.2510644584510413, -7.8475645703673855, 0.0, -23.381536450175066, -50.0, 0.0, -30.0, -14.653807295821041, 0.0, 0.0, -30.0, -2.221384408362593, -16.54437228224431, -30.0, -20.448069103873685, -14.875438922287767, -5.701224596586829, -30.0, 0.0, -10.0, -20.76561956392916, -24.165567569151335, -29.254273722178134, -30.932009855339288, -30.0, 0.0, -10.0, 0.0, -6.472486246069481, -41.994145180414634, -2.3934254362083784, -120.65524525983895, -10.0, -30.399151508202856, -40.0, -10.0, -40.0, -20.0, 0.0, 0.0, -51.40200804349408, -50.0, 0.0, 0.0, -20.0, 0.0, -20.0, -21.168467825076583, 0.0, -60.0, -0.15091732021603854]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6881326608610433, "mean_inference_ms": 1.1906042003252901, "mean_action_processing_ms": 0.23807872988382828, "mean_env_wait_ms": 0.5126745893876923, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004567996955212252, "StateBufferConnector_ms": 0.0033613340354260103, "ViewRequirementAgentConnector_ms": 0.1009892534326624}, "num_episodes": 162, "episode_return_max": 239.34475474016108, "episode_return_min": -27.11590887747599, "episode_return_mean": 24.670986864713694}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 320000, "num_agent_steps_trained": 320000, "num_env_steps_sampled": 80000, "num_env_steps_trained": 80000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 247.1820802680358, "num_env_steps_trained_throughput_per_sec": 247.1820802680358, "timesteps_total": 80000, "num_env_steps_sampled_lifetime": 80000, "num_agent_steps_sampled_lifetime": 320000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 320000, "timers": {"training_iteration_time_ms": 14376.765, "restore_workers_time_ms": 0.019, "training_step_time_ms": 14376.698, "sample_time_ms": 1283.299, "learn_time_ms": 13074.975, "learn_throughput": 305.928, "synch_weights_time_ms": 17.853}, "counters": {"num_env_steps_sampled": 80000, "num_env_steps_trained": 80000, "num_agent_steps_sampled": 320000, "num_agent_steps_trained": 320000}, "done": false, "training_iteration": 20, "trial_id": "86f16_00000", "date": "2024-08-08_16-17-23", "timestamp": 1723148243, "time_this_iter_s": 16.2010600566864, "time_total_s": 286.3641924858093, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3aca2a1f0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 286.3641924858093, "iterations_since_restore": 20, "perf": {"cpu_util_percent": 57.00434782608696, "ram_util_percent": 81.62173913043479}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7375540572912135, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.3005281778937534, "policy_loss": -0.01335850839894463, "vf_loss": 2.312370714862296, "vf_explained_var": -7.554465997303631e-06, "kl": 0.007579823794010233, "entropy": 1.2620993629837713, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 57810.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2983953311418495, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.7282429205874603, "policy_loss": -0.01835916067842239, "vf_loss": 3.744306480636199, "vf_explained_var": -0.0012646053607265155, "kl": 0.011477959425461403, "entropy": 1.3972373245904843, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 19680.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 84000, "num_env_steps_trained": 84000, "num_agent_steps_sampled": 336000, "num_agent_steps_trained": 336000}, "env_runners": {"episode_reward_max": 200.0, "episode_reward_min": -54.659472223278804, "episode_reward_mean": 19.666078986379315, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 153, "episodes_timesteps_total": 3825, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -100.0}, "policy_reward_max": {"adversary_policy": 100.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 11.699346405228757, "agent_policy": -15.431960229306961}, "custom_metrics": {}, "hist_stats": {"episode_reward": [60.0, 59.851192227245946, 20.0, 0.0, -1.2443495223076995, 0.0, 20.0, 0.0, -1.3173878012565399, 0.0, 0.0, 0.0, 36.57989677440693, -12.778685285704572, 0.0, 20.0, 0.0, 0.0, 0.0, -11.56968219110044, 12.538153990787636, -7.371753129113221, 60.0, 20.0, -9.045043056016828, 0.0, 46.994811880512955, -15.252408698039979, 74.65670764670088, -3.869331681208598, 59.912071015869536, -0.1294191361504693, 80.0, 0.0, -0.22204882130899772, 0.0, 0.0, 60.0, 200.0, -14.326187964315396, 0.0, -6.774916753812535, 60.0, 60.0, 0.0, 0.0, 60.0, -17.677788523021135, 20.0, 60.0, 119.31958601360226, 40.0, 20.0, 60.0, 40.0, 0.0, 0.0, -29.13390247148179, 0.0, -1.5556163738853124, 0.0, 80.0, 100.0, 0.0, 0.0, 20.0, 0.0, 56.7958787794338, 40.0, -17.92890010789436, 0.0, 0.0, -4.999538549949447, -54.659472223278804, 0.0, -0.2840752234295607, -1.2935927502934785, 0.0, 40.0, 0.0, -0.07961631421276483, 0.0, 0.0, 80.0, 140.0, -11.194561042368592, 0.0, 0.0, 180.0, -1.9827908208462008, 18.719700933870865, 36.52268494194551, 20.0, -6.052233857794975, -0.9429887903688228, 119.06549477323108, 0.0, 0.0, 0.0, 0.0, 0.0, -29.1917953117899, -21.17913020052119, -9.282945469921618, 0.0, 60.0, 0.0, 0.0, 120.0, -1.5279234235275008, -1.1283582073930332, -27.842160825130573, -11.861867990733558, -8.850247713278183, 80.0, 40.0, 20.0, 0.0, 78.98261851260077, 58.974878833319195, -13.612673811009945, -50.372216508151254, 0.0, 0.0, -7.634231783745801, 0.0, 0.0, 20.0, -1.422418468129183, 0.0, -42.91091582339651, 100.0, 0.0, -14.577877928731978, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 39.30916079841395, -17.31348207270705, -21.786831910824116, 119.79060187365295, 60.0, -1.4814896182372883, 200.0, 10.75316411414525, 94.28258513162811, 60.0, 0.0, 0.0, 59.52375483105631], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 100.0, 100.0, 100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 90.0, 90.0, 90.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 100.0, 100.0, 100.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0], "policy_agent_policy_reward": [-30.0, -30.148807772754047, -10.0, 0.0, -1.2443495223076995, 0.0, -10.0, 0.0, -1.3173878012565399, 0.0, 0.0, 0.0, -23.420103225593067, -12.778685285704572, 0.0, -10.0, 0.0, 0.0, 0.0, -11.56968219110044, -17.46184600921237, -7.371753129113221, -30.0, -10.0, -9.045043056016828, 0.0, -43.005188119487045, -15.252408698039979, -45.34329235329913, -3.869331681208598, -30.08792898413046, -0.1294191361504693, -40.0, 0.0, -0.22204882130899772, 0.0, 0.0, -30.0, -100.0, -14.326187964315396, 0.0, -6.774916753812535, -30.0, -30.0, 0.0, 0.0, -30.0, -17.677788523021135, -10.0, -30.0, -60.68041398639774, -20.0, -10.0, -30.0, -20.0, 0.0, 0.0, -29.13390247148179, 0.0, -1.5556163738853124, 0.0, -40.0, -50.0, 0.0, 0.0, -10.0, 0.0, -33.20412122056621, -20.0, -17.92890010789436, 0.0, 0.0, -4.999538549949447, -54.659472223278804, 0.0, -0.2840752234295607, -1.2935927502934785, 0.0, -20.0, 0.0, -0.07961631421276483, 0.0, 0.0, -40.0, -70.0, -11.194561042368592, 0.0, 0.0, -90.0, -1.9827908208462008, -11.280299066129135, -23.477315058054483, -10.0, -6.052233857794975, -0.9429887903688228, -60.93450522676893, 0.0, 0.0, 0.0, 0.0, 0.0, -29.1917953117899, -21.17913020052119, -9.282945469921618, 0.0, -30.0, 0.0, 0.0, -60.0, -1.5279234235275008, -1.1283582073930332, -27.842160825130573, -11.861867990733558, -8.850247713278183, -40.0, -20.0, -10.0, 0.0, -41.01738148739924, -31.025121166680808, -13.612673811009945, -50.372216508151254, 0.0, 0.0, -7.634231783745801, 0.0, 0.0, -10.0, -1.422418468129183, 0.0, -42.91091582339651, -50.0, 0.0, -14.577877928731978, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -20.69083920158605, -17.31348207270705, -21.786831910824116, -60.20939812634706, -30.0, -1.4814896182372883, -100.0, -19.246835885854754, -55.71741486837189, -30.0, 0.0, 0.0, -30.476245168943688]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.691283012726532, "mean_inference_ms": 1.1995420990918777, "mean_action_processing_ms": 0.2390569967328336, "mean_env_wait_ms": 0.5146070556410408, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004965729183620877, "StateBufferConnector_ms": 0.003454342387080972, "ViewRequirementAgentConnector_ms": 0.113219139622707}, "num_episodes": 153, "episode_return_max": 200.0, "episode_return_min": -54.659472223278804, "episode_return_mean": 19.666078986379315}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 336000, "num_agent_steps_trained": 336000, "num_env_steps_sampled": 84000, "num_env_steps_trained": 84000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 318.3237802011419, "num_env_steps_trained_throughput_per_sec": 318.3237802011419, "timesteps_total": 84000, "num_env_steps_sampled_lifetime": 84000, "num_agent_steps_sampled_lifetime": 336000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 336000, "timers": {"training_iteration_time_ms": 14273.0, "restore_workers_time_ms": 0.018, "training_step_time_ms": 14272.927, "sample_time_ms": 1298.379, "learn_time_ms": 12955.27, "learn_throughput": 308.755, "synch_weights_time_ms": 18.615}, "counters": {"num_env_steps_sampled": 84000, "num_env_steps_trained": 84000, "num_agent_steps_sampled": 336000, "num_agent_steps_trained": 336000}, "done": false, "training_iteration": 21, "trial_id": "86f16_00000", "date": "2024-08-08_16-17-36", "timestamp": 1723148256, "time_this_iter_s": 12.593829870223999, "time_total_s": 298.9580223560333, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3aca92a60>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 298.9580223560333, "iterations_since_restore": 21, "perf": {"cpu_util_percent": 37.3, "ram_util_percent": 80.07222222222222}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7511224183419072, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.6160855071764466, "policy_loss": -0.015656335723705273, "vf_loss": 2.629820478554313, "vf_explained_var": 2.2856901723442348e-07, "kl": 0.009606770417434358, "entropy": 1.233987611151756, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 60630.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4044755118588605, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.4765795201063154, "policy_loss": -0.02170990378144779, "vf_loss": 3.495872787882884, "vf_explained_var": -0.0035665472969412804, "kl": 0.012083187910635488, "entropy": 1.3877550890048345, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 20640.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 88000, "num_env_steps_trained": 88000, "num_agent_steps_sampled": 352000, "num_agent_steps_trained": 352000}, "env_runners": {"episode_reward_max": 140.0, "episode_reward_min": -80.7582523741271, "episode_reward_mean": 23.0508254044456, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -80.7582523741271}, "policy_reward_max": {"adversary_policy": 70.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 12.777777777777779, "agent_policy": -15.282507928887734}, "custom_metrics": {}, "hist_stats": {"episode_reward": [36.63662641933715, 0.0, 40.0, 32.83395070296486, 57.73561572977721, 0.0, 0.0, 20.0, 0.0, -3.7175863560168905, -34.57108466005262, 50.088725931465056, 0.0, 40.0, -1.0017576471371514, 119.70740026237758, -1.6752078413290816, 40.0, -0.10708133281745691, 80.0, 0.0, 0.0, 0.0, 60.0, 80.0, 100.0, -19.345790662384335, -6.987979507830573, 0.0, 60.0, 0.0, 0.0, 60.0, -5.645909305028118, 0.0, 120.0, 0.0, -2.6333274722453455, 120.0, 100.0, -1.6214775397874126, 0.0, 20.0, 20.0, 0.0, -10.908264148259082, 0.0, -0.008931947217333258, -5.106401576155597, 40.0, 0.0, 0.0, 0.0, -1.2395706454718591, 40.0, 0.0, 80.0, -5.525117615336508, 60.0, 0.0, -12.679533320739736, 0.0, 59.200002357673924, 0.0, 60.0, 40.0, 40.0, 20.0, 140.0, 0.0, 40.0, -13.805378119890008, 0.0, -3.579870119316439, -2.2516849131027037, 0.0, 60.0, 0.0, 20.0, 0.0, 0.0, 0.0, 60.0, 0.0, -0.04117863006606215, 0.0, 0.0, 0.0, 120.0, 100.0, -1.8063508508179593, 0.0, 0.0, 60.0, 59.12309804133398, -1.4938376885849614, 0.0, 0.0, 0.0, -9.998900154909482, -4.654940443624611, 40.0, 79.64993585488499, 20.0, 120.0, 0.0, 0.0, 0.0, 20.0, 0.0, -0.6953153435154058, 100.0, 20.0, -5.255192003313608, 40.0, -6.063158925648729, 40.0, 60.0, 0.0, -2.6871773413965903, -80.7582523741271, 60.0, 0.0, -3.314403025470698, -2.230713159416815, 20.0, -3.509538643072157, 0.0, 80.0, 0.0, 20.0, 55.61370894070858, 0.0, 59.966759243506296, 40.0, -2.813896122487135, 13.678310534117127, 16.33780652957331, 138.4588407204092, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 100.0, 100.0, 120.0, 20.0, 0.0, 49.20262391321214, -21.978892731398236, 0.0, 0.0, -1.2601667649737758, 60.0, 60.0, -20.959566103642356, 100.0, -10.743922382564598, 40.0, -1.3223322420059336], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 60.0, 60.0, 60.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-23.363373580662845, 0.0, -20.0, -27.166049297035126, -32.26438427022279, 0.0, 0.0, -10.0, 0.0, -3.7175863560168905, -34.57108466005262, -39.911274068534944, 0.0, -20.0, -1.0017576471371514, -60.292599737622425, -1.6752078413290816, -20.0, -0.10708133281745691, -40.0, 0.0, 0.0, 0.0, -30.0, -40.0, -50.0, -19.345790662384335, -6.987979507830573, 0.0, -30.0, 0.0, 0.0, -30.0, -5.645909305028118, 0.0, -60.0, 0.0, -2.6333274722453455, -60.0, -50.0, -1.6214775397874126, 0.0, -10.0, -10.0, 0.0, -10.908264148259082, 0.0, -0.008931947217333258, -5.106401576155597, -20.0, 0.0, 0.0, 0.0, -1.2395706454718591, -20.0, 0.0, -40.0, -5.525117615336508, -30.0, 0.0, -12.679533320739736, 0.0, -30.79999764232607, 0.0, -30.0, -20.0, -20.0, -10.0, -70.0, 0.0, -20.0, -13.805378119890008, 0.0, -3.579870119316439, -2.2516849131027037, 0.0, -30.0, 0.0, -10.0, 0.0, 0.0, 0.0, -30.0, 0.0, -0.04117863006606215, 0.0, 0.0, 0.0, -60.0, -50.0, -1.8063508508179593, 0.0, 0.0, -30.0, -30.876901958666014, -1.4938376885849614, 0.0, 0.0, 0.0, -9.998900154909482, -4.654940443624611, -20.0, -40.35006414511501, -10.0, -60.0, 0.0, 0.0, 0.0, -10.0, 0.0, -0.6953153435154058, -50.0, -10.0, -35.25519200331361, -20.0, -6.063158925648729, -20.0, -30.0, 0.0, -2.6871773413965903, -80.7582523741271, -30.0, 0.0, -3.314403025470698, -2.230713159416815, -10.0, -3.509538643072157, 0.0, -40.0, 0.0, -10.0, -34.386291059291416, 0.0, -30.033240756493704, -20.0, -2.813896122487135, -16.321689465882873, -43.66219347042669, -71.5411592795908, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -50.0, -50.0, -60.0, -10.0, 0.0, -40.79737608678786, -21.978892731398236, 0.0, 0.0, -1.2601667649737758, -30.0, -30.0, -20.959566103642356, -50.0, -10.743922382564598, -20.0, -1.3223322420059336]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6873689157094702, "mean_inference_ms": 1.1921989303349505, "mean_action_processing_ms": 0.23791208754836138, "mean_env_wait_ms": 0.5120281357972313, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004600889888810523, "StateBufferConnector_ms": 0.0032677326673342857, "ViewRequirementAgentConnector_ms": 0.08996048091370383}, "num_episodes": 162, "episode_return_max": 140.0, "episode_return_min": -80.7582523741271, "episode_return_mean": 23.0508254044456}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 352000, "num_agent_steps_trained": 352000, "num_env_steps_sampled": 88000, "num_env_steps_trained": 88000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 273.14279455100734, "num_env_steps_trained_throughput_per_sec": 273.14279455100734, "timesteps_total": 88000, "num_env_steps_sampled_lifetime": 88000, "num_agent_steps_sampled_lifetime": 352000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 352000, "timers": {"training_iteration_time_ms": 14514.374, "restore_workers_time_ms": 0.018, "training_step_time_ms": 14514.302, "sample_time_ms": 1293.134, "learn_time_ms": 13201.551, "learn_throughput": 302.995, "synch_weights_time_ms": 18.927}, "counters": {"num_env_steps_sampled": 88000, "num_env_steps_trained": 88000, "num_agent_steps_sampled": 352000, "num_agent_steps_trained": 352000}, "done": false, "training_iteration": 22, "trial_id": "86f16_00000", "date": "2024-08-08_16-17-51", "timestamp": 1723148271, "time_this_iter_s": 14.65893006324768, "time_total_s": 313.616952419281, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3aca2ac10>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 313.616952419281, "iterations_since_restore": 22, "perf": {"cpu_util_percent": 50.26190476190476, "ram_util_percent": 78.56666666666668}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7596634941849303, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.7268981389542843, "policy_loss": -0.014312604241443018, "vf_loss": 2.7396110372340425, "vf_explained_var": 2.4557325011449503e-06, "kl": 0.00799849194703415, "entropy": 1.218162536790185, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 63450.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4388323510686556, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.9806868995229405, "policy_loss": -0.016680612566900285, "vf_loss": 3.9951832508047422, "vf_explained_var": -0.0036552863816420238, "kl": 0.010921262521713295, "entropy": 1.399761497353514, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 21600.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 92000, "num_env_steps_trained": 92000, "num_agent_steps_sampled": 368000, "num_agent_steps_trained": 368000}, "env_runners": {"episode_reward_max": 200.0, "episode_reward_min": -38.56125445303386, "episode_reward_mean": 24.064088586823704, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -100.0}, "policy_reward_max": {"adversary_policy": 100.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 13.518518518518519, "agent_policy": -16.49146696873185}, "custom_metrics": {}, "hist_stats": {"episode_reward": [19.506579001878624, 0.0, 0.0, -9.92889660083082, 140.0, -4.231760018887034, 100.0, 80.0, 0.0, 0.0, 60.0, 40.0, 59.94532958310933, 200.0, 0.0, 100.0, 40.0, 0.0, -6.380020963251038, 0.0, -20.983331368900025, 0.0, 58.89630715392818, -33.992056537096, 0.0, -5.041970596228732, 0.0, 0.0, 20.0, -1.3530342082312008, -15.091488891785783, -22.972511010941002, 0.0, 160.0, -9.10803599488436, 38.55728348385644, 0.0, 80.0, -1.231057730098708, -38.56125445303386, 0.0, 0.0, 0.0, 0.0, -0.5448140946072411, -2.9750309921801446, 40.0, 37.35287236631135, 0.0, 32.6706945087367, -13.88224398065283, 40.0, 40.0, 40.0, -12.000914136518464, 0.0, 0.0, 0.0, -1.431239938613329, 60.0, -10.410034008315142, 20.0, 0.0, 59.79060219445084, 0.0, 0.0, -1.7014406743343002, -7.682196693666713, 60.0, 40.0, 19.658206532262355, 19.70702822251417, -0.8155165747823334, -15.416049334397108, 0.0, -10.887370603622651, -9.032510507602309, 100.0, 0.0, 0.0, -0.04091095032734304, 80.0, 19.996804050671795, 40.0, 22.011743344638166, 60.0, -2.237121770924806, 60.0, 80.0, -4.08061996071485, -6.660262946533087, 0.0, 60.0, 0.0, -31.824843389380572, 39.503412654377314, 0.0, 40.0, 58.407987989209786, -2.2071192131887134, 80.0, 140.0, 0.0, 60.0, -1.4173329228885367, 100.0, 40.0, 56.534601738116066, 0.0, 20.0, 0.0, 79.96327182379385, 0.0, -0.15987803835204373, -4.409319088599668, 0.0, 0.0, 0.0, 100.0, 60.0, -20.02420952287525, 0.0, 60.0, 118.07940305977279, 0.0, -3.832821800730907, 40.0, 0.0, -11.252835307535952, 20.0, 0.0, 80.0, 20.0, -7.739803774548731, 60.0, -21.30579995780559, 160.0, -15.101996399282973, 60.0, 0.0, 100.0, -12.065444808063802, 0.0, 80.0, 24.317289268333916, 0.0, 0.0, 60.0, 0.0, 0.0, -0.42367005705331917, 0.0, 0.0, 19.026422249156692, 120.0, -3.6808598785409137, 118.57614154112974, 20.0, 0.0, 0.0, 40.0, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 100.0, 100.0, 100.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 80.0, 80.0, 80.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 80.0, 80.0, 80.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-10.493420998121376, 0.0, 0.0, -9.92889660083082, -70.0, -4.231760018887034, -50.0, -40.0, 0.0, 0.0, -30.0, -20.0, -30.054670416890666, -100.0, 0.0, -50.0, -20.0, 0.0, -6.380020963251038, 0.0, -20.983331368900025, 0.0, -31.103692846071823, -33.992056537096, 0.0, -5.041970596228732, 0.0, 0.0, -10.0, -1.3530342082312008, -15.091488891785783, -22.972511010941002, 0.0, -80.0, -9.10803599488436, -21.44271651614356, 0.0, -40.0, -1.231057730098708, -38.56125445303386, 0.0, 0.0, 0.0, 0.0, -0.5448140946072411, -2.9750309921801446, -20.0, -22.64712763368864, 0.0, -27.329305491263298, -13.88224398065283, -20.0, -20.0, -20.0, -12.000914136518464, 0.0, 0.0, 0.0, -1.431239938613329, -30.0, -10.410034008315142, -10.0, 0.0, -30.209397805549155, 0.0, 0.0, -1.7014406743343002, -7.682196693666713, -30.0, -20.0, -10.341793467737645, -10.292971777485828, -0.8155165747823334, -15.416049334397108, 0.0, -10.887370603622651, -9.032510507602309, -50.0, 0.0, 0.0, -0.04091095032734304, -40.0, -10.003195949328207, -20.0, -37.98825665536182, -30.0, -2.237121770924806, -30.0, -40.0, -4.08061996071485, -6.660262946533087, 0.0, -30.0, 0.0, -31.824843389380572, -20.496587345622686, 0.0, -20.0, -31.59201201079021, -2.2071192131887134, -40.0, -70.0, 0.0, -30.0, -1.4173329228885367, -50.0, -20.0, -33.465398261883934, 0.0, -10.0, 0.0, -40.03672817620616, 0.0, -0.15987803835204373, -4.409319088599668, 0.0, 0.0, 0.0, -50.0, -30.0, -20.02420952287525, 0.0, -30.0, -61.92059694022721, 0.0, -3.832821800730907, -20.0, 0.0, -11.252835307535952, -10.0, 0.0, -40.0, -10.0, -37.73980377454872, -30.0, -21.30579995780559, -80.0, -15.101996399282973, -30.0, 0.0, -50.0, -12.065444808063802, 0.0, -40.0, -35.68271073166608, 0.0, 0.0, -30.0, 0.0, 0.0, -0.42367005705331917, 0.0, 0.0, -10.973577750843306, -60.0, -3.6808598785409137, -61.423858458870264, -10.0, 0.0, 0.0, -20.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6885381616418181, "mean_inference_ms": 1.1958373377963771, "mean_action_processing_ms": 0.2384693567106859, "mean_env_wait_ms": 0.5127016860839045, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00553131103515625, "StateBufferConnector_ms": 0.0035291100725715545, "ViewRequirementAgentConnector_ms": 0.11135207282172309}, "num_episodes": 162, "episode_return_max": 200.0, "episode_return_min": -38.56125445303386, "episode_return_mean": 24.064088586823704}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 368000, "num_agent_steps_trained": 368000, "num_env_steps_sampled": 92000, "num_env_steps_trained": 92000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 225.45105823835024, "num_env_steps_trained_throughput_per_sec": 225.45105823835024, "timesteps_total": 92000, "num_env_steps_sampled_lifetime": 92000, "num_agent_steps_sampled_lifetime": 368000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 368000, "timers": {"training_iteration_time_ms": 14465.013, "restore_workers_time_ms": 0.018, "training_step_time_ms": 14464.953, "sample_time_ms": 1293.346, "learn_time_ms": 13152.042, "learn_throughput": 304.135, "synch_weights_time_ms": 18.874}, "counters": {"num_env_steps_sampled": 92000, "num_env_steps_trained": 92000, "num_agent_steps_sampled": 368000, "num_agent_steps_trained": 368000}, "done": false, "training_iteration": 23, "trial_id": "86f16_00000", "date": "2024-08-08_16-18-09", "timestamp": 1723148289, "time_this_iter_s": 17.75568723678589, "time_total_s": 331.3726396560669, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3aca8f040>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 331.3726396560669, "iterations_since_restore": 23, "perf": {"cpu_util_percent": 61.38400000000001, "ram_util_percent": 79.184}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7629006598858123, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.947235824030342, "policy_loss": -0.012193282863706457, "vf_loss": 2.9578900707951674, "vf_explained_var": 2.091150757268811e-06, "kl": 0.0076951401445619055, "entropy": 1.1997577713313679, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 66270.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4018978571519256, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.5353528020282585, "policy_loss": -0.016488693674909884, "vf_loss": 4.549742551396291, "vf_explained_var": -0.005789491161704063, "kl": 0.010494785133976633, "entropy": 1.3837643013646206, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 22560.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 96000, "num_env_steps_trained": 96000, "num_agent_steps_sampled": 384000, "num_agent_steps_trained": 384000}, "env_runners": {"episode_reward_max": 220.0, "episode_reward_min": -31.074192940617653, "episode_reward_mean": 22.571019178425974, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -110.0}, "policy_reward_max": {"adversary_policy": 110.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 13.333333333333334, "agent_policy": -17.428980821574026}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-19.60429708760821, 39.40850045343562, 59.74325402038954, 0.0, -10.150211773187971, 36.91594735596313, -19.07290068591378, 0.0, 60.0, 0.0, -2.114068380709827, 0.0, -17.70601479815494, -23.17502712566543, 19.69151542327896, 0.0, -9.497009898297398, 17.4026617694312, 0.0, 58.62182671169728, 0.0, 0.0, 14.147837855574366, 40.0, 100.0, 20.0, -2.7608386072903093, 20.0, 60.0, 20.0, 0.0, 60.0, 0.0, -17.467026236099173, 97.6895455847813, 18.469763304790444, 23.53465282610032, -2.1633495258407254, 60.0, 19.087420016224062, 0.0, -15.305420044851598, 20.0, 80.0, -0.07658181156570909, 80.0, -16.61123861328779, -3.526148404450063, 78.00356921982345, -13.085634184319359, 80.0, 100.0, 60.0, -1.2899903095660648, -7.083792498992596, -16.263371563437694, 0.0, -11.394531644764557, 4.6124994418380405, 57.66767946421521, 0.0, 40.0, -20.552858428975345, 140.0, 0.0, -7.260392583069685, 40.0, 0.0, 22.522938552022733, -0.14895091307350894, -0.5598446382482569, -10.476067618138215, 26.17037358259431, -31.074192940617653, 40.0, 60.0, 0.0, 44.512551132067415, -2.484815806445086, 0.0, -19.759979378407504, 40.0, 60.0, 0.0, 80.0, -3.666295407751246, 40.0, 0.0, 0.0, 0.0, -0.18972192360814488, 7.524020555050483, -0.6159056683971209, 0.0, 80.0, -4.099030005345619, 65.40071811988877, -1.7121746009045347, 44.24627146469552, -0.52081542920144, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 100.0, 0.0, -0.6010475865845266, -23.350048100323683, 80.0, 100.0, 220.0, -3.75047173448926, 100.0, 120.0, 60.0, 40.0, 0.0, -0.6366525792058653, -10.987906731884538, -8.953241179658011, 40.0, 38.69527449585236, 0.0, -23.79997131407966, 0.0, 0.0, 40.58340967564736, 40.0, -9.331893506701748, 0.0, 0.0, -0.4146520186290681, -0.4119679602650861, -18.112154582096746, -16.35335657217016, 80.0, 40.0, 0.0, 120.0, 36.416498442577726, 60.0, -6.581305086152025, 20.0, 15.815387060008955, 80.0, -1.3776067907669154, -20.93873537519228, -0.2136796318335521, 40.0, 0.0, 40.0, 39.98735563113217, 76.19898072786167, -2.432135835356026, 80.0, 80.0, 60.0, 0.0, -6.850020860358983, 40.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 50.0, 50.0, 50.0, 110.0, 110.0, 110.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 60.0, 60.0, 60.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0], "policy_agent_policy_reward": [-19.60429708760821, -20.591499546564382, -30.25674597961046, 0.0, -10.150211773187971, -23.084052644036873, -19.07290068591378, 0.0, -30.0, 0.0, -2.114068380709827, 0.0, -17.70601479815494, -23.17502712566543, -10.308484576721039, 0.0, -9.497009898297398, -12.597338230568798, 0.0, -31.378173288302726, 0.0, 0.0, -15.852162144425634, -20.0, -50.0, -10.0, -2.7608386072903093, -10.0, -30.0, -10.0, 0.0, -30.0, 0.0, -17.467026236099173, -52.3104544152187, -11.530236695209556, -66.46534717389967, -2.1633495258407254, -30.0, -10.912579983775938, 0.0, -15.305420044851598, -10.0, -40.0, -0.07658181156570909, -40.0, -16.61123861328779, -3.526148404450063, -41.996430780176546, -13.085634184319359, -40.0, -50.0, -30.0, -1.2899903095660648, -7.083792498992596, -16.263371563437694, 0.0, -11.394531644764557, -25.38750055816196, -32.33232053578479, 0.0, -20.0, -20.552858428975345, -70.0, 0.0, -7.260392583069685, -20.0, 0.0, -37.47706144797726, -0.14895091307350894, -0.5598446382482569, -10.476067618138215, -33.82962641740569, -31.074192940617653, -20.0, -30.0, 0.0, -45.487448867932585, -2.484815806445086, 0.0, -19.759979378407504, -20.0, -30.0, 0.0, -40.0, -3.666295407751246, -20.0, 0.0, 0.0, 0.0, -0.18972192360814488, -22.475979444949516, -0.6159056683971209, 0.0, -40.0, -4.099030005345619, -54.599281880111214, -1.7121746009045347, -45.75372853530447, -0.52081542920144, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -50.0, 0.0, -0.6010475865845266, -23.350048100323683, -40.0, -50.0, -110.0, -3.75047173448926, -50.0, -60.0, -30.0, -20.0, 0.0, -0.6366525792058653, -10.987906731884538, -8.953241179658011, -20.0, -21.304725504147644, 0.0, -23.79997131407966, 0.0, 0.0, -49.41659032435264, -20.0, -9.331893506701748, 0.0, 0.0, -0.4146520186290681, -0.4119679602650861, -18.112154582096746, -16.35335657217016, -40.0, -20.0, 0.0, -60.0, -23.583501557422274, -30.0, -6.581305086152025, -10.0, -14.184612939991045, -40.0, -1.3776067907669154, -20.93873537519228, -0.2136796318335521, -20.0, 0.0, -20.0, -20.012644368867832, -43.80101927213833, -2.432135835356026, -40.0, -40.0, -30.0, 0.0, -6.850020860358983, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6888010025788875, "mean_inference_ms": 1.1970870690909605, "mean_action_processing_ms": 0.23864888764329562, "mean_env_wait_ms": 0.513126310154256, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0049749274312714, "StateBufferConnector_ms": 0.0034964378969168956, "ViewRequirementAgentConnector_ms": 0.10016023376841604}, "num_episodes": 162, "episode_return_max": 220.0, "episode_return_min": -31.074192940617653, "episode_return_mean": 22.571019178425974}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 384000, "num_agent_steps_trained": 384000, "num_env_steps_sampled": 96000, "num_env_steps_trained": 96000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 229.85059478983894, "num_env_steps_trained_throughput_per_sec": 229.85059478983894, "timesteps_total": 96000, "num_env_steps_sampled_lifetime": 96000, "num_agent_steps_sampled_lifetime": 384000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 384000, "timers": {"training_iteration_time_ms": 14901.619, "restore_workers_time_ms": 0.018, "training_step_time_ms": 14901.56, "sample_time_ms": 1280.751, "learn_time_ms": 13602.074, "learn_throughput": 294.073, "synch_weights_time_ms": 17.974}, "counters": {"num_env_steps_sampled": 96000, "num_env_steps_trained": 96000, "num_agent_steps_sampled": 384000, "num_agent_steps_trained": 384000}, "done": false, "training_iteration": 24, "trial_id": "86f16_00000", "date": "2024-08-08_16-18-26", "timestamp": 1723148306, "time_this_iter_s": 17.438270092010498, "time_total_s": 348.8109097480774, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3aca54e50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 348.8109097480774, "iterations_since_restore": 24, "perf": {"cpu_util_percent": 58.715999999999994, "ram_util_percent": 79.68800000000002}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7792370168875296, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.873253247923885, "policy_loss": -0.01551400478599025, "vf_loss": 2.887060431554808, "vf_explained_var": -5.662610344852961e-06, "kl": 0.008534074458082226, "entropy": 1.1957050769041615, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 69090.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.456404486981531, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.972427508731683, "policy_loss": -0.01702362222713418, "vf_loss": 3.9872904675702254, "vf_explained_var": 0.001319474478562673, "kl": 0.010803323716620856, "entropy": 1.3835864740113417, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 23520.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 100000, "num_env_steps_trained": 100000, "num_agent_steps_sampled": 400000, "num_agent_steps_trained": 400000}, "env_runners": {"episode_reward_max": 140.0, "episode_reward_min": -25.464327511535544, "episode_reward_mean": 23.21814413185363, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -70.64158582305436}, "policy_reward_max": {"adversary_policy": 70.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 12.962962962962964, "agent_policy": -15.670744757035258}, "custom_metrics": {}, "hist_stats": {"episode_reward": [66.12749928272659, 0.0, 0.0, 59.94324388034286, 0.0, -5.3418356962440825, 56.811453187324915, 40.0, 0.0, 99.80189333853558, 56.28998068573098, 0.0, 0.0, -1.5994403790773037, 40.0, 0.0, 0.0, 20.0, 60.0, 0.0, 20.0, 60.0, 59.982412289110016, 0.0, 60.0, 78.14966230483235, 60.0, 0.0, 0.0, -13.059194963154178, 0.0, 0.0, 0.0, 0.0, 100.0, 20.0, -7.895320104875694, 55.691644297938744, -14.40760192200173, 0.0, 4.8123923955197885, 0.0, 0.0, 0.0, 0.0, -2.6259652572423997, 0.0, 60.0, -4.421950483254229, 0.0, 40.0, 0.0, 60.0, 0.0, 0.0, 139.35841417694564, 0.0, 40.0, 60.0, 53.76081338878909, -3.071349474890501, 1.644163755449923, 80.0, 40.0, -7.658634405105091, 0.0, -0.5049938155706801, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 0.0, 99.50170115932146, -2.8737030097509564, 0.0, 0.0, 66.34498588770178, 40.0, 0.0, -1.3099893589958367, 0.0, 80.0, -1.0450792712266743, -12.861294651016324, 33.165638144249755, 40.0, 40.0, 0.0, -6.801636130958807, 0.0, -9.7177233973865, 140.0, -1.3023266429882363, 60.0, 40.0, 20.0, 34.93642573843164, 79.63091159186592, 0.0, -0.31501340077526363, 0.0, -1.740703923451531, 20.0, 25.330992462088105, 0.0, 40.0, 78.90005650127861, 30.50426448902671, -5.866639079488348, 0.0, 0.0, 79.65496621520869, 0.0, 0.0, 0.0, -12.510495679735163, 48.21541450972926, 0.0, 0.0, -14.763318676678596, 40.0, -3.0055424409451668, 40.0, 60.0, 60.0, 0.0, 21.405779922317105, 19.394871529158618, -3.7292662192359387, -13.822075259833946, 60.0, -3.743243784663049, 38.37047305000968, 0.0, 20.0, 100.0, -12.113816954840765, 60.0, -25.464327511535544, 0.0, 38.26232701940127, -7.082971099715495, 58.65335381935105, 120.0, 40.0, 0.0, 60.0, -22.322347140715088, -1.4988853881973419, 48.52178090809707, 60.0, 0.0, 0.0, -23.675653570226302, 100.0, 60.0, 18.958616906060477, 59.060155580672514, 59.39012069650775, 18.915279340340852], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0], "policy_agent_policy_reward": [-53.87250071727341, 0.0, 0.0, -30.056756119657134, 0.0, -5.3418356962440825, -33.188546812675085, -20.0, 0.0, -50.19810666146442, -33.71001931426902, 0.0, 0.0, -1.5994403790773037, -20.0, 0.0, 0.0, -10.0, -30.0, 0.0, -10.0, -30.0, -30.01758771088998, 0.0, -30.0, -41.85033769516765, -30.0, 0.0, 0.0, -13.059194963154178, 0.0, 0.0, 0.0, 0.0, -50.0, -10.0, -7.895320104875694, -34.30835570206126, -14.40760192200173, 0.0, -25.187607604480213, 0.0, 0.0, 0.0, 0.0, -2.6259652572423997, 0.0, -30.0, -4.421950483254229, 0.0, -20.0, 0.0, -30.0, 0.0, 0.0, -70.64158582305436, 0.0, -20.0, -30.0, -36.23918661121092, -3.071349474890501, -28.35583624455008, -40.0, -20.0, -7.658634405105091, 0.0, -0.5049938155706801, 0.0, 0.0, 0.0, 0.0, 0.0, -30.0, 0.0, -50.498298840678544, -2.8737030097509564, 0.0, 0.0, -53.65501411229822, -20.0, 0.0, -1.3099893589958367, 0.0, -40.0, -1.0450792712266743, -12.861294651016324, -26.834361855750245, -20.0, -20.0, 0.0, -6.801636130958807, 0.0, -9.7177233973865, -70.0, -1.3023266429882363, -30.0, -20.0, -10.0, -25.063574261568363, -40.369088408134076, 0.0, -0.31501340077526363, 0.0, -1.740703923451531, -10.0, -34.669007537911895, 0.0, -20.0, -41.09994349872139, -59.49573551097329, -5.866639079488348, 0.0, 0.0, -40.34503378479131, 0.0, 0.0, 0.0, -12.510495679735163, -41.78458549027074, 0.0, 0.0, -14.763318676678596, -20.0, -3.0055424409451668, -20.0, -30.0, -30.0, 0.0, -38.59422007768289, -10.605128470841382, -3.7292662192359387, -13.822075259833946, -30.0, -3.743243784663049, -21.62952694999032, 0.0, -10.0, -50.0, -12.113816954840765, -30.0, -25.464327511535544, 0.0, -21.737672980598727, -7.082971099715495, -31.346646180648953, -60.0, -20.0, 0.0, -30.0, -22.322347140715088, -1.4988853881973419, -41.47821909190293, -30.0, 0.0, 0.0, -23.675653570226302, -50.0, -30.0, -11.041383093939523, -30.939844419327486, -30.60987930349225, -11.08472065965915]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6878231515543176, "mean_inference_ms": 1.1971668569962153, "mean_action_processing_ms": 0.23829324210591044, "mean_env_wait_ms": 0.5132243276209888, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0046454829934202595, "StateBufferConnector_ms": 0.0032876744682406203, "ViewRequirementAgentConnector_ms": 0.09510016735689139}, "num_episodes": 162, "episode_return_max": 140.0, "episode_return_min": -25.464327511535544, "episode_return_mean": 23.21814413185363}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 400000, "num_agent_steps_trained": 400000, "num_env_steps_sampled": 100000, "num_env_steps_trained": 100000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 321.76437454294876, "num_env_steps_trained_throughput_per_sec": 321.76437454294876, "timesteps_total": 100000, "num_env_steps_sampled_lifetime": 100000, "num_agent_steps_sampled_lifetime": 400000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 400000, "timers": {"training_iteration_time_ms": 14855.701, "restore_workers_time_ms": 0.019, "training_step_time_ms": 14855.642, "sample_time_ms": 1283.185, "learn_time_ms": 13556.845, "learn_throughput": 295.054, "synch_weights_time_ms": 14.991}, "counters": {"num_env_steps_sampled": 100000, "num_env_steps_trained": 100000, "num_agent_steps_sampled": 400000, "num_agent_steps_trained": 400000}, "done": false, "training_iteration": 25, "trial_id": "86f16_00000", "date": "2024-08-08_16-18-39", "timestamp": 1723148319, "time_this_iter_s": 12.435627937316895, "time_total_s": 361.2465376853943, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3aca8f820>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 361.2465376853943, "iterations_since_restore": 25, "perf": {"cpu_util_percent": 39.61176470588236, "ram_util_percent": 78.77058823529411}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7630462632640034, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.8844615503828575, "policy_loss": -0.014418428318561815, "vf_loss": 2.897403221012007, "vf_explained_var": -3.695340021282223e-06, "kl": 0.007383732599228847, "entropy": 1.1623142158308772, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 71910.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5443322451785206, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.148168501506249, "policy_loss": -0.0188615580254312, "vf_loss": 4.164780782908201, "vf_explained_var": 0.006496493332087993, "kl": 0.011246443933320848, "entropy": 1.371118845542272, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 24480.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 104000, "num_env_steps_trained": 104000, "num_agent_steps_sampled": 416000, "num_agent_steps_trained": 416000}, "env_runners": {"episode_reward_max": 160.0, "episode_reward_min": -31.834483820177674, "episode_reward_mean": 27.033795278960568, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 153, "episodes_timesteps_total": 3825, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -82.75107066773674}, "policy_reward_max": {"adversary_policy": 80.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 15.032679738562091, "agent_policy": -18.064243936725706}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.0, 100.0, -11.255957622091124, 100.0, 40.0, 15.908883532658312, 0.0, 37.48468733239173, 116.7039288921655, -11.92822470731295, 100.0, 37.63769518111402, 0.0, 157.24892933226326, 12.252012698591495, 0.0, 77.17681758859821, -5.844778899925377, 60.0, -10.989647911365987, -21.51518375394235, 80.0, -7.300728953649333, 40.0, -1.9216312604476133, 40.0, 77.57023994113476, 20.0, 0.0, -1.622038252406336, 0.0, 160.0, 0.0, 60.0, -7.155041063932196, 0.0, 60.0, 0.0, -1.3930145252888626, -0.40781235718624576, 40.0, 38.387239548885944, 0.0, 20.0, 0.0, 59.89187990049949, 0.0, -31.834483820177674, 20.0, -9.744779938616858, -23.70443164873279, 35.295892841847575, 0.0, 0.0, 0.0, 20.0, -11.49513090870331, 27.87868922419602, 0.0, -0.0018922033847224018, -27.947889043600846, 80.0, -0.015846807717360134, 120.0, 0.0, 0.0, 20.0, 60.0, 16.65815720913395, 0.0, 0.0, 60.0, 0.0, 20.0, 0.0, -3.34115760475291, -11.167802812827404, 0.0, -5.957359764987303, 119.82620540116262, -1.0718973506895157, -2.5540909063846176, 99.14437460821941, 0.0, 0.0, 20.0, -1.7947672121945446, -15.566766588654746, 59.640532556851326, 38.43445141488724, -30.956705531606136, 0.0, 17.646538236978877, 0.0, -14.152214147250756, -0.10437623546541097, 20.0, 77.75095515643179, -8.718052276524851, 78.7445130774075, 40.0, 0.0, 0.0, 0.0, 60.0, 132.8582176126218, -1.0464810291466886, 59.91436841340062, 0.0, 19.310642052368042, 0.0, 0.0, 60.0, 20.0, 40.0, 40.0, -5.464888802496928, 100.0, 40.0, 60.0, 56.92925770165808, 120.0, 60.0, 20.0, 0.0, 0.0, -0.8189846444321425, 60.0, 0.0, 27.34349209646921, 0.0, -0.5903612131743219, 0.0, 75.0206741698957, 0.0, 140.0, 0.0, -7.96991986519585, 76.58178228517471, 100.0, 60.0, 60.0, 40.0, 114.23845853127995, 0.0, 0.0, -14.104832351924403, 0.0, 80.0, 79.71494639877193, 19.841113019849217, -15.405726259751031, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 80.0, 80.0, 80.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 80.0, 80.0, 80.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 60.0, 60.0, 60.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-20.0, -50.0, -11.255957622091124, -50.0, -20.0, -44.09111646734169, 0.0, -22.515312667608267, -63.296071107834514, -11.92822470731295, -50.0, -22.36230481888598, 0.0, -82.75107066773674, -17.7479873014085, 0.0, -42.823182411401795, -5.844778899925377, -30.0, -40.98964791136599, -21.51518375394235, -40.0, -7.300728953649333, -20.0, -1.9216312604476133, -20.0, -42.42976005886525, -10.0, 0.0, -1.622038252406336, 0.0, -80.0, 0.0, -30.0, -7.155041063932196, 0.0, -30.0, 0.0, -1.3930145252888626, -0.40781235718624576, -20.0, -21.612760451114056, 0.0, -10.0, 0.0, -30.108120099500514, 0.0, -31.834483820177674, -10.0, -9.744779938616858, -23.70443164873279, -24.70410715815242, 0.0, 0.0, 0.0, -10.0, -11.49513090870331, -32.12131077580398, 0.0, -0.0018922033847224018, -27.947889043600846, -40.0, -0.015846807717360134, -60.0, 0.0, 0.0, -10.0, -30.0, -13.34184279086605, 0.0, 0.0, -30.0, 0.0, -10.0, 0.0, -3.34115760475291, -11.167802812827404, 0.0, -5.957359764987303, -60.173794598837375, -1.0718973506895157, -2.5540909063846176, -50.85562539178059, 0.0, 0.0, -10.0, -1.7947672121945446, -15.566766588654746, -30.35946744314868, -21.565548585112758, -30.956705531606136, 0.0, -12.353461763021121, 0.0, -14.152214147250756, -0.10437623546541097, -10.0, -42.249044843568214, -8.718052276524851, -41.2554869225925, -20.0, 0.0, 0.0, 0.0, -30.0, -77.14178238737823, -1.0464810291466886, -30.085631586599387, 0.0, -10.689357947631954, 0.0, 0.0, -30.0, -10.0, -20.0, -20.0, -5.464888802496928, -50.0, -20.0, -30.0, -33.070742298341926, -60.0, -30.0, -10.0, 0.0, 0.0, -0.8189846444321425, -30.0, 0.0, -32.656507903530795, 0.0, -0.5903612131743219, 0.0, -44.9793258301043, 0.0, -70.0, 0.0, -7.96991986519585, -43.41821771482528, -50.0, -30.0, -30.0, -20.0, -65.76154146872005, 0.0, 0.0, -14.104832351924403, 0.0, -40.0, -40.28505360122807, -10.158886980150784, -15.405726259751031, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6843108190820207, "mean_inference_ms": 1.1908693575163687, "mean_action_processing_ms": 0.23737135038867832, "mean_env_wait_ms": 0.5109645758848632, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004513902601852916, "StateBufferConnector_ms": 0.0031002985885719846, "ViewRequirementAgentConnector_ms": 0.08452632068808562}, "num_episodes": 153, "episode_return_max": 160.0, "episode_return_min": -31.834483820177674, "episode_return_mean": 27.033795278960568}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 416000, "num_agent_steps_trained": 416000, "num_env_steps_sampled": 104000, "num_env_steps_trained": 104000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 349.61997837497927, "num_env_steps_trained_throughput_per_sec": 349.61997837497927, "timesteps_total": 104000, "num_env_steps_sampled_lifetime": 104000, "num_agent_steps_sampled_lifetime": 416000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 416000, "timers": {"training_iteration_time_ms": 14756.868, "restore_workers_time_ms": 0.018, "training_step_time_ms": 14756.81, "sample_time_ms": 1261.604, "learn_time_ms": 13479.814, "learn_throughput": 296.74, "synch_weights_time_ms": 14.791}, "counters": {"num_env_steps_sampled": 104000, "num_env_steps_trained": 104000, "num_agent_steps_sampled": 416000, "num_agent_steps_trained": 416000}, "done": false, "training_iteration": 26, "trial_id": "86f16_00000", "date": "2024-08-08_16-18-51", "timestamp": 1723148331, "time_this_iter_s": 11.446196794509888, "time_total_s": 372.6927344799042, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3aca8fa60>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 372.6927344799042, "iterations_since_restore": 26, "perf": {"cpu_util_percent": 29.176470588235293, "ram_util_percent": 78.50588235294117}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7249791912364622, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.2975609849108025, "policy_loss": -0.013847380318242977, "vf_loss": 2.3097757831110175, "vf_explained_var": -4.3515829329795024e-06, "kl": 0.008162863746576933, "entropy": 1.1536606234438875, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 74730.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5035661007588108, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.8132694519435364, "policy_loss": -0.016509136671569044, "vf_loss": 3.8277877284834783, "vf_explained_var": -0.0018855675434072813, "kl": 0.00995429651224883, "entropy": 1.3687921247134607, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 25440.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 108000, "num_env_steps_trained": 108000, "num_agent_steps_sampled": 432000, "num_agent_steps_trained": 432000}, "env_runners": {"episode_reward_max": 200.0, "episode_reward_min": -34.74608531404891, "episode_reward_mean": 18.253288593403216, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -100.0}, "policy_reward_max": {"adversary_policy": 100.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 10.864197530864198, "agent_policy": -14.33930399918938}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-2.520836372142489, -8.958096592059906, 0.0, -0.9677256456681604, 20.0, 38.533285998232344, -0.6770416415850478, 39.687739929789345, 79.39406755386963, 0.0, 40.0, -18.503942872484618, 0.0, -15.563549565666381, 60.0, 44.844892319523595, -16.593251764824142, 80.0, 40.0, 38.694903550752926, 37.546805383225006, 0.0, -8.533182897735857, 11.17446447863183, 0.0, -20.046970071196, 40.0, -5.376301175004237, 0.0, 0.0, 0.0, -0.11501753712642504, -2.883121328881475, 0.0, 40.0, 37.26116240283872, 100.0, 20.0, -3.293892147275537, 20.0, 20.0, 0.0, -0.09056594633881976, -2.1834337071869303, -19.346042069213638, -17.287007125157537, 20.0, -0.7659678375375234, 20.0, -15.759477556567727, -11.417933745111345, 0.0, 40.0, 12.759779333946184, 99.41505498112151, -8.044006685687306, -26.416046003959575, 80.0, 0.0, 0.0, 0.0, -2.794578332979806, 20.0, 100.0, 40.0, 0.0, 200.0, -17.153846231022698, 80.0, -19.305971371560904, 0.0, 140.0, -27.941545471783616, 60.0, 100.0, 80.0, 0.0, 0.0, -7.581333134706288, 0.0, 19.77169986568038, -30.131222964402458, 40.0, 80.0, 0.0, -1.3698323358815456, 0.0, 0.0, -0.12842546311887082, -1.8757755010583932, -0.5179234701417124, 0.0, 100.0, -1.3979046781115079, 40.0, -0.8879500880240154, 0.0, 60.0, 18.199564081306885, 0.0, 20.0, 0.0, 0.0, -1.111052773392448, 0.0, 0.0, 37.12352710559833, -13.920787951307535, 0.0, 0.0, 0.0, -34.74608531404891, 93.06156375816398, 0.0, -1.7126719781374433, 0.0, 119.6259485356264, 60.0, 50.82349957596461, 0.0, 0.0, -5.5660981203015165, 46.04550054274731, -3.8380727001363972, 0.0, 5.97568493236487, -3.777929510968918, 0.0, -10.38104916470337, 20.0, 16.800666067149145, 0.0, -1.6340068624162984, 80.0, 60.0, 0.0, -14.821302868913296, -5.66092196523124, 0.0, 0.0, 39.245318648798275, 0.0, 0.0, 0.0, -0.5414062985681101, 0.0, 0.0, 0.0, 80.0, 60.0, 10.99598490423167, -4.405599248616534, 60.0, -0.044004022857345726, 60.0, 0.0, 60.0, -1.3576537074401573, 0.0, 100.0, 0.0, 40.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 100.0, 100.0, 100.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0], "policy_agent_policy_reward": [-2.520836372142489, -8.958096592059906, 0.0, -0.9677256456681604, -10.0, -21.466714001767656, -0.6770416415850478, -20.31226007021065, -40.60593244613036, 0.0, -20.0, -18.503942872484618, 0.0, -15.563549565666381, -30.0, -45.155107680476405, -16.593251764824142, -40.0, -20.0, -21.305096449247078, -22.453194616775, 0.0, -8.533182897735857, -48.82553552136817, 0.0, -20.046970071196, -20.0, -5.376301175004237, 0.0, 0.0, 0.0, -0.11501753712642504, -2.883121328881475, 0.0, -20.0, -52.73883759716128, -50.0, -10.0, -3.293892147275537, -10.0, -10.0, 0.0, -0.09056594633881976, -2.1834337071869303, -19.346042069213638, -17.287007125157537, -10.0, -0.7659678375375234, -10.0, -15.759477556567727, -11.417933745111345, 0.0, -20.0, -17.240220666053816, -50.584945018878486, -8.044006685687306, -26.416046003959575, -40.0, 0.0, 0.0, 0.0, -2.794578332979806, -10.0, -50.0, -20.0, 0.0, -100.0, -17.153846231022698, -40.0, -19.305971371560904, 0.0, -70.0, -27.941545471783616, -30.0, -50.0, -40.0, 0.0, 0.0, -7.581333134706288, 0.0, -10.228300134319621, -30.131222964402458, -20.0, -40.0, 0.0, -1.3698323358815456, 0.0, 0.0, -0.12842546311887082, -1.8757755010583932, -0.5179234701417124, 0.0, -50.0, -1.3979046781115079, -20.0, -0.8879500880240154, 0.0, -30.0, -11.800435918693115, 0.0, -10.0, 0.0, 0.0, -1.111052773392448, 0.0, 0.0, -22.876472894401676, -13.920787951307535, 0.0, 0.0, 0.0, -34.74608531404891, -56.938436241836015, 0.0, -1.7126719781374433, 0.0, -60.374051464373586, -30.0, -39.17650042403539, 0.0, 0.0, -5.5660981203015165, -43.95449945725268, -3.8380727001363972, 0.0, -24.024315067635136, -3.777929510968918, 0.0, -10.38104916470337, -10.0, -13.199333932850855, 0.0, -1.6340068624162984, -40.0, -30.0, 0.0, -14.821302868913296, -5.66092196523124, 0.0, 0.0, -20.75468135120172, 0.0, 0.0, 0.0, -0.5414062985681101, 0.0, 0.0, 0.0, -40.0, -30.0, -19.00401509576833, -4.405599248616534, -30.0, -0.044004022857345726, -30.0, 0.0, -30.0, -1.3576537074401573, 0.0, -50.0, 0.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6807806250912162, "mean_inference_ms": 1.1842123298343066, "mean_action_processing_ms": 0.23629385612485887, "mean_env_wait_ms": 0.508705012236371, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004514426360895604, "StateBufferConnector_ms": 0.0030836205423614123, "ViewRequirementAgentConnector_ms": 0.08407485337904942}, "num_episodes": 162, "episode_return_max": 200.0, "episode_return_min": -34.74608531404891, "episode_return_mean": 18.253288593403216}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 432000, "num_agent_steps_trained": 432000, "num_env_steps_sampled": 108000, "num_env_steps_trained": 108000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 289.6451008405849, "num_env_steps_trained_throughput_per_sec": 289.6451008405849, "timesteps_total": 108000, "num_env_steps_sampled_lifetime": 108000, "num_agent_steps_sampled_lifetime": 432000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 432000, "timers": {"training_iteration_time_ms": 14869.69, "restore_workers_time_ms": 0.015, "training_step_time_ms": 14869.64, "sample_time_ms": 1247.374, "learn_time_ms": 13605.946, "learn_throughput": 293.989, "synch_weights_time_ms": 15.714}, "counters": {"num_env_steps_sampled": 108000, "num_env_steps_trained": 108000, "num_agent_steps_sampled": 432000, "num_agent_steps_trained": 432000}, "done": false, "training_iteration": 27, "trial_id": "86f16_00000", "date": "2024-08-08_16-19-05", "timestamp": 1723148345, "time_this_iter_s": 13.855998992919922, "time_total_s": 386.5487334728241, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3aca8fb80>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 386.5487334728241, "iterations_since_restore": 27, "perf": {"cpu_util_percent": 42.699999999999996, "ram_util_percent": 77.92000000000002}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7462510401898242, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.9608235193905257, "policy_loss": -0.013005133213331686, "vf_loss": 2.972443853456078, "vf_explained_var": -5.063668210455712e-06, "kl": 0.006923964822882598, "entropy": 1.131477126331194, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 77550.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6286112995818258, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.348909461498261, "policy_loss": -0.017109063435782446, "vf_loss": 4.363909634947777, "vf_explained_var": 0.010338957173128922, "kl": 0.010544516674729228, "entropy": 1.3427047022928795, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 26400.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 112000, "num_env_steps_trained": 112000, "num_agent_steps_sampled": 448000, "num_agent_steps_trained": 448000}, "env_runners": {"episode_reward_max": 180.0, "episode_reward_min": -43.87617181636253, "episode_reward_mean": 21.704131065645583, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -90.0}, "policy_reward_max": {"adversary_policy": 90.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 12.592592592592593, "agent_policy": -16.073646712132195}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, -1.6425147972389553, 137.7609154527496, 20.0, 0.0, 0.0, 180.0, -16.012891869315567, 0.0, 0.0, 120.0, -0.6960269423087906, -8.06484433259218, 60.0, 60.0, 0.0, 100.0, 40.0, -1.9941691123738392, 0.0, 37.9149890523795, 59.540378697078346, 20.0, 33.98633980556482, 0.0, -2.39877595359529, 0.0, 0.0, 40.0, 60.0, 80.0, -31.893217024400105, 40.0, 0.0, 0.0, -1.5792017922508428, 17.522610469732026, 60.0, 140.0, -8.21667888745009, 0.0, 75.12052915457193, 0.0, -11.859867894719315, -7.564629878157863, 40.0, 0.0, -20.138843762050076, 60.0, -6.033217595105866, 20.0, 80.0, 28.00838867959572, 20.0, -7.092968663367325, 0.0, 0.0, -11.744375828551119, -0.588546810336581, 0.0, 20.0, 0.0, 0.0, 0.0, -0.22505862779752306, -1.417205549118642, 59.761816753083906, 0.0, -21.491030796711474, 20.0, 40.0, 60.0, 0.0, -34.3694342891622, 58.36495765375747, -14.845739839926592, 100.0, -0.369688837474923, 0.0, 0.0, -4.1274254655885985, 40.0, -22.21849099758051, 0.0, 0.0, -21.487382266349442, 0.0, -3.6885220451123986, 80.0, -0.2107088808665336, 20.0, 45.62596612195068, 20.0, 18.916379378782878, 58.732416162222094, 17.284128775894605, -0.2970868477896116, -8.016191047193502, 39.91280457335119, 60.0, 100.0, 20.0, -4.403500093238694, 0.0, -13.08813782427294, 0.0, 16.42491010406747, -0.31012436144858935, 0.0, -0.23054236012073015, 0.0, 36.05577345666136, -1.8663152552744888, 0.0, 0.0, 0.0, 0.0, 120.0, 13.529270684832591, 60.0, -12.434538840185457, -3.10964030036976, 100.0, 39.65236063262224, 0.0, 40.0, -19.62074504098002, 80.0, -2.688184049285045, 0.0, 0.0, 0.0, 56.2072353661268, 25.93872254690048, -1.1004887918882655, 40.0, 40.0, 40.0, 40.0, 20.0, 0.0, 40.0, -37.1050533300073, 100.0, -26.969331047104983, 42.68199054130986, 0.0, 0.0, 40.0, 180.0, 60.0, -0.41174869378695744, -10.294229687963288, 59.531155122213505, 60.0, 55.95445322919079, 38.48176671281455, 0.0, -0.67548901263075, -6.238462646497682, -43.87617181636253, 17.866413293033016], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 90.0, 90.0, 90.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 90.0, 90.0, 90.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0], "policy_agent_policy_reward": [0.0, -1.6425147972389553, -72.2390845472504, -10.0, 0.0, 0.0, -90.0, -16.012891869315567, 0.0, 0.0, -60.0, -0.6960269423087906, -8.06484433259218, -30.0, -30.0, 0.0, -50.0, -20.0, -1.9941691123738392, 0.0, -22.085010947620507, -30.459621302921654, -10.0, -26.013660194435182, 0.0, -2.39877595359529, 0.0, 0.0, -20.0, -30.0, -40.0, -31.893217024400105, -20.0, 0.0, 0.0, -1.5792017922508428, -12.477389530267974, -30.0, -70.0, -8.21667888745009, 0.0, -44.87947084542806, 0.0, -11.859867894719315, -7.564629878157863, -20.0, 0.0, -20.138843762050076, -30.0, -6.033217595105866, -10.0, -40.0, -31.99161132040428, -10.0, -7.092968663367325, 0.0, 0.0, -11.744375828551119, -0.588546810336581, 0.0, -10.0, 0.0, 0.0, 0.0, -0.22505862779752306, -1.417205549118642, -30.238183246916094, 0.0, -21.491030796711474, -10.0, -20.0, -30.0, 0.0, -34.3694342891622, -31.63504234624252, -14.845739839926592, -50.0, -0.369688837474923, 0.0, 0.0, -4.1274254655885985, -20.0, -22.21849099758051, 0.0, 0.0, -21.487382266349442, 0.0, -3.6885220451123986, -40.0, -0.2107088808665336, -10.0, -44.37403387804932, -10.0, -11.08362062121712, -31.267583837777902, -12.715871224105395, -0.2970868477896116, -8.016191047193502, -20.08719542664881, -30.0, -50.0, -10.0, -4.403500093238694, 0.0, -13.08813782427294, 0.0, -13.575089895932527, -0.31012436144858935, 0.0, -0.23054236012073015, 0.0, -23.944226543338637, -1.8663152552744888, 0.0, 0.0, 0.0, 0.0, -60.0, -16.470729315167407, -30.0, -12.434538840185457, -3.10964030036976, -50.0, -20.34763936737776, 0.0, -20.0, -19.62074504098002, -40.0, -2.688184049285045, 0.0, 0.0, 0.0, -33.7927646338732, -34.06127745309952, -1.1004887918882655, -20.0, -20.0, -20.0, -20.0, -10.0, 0.0, -20.0, -37.1050533300073, -50.0, -26.969331047104983, -47.31800945869013, 0.0, 0.0, -20.0, -90.0, -30.0, -0.41174869378695744, -10.294229687963288, -30.46884487778649, -30.0, -34.04554677080921, -21.51823328718545, 0.0, -0.67548901263075, -6.238462646497682, -43.87617181636253, -12.133586706966984]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6854299531354298, "mean_inference_ms": 1.1949946866609447, "mean_action_processing_ms": 0.2381254504810252, "mean_env_wait_ms": 0.5127973075026433, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00873546541473012, "StateBufferConnector_ms": 0.004336863388249903, "ViewRequirementAgentConnector_ms": 0.11997370072353034}, "num_episodes": 162, "episode_return_max": 180.0, "episode_return_min": -43.87617181636253, "episode_return_mean": 21.704131065645583}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 448000, "num_agent_steps_trained": 448000, "num_env_steps_sampled": 112000, "num_env_steps_trained": 112000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 204.1383520164508, "num_env_steps_trained_throughput_per_sec": 204.1383520164508, "timesteps_total": 112000, "num_env_steps_sampled_lifetime": 112000, "num_agent_steps_sampled_lifetime": 448000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 448000, "timers": {"training_iteration_time_ms": 15362.729, "restore_workers_time_ms": 0.034, "training_step_time_ms": 15362.608, "sample_time_ms": 1370.442, "learn_time_ms": 13974.646, "learn_throughput": 286.233, "synch_weights_time_ms": 16.579}, "counters": {"num_env_steps_sampled": 112000, "num_env_steps_trained": 112000, "num_agent_steps_sampled": 448000, "num_agent_steps_trained": 448000}, "done": false, "training_iteration": 28, "trial_id": "86f16_00000", "date": "2024-08-08_16-19-25", "timestamp": 1723148365, "time_this_iter_s": 19.607813119888306, "time_total_s": 406.1565465927124, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3acf12280>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 406.1565465927124, "iterations_since_restore": 28, "perf": {"cpu_util_percent": 66.95862068965518, "ram_util_percent": 82.15517241379312}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7872750233568199, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.903699792065519, "policy_loss": -0.01507855368487484, "vf_loss": 2.9172576833278576, "vf_explained_var": 4.305061719096299e-07, "kl": 0.007603292957482986, "entropy": 1.1415571832065041, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 80370.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6807885893930992, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.551155375192563, "policy_loss": -0.019921338524242552, "vf_loss": 4.568844222774108, "vf_explained_var": 0.0408946747581164, "kl": 0.011162483809121512, "entropy": 1.32352212369442, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 27360.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 116000, "num_env_steps_trained": 116000, "num_agent_steps_sampled": 464000, "num_agent_steps_trained": 464000}, "env_runners": {"episode_reward_max": 140.0, "episode_reward_min": -47.89477220539123, "episode_reward_mean": 20.684646866429947, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -72.65073882943847}, "policy_reward_max": {"adversary_policy": 70.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 12.345679012345679, "agent_policy": -16.35239017060709}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 60.0, 0.0, 14.768107845703195, 57.249124219876805, -11.8230307855529, -12.993383936112366, 24.168175643817662, 40.0, -1.0654050379310354, 20.0, 0.0, 0.0, 0.0, 0.0, -18.935674780938452, 0.0, 20.0, 0.0, 60.0, 0.0, 0.0, -8.62670533268198, 0.0, 120.0, -47.89477220539123, 0.0, 0.0, 60.0, -37.41157903519429, 40.0, -7.102561298545384, 0.0, 40.0, -12.725850991423997, 80.0, -2.57048446284482, 19.610626245563985, 80.0, 46.55169272063622, 0.0, 0.0, -14.793424964343306, 58.64803828976552, 60.0, 60.0, 39.33338424609528, 12.680792029037136, 20.0, -0.3328953214984398, 0.0, 77.34926117056153, 0.0, 32.11016795889958, -27.602639810386446, 52.493075616398, 60.0, 60.0, -3.1677331008508247, 0.0, 100.0, 71.4472152596666, -1.4476312751218068, 0.0, -17.14705689598195, -24.3694006176377, 0.0, 60.0, 60.0, 79.991660352174, 59.86166813896887, 40.0, 39.84127967087977, 0.0, 12.305201077242394, 40.0, 39.037933394444394, 20.0, -6.99440581789397, -1.1555340572549988, 40.0, 80.0, 20.0, 0.0, -0.29109594967820507, -19.91056650149922, 0.0, 60.0, 0.0, -0.24400441721153854, -0.4967606385036438, 0.0, 20.0, 100.0, -15.749897297155073, 40.0, -12.515318802620362, 20.0, 0.0, -11.265279164969142, 79.72138070679806, -19.580226136484306, -2.601913876776843, 0.0, 20.0, 64.88595971029666, -22.596279721870406, 80.0, 140.0, 0.0, 60.0, 0.0, 0.0, 18.736438567943782, 0.0, 40.0, 0.0, -6.40607811274563, -2.8975377638484154, -4.615348019104455, 9.279423910120109, 59.58662001524908, 58.90568368816194, 0.0, 80.0, 20.0, 0.0, 60.0, -9.060165712832626, -11.2079453546348, 0.0, 20.0, 20.0, -0.521319637174793, -32.6428827867911, -22.55850839977599, -0.17179333379656603, 0.0, 0.0, 60.0, 0.0, 0.0, 0.0, 60.0, 20.0, 60.0, 19.5932252640252, 0.0, 72.21303273190524, -0.28043378788088935, 0.0, 20.0, 0.0, 100.0, 0.0, 20.0, -20.450170156108967, 80.0, 52.832681235021916, 51.9346379514478, 60.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0], "policy_agent_policy_reward": [0.0, 0.0, -30.0, 0.0, -15.231892154296808, -32.750875780123195, -11.8230307855529, -12.993383936112366, -35.83182435618233, -20.0, -1.0654050379310354, -10.0, 0.0, 0.0, 0.0, 0.0, -18.935674780938452, 0.0, -10.0, 0.0, -30.0, 0.0, 0.0, -8.62670533268198, 0.0, -60.0, -47.89477220539123, 0.0, 0.0, -30.0, -37.41157903519429, -20.0, -7.102561298545384, 0.0, -20.0, -12.725850991423997, -40.0, -2.57048446284482, -10.389373754436013, -40.0, -43.44830727936378, 0.0, 0.0, -14.793424964343306, -31.351961710234473, -30.0, -30.0, -20.666615753904722, -47.31920797096288, -10.0, -0.3328953214984398, 0.0, -72.65073882943847, 0.0, -27.889832041100423, -27.602639810386446, -37.506924383602, -30.0, -30.0, -3.1677331008508247, 0.0, -50.0, -48.552784740333394, -1.4476312751218068, 0.0, -17.14705689598195, -24.3694006176377, 0.0, -30.0, -30.0, -40.008339647826006, -30.138331861031137, -20.0, -20.15872032912023, 0.0, -17.694798922757606, -20.0, -20.962066605555606, -10.0, -6.99440581789397, -1.1555340572549988, -20.0, -40.0, -10.0, 0.0, -0.29109594967820507, -19.91056650149922, 0.0, -30.0, 0.0, -0.24400441721153854, -0.4967606385036438, 0.0, -10.0, -50.0, -15.749897297155073, -20.0, -12.515318802620362, -10.0, 0.0, -11.265279164969142, -40.27861929320194, -19.580226136484306, -2.601913876776843, 0.0, -10.0, -55.114040289703325, -22.596279721870406, -40.0, -70.0, 0.0, -30.0, 0.0, 0.0, -11.263561432056218, 0.0, -20.0, 0.0, -6.40607811274563, -2.8975377638484154, -4.615348019104455, -20.72057608987989, -30.41337998475092, -31.094316311838057, 0.0, -40.0, -10.0, 0.0, -30.0, -9.060165712832626, -11.2079453546348, 0.0, -10.0, -10.0, -0.521319637174793, -32.6428827867911, -22.55850839977599, -0.17179333379656603, 0.0, 0.0, -30.0, 0.0, 0.0, 0.0, -30.0, -10.0, -30.0, -10.406774735974802, 0.0, -47.786967268094756, -0.28043378788088935, 0.0, -10.0, 0.0, -50.0, 0.0, -10.0, -20.450170156108967, -40.0, -37.16731876497809, -38.0653620485522, -30.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6870845247710798, "mean_inference_ms": 1.197698404386515, "mean_action_processing_ms": 0.2384677174873729, "mean_env_wait_ms": 0.5136296192393206, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00487050892394266, "StateBufferConnector_ms": 0.00522438390755359, "ViewRequirementAgentConnector_ms": 0.10261587154718092}, "num_episodes": 162, "episode_return_max": 140.0, "episode_return_min": -47.89477220539123, "episode_return_mean": 20.684646866429947}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 464000, "num_agent_steps_trained": 464000, "num_env_steps_sampled": 116000, "num_env_steps_trained": 116000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 301.6623092784069, "num_env_steps_trained_throughput_per_sec": 301.6623092784069, "timesteps_total": 116000, "num_env_steps_sampled_lifetime": 116000, "num_agent_steps_sampled_lifetime": 464000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 464000, "timers": {"training_iteration_time_ms": 14907.485, "restore_workers_time_ms": 0.033, "training_step_time_ms": 14907.353, "sample_time_ms": 1366.353, "learn_time_ms": 13522.352, "learn_throughput": 295.807, "synch_weights_time_ms": 17.557}, "counters": {"num_env_steps_sampled": 116000, "num_env_steps_trained": 116000, "num_agent_steps_sampled": 464000, "num_agent_steps_trained": 464000}, "done": false, "training_iteration": 29, "trial_id": "86f16_00000", "date": "2024-08-08_16-19-39", "timestamp": 1723148379, "time_this_iter_s": 13.287590980529785, "time_total_s": 419.4441375732422, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3acf125e0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 419.4441375732422, "iterations_since_restore": 29, "perf": {"cpu_util_percent": 43.74210526315788, "ram_util_percent": 81.00526315789473}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7638225083761181, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.416547685565678, "policy_loss": -0.014774269509750108, "vf_loss": 2.4297983155182914, "vf_explained_var": -3.0624951031191128e-06, "kl": 0.007618151361330076, "entropy": 1.135337667389119, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 83190.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7442342076450585, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.8027994366983573, "policy_loss": -0.01838936598554331, "vf_loss": 3.819090735415618, "vf_explained_var": 0.008729434075454871, "kl": 0.010490269368131374, "entropy": 1.3106597863137721, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 28320.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 120000, "num_env_steps_trained": 120000, "num_agent_steps_sampled": 480000, "num_agent_steps_trained": 480000}, "env_runners": {"episode_reward_max": 160.0, "episode_reward_min": -28.011244107596973, "episode_reward_mean": 18.861054456569278, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 157, "episodes_timesteps_total": 3925, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -80.0}, "policy_reward_max": {"adversary_policy": 80.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 10.89171974522293, "agent_policy": -13.81410477909951}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, -1.5974247050174926, 0.0, 20.0, 0.0, -3.6357949473847118, 0.0, 0.0, 0.0, 0.0, 60.0, -2.0333455803754386, 40.0, -9.728135853731024, 60.0, -12.149995647136635, 58.51077067003621, -4.829861738885308, 0.0, 0.0, 0.0, -12.340678300619409, 40.0, -0.27538521704721375, 0.0, 0.0, -16.038438057803393, 0.0, 20.0, 0.0, 59.022297502707715, -9.385551008216806, 0.0, 0.0, 58.70076978060569, 0.0, 60.0, 120.0, 0.0, 120.0, 40.0, 20.0, -3.4630278825789933, 40.0, 73.37486761858095, 40.0, -0.43072881506228455, -18.420602483416783, 0.0, -14.145440070068691, -1.0061153970335242, 59.93240520454673, 120.0, 160.0, 38.815395602667536, 60.0, 40.0, 0.0, 140.0, 80.0, 40.0, 40.0, 0.0, 0.0, 0.0, -8.746318856396499, -18.451851955037892, 0.0, -1.8646312733593595, -0.36133240928636123, -13.500468172562108, 80.0, -0.22084877320693197, 0.0, 0.0, 23.686358350451123, 20.0, 0.0, 40.0, 100.0, 0.0, 58.32086538209114, -0.8774592983145202, -13.254029945157226, -7.7065852867219125, -2.522005739679085, 0.0, -22.98389631594121, 40.0, -0.08852068782279843, 11.980223459884137, 0.0, 60.0, 0.0, 0.0, -0.5216175153003932, -0.012505729277466626, -4.319050416498811, -17.22236396851271, -3.7191174376942895, 0.0, -2.451872588812055, -8.363689674643506, 0.0, 40.0, 0.0, 0.0, 0.0, 160.0, 140.0, 0.0, -9.687398482309717, -11.248388267748759, -3.1863257736203074, 60.0, -4.633353646244505, -28.011244107596973, 100.0, 20.0, -2.800414720690668, 0.0, 0.0, 0.0, 4.8017251475814575, 80.0, 0.0, 0.0, 0.0, 0.0, -13.732721515620016, 0.0, -1.1641990830165239, 40.0, 0.0, 60.0, 40.0, -8.806388162807753, 20.0, 0.0, 0.0, 56.6642024741534, 40.0, 11.51371801859216, 20.0, -0.011680526673648606, 60.0, 0.0, 80.0, -9.083675108306783, -5.14199701294837, 0.0, 0.0, -0.1870883131204637, 0.0, 80.5200219201275, 57.70123343648045, -17.995738417821734], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 60.0, 60.0, 60.0, 80.0, 80.0, 80.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 80.0, 80.0, 80.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [0.0, -1.5974247050174926, 0.0, -10.0, 0.0, -3.6357949473847118, 0.0, 0.0, 0.0, 0.0, -30.0, -2.0333455803754386, -20.0, -9.728135853731024, -30.0, -12.149995647136635, -31.489229329963784, -4.829861738885308, 0.0, 0.0, 0.0, -12.340678300619409, -20.0, -0.27538521704721375, 0.0, 0.0, -16.038438057803393, 0.0, -10.0, 0.0, -30.977702497292277, -9.385551008216806, 0.0, 0.0, -31.299230219394314, 0.0, -30.0, -60.0, 0.0, -60.0, -20.0, -10.0, -3.4630278825789933, -20.0, -46.62513238141907, -20.0, -0.43072881506228455, -18.420602483416783, 0.0, -14.145440070068691, -1.0061153970335242, -30.067594795453264, -60.0, -80.0, -21.184604397332468, -30.0, -20.0, 0.0, -70.0, -40.0, -20.0, -20.0, 0.0, 0.0, 0.0, -8.746318856396499, -18.451851955037892, 0.0, -1.8646312733593595, -0.36133240928636123, -13.500468172562108, -40.0, -0.22084877320693197, 0.0, 0.0, -36.313641649548885, -10.0, 0.0, -20.0, -50.0, 0.0, -31.679134617908865, -0.8774592983145202, -13.254029945157226, -7.7065852867219125, -2.522005739679085, 0.0, -22.98389631594121, -20.0, -0.08852068782279843, -18.019776540115863, 0.0, -30.0, 0.0, 0.0, -0.5216175153003932, -0.012505729277466626, -4.319050416498811, -17.22236396851271, -3.7191174376942895, 0.0, -2.451872588812055, -8.363689674643506, 0.0, -20.0, 0.0, 0.0, 0.0, -80.0, -70.0, 0.0, -9.687398482309717, -11.248388267748759, -33.18632577362031, -30.0, -4.633353646244505, -28.011244107596973, -50.0, -10.0, -2.800414720690668, 0.0, 0.0, 0.0, -25.198274852418542, -40.0, 0.0, 0.0, 0.0, 0.0, -13.732721515620016, 0.0, -1.1641990830165239, -20.0, 0.0, -30.0, -20.0, -8.806388162807753, -10.0, 0.0, 0.0, -33.33579752584661, -20.0, -18.486281981407842, -10.0, -0.011680526673648606, -30.0, 0.0, -40.0, -9.083675108306783, -5.14199701294837, 0.0, 0.0, -0.1870883131204637, 0.0, -69.47997807987247, -32.29876656351955, -17.995738417821734]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6857683859531443, "mean_inference_ms": 1.1963234618110836, "mean_action_processing_ms": 0.23801680944000647, "mean_env_wait_ms": 0.5133591385593897, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005258648258865259, "StateBufferConnector_ms": 0.00334902174153905, "ViewRequirementAgentConnector_ms": 0.09239562757455619}, "num_episodes": 157, "episode_return_max": 160.0, "episode_return_min": -28.011244107596973, "episode_return_mean": 18.861054456569278}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 480000, "num_agent_steps_trained": 480000, "num_env_steps_sampled": 120000, "num_env_steps_trained": 120000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 303.3608740788857, "num_env_steps_trained_throughput_per_sec": 303.3608740788857, "timesteps_total": 120000, "num_env_steps_sampled_lifetime": 120000, "num_agent_steps_sampled_lifetime": 480000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 480000, "timers": {"training_iteration_time_ms": 14607.806, "restore_workers_time_ms": 0.032, "training_step_time_ms": 14607.662, "sample_time_ms": 1355.152, "learn_time_ms": 13233.43, "learn_throughput": 302.265, "synch_weights_time_ms": 17.604}, "counters": {"num_env_steps_sampled": 120000, "num_env_steps_trained": 120000, "num_agent_steps_sampled": 480000, "num_agent_steps_trained": 480000}, "done": false, "training_iteration": 30, "trial_id": "86f16_00000", "date": "2024-08-08_16-19-52", "timestamp": 1723148392, "time_this_iter_s": 13.221529722213745, "time_total_s": 432.66566729545593, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3acf12820>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 432.66566729545593, "iterations_since_restore": 30, "perf": {"cpu_util_percent": 41.678947368421056, "ram_util_percent": 81.17894736842105}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7600341629051993, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.8884374570339286, "policy_loss": -0.0155041598623242, "vf_loss": 2.9025746159096983, "vf_explained_var": -1.046484243785236e-06, "kl": 0.006835010603498508, "entropy": 1.1248426997069771, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 86010.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7307800794641177, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.006407557924589, "policy_loss": -0.0181038649478675, "vf_loss": 4.0224635029832525, "vf_explained_var": 0.015348852363725502, "kl": 0.010239525463296395, "entropy": 1.2917092865953843, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 29280.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 124000, "num_env_steps_trained": 124000, "num_agent_steps_sampled": 496000, "num_agent_steps_trained": 496000}, "env_runners": {"episode_reward_max": 200.0, "episode_reward_min": -52.62205076105986, "episode_reward_mean": 25.22504111511323, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 158, "episodes_timesteps_total": 3950, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -100.0}, "policy_reward_max": {"adversary_policy": 100.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 14.30379746835443, "agent_policy": -17.686351289950064}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.06637798170442855, 60.0, -32.40206382976347, 0.0, 0.0, -2.5560232530901885, 60.0, 0.0, 0.0, 0.0, -8.93479951562217, 0.0, 0.0, 80.0, 60.0, 0.0, 81.51097181631715, -4.769098416103428, 100.0, 20.0, -52.62205076105986, 100.0, -3.5042664555115066, -0.5158176291881378, 35.82452124195022, 54.11246723046348, 0.0, -23.860348275268866, 34.2563629701187, 17.4909426486048, 100.0, 100.0, 40.0, 60.0, 0.0, 0.0, 120.0, 40.0, -12.108408400054438, 20.0, 40.0, 38.064199802602886, 80.0, -5.700941328780078, 0.0, 0.0, 16.81379103616031, 0.0, 0.0, 0.0, 59.753079904595666, 51.98000317756525, 36.27989944395084, -0.23882546445120445, 0.0, 0.0, 14.291371248930608, 200.0, 100.0, -8.697456154393514, 0.0, 0.0, 160.0, 20.0, -9.888849596943308, -31.232009060404792, 0.0, 0.0, 0.0, -12.49043545490833, 0.0, 0.0, 79.82506936670822, 54.659985124230246, -4.032411457360915, -0.2294260645451207, -0.6574165259643727, 0.0, -2.7149473188076625, 0.0, 0.0, 0.0, 77.17444684544117, 0.0, -2.5038576710464113, 20.0, 77.25115958082095, 100.0, -8.203881921232078, -0.11988074865298848, 120.0, -6.650684326734739, 80.0, 0.0, 36.361926181186874, 60.0, 60.0, 0.0, 0.0, 80.0, 56.42674213916955, 0.0, 60.0, 0.0, 140.0, 75.2524764133918, 0.0, 0.0, 0.0, 36.839328717963944, 40.0, 60.0, 40.0, 0.0, 20.0, -0.3157908245432872, -22.44419909508151, 38.783702370023086, 60.0, 20.0, 80.0, 58.10693111136365, 60.0, 0.0, 16.288757006664053, -0.851101868916041, 80.0, 0.0, 0.0, 80.0, 0.0, -1.5366984557998054, 60.0, 0.0, -33.97785743383925, -0.9324432126092796, 52.857233918363114, -3.3651150283306466, 0.0, 0.0, -0.2877736054728064, 40.0, 0.0, -3.704381816077591, 0.0, -13.791557350074912, 0.0, 40.0, 60.0, -34.35149189763599, -3.62167969699627, 0.0, -2.1023921026371353, -35.53575128285074, 80.0, 180.0, 0.0, -3.1303618262394126], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 100.0, 100.0, 100.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 80.0, 80.0, 80.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 90.0, 90.0, 90.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-0.06637798170442855, -30.0, -32.40206382976347, 0.0, 0.0, -2.5560232530901885, -30.0, 0.0, 0.0, 0.0, -8.93479951562217, 0.0, 0.0, -40.0, -30.0, 0.0, -68.48902818368285, -4.769098416103428, -50.0, -10.0, -52.62205076105986, -50.0, -3.5042664555115066, -0.5158176291881378, -24.175478758049774, -35.88753276953651, 0.0, -23.860348275268866, -25.7436370298813, -42.50905735139519, -50.0, -50.0, -20.0, -30.0, 0.0, 0.0, -60.0, -20.0, -12.108408400054438, -10.0, -20.0, -21.935800197397107, -40.0, -5.700941328780078, 0.0, 0.0, -13.18620896383969, 0.0, 0.0, 0.0, -30.24692009540433, -38.01999682243474, -23.720100556049157, -0.23882546445120445, 0.0, 0.0, -45.70862875106939, -100.0, -50.0, -8.697456154393514, 0.0, 0.0, -80.0, -10.0, -9.888849596943308, -31.232009060404792, 0.0, 0.0, 0.0, -12.49043545490833, 0.0, 0.0, -40.17493063329179, -35.340014875769754, -4.032411457360915, -0.2294260645451207, -0.6574165259643727, 0.0, -2.7149473188076625, 0.0, 0.0, 0.0, -42.82555315455883, 0.0, -2.5038576710464113, -10.0, -42.74884041917905, -50.0, -8.203881921232078, -0.11988074865298848, -60.0, -6.650684326734739, -40.0, 0.0, -23.638073818813126, -30.0, -30.0, 0.0, 0.0, -40.0, -33.57325786083045, 0.0, -30.0, 0.0, -70.0, -44.747523586608196, 0.0, 0.0, 0.0, -23.16067128203606, -20.0, -30.0, -20.0, 0.0, -10.0, -0.3157908245432872, -22.44419909508151, -21.216297629976918, -30.0, -10.0, -40.0, -31.89306888863635, -30.0, 0.0, -13.711242993335947, -0.851101868916041, -40.0, 0.0, 0.0, -40.0, 0.0, -1.5366984557998054, -30.0, 0.0, -33.97785743383925, -0.9324432126092796, -37.14276608163688, -3.3651150283306466, 0.0, 0.0, -0.2877736054728064, -20.0, 0.0, -3.704381816077591, 0.0, -13.791557350074912, 0.0, -20.0, -30.0, -34.35149189763599, -3.62167969699627, 0.0, -2.1023921026371353, -35.53575128285074, -40.0, -90.0, 0.0, -3.1303618262394126]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.684444441364355, "mean_inference_ms": 1.1941714189955372, "mean_action_processing_ms": 0.2374440548559699, "mean_env_wait_ms": 0.5126229763155775, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004916326909125606, "StateBufferConnector_ms": 0.0034795531743689427, "ViewRequirementAgentConnector_ms": 0.09689904466460023}, "num_episodes": 158, "episode_return_max": 200.0, "episode_return_min": -52.62205076105986, "episode_return_mean": 25.22504111511323}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 496000, "num_agent_steps_trained": 496000, "num_env_steps_sampled": 124000, "num_env_steps_trained": 124000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 294.75522533744225, "num_env_steps_trained_throughput_per_sec": 294.75522533744225, "timesteps_total": 124000, "num_env_steps_sampled_lifetime": 124000, "num_agent_steps_sampled_lifetime": 496000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 496000, "timers": {"training_iteration_time_ms": 14708.282, "restore_workers_time_ms": 0.032, "training_step_time_ms": 14708.143, "sample_time_ms": 1331.447, "learn_time_ms": 13358.514, "learn_throughput": 299.434, "synch_weights_time_ms": 16.693}, "counters": {"num_env_steps_sampled": 124000, "num_env_steps_trained": 124000, "num_agent_steps_sampled": 496000, "num_agent_steps_trained": 496000}, "done": false, "training_iteration": 31, "trial_id": "86f16_00000", "date": "2024-08-08_16-20-06", "timestamp": 1723148406, "time_this_iter_s": 13.616470098495483, "time_total_s": 446.2821373939514, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3acf12940>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 446.2821373939514, "iterations_since_restore": 31, "perf": {"cpu_util_percent": 45.373684210526314, "ram_util_percent": 82.61052631578947}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7721725128855266, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.54084654518053, "policy_loss": -0.018430297232087674, "vf_loss": 2.557614878771153, "vf_explained_var": -2.9480626397099054e-06, "kl": 0.00830982937919532, "entropy": 1.0841088211705499, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 88830.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.986163300772508, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.274014676113923, "policy_loss": -0.01946500617971954, "vf_loss": 4.291463248431683, "vf_explained_var": 0.019026398472487927, "kl": 0.010082068235236033, "entropy": 1.2692708843698104, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 30240.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 128000, "num_env_steps_trained": 128000, "num_agent_steps_sampled": 512000, "num_agent_steps_trained": 512000}, "env_runners": {"episode_reward_max": 140.0, "episode_reward_min": -74.59911606176513, "episode_reward_mean": 17.22001304630927, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -74.59911606176513}, "policy_reward_max": {"adversary_policy": 70.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 11.049382716049383, "agent_policy": -15.928135101838883}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, -0.7694717547155838, -38.710040206161274, 40.0, 0.0, 58.54920817407655, 0.0, 118.40821824088974, -0.6987130043901701, 19.339397250153624, 58.02863587002874, 59.30122055264283, 37.58566694891258, 40.0, 0.0, -5.336019473676872, -61.49726483200746, -0.7844057129751836, -6.072652024862894, 0.0, 0.0, 20.0, -74.59911606176513, 60.0, 0.0, 78.19326063898092, 39.94214768452255, 18.18549352384008, 0.0, 0.0, 0.0, -12.374821002618916, 140.0, -4.098890481996488, 0.0, 0.0, 0.0, -43.308865352954705, 0.0, -10.177489854072078, 0.0, -2.407766122370435, 20.0, 15.924337419487669, 40.353749211884036, -6.214989485882297, 20.0, -0.789985971623024, -1.119690215669411, 60.0, 40.0, 56.586686546096246, 60.0, 0.0, 0.0, -16.981968343290244, -8.794554296756992, -0.5173878025314271, 0.0, 40.0, 138.45892452156613, 0.0, 0.0, 60.0, 18.83044440499996, 40.0, -3.3573079593636654, 12.17975895508301, 0.0, 40.0, -1.0857346399550827, -20.88117354779089, -0.06243518885724275, 60.0, -6.915006878746076, 14.334873719751148, 54.75877016373198, 0.0, 0.0, -8.565816053413325, 36.91991338280681, -7.285139166911791, 60.0, 40.0, -2.1214207978103614, 80.0, -18.145243142153703, -13.637672965455767, 20.0, 60.0, -1.187337883253694, 0.0, -15.041089972849921, -0.38545105916757083, 0.0, 50.3066754620017, 100.0, -11.650385859986589, -32.39187134164124, -9.678147914478615, 80.0, 0.0, 76.65412567519635, 112.38471685507515, 20.0, -6.528272771633118, 0.0, -9.18394031386486, 19.082529214039155, -0.5683592149076455, -10.068902869331504, -11.761764388835203, 0.0, 1.0420540052513094, 0.0, 0.0, -1.986031019376655, 0.0, 9.203241556406365, 98.28791381971284, 56.17782978842332, 0.0, -0.9238885407290254, 0.0, 80.0, -0.12562658587371045, 0.0, -0.35012561561728495, 40.0, 20.0, 60.0, 0.0, 20.0, 0.0, 0.0, 0.0, 20.0, 0.0, 40.0, -13.563195044119183, 38.775208230000594, 17.330748795357096, 40.0, 0.0, -16.645881651507555, 140.0, 0.0, -11.431460025751765, 0.0, -4.830361124298214, 40.0, 0.0, -6.007128722158612, 40.0, 100.0, 43.07655436813896, -16.440631181767383, 0.0, 58.92091777468096, 0.0, 50.579786190290655], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 60.0, 60.0, 60.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0], "policy_agent_policy_reward": [0.0, 0.0, -0.7694717547155838, -38.710040206161274, -20.0, 0.0, -31.450791825923453, 0.0, -61.59178175911025, -0.6987130043901701, -10.660602749846378, -31.971364129971267, -30.69877944735716, -22.41433305108742, -20.0, 0.0, -5.336019473676872, -61.49726483200746, -0.7844057129751836, -6.072652024862894, 0.0, 0.0, -10.0, -74.59911606176513, -30.0, 0.0, -41.80673936101909, -20.057852315477447, -41.81450647615992, 0.0, 0.0, 0.0, -12.374821002618916, -70.0, -4.098890481996488, 0.0, 0.0, 0.0, -43.308865352954705, 0.0, -10.177489854072078, 0.0, -2.407766122370435, -10.0, -14.075662580512327, -49.646250788115964, -6.214989485882297, -10.0, -0.789985971623024, -1.119690215669411, -30.0, -20.0, -33.41331345390375, -30.0, 0.0, 0.0, -16.981968343290244, -8.794554296756992, -0.5173878025314271, 0.0, -20.0, -71.54107547843387, 0.0, 0.0, -30.0, -11.169555595000043, -20.0, -3.3573079593636654, -17.82024104491699, 0.0, -20.0, -1.0857346399550827, -20.88117354779089, -0.06243518885724275, -30.0, -6.915006878746076, -15.665126280248852, -35.241229836268026, 0.0, 0.0, -8.565816053413325, -23.08008661719319, -7.285139166911791, -30.0, -20.0, -2.1214207978103614, -40.0, -18.145243142153703, -13.637672965455767, -10.0, -30.0, -1.187337883253694, 0.0, -15.041089972849921, -0.38545105916757083, 0.0, -39.6933245379983, -50.0, -41.650385859986585, -32.39187134164124, -9.678147914478615, -40.0, 0.0, -43.345874324803646, -67.61528314492485, -10.0, -6.528272771633118, 0.0, -9.18394031386486, -10.917470785960846, -0.5683592149076455, -10.068902869331504, -11.761764388835203, 0.0, -28.95794599474869, 0.0, 0.0, -1.986031019376655, 0.0, -50.79675844359364, -51.71208618028716, -33.822170211576676, 0.0, -0.9238885407290254, 0.0, -40.0, -0.12562658587371045, 0.0, -0.35012561561728495, -20.0, -10.0, -30.0, 0.0, -10.0, 0.0, 0.0, 0.0, -10.0, 0.0, -20.0, -13.563195044119183, -21.224791769999406, -42.669251204642904, -20.0, 0.0, -16.645881651507555, -70.0, 0.0, -11.431460025751765, 0.0, -4.830361124298214, -20.0, 0.0, -6.007128722158612, -20.0, -50.0, -46.92344563186104, -16.440631181767383, 0.0, -31.079082225319034, 0.0, -39.420213809709345]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6843098490014983, "mean_inference_ms": 1.1926819314255936, "mean_action_processing_ms": 0.23723293776503823, "mean_env_wait_ms": 0.5120826039402104, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004996340951801818, "StateBufferConnector_ms": 0.003601886607982494, "ViewRequirementAgentConnector_ms": 0.09982571189786181}, "num_episodes": 162, "episode_return_max": 140.0, "episode_return_min": -74.59911606176513, "episode_return_mean": 17.22001304630927}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 512000, "num_agent_steps_trained": 512000, "num_env_steps_sampled": 128000, "num_env_steps_trained": 128000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 323.41990293171153, "num_env_steps_trained_throughput_per_sec": 323.41990293171153, "timesteps_total": 128000, "num_env_steps_sampled_lifetime": 128000, "num_agent_steps_sampled_lifetime": 512000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 512000, "timers": {"training_iteration_time_ms": 14480.629, "restore_workers_time_ms": 0.032, "training_step_time_ms": 14480.49, "sample_time_ms": 1340.742, "learn_time_ms": 13121.663, "learn_throughput": 304.839, "synch_weights_time_ms": 16.621}, "counters": {"num_env_steps_sampled": 128000, "num_env_steps_trained": 128000, "num_agent_steps_sampled": 512000, "num_agent_steps_trained": 512000}, "done": false, "training_iteration": 32, "trial_id": "86f16_00000", "date": "2024-08-08_16-20-18", "timestamp": 1723148418, "time_this_iter_s": 12.409731149673462, "time_total_s": 458.6918685436249, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3aca6b160>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 458.6918685436249, "iterations_since_restore": 32, "perf": {"cpu_util_percent": 35.37222222222222, "ram_util_percent": 82.76666666666667}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7485361858885339, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.46299308948483, "policy_loss": -0.01577220433565015, "vf_loss": 2.4771996895894937, "vf_explained_var": -1.5962208416445035e-06, "kl": 0.007827987370946424, "entropy": 1.0664537347800342, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 91650.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6881436723594865, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.5889202520251273, "policy_loss": -0.018844059886517547, "vf_loss": 3.6058799418310326, "vf_explained_var": 0.029904695289830367, "kl": 0.009421898013444823, "entropy": 1.265226675197482, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 31200.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 132000, "num_env_steps_trained": 132000, "num_agent_steps_sampled": 528000, "num_agent_steps_trained": 528000}, "env_runners": {"episode_reward_max": 140.0, "episode_reward_min": -54.618946466084125, "episode_reward_mean": 20.828284833585077, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -70.0}, "policy_reward_max": {"adversary_policy": 70.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 11.851851851851851, "agent_policy": -14.727270721970482}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.017156979478877288, 0.0, 0.0, 20.0, 0.0, 0.0, -9.70759511138527, 0.0, 0.0, -13.37246235760045, 0.0, 40.0, 0.0, 20.0, 40.0, 35.09208133126694, 99.19939753647402, 31.995991988196035, -4.375317547267687, 18.32240801559064, 19.737641660995163, 0.0, 60.0, 60.0, 0.0, -8.717294698960718, 0.0, 59.1677426111809, -0.14335461635958446, 80.0, 40.0, 20.0, 0.0, 99.34520408615857, 20.0, -39.16453605239837, 0.0, 0.0, 117.7310772307366, -1.4715968485688569, -11.3708075044579, 11.256572554173115, 40.0, 0.0, 19.886681126757694, 100.0, 0.0, 99.8974756942563, 40.0, 0.0, -3.2578380189392773, 80.0, 20.0, 18.72792022744046, 18.097529214856372, 19.70085365238299, -0.5389548776686259, 0.0, -7.960245622674864, 0.0, 40.0, 0.0, 0.0, 50.73865825862291, 0.0, -3.890879316908678, 40.0, 60.0, 60.0, -0.4485110282193705, -4.640985582184593, 20.0, -9.954889744839251, -13.165807030407562, 0.0, 71.5090977431738, 100.0, 40.0, 0.0, 0.0, 0.0, 99.75003430361134, 140.0, -2.7572706944201437, 100.0, 0.0, 0.0, 16.436633688448495, -11.387442080696339, 0.0, -7.395067208404529, -4.571991733823481, 0.0, 0.0, 0.0, 38.74386823712151, 0.0, 0.0, 0.0, -0.8320866426782236, -1.9335405151201357, 100.0, 0.0, -5.694360481956258, 52.653594902704164, 0.0, 18.316190563266957, -1.5445645827619259, 40.0, 0.0, 0.0, 20.0, 40.0, 0.0, -12.119820428750964, 36.38695252104073, 0.0, 40.0, 80.0, 0.0, 20.0, 0.0, -0.5492434766820031, 40.0, 0.0, -0.47378827899629106, 40.0, -51.01019817523099, -5.035371208574112, 20.0, -0.74757529980231, -54.618946466084125, 80.0, 60.0, 40.0, -0.14421539364967484, 40.0, 20.0, 120.0, 0.0, 76.98683508810022, -0.4794381373299139, 60.0, 20.0, -31.1693051310294, 49.024930594885305, 0.0, 57.77791979792725, -14.110293837970424, -1.439833698101057, 60.0, -0.5934605208301835, 0.0, 60.0, 0.0, 0.0, 40.0, 0.0, 58.81886955267464, 20.0, -0.31397221004893505, 80.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0], "policy_agent_policy_reward": [-0.017156979478877288, 0.0, 0.0, -10.0, 0.0, 0.0, -9.70759511138527, 0.0, 0.0, -13.37246235760045, 0.0, -20.0, 0.0, -10.0, -20.0, -24.90791866873306, -50.800602463525976, -58.00400801180397, -4.375317547267687, -11.67759198440936, -10.262358339004837, 0.0, -30.0, -30.0, 0.0, -8.717294698960718, 0.0, -30.83225738881911, -0.14335461635958446, -40.0, -20.0, -10.0, 0.0, -50.654795913841426, -10.0, -39.16453605239837, 0.0, 0.0, -62.26892276926339, -1.4715968485688569, -11.3708075044579, -18.743427445826885, -20.0, 0.0, -10.113318873242306, -50.0, 0.0, -50.1025243057437, -20.0, 0.0, -3.2578380189392773, -40.0, -10.0, -11.272079772559536, -11.90247078514363, -10.29914634761701, -0.5389548776686259, 0.0, -7.960245622674864, 0.0, -20.0, 0.0, 0.0, -39.26134174137709, 0.0, -3.890879316908678, -20.0, -30.0, -30.0, -0.4485110282193705, -4.640985582184593, -10.0, -9.954889744839251, -13.165807030407562, 0.0, -48.49090225682619, -50.0, -20.0, 0.0, 0.0, 0.0, -50.24996569638866, -70.0, -2.7572706944201437, -50.0, 0.0, 0.0, -13.563366311551505, -11.387442080696339, 0.0, -7.395067208404529, -4.571991733823481, 0.0, 0.0, 0.0, -21.25613176287849, 0.0, 0.0, 0.0, -0.8320866426782236, -1.9335405151201357, -50.0, 0.0, -5.694360481956258, -37.346405097295836, 0.0, -11.683809436733045, -1.5445645827619259, -20.0, 0.0, 0.0, -10.0, -20.0, 0.0, -12.119820428750964, -53.61304747895928, 0.0, -20.0, -40.0, 0.0, -10.0, 0.0, -0.5492434766820031, -20.0, 0.0, -0.47378827899629106, -20.0, -51.01019817523099, -5.035371208574112, -10.0, -0.74757529980231, -54.618946466084125, -40.0, -30.0, -20.0, -0.14421539364967484, -20.0, -10.0, -60.0, 0.0, -43.013164911899786, -0.4794381373299139, -30.0, -10.0, -31.1693051310294, -40.975069405114695, 0.0, -32.22208020207275, -14.110293837970424, -1.439833698101057, -30.0, -0.5934605208301835, 0.0, -30.0, 0.0, 0.0, -20.0, 0.0, -31.18113044732535, -10.0, -0.31397221004893505, -40.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6832865613197531, "mean_inference_ms": 1.1916417204451035, "mean_action_processing_ms": 0.23698767845259844, "mean_env_wait_ms": 0.5117238294034903, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004731210661523136, "StateBufferConnector_ms": 0.0032703817626576364, "ViewRequirementAgentConnector_ms": 0.09583757247453854}, "num_episodes": 162, "episode_return_max": 140.0, "episode_return_min": -54.618946466084125, "episode_return_mean": 20.828284833585077}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 528000, "num_agent_steps_trained": 528000, "num_env_steps_sampled": 132000, "num_env_steps_trained": 132000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 311.6464765928126, "num_env_steps_trained_throughput_per_sec": 311.6464765928126, "timesteps_total": 132000, "num_env_steps_sampled_lifetime": 132000, "num_agent_steps_sampled_lifetime": 528000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 528000, "timers": {"training_iteration_time_ms": 13989.913, "restore_workers_time_ms": 0.032, "training_step_time_ms": 13989.771, "sample_time_ms": 1328.814, "learn_time_ms": 12640.659, "learn_throughput": 316.439, "synch_weights_time_ms": 18.663}, "counters": {"num_env_steps_sampled": 132000, "num_env_steps_trained": 132000, "num_agent_steps_sampled": 528000, "num_agent_steps_trained": 528000}, "done": false, "training_iteration": 33, "trial_id": "86f16_00000", "date": "2024-08-08_16-20-31", "timestamp": 1723148431, "time_this_iter_s": 12.88149619102478, "time_total_s": 471.57336473464966, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3aca6b3a0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 471.57336473464966, "iterations_since_restore": 33, "perf": {"cpu_util_percent": 39.55, "ram_util_percent": 82.79444444444442}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7606329982690777, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.888679707219415, "policy_loss": -0.01590226807496147, "vf_loss": 2.9029994089552695, "vf_explained_var": -4.561340555231622e-06, "kl": 0.007912815007335323, "entropy": 1.0583153902004796, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 94470.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8534018053362766, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.193659831335148, "policy_loss": -0.021803957938876312, "vf_loss": 4.213353488842646, "vf_explained_var": 0.011843086282412211, "kl": 0.010551474390703783, "entropy": 1.2590074849625428, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 32160.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 136000, "num_env_steps_trained": 136000, "num_agent_steps_sampled": 544000, "num_agent_steps_trained": 544000}, "env_runners": {"episode_reward_max": 180.0, "episode_reward_min": -30.891306995673137, "episode_reward_mean": 23.214502688023323, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 157, "episodes_timesteps_total": 3925, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -90.0}, "policy_reward_max": {"adversary_policy": 90.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 13.121019108280255, "agent_policy": -16.14855463681744}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-7.363224818568119, 74.0291385093025, 0.0, -6.552929468277156, 0.0, 40.0, -7.68119982243312, 20.0, -1.79797091635312, 100.0, 158.97539341494803, -3.4246831666891113, -3.682340007029903, 0.0, 0.0, -0.4474975216060373, 0.0, 0.0, -4.789483160735301, 100.0, 60.0, 40.0, 0.0, -5.2503566666456996, 0.0, 60.0, 0.0, 15.427547394426725, 28.101746907532345, 60.0, 18.80347713122294, 0.0, 40.0, 60.0, 57.44789157297767, -25.375365335000993, 20.0, -30.891306995673137, -19.559897029264967, 0.0, 0.0, -2.5511192306819783, 0.0, 100.0, 20.0, -0.5588296687798977, 40.0, 0.0, -15.13417847765056, 0.0, -7.4692705480157935, 78.87007977894518, 57.714921523637656, 0.0, 0.0, 0.0, -0.4988481187423588, 40.0, -8.38519714369494, 0.0, -0.8016040515695599, 20.0, 160.0, 60.0, -7.770041544275403, 0.0, 0.0, -7.967806733827212, 80.0, -10.460979018093736, 31.31198734771315, 6.736359087719798, 59.2844814076811, 40.0, 60.0, 180.0, 38.62693384436347, 19.279399393933698, 35.70223843845898, 98.9238200031461, 0.0, 40.0, -0.9277489182451548, 0.0, 40.0, 0.0, -11.476564993383194, 120.0, 84.94584825624347, -22.04491310323688, 20.0, 38.154903674891585, 20.0, -4.100517683152404, 0.0, 80.0, 0.0, 0.0, 0.0, -1.7372042010180633, 0.0, 60.0, -21.67427986084251, 19.55966278219535, 20.0, 40.0, 0.0, -0.40087308504308417, -1.4213270805820566, 59.75377189578763, -2.401059857279813, -6.176325588903495, 20.0, 79.6485473434374, 21.91395653606515, 0.0, 9.216722304565776, -0.005523506846137893, 20.0, 0.0, -7.901426414233614, -0.7424459201098199, 39.69920627240959, 158.69575127266188, 0.0, 100.0, 40.0, 0.0, 60.0, -3.5174493611762783, 0.0, 60.0, 0.0, -4.149252650653457, 0.0, 30.96666422586485, 40.0, 0.0, 120.0, 57.62758541431374, -15.66856432767779, 80.0, 40.0, 0.0, 40.0, -14.62773514384323, 0.0, -0.8166380355714042, 0.0, 33.711495212599544, 0.0, 0.0, 39.37566543117239, 0.0, 40.0, 0.0, -9.624295183149112], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 80.0, 80.0, 80.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 80.0, 80.0, 80.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 90.0, 90.0, 90.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 80.0, 80.0, 80.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-7.363224818568119, -45.970861490697494, 0.0, -6.552929468277156, 0.0, -20.0, -7.68119982243312, -10.0, -1.79797091635312, -50.0, -81.02460658505197, -3.4246831666891113, -3.682340007029903, 0.0, 0.0, -0.4474975216060373, 0.0, 0.0, -4.789483160735301, -50.0, -30.0, -20.0, 0.0, -5.2503566666456996, 0.0, -30.0, 0.0, -14.572452605573277, -31.89825309246765, -30.0, -11.196522868777057, 0.0, -20.0, -30.0, -32.55210842702233, -25.375365335000993, -10.0, -30.891306995673137, -19.559897029264967, 0.0, 0.0, -2.5511192306819783, 0.0, -50.0, -10.0, -0.5588296687798977, -20.0, 0.0, -15.13417847765056, 0.0, -7.4692705480157935, -41.12992022105482, -32.285078476362344, 0.0, 0.0, 0.0, -0.4988481187423588, -20.0, -8.38519714369494, 0.0, -0.8016040515695599, -10.0, -80.0, -30.0, -7.770041544275403, 0.0, 0.0, -7.967806733827212, -40.0, -10.460979018093736, -28.68801265228685, -23.263640912280202, -30.715518592318897, -20.0, -30.0, -90.0, -21.373066155636533, -40.7206006060663, -24.29776156154103, -51.07617999685389, 0.0, -20.0, -0.9277489182451548, 0.0, -20.0, 0.0, -11.476564993383194, -60.0, -65.05415174375653, -22.04491310323688, -10.0, -51.845096325108415, -10.0, -4.100517683152404, 0.0, -40.0, 0.0, 0.0, 0.0, -1.7372042010180633, 0.0, -30.0, -21.67427986084251, -10.44033721780465, -10.0, -20.0, 0.0, -0.40087308504308417, -1.4213270805820566, -30.246228104212374, -2.401059857279813, -6.176325588903495, -10.0, -40.3514526565626, -38.08604346393485, 0.0, -20.78327769543422, -0.005523506846137893, -10.0, 0.0, -7.901426414233614, -0.7424459201098199, -20.30079372759041, -81.30424872733815, 0.0, -50.0, -20.0, 0.0, -30.0, -3.5174493611762783, 0.0, -30.0, 0.0, -4.149252650653457, 0.0, -29.033335774135153, -20.0, 0.0, -60.0, -32.37241458568626, -15.66856432767779, -40.0, -20.0, 0.0, -20.0, -14.62773514384323, 0.0, -0.8166380355714042, 0.0, -26.28850478740045, 0.0, 0.0, -20.624334568827607, 0.0, -20.0, 0.0, -9.624295183149112]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6825999899273325, "mean_inference_ms": 1.190631714922345, "mean_action_processing_ms": 0.23678320991996826, "mean_env_wait_ms": 0.5114021916324831, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004705653828420457, "StateBufferConnector_ms": 0.0039531926440585195, "ViewRequirementAgentConnector_ms": 0.09412757909981309}, "num_episodes": 157, "episode_return_max": 180.0, "episode_return_min": -30.891306995673137, "episode_return_mean": 23.214502688023323}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 544000, "num_agent_steps_trained": 544000, "num_env_steps_sampled": 136000, "num_env_steps_trained": 136000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 318.7087471535612, "num_env_steps_trained_throughput_per_sec": 318.7087471535612, "timesteps_total": 136000, "num_env_steps_sampled_lifetime": 136000, "num_agent_steps_sampled_lifetime": 544000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 544000, "timers": {"training_iteration_time_ms": 13504.717, "restore_workers_time_ms": 0.032, "training_step_time_ms": 13504.574, "sample_time_ms": 1318.686, "learn_time_ms": 12164.261, "learn_throughput": 328.832, "synch_weights_time_ms": 18.983}, "counters": {"num_env_steps_sampled": 136000, "num_env_steps_trained": 136000, "num_agent_steps_sampled": 544000, "num_agent_steps_trained": 544000}, "done": false, "training_iteration": 34, "trial_id": "86f16_00000", "date": "2024-08-08_16-20-44", "timestamp": 1723148444, "time_this_iter_s": 12.586737871170044, "time_total_s": 484.1601026058197, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3aca6b4c0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 484.1601026058197, "iterations_since_restore": 34, "perf": {"cpu_util_percent": 35.46842105263158, "ram_util_percent": 82.81052631578946}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7840656373623415, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.717551799234769, "policy_loss": -0.01852130746429271, "vf_loss": 2.734550458023734, "vf_explained_var": 1.0324496749445055e-06, "kl": 0.007613218090193074, "entropy": 1.0514792268791944, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 97290.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9753582043573261, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.09450540356338, "policy_loss": -0.02295237893995363, "vf_loss": 4.114896483719349, "vf_explained_var": 0.023269289049009483, "kl": 0.012806438213008657, "entropy": 1.26710485778749, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 33120.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 140000, "num_env_steps_trained": 140000, "num_agent_steps_sampled": 560000, "num_agent_steps_trained": 560000}, "env_runners": {"episode_reward_max": 180.0, "episode_reward_min": -39.97331598351846, "episode_reward_mean": 21.778136573359493, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -96.06569807845919}, "policy_reward_max": {"adversary_policy": 90.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 12.592592592592593, "agent_policy": -15.999641204418285}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-2.8046991507983208, 60.0, -8.003391847151681, 20.0, 20.0, 60.0, 59.314374280924525, 0.0, 60.0, 40.0, 0.0, 0.0, 80.0, 40.0, 0.0, -39.97331598351846, 180.0, -9.304563541038132, 60.0, 0.0, 20.0, 0.0, 40.0, 0.0, -1.6568389529201821, 17.06567298221417, 80.0, -0.21693642200453334, 40.0, -28.70970310334612, 140.0, 0.0, 0.0, 59.5806106595812, -0.6545295362022974, -0.7906922077702849, 60.0, 40.0, 19.199334205465156, 60.0, 0.0, 100.0, 120.0, 0.0, 17.497995696424752, 0.0, -21.66866865714322, 70.11484257790006, 0.0, 0.0, 137.5444257350651, -1.1176256323313694, 0.0, 60.0, -0.39729826118167333, 0.0, 0.0, 0.0, -1.2079670741869897, 23.151084127033577, 0.0, -10.920903464153485, 20.0, -0.9480924340329211, -3.5027629772539406, 40.0, 0.0, 60.0, 0.0, -2.42065637649638, 0.0, 0.0, -3.230365898415453, -1.721381505267433, 0.0, -6.507632238436418, 118.17640317938066, 0.0, -10.170592485794234, 20.0, 56.77867136170019, -4.962629294969121, 35.803726344224145, 40.0, 0.0, 120.0, 100.0, -17.178109514657162, 56.318266163076274, 100.0, -0.4568298549120642, 0.0, -9.926625354636712, 0.0, 80.0, 20.0, 0.0, 0.0, -0.11597660155454492, -22.619381804034322, -21.58375118975117, 0.0, -3.7807316217960603, 16.50002726732687, 0.0, 33.980976529561104, 60.0, -7.546819010440594, 35.61820738721061, 0.0, 40.0, 0.0, 100.0, 38.55510798153616, -1.6852633461277577, 0.0, 20.0, 31.389741328477527, -2.824771575161514, 20.0, 12.633119783846848, 0.0, 60.0, 0.0, -2.3979653344888803, -27.13689918236087, -6.681924071781941, 100.0, 100.0, -2.681112835621222, -4.524655363499937, 40.0, 60.0, 60.0, 38.934225328838835, 0.0, 0.0, -23.99994626108304, 100.0, 20.0, 0.0, 0.0, -0.45262525377603335, 40.0, 0.0, -14.371629068343031, 0.0, 9.784063904774026, -2.7304944447712343, -11.764980013132645, 0.0, 0.0, 0.0, 0.0, -1.2554028559705865, 59.11126676440368, -1.5161194120416077, 0.0, -1.038424762236595, 143.93430192154082, -33.42445566121396, 19.65782081153753], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 90.0, 90.0, 90.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 80.0, 80.0, 80.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0], "policy_agent_policy_reward": [-2.8046991507983208, -30.0, -8.003391847151681, -10.0, -10.0, -30.0, -30.685625719075475, 0.0, -30.0, -20.0, 0.0, 0.0, -40.0, -20.0, 0.0, -39.97331598351846, -90.0, -9.304563541038132, -30.0, 0.0, -10.0, 0.0, -20.0, 0.0, -1.6568389529201821, -42.934327017785826, -40.0, -0.21693642200453334, -20.0, -28.70970310334612, -70.0, 0.0, 0.0, -30.419389340418796, -0.6545295362022974, -0.7906922077702849, -30.0, -20.0, -10.800665794534845, -30.0, 0.0, -50.0, -60.0, 0.0, -12.502004303575246, 0.0, -21.66866865714322, -49.885157422099944, 0.0, 0.0, -72.4555742649349, -1.1176256323313694, 0.0, -30.0, -0.39729826118167333, 0.0, 0.0, 0.0, -1.2079670741869897, -36.848915872966415, 0.0, -10.920903464153485, -10.0, -0.9480924340329211, -3.5027629772539406, -20.0, 0.0, -30.0, 0.0, -2.42065637649638, 0.0, 0.0, -3.230365898415453, -1.721381505267433, 0.0, -6.507632238436418, -61.823596820619336, 0.0, -10.170592485794234, -10.0, -33.22132863829981, -4.962629294969121, -54.19627365577586, -20.0, 0.0, -60.0, -50.0, -17.178109514657162, -33.681733836923726, -50.0, -0.4568298549120642, 0.0, -9.926625354636712, 0.0, -40.0, -10.0, 0.0, 0.0, -0.11597660155454492, -22.619381804034322, -21.58375118975117, 0.0, -3.7807316217960603, -13.499972732673129, 0.0, -26.019023470438892, -30.0, -7.546819010440594, -24.38179261278939, 0.0, -20.0, 0.0, -50.0, -21.44489201846384, -1.6852633461277577, 0.0, -10.0, -28.610258671522477, -2.824771575161514, -10.0, -17.36688021615315, 0.0, -30.0, 0.0, -2.3979653344888803, -27.13689918236087, -6.681924071781941, -50.0, -50.0, -2.681112835621222, -4.524655363499937, -20.0, -30.0, -30.0, -21.06577467116116, 0.0, 0.0, -23.99994626108304, -50.0, -10.0, 0.0, 0.0, -0.45262525377603335, -20.0, 0.0, -44.37162906834302, 0.0, -20.215936095225974, -2.7304944447712343, -11.764980013132645, 0.0, 0.0, 0.0, 0.0, -1.2554028559705865, -30.88873323559632, -1.5161194120416077, 0.0, -1.038424762236595, -96.06569807845919, -33.42445566121396, -10.34217918846247]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.683912424638986, "mean_inference_ms": 1.1922943754815087, "mean_action_processing_ms": 0.23700745596020276, "mean_env_wait_ms": 0.5121585667837905, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007757654896488896, "StateBufferConnector_ms": 0.003437201182047526, "ViewRequirementAgentConnector_ms": 0.10275347733203276}, "num_episodes": 162, "episode_return_max": 180.0, "episode_return_min": -39.97331598351846, "episode_return_mean": 21.778136573359493}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 560000, "num_agent_steps_trained": 560000, "num_env_steps_sampled": 140000, "num_env_steps_trained": 140000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 307.0447460025767, "num_env_steps_trained_throughput_per_sec": 307.0447460025767, "timesteps_total": 140000, "num_env_steps_sampled_lifetime": 140000, "num_agent_steps_sampled_lifetime": 560000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 560000, "timers": {"training_iteration_time_ms": 13564.315, "restore_workers_time_ms": 0.034, "training_step_time_ms": 13564.167, "sample_time_ms": 1324.732, "learn_time_ms": 12217.662, "learn_throughput": 327.395, "synch_weights_time_ms": 19.106}, "counters": {"num_env_steps_sampled": 140000, "num_env_steps_trained": 140000, "num_agent_steps_sampled": 560000, "num_agent_steps_trained": 560000}, "done": false, "training_iteration": 35, "trial_id": "86f16_00000", "date": "2024-08-08_16-20-57", "timestamp": 1723148457, "time_this_iter_s": 13.07815408706665, "time_total_s": 497.23825669288635, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3acf12ee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 497.23825669288635, "iterations_since_restore": 35, "perf": {"cpu_util_percent": 41.277777777777786, "ram_util_percent": 83.53888888888889}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7597340631992259, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.46486799725404, "policy_loss": -0.016757335741954676, "vf_loss": 2.4801917109929077, "vf_explained_var": -5.439452245725808e-07, "kl": 0.007168097687833226, "entropy": 1.026246866097687, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 100110.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.0357878188292187, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.144641842444738, "policy_loss": -0.019659210825921036, "vf_loss": 4.16220297118028, "vf_explained_var": 0.024070884225269158, "kl": 0.010490329010233146, "entropy": 1.2534958424667517, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 34080.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 144000, "num_env_steps_trained": 144000, "num_agent_steps_sampled": 576000, "num_agent_steps_trained": 576000}, "env_runners": {"episode_reward_max": 160.0, "episode_reward_min": -44.315806264888664, "episode_reward_mean": 18.702467857003537, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 158, "episodes_timesteps_total": 3950, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -80.0}, "policy_reward_max": {"adversary_policy": 80.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 11.012658227848101, "agent_policy": -14.335506826540765}, "custom_metrics": {}, "hist_stats": {"episode_reward": [60.0, -19.484827821716387, 100.0, -22.506924443890924, 0.0, -0.4427826805623636, -3.33899948494215, -0.17341702109862855, 60.0, 40.0, 0.0, 80.0, -2.3621309373434363, 100.0, 0.0, 0.0, -4.92636698979266, 0.0, 98.94596095859693, 119.91822410152321, 160.0, 0.0, 16.507815366387117, 0.0, 0.0, 100.0, 0.0, -17.591267566526767, 0.0, -14.700500320111043, -13.217242894308095, 40.0, 140.0, -4.518948494302734, 0.0, 19.847331698734774, 0.0, -2.5345575706384604, 40.0, 0.0, -7.99516563032609, 0.0, 0.0, 31.97200974783734, 0.0, 56.7522202037581, -0.7747648812644692, 0.0, -0.32284557597341723, 15.30770628109714, -9.01948674974955, 0.0, 0.0, 140.0, 120.0, -13.758880708882907, 0.0, 100.0, 32.83390539611415, 80.0, 0.0, -2.151283085435134, 18.12648332358225, 0.0, 20.0, 20.0, 12.790533281912785, -8.535923241225783, -14.7102256721535, 0.0, 0.0, 0.0, 0.0, 0.0, -15.865339456864977, 40.0, 0.0, -10.137525879822634, 40.0, 40.0, -3.3499798736252515, 0.0, -0.05013460702324779, -6.4485939410946616, -11.044285931118699, 120.0, 60.0, 0.0, -0.7846972246125161, -0.2619956111121158, 0.0, 16.157172752742845, 0.0, 40.0, 0.0, 20.0, 60.0, 20.0, 60.0, -7.173395969205722, 0.0, 0.0, 40.0, 79.89631768971952, -0.6952729715747152, -0.5714568351110816, 0.0, 0.0, 60.0, 60.0, -5.110969416486899, 0.0, 0.0, 7.464258355755046, -9.261348394529833, 40.0, 60.0, -0.011223000646283232, 0.0, -6.324185485754368, -7.59899449454479, -11.658259352000865, 0.0, 0.0, 19.833316456769463, 40.0, 20.0, 139.95601020913602, -2.374306365510778, -5.834302470124537, -44.315806264888664, -11.291847111955988, -5.596200787494172, 28.446633639116698, 0.0, 0.0, 98.5263876838779, -22.035707722004393, 20.0, -2.6655482816051546, -7.368006957013597, 40.0, 40.0, -4.462162145827484, 39.62737425485217, 0.0, 20.0, -8.560386674147988, -3.9401320922998266, 60.0, -0.6881823309773694, 40.0, -5.356523685321941, 60.0, -14.016426890409493, 0.0, 0.0, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 60.0, 60.0, 60.0, 80.0, 80.0, 80.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-30.0, -19.484827821716387, -50.0, -22.506924443890924, 0.0, -0.4427826805623636, -3.33899948494215, -0.17341702109862855, -30.0, -20.0, 0.0, -40.0, -2.3621309373434363, -50.0, 0.0, 0.0, -4.92636698979266, 0.0, -51.05403904140307, -60.0817758984768, -80.0, 0.0, -13.492184633612888, 0.0, 0.0, -50.0, 0.0, -17.591267566526767, 0.0, -14.700500320111043, -13.217242894308095, -20.0, -70.0, -4.518948494302734, 0.0, -10.152668301265226, 0.0, -2.5345575706384604, -20.0, 0.0, -7.99516563032609, 0.0, 0.0, -28.027990252162656, 0.0, -33.2477797962419, -0.7747648812644692, 0.0, -0.32284557597341723, -14.692293718902864, -9.01948674974955, 0.0, 0.0, -70.0, -60.0, -13.758880708882907, 0.0, -50.0, -57.16609460388585, -40.0, 0.0, -2.151283085435134, -11.87351667641775, 0.0, -10.0, -10.0, -17.209466718087214, -8.535923241225783, -14.7102256721535, 0.0, 0.0, 0.0, 0.0, 0.0, -15.865339456864977, -20.0, 0.0, -10.137525879822634, -20.0, -20.0, -3.3499798736252515, 0.0, -0.05013460702324779, -6.4485939410946616, -11.044285931118699, -60.0, -30.0, 0.0, -0.7846972246125161, -0.2619956111121158, 0.0, -43.842827247257155, 0.0, -20.0, 0.0, -10.0, -30.0, -10.0, -30.0, -7.173395969205722, 0.0, 0.0, -20.0, -40.10368231028048, -0.6952729715747152, -0.5714568351110816, 0.0, 0.0, -30.0, -30.0, -5.110969416486899, 0.0, 0.0, -22.535741644244954, -9.261348394529833, -20.0, -30.0, -0.011223000646283232, 0.0, -6.324185485754368, -7.59899449454479, -11.658259352000865, 0.0, 0.0, -10.166683543230535, -20.0, -10.0, -70.04398979086398, -2.374306365510778, -5.834302470124537, -44.315806264888664, -11.291847111955988, -5.596200787494172, -31.553366360883302, 0.0, 0.0, -51.4736123161221, -22.035707722004393, -10.0, -2.6655482816051546, -7.368006957013597, -20.0, -20.0, -4.462162145827484, -20.37262574514783, 0.0, -10.0, -38.560386674147985, -3.9401320922998266, -30.0, -0.6881823309773694, -20.0, -5.356523685321941, -30.0, -14.016426890409493, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6849188540580659, "mean_inference_ms": 1.1949192238616508, "mean_action_processing_ms": 0.23735500266281725, "mean_env_wait_ms": 0.5132548194453201, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004946732822852799, "StateBufferConnector_ms": 0.0035257279118405113, "ViewRequirementAgentConnector_ms": 0.10454466071309923}, "num_episodes": 158, "episode_return_max": 160.0, "episode_return_min": -44.315806264888664, "episode_return_mean": 18.702467857003537}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 576000, "num_agent_steps_trained": 576000, "num_env_steps_sampled": 144000, "num_env_steps_trained": 144000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 315.034644727103, "num_env_steps_trained_throughput_per_sec": 315.034644727103, "timesteps_total": 144000, "num_env_steps_sampled_lifetime": 144000, "num_agent_steps_sampled_lifetime": 576000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 576000, "timers": {"training_iteration_time_ms": 13689.918, "restore_workers_time_ms": 0.033, "training_step_time_ms": 13689.769, "sample_time_ms": 1347.357, "learn_time_ms": 12320.166, "learn_throughput": 324.671, "synch_weights_time_ms": 19.483}, "counters": {"num_env_steps_sampled": 144000, "num_env_steps_trained": 144000, "num_agent_steps_sampled": 576000, "num_agent_steps_trained": 576000}, "done": false, "training_iteration": 36, "trial_id": "86f16_00000", "date": "2024-08-08_16-21-10", "timestamp": 1723148470, "time_this_iter_s": 12.741477012634277, "time_total_s": 509.97973370552063, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3aca6be50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 509.97973370552063, "iterations_since_restore": 36, "perf": {"cpu_util_percent": 37.39473684210526, "ram_util_percent": 83.51052631578949}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7375387517801413, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.5949277699839137, "policy_loss": -0.01653564158226, "vf_loss": 2.6099567819571665, "vf_explained_var": -1.3614377231462628e-06, "kl": 0.007533140043211276, "entropy": 1.0465316240457778, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 102930.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8336347809061408, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.8237614527344705, "policy_loss": -0.01908815489587141, "vf_loss": 3.840631769100825, "vf_explained_var": 0.026608831559618313, "kl": 0.011089152267877907, "entropy": 1.2810475292305152, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 35040.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 148000, "num_env_steps_trained": 148000, "num_agent_steps_sampled": 592000, "num_agent_steps_trained": 592000}, "env_runners": {"episode_reward_max": 180.0, "episode_reward_min": -37.16693765649416, "episode_reward_mean": 20.27309188216363, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -90.0}, "policy_reward_max": {"adversary_policy": 90.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 11.358024691358025, "agent_policy": -13.80098219191044}, "custom_metrics": {}, "hist_stats": {"episode_reward": [20.0, 0.0, 160.0, 0.0, 0.0, 62.77601935478674, 40.0, -10.756496596180321, 54.39454432865196, -7.624619864199214, 0.0, 20.0, 17.889929881378993, 40.0, 0.0, -3.689315599121671, 0.0, -0.8770711787638708, 0.0, 117.28469963127917, 0.0, -2.7676656104820454, 54.588661683519746, 40.0, -12.984761926223818, -1.0750833401597093, 20.0, 75.96442397724334, -15.796439372066898, 0.0, 80.0, 20.0, 0.0, 0.0, 120.0, 0.0, -1.6974342771970352, 0.0, 0.0, 20.0, 0.0, 19.823186938331915, 20.0, 180.0, 0.0, 20.0, 20.0, 30.0513586968835, 20.0, -1.5146754379829896, 20.0, -37.16693765649416, 0.0, 80.0, 60.0, -1.9335610445472118, 40.0, 60.0, -0.05561163008506731, 40.0, 20.0, 20.0, 100.0, -4.699306665626603, 0.0, 0.0, 0.0, -12.776861107784885, -1.602730781129722, -7.965817416469001, 40.0, 40.0, 40.0, 100.0, 120.0, 0.0, -0.2412423803924768, 120.0, -15.733481845062293, -0.04409733402569782, 100.0, 60.0, 0.0, 0.0, 0.0, 40.0, 120.0, 0.0, -3.789702710837977, 0.0, 3.066621486626836, 0.0, 0.0, 0.0, 100.0, 20.0, 0.0, -5.096514881807354, 39.767146028552986, -0.18329881063020248, 0.0, -13.343510737401457, -0.16927177351134248, -0.18812160626516028, 0.0, -0.09519663017921176, -12.799743696817755, 100.0, -1.2146054410456975, 0.0, 20.0, 11.648328150896685, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 40.0, 0.0, 0.0, 79.05399059421866, 0.0, 0.0, -4.066674965356326, 0.0, 0.0, -24.465045738143754, 0.0, -3.9121569537928487, -11.525223376142412, 0.0, 0.0, 0.0, 32.68410656446328, 80.0, 18.396887358641116, -0.38598178785519743, -0.5341748317658135, 0.0, 60.0, -14.388333200371298, -5.27609506981617, -0.4164763532031579, 0.0, -4.3114125475893355, 0.0, 0.0, -5.01104105960149, 60.0, 39.28387809396828, -1.7452760259742428, 59.84351924525219, 34.3877630579964, 79.56033683410651, -1.3478594594682691, 0.0, -0.9781004495617296, 40.0, 36.453377559329525, 100.0, -26.430865384486516], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 80.0, 80.0, 80.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 90.0, 90.0, 90.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-10.0, 0.0, -80.0, 0.0, 0.0, -57.22398064521326, -20.0, -10.756496596180321, -35.60545567134805, -7.624619864199214, 0.0, -10.0, -12.110070118621007, -20.0, 0.0, -3.689315599121671, 0.0, -0.8770711787638708, 0.0, -62.71530036872083, 0.0, -2.7676656104820454, -35.41133831648025, -20.0, -12.984761926223818, -1.0750833401597093, -10.0, -44.03557602275665, -15.796439372066898, 0.0, -40.0, -10.0, 0.0, 0.0, -60.0, 0.0, -1.6974342771970352, 0.0, 0.0, -10.0, 0.0, -10.176813061668085, -10.0, -90.0, 0.0, -10.0, -10.0, -29.9486413031165, -10.0, -1.5146754379829896, -10.0, -37.16693765649416, 0.0, -40.0, -30.0, -1.9335610445472118, -20.0, -30.0, -0.05561163008506731, -20.0, -10.0, -10.0, -50.0, -4.699306665626603, 0.0, 0.0, 0.0, -12.776861107784885, -1.602730781129722, -7.965817416469001, -20.0, -20.0, -20.0, -50.0, -60.0, 0.0, -0.2412423803924768, -60.0, -15.733481845062293, -0.04409733402569782, -50.0, -30.0, 0.0, 0.0, 0.0, -20.0, -60.0, 0.0, -3.789702710837977, 0.0, -26.933378513373164, 0.0, 0.0, 0.0, -50.0, -10.0, 0.0, -5.096514881807354, -20.232853971447014, -0.18329881063020248, 0.0, -13.343510737401457, -0.16927177351134248, -0.18812160626516028, 0.0, -0.09519663017921176, -12.799743696817755, -50.0, -1.2146054410456975, 0.0, -10.0, -18.35167184910331, 0.0, 0.0, 0.0, 0.0, 0.0, -10.0, -20.0, 0.0, 0.0, -40.94600940578134, 0.0, 0.0, -4.066674965356326, 0.0, 0.0, -24.465045738143754, 0.0, -3.9121569537928487, -11.525223376142412, 0.0, 0.0, 0.0, -27.31589343553672, -40.0, -11.603112641358885, -0.38598178785519743, -0.5341748317658135, 0.0, -30.0, -14.388333200371298, -5.27609506981617, -0.4164763532031579, 0.0, -4.3114125475893355, 0.0, 0.0, -5.01104105960149, -30.0, -20.716121906031717, -1.7452760259742428, -30.15648075474781, -55.6122369420036, -40.43966316589349, -1.3478594594682691, 0.0, -0.9781004495617296, -20.0, -23.54662244067047, -50.0, -26.430865384486516]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6858725186247159, "mean_inference_ms": 1.1965323122935552, "mean_action_processing_ms": 0.23759817062775646, "mean_env_wait_ms": 0.5137335008326261, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005232699123429664, "StateBufferConnector_ms": 0.004138769926848235, "ViewRequirementAgentConnector_ms": 0.10517990147625958}, "num_episodes": 162, "episode_return_max": 180.0, "episode_return_min": -37.16693765649416, "episode_return_mean": 20.27309188216363}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 592000, "num_agent_steps_trained": 592000, "num_env_steps_sampled": 148000, "num_env_steps_trained": 148000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 228.85067818494025, "num_env_steps_trained_throughput_per_sec": 228.85067818494025, "timesteps_total": 148000, "num_env_steps_sampled_lifetime": 148000, "num_agent_steps_sampled_lifetime": 592000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 592000, "timers": {"training_iteration_time_ms": 14056.783, "restore_workers_time_ms": 0.034, "training_step_time_ms": 14056.631, "sample_time_ms": 1372.332, "learn_time_ms": 12662.523, "learn_throughput": 315.893, "synch_weights_time_ms": 18.978}, "counters": {"num_env_steps_sampled": 148000, "num_env_steps_trained": 148000, "num_agent_steps_sampled": 592000, "num_agent_steps_trained": 592000}, "done": false, "training_iteration": 37, "trial_id": "86f16_00000", "date": "2024-08-08_16-21-28", "timestamp": 1723148488, "time_this_iter_s": 17.491905689239502, "time_total_s": 527.4716393947601, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3acf12940>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 527.4716393947601, "iterations_since_restore": 37, "perf": {"cpu_util_percent": 62.69200000000001, "ram_util_percent": 82.86}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7893812193938181, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.4215884882507597, "policy_loss": -0.017170505935626752, "vf_loss": 2.437241430062774, "vf_explained_var": -2.1875538724534057e-06, "kl": 0.007587799741554971, "entropy": 1.0371147063395656, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 105750.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.0319506819049518, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.34226098805666, "policy_loss": -0.023079880940107007, "vf_loss": 4.362937971701225, "vf_explained_var": 0.037466971389949325, "kl": 0.01201449744351692, "entropy": 1.2696824637552102, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 36000.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 152000, "num_env_steps_trained": 152000, "num_agent_steps_sampled": 608000, "num_agent_steps_trained": 608000}, "env_runners": {"episode_reward_max": 167.01644509219003, "episode_reward_min": -30.203685260430966, "episode_reward_mean": 17.835734480834923, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 157, "episodes_timesteps_total": 3925, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -102.98355490781}, "policy_reward_max": {"adversary_policy": 90.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 10.89171974522293, "agent_policy": -14.83942475483387}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, -8.342415064432005, 38.759904387473945, -10.850053197490613, 40.0, -0.5025224004120687, 0.0, 0.0, 0.0, 0.0, -25.22921489749766, 0.0, 79.47851221997927, 60.0, 0.0, 0.0, 34.52339523720997, 60.0, 0.0, -9.480690459360982, -24.492386395583424, 0.0, 38.670877654866885, 8.108852601371591, 78.85695804016292, 14.377241964687542, -9.762289267582851, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 39.666128001052364, -10.0381003173238, -0.07398594559104632, -1.4985385497224335, -0.667432933950185, 37.800607836268085, 0.0, -17.946780372803993, -17.483191134145986, 40.0, 40.0, -14.464958212461198, -11.954645864464055, 0.0, 0.0, 60.0, 40.0, 0.0, -18.334268573563264, 100.0, 80.0, 58.74006061812193, -1.900523725295603, -21.377994887856165, 20.0, 0.0, -0.4405441579144109, -5.990343120253724, -10.947540394952368, -5.920351877002259, 0.0, 0.0, -2.3890966650660026, 34.42645392627955, -1.1697194397710362, -0.051190150220918884, 59.94019852295163, -13.817395780242965, -17.828333348610016, 56.00469211572067, 0.0, -4.679518233162748, -0.12788102740313834, 0.0, 40.0, 0.0, 0.0, 0.0, -30.203685260430966, 100.0, 0.0, -2.3070990857357723, 40.0, -17.102242973215006, 0.0, 80.0, -1.4712534287489976, 0.0, 167.01644509219003, -1.4665149654922527, 0.0, 0.0, 59.88554890080198, 20.0, 0.0, 59.75730581832096, -21.72030614662519, -1.069858042472197, 80.0, -2.4551041621121117, 20.0, -28.403804731536, -5.947565319319413, 0.0, -1.4027402173798653, -10.602180965934041, 40.0, -1.5369416208961295, -7.397093028720318, 20.0, 0.0, 20.0, -5.823451112104424, 0.0, 20.0, -5.297393629743268, -8.262731659824365, -21.789447128707693, 20.0, -1.328443433873998, 60.0, 0.0, 20.0, 40.0, 40.0, -4.028820290185381, 36.68164102196104, 60.0, 0.0, 137.11458420342035, -0.45380171573110584, 20.0, -4.469302346469878, 140.075199994213, 20.0, 80.0, 20.0, 0.0, 0.0, 18.82480949972328, 0.0, 55.035758093693715, 91.75560207663062, -11.648754188545201, 60.0, 20.0, 20.0, 0.0, 100.0, 58.947148559057254, 0.0, 80.0, 19.7128289528645, 40.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 90.0, 90.0, 90.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 80.0, 80.0, 80.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0], "policy_agent_policy_reward": [0.0, -8.342415064432005, -21.24009561252605, -10.850053197490613, -20.0, -0.5025224004120687, 0.0, 0.0, 0.0, 0.0, -25.22921489749766, 0.0, -40.52148778002073, -30.0, 0.0, 0.0, -55.47660476279003, -30.0, 0.0, -9.480690459360982, -24.492386395583424, 0.0, -21.32912234513312, -21.89114739862841, -41.14304195983708, -15.622758035312458, -9.762289267582851, 0.0, 0.0, 0.0, 0.0, -30.0, -30.0, -20.333871998947636, -10.0381003173238, -0.07398594559104632, -1.4985385497224335, -0.667432933950185, -22.19939216373191, 0.0, -17.946780372803993, -17.483191134145986, -20.0, -20.0, -14.464958212461198, -11.954645864464055, 0.0, 0.0, -30.0, -20.0, 0.0, -18.334268573563264, -50.0, -40.0, -31.259939381878063, -1.900523725295603, -21.377994887856165, -10.0, 0.0, -0.4405441579144109, -5.990343120253724, -10.947540394952368, -5.920351877002259, 0.0, 0.0, -2.3890966650660026, -25.573546073720458, -31.169719439771036, -0.051190150220918884, -30.059801477048364, -13.817395780242965, -47.828333348610016, -33.99530788427932, 0.0, -4.679518233162748, -0.12788102740313834, 0.0, -20.0, 0.0, 0.0, 0.0, -30.203685260430966, -50.0, 0.0, -2.3070990857357723, -20.0, -17.102242973215006, 0.0, -40.0, -1.4712534287489976, 0.0, -102.98355490781, -1.4665149654922527, 0.0, 0.0, -30.114451099198025, -10.0, 0.0, -30.24269418167904, -21.72030614662519, -1.069858042472197, -40.0, -2.4551041621121117, -10.0, -28.403804731536, -5.947565319319413, 0.0, -1.4027402173798653, -10.602180965934041, -20.0, -1.5369416208961295, -7.397093028720318, -10.0, 0.0, -10.0, -5.823451112104424, 0.0, -10.0, -5.297393629743268, -8.262731659824365, -21.789447128707693, -10.0, -1.328443433873998, -30.0, 0.0, -10.0, -20.0, -20.0, -4.028820290185381, -23.318358978038955, -30.0, 0.0, -72.88541579657965, -0.45380171573110584, -10.0, -4.469302346469878, -99.924800005787, -10.0, -40.0, -10.0, 0.0, 0.0, -11.17519050027672, 0.0, -34.964241906306285, -58.244397923369384, -11.648754188545201, -30.0, -10.0, -10.0, 0.0, -50.0, -31.052851440942742, 0.0, -40.0, -10.2871710471355, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6868538618075583, "mean_inference_ms": 1.196201693372181, "mean_action_processing_ms": 0.23777939014638377, "mean_env_wait_ms": 0.5134940815630898, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005945202651297211, "StateBufferConnector_ms": 0.003518040772456272, "ViewRequirementAgentConnector_ms": 0.0965165484483075}, "num_episodes": 157, "episode_return_max": 167.01644509219003, "episode_return_min": -30.203685260430966, "episode_return_mean": 17.835734480834923}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 608000, "num_agent_steps_trained": 608000, "num_env_steps_sampled": 152000, "num_env_steps_trained": 152000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 310.09727839124264, "num_env_steps_trained_throughput_per_sec": 310.09727839124264, "timesteps_total": 152000, "num_env_steps_sampled_lifetime": 152000, "num_agent_steps_sampled_lifetime": 608000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 608000, "timers": {"training_iteration_time_ms": 13387.198, "restore_workers_time_ms": 0.016, "training_step_time_ms": 13387.116, "sample_time_ms": 1253.986, "learn_time_ms": 12112.774, "learn_throughput": 330.23, "synch_weights_time_ms": 17.898}, "counters": {"num_env_steps_sampled": 152000, "num_env_steps_trained": 152000, "num_agent_steps_sampled": 608000, "num_agent_steps_trained": 608000}, "done": false, "training_iteration": 38, "trial_id": "86f16_00000", "date": "2024-08-08_16-21-41", "timestamp": 1723148501, "time_this_iter_s": 12.904489040374756, "time_total_s": 540.3761284351349, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3aca72550>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 540.3761284351349, "iterations_since_restore": 38, "perf": {"cpu_util_percent": 37.72777777777779, "ram_util_percent": 80.57222222222222}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7530283439455303, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.236111590963729, "policy_loss": -0.017314457000245205, "vf_loss": 2.252003915385997, "vf_explained_var": -1.50212159393527e-06, "kl": 0.0071106366507886504, "entropy": 0.9925935435591015, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 108570.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.33242767068247, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.937755231807629, "policy_loss": -0.019899507681354105, "vf_loss": 3.9553762366374334, "vf_explained_var": 0.047807083403070764, "kl": 0.011392466075234845, "entropy": 1.2526964202523232, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 36960.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 156000, "num_env_steps_trained": 156000, "num_agent_steps_sampled": 624000, "num_agent_steps_trained": 624000}, "env_runners": {"episode_reward_max": 160.0, "episode_reward_min": -37.24265271917352, "episode_reward_mean": 15.646816539191832, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -80.0}, "policy_reward_max": {"adversary_policy": 80.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 9.691358024691358, "agent_policy": -13.427257534882242}, "custom_metrics": {}, "hist_stats": {"episode_reward": [20.0, 0.0, 0.0, -3.263500709874352, -3.5769196701666095, 18.7379844526738, 20.0, -4.144510552959395, 60.0, 0.0, -1.170877088481419, 160.0, 20.0, -13.001343318291873, 100.0, 60.0, -13.664904341564021, -6.070935393144689, -0.1565859954145532, 0.0, 0.0, -5.063379914521395, 0.0, 0.4579602852009774, -5.259471921068337, 39.79159410633502, 0.0, 15.467123322504076, 0.0, -17.239420311485837, 79.07635403099218, 20.0, 0.0, 40.0, 0.0, 0.0, 20.0, 38.87435703724382, -0.6307910252614435, 60.0, 58.4212978019317, 0.0, -5.655900296463974, 13.929351241771379, 40.0, -13.969610199942736, 100.0, -7.133563372362346, 60.0, -18.547942028614045, -0.6410500638460181, 60.0, -15.703779578043166, -5.361458124980373, 20.0, -0.872285545069772, -9.188675330436695, 0.0, -7.684645386064777, 0.0, 57.212343522673315, 15.555012871045633, 80.0, 34.5533071025757, 59.7797640275016, 20.0, 99.80236705884832, 0.0, 0.0, -6.938854998374087, 0.0, -3.8276229583217454, 0.0, 59.870134614883625, -10.567404747087155, 60.0, 0.0, 77.9981881180495, -5.827717687139022, 13.506819365516538, 0.0, 140.0, -5.1488083281093076, 34.54238403323851, 0.0, -0.675863386266381, 40.0, -2.169576182729851, -29.57631784004147, 63.15508146409043, 40.0, 1.6949874545088086, -2.5835418030791546, 0.0, 0.0, 0.0, 0.0, -7.086743701850799, -23.0116223784321, 0.0, -4.87501450410504, 20.0, 38.84841300411354, -0.04017744322680761, 0.0, 0.0, 20.0, 37.7441730863105, 80.0, -1.3639179772676113, -5.594113236662057, -0.06835231515562201, 0.0, 25.117892279419358, -37.24265271917352, 0.0, 0.0, 20.0, 40.0, 120.0, 0.0, 20.0, -20.955576719789075, 20.0, -27.330363782898687, -1.3304304132314948, -8.511678370669603, 0.0, 35.24795236699223, 0.0, 0.0, -1.7000021765275886, 0.0, 0.0, 0.0, -16.130012162933944, 60.0, -2.19588068441798, 21.460179229593617, 0.0, -3.875150170811507, 0.0, -7.8559638355690105, 60.0, -18.497972216233187, 20.0, 19.655289999012123, -2.545592906487226, 0.0, -21.40107070380856, 0.0, 0.0, 80.0, 160.0, -1.7085544843736233, 0.0, 52.92206847488154, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 80.0, 80.0, 80.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 80.0, 80.0, 80.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-10.0, 0.0, 0.0, -3.263500709874352, -3.5769196701666095, -11.2620155473262, -10.0, -4.144510552959395, -30.0, 0.0, -1.170877088481419, -80.0, -10.0, -13.001343318291873, -50.0, -30.0, -13.664904341564021, -6.070935393144689, -0.1565859954145532, 0.0, 0.0, -5.063379914521395, 0.0, -59.542039714799024, -5.259471921068337, -20.20840589366498, 0.0, -14.532876677495928, 0.0, -17.239420311485837, -40.923645969007815, -10.0, 0.0, -20.0, 0.0, 0.0, -10.0, -21.12564296275618, -0.6307910252614435, -30.0, -31.578702198068292, 0.0, -5.655900296463974, -16.07064875822862, -20.0, -13.969610199942736, -50.0, -7.133563372362346, -30.0, -18.547942028614045, -0.6410500638460181, -30.0, -15.703779578043166, -5.361458124980373, -10.0, -0.872285545069772, -9.188675330436695, 0.0, -7.684645386064777, 0.0, -32.787656477326685, -14.444987128954368, -40.0, -25.446692897424292, -30.2202359724984, -10.0, -50.19763294115168, 0.0, 0.0, -6.938854998374087, 0.0, -3.8276229583217454, 0.0, -30.129865385116368, -10.567404747087155, -30.0, 0.0, -42.0018118819505, -5.827717687139022, -16.493180634483462, 0.0, -70.0, -5.1488083281093076, -25.457615966761487, 0.0, -0.675863386266381, -20.0, -2.169576182729851, -29.57631784004147, -56.844918535909585, -20.0, -28.30501254549119, -2.5835418030791546, 0.0, 0.0, 0.0, 0.0, -7.086743701850799, -23.0116223784321, 0.0, -4.87501450410504, -10.0, -21.15158699588646, -0.04017744322680761, 0.0, 0.0, -10.0, -22.255826913689493, -40.0, -1.3639179772676113, -5.594113236662057, -0.06835231515562201, 0.0, -34.88210772058064, -37.24265271917352, 0.0, 0.0, -10.0, -20.0, -60.0, 0.0, -10.0, -20.955576719789075, -10.0, -27.330363782898687, -1.3304304132314948, -8.511678370669603, 0.0, -24.752047633007763, 0.0, 0.0, -1.7000021765275886, 0.0, 0.0, 0.0, -16.130012162933944, -30.0, -2.19588068441798, -38.53982077040638, 0.0, -3.875150170811507, 0.0, -7.8559638355690105, -30.0, -18.497972216233187, -10.0, -10.344710000987877, -2.545592906487226, 0.0, -21.40107070380856, 0.0, 0.0, -40.0, -80.0, -1.7085544843736233, 0.0, -37.07793152511846, 0.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.687631625626607, "mean_inference_ms": 1.1992508026069304, "mean_action_processing_ms": 0.23839617511192793, "mean_env_wait_ms": 0.5146529896642084, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006034050458743248, "StateBufferConnector_ms": 0.0038212464179521724, "ViewRequirementAgentConnector_ms": 0.10810501781510717}, "num_episodes": 162, "episode_return_max": 160.0, "episode_return_min": -37.24265271917352, "episode_return_mean": 15.646816539191832}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 624000, "num_agent_steps_trained": 624000, "num_env_steps_sampled": 156000, "num_env_steps_trained": 156000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 309.24993028279846, "num_env_steps_trained_throughput_per_sec": 309.24993028279846, "timesteps_total": 156000, "num_env_steps_sampled_lifetime": 156000, "num_agent_steps_sampled_lifetime": 624000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 624000, "timers": {"training_iteration_time_ms": 13354.664, "restore_workers_time_ms": 0.016, "training_step_time_ms": 13354.595, "sample_time_ms": 1256.01, "learn_time_ms": 12078.259, "learn_throughput": 331.174, "synch_weights_time_ms": 18.07}, "counters": {"num_env_steps_sampled": 156000, "num_env_steps_trained": 156000, "num_agent_steps_sampled": 624000, "num_agent_steps_trained": 624000}, "done": false, "training_iteration": 39, "trial_id": "86f16_00000", "date": "2024-08-08_16-21-54", "timestamp": 1723148514, "time_this_iter_s": 12.957372903823853, "time_total_s": 553.3335013389587, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3aca72790>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 553.3335013389587, "iterations_since_restore": 39, "perf": {"cpu_util_percent": 40.98947368421053, "ram_util_percent": 80.06315789473685}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.761007493163677, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.3448665186023034, "policy_loss": -0.016108971831891587, "vf_loss": 2.359661273626571, "vf_explained_var": -7.48672383896848e-07, "kl": 0.006571083333148878, "entropy": 0.9816251855370001, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 111390.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.324434394265215, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.6596946517626443, "policy_loss": -0.0188430210245618, "vf_loss": 3.676503495126963, "vf_explained_var": 0.011310995556414127, "kl": 0.01017088571273888, "entropy": 1.2380434896796941, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 37920.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 160000, "num_env_steps_trained": 160000, "num_agent_steps_sampled": 640000, "num_agent_steps_trained": 640000}, "env_runners": {"episode_reward_max": 160.0, "episode_reward_min": -20.57152507186854, "episode_reward_mean": 18.931019794835862, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -80.0}, "policy_reward_max": {"adversary_policy": 80.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 11.049382716049383, "agent_policy": -14.217128353312285}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-1.3448331381108183, 0.0, 54.17943604389896, 0.0, 14.789192935646499, -2.471080922599884, 0.0, 0.0, 0.0, 0.0, 68.20361549859398, -17.371088227370123, 40.0, 0.0, 0.0, -0.6523960189425504, 80.0, -2.6898026532909034, -3.6926123325024225, 15.532173476422127, -13.43641569850363, -10.534352997483321, 79.88268597871937, 17.816349288130258, 140.0, 56.38275367834603, -2.6730694068275165, 0.0, -0.6394818122114254, 40.0, 0.0, 0.0, 75.57356927734902, 60.0, -2.30944172782793, 0.0, -14.959746305566876, 0.0, -12.730118377411989, 0.0, 0.0, 31.011549283321294, 100.0, 40.0, -0.8273035265358697, 0.0, 39.280207987838054, -10.657803907967741, -20.57152507186854, -0.09874485620091966, 19.679474814541805, -6.407731374859582, 0.0, 0.0, 0.0, 0.0, 40.0, -11.444475443503558, 0.0, 0.0, 0.0, 0.0, -6.52422049260761, 0.0, 0.0, 19.965261688439398, 0.0, 0.0, 0.0, 94.0426985831884, 0.0, 39.94812111224534, -4.710734173160303, 0.0, -7.479606043812351, 100.0, 7.4453077966783034, -15.617111989374514, 40.0, 40.0, 0.0, -14.681278382879164, 0.0, 34.30181623082405, -2.0620832410144896, 80.0, 20.0, -1.1051096938300575, 20.0, 53.77498059118608, -12.472718052131263, 59.49948029897378, 0.0, -0.08674190744378918, 40.0, 140.0, 17.43672289151333, -6.724460067052041, 0.0, 0.0, -7.991575182769472, -0.8266534547132054, 0.0, 160.0, 58.23200282182697, -1.106185115350532, -0.3657516854853715, -2.3702178234033626, 0.0, -13.46712234210846, 51.66333945346629, -2.2646570378141555, 0.0, 80.0, 0.0, -8.863347634563327, -2.7469031325479376, 37.82736895975429, 0.0, -2.7187692790235722, 40.0, 17.34340601048705, 140.0, 46.17878282567529, 80.0, 20.0, 56.97881188830292, -17.238845704832038, -3.776566366608197, 114.1510699404987, 39.7944489914636, 0.0, 20.0, 40.0, -1.3588570774635644, 80.0, 20.0, -4.987581577294597, 98.47022057832888, 45.31395946443024, 60.0, 0.0, 18.598878436089016, -3.1759502932783192, 20.0, -3.5965277480985556, -2.88547321054779, 100.0, -1.965178957158048, -1.0832206748942363, 20.0, 0.0, -0.5617559704193176, -4.097051436334982, 20.0, -4.952608770693824, 0.0, -16.454526048539805, 0.0, -0.6410656959356165, 0.0, 80.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 70.0, 70.0, 70.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 70.0, 70.0, 70.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 80.0, 80.0, 80.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 70.0, 70.0, 70.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0], "policy_agent_policy_reward": [-31.34483313811082, 0.0, -35.82056395610105, 0.0, -15.210807064353501, -2.471080922599884, 0.0, 0.0, 0.0, 0.0, -51.79638450140604, -17.371088227370123, -20.0, 0.0, 0.0, -0.6523960189425504, -40.0, -2.6898026532909034, -3.6926123325024225, -14.467826523577875, -13.43641569850363, -10.534352997483321, -70.11731402128063, -12.183650711869742, -70.0, -33.617246321653965, -2.6730694068275165, 0.0, -0.6394818122114254, -20.0, 0.0, 0.0, -44.42643072265098, -30.0, -2.30944172782793, 0.0, -14.959746305566876, 0.0, -12.730118377411989, 0.0, 0.0, -28.988450716678706, -50.0, -20.0, -0.8273035265358697, 0.0, -20.719792012161946, -10.657803907967741, -20.57152507186854, -0.09874485620091966, -10.320525185458195, -6.407731374859582, 0.0, 0.0, 0.0, 0.0, -20.0, -11.444475443503558, 0.0, 0.0, 0.0, 0.0, -6.52422049260761, 0.0, 0.0, -10.034738311560602, 0.0, 0.0, 0.0, -55.957301416811625, 0.0, -20.051878887754658, -4.710734173160303, 0.0, -7.479606043812351, -50.0, -22.554692203321697, -15.617111989374514, -20.0, -20.0, 0.0, -14.681278382879164, 0.0, -25.698183769175948, -2.0620832410144896, -40.0, -10.0, -1.1051096938300575, -10.0, -36.225019408813914, -12.472718052131263, -30.50051970102622, 0.0, -0.08674190744378918, -20.0, -70.0, -12.56327710848667, -6.724460067052041, 0.0, 0.0, -7.991575182769472, -0.8266534547132054, 0.0, -80.0, -31.767997178173037, -1.106185115350532, -0.3657516854853715, -2.3702178234033626, 0.0, -13.46712234210846, -38.33666054653371, -2.2646570378141555, 0.0, -40.0, 0.0, -8.863347634563327, -2.7469031325479376, -22.172631040245715, 0.0, -2.7187692790235722, -20.0, -12.656593989512949, -70.0, -43.82121717432472, -40.0, -10.0, -33.021188111697086, -17.238845704832038, -3.776566366608197, -65.84893005950128, -20.205551008536407, 0.0, -10.0, -20.0, -1.3588570774635644, -40.0, -10.0, -4.987581577294597, -51.52977942167112, -44.68604053556976, -30.0, 0.0, -11.401121563910982, -3.1759502932783192, -10.0, -3.5965277480985556, -32.88547321054779, -50.0, -1.965178957158048, -1.0832206748942363, -10.0, 0.0, -0.5617559704193176, -4.097051436334982, -10.0, -4.952608770693824, 0.0, -16.454526048539805, 0.0, -0.6410656959356165, 0.0, -40.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6870995450266214, "mean_inference_ms": 1.1994199543806716, "mean_action_processing_ms": 0.23817533511377253, "mean_env_wait_ms": 0.5140278591412978, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005804535783367392, "StateBufferConnector_ms": 0.0033160786569854358, "ViewRequirementAgentConnector_ms": 0.09893936875425739}, "num_episodes": 162, "episode_return_max": 160.0, "episode_return_min": -20.57152507186854, "episode_return_mean": 18.931019794835862}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 640000, "num_agent_steps_trained": 640000, "num_env_steps_sampled": 160000, "num_env_steps_trained": 160000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 278.3421381245413, "num_env_steps_trained_throughput_per_sec": 278.3421381245413, "timesteps_total": 160000, "num_env_steps_sampled_lifetime": 160000, "num_agent_steps_sampled_lifetime": 640000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 640000, "timers": {"training_iteration_time_ms": 13473.182, "restore_workers_time_ms": 0.016, "training_step_time_ms": 13473.126, "sample_time_ms": 1258.647, "learn_time_ms": 12193.588, "learn_throughput": 328.041, "synch_weights_time_ms": 18.968}, "counters": {"num_env_steps_sampled": 160000, "num_env_steps_trained": 160000, "num_agent_steps_sampled": 640000, "num_agent_steps_trained": 640000}, "done": false, "training_iteration": 40, "trial_id": "86f16_00000", "date": "2024-08-08_16-22-09", "timestamp": 1723148529, "time_this_iter_s": 14.410555839538574, "time_total_s": 567.7440571784973, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3aca72d30>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 567.7440571784973, "iterations_since_restore": 40, "perf": {"cpu_util_percent": 48.235, "ram_util_percent": 81.41499999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7664435265334786, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.6134953306499105, "policy_loss": -0.01770469893937508, "vf_loss": 2.629848182539568, "vf_explained_var": 1.7579777020934626e-06, "kl": 0.006759217857686484, "entropy": 0.9919206435164661, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 114210.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.1407515111068887, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.283906520406405, "policy_loss": -0.018213730300582636, "vf_loss": 4.300197758277258, "vf_explained_var": 0.01766296774148941, "kl": 0.009612503533875053, "entropy": 1.2577823776751758, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 38880.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 164000, "num_env_steps_trained": 164000, "num_agent_steps_sampled": 656000, "num_agent_steps_trained": 656000}, "env_runners": {"episode_reward_max": 140.0, "episode_reward_min": -54.39158798327128, "episode_reward_mean": 20.443017068552457, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 158, "episodes_timesteps_total": 3950, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -70.02359006035898}, "policy_reward_max": {"adversary_policy": 70.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 12.08860759493671, "agent_policy": -15.822805716257669}, "custom_metrics": {}, "hist_stats": {"episode_reward": [60.0, -7.054758293459529, 0.0, 0.0, 40.0, 49.91384141254127, 0.0, 0.0, -9.138916958504678, 0.0, 60.0, -24.84295457608426, 140.0, 0.0, -48.38063299939141, 39.38378127584379, -9.342108187373132, 20.0, 51.86094523314824, 0.0, 39.140521268096755, -0.22299889236523818, 139.97640993964103, 20.0, 0.0, 40.0, 44.029194789594065, 0.0, 20.0, 0.0, -5.85454955505682, -0.7486790272260802, 60.0, -6.646747789220391, 40.0, -22.79970029546066, 0.0, 60.0, 0.0, -0.2945199557330369, 0.0, -5.358871476928539, 0.0, 0.0, -4.351252993487687, 12.078316689384824, 80.0, 79.90727748436595, 39.80367942730577, -8.538501645348454, -54.39158798327128, 0.0, 80.0, 0.0, -0.035349024667034046, 20.0, 79.1343067017701, 9.977125989164481, 120.0, 20.0, 0.0, -6.2963784309417035, 80.0, -12.948794210709254, 60.0, 57.46448827689764, 0.0, 60.0, -1.37671265756105, 0.0, -2.0441385083991106, 0.0, -1.0199512096444963, 0.0, 0.0, 2.531637230125689, -3.092301278365448, 29.318944774016316, -5.441069687915855, -3.8526986121387594, 0.0, 0.0, 0.0, 40.0, 0.0, -12.477779799487305, 0.0, -18.501442452148275, 40.0, 80.0, 0.0, 0.0, 40.0, -15.219125547428265, 38.52223100385478, 13.383689451297954, 16.15309140563417, 0.0, 10.536188510162035, 59.017706087122306, 20.0, -1.2460787109433469, -4.254019388643391, 20.0, 36.14154382800181, 0.0, -0.23517696892355278, -21.114124680901458, -1.8983642119728528, 91.64574866524296, 117.12971589487859, 0.0, 19.402054542855605, 0.0, 0.0, 0.0, 0.0, -1.6757232904582153, -10.574383390976072, 20.0, 0.0, 40.0, 40.0, 0.0, 58.97780067445815, 60.0, 60.0, 20.0, 20.0, 0.0, -8.961097779399582, 20.0, -3.6865728403456535, 0.0, 0.0, -2.2222802872843586, -11.121558042659988, 0.0, 80.0, 100.0, -2.337028670378624, -24.63229393569952, 60.0, 0.0, 60.0, 0.0, -0.6605320646629398, 115.97405153466444, 73.05611173268868, 120.0, 60.0, -6.57752245054694, 20.0, 40.0, 55.57076515355233, 40.0, 40.0, 21.43480661709271], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 60.0, 60.0, 60.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 40.0, 40.0, 40.0, 60.0, 60.0, 60.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0], "policy_agent_policy_reward": [-30.0, -7.054758293459529, 0.0, 0.0, -20.0, -40.08615858745874, 0.0, 0.0, -9.138916958504678, 0.0, -30.0, -24.84295457608426, -70.0, 0.0, -48.38063299939141, -20.616218724156216, -9.342108187373132, -10.0, -38.13905476685176, 0.0, -20.859478731903245, -0.22299889236523818, -70.02359006035898, -10.0, 0.0, -20.0, -45.970805210405935, 0.0, -10.0, 0.0, -5.85454955505682, -0.7486790272260802, -30.0, -6.646747789220391, -20.0, -22.79970029546066, 0.0, -30.0, 0.0, -0.2945199557330369, 0.0, -5.358871476928539, 0.0, 0.0, -4.351252993487687, -17.921683310615176, -40.0, -40.09272251563405, -20.19632057269423, -8.538501645348454, -54.39158798327128, 0.0, -40.0, 0.0, -0.035349024667034046, -10.0, -40.86569329822989, -50.02287401083552, -60.0, -10.0, 0.0, -6.2963784309417035, -40.0, -12.948794210709254, -30.0, -32.53551172310235, 0.0, -30.0, -1.37671265756105, 0.0, -2.0441385083991106, 0.0, -1.0199512096444963, 0.0, 0.0, -27.468362769874318, -3.092301278365448, -30.68105522598368, -5.441069687915855, -3.8526986121387594, 0.0, 0.0, 0.0, -20.0, 0.0, -12.477779799487305, 0.0, -18.501442452148275, -20.0, -40.0, 0.0, 0.0, -20.0, -15.219125547428265, -21.477768996145223, -16.61631054870205, -43.846908594365814, 0.0, -19.46381148983797, -30.982293912877694, -10.0, -1.2460787109433469, -4.254019388643391, -10.0, -23.858456171998192, 0.0, -0.23517696892355278, -21.114124680901458, -1.8983642119728528, -58.35425133475704, -62.870284105121414, 0.0, -10.597945457144393, 0.0, 0.0, 0.0, 0.0, -1.6757232904582153, -10.574383390976072, -10.0, 0.0, -20.0, -20.0, 0.0, -31.02219932554185, -30.0, -30.0, -10.0, -10.0, 0.0, -8.961097779399582, -10.0, -3.6865728403456535, 0.0, 0.0, -2.2222802872843586, -11.121558042659988, 0.0, -40.0, -50.0, -2.337028670378624, -24.63229393569952, -30.0, 0.0, -30.0, 0.0, -0.6605320646629398, -64.02594846533555, -46.94388826731132, -60.0, -30.0, -6.57752245054694, -10.0, -20.0, -34.42923484644766, -20.0, -20.0, -38.5651933829073]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6875542800505369, "mean_inference_ms": 1.2010869371224702, "mean_action_processing_ms": 0.23827796701079948, "mean_env_wait_ms": 0.5142969710668563, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0050797492642945885, "StateBufferConnector_ms": 0.0033525726463221298, "ViewRequirementAgentConnector_ms": 0.10115632527991186}, "num_episodes": 158, "episode_return_max": 140.0, "episode_return_min": -54.39158798327128, "episode_return_mean": 20.443017068552457}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 656000, "num_agent_steps_trained": 656000, "num_env_steps_sampled": 164000, "num_env_steps_trained": 164000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 315.8821651369728, "num_env_steps_trained_throughput_per_sec": 315.8821651369728, "timesteps_total": 164000, "num_env_steps_sampled_lifetime": 164000, "num_agent_steps_sampled_lifetime": 656000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 656000, "timers": {"training_iteration_time_ms": 13382.42, "restore_workers_time_ms": 0.016, "training_step_time_ms": 13382.35, "sample_time_ms": 1281.886, "learn_time_ms": 12078.832, "learn_throughput": 331.158, "synch_weights_time_ms": 19.629}, "counters": {"num_env_steps_sampled": 164000, "num_env_steps_trained": 164000, "num_agent_steps_sampled": 656000, "num_agent_steps_trained": 656000}, "done": false, "training_iteration": 41, "trial_id": "86f16_00000", "date": "2024-08-08_16-22-22", "timestamp": 1723148542, "time_this_iter_s": 12.698044061660767, "time_total_s": 580.4421012401581, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3aca72f70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 580.4421012401581, "iterations_since_restore": 41, "perf": {"cpu_util_percent": 39.17894736842105, "ram_util_percent": 81.75263157894737}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.747385494115082, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.3595731711133996, "policy_loss": -0.016999270488072107, "vf_loss": 2.3750831115330366, "vf_explained_var": -1.666393685848155e-07, "kl": 0.007446634777451318, "entropy": 0.9690293754034854, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 117030.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.264753477027019, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.298959814260403, "policy_loss": -0.022571040852441607, "vf_loss": 4.31956155175964, "vf_explained_var": 0.08322662015755972, "kl": 0.009846571485793732, "entropy": 1.2494538859774669, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 39840.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 168000, "num_env_steps_trained": 168000, "num_agent_steps_sampled": 672000, "num_agent_steps_trained": 672000}, "env_runners": {"episode_reward_max": 180.0, "episode_reward_min": -35.83668682802276, "episode_reward_mean": 18.040561993229918, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 157, "episodes_timesteps_total": 3925, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -90.0}, "policy_reward_max": {"adversary_policy": 90.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 11.210191082802547, "agent_policy": -15.590011255177725}, "custom_metrics": {}, "hist_stats": {"episode_reward": [19.43620639724664, -31.62526654189618, -7.963002722755002, 29.469269060371587, 0.0, 0.0, 40.0, -12.397778540145698, 80.0, -21.7518315525755, 60.0, -4.370976566554371, 31.532817139218633, -21.988736776384552, 18.8801602087099, -10.460679687649176, 0.0, 0.0, -0.05653176836591056, 0.0, 38.00083477319366, 0.0, 0.0, 26.46622094180627, 18.89760760374829, 0.0, 0.0, 18.170159132251108, 40.0, 56.751175341637975, 0.0, 39.912044027198, 11.293315226132492, -35.83668682802276, 0.0, 20.0, -7.771218974119359, 0.0, 12.16755146769895, -5.488702428260161, 40.0, 10.795796615754288, 20.0, -16.301042968941857, 80.0, 0.0, -0.23321352915450455, 52.764320103796145, 0.0, -24.797320922767497, 40.0, 0.0, -2.351657015217755, 60.0, 0.0, 0.0, 0.0, -3.287726080492784, 0.0, 60.0, 20.0, -13.214449069020008, 39.169533321649645, -17.461537247279235, 40.0, 56.0882585108734, 39.915158762208016, 60.0, 78.27231900265691, 0.0, -4.293165299626795, -0.49959963640838656, -9.034688125850455, -0.47164731660503834, -20.21258235995433, -10.536065357629765, 100.0, -4.49143808057166, 39.42112402541271, 0.0, -0.26930696406071264, 11.214864306382445, 39.45921376363852, 0.0, 38.33185253808798, 18.014126949179293, 56.916897654032454, 0.0, 0.0, 20.0, 20.0, 0.0, 20.0, 160.0, 60.0, 0.0, 17.0782959618528, 0.0, 40.0, -12.665354127784294, 14.469425349113905, 180.0, 0.0, 0.0, 63.50261336162805, -2.161901667697445, 60.0, 80.0, -1.8565760834453535, -0.5034748722318516, -0.19797986091187658, 0.0, 0.0, 0.0, 40.0, 19.79924784729912, 17.80002451391127, -25.886840841120147, -19.10263924436941, 40.0, 0.0, 0.0, 0.0, 38.88206275571933, -1.7349506544904314, -17.91925966302329, 19.16359576825765, 0.0, 0.0, 0.0, -0.34018206042291443, 0.0, 60.0, -11.349100446151738, 20.0, -5.313613295671409, 0.0, 20.86182570614432, 0.0, 100.0, 58.5326116898387, 39.29072299097441, -11.164088454067214, -3.6348482445549255, 0.0, 140.0, -4.237751188035161, 84.60223048186205, 19.93559668748939, -15.19064975986269, 79.06576698399329, 50.159261364378466, 39.99602336929527, 33.086821579226346, 40.0, 0.0, -4.772657522622626], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 80.0, 80.0, 80.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 90.0, 90.0, 90.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-10.56379360275336, -31.62526654189618, -7.963002722755002, -30.530730939628413, 0.0, 0.0, -20.0, -12.397778540145698, -40.0, -21.7518315525755, -30.0, -4.370976566554371, -58.46718286078138, -21.988736776384552, -11.1198397912901, -10.460679687649176, 0.0, 0.0, -0.05653176836591056, 0.0, -21.99916522680634, 0.0, 0.0, -33.53377905819373, -11.102392396251709, 0.0, 0.0, -11.82984086774889, -20.0, -33.248824658362025, 0.0, -20.087955972802, -18.706684773867508, -35.83668682802276, 0.0, -10.0, -7.771218974119359, 0.0, -17.83244853230105, -5.488702428260161, -20.0, -49.204203384245716, -10.0, -16.301042968941857, -40.0, 0.0, -0.23321352915450455, -37.23567989620386, 0.0, -24.797320922767497, -20.0, 0.0, -2.351657015217755, -30.0, 0.0, 0.0, 0.0, -3.287726080492784, 0.0, -30.0, -10.0, -13.214449069020008, -20.830466678350355, -17.461537247279235, -20.0, -33.9117414891266, -20.084841237791984, -30.0, -41.727680997343086, 0.0, -4.293165299626795, -0.49959963640838656, -9.034688125850455, -0.47164731660503834, -20.21258235995433, -10.536065357629765, -50.0, -4.49143808057166, -20.57887597458729, 0.0, -0.26930696406071264, -18.785135693617555, -20.540786236361477, 0.0, -21.66814746191202, -11.98587305082071, -33.08310234596754, 0.0, 0.0, -10.0, -10.0, 0.0, -10.0, -80.0, -30.0, 0.0, -12.9217040381472, 0.0, -20.0, -12.665354127784294, -45.530574650886095, -90.0, 0.0, 0.0, -56.497386638371964, -2.161901667697445, -30.0, -40.0, -1.8565760834453535, -0.5034748722318516, -0.19797986091187658, 0.0, 0.0, 0.0, -20.0, -10.200752152700879, -12.199975486088729, -25.886840841120147, -19.10263924436941, -20.0, 0.0, 0.0, 0.0, -51.117937244280654, -1.7349506544904314, -17.91925966302329, -10.83640423174235, 0.0, 0.0, 0.0, -0.34018206042291443, 0.0, -30.0, -11.349100446151738, -10.0, -5.313613295671409, 0.0, -39.13817429385567, 0.0, -50.0, -31.467388310161297, -20.70927700902559, -11.164088454067214, -3.6348482445549255, 0.0, -70.0, -4.237751188035161, -65.39776951813793, -10.06440331251061, -15.19064975986269, -40.93423301600672, -39.84073863562153, -20.003976630704724, -26.913178420773647, -20.0, 0.0, -4.772657522622626]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6871855595214809, "mean_inference_ms": 1.20081036941893, "mean_action_processing_ms": 0.26469148160617584, "mean_env_wait_ms": 0.5139104766408654, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006255450522064403, "StateBufferConnector_ms": 0.0037536499606575934, "ViewRequirementAgentConnector_ms": 0.10182379157679855}, "num_episodes": 157, "episode_return_max": 180.0, "episode_return_min": -35.83668682802276, "episode_return_mean": 18.040561993229918}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 672000, "num_agent_steps_trained": 672000, "num_env_steps_sampled": 168000, "num_env_steps_trained": 168000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 316.39306069203366, "num_env_steps_trained_throughput_per_sec": 316.39306069203366, "timesteps_total": 168000, "num_env_steps_sampled_lifetime": 168000, "num_agent_steps_sampled_lifetime": 672000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 672000, "timers": {"training_iteration_time_ms": 13409.888, "restore_workers_time_ms": 0.016, "training_step_time_ms": 13409.818, "sample_time_ms": 1333.116, "learn_time_ms": 12054.689, "learn_throughput": 331.821, "synch_weights_time_ms": 20.001}, "counters": {"num_env_steps_sampled": 168000, "num_env_steps_trained": 168000, "num_agent_steps_sampled": 672000, "num_agent_steps_trained": 672000}, "done": false, "training_iteration": 42, "trial_id": "86f16_00000", "date": "2024-08-08_16-22-34", "timestamp": 1723148554, "time_this_iter_s": 12.666844844818115, "time_total_s": 593.1089460849762, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3aca6e160>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 593.1089460849762, "iterations_since_restore": 42, "perf": {"cpu_util_percent": 37.22777777777778, "ram_util_percent": 81.31666666666666}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7587707229856904, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.9198253114172754, "policy_loss": -0.01921805745512511, "vf_loss": 2.9375738770826487, "vf_explained_var": 2.8705343287041844e-07, "kl": 0.00734745577293361, "entropy": 0.9233379945687369, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 119850.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.064616614518066, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.625407483180364, "policy_loss": -0.02554221842729021, "vf_loss": 4.648497556398312, "vf_explained_var": 0.042289457035561404, "kl": 0.012260762909867965, "entropy": 1.262451221421361, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 40800.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 172000, "num_env_steps_trained": 172000, "num_agent_steps_sampled": 688000, "num_agent_steps_trained": 688000}, "env_runners": {"episode_reward_max": 152.22970191289278, "episode_reward_min": -68.96639276164635, "episode_reward_mean": 20.108428915317504, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -97.30248329089864}, "policy_reward_max": {"adversary_policy": 80.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 12.037037037037036, "agent_policy": -16.002682195793607}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, -0.30890824320486954, 0.0, 0.0, 40.0, 60.0, 0.0, -6.3338004532403875, 0.0, -23.941298048109203, 58.22314646790599, -18.359402125449904, 0.0, 60.0, 0.0, 120.0, 34.91984898012827, 0.0, -11.46917807982027, 58.89925217892937, 20.0, 77.89795518079777, 0.0, 0.0, 40.0, -9.563719725328312, 40.0, -4.172156814155651, 40.0, 38.50915869585377, -26.719442525404055, 19.845320707659386, 0.0, -4.81242656443661, 59.87371827612185, 11.431183995835001, 56.958116814532644, 38.2417607467394, -18.07050498002517, 0.0, -0.40637781178210153, -4.675452459793505, 40.0, 20.0, -14.604483697335795, 40.0, 0.0, -9.803521250810666, 18.180035983167016, 40.0, 19.188648094691263, -8.853495013794067, 20.0, -2.765764904198331, 59.87327999451523, 0.0, 140.0, 0.0, -7.941389520941206, 20.0, 100.0, 20.0, 0.0, -0.6437238526600253, 0.0, -27.047262162196564, 0.0, 100.0, 0.0, -14.43443253364916, 140.0, -2.003965867855136, 49.40222701232052, 18.64290522054899, 0.0, -0.3785723369541871, 100.0, 0.0, 56.7846797637139, 152.22970191289278, 20.0, 120.0, 40.0, 0.0, 8.237817116714233, -2.1377351284440795, 60.0, 40.0, 0.0, 0.0, -0.12691679598827, 99.18578393054067, 0.0, 80.0, -3.2903034868319185, -0.255710586864778, -3.9988425238142824, 0.0, 0.0, -18.005906219279616, 0.0, -7.084389341144944, 120.0, 0.0, 40.0, -11.398232781851945, -12.395574448127721, 79.10401795425524, 0.0, -5.67693957391754, -0.7199662159217068, -12.937606767070637, -68.96639276164635, 0.0, -13.25831152444963, 20.0, 97.22951387906159, 16.795613123856583, 20.0, 60.0, 58.082072304977615, -16.005936243370236, 20.0, 20.0, 80.0, 20.0, 25.976661227626717, 79.54900051944205, 0.0, 0.0, 76.58916273245148, 0.0, 0.0, 20.0, 40.0, -2.5363522789834887, 0.0, 20.0, 20.0, 40.0, -5.384541386453687, -6.94181844978562, 0.0, -6.166801145659349, 40.0, 17.37182311891579, 0.0, 0.0, 0.0, -1.9198455191407449, -0.44877956540920416, -5.740287705571915, 80.0, -31.365881215534024, 0.0, 40.0, -13.334425552863713, 112.69751670910136, 0.0, -34.94766217259051, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 80.0, 80.0, 80.0, 10.0, 10.0, 10.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [0.0, 0.0, -0.30890824320486954, 0.0, 0.0, -20.0, -30.0, 0.0, -6.3338004532403875, 0.0, -23.941298048109203, -31.776853532094012, -18.359402125449904, 0.0, -30.0, 0.0, -60.0, -25.080151019871728, 0.0, -11.46917807982027, -31.10074782107062, -10.0, -42.102044819202234, 0.0, 0.0, -20.0, -9.563719725328312, -20.0, -4.172156814155651, -20.0, -21.490841304146226, -26.719442525404055, -10.154679292340614, 0.0, -4.81242656443661, -30.12628172387815, -18.568816004165, -33.041883185467356, -51.7582392532606, -18.07050498002517, 0.0, -0.40637781178210153, -4.675452459793505, -20.0, -10.0, -14.604483697335795, -20.0, 0.0, -9.803521250810666, -11.819964016832982, -20.0, -10.811351905308737, -8.853495013794067, -10.0, -2.765764904198331, -30.126720005484756, 0.0, -70.0, 0.0, -7.941389520941206, -10.0, -50.0, -10.0, 0.0, -0.6437238526600253, 0.0, -27.047262162196564, 0.0, -50.0, 0.0, -14.43443253364916, -70.0, -2.003965867855136, -40.59777298767946, -11.357094779451009, 0.0, -0.3785723369541871, -50.0, 0.0, -33.2153202362861, -87.77029808710724, -10.0, -60.0, -20.0, 0.0, -21.762182883285767, -2.1377351284440795, -30.0, -20.0, 0.0, 0.0, -0.12691679598827, -50.81421606945933, 0.0, -40.0, -3.2903034868319185, -0.255710586864778, -3.9988425238142824, 0.0, 0.0, -18.005906219279616, 0.0, -7.084389341144944, -60.0, 0.0, -20.0, -11.398232781851945, -12.395574448127721, -40.89598204574476, 0.0, -5.67693957391754, -0.7199662159217068, -12.937606767070637, -68.96639276164635, 0.0, -13.25831152444963, -10.0, -52.770486120938415, -13.204386876143415, -10.0, -30.0, -31.917927695022385, -16.005936243370236, -10.0, -10.0, -40.0, -10.0, -34.023338772373286, -40.45099948055795, 0.0, 0.0, -43.410837267548516, 0.0, 0.0, -10.0, -20.0, -2.5363522789834887, 0.0, -10.0, -10.0, -20.0, -5.384541386453687, -6.94181844978562, 0.0, -6.166801145659349, -20.0, -12.628176881084212, 0.0, 0.0, 0.0, -1.9198455191407449, -0.44877956540920416, -5.740287705571915, -40.0, -31.365881215534024, 0.0, -20.0, -13.334425552863713, -97.30248329089864, 0.0, -34.94766217259051, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6876652582870337, "mean_inference_ms": 1.2015516835512172, "mean_action_processing_ms": 0.2641693981302022, "mean_env_wait_ms": 0.5145553902537844, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005514165501535675, "StateBufferConnector_ms": 0.0034611902119200907, "ViewRequirementAgentConnector_ms": 0.10184159985295048}, "num_episodes": 162, "episode_return_max": 152.22970191289278, "episode_return_min": -68.96639276164635, "episode_return_mean": 20.108428915317504}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 688000, "num_agent_steps_trained": 688000, "num_env_steps_sampled": 172000, "num_env_steps_trained": 172000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 326.40660622745514, "num_env_steps_trained_throughput_per_sec": 326.40660622745514, "timesteps_total": 172000, "num_env_steps_sampled_lifetime": 172000, "num_agent_steps_sampled_lifetime": 688000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 688000, "timers": {"training_iteration_time_ms": 13351.847, "restore_workers_time_ms": 0.016, "training_step_time_ms": 13351.781, "sample_time_ms": 1336.405, "learn_time_ms": 11995.8, "learn_throughput": 333.45, "synch_weights_time_ms": 17.705}, "counters": {"num_env_steps_sampled": 172000, "num_env_steps_trained": 172000, "num_agent_steps_sampled": 688000, "num_agent_steps_trained": 688000}, "done": false, "training_iteration": 43, "trial_id": "86f16_00000", "date": "2024-08-08_16-22-47", "timestamp": 1723148567, "time_this_iter_s": 12.260167837142944, "time_total_s": 605.3691139221191, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3aca6e5e0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 605.3691139221191, "iterations_since_restore": 43, "perf": {"cpu_util_percent": 36.323529411764696, "ram_util_percent": 81.14705882352942}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7261424529531323, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.5664344200851223, "policy_loss": -0.01719276366188977, "vf_loss": 2.582326758034686, "vf_explained_var": 9.321363259714546e-07, "kl": 0.0065021345141134035, "entropy": 0.9310499247718365, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 122670.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.125522607937455, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.8689778998494146, "policy_loss": -0.02090962613389517, "vf_loss": 3.8881620404620967, "vf_explained_var": 0.024580064664284387, "kl": 0.00862743145471457, "entropy": 1.2528931406637034, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 41760.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 176000, "num_env_steps_trained": 176000, "num_agent_steps_sampled": 704000, "num_agent_steps_trained": 704000}, "env_runners": {"episode_reward_max": 240.0, "episode_reward_min": -85.43759490211828, "episode_reward_mean": 21.89414760378144, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -120.0}, "policy_reward_max": {"adversary_policy": 120.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 12.777777777777779, "agent_policy": -16.439185729551898}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 60.0, 20.0, -9.453004355248876, 0.0, -85.43759490211828, 0.0, 20.0, -2.6360914834615543, 12.335779132186579, 40.0, -0.1951952445571048, 58.56698869869311, -11.402048453573194, -4.586210049316849, 0.0, 20.0, 36.34352378257852, 60.0, -4.064890016646055, 40.0, -6.293904863523251, -0.5149516828935763, -10.53088632648229, 0.0, 60.0, 0.0, 17.95645422015024, 0.0, -0.15231882562043442, 0.0, -3.725942364260556, 57.42560822976125, 0.0, -10.107034024912085, 0.0, -12.687754290264863, 17.162868894878457, 80.0, 40.0, 0.0, 59.32706758368674, -15.670274990495745, 0.0, 60.0, 20.0, 20.0, 80.0, 0.0, -25.363639242505037, 0.0, -1.1344128852670543, 100.0, 160.0, 15.108229273534556, 0.0, 99.99123108835482, 20.0, 9.095071591835097, 40.0, -9.711595628530956, 0.0, 40.0, 30.27211867566436, 0.0, -7.021926850121918, -8.532096476690326, 0.0, 6.6900131774066764, 13.861064721851633, 0.0, 0.0, -0.6458510777839177, 0.0, 0.0, 0.0, 37.2732221746801, 19.570687342835846, -1.5293830301998157, 80.0, 20.0, 20.0, 60.0, 39.373051530384565, -0.1402653471889792, -28.42605626036269, 29.344043353715374, -14.972025186554307, 19.17724420948742, 40.0, 80.0, 0.0, 20.0, 40.0, 79.36153121614676, 20.0, -3.351628483945146, 0.0, -33.32354570277573, 0.0, -0.2510439159981326, 56.187010236535144, 20.0, 60.0, 20.0, -1.9759127449242764, 139.0451854300183, -9.62411011917918, 0.0, 0.0, 0.0, -0.17933746048101384, 20.0, 20.0, 59.3830505338048, 54.19913055729396, -2.25951311635205, 55.93738143238954, 0.0, 38.88131949007327, 60.0, -7.7372518915895645, 99.68987890023786, 39.46962977758397, -9.08882167954162, 39.774305229455834, 60.0, -2.103639099018859, 100.0, 0.0, 0.0, 57.71223121890265, 240.0, 60.0, 40.7379838671589, 80.0, 60.0, 17.850596572769348, 0.0, -0.9522268398731959, 120.0, 40.0, -1.08616059681228, 0.0, 0.0, 0.0, 0.0, 0.0, -14.032296719657797, -26.472749361141684, 0.0, 20.0, -3.9904554077355434, 80.0, 40.0, 34.68544291497679, 0.0, 52.476196225583735, 0.0, 33.95081752558231], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 80.0, 80.0, 80.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 120.0, 120.0, 120.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0], "policy_agent_policy_reward": [0.0, 0.0, 0.0, -30.0, -10.0, -9.453004355248876, 0.0, -85.43759490211828, 0.0, -10.0, -2.6360914834615543, -47.66422086781343, -20.0, -0.1951952445571048, -31.433011301306898, -11.402048453573194, -4.586210049316849, 0.0, -10.0, -23.65647621742148, -30.0, -4.064890016646055, -20.0, -6.293904863523251, -0.5149516828935763, -10.53088632648229, 0.0, -30.0, 0.0, -12.043545779849762, 0.0, -0.15231882562043442, 0.0, -3.725942364260556, -32.574391770238734, 0.0, -10.107034024912085, 0.0, -12.687754290264863, -12.837131105121543, -40.0, -20.0, 0.0, -30.672932416313262, -15.670274990495745, 0.0, -30.0, -10.0, -10.0, -40.0, 0.0, -25.363639242505037, 0.0, -1.1344128852670543, -50.0, -80.0, -44.891770726465445, 0.0, -50.008768911645184, -10.0, -20.904928408164903, -20.0, -9.711595628530956, 0.0, -20.0, -29.72788132433564, 0.0, -7.021926850121918, -8.532096476690326, 0.0, -23.309986822593324, -16.13893527814837, 0.0, 0.0, -0.6458510777839177, 0.0, 0.0, 0.0, -22.7267778253199, -10.429312657164152, -1.5293830301998157, -40.0, -10.0, -10.0, -30.0, -20.626948469615435, -0.1402653471889792, -28.42605626036269, -30.655956646284626, -14.972025186554307, -10.82275579051258, -20.0, -40.0, 0.0, -10.0, -20.0, -40.63846878385324, -10.0, -3.351628483945146, 0.0, -33.32354570277573, 0.0, -0.2510439159981326, -33.812989763464856, -10.0, -30.0, -10.0, -1.9759127449242764, -70.95481456998169, -9.62411011917918, 0.0, 0.0, 0.0, -0.17933746048101384, -10.0, -10.0, -30.616949466195205, -35.80086944270604, -2.25951311635205, -34.06261856761046, 0.0, -21.118680509926733, -30.0, -7.7372518915895645, -50.31012109976214, -20.53037022241603, -9.08882167954162, -20.225694770544166, -30.0, -2.103639099018859, -50.0, 0.0, 0.0, -32.287768781097355, -120.0, -30.0, -49.262016132841104, -40.0, -30.0, -12.14940342723065, 0.0, -0.9522268398731959, -60.0, -20.0, -1.08616059681228, 0.0, 0.0, 0.0, 0.0, 0.0, -14.032296719657797, -26.472749361141684, 0.0, -10.0, -3.9904554077355434, -40.0, -20.0, -55.31455708502321, 0.0, -37.523803774416265, 0.0, -26.049182474417705]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6868687842009362, "mean_inference_ms": 1.19977415215067, "mean_action_processing_ms": 0.2633113914469755, "mean_env_wait_ms": 0.5139486516278967, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005051530437704958, "StateBufferConnector_ms": 0.00350600407447344, "ViewRequirementAgentConnector_ms": 0.09819041063756119}, "num_episodes": 162, "episode_return_max": 240.0, "episode_return_min": -85.43759490211828, "episode_return_mean": 21.89414760378144}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 704000, "num_agent_steps_trained": 704000, "num_env_steps_sampled": 176000, "num_env_steps_trained": 176000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 256.4165869638642, "num_env_steps_trained_throughput_per_sec": 256.4165869638642, "timesteps_total": 176000, "num_env_steps_sampled_lifetime": 176000, "num_agent_steps_sampled_lifetime": 704000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 704000, "timers": {"training_iteration_time_ms": 13656.744, "restore_workers_time_ms": 0.016, "training_step_time_ms": 13656.679, "sample_time_ms": 1336.097, "learn_time_ms": 12300.181, "learn_throughput": 325.198, "synch_weights_time_ms": 19.577}, "counters": {"num_env_steps_sampled": 176000, "num_env_steps_trained": 176000, "num_agent_steps_sampled": 704000, "num_agent_steps_trained": 704000}, "done": false, "training_iteration": 44, "trial_id": "86f16_00000", "date": "2024-08-08_16-23-03", "timestamp": 1723148583, "time_this_iter_s": 15.619151830673218, "time_total_s": 620.9882657527924, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3aca6eee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 620.9882657527924, "iterations_since_restore": 44, "perf": {"cpu_util_percent": 52.01739130434783, "ram_util_percent": 82.66956521739131}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.756489531970616, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.5183917980667547, "policy_loss": -0.018052991311287125, "vf_loss": 2.5350731382555995, "vf_explained_var": -5.051599326708638e-07, "kl": 0.006858242753289414, "entropy": 0.9142543167509931, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 125490.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.0226760988434154, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.229642391453186, "policy_loss": -0.021541061300376897, "vf_loss": 4.249212533483902, "vf_explained_var": 0.04650830812752247, "kl": 0.00985455146599357, "entropy": 1.215729369223118, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 42720.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 180000, "num_env_steps_trained": 180000, "num_agent_steps_sampled": 720000, "num_agent_steps_trained": 720000}, "env_runners": {"episode_reward_max": 120.0, "episode_reward_min": -32.156448856006676, "episode_reward_mean": 19.816876705026953, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -68.90903767861946}, "policy_reward_max": {"adversary_policy": 60.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 12.098765432098766, "agent_policy": -16.47941959126934}, "custom_metrics": {}, "hist_stats": {"episode_reward": [100.0, 0.0, 38.41027543145312, -13.667259848538265, 0.0, 35.61004166869293, 0.0, -24.095286602600787, 40.0, -2.0484377795344058, 0.0, 0.0, -5.0014024802410315, 0.0, 40.0, 20.0, -1.3930185285241792, -14.00418093507289, 119.80777456720696, -0.73576796399757, 20.0, -0.5022533590363121, -2.048800577141752, 0.0, 120.0, 120.0, -8.48042359846686, 99.59059764950365, 20.0, 0.0, 14.83824047177442, -3.042426661041908, -17.926659028432105, -12.613960192864097, 0.0, 0.0, -0.031739336064979806, 8.334731556408546, -2.858155798629121, -0.5060727058983194, 0.0, -19.69938511394344, 36.51821114820846, 0.0, 0.0, 0.0, 61.38355515964567, 0.0, 27.77413131601395, 0.0, 0.0, 40.0, 0.0, -0.07709276083916472, 40.0, 0.0, 0.0, 20.0, 0.0, 0.0, 0.0, 0.0, -28.508998080051175, 0.0, -1.1286098024313207, 40.0, 37.49860340705383, -26.069962651762353, 4.697310144179028, 20.0, -14.291130908950887, -7.84055305733171, 40.0, 78.74657934691888, 24.75630060987777, -2.7579910389913014, 88.86491631169574, 60.0, 0.0, 0.0, -32.156448856006676, 20.0, 38.45342268653134, 78.10366881019931, 60.0, 60.0, 40.0, 75.41705666867517, 21.090962321380534, 19.68542145424926, 0.0, 20.0, 53.25744882444933, -6.504077163898308, 0.0, -10.771416521089854, -10.00421593370634, 80.0, 20.0, 0.0, -1.6711895852252856, 57.47834659304271, 38.76454777516604, 40.0, -0.21206089062777544, 40.0, 60.0, 0.0, -12.413364357056505, -9.258526938589542, 60.0, 120.0, 80.0, 39.22644861556067, 0.0, 19.48819190432585, 0.0, 59.86993523728321, 3.7013783205957083, 40.0, 58.51188081920152, -13.895575930709494, -17.894327756579635, 20.0, 60.0, -3.8310731624724275, 100.0, 19.81540082084502, 60.0, 40.0, 0.0, 76.00695478100272, 0.0, 80.0, -0.07823914593260262, -2.257179081496461, 46.61537308142756, 60.0, 100.0, 40.0, 20.0, 40.0, 0.0, -1.7963016887305794, 40.0, -0.36949534877103285, -11.37198264064044, -2.0089734764850196, 0.0, -18.978535524552385, 15.475464218898047, 0.0, -17.253333023691855, 21.55720859339253, 20.0, -23.408478783716117, -9.30075739564932, -11.44695773765354, 57.94077491812287, 0.0, 0.0, -0.7450492649484963], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 60.0, 60.0, 60.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 60.0, 60.0, 60.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-50.0, 0.0, -21.589724568546877, -13.667259848538265, 0.0, -24.389958331307067, 0.0, -24.095286602600787, -20.0, -2.0484377795344058, 0.0, 0.0, -5.0014024802410315, 0.0, -20.0, -10.0, -1.3930185285241792, -14.00418093507289, -60.19222543279303, -0.73576796399757, -10.0, -0.5022533590363121, -2.048800577141752, 0.0, -60.0, -60.0, -38.48042359846686, -50.40940235049636, -10.0, 0.0, -15.16175952822558, -3.042426661041908, -17.926659028432105, -12.613960192864097, 0.0, 0.0, -0.031739336064979806, -21.66526844359145, -32.85815579862912, -0.5060727058983194, 0.0, -19.69938511394344, -23.481788851791542, 0.0, 0.0, 0.0, -58.616444840354326, 0.0, -32.22586868398605, 0.0, 0.0, -20.0, 0.0, -0.07709276083916472, -20.0, 0.0, 0.0, -10.0, 0.0, 0.0, 0.0, 0.0, -28.508998080051175, 0.0, -1.1286098024313207, -20.0, -22.501396592946172, -26.069962651762353, -55.30268985582098, -10.0, -14.291130908950887, -7.84055305733171, -20.0, -41.253420653081136, -35.24369939012223, -2.7579910389913014, -61.135083688304285, -30.0, 0.0, 0.0, -32.156448856006676, -10.0, -21.54657731346866, -41.89633118980069, -30.0, -30.0, -20.0, -44.58294333132483, -68.90903767861946, -10.31457854575074, 0.0, -10.0, -36.74255117555067, -6.504077163898308, 0.0, -10.771416521089854, -10.00421593370634, -40.0, -10.0, 0.0, -1.6711895852252856, -32.52165340695729, -21.235452224833963, -20.0, -0.21206089062777544, -20.0, -30.0, 0.0, -12.413364357056505, -9.258526938589542, -30.0, -60.0, -40.0, -20.773551384439322, 0.0, -10.511808095674152, 0.0, -30.130064762716795, -26.298621679404295, -20.0, -31.488119180798478, -13.895575930709494, -17.894327756579635, -10.0, -30.0, -3.8310731624724275, -50.0, -10.18459917915498, -30.0, -20.0, 0.0, -43.993045218997274, 0.0, -40.0, -0.07823914593260262, -2.257179081496461, -43.38462691857244, -30.0, -50.0, -20.0, -10.0, -20.0, 0.0, -1.7963016887305794, -20.0, -0.36949534877103285, -11.37198264064044, -2.0089734764850196, 0.0, -18.978535524552385, -14.524535781101953, 0.0, -17.253333023691855, -38.44279140660746, -10.0, -23.408478783716117, -9.30075739564932, -11.44695773765354, -32.05922508187713, 0.0, 0.0, -0.7450492649484963]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6882706699511414, "mean_inference_ms": 1.202723278627093, "mean_action_processing_ms": 0.263115852952455, "mean_env_wait_ms": 0.5149537217297027, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0054875273763397596, "StateBufferConnector_ms": 0.0035018832595260056, "ViewRequirementAgentConnector_ms": 0.10703242855307496}, "num_episodes": 162, "episode_return_max": 120.0, "episode_return_min": -32.156448856006676, "episode_return_mean": 19.816876705026953}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 720000, "num_agent_steps_trained": 720000, "num_env_steps_sampled": 180000, "num_env_steps_trained": 180000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 306.22759654642067, "num_env_steps_trained_throughput_per_sec": 306.22759654642067, "timesteps_total": 180000, "num_env_steps_sampled_lifetime": 180000, "num_agent_steps_sampled_lifetime": 720000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 720000, "timers": {"training_iteration_time_ms": 13660.217, "restore_workers_time_ms": 0.014, "training_step_time_ms": 13660.158, "sample_time_ms": 1352.508, "learn_time_ms": 12286.418, "learn_throughput": 325.563, "synch_weights_time_ms": 20.233}, "counters": {"num_env_steps_sampled": 180000, "num_env_steps_trained": 180000, "num_agent_steps_sampled": 720000, "num_agent_steps_trained": 720000}, "done": false, "training_iteration": 45, "trial_id": "86f16_00000", "date": "2024-08-08_16-23-16", "timestamp": 1723148596, "time_this_iter_s": 13.093135833740234, "time_total_s": 634.0814015865326, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3aca60160>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 634.0814015865326, "iterations_since_restore": 45, "perf": {"cpu_util_percent": 42.6, "ram_util_percent": 82.93684210526315}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7250967491603066, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.287004760943406, "policy_loss": -0.019300816931467873, "vf_loss": 2.3048260193767276, "vf_explained_var": -2.5444631035446274e-06, "kl": 0.007397789885126686, "entropy": 0.8929672172729005, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 128310.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.2626551998158297, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.8763226360082625, "policy_loss": -0.022800589705002493, "vf_loss": 3.89674768820405, "vf_explained_var": 0.007226796137789885, "kl": 0.011877638174535953, "entropy": 1.210107733309269, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 43680.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 184000, "num_env_steps_trained": 184000, "num_agent_steps_sampled": 736000, "num_agent_steps_trained": 736000}, "env_runners": {"episode_reward_max": 140.0, "episode_reward_min": -35.123002744728524, "episode_reward_mean": 20.93936653902994, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 153, "episodes_timesteps_total": 3825, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -70.0}, "policy_reward_max": {"adversary_policy": 70.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 12.352941176470589, "agent_policy": -16.119456990381824}, "custom_metrics": {}, "hist_stats": {"episode_reward": [60.0, 80.0, 0.0, -2.6459318270076606, -0.0774339112545952, 59.85432406145321, -5.242412889486391, 38.49300747101699, -0.3093609005559661, 19.563090255152925, -8.26043501620598, 0.0, 0.0, -4.982994930632893, 0.0, 60.0, -12.68161121751599, 0.0, 60.0, -1.5593006581610636, 56.28783653013775, -9.218511433904691, -11.919524875963138, 99.20615975618651, 0.0, 53.22195365570489, -27.510170599902533, 24.305349979990552, -19.709772143692312, 80.0, 0.0, 75.14198682314733, -35.123002744728524, -11.440954559603112, 100.0, 14.569050286891823, 0.0, 77.09678050563225, 80.0, 140.0, -1.6105364932764454, 0.0, -2.581097348729286, 0.0, -8.817951774669108, 0.0, -10.039446038494642, 0.0, 42.21088392711696, 38.19918332474303, 0.0, -15.289368776694698, -0.02003325762612196, 0.0, 38.15260936553684, 0.0, 0.0, -1.1152876355827956, 80.0, 28.70816380582611, 0.0, -0.5214457127230709, 0.0, 0.0, 80.0, 0.0, 13.5240740964925, 60.0, -16.398925213305468, 0.0, 0.0, 110.39946705670067, 0.0, 118.71298664054575, 60.0, -7.2088997634651335, 100.0, 57.68020332763491, 80.0, -11.836566046783568, 0.0, -13.136659349871385, -0.044679922075078204, 67.99003934183288, 0.0, 0.0, 140.0, 0.0, 18.155568861290245, 0.0, 0.0, -0.38337078741969566, 0.0, 20.0, -2.7416680936797864, -0.6049864709920028, -4.704708217840558, 20.0, 12.568177354064213, -11.423088190453477, 49.62605429871412, 0.0, 0.0, -4.446167839142833, 0.0, 22.100821002188457, 0.0, -3.9745217287895622, -1.8815048866069173, -2.067940149621398, -1.8336784100488945, 74.27327165269249, 0.0, 80.0, 20.0, 20.0, 60.0, -2.456639373131371, -4.243048680017398, 99.60229092180609, -0.9329155810656597, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 20.0, -0.04657297615931033, -14.188638066383934, 100.0, -12.547899132893663, -4.629562117193026, 0.0, 0.0, 81.68800939303372, 30.110689617717455, 40.0, 40.0, 40.0, 39.81066747723964, -0.05337921402914225, 40.0, -2.2509656333436983, 99.1027170774285, 36.85561896256635, 15.58443349017706, 0.0, -0.09548650381123847, 37.166101656570504, -11.429434411116894, 20.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0], "policy_agent_policy_reward": [-30.0, -40.0, 0.0, -2.6459318270076606, -0.0774339112545952, -30.145675938546788, -5.242412889486391, -21.506992528983012, -0.3093609005559661, -10.436909744847075, -8.26043501620598, 0.0, 0.0, -4.982994930632893, 0.0, -30.0, -12.68161121751599, 0.0, -30.0, -1.5593006581610636, -33.71216346986224, -9.218511433904691, -11.919524875963138, -50.7938402438135, 0.0, -36.77804634429512, -27.510170599902533, -35.69465002000945, -19.709772143692312, -40.0, 0.0, -44.858013176852666, -35.123002744728524, -11.440954559603112, -50.0, -15.430949713108177, 0.0, -42.903219494367754, -40.0, -70.0, -1.6105364932764454, 0.0, -2.581097348729286, 0.0, -8.817951774669108, 0.0, -10.039446038494642, 0.0, -47.78911607288304, -21.80081667525697, 0.0, -15.289368776694698, -0.02003325762612196, 0.0, -21.847390634463167, 0.0, 0.0, -1.1152876355827956, -40.0, -31.291836194173875, 0.0, -0.5214457127230709, 0.0, 0.0, -40.0, 0.0, -16.475925903507502, -30.0, -16.398925213305468, 0.0, 0.0, -69.60053294329933, 0.0, -61.287013359454264, -30.0, -7.2088997634651335, -50.0, -32.31979667236509, -40.0, -11.836566046783568, 0.0, -13.136659349871385, -0.044679922075078204, -52.00996065816711, 0.0, 0.0, -70.0, 0.0, -11.84443113870975, 0.0, 0.0, -0.38337078741969566, 0.0, -10.0, -2.7416680936797864, -0.6049864709920028, -4.704708217840558, -10.0, -47.4318226459358, -11.423088190453477, -40.37394570128588, 0.0, 0.0, -4.446167839142833, 0.0, -67.89917899781155, 0.0, -3.9745217287895622, -1.8815048866069173, -2.067940149621398, -1.8336784100488945, -45.72672834730753, 0.0, -40.0, -10.0, -10.0, -30.0, -2.456639373131371, -4.243048680017398, -50.397709078193905, -0.9329155810656597, -10.0, -10.0, -10.0, 0.0, 0.0, 0.0, -20.0, -10.0, -0.04657297615931033, -14.188638066383934, -50.0, -12.547899132893663, -4.629562117193026, 0.0, 0.0, -68.31199060696628, -29.889310382282545, -20.0, -20.0, -20.0, -20.18933252276036, -0.05337921402914225, -20.0, -2.2509656333436983, -50.8972829225715, -23.144381037433646, -14.415566509822936, 0.0, -0.09548650381123847, -52.833898343429496, -11.429434411116894, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6874908510546666, "mean_inference_ms": 1.2010433033191137, "mean_action_processing_ms": 0.26238217539145914, "mean_env_wait_ms": 0.5142979788308923, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004514681747536254, "StateBufferConnector_ms": 0.003496961655959584, "ViewRequirementAgentConnector_ms": 0.0954832126891691}, "num_episodes": 153, "episode_return_max": 140.0, "episode_return_min": -35.123002744728524, "episode_return_mean": 20.93936653902994}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 736000, "num_agent_steps_trained": 736000, "num_env_steps_sampled": 184000, "num_env_steps_trained": 184000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 292.9190093818602, "num_env_steps_trained_throughput_per_sec": 292.9190093818602, "timesteps_total": 184000, "num_env_steps_sampled_lifetime": 184000, "num_agent_steps_sampled_lifetime": 736000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 736000, "timers": {"training_iteration_time_ms": 13756.081, "restore_workers_time_ms": 0.015, "training_step_time_ms": 13756.018, "sample_time_ms": 1340.647, "learn_time_ms": 12393.991, "learn_throughput": 322.737, "synch_weights_time_ms": 20.431}, "counters": {"num_env_steps_sampled": 184000, "num_env_steps_trained": 184000, "num_agent_steps_sampled": 736000, "num_agent_steps_trained": 736000}, "done": false, "training_iteration": 46, "trial_id": "86f16_00000", "date": "2024-08-08_16-23-30", "timestamp": 1723148610, "time_this_iter_s": 13.701353788375854, "time_total_s": 647.7827553749084, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3aca605e0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 647.7827553749084, "iterations_since_restore": 46, "perf": {"cpu_util_percent": 43.78947368421053, "ram_util_percent": 82.85789473684211}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7293059801061949, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.331231019048826, "policy_loss": -0.018051343267050355, "vf_loss": 2.347924054218522, "vf_explained_var": -8.057829336071691e-07, "kl": 0.006791543547741729, "entropy": 0.8603675712719031, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 131130.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.2618739486982427, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.745122470955054, "policy_loss": -0.019566851120180216, "vf_loss": 3.762937026719252, "vf_explained_var": 0.07236630997310083, "kl": 0.00876149055376276, "entropy": 1.2142222500095765, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 44640.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 188000, "num_env_steps_trained": 188000, "num_agent_steps_sampled": 752000, "num_agent_steps_trained": 752000}, "env_runners": {"episode_reward_max": 140.0, "episode_reward_min": -55.05386323437484, "episode_reward_mean": 17.170045151383132, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -71.99991816730592}, "policy_reward_max": {"adversary_policy": 70.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 10.432098765432098, "agent_policy": -14.126251144913166}, "custom_metrics": {}, "hist_stats": {"episode_reward": [27.21892628607025, 0.0, 20.0, 0.0, 0.0, 58.39685274210374, 20.0, -19.474500942541475, 73.91575761010189, -20.73777843433875, 0.0, 60.0, -0.21712015431908482, 0.0, -2.7167375451952216, 60.0, -55.05386323437484, -6.20738877046581, 84.52997177291924, 49.29873006838646, 20.0, 60.0, 138.00008183269406, 80.0, 0.0, -12.875261633291824, -5.093918980054597, -0.31321630084926166, 39.26982040666501, -2.4893719820215945, 0.0, 0.0, 60.0, -4.882474166521941, 0.0, 17.92088352363487, -1.6983700352994924, 59.916309191288605, 40.0, -1.1985950058048036, 60.0, 20.0, 40.0, 0.0, 20.0, 20.0, 0.0, 0.0, 20.0, 56.5080733665539, -8.525768795916077, 120.0, 17.651137109584326, -0.5032101634483577, -11.77073426573883, 1.6686141256724794, 0.0, 80.0, 60.0, 40.0, -6.101685848962952, 0.0, -2.928748406474294, 0.0, 60.0, -27.42065979028358, 58.370816912214366, -4.419359550995202, 18.599384064886138, -22.224294194642653, 75.42859454815948, 60.0, 0.0, -7.141743275548261, 40.0, 33.35773690177577, -0.8102224765499055, -1.4143932732781572, -3.914980594139645, 0.0, 0.0, -1.890756857212339, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -6.528414416663432, 0.0, 0.0, 0.0, -14.798262632023, -1.909815080601615, 40.0, -23.59510411550613, 33.32408863048104, 40.0, 60.0, -13.046326930642921, -1.9368751840629117, -1.6775463108336275, 30.37329778514947, 39.585623097518614, 33.77937978290184, -4.661429507755212, 20.0, 0.0, -0.419648532687924, 15.595798289445584, 60.0, 20.0, 80.0, 119.35558307278801, 20.0, 14.635801806728601, 0.0, 0.0, 0.0, 0.0, 35.87423416086576, 0.0, -4.166783357352803, 0.0, 0.0, 0.0, 40.0, -0.8527103592183516, 0.0, 38.97344531830436, -17.664100551734332, -0.6658860110807918, 44.12937280017936, -29.511285017635238, -1.2983513955233161, -0.8657758984027042, 0.0, 60.0, 40.0, 60.0, -0.32846066916144445, -0.35946198051527434, 0.0, -2.4537286666881797, 0.0, 0.0, -0.08639546386993491, -8.801409577796637, 140.0, 60.0, 18.91289725075962, -2.4600137613095425, 112.50013614283762, 0.0, 0.0, 40.0, -25.42030062763184, -6.051961009359816, -3.9588323402773313], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 70.0, 70.0, 70.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 60.0, 60.0, 60.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-32.78107371392976, 0.0, -10.0, 0.0, 0.0, -31.603147257896254, -10.0, -19.474500942541475, -46.08424238989811, -20.73777843433875, 0.0, -30.0, -0.21712015431908482, 0.0, -2.7167375451952216, -30.0, -55.05386323437484, -6.20738877046581, -65.47002822708077, -40.70126993161353, -10.0, -30.0, -71.99991816730592, -40.0, 0.0, -12.875261633291824, -5.093918980054597, -0.31321630084926166, -20.73017959333499, -2.4893719820215945, 0.0, 0.0, -30.0, -4.882474166521941, 0.0, -12.07911647636513, -1.6983700352994924, -30.083690808711395, -20.0, -1.1985950058048036, -30.0, -10.0, -20.0, 0.0, -10.0, -10.0, 0.0, 0.0, -10.0, -33.491926633446106, -8.525768795916077, -60.0, -12.348862890415678, -0.5032101634483577, -11.77073426573883, -28.331385874327523, 0.0, -40.0, -30.0, -20.0, -6.101685848962952, 0.0, -2.928748406474294, 0.0, -30.0, -27.42065979028358, -31.62918308778563, -4.419359550995202, -11.400615935113864, -22.224294194642653, -44.57140545184052, -30.0, 0.0, -7.141743275548261, -20.0, -26.642263098224227, -0.8102224765499055, -1.4143932732781572, -33.91498059413965, 0.0, 0.0, -1.890756857212339, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -6.528414416663432, 0.0, 0.0, 0.0, -14.798262632023, -1.909815080601615, -20.0, -53.59510411550614, -26.675911369518957, -20.0, -30.0, -13.046326930642921, -1.9368751840629117, -1.6775463108336275, -29.626702214850532, -20.414376902481386, -26.220620217098162, -4.661429507755212, -10.0, 0.0, -0.419648532687924, -14.404201710554416, -30.0, -10.0, -40.0, -60.64441692721199, -10.0, -15.364198193271402, 0.0, 0.0, 0.0, 0.0, -24.12576583913424, 0.0, -4.166783357352803, 0.0, 0.0, 0.0, -20.0, -0.8527103592183516, 0.0, -21.026554681695643, -17.664100551734332, -0.6658860110807918, -45.87062719982064, -29.511285017635238, -1.2983513955233161, -0.8657758984027042, 0.0, -30.0, -20.0, -30.0, -0.32846066916144445, -0.35946198051527434, 0.0, -2.4537286666881797, 0.0, 0.0, -0.08639546386993491, -8.801409577796637, -70.0, -30.0, -11.087102749240382, -2.4600137613095425, -67.49986385716238, 0.0, 0.0, -20.0, -25.42030062763184, -6.051961009359816, -3.9588323402773313]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6870266270935218, "mean_inference_ms": 1.1996408636103162, "mean_action_processing_ms": 0.26167614064559686, "mean_env_wait_ms": 0.5138908004351526, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00499442771629051, "StateBufferConnector_ms": 0.0037503095320713374, "ViewRequirementAgentConnector_ms": 0.09586406342777205}, "num_episodes": 162, "episode_return_max": 140.0, "episode_return_min": -55.05386323437484, "episode_return_mean": 17.170045151383132}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 752000, "num_agent_steps_trained": 752000, "num_env_steps_sampled": 188000, "num_env_steps_trained": 188000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 326.97729896217373, "num_env_steps_trained_throughput_per_sec": 326.97729896217373, "timesteps_total": 188000, "num_env_steps_sampled_lifetime": 188000, "num_agent_steps_sampled_lifetime": 752000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 752000, "timers": {"training_iteration_time_ms": 13231.543, "restore_workers_time_ms": 0.015, "training_step_time_ms": 13231.482, "sample_time_ms": 1332.411, "learn_time_ms": 11878.128, "learn_throughput": 336.753, "synch_weights_time_ms": 20.029}, "counters": {"num_env_steps_sampled": 188000, "num_env_steps_trained": 188000, "num_agent_steps_sampled": 752000, "num_agent_steps_trained": 752000}, "done": false, "training_iteration": 47, "trial_id": "86f16_00000", "date": "2024-08-08_16-23-42", "timestamp": 1723148622, "time_this_iter_s": 12.238656997680664, "time_total_s": 660.0214123725891, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3aca60820>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 660.0214123725891, "iterations_since_restore": 47, "perf": {"cpu_util_percent": 31.672222222222224, "ram_util_percent": 82.02777777777777}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7516386304975401, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.120575961364922, "policy_loss": -0.01811391108583474, "vf_loss": 2.1374298164607786, "vf_explained_var": -1.7542154230970018e-06, "kl": 0.0063002565698989255, "entropy": 0.8762777389998132, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 133950.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.1704191944251456, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.6108414750856657, "policy_loss": -0.02249439198227871, "vf_loss": 3.6314078021794556, "vf_explained_var": 0.04659719771395127, "kl": 0.009640334305422287, "entropy": 1.205946034565568, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 45600.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 192000, "num_env_steps_trained": 192000, "num_agent_steps_sampled": 768000, "num_agent_steps_trained": 768000}, "env_runners": {"episode_reward_max": 140.0, "episode_reward_min": -46.5681231782877, "episode_reward_mean": 19.570297382279314, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -92.95468045106381}, "policy_reward_max": {"adversary_policy": 70.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 11.296296296296296, "agent_policy": -14.318591506609572}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.15278450294312296, 0.0, -6.4128908231295405, -9.717496147917979, 0.0, 0.0, 40.0, 0.0, 0.0, -31.65254889800811, 60.0, 48.726021570015284, 0.0, 20.0, 0.0, 0.0, -2.934012674525319, 0.0, -0.13881787532296408, 80.0, 0.0, 100.0, 0.0, 0.0, 100.0, -1.4516620314018336, 116.94337029052642, 0.0, 0.0, -1.2108878048830718, 40.0, 18.04952416580824, -0.9623936308329473, 40.0, 80.0, 20.0, 0.0, 57.44299373676825, 20.0, 20.0, 76.05454391133165, 60.0, -18.201640124228884, -25.120402238645674, -0.9019615760063959, -13.509572811631891, 40.0, 0.0, 0.0, 72.76272435399297, 20.0, 0.0, 60.0, 0.0, 80.0, -4.078996755596383, -1.2337614184968726, 0.0, 0.0, -1.5062636742757207, -10.329811938961258, 36.45800823093751, -4.834719451375486, 0.0, 0.0, -2.2781241054151904, 0.0, 0.0, 80.0, 80.0, 20.0, 100.0, 49.19667043096341, 0.0, 140.0, -11.420252069467278, 60.0, -17.38716154299457, -3.420642037394769, 0.0, 0.0, 0.0, 18.649125847574616, 0.0, 60.0, 0.0, 59.29215278637275, 20.0, 80.0, -0.8731131661468772, 17.40278987698359, -0.4044925654139431, 40.0, -6.234111608980216, 119.20530744266674, 0.0, 0.0, 100.0, 79.07890347527557, 0.0, 0.0, -16.356037057214643, -3.109712717387625, 0.0, -0.4141614258656756, 0.0, -15.109587789615988, 20.0, -0.43855766755852343, 0.0, 0.0, -22.126372461317725, 60.0, 0.0, 0.0, 20.0, 59.70047304077718, 0.0, -8.353207755820758, 0.0, -3.3944487951843376, 0.0, 39.008497520010884, -0.25321615965267275, 80.0, 20.0, 0.0, 0.0, 0.0, 20.0, 0.0, 39.63384699251917, -7.5011128308793715, 60.0, 0.0, -13.465262571374225, 0.0, 40.0, 87.04531954893619, 80.0, 60.0, 0.0, 27.874585798110765, 0.0, 140.0, -2.0707209140538865, 0.0, 0.0, 40.0, 0.0, -14.886193328078022, 58.94015446923986, -6.254216969911246, 80.0, 0.0, -46.5681231782877, 20.0, -9.379824628514815, -7.6584491796499865, 65.4106383370352, -22.779748992233404, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 60.0, 60.0, 60.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-0.15278450294312296, 0.0, -6.4128908231295405, -9.717496147917979, 0.0, 0.0, -20.0, 0.0, 0.0, -31.65254889800811, -30.0, -41.273978429984716, 0.0, -10.0, 0.0, 0.0, -2.934012674525319, 0.0, -0.13881787532296408, -40.0, 0.0, -50.0, 0.0, 0.0, -50.0, -1.4516620314018336, -63.05662970947359, 0.0, 0.0, -1.2108878048830718, -20.0, -11.950475834191758, -0.9623936308329473, -20.0, -40.0, -10.0, 0.0, -32.55700626323175, -10.0, -10.0, -43.94545608866836, -30.0, -18.201640124228884, -25.120402238645674, -0.9019615760063959, -13.509572811631891, -20.0, 0.0, 0.0, -47.237275646007035, -10.0, 0.0, -30.0, 0.0, -40.0, -4.078996755596383, -1.2337614184968726, 0.0, 0.0, -1.5062636742757207, -10.329811938961258, -23.541991769062484, -4.834719451375486, 0.0, 0.0, -2.2781241054151904, 0.0, 0.0, -40.0, -40.0, -10.0, -50.0, -40.80332956903659, 0.0, -70.0, -11.420252069467278, -30.0, -17.38716154299457, -3.420642037394769, 0.0, 0.0, 0.0, -11.350874152425384, 0.0, -30.0, 0.0, -30.707847213627243, -10.0, -40.0, -0.8731131661468772, -12.597210123016408, -0.4044925654139431, -20.0, -6.234111608980216, -60.79469255733326, 0.0, 0.0, -50.0, -40.92109652472444, 0.0, 0.0, -16.356037057214643, -3.109712717387625, 0.0, -0.4141614258656756, 0.0, -15.109587789615988, -10.0, -0.43855766755852343, 0.0, 0.0, -22.126372461317725, -30.0, 0.0, 0.0, -10.0, -30.299526959222817, 0.0, -8.353207755820758, 0.0, -3.3944487951843376, 0.0, -20.991502479989116, -0.25321615965267275, -40.0, -10.0, 0.0, 0.0, 0.0, -10.0, 0.0, -20.366153007480833, -7.5011128308793715, -30.0, 0.0, -13.465262571374225, 0.0, -20.0, -92.95468045106381, -40.0, -30.0, 0.0, -32.12541420188925, 0.0, -70.0, -2.0707209140538865, 0.0, 0.0, -20.0, 0.0, -14.886193328078022, -31.05984553076014, -6.254216969911246, -40.0, 0.0, -46.5681231782877, -10.0, -9.379824628514815, -7.6584491796499865, -54.589361662964805, -22.779748992233404, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6878383605274117, "mean_inference_ms": 1.2014259585937077, "mean_action_processing_ms": 0.26168681582747544, "mean_env_wait_ms": 0.5145053370647087, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055402149388819565, "StateBufferConnector_ms": 0.0043895509507921, "ViewRequirementAgentConnector_ms": 0.10678782875155225}, "num_episodes": 162, "episode_return_max": 140.0, "episode_return_min": -46.5681231782877, "episode_return_mean": 19.570297382279314}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 768000, "num_agent_steps_trained": 768000, "num_env_steps_sampled": 192000, "num_env_steps_trained": 192000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 305.7352047943007, "num_env_steps_trained_throughput_per_sec": 305.7352047943007, "timesteps_total": 192000, "num_env_steps_sampled_lifetime": 192000, "num_agent_steps_sampled_lifetime": 768000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 768000, "timers": {"training_iteration_time_ms": 13249.946, "restore_workers_time_ms": 0.015, "training_step_time_ms": 13249.816, "sample_time_ms": 1342.979, "learn_time_ms": 11883.224, "learn_throughput": 336.609, "synch_weights_time_ms": 22.518}, "counters": {"num_env_steps_sampled": 192000, "num_env_steps_trained": 192000, "num_agent_steps_sampled": 768000, "num_agent_steps_trained": 768000}, "done": false, "training_iteration": 48, "trial_id": "86f16_00000", "date": "2024-08-08_16-23-55", "timestamp": 1723148635, "time_this_iter_s": 13.109069108963013, "time_total_s": 673.1304814815521, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3aca60940>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 673.1304814815521, "iterations_since_restore": 48, "perf": {"cpu_util_percent": 40.92631578947368, "ram_util_percent": 82.55263157894738}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7371054086385044, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.6371217227996664, "policy_loss": -0.016579084712698238, "vf_loss": 2.652731604652202, "vf_explained_var": -1.3321638107299806e-06, "kl": 0.0048460032417671885, "entropy": 0.8324250586912142, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 136770.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.069618225035568, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.860046363870303, "policy_loss": -0.023868177521702214, "vf_loss": 3.881738517433405, "vf_explained_var": 0.05806954701741537, "kl": 0.010880116680475402, "entropy": 1.206256277114153, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 46560.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 196000, "num_env_steps_trained": 196000, "num_agent_steps_sampled": 784000, "num_agent_steps_trained": 784000}, "env_runners": {"episode_reward_max": 180.0, "episode_reward_min": -37.60882351900976, "episode_reward_mean": 19.315156330349808, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -90.0}, "policy_reward_max": {"adversary_policy": 90.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 11.234567901234568, "agent_policy": -14.388547373353896}, "custom_metrics": {}, "hist_stats": {"episode_reward": [59.6269254341842, 59.540869626555974, 20.0, 0.0, -2.7808086707301136, 20.0, 36.40261500348703, -8.923194398046059, 0.0, 29.275598916169187, 20.0, 0.0, 60.0, 40.0, 20.0, 0.0, -0.1900692434832585, 0.0, 0.0, 0.0, 60.0, -4.430737911860087, 15.531417302456168, 20.0, 100.0, 0.0, 40.0, 0.0, 100.0, 0.0, -3.3309109006271322, 0.0, 20.0, 19.589889096804818, 20.0, 0.0, 20.0, 0.0, 0.0, -0.1115972097800133, -35.29281763392059, 0.0, 0.0, 10.503585484374035, 0.0, -11.89344859676069, 40.0, 14.159946139471984, 0.0, 17.836705875952788, 40.0, 60.0, 43.12932591501263, 0.0, 60.0, 0.0, 4.282334868317834, 20.0, 0.0, -9.123785051049515, -0.020401914954454314, -18.577290452508866, -3.7584750375453284, 35.85919470827666, 0.0, 0.0, 0.0, 60.0, -6.246035201170413, 60.0, 50.36198547615014, 0.0, 38.08361090023266, -5.802446508367541, -9.674546014296643, -13.934203410942605, 35.65736365130688, -0.03371548959404724, 0.0, 37.69947479673197, -4.257396617958355, 58.4500788942944, -0.6797213033329741, 40.0, 0.0, 0.0, 80.0, 100.0, -5.040542717444669, -25.73114216877008, 20.0, 0.0, 0.0, 0.0, 0.0, 40.0, 100.0, -6.15471064397372, -28.148306111023548, 0.0, 20.0, 0.0, 76.29521605376897, 96.30631953647034, 60.0, 31.37817350341091, -19.145975760299894, 40.0, -0.38453809133739525, -5.9210417233957315, -1.528800680297927, -3.1978187012738912, -26.26218513347907, 60.0, 20.0, 0.0, 93.36456084554733, 0.0, 60.0, -0.6446842887108306, 0.0, 80.0, 0.0, 40.0, 60.0, -1.16251224150265, 31.37476320235635, 0.0, -2.3483149292460643, 20.0, 40.0, 0.0, 20.0, 0.0, 0.0, 180.0, -18.893400218857515, 20.0, -37.60882351900976, -6.779470589776423, -1.5094355662820491, -0.27460335440679495, -3.291599568505934, 100.0, -6.521648501813507, 0.0, -10.121127822375053, 0.0, 0.0, 50.159502931637356, 80.0, 20.0, 40.0, 20.0, -1.3119423392925966, 35.230093591702065, 100.0, 20.0, 80.0, 0.0, 40.0, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 90.0, 90.0, 90.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-30.373074565815802, -30.459130373444026, -10.0, 0.0, -2.7808086707301136, -10.0, -23.59738499651297, -8.923194398046059, 0.0, -30.72440108383081, -10.0, 0.0, -30.0, -20.0, -10.0, 0.0, -0.1900692434832585, 0.0, 0.0, 0.0, -30.0, -4.430737911860087, -14.468582697543832, -10.0, -50.0, 0.0, -20.0, 0.0, -50.0, 0.0, -3.3309109006271322, 0.0, -10.0, -10.410110903195182, -10.0, 0.0, -10.0, 0.0, 0.0, -0.1115972097800133, -35.29281763392059, 0.0, 0.0, -19.496414515625965, 0.0, -11.89344859676069, -20.0, -15.840053860528018, 0.0, -12.163294124047214, -20.0, -30.0, -46.87067408498737, 0.0, -30.0, 0.0, -25.717665131682164, -10.0, 0.0, -9.123785051049515, -0.020401914954454314, -18.577290452508866, -3.7584750375453284, -24.140805291723336, 0.0, 0.0, 0.0, -30.0, -6.246035201170413, -30.0, -39.63801452384986, 0.0, -21.916389099767347, -5.802446508367541, -9.674546014296643, -43.934203410942615, -24.34263634869311, -0.03371548959404724, 0.0, -22.300525203268037, -4.257396617958355, -31.549921105705604, -0.6797213033329741, -20.0, 0.0, 0.0, -40.0, -50.0, -5.040542717444669, -25.73114216877008, -10.0, 0.0, 0.0, 0.0, 0.0, -20.0, -50.0, -6.15471064397372, -28.148306111023548, 0.0, -10.0, 0.0, -43.70478394623104, -53.69368046352965, -30.0, -28.621826496589094, -19.145975760299894, -20.0, -0.38453809133739525, -5.9210417233957315, -1.528800680297927, -3.1978187012738912, -26.26218513347907, -30.0, -10.0, 0.0, -56.63543915445267, 0.0, -30.0, -0.6446842887108306, 0.0, -40.0, 0.0, -20.0, -30.0, -1.16251224150265, -28.625236797643655, 0.0, -2.3483149292460643, -10.0, -20.0, 0.0, -10.0, 0.0, 0.0, -90.0, -18.893400218857515, -10.0, -37.60882351900976, -6.779470589776423, -1.5094355662820491, -0.27460335440679495, -3.291599568505934, -50.0, -6.521648501813507, 0.0, -10.121127822375053, 0.0, 0.0, -39.840497068362644, -40.0, -10.0, -20.0, -10.0, -1.3119423392925966, -24.769906408297935, -50.0, -10.0, -40.0, 0.0, -20.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6885302591245563, "mean_inference_ms": 1.2023510665185193, "mean_action_processing_ms": 0.2611412987245219, "mean_env_wait_ms": 0.5145951084060136, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005735659304960275, "StateBufferConnector_ms": 0.0037425094180636937, "ViewRequirementAgentConnector_ms": 0.10177294413248698}, "num_episodes": 162, "episode_return_max": 180.0, "episode_return_min": -37.60882351900976, "episode_return_mean": 19.315156330349808}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 784000, "num_agent_steps_trained": 784000, "num_env_steps_sampled": 196000, "num_env_steps_trained": 196000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 267.15301041435873, "num_env_steps_trained_throughput_per_sec": 267.15301041435873, "timesteps_total": 196000, "num_env_steps_sampled_lifetime": 196000, "num_agent_steps_sampled_lifetime": 784000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 784000, "timers": {"training_iteration_time_ms": 13453.764, "restore_workers_time_ms": 0.014, "training_step_time_ms": 13453.627, "sample_time_ms": 1340.088, "learn_time_ms": 12091.135, "learn_throughput": 330.821, "synch_weights_time_ms": 21.209}, "counters": {"num_env_steps_sampled": 196000, "num_env_steps_trained": 196000, "num_agent_steps_sampled": 784000, "num_agent_steps_trained": 784000}, "done": false, "training_iteration": 49, "trial_id": "86f16_00000", "date": "2024-08-08_16-24-11", "timestamp": 1723148651, "time_this_iter_s": 15.010932922363281, "time_total_s": 688.1414144039154, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3aca60f70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 688.1414144039154, "iterations_since_restore": 49, "perf": {"cpu_util_percent": 52.57619047619048, "ram_util_percent": 82.03809523809525}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7449546040478328, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.7299918308748423, "policy_loss": -0.018501453631820076, "vf_loss": 2.7477098105647038, "vf_explained_var": -6.763436270098315e-07, "kl": 0.007834676967308855, "entropy": 0.8313253940419948, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 139590.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.0275101934249204, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.760085322583715, "policy_loss": -0.023220437432367666, "vf_loss": 3.781372037778298, "vf_explained_var": 0.04622456897050142, "kl": 0.009668636392215527, "entropy": 1.1857491659621398, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 47520.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 200000, "num_env_steps_trained": 200000, "num_agent_steps_sampled": 800000, "num_agent_steps_trained": 800000}, "env_runners": {"episode_reward_max": 160.0, "episode_reward_min": -31.105076516076505, "episode_reward_mean": 18.274527017416915, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -80.0}, "policy_reward_max": {"adversary_policy": 80.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 10.493827160493828, "agent_policy": -13.206954464064568}, "custom_metrics": {}, "hist_stats": {"episode_reward": [60.0, -2.971118353879996, 0.0, 51.00055239584129, 80.0, -1.9455716785024946, -10.20239012233777, 56.92058130223147, 12.896123994654161, 0.0, 40.0, 20.0, 79.7958214066489, 59.85223845713473, 60.0, -15.34637266458003, -1.3703719953526383, 0.0, 40.0, 0.0, 0.0, 80.0, 40.0, 48.912354110993796, 40.0, -16.05541177131176, -3.94343830131407, 0.0, 8.171261989091938, 80.0, 20.0, -0.4420051459230179, 0.0, 0.0, 0.0, -1.6159660664256903, -3.0907973381508533, -6.3804612498950455, 18.006978579578025, 18.99576684688499, -0.3209721259525722, 0.0, -31.105076516076505, 19.960511576883935, 80.0, 60.0, 80.0, -4.945104102843357, 20.0, 0.0, -1.437522956434344, 60.0, 0.0, -2.417308519506955, -3.553933887083139, 50.83334110524997, 0.0, 40.0, 34.177507419142714, -0.7294122719882412, 80.0, 120.0, -10.663860767230487, -16.463547693533066, 64.25569997370594, -3.1862531280719644, 0.0, 60.0, -15.458508970483365, -0.4488495021168659, 20.0, 20.0, 0.0, -7.640777465629341, 40.0, 0.0, -19.982246500787195, 80.0, 15.996899677011598, 60.0, 0.0, -4.939562122610514, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, -0.09299168084453635, 0.0, -2.262820921786213, 50.134910422891096, 54.473621519325945, 0.0, -3.2869896277255215, 40.0, 40.0, 0.0, -11.4859607133074, 0.0, -28.91590137520637, 100.0, -0.397934287490066, 0.0, -0.8214680872499069, -0.054294143511935955, 0.0, 20.0, -1.0238090314231352, 0.0, 0.0, 0.0, 60.0, -3.1645367159048234, 20.0, 60.0, -0.8879523532978584, 60.0, 0.0, 19.753026851304192, 0.0, 0.0, -1.2698749214636296, -21.530546096475412, 0.0, -8.40750389681747, 160.0, 11.830776811053546, -5.036109568835941, 0.0, 0.0, 0.0, -0.7820095656619785, 60.0, 0.0, 39.387558109622354, 39.2339394577644, 0.0, 0.0, 80.0, 0.0, 80.0, 0.0, 37.34360156547612, 0.0, 40.0, 77.64632785234284, -7.82075204234282, 0.0, -0.06674816712572307, 40.0, 0.0, 20.0, 0.0, 20.0, 0.0, 0.0, -15.363569462169693, 20.0, -6.227713121926226, -1.1944783773470213, 77.6447807726414], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 80.0, 80.0, 80.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0], "policy_agent_policy_reward": [-30.0, -2.971118353879996, 0.0, -38.99944760415871, -40.0, -1.9455716785024946, -10.20239012233777, -33.07941869776853, -17.10387600534584, 0.0, -20.0, -10.0, -40.2041785933511, -30.147761542865272, -30.0, -15.34637266458003, -1.3703719953526383, 0.0, -20.0, 0.0, 0.0, -40.0, -20.0, -41.087645889006204, -20.0, -16.05541177131176, -3.94343830131407, 0.0, -21.82873801090806, -40.0, -10.0, -0.4420051459230179, 0.0, 0.0, 0.0, -1.6159660664256903, -3.0907973381508533, -6.3804612498950455, -11.993021420421973, -11.004233153115008, -0.3209721259525722, 0.0, -31.105076516076505, -10.039488423116065, -40.0, -30.0, -40.0, -4.945104102843357, -10.0, 0.0, -1.437522956434344, -30.0, 0.0, -2.417308519506955, -3.553933887083139, -39.166658894750036, 0.0, -20.0, -25.822492580857286, -0.7294122719882412, -40.0, -60.0, -10.663860767230487, -16.463547693533066, -55.744300026294056, -3.1862531280719644, 0.0, -30.0, -15.458508970483365, -0.4488495021168659, -10.0, -10.0, 0.0, -7.640777465629341, -20.0, 0.0, -19.982246500787195, -40.0, -14.003100322988402, -30.0, 0.0, -4.939562122610514, 0.0, 0.0, 0.0, 0.0, 0.0, -10.0, -0.09299168084453635, 0.0, -2.262820921786213, -39.86508957710891, -35.526378480674055, 0.0, -33.28698962772552, -20.0, -20.0, 0.0, -11.4859607133074, 0.0, -28.91590137520637, -50.0, -0.397934287490066, 0.0, -0.8214680872499069, -0.054294143511935955, 0.0, -10.0, -1.0238090314231352, 0.0, 0.0, 0.0, -30.0, -3.1645367159048234, -10.0, -30.0, -0.8879523532978584, -30.0, 0.0, -10.246973148695806, 0.0, 0.0, -1.2698749214636296, -21.530546096475412, 0.0, -8.40750389681747, -80.0, -18.169223188946457, -5.036109568835941, 0.0, 0.0, 0.0, -0.7820095656619785, -30.0, 0.0, -20.612441890377646, -20.7660605422356, 0.0, 0.0, -40.0, 0.0, -40.0, 0.0, -22.656398434523876, 0.0, -20.0, -42.353672147657164, -7.82075204234282, 0.0, -0.06674816712572307, -20.0, 0.0, -10.0, 0.0, -10.0, 0.0, 0.0, -15.363569462169693, -10.0, -6.227713121926226, -1.1944783773470213, -42.3552192273586]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.687513842396037, "mean_inference_ms": 1.200965144682239, "mean_action_processing_ms": 0.260245162848577, "mean_env_wait_ms": 0.5137868019162357, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004387711301261996, "StateBufferConnector_ms": 0.0034100479549831813, "ViewRequirementAgentConnector_ms": 0.0920712211985647}, "num_episodes": 162, "episode_return_max": 160.0, "episode_return_min": -31.105076516076505, "episode_return_mean": 18.274527017416915}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 800000, "num_agent_steps_trained": 800000, "num_env_steps_sampled": 200000, "num_env_steps_trained": 200000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 294.670136248539, "num_env_steps_trained_throughput_per_sec": 294.670136248539, "timesteps_total": 200000, "num_env_steps_sampled_lifetime": 200000, "num_agent_steps_sampled_lifetime": 800000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 800000, "timers": {"training_iteration_time_ms": 13374.133, "restore_workers_time_ms": 0.014, "training_step_time_ms": 13373.997, "sample_time_ms": 1329.902, "learn_time_ms": 12022.668, "learn_throughput": 332.705, "synch_weights_time_ms": 20.251}, "counters": {"num_env_steps_sampled": 200000, "num_env_steps_trained": 200000, "num_agent_steps_sampled": 800000, "num_agent_steps_trained": 800000}, "done": false, "training_iteration": 50, "trial_id": "86f16_00000", "date": "2024-08-08_16-24-24", "timestamp": 1723148664, "time_this_iter_s": 13.592813968658447, "time_total_s": 701.7342283725739, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3acda11f0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 701.7342283725739, "iterations_since_restore": 50, "perf": {"cpu_util_percent": 42.58, "ram_util_percent": 81.98499999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7110394015696877, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.546251590243468, "policy_loss": -0.019385725043297924, "vf_loss": 2.564836362321326, "vf_explained_var": 2.4761291260414933e-07, "kl": 0.00800948435747934, "entropy": 0.8319979417408612, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 142410.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.2672259309639533, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.088073838998874, "policy_loss": -0.021674273506505415, "vf_loss": 4.108023817340533, "vf_explained_var": 0.03701721001416445, "kl": 0.008621386866148368, "entropy": 1.1806335892528295, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 48480.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 204000, "num_env_steps_trained": 204000, "num_agent_steps_sampled": 816000, "num_agent_steps_trained": 816000}, "env_runners": {"episode_reward_max": 135.97555265082147, "episode_reward_min": -64.87237372901195, "episode_reward_mean": 17.230582449954376, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 153, "episodes_timesteps_total": 3825, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -74.02444734917853}, "policy_reward_max": {"adversary_policy": 70.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 10.588235294117647, "agent_policy": -14.534123432398564}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, -17.39285351651335, -8.856484773022645, -1.0857782431809304, 98.09925395739364, 60.0, -5.665390345142889, 59.77125514988029, 37.43345799853088, -24.606172860753446, -1.018069461731076, 60.0, 118.53812932164635, 38.49490220864628, 0.0, 40.0, 36.618195853379454, 40.0, 0.0, 19.861530460086094, -3.2416190465167216, 60.0, 0.0, 0.0, -21.35976507153222, 20.0, 20.0, 40.0, 20.0, -40.81100348205503, 0.0, -0.28387147571663496, 0.0, -12.442079176910658, 5.653513821834794, 18.514609813429807, 60.0, 0.0, -22.734244995236864, -1.6654248444830022, 120.0, 0.0, 21.037431546187072, 0.0, 100.0, 60.0, 0.0, 0.0, 0.0, 0.0, 39.04037039866259, 60.0, 20.0, 0.0, 0.0, 0.0, 59.75801786398621, 78.13375428975368, -6.125471036643511, 47.50917876645081, 59.621905262208685, -1.9823943168188773, 19.577417104297396, 40.0, 0.0, 40.0, -0.28155017178521313, -4.379932067639905, 0.0, 0.0, -18.902304569193394, 0.0, -13.161086976081414, 38.88575434092443, 0.0, -8.652581102167956, -15.947617895184898, 0.0, -19.45144448086368, 20.0, 20.0, 57.1826058533955, -4.091941508782369, 20.0, 40.0, -2.481836796723363, 0.0, 20.0, -6.16346468085467, 15.032396831370733, 0.0, 0.0, 37.201267307423244, 59.698677493908036, 0.0, 0.0, 0.0, 0.0, 119.12039658733184, 0.0, 60.0, 0.0, 1.6543838668547366, 0.0, 3.6657482265762784, 0.0, -3.7740551433798117, -3.5260431052797827, 60.0, 40.0, 135.97555265082147, 0.0, 20.0, -4.414739172302197, -4.769956577544207, 0.0, 0.0, 15.143495176419549, 60.0, 60.0, -0.33636834231229207, 39.51601104803124, 0.0, -19.052964648685457, -6.100597175915619, 0.0, 16.536991645206264, 40.0, 59.139782593484824, -8.556618853617984, 0.0, 40.0, 60.0, 40.0, -64.87237372901195, 50.173723124157405, 0.0, 0.0, 0.0, 29.514883864548406, 0.0, -12.782318693137512, -14.40637223093498, 0.0, 0.0, 57.09389569643042, 0.0, 11.778289245764972, -16.989960479502336, 55.71897575153338, 20.0, 18.55907711653919, -0.6089663469177498], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [0.0, -17.39285351651335, -8.856484773022645, -1.0857782431809304, -51.90074604260636, -30.0, -5.665390345142889, -30.228744850119718, -22.566542001469116, -24.606172860753446, -1.018069461731076, -30.0, -61.46187067835366, -21.505097791353723, 0.0, -20.0, -23.381804146620546, -20.0, 0.0, -10.138469539913904, -3.2416190465167216, -30.0, 0.0, 0.0, -21.35976507153222, -10.0, -10.0, -20.0, -10.0, -40.81100348205503, 0.0, -0.28387147571663496, 0.0, -12.442079176910658, -24.34648617816521, -41.485390186570186, -30.0, 0.0, -22.734244995236864, -1.6654248444830022, -60.0, 0.0, -38.96256845381293, 0.0, -50.0, -30.0, 0.0, 0.0, 0.0, 0.0, -20.95962960133741, -30.0, -10.0, 0.0, 0.0, 0.0, -30.241982136013792, -41.866245710246325, -6.125471036643511, -42.49082123354919, -30.378094737791308, -1.9823943168188773, -10.422582895702604, -20.0, 0.0, -20.0, -0.28155017178521313, -4.379932067639905, 0.0, 0.0, -18.902304569193394, 0.0, -13.161086976081414, -21.11424565907557, 0.0, -8.652581102167956, -15.947617895184898, 0.0, -19.45144448086368, -10.0, -10.0, -32.8173941466045, -4.091941508782369, -10.0, -20.0, -2.481836796723363, 0.0, -10.0, -6.16346468085467, -14.967603168629267, 0.0, 0.0, -22.798732692576746, -30.301322506091967, 0.0, 0.0, 0.0, 0.0, -60.87960341266816, 0.0, -30.0, 0.0, -28.345616133145263, 0.0, -26.334251773423723, 0.0, -3.7740551433798117, -3.5260431052797827, -30.0, -20.0, -74.02444734917853, 0.0, -10.0, -4.414739172302197, -4.769956577544207, 0.0, 0.0, -14.856504823580453, -30.0, -30.0, -0.33636834231229207, -20.48398895196876, 0.0, -19.052964648685457, -6.100597175915619, 0.0, -13.46300835479373, -20.0, -30.860217406515176, -8.556618853617984, 0.0, -20.0, -30.0, -20.0, -64.87237372901195, -39.826276875842595, 0.0, 0.0, 0.0, -30.485116135451598, 0.0, -12.782318693137512, -14.40637223093498, 0.0, 0.0, -32.906104303569585, 0.0, -18.221710754235026, -16.989960479502336, -34.28102424846662, -10.0, -11.44092288346081, -0.6089663469177498]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6869341032353016, "mean_inference_ms": 1.2003792463924619, "mean_action_processing_ms": 0.25960737285565116, "mean_env_wait_ms": 0.5135524172579736, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0045646249858382485, "StateBufferConnector_ms": 0.003373389150582108, "ViewRequirementAgentConnector_ms": 0.0955002759796342}, "num_episodes": 153, "episode_return_max": 135.97555265082147, "episode_return_min": -64.87237372901195, "episode_return_mean": 17.230582449954376}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 816000, "num_agent_steps_trained": 816000, "num_env_steps_sampled": 204000, "num_env_steps_trained": 204000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 336.54467211428596, "num_env_steps_trained_throughput_per_sec": 336.54467211428596, "timesteps_total": 204000, "num_env_steps_sampled_lifetime": 204000, "num_agent_steps_sampled_lifetime": 816000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 816000, "timers": {"training_iteration_time_ms": 13296.388, "restore_workers_time_ms": 0.014, "training_step_time_ms": 13296.265, "sample_time_ms": 1320.93, "learn_time_ms": 11955.173, "learn_throughput": 334.583, "synch_weights_time_ms": 19.182}, "counters": {"num_env_steps_sampled": 204000, "num_env_steps_trained": 204000, "num_agent_steps_sampled": 816000, "num_agent_steps_trained": 816000}, "done": false, "training_iteration": 51, "trial_id": "86f16_00000", "date": "2024-08-08_16-24-37", "timestamp": 1723148677, "time_this_iter_s": 11.890375852584839, "time_total_s": 713.6246042251587, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3acda10d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 713.6246042251587, "iterations_since_restore": 51, "perf": {"cpu_util_percent": 33.95, "ram_util_percent": 82.20555555555556}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6762670763206821, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.0583410915330793, "policy_loss": -0.01744882112277295, "vf_loss": 2.0750036938182004, "vf_explained_var": -3.2773254610967975e-06, "kl": 0.007862106688297723, "entropy": 0.7779831771309494, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 145230.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.261928634221355, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.7656334441155197, "policy_loss": -0.02620490460540168, "vf_loss": 3.7894344327350455, "vf_explained_var": 0.07636794131249189, "kl": 0.012019629443737172, "entropy": 1.1459330506622791, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 49440.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 208000, "num_env_steps_trained": 208000, "num_agent_steps_sampled": 832000, "num_agent_steps_trained": 832000}, "env_runners": {"episode_reward_max": 140.0, "episode_reward_min": -32.14675160839257, "episode_reward_mean": 14.412267933676082, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -76.1782362210189}, "policy_reward_max": {"adversary_policy": 70.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 9.135802469135802, "agent_policy": -12.995139473731326}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, -0.7681556665115385, 38.08513454086563, 20.0, -0.1589519460000044, -0.7371714994302603, 20.0, -14.289085320475502, 20.0, 40.0, 0.0, 0.0, 39.587137234523546, 0.0, 60.0, 9.968428069678918, 0.0, 0.0, 80.0, 0.0, -17.97141458005584, 0.0, 80.0, 40.0, 0.0, 0.0, 140.0, 40.0, 0.0, 0.0, 20.0, 40.0, 60.0, 0.0, 20.0, 0.0, 140.0, 40.0, 100.0, -23.58435558052577, -18.83462852138928, 0.0, -2.298434861059616, 39.637757309010766, 20.0, 79.4936751188075, 19.934792507631606, -7.961826441350219, 0.0, 73.27576212614628, -15.942515224084637, 20.0, -0.9760100066265354, 0.38346024233256704, 0.0, 20.0, 0.0, -2.8942213684372984, -0.6047564865230548, 0.0, -8.898510310656949, 0.0, 43.821763778981065, 20.0, 0.0, 40.0, 26.11774339960685, 0.0, -0.9659912701242335, 19.95908183502323, 40.0, 19.213190012647498, 0.0, -1.7025581294612304, 0.0, 0.0, 19.959507062399638, 0.0, 0.0, -3.7469766467238212, -15.817316952735634, 0.0, -14.300178845034727, 0.0, 0.0, 0.0, 60.0, 0.0, 0.0, -1.4081146925545163, 0.0, -11.322577427350097, 0.0, 0.0, 20.0, -25.794245520742297, 0.0, 0.0, 0.0, 0.0, 50.24087045311226, 60.0, -23.100442390436726, 93.62404230321138, 0.0, 59.183798226589005, -2.0376929542964497, 60.0, 20.0, 35.91307392096818, -11.307401963422157, 0.0, -5.913001535388314, 20.0, -18.56896425876432, -7.517077161222501, 120.0, -26.441893904623832, 53.58161227466026, 0.0, -8.097302525749852, 0.0, -0.06576232163066242, 96.64053746637312, 0.0, 0.0, 40.0, -32.14675160839257, 20.0, -0.39556631967438305, -31.0697252326805, 71.73736896446195, 80.0, 0.0, -6.109543222051255, 0.0, -21.41995414058017, -4.303818709022524, -1.249060150714526, -7.330136349710375, 49.19109078555971, -7.165776971561469, -0.41429280611591746, 20.0, 33.29711507102483, 0.0, 40.0, -5.1907144267455605, 20.0, 0.0, 0.0, -9.667398718808988, 0.0, 0.0, 0.0, -9.483135218065868, 60.0, 0.0, -1.1973589586316102, -6.888768301946722, 20.0, 20.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0], "policy_agent_policy_reward": [0.0, -0.7681556665115385, -21.91486545913437, -10.0, -0.1589519460000044, -0.7371714994302603, -10.0, -14.289085320475502, -10.0, -20.0, 0.0, 0.0, -20.412862765476458, 0.0, -30.0, -20.031571930321082, 0.0, 0.0, -40.0, 0.0, -17.97141458005584, 0.0, -40.0, -20.0, 0.0, 0.0, -70.0, -20.0, 0.0, 0.0, -10.0, -20.0, -30.0, 0.0, -10.0, 0.0, -70.0, -20.0, -50.0, -23.58435558052577, -18.83462852138928, 0.0, -2.298434861059616, -20.362242690989238, -10.0, -40.50632488119249, -10.065207492368396, -7.961826441350219, 0.0, -46.724237873853724, -15.942515224084637, -10.0, -0.9760100066265354, -29.61653975766743, 0.0, -10.0, 0.0, -2.8942213684372984, -0.6047564865230548, 0.0, -8.898510310656949, 0.0, -76.1782362210189, -10.0, 0.0, -20.0, -33.88225660039315, 0.0, -0.9659912701242335, -10.04091816497677, -20.0, -10.786809987352502, 0.0, -1.7025581294612304, 0.0, 0.0, -10.040492937600362, 0.0, 0.0, -3.7469766467238212, -15.817316952735634, 0.0, -14.300178845034727, 0.0, 0.0, 0.0, -30.0, 0.0, 0.0, -1.4081146925545163, 0.0, -11.322577427350097, 0.0, 0.0, -10.0, -25.794245520742297, 0.0, 0.0, 0.0, 0.0, -39.75912954688774, -30.0, -23.100442390436726, -56.37595769678862, 0.0, -30.816201773410988, -2.0376929542964497, -30.0, -10.0, -24.08692607903182, -11.307401963422157, 0.0, -5.913001535388314, -10.0, -18.56896425876432, -37.5170771612225, -60.0, -26.441893904623832, -36.41838772533974, 0.0, -8.097302525749852, 0.0, -0.06576232163066242, -53.359462533626875, 0.0, 0.0, -20.0, -32.14675160839257, -10.0, -0.39556631967438305, -31.0697252326805, -48.26263103553806, -40.0, 0.0, -6.109543222051255, 0.0, -21.41995414058017, -4.303818709022524, -1.249060150714526, -7.330136349710375, -40.8089092144403, -7.165776971561469, -30.414292806115917, -10.0, -26.702884928975177, 0.0, -20.0, -5.1907144267455605, -10.0, 0.0, 0.0, -9.667398718808988, 0.0, 0.0, 0.0, -9.483135218065868, -30.0, 0.0, -1.1973589586316102, -6.888768301946722, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.68583083778959, "mean_inference_ms": 1.1986268095283168, "mean_action_processing_ms": 0.25888595232954104, "mean_env_wait_ms": 0.5129013104348328, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0044754257908573855, "StateBufferConnector_ms": 0.0038777604515169875, "ViewRequirementAgentConnector_ms": 0.09571851035695017}, "num_episodes": 162, "episode_return_max": 140.0, "episode_return_min": -32.14675160839257, "episode_return_mean": 14.412267933676082}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 832000, "num_agent_steps_trained": 832000, "num_env_steps_sampled": 208000, "num_env_steps_trained": 208000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 349.0511981839002, "num_env_steps_trained_throughput_per_sec": 349.0511981839002, "timesteps_total": 208000, "num_env_steps_sampled_lifetime": 208000, "num_agent_steps_sampled_lifetime": 832000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 832000, "timers": {"training_iteration_time_ms": 13178.101, "restore_workers_time_ms": 0.015, "training_step_time_ms": 13177.978, "sample_time_ms": 1264.652, "learn_time_ms": 11893.358, "learn_throughput": 336.322, "synch_weights_time_ms": 18.888}, "counters": {"num_env_steps_sampled": 208000, "num_env_steps_trained": 208000, "num_agent_steps_sampled": 832000, "num_agent_steps_trained": 832000}, "done": false, "training_iteration": 52, "trial_id": "86f16_00000", "date": "2024-08-08_16-24-48", "timestamp": 1723148688, "time_this_iter_s": 11.488941192626953, "time_total_s": 725.1135454177856, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3aca60e50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 725.1135454177856, "iterations_since_restore": 52, "perf": {"cpu_util_percent": 32.6625, "ram_util_percent": 81.9375}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.685968099291443, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.1484535292530738, "policy_loss": -0.017119177997670407, "vf_loss": 2.164865913057158, "vf_explained_var": -1.1589721584996434e-06, "kl": 0.007067928726744221, "entropy": 0.7593334929317447, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 148050.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.1271516039967535, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.1773625018695992, "policy_loss": -0.02277162135578692, "vf_loss": 3.198001032198469, "vf_explained_var": 0.04761966944982608, "kl": 0.010665439658400055, "entropy": 1.1485047326733668, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 50400.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 212000, "num_env_steps_trained": 212000, "num_agent_steps_sampled": 848000, "num_agent_steps_trained": 848000}, "env_runners": {"episode_reward_max": 160.0, "episode_reward_min": -29.98069119813855, "episode_reward_mean": 20.951823202414705, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -89.33554176942161}, "policy_reward_max": {"adversary_policy": 80.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 11.54320987654321, "agent_policy": -13.677806427214925}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.8571512325162467, 20.0, 0.0, 0.0, 40.0, 20.0, -5.896406568223171, 0.0, 0.0, -12.747313297831127, 0.0, -11.96858241185478, 120.0, 20.0, -0.09931169677697471, 100.0, 39.01972411509157, 57.21132493345555, -0.4347628717685459, 100.0, 140.0, -3.0657205534988146, 50.14358614259412, 0.0, 0.0, 60.0, 0.0, -0.7196141749719331, -2.927889493437939, -2.5201477975874385, -8.800199326220852, 0.0, 19.024273958810873, 32.526726523237016, 0.0, -0.5239587834714532, 0.0, 0.0, -1.7482841685458106, 0.0, 20.0, 0.0, 40.0, 20.0, 0.0, 20.0, -29.98069119813855, -5.927658419718642, -0.7375353982907507, -1.0897249497289174, 0.0, 0.0, 51.80229133642111, 0.0, -22.63779495225294, 20.0, 0.0, -25.84234015638252, 16.01244157542167, 0.0, 56.65669605322423, 120.0, 60.0, 20.066261843440078, 0.0, 17.347584369150468, 0.0, 20.0, -8.29331373426784, 0.0, 0.0, -2.6901528380088333, -0.024977866495837775, -4.591645111880919, 58.363740905741665, 0.0, 0.0, 40.0, 0.0, 150.6644582305784, 120.0, 40.0, -5.604964923680881, 19.88936828653549, -10.807262437760533, 0.0, 100.0, 60.0, 19.62436627536688, 40.0, 79.76475641928883, 0.0, -1.4321290609106585, 0.0, 60.0, 59.440951700869284, 31.135738286801903, 0.0, -15.366902067237612, 0.0, 20.0, 0.0, -1.4934203340764796, 40.0, 20.0, 40.0, 40.0, 100.0, -0.8824257920826617, 0.0, 0.0, 0.0, 20.0, 40.0, 60.0, -3.591342829857676, 16.194151400082998, 19.310528780659, 55.71035295464688, 39.578162037138796, -1.206293049099909, 160.0, -4.530371358723499, -1.0066305193028924, 40.0, 0.0, 0.0, -6.314119716540477, 100.0, 0.0, 0.0, -15.162319870978846, 0.0, -0.30219951133360845, 0.0, 60.0, -1.129487723013165, 119.40510882434378, -0.7239258503242296, 0.0, 0.0, -5.608918187695561, 99.58446877645221, 60.0, 0.0, -2.981915359418606, -0.12421379318402148, -13.172955711773822, 40.0, 0.0, 60.0, 0.0, -7.193025424141672, 39.31294340156558, 40.0, 20.0, 0.0, 0.0, 20.0, -0.18976814012920173, 80.0, 19.35512032340067], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 60.0, 60.0, 60.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 80.0, 80.0, 80.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 80.0, 80.0, 80.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0], "policy_agent_policy_reward": [-0.8571512325162467, -10.0, 0.0, 0.0, -20.0, -10.0, -5.896406568223171, 0.0, 0.0, -12.747313297831127, 0.0, -11.96858241185478, -60.0, -10.0, -0.09931169677697471, -50.0, -20.980275884908437, -32.78867506654445, -0.4347628717685459, -50.0, -70.0, -3.0657205534988146, -39.856413857405876, 0.0, 0.0, -30.0, 0.0, -0.7196141749719331, -2.927889493437939, -2.5201477975874385, -8.800199326220852, 0.0, -10.975726041189125, -27.473273476762962, 0.0, -0.5239587834714532, 0.0, 0.0, -1.7482841685458106, 0.0, -10.0, 0.0, -20.0, -10.0, 0.0, -10.0, -29.98069119813855, -5.927658419718642, -0.7375353982907507, -1.0897249497289174, 0.0, 0.0, -38.19770866357889, 0.0, -22.63779495225294, -10.0, 0.0, -25.84234015638252, -13.987558424578332, 0.0, -33.34330394677578, -60.0, -30.0, -39.93373815655993, 0.0, -12.652415630849534, 0.0, -10.0, -8.29331373426784, 0.0, 0.0, -2.6901528380088333, -0.024977866495837775, -4.591645111880919, -31.636259094258335, 0.0, 0.0, -20.0, 0.0, -89.33554176942161, -60.0, -20.0, -5.604964923680881, -10.11063171346451, -10.807262437760533, 0.0, -50.0, -30.0, -10.37563372463312, -20.0, -40.23524358071118, 0.0, -1.4321290609106585, 0.0, -30.0, -30.559048299130723, -28.864261713198097, 0.0, -15.366902067237612, 0.0, -10.0, 0.0, -1.4934203340764796, -20.0, -10.0, -20.0, -20.0, -50.0, -0.8824257920826617, 0.0, 0.0, 0.0, -10.0, -20.0, -30.0, -3.591342829857676, -13.805848599917002, -10.689471219341, -34.289647045353114, -20.421837962861208, -1.206293049099909, -80.0, -4.530371358723499, -1.0066305193028924, -20.0, 0.0, 0.0, -6.314119716540477, -50.0, 0.0, 0.0, -15.162319870978846, 0.0, -0.30219951133360845, 0.0, -30.0, -1.129487723013165, -60.594891175656215, -0.7239258503242296, 0.0, 0.0, -5.608918187695561, -50.415531223547795, -30.0, 0.0, -2.981915359418606, -0.12421379318402148, -13.172955711773822, -20.0, 0.0, -30.0, 0.0, -7.193025424141672, -20.68705659843441, -20.0, -10.0, 0.0, 0.0, -10.0, -0.18976814012920173, -40.0, -10.64487967659933]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6854868395370721, "mean_inference_ms": 1.1986106429970584, "mean_action_processing_ms": 0.2584609050171981, "mean_env_wait_ms": 0.5128368149472128, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0051207748460180965, "StateBufferConnector_ms": 0.0037649531423309705, "ViewRequirementAgentConnector_ms": 0.09613868630962608}, "num_episodes": 162, "episode_return_max": 160.0, "episode_return_min": -29.98069119813855, "episode_return_mean": 20.951823202414705}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 848000, "num_agent_steps_trained": 848000, "num_env_steps_sampled": 212000, "num_env_steps_trained": 212000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 223.29466699956137, "num_env_steps_trained_throughput_per_sec": 223.29466699956137, "timesteps_total": 212000, "num_env_steps_sampled_lifetime": 212000, "num_agent_steps_sampled_lifetime": 848000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 848000, "timers": {"training_iteration_time_ms": 13743.99, "restore_workers_time_ms": 0.014, "training_step_time_ms": 13743.867, "sample_time_ms": 1264.114, "learn_time_ms": 12458.695, "learn_throughput": 321.061, "synch_weights_time_ms": 19.509}, "counters": {"num_env_steps_sampled": 212000, "num_env_steps_trained": 212000, "num_agent_steps_sampled": 848000, "num_agent_steps_trained": 848000}, "done": false, "training_iteration": 53, "trial_id": "86f16_00000", "date": "2024-08-08_16-25-07", "timestamp": 1723148707, "time_this_iter_s": 17.959465265274048, "time_total_s": 743.0730106830597, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3acda1ee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 743.0730106830597, "iterations_since_restore": 53, "perf": {"cpu_util_percent": 62.16538461538461, "ram_util_percent": 82.22307692307693}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6990350667043781, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.2259799975029964, "policy_loss": -0.017174278558496094, "vf_loss": 2.242409131078855, "vf_explained_var": -6.550170005636012e-07, "kl": 0.0074514465558649014, "entropy": 0.7463664690864847, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 150870.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.1857434066633386, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.701338737954696, "policy_loss": -0.025398333648627158, "vf_loss": 3.724477762853106, "vf_explained_var": 0.07832583151757717, "kl": 0.011296569160457182, "entropy": 1.137137327467402, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 51360.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 216000, "num_env_steps_trained": 216000, "num_agent_steps_sampled": 864000, "num_agent_steps_trained": 864000}, "env_runners": {"episode_reward_max": 140.0, "episode_reward_min": -68.50563260616869, "episode_reward_mean": 19.571086383389698, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -70.71566494604846}, "policy_reward_max": {"adversary_policy": 70.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 11.419753086419753, "agent_policy": -14.688172875869565}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-7.795149178782554, -19.00141132628895, -11.928764655602892, 0.0, 40.0, 0.0, 39.99425711827887, 18.99711343778876, 0.0, 0.0, 19.784139377073387, -13.639104980072203, 60.0, 99.35840465591295, 0.0, 40.0, 73.48725457393557, -5.654695027573834, 19.19903695702643, 0.0, 40.0, 38.98173608979765, 0.0, 80.0, 60.0, 0.0, 0.0, 69.51057261536806, -0.01924926337461552, -14.015100016850626, 0.0, 80.0, 40.0, 40.0, 0.0, -5.084868383360195, 0.0, -3.9557534426019902, -7.1785575306692975, -0.5581697834204258, -14.782505846817676, 0.0, 60.0, 57.82650675877197, -14.695945366076215, 40.0, -3.4188416356080245, -5.210625461839637, 20.0, 33.79907645208213, 60.0, 80.0, 20.0, 0.0, -1.023596695264366, -5.743232889963881, 39.999435023397865, -7.029807531957872, 0.0, 60.0, 0.0, 20.0, 51.161253242799766, 40.0, 0.0, 51.14749011631204, 40.0, 0.0, 0.0, -7.040515491822974, 80.0, 0.0, 100.0, 0.0, 59.81938226697161, 20.0, 60.0, 20.0, 0.0, -4.4484385665732935, 0.0, 42.95036087383103, 18.045454707747957, 72.10518922610811, -0.33019270804447776, 113.241456456952, 139.28433505395154, 0.0, -2.407896315997655, 40.0, -1.3112590588240902, 100.0, 30.965344947582878, 0.0, -13.002448475693551, 0.0, -0.983857433466746, -5.155731924662575, 0.0, 0.0, 0.0, 118.28638486896932, 0.0, -68.50563260616869, 0.0, 0.0, 0.0, 80.0, 60.0, 80.0, 17.21461949016464, 0.0, -8.100654994806758, 20.0, 0.0, -11.539186508846075, 0.0, 0.0, -1.9923981449287398, 0.0, -1.1956899578948177, 0.0, 40.0, 60.0, -10.31715397215747, -11.931810392030979, 0.0, 39.49243847332558, 0.0, 0.0, 0.0, 60.0, 0.0, 0.0, -12.461233283596837, 0.0, 36.08832417072832, 0.0, -7.518821261620211, 0.0, -21.56948311647097, 0.0, 7.417263648561927, 0.0, 0.0, -3.443377742176681, 60.0, -13.586215288760366, 0.0, 40.0, 60.0, -0.32706416408705974, -6.1464658258329115, 6.380063805719551, 40.0, -0.06093814878819104, 140.0, -9.909055900651532, 0.0, 20.0, 0.0, 120.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0], "policy_agent_policy_reward": [-7.795149178782554, -19.00141132628895, -11.928764655602892, 0.0, -20.0, 0.0, -20.005742881721137, -41.00288656221124, 0.0, 0.0, -10.215860622926614, -13.639104980072203, -30.0, -50.64159534408706, 0.0, -20.0, -46.51274542606443, -5.654695027573834, -10.80096304297357, 0.0, -20.0, -21.01826391020236, 0.0, -40.0, -30.0, 0.0, 0.0, -50.48942738463194, -0.01924926337461552, -14.015100016850626, 0.0, -40.0, -20.0, -20.0, 0.0, -5.084868383360195, 0.0, -3.9557534426019902, -7.1785575306692975, -0.5581697834204258, -14.782505846817676, 0.0, -30.0, -32.17349324122803, -14.695945366076215, -20.0, -3.4188416356080245, -5.210625461839637, -10.0, -26.20092354791787, -30.0, -40.0, -10.0, 0.0, -1.023596695264366, -5.743232889963881, -20.000564976602135, -7.029807531957872, 0.0, -30.0, 0.0, -10.0, -38.838746757200234, -20.0, 0.0, -38.85250988368795, -20.0, 0.0, 0.0, -7.040515491822974, -40.0, 0.0, -50.0, 0.0, -30.180617733028395, -10.0, -30.0, -10.0, 0.0, -4.4484385665732935, 0.0, -47.04963912616898, -11.954545292252043, -47.89481077389189, -0.33019270804447776, -66.758543543048, -70.71566494604846, 0.0, -2.407896315997655, -20.0, -1.3112590588240902, -50.0, -29.034655052417122, 0.0, -13.002448475693551, 0.0, -0.983857433466746, -5.155731924662575, 0.0, 0.0, 0.0, -61.71361513103069, 0.0, -68.50563260616869, 0.0, 0.0, 0.0, -40.0, -30.0, -40.0, -12.785380509835358, 0.0, -8.100654994806758, -10.0, 0.0, -41.53918650884606, 0.0, 0.0, -1.9923981449287398, 0.0, -1.1956899578948177, 0.0, -20.0, -30.0, -10.31715397215747, -11.931810392030979, 0.0, -20.507561526674422, 0.0, 0.0, 0.0, -30.0, 0.0, 0.0, -12.461233283596837, 0.0, -23.911675829271687, 0.0, -7.518821261620211, 0.0, -21.56948311647097, 0.0, -22.582736351438076, 0.0, 0.0, -3.443377742176681, -30.0, -13.586215288760366, 0.0, -20.0, -30.0, -0.32706416408705974, -6.1464658258329115, -23.619936194280452, -20.0, -0.06093814878819104, -70.0, -9.909055900651532, 0.0, -10.0, 0.0, -60.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6858545471972981, "mean_inference_ms": 1.1999999398315297, "mean_action_processing_ms": 0.2581954216197665, "mean_env_wait_ms": 0.5133243298042584, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0053169550719084566, "StateBufferConnector_ms": 0.007562799218260211, "ViewRequirementAgentConnector_ms": 0.10487297434865693}, "num_episodes": 162, "episode_return_max": 140.0, "episode_return_min": -68.50563260616869, "episode_return_mean": 19.571086383389698}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 864000, "num_agent_steps_trained": 864000, "num_env_steps_sampled": 216000, "num_env_steps_trained": 216000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 245.6835405950031, "num_env_steps_trained_throughput_per_sec": 245.6835405950031, "timesteps_total": 216000, "num_env_steps_sampled_lifetime": 216000, "num_agent_steps_sampled_lifetime": 864000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 864000, "timers": {"training_iteration_time_ms": 13812.14, "restore_workers_time_ms": 0.015, "training_step_time_ms": 13812.007, "sample_time_ms": 1277.644, "learn_time_ms": 12511.546, "learn_throughput": 319.705, "synch_weights_time_ms": 21.103}, "counters": {"num_env_steps_sampled": 216000, "num_env_steps_trained": 216000, "num_agent_steps_sampled": 864000, "num_agent_steps_trained": 864000}, "done": false, "training_iteration": 54, "trial_id": "86f16_00000", "date": "2024-08-08_16-25-23", "timestamp": 1723148723, "time_this_iter_s": 16.3328640460968, "time_total_s": 759.4058747291565, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3acdd03a0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 759.4058747291565, "iterations_since_restore": 54, "perf": {"cpu_util_percent": 59.94347826086957, "ram_util_percent": 82.71739130434784}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7228271201464301, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.2929119245380374, "policy_loss": -0.017875753624628114, "vf_loss": 2.310062056526225, "vf_explained_var": 6.18451030541819e-07, "kl": 0.007256235321492105, "entropy": 0.7763126069138236, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 153690.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.313733962054054, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.9927890277157227, "policy_loss": -0.025989210447005463, "vf_loss": 4.0167753060658775, "vf_explained_var": 0.12388619321087996, "kl": 0.010014660546241757, "entropy": 1.172661134848992, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 52320.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 220000, "num_env_steps_trained": 220000, "num_agent_steps_sampled": 880000, "num_agent_steps_trained": 880000}, "env_runners": {"episode_reward_max": 118.27311104944528, "episode_reward_min": -90.36326991186112, "episode_reward_mean": 14.653430381934506, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 157, "episodes_timesteps_total": 3925, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -90.36326991186112}, "policy_reward_max": {"adversary_policy": 60.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 9.617834394904458, "agent_policy": -14.20007280277887}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 63.310013751952944, 20.0, 0.0, 0.0, 80.0, 0.0, 59.946723818869, 20.0, -4.12610830533071, 60.0, 100.0, -0.674898167367497, -11.031052878052598, 0.0, -1.524771585053451, 0.0, 20.0, 0.0, 20.0, 4.884126396997511, 0.0, 0.0, 0.0, -2.024697262893193, -0.3383008526930642, 88.50375016775398, 57.93481774365901, 0.0, -5.615098839076479, 37.62393701870376, 20.0, 0.0, -7.4376334240423105, 0.0, 40.0, -5.770432657124999, 60.0, 0.0, 0.0, 40.0, 60.0, -27.712650873225044, -11.375719225248613, 19.6182938368714, 0.0, 0.0, -7.0416128048360775, 40.0, -18.943934417364126, 20.0, -3.648759495348793, 40.0, 11.61562287342877, -0.05041449576299706, 0.0, 60.0, 20.0, 118.27311104944528, -23.8772361937144, 37.393259008246346, -4.499458893738151, 19.99435942159996, 60.0, 20.0, -6.2508327187585975, 41.01978309542499, 0.0, 59.80647774017234, -0.9071214128822536, 15.623021568444912, -45.485880159922054, 0.0, 7.964334831777265, -17.032484682403012, 38.83113158830117, 20.0, -23.46689602705295, 33.62939251438645, 36.71406873015417, -17.5182753107168, 0.0, 17.584439675548033, 0.0, 0.0, 0.0, -8.72547805261911, 0.0, -0.8508834420430855, 20.0, -0.2322970718681172, 0.0, -0.588448550837819, -0.2613654664065612, 0.0, 0.0, 40.0, -2.2909715515660034, 60.0, 0.0, 0.0, 20.0, 0.0, 0.0, 36.54354527192584, 7.7741770412021545, -6.475274532608802, -8.963778416826443, -7.762228260803395, 0.0, 100.0, 36.162633326802464, 14.396611416586499, 20.0, 40.0, -4.513079468451897, -6.07345454871772, -1.1061635550052018, 40.0, 20.0, 60.0, 40.0, -2.9469529467240982, -1.6048677980052017, 80.0, 0.0, 40.0, 60.0, 53.90708197865092, -0.31969821940102894, -1.065642706777088, 60.0, 60.0, 56.67896754636464, 0.0, -5.845402954309067, 0.0, -36.68230499983221, 0.0, -1.4679182287704173, 0.0, 30.087760412305844, -0.1304043877879213, 79.69458273430973, -16.959962295537196, 20.0, -4.945908598226234, -4.765523206380002, -3.631904742194217, 0.0, 0.0, 40.0, -90.36326991186112, 20.0, 0.0, 20.0, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [0.0, -56.689986248047056, -10.0, 0.0, 0.0, -40.0, 0.0, -60.053276181131, -10.0, -4.12610830533071, -30.0, -50.0, -0.674898167367497, -11.031052878052598, 0.0, -1.524771585053451, 0.0, -10.0, 0.0, -10.0, -25.11587360300249, 0.0, 0.0, 0.0, -2.024697262893193, -0.3383008526930642, -61.49624983224603, -32.06518225634098, 0.0, -5.615098839076479, -22.376062981296254, -10.0, 0.0, -7.4376334240423105, 0.0, -20.0, -5.770432657124999, -30.0, 0.0, 0.0, -20.0, -30.0, -27.712650873225044, -11.375719225248613, -10.381706163128602, 0.0, 0.0, -7.0416128048360775, -20.0, -18.943934417364126, -10.0, -3.648759495348793, -20.0, -18.384377126571238, -0.05041449576299706, 0.0, -30.0, -10.0, -61.72688895055471, -23.8772361937144, -22.606740991753657, -4.499458893738151, -10.00564057840004, -30.0, -10.0, -6.2508327187585975, -48.98021690457501, 0.0, -30.193522259827652, -0.9071214128822536, -14.376978431555093, -45.485880159922054, 0.0, -52.035665168222735, -17.032484682403012, -21.16886841169883, -10.0, -23.46689602705295, -26.370607485613544, -23.285931269845836, -17.5182753107168, 0.0, -12.415560324451965, 0.0, 0.0, 0.0, -8.72547805261911, 0.0, -0.8508834420430855, -10.0, -0.2322970718681172, 0.0, -0.588448550837819, -0.2613654664065612, 0.0, 0.0, -20.0, -2.2909715515660034, -30.0, 0.0, 0.0, -10.0, 0.0, 0.0, -53.45645472807416, -22.225822958797846, -6.475274532608802, -8.963778416826443, -7.762228260803395, 0.0, -50.0, -23.83736667319754, -45.603388583413505, -10.0, -20.0, -34.5130794684519, -6.07345454871772, -1.1061635550052018, -20.0, -10.0, -30.0, -20.0, -2.9469529467240982, -1.6048677980052017, -40.0, 0.0, -20.0, -30.0, -36.09291802134908, -0.31969821940102894, -1.065642706777088, -30.0, -30.0, -33.32103245363536, 0.0, -5.845402954309067, 0.0, -36.68230499983221, 0.0, -1.4679182287704173, 0.0, -29.912239587694156, -0.1304043877879213, -40.30541726569027, -16.959962295537196, -10.0, -4.945908598226234, -4.765523206380002, -3.631904742194217, 0.0, 0.0, -20.0, -90.36326991186112, -10.0, 0.0, -10.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6855835505603632, "mean_inference_ms": 1.1995412781824013, "mean_action_processing_ms": 0.25778434625841107, "mean_env_wait_ms": 0.5130714597217682, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006128040848264269, "StateBufferConnector_ms": 0.003299212000172609, "ViewRequirementAgentConnector_ms": 0.09954712193483001}, "num_episodes": 157, "episode_return_max": 118.27311104944528, "episode_return_min": -90.36326991186112, "episode_return_mean": 14.653430381934506}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 880000, "num_agent_steps_trained": 880000, "num_env_steps_sampled": 220000, "num_env_steps_trained": 220000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 245.62702558798344, "num_env_steps_trained_throughput_per_sec": 245.62702558798344, "timesteps_total": 220000, "num_env_steps_sampled_lifetime": 220000, "num_agent_steps_sampled_lifetime": 880000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 880000, "timers": {"training_iteration_time_ms": 14134.407, "restore_workers_time_ms": 0.015, "training_step_time_ms": 14134.273, "sample_time_ms": 1249.424, "learn_time_ms": 12862.747, "learn_throughput": 310.976, "synch_weights_time_ms": 20.556}, "counters": {"num_env_steps_sampled": 220000, "num_env_steps_trained": 220000, "num_agent_steps_sampled": 880000, "num_agent_steps_trained": 880000}, "done": false, "training_iteration": 55, "trial_id": "86f16_00000", "date": "2024-08-08_16-25-40", "timestamp": 1723148740, "time_this_iter_s": 16.33006477355957, "time_total_s": 775.7359395027161, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3acdd08b0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 775.7359395027161, "iterations_since_restore": 55, "perf": {"cpu_util_percent": 57.15652173913043, "ram_util_percent": 82.22173913043478}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7165861667048001, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.250251189360382, "policy_loss": -0.017770144223802763, "vf_loss": 2.2673426418439715, "vf_explained_var": -1.0347535424198665e-06, "kl": 0.006786934295747101, "entropy": 0.7459817437415427, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 156510.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.470134672274192, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.7811026155948637, "policy_loss": -0.024483512538912084, "vf_loss": 3.80370911732316, "vf_explained_var": 0.08444155820955833, "kl": 0.00938507108239482, "entropy": 1.1519893743097782, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 53280.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 224000, "num_env_steps_trained": 224000, "num_agent_steps_sampled": 896000, "num_agent_steps_trained": 896000}, "env_runners": {"episode_reward_max": 130.2730532316744, "episode_reward_min": -39.89031928733698, "episode_reward_mean": 15.039130271838383, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 158, "episodes_timesteps_total": 3950, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -79.72694676832559}, "policy_reward_max": {"adversary_policy": 70.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 9.367088607594937, "agent_policy": -13.062135550946426}, "custom_metrics": {}, "hist_stats": {"episode_reward": [59.78488689734315, 54.64763053329678, -1.9826095254150533, 40.0, -10.935647968872736, 60.0, -10.177546953799194, -4.725945130876907, 0.0, -8.792920516672183, 18.95080866227827, 0.0, 0.0, 14.460332629769743, 20.0, 0.0, 0.0, 0.0, 40.0, 0.0, 60.0, -39.89031928733698, 20.0, 8.19701955386698, 40.0, -4.098263771032672, 0.0, 0.0, 40.0, -18.432766205994177, 20.0, 0.0, 59.42930304455315, 0.0, 93.68472304067359, -6.284434986007593, 60.0, 0.0, 79.43509354031744, 3.4923019347787854, 0.0, -2.4932375263738793, -6.757324248434257, 36.665764916397954, 0.0, 120.0, 60.0, -7.174907837685726, -14.378885019595037, 25.712652729205274, -34.939141286307745, -3.2040897761006644, 20.0, 20.0, 38.60792973034516, 5.583526954177068, 59.38225786056465, -1.3212724775355555, 0.0, 0.0, -7.8818965909564085, 0.0, 0.0, -13.820940061466779, 30.9097329896208, 58.440785901185656, -5.404994553900504, 0.0, 20.0, 0.0, 98.8986388967177, 38.85794870258101, -0.23103896261842283, 0.0, 44.005197298987824, 0.0, 40.0, 40.0, 59.583692498000026, -3.007240163766952, 0.0, 0.0, 0.0, 32.35917505092707, 58.405827655648864, 0.0, -31.318124607213306, 130.2730532316744, -2.196457216302397, -8.920420907984836, 60.0, 0.0, 40.0, 20.0, 60.0, 0.0, -21.672262140161813, 0.0, -0.9778077998566748, 7.410527685395637, -15.236406196733427, 0.0, 20.0, -16.727561824766177, -29.279717592553858, 0.0, 40.0, 0.0, 0.0, 20.0, 20.0, 0.0, -1.0191781671208089, 0.0, 16.424139813579693, 100.0, -11.045470439592687, 0.0, 0.0, 0.0, 0.0, 0.0, -1.1838730199356762, 0.0, 0.0, 0.0, 98.21913739551334, 0.0, -2.722599969924162, 33.76860637909178, -0.09870534352502847, 0.0, 0.0, 0.0, 59.50566238148238, -5.1008701095585725, 0.0, 0.0, 20.0, 80.0, 59.31519027696788, 0.0, 0.0, -1.9273971679038193, 40.0, 60.0, -0.12130921657473426, -9.18156122170281, -5.774786133400409, 0.0, 36.829195986657936, 30.890154081485925, 0.0, 0.0, -21.343664877206272, 0.0, 0.0, 15.835281500145632], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0], "policy_agent_policy_reward": [-30.215113102656847, -35.35236946670323, -1.9826095254150533, -20.0, -10.935647968872736, -30.0, -10.177546953799194, -4.725945130876907, 0.0, -8.792920516672183, -11.049191337721732, 0.0, 0.0, -15.539667370230253, -10.0, 0.0, 0.0, 0.0, -20.0, 0.0, -30.0, -39.89031928733698, -10.0, -21.80298044613302, -20.0, -4.098263771032672, 0.0, 0.0, -20.0, -18.432766205994177, -10.0, 0.0, -30.570696955446852, 0.0, -56.31527695932641, -6.284434986007593, -30.0, 0.0, -40.56490645968256, -26.50769806522122, 0.0, -2.4932375263738793, -6.757324248434257, -23.334235083602046, 0.0, -60.0, -30.0, -7.174907837685726, -14.378885019595037, -34.28734727079474, -34.939141286307745, -3.2040897761006644, -10.0, -10.0, -21.392070269654837, -24.416473045822936, -30.61774213943534, -1.3212724775355555, 0.0, 0.0, -7.8818965909564085, 0.0, 0.0, -13.820940061466779, -59.0902670103792, -31.559214098814337, -5.404994553900504, 0.0, -10.0, 0.0, -51.1013611032823, -21.142051297418984, -0.23103896261842283, 0.0, -45.994802701012176, 0.0, -20.0, -20.0, -30.416307501999974, -3.007240163766952, 0.0, 0.0, 0.0, -27.64082494907293, -31.59417234435113, 0.0, -31.318124607213306, -79.72694676832559, -2.196457216302397, -8.920420907984836, -30.0, 0.0, -20.0, -10.0, -30.0, 0.0, -21.672262140161813, 0.0, -0.9778077998566748, -22.589472314604368, -15.236406196733427, 0.0, -10.0, -16.727561824766177, -29.279717592553858, 0.0, -20.0, 0.0, 0.0, -10.0, -10.0, 0.0, -1.0191781671208089, 0.0, -13.575860186420309, -50.0, -11.045470439592687, 0.0, 0.0, 0.0, 0.0, 0.0, -1.1838730199356762, 0.0, 0.0, 0.0, -51.78086260448666, 0.0, -2.722599969924162, -26.231393620908218, -0.09870534352502847, 0.0, 0.0, 0.0, -30.49433761851762, -5.1008701095585725, 0.0, 0.0, -10.0, -40.0, -30.68480972303212, 0.0, 0.0, -1.9273971679038193, -20.0, -30.0, -0.12130921657473426, -9.18156122170281, -5.774786133400409, 0.0, -23.170804013342064, -29.109845918514075, 0.0, 0.0, -21.343664877206272, 0.0, 0.0, -14.16471849985437]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.685154145549136, "mean_inference_ms": 1.1986086423316753, "mean_action_processing_ms": 0.2574465166833587, "mean_env_wait_ms": 0.512942425709138, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004618530032000964, "StateBufferConnector_ms": 0.0032935715928862365, "ViewRequirementAgentConnector_ms": 0.09966537922243529}, "num_episodes": 158, "episode_return_max": 130.2730532316744, "episode_return_min": -39.89031928733698, "episode_return_mean": 15.039130271838383}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 896000, "num_agent_steps_trained": 896000, "num_env_steps_sampled": 224000, "num_env_steps_trained": 224000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 251.61574839049055, "num_env_steps_trained_throughput_per_sec": 251.61574839049055, "timesteps_total": 224000, "num_env_steps_sampled_lifetime": 224000, "num_agent_steps_sampled_lifetime": 896000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 896000, "timers": {"training_iteration_time_ms": 14358.567, "restore_workers_time_ms": 0.014, "training_step_time_ms": 14358.437, "sample_time_ms": 1252.154, "learn_time_ms": 13083.95, "learn_throughput": 305.718, "synch_weights_time_ms": 20.785}, "counters": {"num_env_steps_sampled": 224000, "num_env_steps_trained": 224000, "num_agent_steps_sampled": 896000, "num_agent_steps_trained": 896000}, "done": false, "training_iteration": 56, "trial_id": "86f16_00000", "date": "2024-08-08_16-25-56", "timestamp": 1723148756, "time_this_iter_s": 15.910089015960693, "time_total_s": 791.6460285186768, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3acdd0af0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 791.6460285186768, "iterations_since_restore": 56, "perf": {"cpu_util_percent": 57.7391304347826, "ram_util_percent": 82.4304347826087}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6702041120076856, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.597614702941678, "policy_loss": -0.018027344225007538, "vf_loss": 1.6149988918228353, "vf_explained_var": 8.930339880868898e-07, "kl": 0.006431558612095173, "entropy": 0.75845063880403, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 159330.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.386150480496387, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.8579330263659357, "policy_loss": -0.022178990150374982, "vf_loss": 2.8778974886983635, "vf_explained_var": 0.11371505732337633, "kl": 0.011072685519019543, "entropy": 1.161887546007832, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 54240.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 228000, "num_env_steps_trained": 228000, "num_agent_steps_sampled": 912000, "num_agent_steps_trained": 912000}, "env_runners": {"episode_reward_max": 140.0, "episode_reward_min": -46.56195992999425, "episode_reward_mean": 10.736953518056476, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -70.0}, "policy_reward_max": {"adversary_policy": 70.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 6.91358024691358, "agent_policy": -10.003787222684267}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 19.346851107770547, -1.4352166804105881, 39.699222176435235, 56.872190206842504, 40.0, 0.0, 0.0, 0.0, 0.0, -2.2574808886402655, 40.0, 0.0, 60.0, 0.0, 19.04517038608493, -25.063034126719398, -0.18556155190419532, -0.5156065932606013, 39.91292106376929, 0.0, 0.0, 0.0, -18.12904567343364, 0.0, -13.463200362750513, 0.0, -2.793551745055655, 0.0, 0.0, 0.0, 80.0, 60.0, 60.0, 0.0, 20.0, 0.0, -1.0856391983222424, 0.0, -11.414350032966738, 0.0, 0.0, -23.64060576102897, 0.0, 40.0, 0.0, 0.0, -4.573198171905561, 0.0, 40.0, -3.3466000326707324, -6.938320771792549, -0.44548523538260776, 0.0, 20.0, 0.0, -18.813938724904325, 0.0, 0.0, 0.0, 0.0, -0.3731916716296779, 0.0, 80.0, 0.0, 80.0, 76.17616635665713, -0.637307221612543, 0.0, 0.0, 0.0, 0.0, 20.0, -0.7877525275085784, 60.0, -1.2466090003399533, 0.0, 0.0, 40.0, 74.10047568367081, -25.900169058006693, 20.0, 0.0, 0.0, 17.30664928652073, 51.72945080189723, 0.0, -7.171446675948978, -1.3808742454135536, -10.237854389043644, 0.0, 20.0, 20.0, 0.0, -11.622138901526622, -14.374932054891307, -3.4333491591575798, -2.8194928619065953, 20.0, 40.0, 0.0, 60.0, 0.0, -0.7127732970586043, 16.4393062346522, -9.380690519825588, -5.230140776021799, 0.0, 0.0, 0.0, -9.144072581869956, -3.7823617046119082, 0.0, -8.08300732004687, 0.0, 40.0, 0.0, 32.940377499492584, 0.0, -2.6258232927958405, 0.0, 0.0, 140.0, 0.0, 80.0, 18.717571260037666, -46.56195992999425, 0.0, 0.0, 0.0, 0.0, 11.864213415538934, 39.84241790058102, -1.67723346314397, -28.15598420135986, 20.0, -0.6727708669643162, 0.0, 0.0, 16.63318479491677, -0.05239722543008529, 40.0, 0.0, 0.0, -2.2115780257594384, 60.0, -0.07890557699042344, 20.0, 0.0, 14.701974877223275, 19.174864672079508, 60.0, 19.087812620882012, 0.0, -0.27397094437327296, 40.0, -25.71756219288497, 119.77717753314363, -25.534342715781463, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [0.0, 0.0, 0.0, -10.653148892229451, -31.4352166804106, -20.300777823564765, -33.1278097931575, -20.0, 0.0, 0.0, 0.0, 0.0, -2.2574808886402655, -20.0, 0.0, -30.0, 0.0, -10.95482961391507, -25.063034126719398, -0.18556155190419532, -0.5156065932606013, -20.08707893623071, 0.0, 0.0, 0.0, -18.12904567343364, 0.0, -13.463200362750513, 0.0, -2.793551745055655, 0.0, 0.0, 0.0, -40.0, -30.0, -30.0, 0.0, -10.0, 0.0, -1.0856391983222424, 0.0, -11.414350032966738, 0.0, 0.0, -23.64060576102897, 0.0, -20.0, 0.0, 0.0, -4.573198171905561, 0.0, -20.0, -3.3466000326707324, -6.938320771792549, -0.44548523538260776, 0.0, -10.0, 0.0, -18.813938724904325, 0.0, 0.0, 0.0, 0.0, -0.3731916716296779, 0.0, -40.0, 0.0, -40.0, -43.823833643342894, -0.637307221612543, 0.0, 0.0, 0.0, 0.0, -10.0, -0.7877525275085784, -30.0, -1.2466090003399533, 0.0, 0.0, -20.0, -45.89952431632921, -25.900169058006693, -10.0, 0.0, 0.0, -12.693350713479273, -38.270549198102785, 0.0, -7.171446675948978, -1.3808742454135536, -10.237854389043644, 0.0, -10.0, -10.0, 0.0, -11.622138901526622, -14.374932054891307, -3.4333491591575798, -2.8194928619065953, -10.0, -20.0, 0.0, -30.0, 0.0, -0.7127732970586043, -43.5606937653478, -39.380690519825585, -5.230140776021799, 0.0, 0.0, 0.0, -9.144072581869956, -3.7823617046119082, 0.0, -8.08300732004687, 0.0, -20.0, 0.0, -27.05962250050741, 0.0, -2.6258232927958405, 0.0, 0.0, -70.0, 0.0, -40.0, -11.282428739962336, -46.56195992999425, 0.0, 0.0, 0.0, 0.0, -18.135786584461066, -20.15758209941898, -1.67723346314397, -28.15598420135986, -10.0, -0.6727708669643162, 0.0, 0.0, -13.366815205083231, -0.05239722543008529, -20.0, 0.0, 0.0, -2.2115780257594384, -30.0, -0.07890557699042344, -10.0, 0.0, -15.298025122776725, -10.825135327920488, -30.0, -10.912187379117986, 0.0, -0.27397094437327296, -20.0, -25.71756219288497, -60.22282246685636, -25.534342715781463, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6855781810293745, "mean_inference_ms": 1.1989651973828084, "mean_action_processing_ms": 0.25722877749252104, "mean_env_wait_ms": 0.5133715216187807, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0046677059597439235, "StateBufferConnector_ms": 0.003470462045551818, "ViewRequirementAgentConnector_ms": 0.09702738420462903}, "num_episodes": 162, "episode_return_max": 140.0, "episode_return_min": -46.56195992999425, "episode_return_mean": 10.736953518056476}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 912000, "num_agent_steps_trained": 912000, "num_env_steps_sampled": 228000, "num_env_steps_trained": 228000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 252.7729675229112, "num_env_steps_trained_throughput_per_sec": 252.7729675229112, "timesteps_total": 228000, "num_env_steps_sampled_lifetime": 228000, "num_agent_steps_sampled_lifetime": 912000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 912000, "timers": {"training_iteration_time_ms": 14717.689, "restore_workers_time_ms": 0.015, "training_step_time_ms": 14717.555, "sample_time_ms": 1264.256, "learn_time_ms": 13430.787, "learn_throughput": 297.823, "synch_weights_time_ms": 20.965}, "counters": {"num_env_steps_sampled": 228000, "num_env_steps_trained": 228000, "num_agent_steps_sampled": 912000, "num_agent_steps_trained": 912000}, "done": false, "training_iteration": 57, "trial_id": "86f16_00000", "date": "2024-08-08_16-26-12", "timestamp": 1723148772, "time_this_iter_s": 15.837926149368286, "time_total_s": 807.483954668045, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3acdab1f0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 807.483954668045, "iterations_since_restore": 57, "perf": {"cpu_util_percent": 54.739130434782616, "ram_util_percent": 82.50434782608694}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7051300313984249, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.8030027597085805, "policy_loss": -0.01769722663278936, "vf_loss": 1.8199892878955137, "vf_explained_var": -9.11316973097781e-07, "kl": 0.007106954036579779, "entropy": 0.7364092122789816, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 162150.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.429606782148282, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.108929069588582, "policy_loss": -0.019210299484742184, "vf_loss": 3.1261821534484624, "vf_explained_var": 0.1333669371282061, "kl": 0.009786121981386925, "entropy": 1.1408086671183506, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 55200.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 232000, "num_env_steps_trained": 232000, "num_agent_steps_sampled": 928000, "num_agent_steps_trained": 928000}, "env_runners": {"episode_reward_max": 120.0, "episode_reward_min": -56.70188342395155, "episode_reward_mean": 13.996389490890056, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -69.27435807650039}, "policy_reward_max": {"adversary_policy": 60.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 8.580246913580247, "agent_policy": -11.744351249850688}, "custom_metrics": {}, "hist_stats": {"episode_reward": [20.0, -17.888012858394884, -0.031359040076124334, 35.06422421395952, 0.0, -2.389937962254265, 0.0, 0.0, -4.96433426334759, 20.0, 0.0, -0.1934603128368495, -4.445784304317625, 0.0, 0.0, 0.0, 0.0, 59.177747785390494, -8.26191582592227, 0.0, -1.6092003164466173, 0.0, 52.52918372807157, -2.51991392554475, 91.0367823510878, -5.162497552620914, 40.0, -1.9811467927137616, 20.0, 0.0, -8.656602669661988, 0.0, -56.70188342395155, 55.56854068081999, 20.0, -1.5985846608234733, 0.0, 60.0, 0.0, -17.69220715777484, 0.0, -0.2675106309983588, 20.0, 46.271720321956025, 53.366231898934004, -0.46917456200827656, 79.57600845912535, 0.0, -3.2802812041536287, -31.859580743775783, 60.0, 40.0, 110.72564192349961, 60.0, 0.0, 0.0, 40.0, 0.0, 119.73486280367098, 0.0, 15.146643670845176, 0.0, 0.0, 99.49628209319641, 20.0, 60.0, 40.0, 20.0, -9.189176878538465, -15.40999024121477, -1.6840305252934062, 0.0, 0.0, 60.0, 0.0, -0.4683671658801425, 80.0, -6.98568231301371, 0.0, -0.6054448162565396, -2.013031798256371, 36.39063415265639, 43.56162383638696, 20.0, 0.0, -6.496677318826862, 0.0, 0.0, 0.0, 0.0, 20.0, 80.0, 54.65082853289998, 0.0, 120.0, -5.761133974656237, 0.0, 54.709452583113716, 40.0, 0.0, 40.0, -2.7393533945797497, 0.0, 36.886050970495745, 60.0, 0.0, 40.0, -0.007734161910882831, 60.0, 0.0, -0.47887420343586395, -0.21224719287248894, -14.076717015335841, -1.253722325744473, -0.8496243164720574, 0.0, 79.62052002098756, -4.82994034542449, 0.0, -0.35100402245587303, 20.0, 0.0, 36.45917172546765, 40.0, -2.1062401585428505, -2.2728858479752496, -2.7002286764398784, 0.0, 40.0, -0.22455558016834187, 0.0, 40.0, 0.0, 20.0, 0.0, 19.103503628910595, 0.0, 0.0, 60.0, -14.448078628288808, 0.0, -3.4170024011642592, -5.599720762457828, -3.234006676238673, -24.661429808584128, 0.0, -0.877735303784204, 29.79332786729993, 0.0, -7.7734768791412145, -14.486923916134849, -16.312365252351633, 0.0, 0.0, 0.0, -0.7836270495032582, 21.192197258675726, 0.0, 0.0, 0.0, 0.0, -0.3616658246954363], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 60.0, 60.0, 60.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-10.0, -17.888012858394884, -0.031359040076124334, -24.93577578604048, 0.0, -2.389937962254265, 0.0, 0.0, -4.96433426334759, -10.0, 0.0, -0.1934603128368495, -4.445784304317625, 0.0, 0.0, 0.0, 0.0, -30.8222522146095, -8.26191582592227, 0.0, -1.6092003164466173, 0.0, -37.47081627192842, -2.51991392554475, -58.96321764891219, -5.162497552620914, -20.0, -1.9811467927137616, -10.0, 0.0, -8.656602669661988, 0.0, -56.70188342395155, -34.43145931918001, -10.0, -1.5985846608234733, 0.0, -30.0, 0.0, -17.69220715777484, 0.0, -0.2675106309983588, -10.0, -43.728279678043975, -36.633768101065996, -0.46917456200827656, -40.42399154087465, 0.0, -3.2802812041536287, -31.859580743775783, -30.0, -20.0, -69.27435807650039, -30.0, 0.0, 0.0, -20.0, 0.0, -60.26513719632901, 0.0, -14.853356329154824, 0.0, 0.0, -50.503717906803594, -10.0, -30.0, -20.0, -10.0, -9.189176878538465, -15.40999024121477, -1.6840305252934062, 0.0, 0.0, -30.0, 0.0, -0.4683671658801425, -40.0, -6.98568231301371, 0.0, -0.6054448162565396, -2.013031798256371, -23.609365847343614, -46.438376163613036, -10.0, 0.0, -6.496677318826862, 0.0, 0.0, 0.0, 0.0, -10.0, -40.0, -35.349171467100014, 0.0, -60.0, -5.761133974656237, 0.0, -35.290547416886284, -20.0, 0.0, -20.0, -2.7393533945797497, 0.0, -23.113949029504255, -30.0, 0.0, -20.0, -0.007734161910882831, -30.0, 0.0, -0.47887420343586395, -0.21224719287248894, -44.076717015335845, -1.253722325744473, -0.8496243164720574, 0.0, -40.379479979012444, -4.82994034542449, 0.0, -0.35100402245587303, -10.0, 0.0, -23.54082827453233, -20.0, -2.1062401585428505, -2.2728858479752496, -2.7002286764398784, 0.0, -20.0, -0.22455558016834187, 0.0, -20.0, 0.0, -10.0, 0.0, -10.896496371089405, 0.0, 0.0, -30.0, -14.448078628288808, 0.0, -3.4170024011642592, -5.599720762457828, -33.23400667623867, -24.661429808584128, 0.0, -0.877735303784204, -30.20667213270007, 0.0, -7.7734768791412145, -14.486923916134849, -16.312365252351633, 0.0, 0.0, 0.0, -0.7836270495032582, -38.807802741324274, 0.0, 0.0, 0.0, 0.0, -0.3616658246954363]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6850190606617469, "mean_inference_ms": 1.1981866485680317, "mean_action_processing_ms": 0.2567453609888284, "mean_env_wait_ms": 0.5130415134032289, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005599083723845305, "StateBufferConnector_ms": 0.003246466318766276, "ViewRequirementAgentConnector_ms": 0.09593632486131456}, "num_episodes": 162, "episode_return_max": 120.0, "episode_return_min": -56.70188342395155, "episode_return_mean": 13.996389490890056}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 928000, "num_agent_steps_trained": 928000, "num_env_steps_sampled": 232000, "num_env_steps_trained": 232000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 241.96963429076183, "num_env_steps_trained_throughput_per_sec": 241.96963429076183, "timesteps_total": 232000, "num_env_steps_sampled_lifetime": 232000, "num_agent_steps_sampled_lifetime": 928000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 928000, "timers": {"training_iteration_time_ms": 15062.467, "restore_workers_time_ms": 0.015, "training_step_time_ms": 15062.401, "sample_time_ms": 1253.042, "learn_time_ms": 13783.631, "learn_throughput": 290.199, "synch_weights_time_ms": 24.226}, "counters": {"num_env_steps_sampled": 232000, "num_env_steps_trained": 232000, "num_agent_steps_sampled": 928000, "num_agent_steps_trained": 928000}, "done": false, "training_iteration": 58, "trial_id": "86f16_00000", "date": "2024-08-08_16-26-29", "timestamp": 1723148789, "time_this_iter_s": 16.59035015106201, "time_total_s": 824.074304819107, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3aca2aa60>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 824.074304819107, "iterations_since_restore": 58, "perf": {"cpu_util_percent": 58.57826086956521, "ram_util_percent": 82.9391304347826}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6925627831660264, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.9459789744717009, "policy_loss": -0.019979412151551773, "vf_loss": 1.9651761967662378, "vf_explained_var": -1.0244178433790275e-06, "kl": 0.00782190474020301, "entropy": 0.7211543292863994, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 164970.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.436220864454905, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.284378043934703, "policy_loss": -0.022188804528559557, "vf_loss": 3.304688037186861, "vf_explained_var": 0.10607960882286231, "kl": 0.009394036668344086, "entropy": 1.157957316438357, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 56160.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 236000, "num_env_steps_trained": 236000, "num_agent_steps_sampled": 944000, "num_agent_steps_trained": 944000}, "env_runners": {"episode_reward_max": 113.64149455246715, "episode_reward_min": -46.0757414341186, "episode_reward_mean": 12.661347128844612, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 157, "episodes_timesteps_total": 3925, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -66.35850544753283}, "policy_reward_max": {"adversary_policy": 60.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 7.898089171974522, "agent_policy": -11.032920387078951}, "custom_metrics": {}, "hist_stats": {"episode_reward": [37.241384863289134, 0.0, 36.17176819982173, -5.33940406810433, 0.0, 0.0, 80.0, 0.0, 40.0, 0.0, 0.0, 19.24778762416023, 0.0, 40.0, 40.0, -8.318635067199747, -3.487373508634204, -1.9349824541143756, -4.373370817742934, -2.7147577196902386, 44.913681200252725, -0.04345121187365075, 0.0, 0.0, 20.0, 0.0, 0.0, -1.0088735162560236, -0.33003513440281407, 36.424031660569, 39.74222413226099, 35.45851757846903, 20.897829790493013, -0.872703227914603, 0.0, 39.66747954830731, 0.0, 0.0, 0.0, 0.0, 0.0, -0.903848824069271, 40.0, 40.0, -2.9016405723444527, -2.6392222823983644, 59.10944711247244, -1.8579856884410872, -0.5762330596733367, 40.0, 0.0, 0.0, 0.0, 60.0, 0.0, 20.0, 0.0, 58.83954208262537, 0.0, 0.0, -0.43442519286272296, 0.0, 0.0, 38.87563488503624, 0.0, -15.240083387760926, 40.0, -6.852690823243937, 40.0, 40.0, 79.69055384102019, 0.0, -7.8455925384540555, 39.83532387066048, 59.83979547771887, 0.0, 12.647115396402953, 37.71302253806793, 40.0, 0.0, 0.0, 60.0, 20.0, 0.0, -12.491986197871945, 0.0, 0.0, 0.45365987773377037, 0.0, -0.1578207134091003, 0.0, 0.0, -12.757795706818962, -12.333785648007378, -3.649412670653061, -23.87983398398667, 60.0, 40.0, 0.0, 40.0, 40.0, -2.885825525611229, 19.210769742683034, 40.0, -10.638296242000424, 17.211996198955184, -5.052873344544862, 113.64149455246715, -1.041131475290411, 100.0, 0.0, -6.929588984226051, 0.0, 0.0, 0.0, 20.0, -4.887019851509301, 20.0, 40.0, 0.0, -0.568904446421935, -46.0757414341186, 0.0, -35.22189432454532, 16.639191824150632, 0.0, -10.622884059916458, 0.0, 20.0, 0.0, 60.0, -2.6282463434875902, 0.0, 20.0, 0.0, 0.0, 40.0, 40.0, -31.13303710878801, 0.0, 60.0, 20.0, 0.0, -7.982230599900243, 20.0, -7.96000023688893, -22.249402505948655, 40.0, -0.43786044738738705, -13.19498006202701, 37.64547619898087, 0.0, -1.283861718965098, 59.945405158627636, 0.0, -0.338626384500309, -9.153285014615788], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-22.758615136710866, 0.0, -23.82823180017828, -5.33940406810433, 0.0, 0.0, -40.0, 0.0, -20.0, 0.0, 0.0, -10.752212375839768, 0.0, -20.0, -20.0, -8.318635067199747, -3.487373508634204, -1.9349824541143756, -4.373370817742934, -2.7147577196902386, -45.08631879974727, -0.04345121187365075, 0.0, 0.0, -10.0, 0.0, 0.0, -1.0088735162560236, -0.33003513440281407, -23.575968339431, -20.257775867739007, -24.541482421530965, -39.10217020950698, -0.872703227914603, 0.0, -20.33252045169268, 0.0, 0.0, 0.0, 0.0, 0.0, -0.903848824069271, -20.0, -20.0, -2.9016405723444527, -2.6392222823983644, -30.890552887527566, -1.8579856884410872, -0.5762330596733367, -20.0, 0.0, 0.0, 0.0, -30.0, 0.0, -10.0, 0.0, -31.160457917374632, 0.0, 0.0, -0.43442519286272296, 0.0, 0.0, -21.12436511496376, 0.0, -15.240083387760926, -20.0, -6.852690823243937, -20.0, -20.0, -40.30944615897981, 0.0, -7.8455925384540555, -20.16467612933952, -30.16020452228113, 0.0, -17.352884603597047, -22.286977461932064, -20.0, 0.0, 0.0, -30.0, -10.0, 0.0, -12.491986197871945, 0.0, 0.0, -29.54634012226623, 0.0, -0.1578207134091003, 0.0, 0.0, -42.75779570681896, -12.333785648007378, -3.649412670653061, -23.87983398398667, -30.0, -20.0, 0.0, -20.0, -20.0, -2.885825525611229, -10.789230257316966, -20.0, -10.638296242000424, -12.788003801044818, -5.052873344544862, -66.35850544753283, -1.041131475290411, -50.0, 0.0, -6.929588984226051, 0.0, 0.0, 0.0, -10.0, -4.887019851509301, -10.0, -20.0, 0.0, -0.568904446421935, -46.0757414341186, 0.0, -35.22189432454532, -13.360808175849368, 0.0, -40.62288405991646, 0.0, -10.0, 0.0, -30.0, -2.6282463434875902, 0.0, -10.0, 0.0, 0.0, -20.0, -20.0, -31.13303710878801, 0.0, -30.0, -10.0, 0.0, -7.982230599900243, -10.0, -7.96000023688893, -22.249402505948655, -20.0, -0.43786044738738705, -13.19498006202701, -22.354523801019123, 0.0, -1.283861718965098, -30.05459484137236, 0.0, -0.338626384500309, -9.153285014615788]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6862270280121375, "mean_inference_ms": 1.2011518076450949, "mean_action_processing_ms": 0.25687030268995575, "mean_env_wait_ms": 0.5136672878053903, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0049227362225769435, "StateBufferConnector_ms": 0.004240889458139991, "ViewRequirementAgentConnector_ms": 0.10609186379013548}, "num_episodes": 157, "episode_return_max": 113.64149455246715, "episode_return_min": -46.0757414341186, "episode_return_mean": 12.661347128844612}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 944000, "num_agent_steps_trained": 944000, "num_env_steps_sampled": 236000, "num_env_steps_trained": 236000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 209.0160309257518, "num_env_steps_trained_throughput_per_sec": 209.0160309257518, "timesteps_total": 236000, "num_env_steps_sampled_lifetime": 236000, "num_agent_steps_sampled_lifetime": 944000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 944000, "timers": {"training_iteration_time_ms": 15478.951, "restore_workers_time_ms": 0.015, "training_step_time_ms": 15478.866, "sample_time_ms": 1266.294, "learn_time_ms": 14185.846, "learn_throughput": 281.971, "synch_weights_time_ms": 24.367}, "counters": {"num_env_steps_sampled": 236000, "num_env_steps_trained": 236000, "num_agent_steps_sampled": 944000, "num_agent_steps_trained": 944000}, "done": false, "training_iteration": 59, "trial_id": "86f16_00000", "date": "2024-08-08_16-26-48", "timestamp": 1723148808, "time_this_iter_s": 19.178529977798462, "time_total_s": 843.2528347969055, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3acdabaf0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 843.2528347969055, "iterations_since_restore": 59, "perf": {"cpu_util_percent": 65.16428571428571, "ram_util_percent": 82.92857142857143}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7267725691199303, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.435719402969306, "policy_loss": -0.02058304647824451, "vf_loss": 2.455562942966502, "vf_explained_var": 6.093412426346583e-07, "kl": 0.007395097269700144, "entropy": 0.695410347661228, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 167790.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.279978120823701, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.67555645853281, "policy_loss": -0.021624567802549184, "vf_loss": 3.6953748161594073, "vf_explained_var": 0.08414667366693417, "kl": 0.009031094019354372, "entropy": 1.1395200829952956, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 57120.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 240000, "num_env_steps_trained": 240000, "num_agent_steps_sampled": 960000, "num_agent_steps_trained": 960000}, "env_runners": {"episode_reward_max": 139.8261332842195, "episode_reward_min": -39.49990026751302, "episode_reward_mean": 20.20529310021854, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -70.17386671578049}, "policy_reward_max": {"adversary_policy": 70.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 11.728395061728396, "agent_policy": -14.979892084966645}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-23.98298697684132, 40.0, 0.0, 40.0, 40.0, -2.5903933708061224, 65.49336660379171, -2.3540049365670623, 0.0, 0.0, 60.0, 30.1521052790716, 0.0, -17.163371907631387, 39.805443243189785, -17.232771291329502, 18.63627641957545, 19.869496864708797, 60.0, 0.0, -1.6467522064454732, 66.30167600785906, 60.0, 37.57906076104226, 37.02152919288195, 0.0, 0.0, -0.404559175793876, -5.74467651134184, 0.0, 0.0, 20.0, 56.30904243471223, 26.70361619783824, 60.0, 0.0, 20.0, 60.0, -0.523451307337881, 40.0, -5.99164179365851, 0.0, -1.8793706384406428, -0.1986117364022355, 60.0, -22.87133281731771, -1.115249453690459, 60.0, 19.531533526810502, 11.68132019208263, 0.0, -1.8384204451849406, 60.0, 0.0, -1.492306974294293, 20.0, 100.0, -1.2328224443773805, 0.0, 0.0, -5.365798050309914, 64.00171226595816, -27.38400532133963, -6.927306963686393, 0.0, -0.8161342429638574, 78.03954510011806, 20.0, 40.0, 100.0, -2.981252635028727, 40.0, 0.0, -0.47246433872251026, 26.02876753179555, -1.9355301606105646, -3.835704475548776, 20.0, 60.0, 60.0, -0.6438436655227853, -0.2881258690220434, 0.0, 0.0, 0.0, 20.0, -3.0408053501083376, 18.315332409772886, 80.0, -0.21716091595885945, 12.840352565790866, 0.0, 0.0, 40.0, 0.0, -2.4361171306934137, 0.0, 67.24240529702176, -6.442672606590854, 20.0, 19.856812570542175, 20.0, 40.0, 0.0, 79.45598612240998, 20.0, -8.328757470599829, 80.0, -0.26199997628914673, 58.024092427387586, -7.8812167786292155, -1.6774302760253434, 0.0, -2.187116606450515, 0.0, 60.0, 0.0, 51.98476838145837, 20.0, -2.3027663130167286, 0.0, 119.9582163856897, -10.676286050812138, 139.8261332842195, 0.0, 0.0, 100.0, 0.0, 0.0, -2.991984516412329, 0.0, 0.0, -0.10199929877322322, -17.140327822437275, -0.4006390994730791, -3.5612679989712115, 60.0, 60.0, 0.0, 30.669118292961443, 19.7049882832802, 0.0, 60.0, 96.61537815706583, -0.5031469851147152, 0.0, 0.0, -12.748567587625342, 20.0, 20.0, 80.0, 80.0, -0.8895499307926125, -39.49990026751302, -3.0211459896705106, 114.56687445867722, 28.84977045302166, 3.4165102068417603, 80.0, 0.0, 0.0, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-23.98298697684132, -20.0, 0.0, -20.0, -20.0, -2.5903933708061224, -54.5066333962083, -2.3540049365670623, 0.0, 0.0, -30.0, -29.847894720928398, 0.0, -17.163371907631387, -20.194556756810215, -17.232771291329502, -11.363723580424551, -10.130503135291203, -30.0, 0.0, -1.6467522064454732, -53.69832399214094, -30.0, -22.420939238957747, -22.978470807118057, 0.0, 0.0, -0.404559175793876, -5.74467651134184, 0.0, 0.0, -10.0, -33.69095756528777, -33.29638380216176, -30.0, 0.0, -10.0, -30.0, -0.523451307337881, -20.0, -5.99164179365851, 0.0, -1.8793706384406428, -0.1986117364022355, -30.0, -22.87133281731771, -1.115249453690459, -30.0, -10.468466473189498, -48.31867980791737, 0.0, -1.8384204451849406, -30.0, 0.0, -1.492306974294293, -10.0, -50.0, -1.2328224443773805, 0.0, 0.0, -5.365798050309914, -55.99828773404183, -27.38400532133963, -6.927306963686393, 0.0, -0.8161342429638574, -41.960454899881945, -10.0, -20.0, -50.0, -2.981252635028727, -20.0, 0.0, -0.47246433872251026, -33.97123246820445, -1.9355301606105646, -3.835704475548776, -10.0, -30.0, -30.0, -0.6438436655227853, -0.2881258690220434, 0.0, 0.0, 0.0, -10.0, -3.0408053501083376, -11.684667590227114, -40.0, -0.21716091595885945, -17.15964743420913, 0.0, 0.0, -20.0, 0.0, -2.4361171306934137, 0.0, -52.757594702978245, -6.442672606590854, -10.0, -10.143187429457823, -10.0, -20.0, 0.0, -40.54401387759002, -10.0, -8.328757470599829, -40.0, -30.261999976289147, -31.97590757261241, -7.8812167786292155, -1.6774302760253434, 0.0, -2.187116606450515, 0.0, -30.0, 0.0, -38.01523161854163, -10.0, -2.3027663130167286, 0.0, -60.041783614310305, -10.676286050812138, -70.17386671578049, 0.0, 0.0, -50.0, 0.0, 0.0, -2.991984516412329, 0.0, 0.0, -0.10199929877322322, -17.140327822437275, -0.4006390994730791, -3.5612679989712115, -30.0, -30.0, 0.0, -59.33088170703856, -10.2950117167198, 0.0, -30.0, -53.384621842934166, -0.5031469851147152, 0.0, 0.0, -12.748567587625342, -10.0, -10.0, -40.0, -40.0, -0.8895499307926125, -39.49990026751302, -3.0211459896705106, -65.43312554132278, -31.150229546978345, -26.58348979315824, -40.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6862774514085698, "mean_inference_ms": 1.2017747455585899, "mean_action_processing_ms": 0.25669725420638034, "mean_env_wait_ms": 0.5138201823903605, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004679258958792981, "StateBufferConnector_ms": 0.0034088705792839143, "ViewRequirementAgentConnector_ms": 0.09947897475442768}, "num_episodes": 162, "episode_return_max": 139.8261332842195, "episode_return_min": -39.49990026751302, "episode_return_mean": 20.20529310021854}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 960000, "num_agent_steps_trained": 960000, "num_env_steps_sampled": 240000, "num_env_steps_trained": 240000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 265.6111972652515, "num_env_steps_trained_throughput_per_sec": 265.6111972652515, "timesteps_total": 240000, "num_env_steps_sampled_lifetime": 240000, "num_agent_steps_sampled_lifetime": 960000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 960000, "timers": {"training_iteration_time_ms": 15627.464, "restore_workers_time_ms": 0.017, "training_step_time_ms": 15627.37, "sample_time_ms": 1285.193, "learn_time_ms": 14315.651, "learn_throughput": 279.414, "synch_weights_time_ms": 24.177}, "counters": {"num_env_steps_sampled": 240000, "num_env_steps_trained": 240000, "num_agent_steps_sampled": 960000, "num_agent_steps_trained": 960000}, "done": false, "training_iteration": 60, "trial_id": "86f16_00000", "date": "2024-08-08_16-27-03", "timestamp": 1723148823, "time_this_iter_s": 15.098834991455078, "time_total_s": 858.3516697883606, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3acdabee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 858.3516697883606, "iterations_since_restore": 60, "perf": {"cpu_util_percent": 53.79523809523808, "ram_util_percent": 83.04761904761905}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6953691459610952, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.0089986411814995, "policy_loss": -0.016634243611305794, "vf_loss": 2.0249519799195284, "vf_explained_var": 4.049734020909519e-08, "kl": 0.006809084907922967, "entropy": 0.696894623222926, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 170610.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.4789688856651386, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.3673190383861464, "policy_loss": -0.02070922126925628, "vf_loss": 3.386579040189584, "vf_explained_var": 0.08279100482662519, "kl": 0.007246095378457796, "entropy": 1.1272794242948294, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 58080.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 244000, "num_env_steps_trained": 244000, "num_agent_steps_sampled": 976000, "num_agent_steps_trained": 976000}, "env_runners": {"episode_reward_max": 180.0, "episode_reward_min": -28.887719364094746, "episode_reward_mean": 17.84131591485859, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 158, "episodes_timesteps_total": 3950, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -90.0}, "policy_reward_max": {"adversary_policy": 90.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 10.569620253164556, "agent_policy": -13.867544844635082}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, -1.7394717452015074, 0.0, -1.3196316949162612, -1.1982316787823677, -9.98335493679084, 20.0, -4.472986082864153, -0.18548677000682523, 0.0, -3.345605944735297, 0.0, 40.0, -1.1003961700933251, 0.0, -2.2641332727076007, 0.0, 33.52945208657696, -1.3483848675073051, 0.0, 40.0, 40.0, 40.0, 80.0, 23.06832658411255, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 0.0, -6.539542494576392, 139.25809736534933, -4.404432289227502, 60.0, 0.0, -3.979326901852657, 20.0, 35.72044427595091, -5.363255495018231, 0.0, 0.0, 40.0, 40.0, 0.0, 53.9346350279612, 57.67569620335556, 17.773740349688342, 108.51492108170378, 40.0, 38.35831962074818, 0.0, -3.7205042625570695, 4.276131539130097, -11.41765771225417, 0.0, 0.0, 60.0, 20.0, 0.0, 20.0, 40.0, -10.53208077319426, 57.97754281366027, 40.0, -1.5536730688471967, 0.0, -5.320541851162636, 40.0, 60.0, -18.97421648969392, 40.0, 0.0, 180.0, 29.420954063558373, 140.0, 20.0, 20.0, 0.0, 29.405446147146378, 0.0, -8.414968813705451, -14.700728513876074, 20.0, -1.7130365682095472, 40.0, 0.0, 37.685525071686705, 0.0, 0.0, 0.0, 3.2015400470162176, 0.0, 38.57410582783989, -1.4806467269710122, 0.0, 0.0, -28.887719364094746, -8.066232309612726, 56.000227041307994, 46.05256521588287, 60.0, 0.0, 60.0, -12.966586358509627, -1.048506391466072, 73.01755462736477, 60.0, 19.12245262241892, -24.291737567741137, 31.164323219976968, -2.5390753174536824, -0.27402437451759964, 16.759155679138797, 0.0, -10.733909665737537, 20.0, -1.2133176608616791, 0.0, 0.0, 16.920123154779446, -9.974630878892304, -3.249123878168567, 0.0, 40.0, -1.589288858623371, 120.0, 60.0, -4.239573008776081, 36.09542037347935, -1.6843502016650536, 0.0, 60.0, 0.0, 0.0, 0.0, -11.553602440772844, 15.260368139006172, -7.3008735118753, 11.04245649245824, 0.0, 40.0, 0.0, 58.85372431617981, 0.0, 78.58510330912293, 0.0, 0.0, 0.0, 56.586714560258784, 0.0, -7.5384771305367, -1.594640968150558, 0.0, -1.0891872969954741, 40.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 90.0, 90.0, 90.0, 20.0, 20.0, 20.0, 70.0, 70.0, 70.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0], "policy_agent_policy_reward": [0.0, -1.7394717452015074, 0.0, -1.3196316949162612, -1.1982316787823677, -9.98335493679084, -10.0, -4.472986082864153, -0.18548677000682523, 0.0, -3.345605944735297, 0.0, -20.0, -1.1003961700933251, 0.0, -2.2641332727076007, 0.0, -26.470547913423047, -1.3483848675073051, 0.0, -20.0, -20.0, -20.0, -40.0, -36.93167341588745, -30.0, 0.0, 0.0, 0.0, 0.0, 0.0, -20.0, 0.0, -6.539542494576392, -70.74190263465067, -4.404432289227502, -30.0, 0.0, -3.979326901852657, -10.0, -54.27955572404909, -5.363255495018231, 0.0, 0.0, -20.0, -20.0, 0.0, -36.06536497203879, -32.32430379664445, -12.22625965031166, -71.48507891829624, -20.0, -21.64168037925182, 0.0, -3.7205042625570695, -25.7238684608699, -41.41765771225417, 0.0, 0.0, -30.0, -10.0, 0.0, -10.0, -20.0, -10.53208077319426, -32.02245718633973, -20.0, -1.5536730688471967, 0.0, -5.320541851162636, -20.0, -30.0, -18.97421648969392, -20.0, 0.0, -90.0, -30.579045936441624, -70.0, -10.0, -10.0, 0.0, -30.594553852853625, 0.0, -8.414968813705451, -14.700728513876074, -10.0, -1.7130365682095472, -20.0, 0.0, -52.314474928313295, 0.0, 0.0, 0.0, -26.798459952983773, 0.0, -51.425894172160106, -1.4806467269710122, 0.0, 0.0, -28.887719364094746, -8.066232309612726, -33.999772958692, -43.94743478411713, -30.0, 0.0, -30.0, -12.966586358509627, -1.048506391466072, -46.982445372635226, -30.0, -10.877547377581081, -24.291737567741137, -28.835676780023043, -2.5390753174536824, -0.27402437451759964, -13.240844320861203, 0.0, -10.733909665737537, -10.0, -1.2133176608616791, 0.0, 0.0, -13.079876845220554, -9.974630878892304, -3.249123878168567, 0.0, -20.0, -1.589288858623371, -60.0, -30.0, -4.239573008776081, -23.904579626520647, -1.6843502016650536, 0.0, -30.0, 0.0, 0.0, 0.0, -11.553602440772844, -14.739631860993828, -7.3008735118753, -18.957543507541764, 0.0, -20.0, 0.0, -31.1462756838202, 0.0, -41.41489669087707, 0.0, 0.0, 0.0, -33.413285439741216, 0.0, -7.5384771305367, -1.594640968150558, 0.0, -1.0891872969954741, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6854351983267079, "mean_inference_ms": 1.2001466692072167, "mean_action_processing_ms": 0.256034006111154, "mean_env_wait_ms": 0.5131265377636137, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0053489510017105295, "StateBufferConnector_ms": 0.0033377092095870004, "ViewRequirementAgentConnector_ms": 0.09591798239116427}, "num_episodes": 158, "episode_return_max": 180.0, "episode_return_min": -28.887719364094746, "episode_return_mean": 17.84131591485859}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 976000, "num_agent_steps_trained": 976000, "num_env_steps_sampled": 244000, "num_env_steps_trained": 244000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 339.05523012685904, "num_env_steps_trained_throughput_per_sec": 339.05523012685904, "timesteps_total": 244000, "num_env_steps_sampled_lifetime": 244000, "num_agent_steps_sampled_lifetime": 976000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 976000, "timers": {"training_iteration_time_ms": 15618.663, "restore_workers_time_ms": 0.017, "training_step_time_ms": 15618.57, "sample_time_ms": 1269.239, "learn_time_ms": 14322.756, "learn_throughput": 279.276, "synch_weights_time_ms": 24.222}, "counters": {"num_env_steps_sampled": 244000, "num_env_steps_trained": 244000, "num_agent_steps_sampled": 976000, "num_agent_steps_trained": 976000}, "done": false, "training_iteration": 61, "trial_id": "86f16_00000", "date": "2024-08-08_16-27-15", "timestamp": 1723148835, "time_this_iter_s": 11.801420211791992, "time_total_s": 870.1530900001526, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3acdbc160>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 870.1530900001526, "iterations_since_restore": 61, "perf": {"cpu_util_percent": 34.28235294117647, "ram_util_percent": 80.98235294117646}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6653589467841683, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.9833715523388369, "policy_loss": -0.017512866750141565, "vf_loss": 2.000193927178146, "vf_explained_var": -6.052407812564931e-07, "kl": 0.006904876296096991, "entropy": 0.6903516007864728, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 173430.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.4521459305038054, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.1838956102728844, "policy_loss": -0.02536288863096464, "vf_loss": 3.2073389106740553, "vf_explained_var": 0.06282291735212008, "kl": 0.009597854392767998, "entropy": 1.1242076266556977, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 59040.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 248000, "num_env_steps_trained": 248000, "num_agent_steps_sampled": 992000, "num_agent_steps_trained": 992000}, "env_runners": {"episode_reward_max": 140.0, "episode_reward_min": -25.845306834014174, "episode_reward_mean": 17.604452704657422, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -70.0}, "policy_reward_max": {"adversary_policy": 70.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 10.185185185185185, "agent_policy": -12.951102850898133}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-15.436402562902186, 40.0, 0.0, 0.0, -14.338562208198082, -20.112041040016095, 0.0, 0.0, 0.0, 80.0, 27.33821914223103, 0.0, 0.0, 0.0, -1.6393932517030219, -25.845306834014174, -0.1825861605583512, 100.0, 0.0, -6.195729217867584, 20.0, -0.017267994470131498, 140.0, 25.548689501462, -3.5784724400234316, 60.0, -1.1122803610257093, -0.6306216581046808, -0.03221957472410719, 0.0, -5.537073076443157, -14.431600868145427, 0.0, 39.464991423777505, -2.67944379189088, 60.503546128813, 18.89620888498469, -0.1644450201179548, 20.0, 0.0, 20.0, 0.0, 76.42033924078211, 0.0, 0.0, 0.0, 0.0, -4.349661271525317, 60.0, 0.0, 49.250288162708806, -0.5471489760652426, 3.7446359471475574, 39.97185072769874, 20.0, 20.0, -11.542079363389421, 20.0, 0.0, 56.36518390137548, 0.0, -15.051242518397242, -0.03776526327060492, 66.50662625908636, -0.4956447221624205, -7.5168815663094914, 60.0, -0.08131272361662001, -0.16266081545449285, 60.0, -0.2731016777293449, -11.739842162098546, 0.0, 0.0, -1.099526677793442, 0.0, 120.0, 58.3739377418419, 100.0, 0.0, -6.740129876994708, 60.0, 60.0, -2.3350795888229006, 0.0, 60.0, 0.0, 0.0, 0.0, 0.0, 20.0, -1.0827464784423535, 0.0, 0.0, -1.6639624015850896, 0.0, 120.0, 0.0, 100.0, 0.0, -0.09417709865191082, 0.0, 38.467615126964176, 0.0, 19.047631169534107, 0.0, 40.0, -0.29815211443833145, 0.0, 0.0, 33.79733131215665, 0.0, 80.0, -1.6033939966943123, 15.514521729976757, 40.0, 36.60617145664365, 58.8426938453572, 8.816321458507058, 0.0, -0.23076077871388878, -0.574287763883985, 58.714335882665246, 0.0, 40.0, -0.24097600590849533, 60.0, 0.0, 120.0, 0.0, 0.0, -0.3875004707865426, -4.196413269822061, 0.0, 0.0, 0.0, 40.0, 0.0, 0.0, 19.939540726936222, -17.581949503606488, 0.0, 20.0, -6.140087848568546, 60.0, -2.0684398960686803, -17.336786098094816, 6.137583832163295, 60.0, 60.0, 40.0, 14.502445468216994, 20.0, 0.0, 0.0, 0.0, -5.56616124245337, 17.20886939472971, 100.0, 0.0, 55.060652784260604, 39.85242513603528], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0], "policy_agent_policy_reward": [-15.436402562902186, -20.0, 0.0, 0.0, -14.338562208198082, -20.112041040016095, 0.0, 0.0, 0.0, -40.0, -32.66178085776897, 0.0, 0.0, 0.0, -1.6393932517030219, -25.845306834014174, -0.1825861605583512, -50.0, 0.0, -66.1957292178676, -10.0, -0.017267994470131498, -70.0, -34.451310498538, -3.5784724400234316, -30.0, -1.1122803610257093, -0.6306216581046808, -0.03221957472410719, 0.0, -5.537073076443157, -14.431600868145427, 0.0, -20.5350085762225, -2.67944379189088, -59.496453871187, -11.103791115015309, -0.1644450201179548, -10.0, 0.0, -10.0, 0.0, -43.57966075921787, 0.0, 0.0, 0.0, 0.0, -4.349661271525317, -30.0, 0.0, -40.749711837291194, -0.5471489760652426, -26.255364052852443, -20.028149272301263, -10.0, -10.0, -11.542079363389421, -10.0, 0.0, -33.634816098624526, 0.0, -15.051242518397242, -0.03776526327060492, -53.493373740913626, -0.4956447221624205, -7.5168815663094914, -30.0, -0.08131272361662001, -0.16266081545449285, -30.0, -0.2731016777293449, -11.739842162098546, 0.0, 0.0, -1.099526677793442, 0.0, -60.0, -31.626062258158104, -50.0, 0.0, -6.740129876994708, -30.0, -30.0, -2.3350795888229006, 0.0, -30.0, 0.0, 0.0, 0.0, 0.0, -10.0, -1.0827464784423535, 0.0, 0.0, -1.6639624015850896, 0.0, -60.0, 0.0, -50.0, 0.0, -0.09417709865191082, 0.0, -21.532384873035827, 0.0, -10.952368830465893, 0.0, -20.0, -0.29815211443833145, 0.0, 0.0, -26.202668687843342, 0.0, -40.0, -1.6033939966943123, -14.485478270023245, -20.0, -23.393828543356353, -31.157306154642797, -21.18367854149294, 0.0, -0.23076077871388878, -0.574287763883985, -31.285664117334754, 0.0, -20.0, -0.24097600590849533, -30.0, 0.0, -60.0, 0.0, 0.0, -0.3875004707865426, -4.196413269822061, 0.0, 0.0, 0.0, -20.0, 0.0, 0.0, -10.06045927306378, -17.581949503606488, 0.0, -10.0, -6.140087848568546, -30.0, -2.0684398960686803, -17.336786098094816, -23.862416167836702, -30.0, -30.0, -20.0, -15.497554531783006, -10.0, 0.0, 0.0, 0.0, -35.566161242453376, -12.791130605270288, -50.0, 0.0, -34.9393472157394, -20.147574863964717]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6844012901901214, "mean_inference_ms": 1.1983633436327321, "mean_action_processing_ms": 0.25549335164857223, "mean_env_wait_ms": 0.5124543246519689, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00456041759914822, "StateBufferConnector_ms": 0.003730809247052228, "ViewRequirementAgentConnector_ms": 0.08884977411340785}, "num_episodes": 162, "episode_return_max": 140.0, "episode_return_min": -25.845306834014174, "episode_return_mean": 17.604452704657422}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 992000, "num_agent_steps_trained": 992000, "num_env_steps_sampled": 248000, "num_env_steps_trained": 248000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 314.3664047017831, "num_env_steps_trained_throughput_per_sec": 314.3664047017831, "timesteps_total": 248000, "num_env_steps_sampled_lifetime": 248000, "num_agent_steps_sampled_lifetime": 992000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 992000, "timers": {"training_iteration_time_ms": 15745.1, "restore_workers_time_ms": 0.017, "training_step_time_ms": 15745.007, "sample_time_ms": 1265.988, "learn_time_ms": 14451.04, "learn_throughput": 276.797, "synch_weights_time_ms": 25.706}, "counters": {"num_env_steps_sampled": 248000, "num_env_steps_trained": 248000, "num_agent_steps_sampled": 992000, "num_agent_steps_trained": 992000}, "done": false, "training_iteration": 62, "trial_id": "86f16_00000", "date": "2024-08-08_16-27-28", "timestamp": 1723148848, "time_this_iter_s": 12.735881090164185, "time_total_s": 882.8889710903168, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3acdbc5e0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 882.8889710903168, "iterations_since_restore": 62, "perf": {"cpu_util_percent": 43.55, "ram_util_percent": 80.52222222222223}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.67439914617344, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.283417098530641, "policy_loss": -0.016984044770476513, "vf_loss": 2.299700797787795, "vf_explained_var": -8.152520402948907e-07, "kl": 0.007003445733178894, "entropy": 0.6826178153355916, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 176250.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.262581675623854, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.531587854276101, "policy_loss": -0.021777944042211554, "vf_loss": 3.5517994773884616, "vf_explained_var": 0.1307273148248593, "kl": 0.007831584182747046, "entropy": 1.106871637950341, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 60000.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 252000, "num_env_steps_trained": 252000, "num_agent_steps_sampled": 1008000, "num_agent_steps_trained": 1008000}, "env_runners": {"episode_reward_max": 177.2242430740574, "episode_reward_min": -35.1872233003528, "episode_reward_mean": 15.027868038020028, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 157, "episodes_timesteps_total": 3925, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -92.7757569259426}, "policy_reward_max": {"adversary_policy": 90.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 9.044585987261147, "agent_policy": -12.105889923763407}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 40.0, 40.0, -0.04597543970609186, 0.0, -9.636047930557417, 5.722779106146783, 20.0, 40.0, 0.0, -21.18841317339581, 9.069822252254454, 0.0, 80.0, 38.36191363289043, 72.7911674679624, 0.0, -1.3831609366993325, 0.0, 60.0, 0.0, 38.55723025951517, 20.0, -5.453839675002749, -5.43697985394394, 0.0, -10.695245443573203, -35.1872233003528, -6.019388044552922, -0.7083388394411183, -2.4861124900838716, 59.217847461883764, 0.0, 40.0, 0.0, 0.0, 0.0, 40.0, 0.0, -0.892258548491861, -1.283898731000831, 20.0, 19.352352294239644, -1.4052855368249528, -1.4025177604559724, 0.0, 0.0, 80.0, 0.0, 80.0, 0.0, 20.0, -14.868989514054107, -0.9805121846024201, -5.108909558116231, -5.636702294212085, 44.670699425138714, -9.26271302467335, 57.51781451852432, -16.77178236402927, 40.0, 0.0, 20.0, 56.76651830132144, 19.644015078006937, 1.955796901221876, -6.731953498982811, -1.7109670219270057, 0.0, 177.2242430740574, -17.822274483014883, -14.321021912752002, 80.0, 40.0, 0.0, -8.944440443682629, 38.71551581982473, 19.61029984683087, -1.402807983199138, 55.10780690696543, 0.0, 0.0, 0.0, -14.448679921659497, 0.0, -0.5214542984784853, 16.77225709437883, 57.83498614042789, -0.8946867361074196, 0.0, 20.0, -2.402596999373406, -24.910672111243134, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 80.0, 57.3836475193295, 0.0, 16.368464723799544, 0.0, 120.0, 0.0, 60.0, 0.0, 0.0, 0.0, 4.344591258295068, 10.614358377764121, 0.0, 0.0, 17.26690998164887, 60.0, 9.608007844196917, 20.0, -0.40135889130543134, 20.0, 0.0, -0.015831862445089273, 0.0, 20.0, 0.0, 40.0, 40.0, 60.0, -16.787239794705798, 0.0, 0.0, 0.0, -8.191741434937896, 0.0, 20.0, 0.0, -0.7632569605146844, 0.0, 39.693738796441565, -1.4704127527440303, -4.039797241647541, 97.64153292850028, -0.2717274513523027, -3.6052062112313576, 20.0, 0.0, -17.81202908801249, 20.0, 39.87392271146031, 0.0, 80.0, -8.245872041687274, 40.0, -4.85770340567241, 54.11506943656476, 60.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 90.0, 90.0, 90.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0], "policy_agent_policy_reward": [0.0, 0.0, -20.0, -20.0, -0.04597543970609186, 0.0, -9.636047930557417, -24.27722089385322, -10.0, -20.0, 0.0, -21.18841317339581, -20.930177747745546, 0.0, -40.0, -21.638086367109572, -47.208832532037604, 0.0, -1.3831609366993325, 0.0, -30.0, 0.0, -21.442769740484827, -10.0, -5.453839675002749, -5.43697985394394, 0.0, -10.695245443573203, -35.1872233003528, -6.019388044552922, -0.7083388394411183, -2.4861124900838716, -30.782152538116232, 0.0, -20.0, 0.0, 0.0, 0.0, -20.0, 0.0, -0.892258548491861, -1.283898731000831, -10.0, -10.647647705760354, -1.4052855368249528, -1.4025177604559724, 0.0, 0.0, -40.0, 0.0, -40.0, 0.0, -10.0, -14.868989514054107, -0.9805121846024201, -5.108909558116231, -5.636702294212085, -45.329300574861286, -9.26271302467335, -32.482185481475675, -16.77178236402927, -20.0, 0.0, -10.0, -33.23348169867857, -10.355984921993063, -28.044203098778134, -6.731953498982811, -1.7109670219270057, 0.0, -92.7757569259426, -17.822274483014883, -14.321021912752002, -40.0, -20.0, 0.0, -8.944440443682629, -21.284484180175266, -10.389700153169128, -1.402807983199138, -34.89219309303457, 0.0, 0.0, 0.0, -14.448679921659497, 0.0, -0.5214542984784853, -13.22774290562117, -32.16501385957211, -0.8946867361074196, 0.0, -10.0, -2.402596999373406, -24.910672111243134, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -40.0, -32.6163524806705, 0.0, -13.631535276200456, 0.0, -60.0, 0.0, -30.0, 0.0, 0.0, 0.0, -25.65540874170493, -19.385641622235873, 0.0, 0.0, -12.733090018351131, -30.0, -20.39199215580308, -10.0, -30.40135889130543, -10.0, 0.0, -0.015831862445089273, 0.0, -10.0, 0.0, -20.0, -20.0, -30.0, -16.787239794705798, 0.0, 0.0, 0.0, -8.191741434937896, 0.0, -10.0, 0.0, -0.7632569605146844, 0.0, -20.30626120355843, -1.4704127527440303, -4.039797241647541, -52.3584670714997, -0.2717274513523027, -3.6052062112313576, -10.0, 0.0, -17.81202908801249, -10.0, -20.126077288539694, 0.0, -40.0, -8.245872041687274, -20.0, -4.85770340567241, -35.88493056343524, -30.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.685872840969611, "mean_inference_ms": 1.2021902721603803, "mean_action_processing_ms": 0.2557828743642565, "mean_env_wait_ms": 0.513614769986874, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006318547923094148, "StateBufferConnector_ms": 0.0044639702815159115, "ViewRequirementAgentConnector_ms": 0.11156501284070836}, "num_episodes": 157, "episode_return_max": 177.2242430740574, "episode_return_min": -35.1872233003528, "episode_return_mean": 15.027868038020028}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1008000, "num_agent_steps_trained": 1008000, "num_env_steps_sampled": 252000, "num_env_steps_trained": 252000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 249.3541577119104, "num_env_steps_trained_throughput_per_sec": 249.3541577119104, "timesteps_total": 252000, "num_env_steps_sampled_lifetime": 252000, "num_agent_steps_sampled_lifetime": 1008000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1008000, "timers": {"training_iteration_time_ms": 15557.889, "restore_workers_time_ms": 0.017, "training_step_time_ms": 15557.797, "sample_time_ms": 1289.031, "learn_time_ms": 14240.96, "learn_throughput": 280.88, "synch_weights_time_ms": 26.032}, "counters": {"num_env_steps_sampled": 252000, "num_env_steps_trained": 252000, "num_agent_steps_sampled": 1008000, "num_agent_steps_trained": 1008000}, "done": false, "training_iteration": 63, "trial_id": "86f16_00000", "date": "2024-08-08_16-27-44", "timestamp": 1723148864, "time_this_iter_s": 16.055600881576538, "time_total_s": 898.9445719718933, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3acdbca60>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 898.9445719718933, "iterations_since_restore": 63, "perf": {"cpu_util_percent": 54.84782608695652, "ram_util_percent": 80.03478260869564}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6883259240088734, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.2081520900235954, "policy_loss": -0.017556655952834496, "vf_loss": 2.2250664892771566, "vf_explained_var": -4.23256387101843e-07, "kl": 0.006422552021197121, "entropy": 0.6804368081879109, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 179070.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.299087907373905, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.7101756387700635, "policy_loss": -0.024338863940405037, "vf_loss": 3.732698748384913, "vf_explained_var": 0.07942169203112523, "kl": 0.009078822122781782, "entropy": 1.07676247668763, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 60960.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 256000, "num_env_steps_trained": 256000, "num_agent_steps_sampled": 1024000, "num_agent_steps_trained": 1024000}, "env_runners": {"episode_reward_max": 140.0, "episode_reward_min": -38.35048807813922, "episode_reward_mean": 16.199108708187083, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -70.0}, "policy_reward_max": {"adversary_policy": 70.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 9.814814814814815, "agent_policy": -13.245335736257363}, "custom_metrics": {}, "hist_stats": {"episode_reward": [35.28656911725925, 38.49581427339471, 140.0, -3.2763335669065263, 20.0, 40.0, -26.453611484501234, 19.303954741028615, 29.579571740949042, -2.5809459203822085, 0.0, 0.0, -38.35048807813922, 0.0, 0.0, 0.0, -5.712903697804546, 60.0, -6.557989105828738, 66.72982786285948, -1.5889430893226963, 0.0, 0.0, -23.0771697604368, 20.0, -0.5624926361667959, 0.0, 0.0, -2.047197390881164, 36.38879501742435, 0.0, 20.0, -9.359410212116462, 0.0, 0.0, -15.925690100813842, 40.0, 38.95651535724391, 0.0, 0.0, 20.0, -7.548479701656299, 100.0, 0.0, 40.0, 35.23842420817907, -5.953168295101601, 40.0, -4.507923315958033, 0.0, 40.0, -1.2692830808082944, 19.93106082386914, -9.04038854003091, 20.0, -15.98693103645788, 0.0, 0.0, 79.73452542295027, 0.0, 0.0, 0.0, 0.0, 120.0, 39.74799200083753, 0.0, -6.488477900932941, 0.0, 0.0, 0.0, -2.848672765170721, -8.507762845573156, 0.0, -14.513821452700947, 0.0, 40.0, 80.0, 40.0, -1.776782467068173, 100.0, 100.0, -14.116225572762142, 15.125414278797193, -2.0130784123715784, 14.021772030485812, 0.0, 40.0, 0.0, 0.0, -9.820576659297318, 40.0, 20.0, 18.618032317066998, -2.1102996530070692, 39.73256123409031, 0.0, 0.0, -24.769520060734695, 60.0, 1.0791019498788847, -0.5655871074897867, -10.21877060214749, 20.0, -0.49236981700898963, 20.0, -26.37127946418691, 0.0, 13.89611956642553, 32.13868248774506, 40.0, 120.0, 0.0, -1.7026114329896709, 12.00540643429601, 60.0, 0.0, 0.0, 12.32422092095417, 0.0, 18.91524187381733, 16.95040974663309, 140.0, 20.0, 80.0, 40.0, 0.0, 100.0, 20.0, 60.0, -2.5604482991697797, -2.429754886402933, 0.0, 0.0, 60.0, 0.0, 30.229856747817166, -2.8011745795218284, 0.0, 0.0, 0.0, 20.0, -11.199088075031982, -0.3714021161451653, 19.72772912796989, 0.0, 40.0, -2.221370425000626, 20.0, 0.0, 0.0, 69.1009751754713, -7.083368468153491, 0.0, 58.89269270106732, -4.045836115891412, -11.252378122510759, 0.0, 39.44286779270839, 0.0, 40.0, 0.0, -17.258517910329704], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 70.0, 70.0, 70.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-24.71343088274075, -21.504185726605293, -70.0, -3.2763335669065263, -10.0, -20.0, -26.453611484501234, -10.696045258971385, -30.420428259050958, -2.5809459203822085, 0.0, 0.0, -38.35048807813922, 0.0, 0.0, 0.0, -5.712903697804546, -30.0, -6.557989105828738, -53.270172137140534, -1.5889430893226963, 0.0, 0.0, -53.07716976043679, -10.0, -0.5624926361667959, 0.0, 0.0, -2.047197390881164, -23.61120498257565, 0.0, -10.0, -9.359410212116462, 0.0, 0.0, -15.925690100813842, -20.0, -51.04348464275609, 0.0, 0.0, -10.0, -7.548479701656299, -50.0, 0.0, -20.0, -24.761575791820942, -5.953168295101601, -20.0, -4.507923315958033, 0.0, -20.0, -1.2692830808082944, -10.06893917613086, -9.04038854003091, -10.0, -15.98693103645788, 0.0, 0.0, -40.26547457704972, 0.0, 0.0, 0.0, 0.0, -60.0, -20.252007999162476, 0.0, -6.488477900932941, 0.0, 0.0, 0.0, -2.848672765170721, -8.507762845573156, 0.0, -14.513821452700947, 0.0, -20.0, -40.0, -20.0, -1.776782467068173, -50.0, -50.0, -14.116225572762142, -14.874585721202807, -2.0130784123715784, -45.97822796951418, 0.0, -20.0, 0.0, 0.0, -9.820576659297318, -20.0, -10.0, -11.381967682933, -2.1102996530070692, -20.267438765909688, 0.0, 0.0, -24.769520060734695, -30.0, -28.920898050121107, -0.5655871074897867, -10.21877060214749, -10.0, -0.49236981700898963, -10.0, -26.37127946418691, 0.0, -16.103880433574478, -27.861317512254946, -20.0, -60.0, 0.0, -1.7026114329896709, -17.994593565703987, -30.0, 0.0, 0.0, -17.675779079045828, 0.0, -11.084758126182669, -13.049590253366912, -70.0, -10.0, -40.0, -20.0, 0.0, -50.0, -10.0, -30.0, -2.5604482991697797, -2.429754886402933, 0.0, 0.0, -30.0, 0.0, -29.770143252182834, -2.8011745795218284, 0.0, 0.0, 0.0, -10.0, -11.199088075031982, -0.3714021161451653, -10.272270872030111, 0.0, -20.0, -2.221370425000626, -10.0, 0.0, 0.0, -50.899024824528674, -7.083368468153491, 0.0, -31.107307298932675, -4.045836115891412, -11.252378122510759, 0.0, -20.557132207291613, 0.0, -20.0, 0.0, -17.258517910329704]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6855827966157643, "mean_inference_ms": 1.2016904559271628, "mean_action_processing_ms": 0.2553724432169693, "mean_env_wait_ms": 0.5134188026630317, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006440318660971559, "StateBufferConnector_ms": 0.0036051979771366824, "ViewRequirementAgentConnector_ms": 0.09484901840304151}, "num_episodes": 162, "episode_return_max": 140.0, "episode_return_min": -38.35048807813922, "episode_return_mean": 16.199108708187083}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1024000, "num_agent_steps_trained": 1024000, "num_env_steps_sampled": 256000, "num_env_steps_trained": 256000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 212.7244640863041, "num_env_steps_trained_throughput_per_sec": 212.7244640863041, "timesteps_total": 256000, "num_env_steps_sampled_lifetime": 256000, "num_agent_steps_sampled_lifetime": 1024000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1024000, "timers": {"training_iteration_time_ms": 15810.145, "restore_workers_time_ms": 0.017, "training_step_time_ms": 15810.063, "sample_time_ms": 1279.854, "learn_time_ms": 14506.123, "learn_throughput": 275.746, "synch_weights_time_ms": 22.534}, "counters": {"num_env_steps_sampled": 256000, "num_env_steps_trained": 256000, "num_agent_steps_sampled": 1024000, "num_agent_steps_trained": 1024000}, "done": false, "training_iteration": 64, "trial_id": "86f16_00000", "date": "2024-08-08_16-28-03", "timestamp": 1723148883, "time_this_iter_s": 18.823354959487915, "time_total_s": 917.7679269313812, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3acdbcdc0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 917.7679269313812, "iterations_since_restore": 64, "perf": {"cpu_util_percent": 65.9814814814815, "ram_util_percent": 81.35185185185185}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6633295717602926, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.0697649858522076, "policy_loss": -0.018370954890765172, "vf_loss": 2.087461214369916, "vf_explained_var": 1.6435663750831117e-07, "kl": 0.006747240388478219, "entropy": 0.6669808089521759, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 181890.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.220500600958864, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.3985712847361964, "policy_loss": -0.020444243018088552, "vf_loss": 3.417424836878975, "vf_explained_var": 0.08823396631826957, "kl": 0.007953390492979887, "entropy": 1.0911684460317095, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 61920.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 260000, "num_env_steps_trained": 260000, "num_agent_steps_sampled": 1040000, "num_agent_steps_trained": 1040000}, "env_runners": {"episode_reward_max": 131.78168900591703, "episode_reward_min": -29.425909842900207, "episode_reward_mean": 15.988339683692034, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -78.21831099408297}, "policy_reward_max": {"adversary_policy": 70.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 9.25925925925926, "agent_policy": -11.789438094085744}, "custom_metrics": {}, "hist_stats": {"episode_reward": [20.0, 0.0, 20.0, 0.0, 40.0, 0.0, 60.0, -21.813808660632645, 0.0, 38.813117792479275, 80.0, 0.0, 0.0, -0.6931020093173534, 0.0, -12.507903991466563, -3.5090291549139607, 40.0, 0.0, 0.0, 40.0, 0.0, -5.405700356328103, 0.0, -17.835353390367022, -0.04927222728414171, -0.015865465317729255, 20.0, 0.0, -2.3092050657298, 0.0, 0.0, 0.0, -11.136902655249168, 20.0, 20.0, 0.0, 20.0, 60.0, -0.6998604882824089, 0.0, 20.0, 0.0, 0.0, 0.0, 60.0, 16.51820164118178, 60.0, 11.449765970514619, -0.17305238044241444, 0.0, 20.0, 79.40171647655518, -20.479739126415655, 0.0, 16.346748683656646, 20.0, 0.0, -10.971823868623925, 0.0, -2.215131740503282, 40.0, 2.535439982674929, -3.9392622662716192, 0.0, -11.760329338446203, 0.0, 0.0, -0.6945922597819143, 80.0, 0.0, 20.0, 0.0, 0.0, -15.229994321110505, -4.936852595188177, 58.8132464271055, -8.099483234745321, -7.470356789711767, 11.984876438366275, -2.883096067338041, -0.9117163124137284, 0.0, 0.0, 54.998975762013416, 100.0, -1.740010404070913, 0.0, 60.0, 131.78168900591703, 0.0, -0.34489180125573005, 0.0, -2.265619439869162, 0.0, 40.0, 0.0, 0.0, 0.0, 53.636512110542654, -1.7626911529042133, 93.9941662702277, 0.0, -1.0342990644104466, 60.0, 38.33269537551726, -1.3667788007023718, -25.707747384885685, 20.0, -0.3947849183632357, 80.0, 57.40040043812692, 80.0, -0.826468590572973, -0.5809006057759969, 0.0, 20.0, 60.0, 40.0, 0.0, 0.0, 40.0, 0.0, -29.425909842900207, 20.0, 80.0, -0.7285570918484585, 24.61923329635478, 0.0, 39.97191061223871, -5.218692838810658, -6.368751795732818, 0.0, 40.0, 0.0, 80.0, -9.273861504854066, 0.0, -0.39932040843372874, 40.0, 57.72765784210165, 40.0, 39.98825182779419, -1.865100465929499, 20.0, 0.0, 60.0, -0.532470235092195, 40.0, 0.0, 40.0, -0.07126255590258368, 0.0, -11.643022486358149, 78.4668208005443, -20.615305133890967, 0.0, 100.0, 20.34094795697113, 0.0, -9.103465664328949, 40.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0], "policy_agent_policy_reward": [-10.0, 0.0, -10.0, 0.0, -20.0, 0.0, -30.0, -21.813808660632645, 0.0, -21.186882207520725, -40.0, 0.0, 0.0, -0.6931020093173534, 0.0, -12.507903991466563, -3.5090291549139607, -20.0, 0.0, 0.0, -20.0, 0.0, -5.405700356328103, 0.0, -17.835353390367022, -0.04927222728414171, -0.015865465317729255, -10.0, 0.0, -2.3092050657298, 0.0, 0.0, 0.0, -11.136902655249168, -10.0, -10.0, 0.0, -10.0, -30.0, -0.6998604882824089, 0.0, -10.0, 0.0, 0.0, 0.0, -30.0, -13.48179835881822, -30.0, -18.550234029485374, -0.17305238044241444, 0.0, -10.0, -40.59828352344483, -20.479739126415655, 0.0, -13.653251316343354, -10.0, 0.0, -10.971823868623925, 0.0, -2.215131740503282, -20.0, -27.46456001732508, -3.9392622662716192, 0.0, -11.760329338446203, 0.0, 0.0, -0.6945922597819143, -40.0, 0.0, -10.0, 0.0, 0.0, -15.229994321110505, -4.936852595188177, -31.1867535728945, -8.099483234745321, -7.470356789711767, -18.015123561633725, -2.883096067338041, -0.9117163124137284, 0.0, 0.0, -35.001024237986584, -50.0, -1.740010404070913, 0.0, -30.0, -78.21831099408297, 0.0, -0.34489180125573005, 0.0, -2.265619439869162, 0.0, -20.0, 0.0, 0.0, 0.0, -36.36348788945734, -1.7626911529042133, -56.00583372977231, 0.0, -1.0342990644104466, -30.0, -21.66730462448274, -1.3667788007023718, -25.707747384885685, -10.0, -0.3947849183632357, -40.0, -32.59959956187307, -40.0, -0.826468590572973, -0.5809006057759969, 0.0, -10.0, -30.0, -20.0, 0.0, 0.0, -20.0, 0.0, -29.425909842900207, -10.0, -40.0, -0.7285570918484585, -35.38076670364522, 0.0, -20.028089387761295, -5.218692838810658, -6.368751795732818, 0.0, -20.0, 0.0, -40.0, -9.273861504854066, 0.0, -0.39932040843372874, -20.0, -32.27234215789835, -20.0, -20.011748172205813, -1.865100465929499, -10.0, 0.0, -30.0, -0.532470235092195, -20.0, 0.0, -20.0, -0.07126255590258368, 0.0, -11.643022486358149, -41.533179199455695, -20.615305133890967, 0.0, -50.0, -39.659052043028865, 0.0, -9.103465664328949, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6865494173111838, "mean_inference_ms": 1.2029496324528182, "mean_action_processing_ms": 0.255351011881769, "mean_env_wait_ms": 0.5141549955263365, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0061330971894440825, "StateBufferConnector_ms": 0.004573589489783769, "ViewRequirementAgentConnector_ms": 0.11571807625852985}, "num_episodes": 162, "episode_return_max": 131.78168900591703, "episode_return_min": -29.425909842900207, "episode_return_mean": 15.988339683692034}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1040000, "num_agent_steps_trained": 1040000, "num_env_steps_sampled": 260000, "num_env_steps_trained": 260000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 195.92384388640636, "num_env_steps_trained_throughput_per_sec": 195.92384388640636, "timesteps_total": 260000, "num_env_steps_sampled_lifetime": 260000, "num_agent_steps_sampled_lifetime": 1040000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1040000, "timers": {"training_iteration_time_ms": 16223.27, "restore_workers_time_ms": 0.017, "training_step_time_ms": 16223.187, "sample_time_ms": 1337.012, "learn_time_ms": 14861.9, "learn_throughput": 269.145, "synch_weights_time_ms": 22.701}, "counters": {"num_env_steps_sampled": 260000, "num_env_steps_trained": 260000, "num_agent_steps_sampled": 1040000, "num_agent_steps_trained": 1040000}, "done": false, "training_iteration": 65, "trial_id": "86f16_00000", "date": "2024-08-08_16-28-24", "timestamp": 1723148904, "time_this_iter_s": 20.429079055786133, "time_total_s": 938.1970059871674, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3acdba280>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 938.1970059871674, "iterations_since_restore": 65, "perf": {"cpu_util_percent": 78.0689655172414, "ram_util_percent": 82.13103448275862}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6215074486660619, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.8003691261330395, "policy_loss": -0.01794866678539865, "vf_loss": 1.8175790483647205, "vf_explained_var": 9.769454915472801e-07, "kl": 0.007387464727469291, "entropy": 0.6399497098111092, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 184710.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.280778735006849, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.029964131737749, "policy_loss": -0.02183596305937196, "vf_loss": 3.0502843341479697, "vf_explained_var": 0.09887761529535055, "kl": 0.007578840564398229, "entropy": 1.0893949539090195, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 62880.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 264000, "num_env_steps_trained": 264000, "num_agent_steps_sampled": 1056000, "num_agent_steps_trained": 1056000}, "env_runners": {"episode_reward_max": 138.67588547515896, "episode_reward_min": -30.58236031543478, "episode_reward_mean": 14.504056391569831, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 158, "episodes_timesteps_total": 3950, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -71.32411452484104}, "policy_reward_max": {"adversary_policy": 70.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 8.417721518987342, "agent_policy": -10.749108165392192}, "custom_metrics": {}, "hist_stats": {"episode_reward": [80.0, 0.0, 0.0, 60.0, 0.0, 138.67588547515896, 0.0, -1.2691594900096403, 0.0, 0.0, -1.3776698814840183, 27.87772567308862, -0.8190367667683884, 99.3329738628434, 0.0, 0.0, 40.0, 19.751758497744454, 0.0, 0.0, 18.530441531576994, 40.0, -23.704344372509734, 39.82509726306192, -19.879621005046246, 0.0, 40.0, 40.0, -13.14998616235411, 0.0, 97.35433223151924, 36.82948481473374, 0.0, 0.0, -3.036032403209286, 0.0, 60.0, -2.3327455940834363, -4.48724167772075, 20.0, -8.413199659532443, 40.0, -4.649051279431999, 60.0, 20.0, 78.22398655389526, 20.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -2.1070824088840077, -4.110904463175773, 40.0, 0.0, 40.0, 60.0, 0.0, 0.0, 80.0, -4.945134249884002, 0.0, 0.0, 0.0, 46.89542382932762, -30.58236031543478, -1.2994859657953028, -17.188286628065395, 0.0, 0.0, 40.0, 0.0, -0.6754926034030828, 60.0, 40.0, -2.116515012861501, 0.0, 0.0, -8.029821330141651, -11.21769608471729, 0.0, 0.0, 40.0, 80.0, 50.52382791580578, -2.268418921582075, 40.0, 20.0, 0.0, 60.0, 20.0, -0.06266006479091812, -8.119709853107807, 0.0, 20.90893505323024, -1.1140790093283393, -12.834470966126574, 0.0, -1.2771103246405715, -7.4096680736812015, 0.0, -3.4765091176687326, 40.0, 0.0, 0.0, 20.0, 20.0, -12.973714741862192, 0.0, 0.0, -1.09905558229633, 0.0, 0.0, 0.0, 0.0, 0.0, -5.68553951632763, 17.59018471431393, 0.0, 59.91628802699094, -7.672456889368298, 70.53161793230969, 0.0, 0.0, 0.0, 0.0, -8.977433125197596, -2.77822497871541, 0.0, 0.0, 0.0, 18.553024449599242, 91.25285343327187, 0.0, -0.7221703112507494, -12.78327164336442, 60.0, 60.0, 0.0, -3.2359927816177625, -0.5827882938891804, -2.3237715114527653, -0.515018451629804, -1.877895106171057, -1.2798667514152895, 27.717028819221436, 60.0, -0.6309939925689645, 40.0, 0.0, 0.0, 36.441727152906836, 0.0, 0.0, 80.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0], "policy_agent_policy_reward": [-40.0, 0.0, 0.0, -30.0, 0.0, -71.32411452484104, 0.0, -1.2691594900096403, 0.0, 0.0, -1.3776698814840183, -32.12227432691139, -0.8190367667683884, -50.6670261371566, 0.0, 0.0, -20.0, -10.248241502255544, 0.0, 0.0, -11.469558468423006, -20.0, -23.704344372509734, -20.174902736938083, -19.879621005046246, 0.0, -20.0, -20.0, -13.14998616235411, 0.0, -52.64566776848076, -23.17051518526626, 0.0, 0.0, -3.036032403209286, 0.0, -30.0, -2.3327455940834363, -4.48724167772075, -10.0, -8.413199659532443, -20.0, -4.649051279431999, -30.0, -10.0, -41.77601344610475, -10.0, -20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -2.1070824088840077, -4.110904463175773, -20.0, 0.0, -20.0, -30.0, 0.0, 0.0, -40.0, -4.945134249884002, 0.0, 0.0, 0.0, -43.10457617067238, -30.58236031543478, -1.2994859657953028, -17.188286628065395, 0.0, 0.0, -20.0, 0.0, -0.6754926034030828, -30.0, -20.0, -2.116515012861501, 0.0, 0.0, -8.029821330141651, -11.21769608471729, 0.0, 0.0, -20.0, -40.0, -39.47617208419421, -2.268418921582075, -20.0, -10.0, 0.0, -30.0, -10.0, -0.06266006479091812, -8.119709853107807, 0.0, -39.09106494676975, -1.1140790093283393, -12.834470966126574, 0.0, -1.2771103246405715, -7.4096680736812015, 0.0, -3.4765091176687326, -20.0, 0.0, 0.0, -10.0, -10.0, -12.973714741862192, 0.0, 0.0, -1.09905558229633, 0.0, 0.0, 0.0, 0.0, 0.0, -5.68553951632763, -12.409815285686069, 0.0, -30.08371197300906, -7.672456889368298, -49.46838206769031, 0.0, 0.0, 0.0, 0.0, -8.977433125197596, -2.77822497871541, 0.0, 0.0, 0.0, -11.446975550400762, -58.74714656672814, 0.0, -0.7221703112507494, -12.78327164336442, -30.0, -30.0, 0.0, -3.2359927816177625, -0.5827882938891804, -2.3237715114527653, -0.515018451629804, -1.877895106171057, -1.2798667514152895, -32.282971180778574, -30.0, -0.6309939925689645, -20.0, 0.0, 0.0, -23.558272847093164, 0.0, 0.0, -40.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6861449922482111, "mean_inference_ms": 1.2023145272050375, "mean_action_processing_ms": 0.25499350850968744, "mean_env_wait_ms": 0.5138042166845229, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0050086009351513056, "StateBufferConnector_ms": 0.003337256516082377, "ViewRequirementAgentConnector_ms": 0.0917664811580996}, "num_episodes": 158, "episode_return_max": 138.67588547515896, "episode_return_min": -30.58236031543478, "episode_return_mean": 14.504056391569831}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1056000, "num_agent_steps_trained": 1056000, "num_env_steps_sampled": 264000, "num_env_steps_trained": 264000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 341.5406397185336, "num_env_steps_trained_throughput_per_sec": 341.5406397185336, "timesteps_total": 264000, "num_env_steps_sampled_lifetime": 264000, "num_agent_steps_sampled_lifetime": 1056000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1056000, "timers": {"training_iteration_time_ms": 15804.708, "restore_workers_time_ms": 0.017, "training_step_time_ms": 15804.625, "sample_time_ms": 1337.099, "learn_time_ms": 14444.042, "learn_throughput": 276.931, "synch_weights_time_ms": 21.955}, "counters": {"num_env_steps_sampled": 264000, "num_env_steps_trained": 264000, "num_agent_steps_sampled": 1056000, "num_agent_steps_trained": 1056000}, "done": false, "training_iteration": 66, "trial_id": "86f16_00000", "date": "2024-08-08_16-28-36", "timestamp": 1723148916, "time_this_iter_s": 11.71568512916565, "time_total_s": 949.912691116333, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3acdba4c0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 949.912691116333, "iterations_since_restore": 66, "perf": {"cpu_util_percent": 40.3, "ram_util_percent": 79.91176470588235}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6102199912388274, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.3843867190340733, "policy_loss": -0.0164902318090676, "vf_loss": 1.400201315004775, "vf_explained_var": 4.803669368121641e-07, "kl": 0.006756340306387839, "entropy": 0.6547124342081395, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 187530.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.263698575894038, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.779503775015473, "policy_loss": -0.021328000595288662, "vf_loss": 2.7990210526933272, "vf_explained_var": 0.17027072701603174, "kl": 0.009053612159077315, "entropy": 1.1043631387253603, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 63840.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 268000, "num_env_steps_trained": 268000, "num_agent_steps_sampled": 1072000, "num_agent_steps_trained": 1072000}, "env_runners": {"episode_reward_max": 120.0, "episode_reward_min": -24.643305208339868, "episode_reward_mean": 10.22415275451433, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 157, "episodes_timesteps_total": 3925, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -72.9998851449249}, "policy_reward_max": {"adversary_policy": 60.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 6.8152866242038215, "agent_policy": -10.221707118097134}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-6.443802532984201, 0.0, -20.244080459442415, 0.0, 0.0, 0.0, 37.16815747373251, 40.0, 0.0, 53.43938344217157, 0.0, -0.9629037079451375, 0.0, -5.607590452774332, 0.0, -10.651750984003696, 17.467111776691265, 0.0, -19.257930133687935, 0.0, 0.0, 0.0, 60.0, -2.0351770189275564, -4.147157458937896, -8.514687274071273, -12.999885144924917, 20.0, -15.966585251632813, 0.0, 31.145264853928616, -0.9640214185692086, 8.250560087437934, 40.0, 0.0, 60.0, 40.0, -16.53370041042567, 0.0, 59.713125843205574, 0.0, 40.0, 0.0, 0.0, 60.0, -4.213699279323457, 0.0, -0.3019558117393062, -15.146008311141072, 0.0, -15.825892709021963, -21.87667996334818, 0.0, 40.0, 20.0, 40.0, 0.0, 0.0, -9.57789693606534, 40.0, 0.0, -0.5303636258409761, 60.0, -3.9476882045634722, 40.0, 120.0, 0.0, 37.61193086301053, 40.0, 16.68175303145768, 39.419674329123126, 0.0, 40.0, 20.0, 0.0, 0.0, -0.3857919400713672, 0.0, -0.20354536373144327, 0.0, 60.0, -17.17245185637094, 0.0, -5.159803339623943, -0.7692103763945002, 0.0, 0.0, 0.0, -9.197974439560776, 0.0, 0.0, -7.851409661101362, 0.0, -16.85314605139422, 0.0, -3.71903592397199, -12.402250356728668, 20.0, -16.00696786580213, 60.0, -0.41950283204477135, 12.501763308019484, 0.0, 79.68563449108433, -1.016478389150277, 0.0, -1.8258530872909162, -3.3103186160723093, -2.451330295267902, 0.0, 0.0, 0.0, 3.237615621907557, 0.0, 0.0, 30.397754919690215, 20.0, 40.0, 0.0, -4.739486661652062, 0.0, 0.0, -2.001307828170229, 20.0, 50.26903091161642, -2.262433213344358, -0.20923756049907039, -0.576629908935079, 10.469967209738726, 60.0, 39.556290924057734, 23.35742587955233, 0.0, 0.0, -0.2336322814645908, 0.0, 0.0, -0.48031836594491284, -7.1735987935939605, 10.867468090812928, 0.0, 28.43774503147752, 0.0, 39.83341050276961, 73.90091828208342, 0.0, 0.0, -1.389812576394971, 0.0, 0.0, 60.0, -24.643305208339868, 20.0, 0.0, 40.0, 20.0, -0.015714532531793113], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-6.443802532984201, 0.0, -20.244080459442415, 0.0, 0.0, 0.0, -52.83184252626749, -20.0, 0.0, -36.56061655782843, 0.0, -0.9629037079451375, 0.0, -5.607590452774332, 0.0, -10.651750984003696, -12.532888223308735, 0.0, -19.257930133687935, 0.0, 0.0, 0.0, -30.0, -2.0351770189275564, -4.147157458937896, -8.514687274071273, -72.9998851449249, -10.0, -15.966585251632813, 0.0, -28.854735146071384, -0.9640214185692086, -21.74943991256207, -20.0, 0.0, -30.0, -20.0, -16.53370041042567, 0.0, -30.28687415679442, 0.0, -20.0, 0.0, 0.0, -30.0, -4.213699279323457, 0.0, -0.3019558117393062, -15.146008311141072, 0.0, -15.825892709021963, -21.87667996334818, 0.0, -20.0, -10.0, -20.0, 0.0, 0.0, -9.57789693606534, -20.0, 0.0, -0.5303636258409761, -30.0, -3.9476882045634722, -20.0, -60.0, 0.0, -22.388069136989476, -20.0, -13.318246968542322, -20.580325670876874, 0.0, -20.0, -10.0, 0.0, 0.0, -0.3857919400713672, 0.0, -0.20354536373144327, 0.0, -30.0, -17.17245185637094, 0.0, -5.159803339623943, -0.7692103763945002, 0.0, 0.0, 0.0, -9.197974439560776, 0.0, 0.0, -7.851409661101362, 0.0, -16.85314605139422, 0.0, -3.71903592397199, -12.402250356728668, -10.0, -16.00696786580213, -30.0, -0.41950283204477135, -17.498236691980516, 0.0, -40.31436550891567, -1.016478389150277, 0.0, -1.8258530872909162, -3.3103186160723093, -2.451330295267902, 0.0, 0.0, 0.0, -26.762384378092445, 0.0, 0.0, -29.602245080309775, -10.0, -20.0, 0.0, -4.739486661652062, 0.0, 0.0, -2.001307828170229, -10.0, -39.73096908838358, -2.262433213344358, -0.20923756049907039, -0.576629908935079, -19.53003279026127, -30.0, -20.44370907594226, -36.64257412044766, 0.0, 0.0, -0.2336322814645908, 0.0, 0.0, -0.48031836594491284, -7.1735987935939605, -19.132531909187072, 0.0, -31.56225496852248, 0.0, -20.16658949723039, -46.09908171791658, 0.0, 0.0, -1.389812576394971, 0.0, 0.0, -30.0, -24.643305208339868, -10.0, 0.0, -20.0, -10.0, -0.015714532531793113]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6847573488272318, "mean_inference_ms": 1.1996283619749144, "mean_action_processing_ms": 0.2542611757363974, "mean_env_wait_ms": 0.5128155414768837, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004562147104056778, "StateBufferConnector_ms": 0.0032775720972923715, "ViewRequirementAgentConnector_ms": 0.08934106037115595}, "num_episodes": 157, "episode_return_max": 120.0, "episode_return_min": -24.643305208339868, "episode_return_mean": 10.22415275451433}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1072000, "num_agent_steps_trained": 1072000, "num_env_steps_sampled": 268000, "num_env_steps_trained": 268000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 340.03610169325947, "num_env_steps_trained_throughput_per_sec": 340.03610169325947, "timesteps_total": 268000, "num_env_steps_sampled_lifetime": 268000, "num_agent_steps_sampled_lifetime": 1072000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1072000, "timers": {"training_iteration_time_ms": 15398.605, "restore_workers_time_ms": 0.017, "training_step_time_ms": 15398.523, "sample_time_ms": 1310.454, "learn_time_ms": 14060.74, "learn_throughput": 284.48, "synch_weights_time_ms": 24.715}, "counters": {"num_env_steps_sampled": 268000, "num_env_steps_trained": 268000, "num_agent_steps_sampled": 1072000, "num_agent_steps_trained": 1072000}, "done": false, "training_iteration": 67, "trial_id": "86f16_00000", "date": "2024-08-08_16-28-48", "timestamp": 1723148928, "time_this_iter_s": 11.794476985931396, "time_total_s": 961.7071681022644, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3acdba700>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 961.7071681022644, "iterations_since_restore": 67, "perf": {"cpu_util_percent": 42.47647058823529, "ram_util_percent": 79.40588235294116}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.667455939166512, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.9724397340987592, "policy_loss": -0.01841685091564762, "vf_loss": 1.990118941897196, "vf_explained_var": -2.1161762535149323e-07, "kl": 0.007376405474242621, "entropy": 0.6310016253738538, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 190350.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.436790160710613, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.6403219766914843, "policy_loss": -0.022113670735173705, "vf_loss": 3.6607706593970457, "vf_explained_var": 0.14585773460566998, "kl": 0.008324904257609815, "entropy": 1.078599025743703, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 64800.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 272000, "num_env_steps_trained": 272000, "num_agent_steps_sampled": 1088000, "num_agent_steps_trained": 1088000}, "env_runners": {"episode_reward_max": 119.37151429583204, "episode_reward_min": -36.76236400056337, "episode_reward_mean": 15.732269033261774, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -75.85671071443602}, "policy_reward_max": {"adversary_policy": 60.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 9.444444444444445, "agent_policy": -12.60106430007156}, "custom_metrics": {}, "hist_stats": {"episode_reward": [20.0, -10.933968621985912, 0.0, 0.0, -0.32679807987525344, -2.0627684205578225, -6.885167415764106, 40.0, 40.0, 60.0, -24.753995375724987, 35.314595713490434, 20.0, 11.82350651075094, 0.0, 40.0, 0.0, -2.8776176675251, 19.469091278800228, 0.0, 0.0, 20.0, 0.0, 0.0, -10.27777726393789, 0.0, -22.911700618193468, -1.0703961946916407, 40.0, 76.10130487953056, 0.0, 17.925147036726493, 0.0, 7.1688634351983005, -2.978780950864202, 0.0, 0.0, 119.37151429583204, 0.0, -0.2288105906981741, -11.770406906903819, 38.183532361818024, 0.0, 79.10753306261245, 18.013988119644356, -5.447576023032869, 0.0, 0.0, -3.254138075134585, 0.0, 0.0, 0.0, 0.0, 0.0, 59.45882161155842, 57.352470222131785, 19.9810810412376, 0.0, 40.0, 0.0, 40.0, 19.790408191567753, 0.0, 40.0, -9.787254651775193, 0.0, 60.0, 40.0, 0.0, -0.8952021226868634, -0.1042132602094481, 0.0, -6.431572581133829, -1.5560766481339894, -27.414436331732574, 0.0, -11.946642000052996, 80.0, 0.0, 0.0, 15.53789932872764, -6.005544726058427, -0.19191658720301152, -13.48247866541931, 0.0, 78.7182116470257, 40.0, -12.477584800050481, -3.3794869131208465, -0.5773254570590614, -0.2080650596004774, 100.0, -22.35396189592892, -4.349162744971127, 40.0, 73.4269451774017, 0.0, 0.0, 100.0, 0.0, 15.63440521361304, 60.0, 16.30328787382441, -36.76236400056337, 0.0, -15.093627951646413, 60.0, 0.0, 20.0, 20.0, 39.79288605018395, 0.0, 20.0, 39.68512907185113, 17.807111605848, 0.0, 60.0, 0.0, -0.09011129231479953, 0.0, 0.0, -1.7986217995566838, -9.596352029527539, 0.0, 0.0, -28.29168395942955, 104.14328928556401, 99.85369330976525, 40.0, 99.85781197752432, -0.25080491939078575, 39.68983858524196, -3.365162596332093, 35.87707865303522, -26.906445846559837, 80.0, -13.752171889495006, -1.9046767537181994, 0.0, -3.439959397618543, -7.6264209422511895, 0.0, 0.0, 0.0, -2.605703918435781, 60.0, 20.0, 32.779093359746085, 40.0, 100.0, 0.0, 0.0, -3.454930993649654, -15.469816998730598, 0.0, 58.62344836929985, -2.965528134833992, 43.770151619762814, -1.6193454268264496, 20.0, 100.0, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-10.0, -10.933968621985912, 0.0, 0.0, -0.32679807987525344, -2.0627684205578225, -6.885167415764106, -20.0, -20.0, -30.0, -24.753995375724987, -24.685404286509566, -10.0, -18.17649348924906, 0.0, -20.0, 0.0, -2.8776176675251, -10.530908721199774, 0.0, 0.0, -10.0, 0.0, 0.0, -10.27777726393789, 0.0, -22.911700618193468, -1.0703961946916407, -20.0, -43.89869512046946, 0.0, -12.074852963273509, 0.0, -22.831136564801696, -2.978780950864202, 0.0, 0.0, -60.628485704167964, 0.0, -0.2288105906981741, -11.770406906903819, -21.816467638181987, 0.0, -40.89246693738756, -11.986011880355644, -5.447576023032869, 0.0, 0.0, -3.254138075134585, 0.0, 0.0, 0.0, 0.0, 0.0, -30.54117838844158, -32.647529777868215, -10.018918958762399, 0.0, -20.0, 0.0, -20.0, -10.20959180843225, 0.0, -20.0, -9.787254651775193, 0.0, -30.0, -20.0, 0.0, -0.8952021226868634, -0.1042132602094481, 0.0, -6.431572581133829, -1.5560766481339894, -27.414436331732574, 0.0, -11.946642000052996, -40.0, 0.0, 0.0, -14.462100671272362, -6.005544726058427, -0.19191658720301152, -13.48247866541931, 0.0, -41.28178835297431, -20.0, -12.477584800050481, -3.3794869131208465, -0.5773254570590614, -0.2080650596004774, -50.0, -22.35396189592892, -4.349162744971127, -20.0, -46.5730548225983, 0.0, 0.0, -50.0, 0.0, -14.36559478638696, -30.0, -13.69671212617559, -36.76236400056337, 0.0, -15.093627951646413, -30.0, 0.0, -10.0, -10.0, -20.207113949816044, 0.0, -10.0, -20.31487092814887, -12.192888394152003, 0.0, -30.0, 0.0, -0.09011129231479953, 0.0, 0.0, -1.7986217995566838, -9.596352029527539, 0.0, 0.0, -28.29168395942955, -75.85671071443602, -50.14630669023475, -20.0, -50.14218802247568, -0.25080491939078575, -20.310161414758042, -3.365162596332093, -24.122921346964784, -26.906445846559837, -40.0, -13.752171889495006, -1.9046767537181994, 0.0, -3.439959397618543, -7.6264209422511895, 0.0, 0.0, 0.0, -2.605703918435781, -30.0, -10.0, -27.220906640253904, -20.0, -50.0, 0.0, 0.0, -3.454930993649654, -15.469816998730598, 0.0, -31.376551630700153, -2.965528134833992, -46.229848380237186, -1.6193454268264496, -10.0, -50.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6849939290566031, "mean_inference_ms": 1.2001049043245207, "mean_action_processing_ms": 0.2540972283664305, "mean_env_wait_ms": 0.5129425197381654, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004644158445758584, "StateBufferConnector_ms": 0.003487460407209985, "ViewRequirementAgentConnector_ms": 0.10126122721919308}, "num_episodes": 162, "episode_return_max": 119.37151429583204, "episode_return_min": -36.76236400056337, "episode_return_mean": 15.732269033261774}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1088000, "num_agent_steps_trained": 1088000, "num_env_steps_sampled": 272000, "num_env_steps_trained": 272000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 333.23139421588695, "num_env_steps_trained_throughput_per_sec": 333.23139421588695, "timesteps_total": 272000, "num_env_steps_sampled_lifetime": 272000, "num_agent_steps_sampled_lifetime": 1088000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1088000, "timers": {"training_iteration_time_ms": 14945.872, "restore_workers_time_ms": 0.017, "training_step_time_ms": 14945.792, "sample_time_ms": 1314.227, "learn_time_ms": 13610.236, "learn_throughput": 293.896, "synch_weights_time_ms": 18.861}, "counters": {"num_env_steps_sampled": 272000, "num_env_steps_trained": 272000, "num_agent_steps_sampled": 1088000, "num_agent_steps_trained": 1088000}, "done": false, "training_iteration": 68, "trial_id": "86f16_00000", "date": "2024-08-08_16-29-00", "timestamp": 1723148940, "time_this_iter_s": 12.008334159851074, "time_total_s": 973.7155022621155, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3acf3d280>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 973.7155022621155, "iterations_since_restore": 68, "perf": {"cpu_util_percent": 38.57058823529412, "ram_util_percent": 78.49411764705883}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5856081122149389, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.5280401008771667, "policy_loss": -0.017565234010982995, "vf_loss": 1.544944961548697, "vf_explained_var": 3.3875306447347007e-07, "kl": 0.006603741585711809, "entropy": 0.6066386136074439, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 193170.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.3837043207138775, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.009403693303466, "policy_loss": -0.02225823756113338, "vf_loss": 3.029856395597259, "vf_explained_var": 0.09552987857411305, "kl": 0.009027639119986948, "entropy": 1.0894452666863799, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 65760.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 276000, "num_env_steps_trained": 276000, "num_agent_steps_sampled": 1104000, "num_agent_steps_trained": 1104000}, "env_runners": {"episode_reward_max": 140.0, "episode_reward_min": -37.84159638005743, "episode_reward_mean": 9.985913704763504, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -70.0}, "policy_reward_max": {"adversary_policy": 70.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 6.666666666666667, "agent_policy": -10.014086295236494}, "custom_metrics": {}, "hist_stats": {"episode_reward": [39.98720511007042, 0.0, 60.0, -1.7575712454245163, 20.0, 0.0, -1.0063959644897635, -1.300339935311876, 0.0, -1.3467286026070213, 0.0, 20.0, 20.0, 0.0, 0.0, -21.44419497152721, 0.0, -0.3817979632524726, 0.0, -15.701922151306174, 20.0, 60.0, 20.0, 60.0, -5.1283892190215, 35.381614446513915, 40.0, -0.6182493908421716, 60.0, -20.14996665132475, -0.1471038899692323, 0.0, 0.0, 60.0, 17.89952674308902, 3.229645057814974, 15.53056504881166, 34.930449422340395, 20.0, -0.9403659653860985, 20.0, -0.524438832297438, 0.0, 0.0, -23.29682935908116, 0.0, 0.0, -0.3382312122189046, 60.0, 20.0, -0.8238220791938966, 0.0, -2.2323806271820814, 0.0, 0.0, -1.4936702481178044, 59.679224759061654, -3.141836130802872, -17.770367555474635, 60.0, 40.0, -0.2964787913329314, 0.0, 39.20149569960522, 0.0, -5.811485491681427, 0.0, 57.686093695810584, 0.0, 18.673170403874984, 0.0, -1.0747130671676586, 40.0, -3.4920683467231504, -0.6841844166598032, -5.874394316120658, 20.0, 18.047580610354917, -2.718701652083122, -36.95807444528734, 0.0, -19.503780898965886, -22.030048319692334, 13.373529727854539, 22.957587127158845, 17.561188165443383, -0.02460383060439497, 0.0, -5.162798768929686, 14.719946896009633, 0.0, 0.0, 60.0, 0.0, -30.25018359334852, 15.644079919970402, 15.732741825041375, -4.005635488714716, 60.0, -6.272215540849215, 60.0, 0.0, 0.0, -0.05803001901560689, 0.0, 0.0, 20.0, 0.0, 40.0, 0.0, -5.916917788841698, 0.0, -37.84159638005743, 0.0, 20.0, 0.0, -6.360211131627244, -1.376861145373881, -1.1626268674002382, 20.0, 20.0, -0.18340462997716522, 0.0, -3.8498735019785855, -13.024489807448209, -5.153742981779955, -0.9610972106264726, 20.0, 60.0, 17.353893836927018, -6.441323905666165, 0.0, 43.10857967248191, 80.0, 0.0, -2.7495059434186375, 18.33670416937674, -16.474906235516066, 0.0, 0.0, 0.0, 0.0, 140.0, 0.0, -6.607604983452275, -5.429580863817886, 19.4621907743941, 60.0, 0.0, 19.995053977769636, -1.746996602841382, -20.87576498318957, -12.367442718312274, -0.11710233905365408, 0.0, 0.0, 40.0, 58.51621341162161, 0.0, -3.202509438574504, -3.6847018887475818, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-20.01279488992958, 0.0, -30.0, -1.7575712454245163, -10.0, 0.0, -1.0063959644897635, -1.300339935311876, 0.0, -1.3467286026070213, 0.0, -10.0, -10.0, 0.0, 0.0, -21.44419497152721, 0.0, -0.3817979632524726, 0.0, -15.701922151306174, -10.0, -30.0, -10.0, -30.0, -5.1283892190215, -24.61838555348609, -20.0, -0.6182493908421716, -30.0, -20.14996665132475, -0.1471038899692323, 0.0, 0.0, -30.0, -12.100473256910979, -26.770354942185026, -14.46943495118834, -25.069550577659598, -10.0, -0.9403659653860985, -10.0, -0.524438832297438, 0.0, 0.0, -23.29682935908116, 0.0, 0.0, -0.3382312122189046, -30.0, -10.0, -0.8238220791938966, 0.0, -2.2323806271820814, 0.0, 0.0, -1.4936702481178044, -30.32077524093835, -3.141836130802872, -17.770367555474635, -30.0, -20.0, -0.2964787913329314, 0.0, -20.798504300394782, 0.0, -5.811485491681427, 0.0, -32.313906304189416, 0.0, -11.326829596125016, 0.0, -1.0747130671676586, -20.0, -3.4920683467231504, -0.6841844166598032, -5.874394316120658, -10.0, -11.952419389645083, -2.718701652083122, -36.95807444528734, 0.0, -49.50378089896589, -22.030048319692334, -16.62647027214546, -37.042412872841155, -12.438811834556615, -0.02460383060439497, 0.0, -5.162798768929686, -15.280053103990369, 0.0, 0.0, -30.0, 0.0, -30.25018359334852, -14.355920080029602, -14.267258174958627, -4.005635488714716, -30.0, -6.272215540849215, -30.0, 0.0, 0.0, -0.05803001901560689, 0.0, 0.0, -10.0, 0.0, -20.0, 0.0, -5.916917788841698, 0.0, -37.84159638005743, 0.0, -10.0, 0.0, -6.360211131627244, -1.376861145373881, -1.1626268674002382, -10.0, -10.0, -0.18340462997716522, 0.0, -3.8498735019785855, -13.024489807448209, -5.153742981779955, -0.9610972106264726, -10.0, -30.0, -12.646106163072982, -6.441323905666165, 0.0, -46.891420327518084, -40.0, 0.0, -2.7495059434186375, -11.66329583062326, -16.474906235516066, 0.0, 0.0, 0.0, 0.0, -70.0, 0.0, -6.607604983452275, -5.429580863817886, -10.5378092256059, -30.0, 0.0, -10.004946022230364, -1.746996602841382, -20.87576498318957, -12.367442718312274, -0.11710233905365408, 0.0, 0.0, -20.0, -31.4837865883784, 0.0, -3.202509438574504, -3.6847018887475818, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.683752795474633, "mean_inference_ms": 1.1976609948907164, "mean_action_processing_ms": 0.2535258856083717, "mean_env_wait_ms": 0.5121051733481408, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004899575386518314, "StateBufferConnector_ms": 0.0032070242328408323, "ViewRequirementAgentConnector_ms": 0.08736848831176758}, "num_episodes": 162, "episode_return_max": 140.0, "episode_return_min": -37.84159638005743, "episode_return_mean": 9.985913704763504}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1104000, "num_agent_steps_trained": 1104000, "num_env_steps_sampled": 276000, "num_env_steps_trained": 276000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 347.88120328147465, "num_env_steps_trained_throughput_per_sec": 347.88120328147465, "timesteps_total": 276000, "num_env_steps_sampled_lifetime": 276000, "num_agent_steps_sampled_lifetime": 1104000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1104000, "timers": {"training_iteration_time_ms": 14181.937, "restore_workers_time_ms": 0.017, "training_step_time_ms": 14181.882, "sample_time_ms": 1278.651, "learn_time_ms": 12883.727, "learn_throughput": 310.469, "synch_weights_time_ms": 18.027}, "counters": {"num_env_steps_sampled": 276000, "num_env_steps_trained": 276000, "num_agent_steps_sampled": 1104000, "num_agent_steps_trained": 1104000}, "done": false, "training_iteration": 69, "trial_id": "86f16_00000", "date": "2024-08-08_16-29-12", "timestamp": 1723148952, "time_this_iter_s": 11.502786874771118, "time_total_s": 985.2182891368866, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad1c8160>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 985.2182891368866, "iterations_since_restore": 69, "perf": {"cpu_util_percent": 33.65, "ram_util_percent": 77.80625}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6544603472905801, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.8338878579173528, "policy_loss": -0.019093805505623316, "vf_loss": 1.852282801376167, "vf_explained_var": 7.509128421756392e-07, "kl": 0.006988634972477643, "entropy": 0.6048597641659121, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 195990.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.431575709457199, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.1416495528072117, "policy_loss": -0.029150057619942042, "vf_loss": 3.1683696820090215, "vf_explained_var": 0.1066540806243817, "kl": 0.012149577978147728, "entropy": 1.0998818089564641, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 66720.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 280000, "num_env_steps_trained": 280000, "num_agent_steps_sampled": 1120000, "num_agent_steps_trained": 1120000}, "env_runners": {"episode_reward_max": 160.0, "episode_reward_min": -26.92853312791306, "episode_reward_mean": 12.833533282592922, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -80.0}, "policy_reward_max": {"adversary_policy": 80.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 7.839506172839506, "agent_policy": -10.684985235925597}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-7.932952657599703, -2.924478524556452, 0.0, -2.6788522551271026, -2.967339500166701, 19.172492228483666, -24.382340976003643, -4.271128437856445, 0.0, 0.0, -4.100021511374673, 39.487191048416264, 120.0, 0.0, 20.0, 0.0, 59.35524471609614, 0.0, 0.0, 20.0, 20.0, -3.8603241779337765, 0.0, 0.0, -0.38560538854282567, -0.2838181295261777, 0.0, 16.384996988481582, -7.495725466404887, 0.0, -0.1696602538361558, -1.62145369605051, 0.0, -24.340361974163816, 14.068254976232232, 4.251785309281436, 0.0, 0.0, 13.581788355758121, 0.0, -12.510203211963269, -8.308470521863006, -9.900344037888267, -3.164315355957781, 0.0, 0.0, -1.3771634355504592, 55.58129436599289, 60.0, 14.302905478119555, 0.0, -1.1226170802191615, 40.0, 60.0, 20.0, 0.0, 0.0, 0.0, 20.0, 0.0, -6.609992765450196, -7.109570681519115, -2.092627947946614, 0.0, 58.697569547445596, 0.0, -4.467749816593084, -22.67404143096318, 0.0, 60.0, -10.788481476589073, -1.2861462594918902, 7.673569398684188, 100.0, 100.0, 20.0, 0.0, 60.0, -3.3628390132925023, 0.0, -12.090078566485976, 0.0, 60.0, 0.0, 0.0, 20.0, 18.065619961222396, 0.0, 0.0, 40.0, 0.0, 14.002511661318557, 0.0, 86.73258363820925, -0.05631939769961347, 0.0, 60.0, 0.0, -2.6995829258269177, 0.0, 97.49312568773955, -11.841087011697757, 160.0, 0.0, -0.7641409347865802, 0.0, -17.947735866790016, 0.0, -1.9967840683636113, 17.556684730942468, 0.0, 0.0, -8.181202208538107, -3.6330663309559483, 80.0, 0.0, 0.0, 0.0, -0.6823113006160786, -6.50888898196219, -22.763938143052926, 77.60404863732548, 0.0, 0.0, 53.821770843370786, 77.7150343143367, 40.0, -1.3199045856735625, 40.0, 20.0, 0.0, -0.8916706332404822, 0.0, 0.0, 40.0, -10.341615352886341, 0.0, 80.0, 0.0, -10.403024526424872, 0.0, -1.8235899077167415, -26.92853312791306, 38.797884876873354, 0.0, 0.0, 0.0, 12.374441838724076, 0.0, 0.0, 39.14147571025029, 0.0, 40.0, 0.0, -1.3481524047074867, 0.0, 52.449410740058795, 0.0, 79.48072686831023, 0.0, 40.0, -4.34976788185171], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 80.0, 80.0, 80.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-7.932952657599703, -2.924478524556452, 0.0, -2.6788522551271026, -2.967339500166701, -10.827507771516338, -24.382340976003643, -4.271128437856445, 0.0, 0.0, -4.100021511374673, -20.512808951583736, -60.0, 0.0, -10.0, 0.0, -30.644755283903862, 0.0, 0.0, -10.0, -10.0, -3.8603241779337765, 0.0, 0.0, -0.38560538854282567, -0.2838181295261777, 0.0, -13.615003011518418, -7.495725466404887, 0.0, -0.1696602538361558, -1.62145369605051, 0.0, -24.340361974163816, -15.931745023767768, -25.748214690718566, 0.0, 0.0, -16.418211644241882, 0.0, -12.510203211963269, -8.308470521863006, -9.900344037888267, -3.164315355957781, 0.0, 0.0, -1.3771634355504592, -34.41870563400711, -30.0, -15.697094521880445, 0.0, -1.1226170802191615, -20.0, -30.0, -10.0, 0.0, 0.0, 0.0, -10.0, 0.0, -6.609992765450196, -7.109570681519115, -2.092627947946614, 0.0, -31.30243045255441, 0.0, -4.467749816593084, -22.67404143096318, 0.0, -30.0, -10.788481476589073, -31.286146259491893, -22.326430601315813, -50.0, -50.0, -10.0, 0.0, -30.0, -3.3628390132925023, 0.0, -12.090078566485976, 0.0, -30.0, 0.0, 0.0, -10.0, -11.934380038777606, 0.0, 0.0, -20.0, 0.0, -15.997488338681443, 0.0, -63.26741636179075, -0.05631939769961347, 0.0, -30.0, 0.0, -2.6995829258269177, 0.0, -52.50687431226044, -11.841087011697757, -80.0, 0.0, -0.7641409347865802, 0.0, -17.947735866790016, 0.0, -1.9967840683636113, -12.443315269057532, 0.0, 0.0, -8.181202208538107, -3.6330663309559483, -40.0, 0.0, 0.0, 0.0, -0.6823113006160786, -6.50888898196219, -22.763938143052926, -42.39595136267452, 0.0, 0.0, -36.178229156629214, -42.284965685663295, -20.0, -1.3199045856735625, -20.0, -10.0, 0.0, -0.8916706332404822, 0.0, 0.0, -20.0, -10.341615352886341, 0.0, -40.0, 0.0, -10.403024526424872, 0.0, -1.8235899077167415, -26.92853312791306, -21.202115123126653, 0.0, 0.0, 0.0, -17.625558161275922, 0.0, 0.0, -20.858524289749706, 0.0, -20.0, 0.0, -1.3481524047074867, 0.0, -37.550589259941205, 0.0, -40.519273131689765, 0.0, -20.0, -4.34976788185171]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6832567829434414, "mean_inference_ms": 1.1965761888157498, "mean_action_processing_ms": 0.2530743370710588, "mean_env_wait_ms": 0.5117514348790377, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004836953716513551, "StateBufferConnector_ms": 0.0033055558616732375, "ViewRequirementAgentConnector_ms": 0.094945416038419}, "num_episodes": 162, "episode_return_max": 160.0, "episode_return_min": -26.92853312791306, "episode_return_mean": 12.833533282592922}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1120000, "num_agent_steps_trained": 1120000, "num_env_steps_sampled": 280000, "num_env_steps_trained": 280000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 350.2482822721391, "num_env_steps_trained_throughput_per_sec": 350.2482822721391, "timesteps_total": 280000, "num_env_steps_sampled_lifetime": 280000, "num_agent_steps_sampled_lifetime": 1120000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1120000, "timers": {"training_iteration_time_ms": 13818.021, "restore_workers_time_ms": 0.014, "training_step_time_ms": 13817.975, "sample_time_ms": 1262.631, "learn_time_ms": 12536.279, "learn_throughput": 319.074, "synch_weights_time_ms": 17.617}, "counters": {"num_env_steps_sampled": 280000, "num_env_steps_trained": 280000, "num_agent_steps_sampled": 1120000, "num_agent_steps_trained": 1120000}, "done": false, "training_iteration": 70, "trial_id": "86f16_00000", "date": "2024-08-08_16-29-23", "timestamp": 1723148963, "time_this_iter_s": 11.42474913597107, "time_total_s": 996.6430382728577, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad1c83a0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 996.6430382728577, "iterations_since_restore": 70, "perf": {"cpu_util_percent": 32.641176470588235, "ram_util_percent": 77.19999999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.637569092615699, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.3778143821455906, "policy_loss": -0.017789170620896928, "vf_loss": 2.3949837469462807, "vf_explained_var": 2.284844716389974e-08, "kl": 0.006198044711325887, "entropy": 0.594930958388545, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 198810.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.4880366419752438, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.5418977153797946, "policy_loss": -0.02286620864494277, "vf_loss": 3.5627313826233147, "vf_explained_var": 0.0886379266778628, "kl": 0.010162672729210639, "entropy": 1.0776561894143621, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 67680.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 284000, "num_env_steps_trained": 284000, "num_agent_steps_sampled": 1136000, "num_agent_steps_trained": 1136000}, "env_runners": {"episode_reward_max": 140.0, "episode_reward_min": -19.822430452094558, "episode_reward_mean": 16.58906254582917, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 153, "episodes_timesteps_total": 3825, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -70.0}, "policy_reward_max": {"adversary_policy": 70.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 9.411764705882353, "agent_policy": -11.646231571817891}, "custom_metrics": {}, "hist_stats": {"episode_reward": [8.037707036216228, -4.033680362614071, 40.0, 0.0, 27.880718050008355, 0.0, 0.0, -9.611699906701359, -1.2601101217886956, -0.48946858156748263, 0.0, 60.0, 120.0, 0.0, 80.0, 140.0, 0.0, 16.8719162411619, 100.0, 0.0, 120.0, 0.0, 0.0, 17.074334675536793, -1.6901820168888515, 20.0, 0.0, 20.0, 0.0, 0.0, 10.948131723448764, -1.1954880890376096, 0.0, 40.0, -1.1837899763273485, -5.726607990254756, 20.0, 0.0, 0.0, -4.392865162256763, 31.837383157522197, 20.0, 20.0, -5.441426768329668, 20.0, 0.0, 0.0, -13.599165492540573, 0.0, 0.0, -0.05339499647815105, -3.393944105625926, 0.0, 79.60944955782128, -4.403995303983521, 40.0, 60.0, 19.04781764770875, 40.0, 20.0, 20.0, -5.742334403348984, 0.0, 0.0, 60.0, 0.0, 20.0, 0.0, -0.1916904487138804, 58.09300540339771, 0.0, 0.0, -8.665388434580056, 36.112571138271356, 0.0, -19.822430452094558, -1.7288869841550558, -13.66843678952414, 70.19839553100188, 0.0, -15.1496999445122, -3.398029963954011, 0.0, -0.53061694390791, 80.0, 17.713494877189177, 17.99681643545328, 0.0, 20.0, 20.0, 34.315434755072495, 0.0, 20.0, 19.91237917456912, 0.0, 18.99536626210961, 0.0, 13.226970579425466, 40.0, 20.0, -2.0534924718120093, -0.8099751244524112, 0.0, 40.0, 20.0, 37.89241531024501, -0.5735783390918203, 20.0, 0.0, 36.497369442783636, 0.0, -0.5703693804008936, -9.06894470779909, 80.0, 60.0, 0.0, 20.0, 17.520661066842653, 17.09165683988772, 0.0, -0.5449744140344182, 10.23899995226245, -4.3907688668678775, 0.0, 51.588633904952225, -7.781699641124565, 59.27036263963085, 20.0, 0.0, 39.76887667910664, -7.712774154076437, 40.0, 0.0, -1.2667827908453955, 0.0, 28.32197017444669, 0.0, 53.28993766809246, 0.0, 0.0, -1.3250330763860307, 87.56358366008712, 13.69057108687175, 0.0, -10.43991554640063, 99.8321407965161, 0.0, 40.0, 20.0, 0.0, -0.40086020329988203, 20.0, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-21.962292963783778, -4.033680362614071, -20.0, 0.0, -32.119281949991645, 0.0, 0.0, -9.611699906701359, -1.2601101217886956, -0.48946858156748263, 0.0, -30.0, -60.0, 0.0, -40.0, -70.0, 0.0, -13.128083758838093, -50.0, 0.0, -60.0, 0.0, 0.0, -12.925665324463207, -1.6901820168888515, -10.0, 0.0, -10.0, 0.0, 0.0, -19.05186827655124, -1.1954880890376096, 0.0, -20.0, -1.1837899763273485, -5.726607990254756, -10.0, 0.0, 0.0, -4.392865162256763, -28.16261684247781, -10.0, -10.0, -5.441426768329668, -10.0, 0.0, 0.0, -13.599165492540573, 0.0, 0.0, -0.05339499647815105, -3.393944105625926, 0.0, -40.39055044217872, -4.403995303983521, -20.0, -30.0, -10.952182352291246, -20.0, -10.0, -10.0, -5.742334403348984, 0.0, 0.0, -30.0, 0.0, -10.0, 0.0, -0.1916904487138804, -31.906994596602292, 0.0, 0.0, -8.665388434580056, -23.887428861728644, 0.0, -19.822430452094558, -1.7288869841550558, -13.66843678952414, -49.80160446899812, 0.0, -15.1496999445122, -3.398029963954011, 0.0, -0.53061694390791, -40.0, -12.286505122810821, -12.003183564546717, 0.0, -10.0, -10.0, -25.684565244927523, 0.0, -10.0, -10.087620825430879, 0.0, -41.00463373789038, 0.0, -16.773029420574538, -20.0, -10.0, -2.0534924718120093, -0.8099751244524112, 0.0, -20.0, -10.0, -22.107584689754987, -0.5735783390918203, -10.0, 0.0, -23.502630557216364, 0.0, -0.5703693804008936, -9.06894470779909, -40.0, -30.0, 0.0, -10.0, -12.47933893315735, -12.908343160112285, 0.0, -0.5449744140344182, -19.76100004773755, -4.3907688668678775, 0.0, -38.411366095047775, -7.781699641124565, -30.729637360369153, -10.0, 0.0, -20.23112332089336, -7.712774154076437, -20.0, 0.0, -1.2667827908453955, 0.0, -31.67802982555331, 0.0, -36.710062331907544, 0.0, 0.0, -1.3250330763860307, -62.43641633991288, -16.309428913128258, 0.0, -10.43991554640063, -50.1678592034839, 0.0, -20.0, -10.0, 0.0, -0.40086020329988203, -10.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6833208304542908, "mean_inference_ms": 1.1969741449563087, "mean_action_processing_ms": 0.25300351296301915, "mean_env_wait_ms": 0.5120653863111394, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004607166340148527, "StateBufferConnector_ms": 0.0034104764851090176, "ViewRequirementAgentConnector_ms": 0.1041522992202659}, "num_episodes": 153, "episode_return_max": 140.0, "episode_return_min": -19.822430452094558, "episode_return_mean": 16.58906254582917}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1136000, "num_agent_steps_trained": 1136000, "num_env_steps_sampled": 284000, "num_env_steps_trained": 284000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 305.79538868240627, "num_env_steps_trained_throughput_per_sec": 305.79538868240627, "timesteps_total": 284000, "num_env_steps_sampled_lifetime": 284000, "num_agent_steps_sampled_lifetime": 1136000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1136000, "timers": {"training_iteration_time_ms": 13946.336, "restore_workers_time_ms": 0.014, "training_step_time_ms": 13946.291, "sample_time_ms": 1276.464, "learn_time_ms": 12650.441, "learn_throughput": 316.195, "synch_weights_time_ms": 17.939}, "counters": {"num_env_steps_sampled": 284000, "num_env_steps_trained": 284000, "num_agent_steps_sampled": 1136000, "num_agent_steps_trained": 1136000}, "done": false, "training_iteration": 71, "trial_id": "86f16_00000", "date": "2024-08-08_16-29-37", "timestamp": 1723148977, "time_this_iter_s": 13.108588695526123, "time_total_s": 1009.7516269683838, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad1c84c0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1009.7516269683838, "iterations_since_restore": 71, "perf": {"cpu_util_percent": 44.88947368421052, "ram_util_percent": 78.14736842105262}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.57317821200118, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.0252223909323943, "policy_loss": -0.017834245096908632, "vf_loss": 2.042340794860894, "vf_explained_var": -4.184372881625561e-07, "kl": 0.007158340036006371, "entropy": 0.5965577088032209, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 201630.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.4448167068262894, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.505398596699039, "policy_loss": -0.024395473621795342, "vf_loss": 3.528070443868637, "vf_explained_var": 0.0781983757391572, "kl": 0.008618127983314138, "entropy": 1.0926703887681166, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 68640.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 288000, "num_env_steps_trained": 288000, "num_agent_steps_sampled": 1152000, "num_agent_steps_trained": 1152000}, "env_runners": {"episode_reward_max": 168.48414342917116, "episode_reward_min": -65.73433753244908, "episode_reward_mean": 13.78865634883448, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -101.51585657082884}, "policy_reward_max": {"adversary_policy": 90.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 8.82716049382716, "agent_policy": -12.692825132647002}, "custom_metrics": {}, "hist_stats": {"episode_reward": [9.402665545350587, 40.0, 40.0, 0.0, 40.0, -0.5224954460013287, 36.55652188228348, 0.0, 20.0, -0.6241176366531342, 40.0, 0.0, 80.0, 0.0, -7.866179917253729, 55.781803879169, 20.0, 0.0, -22.896140871174325, 0.0, 10.47930651250748, -16.847091301310833, 0.0, 60.0, 20.0, 20.0, 20.0, -12.324415388943471, 40.0, 60.0, -20.098858084019657, -0.6001951861901911, 20.0, 0.0, 0.0, 0.0, 10.07893164614434, 0.0, 0.0, -6.043562903534796, 59.40968520102567, 0.0, 0.0, -11.757568325804453, 60.0, 0.0, -1.1605585567219001, 40.0, -2.3895624100614707, 20.0, 0.0, 40.0, -7.148116903701721, 20.0, 80.0, 40.0, 80.0, 53.97863624844786, -0.14563373317264428, -11.269001975655657, -1.913781791186998, 0.0, 80.0, -10.5939321133643, 0.0, 0.0, -0.32649875813195894, 40.0, -0.02083583375034892, 20.0, 168.48414342917116, 0.0, 20.0, -2.9613277641886557, 19.686498685257263, -1.7372297210243137, -8.640711529959024, -29.334707845691224, 0.0, 20.0, 0.0, 40.0, -9.86082883315744, -0.15485674934516913, -0.3190281417169527, 0.0, 39.46803449120651, 0.0, 40.0, 40.0, 0.0, -0.979441790059582, 60.0, 0.0, -2.303674380171752, -1.1857648670171073, -0.10530203955127715, -13.068430351044368, -0.5021736326015847, -11.846363740442552, 20.0, -9.040629155996186, -1.8938281040137384, 0.0, -18.414064218103434, 0.0, 20.0, 40.0, 0.0, -14.673431903699816, 20.0, 0.0, -0.21256486369995442, 91.18252854271846, 20.0, 0.0, -1.8146178972007887, -46.0828161585641, 0.0, -1.2039105670341232, -6.423429129444871, -0.8936152577802192, 80.0, 40.0, -2.6219464580007954, -65.73433753244908, 40.0, 27.07550776384302, -0.9003417093285537, -13.09349123186883, 9.141041485370387, 0.0, 38.16496582939151, 32.852307501951884, 0.0, 99.9786730762527, -0.5922475014157957, 0.0, -1.5081157341614726, 40.0, 20.0, 0.0, 0.0, 3.2759229514486643, 19.98779588888285, 39.59585947385903, 59.199436843764325, 14.522260259699998, 40.0, -1.117244821542852, 18.427325894813848, -9.871758457207676, -1.5706837377870941, -0.4752042497288378, 0.0, 54.647310413584805, -4.667875686486092, -14.052643815682567, -2.657216775729246, -0.3919632542555329, 80.0, -20.158468191173156], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 90.0, 90.0, 90.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-20.597334454649413, -20.0, -20.0, 0.0, -20.0, -0.5224954460013287, -23.443478117716527, 0.0, -10.0, -0.6241176366531342, -20.0, 0.0, -40.0, 0.0, -7.866179917253729, -34.218196120831, -10.0, 0.0, -22.896140871174325, 0.0, -19.520693487492522, -16.847091301310833, 0.0, -30.0, -10.0, -10.0, -10.0, -12.324415388943471, -20.0, -30.0, -20.098858084019657, -0.6001951861901911, -10.0, 0.0, 0.0, 0.0, -19.92106835385566, 0.0, 0.0, -36.0435629035348, -30.590314798974326, 0.0, 0.0, -11.757568325804453, -30.0, 0.0, -1.1605585567219001, -20.0, -2.3895624100614707, -10.0, 0.0, -20.0, -7.148116903701721, -10.0, -40.0, -20.0, -40.0, -36.021363751552144, -0.14563373317264428, -11.269001975655657, -1.913781791186998, 0.0, -40.0, -10.5939321133643, 0.0, 0.0, -0.32649875813195894, -20.0, -0.02083583375034892, -10.0, -101.51585657082884, 0.0, -10.0, -2.9613277641886557, -10.313501314742737, -1.7372297210243137, -8.640711529959024, -29.334707845691224, 0.0, -10.0, 0.0, -20.0, -9.86082883315744, -0.15485674934516913, -0.3190281417169527, 0.0, -20.53196550879349, 0.0, -20.0, -20.0, 0.0, -0.979441790059582, -30.0, 0.0, -2.303674380171752, -1.1857648670171073, -0.10530203955127715, -13.068430351044368, -0.5021736326015847, -11.846363740442552, -10.0, -9.040629155996186, -1.8938281040137384, 0.0, -18.414064218103434, 0.0, -10.0, -20.0, 0.0, -14.673431903699816, -10.0, 0.0, -0.21256486369995442, -58.81747145728155, -10.0, 0.0, -1.8146178972007887, -46.0828161585641, 0.0, -1.2039105670341232, -6.423429129444871, -0.8936152577802192, -40.0, -20.0, -2.6219464580007954, -65.73433753244908, -20.0, -32.924492236156986, -0.9003417093285537, -13.09349123186883, -50.85895851462962, 0.0, -21.835034170608488, -27.14769249804811, 0.0, -50.02132692374729, -0.5922475014157957, 0.0, -1.5081157341614726, -20.0, -10.0, 0.0, 0.0, -26.724077048551344, -10.01220411111715, -20.404140526140964, -30.80056315623568, -15.477739740300002, -20.0, -1.117244821542852, -11.572674105186154, -9.871758457207676, -1.5706837377870941, -0.4752042497288378, 0.0, -35.35268958641518, -4.667875686486092, -14.052643815682567, -2.657216775729246, -0.3919632542555329, -40.0, -20.158468191173156]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6830579522954586, "mean_inference_ms": 1.1960900911767227, "mean_action_processing_ms": 0.25272490794629254, "mean_env_wait_ms": 0.5118001155766351, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005044613355471764, "StateBufferConnector_ms": 0.0034291067241150656, "ViewRequirementAgentConnector_ms": 0.09908712940451539}, "num_episodes": 162, "episode_return_max": 168.48414342917116, "episode_return_min": -65.73433753244908, "episode_return_mean": 13.78865634883448}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1152000, "num_agent_steps_trained": 1152000, "num_env_steps_sampled": 288000, "num_env_steps_trained": 288000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 346.72113227244, "num_env_steps_trained_throughput_per_sec": 346.72113227244, "timesteps_total": 288000, "num_env_steps_sampled_lifetime": 288000, "num_agent_steps_sampled_lifetime": 1152000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1152000, "timers": {"training_iteration_time_ms": 13827.6, "restore_workers_time_ms": 0.014, "training_step_time_ms": 13827.556, "sample_time_ms": 1282.611, "learn_time_ms": 12527.501, "learn_throughput": 319.298, "synch_weights_time_ms": 16.021}, "counters": {"num_env_steps_sampled": 288000, "num_env_steps_trained": 288000, "num_agent_steps_sampled": 1152000, "num_agent_steps_trained": 1152000}, "done": false, "training_iteration": 72, "trial_id": "86f16_00000", "date": "2024-08-08_16-29-48", "timestamp": 1723148988, "time_this_iter_s": 11.540776014328003, "time_total_s": 1021.2924029827118, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad1c88b0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1021.2924029827118, "iterations_since_restore": 72, "perf": {"cpu_util_percent": 33.5, "ram_util_percent": 77.8125}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6084503499434349, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.3928642043407926, "policy_loss": -0.018045706380394384, "vf_loss": 1.4102208924420336, "vf_explained_var": 5.825825616823021e-07, "kl": 0.006890158188683319, "entropy": 0.5776854964646887, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 204450.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.6431775448222954, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.2599240516622863, "policy_loss": -0.02590201674514295, "vf_loss": 3.283844987799724, "vf_explained_var": 0.11347895128031572, "kl": 0.009905423850482957, "entropy": 1.0601688150316477, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 69600.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 292000, "num_env_steps_trained": 292000, "num_agent_steps_sampled": 1168000, "num_agent_steps_trained": 1168000}, "env_runners": {"episode_reward_max": 160.0, "episode_reward_min": -46.23198551783003, "episode_reward_mean": 10.333458586867007, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -80.0}, "policy_reward_max": {"adversary_policy": 80.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 7.037037037037037, "agent_policy": -10.777652524244104}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-5.6333641312133995, 0.0, -13.2401597861799, -0.5934908365602953, 0.0, -5.122702632490606, 0.0, 0.0, 40.0, -11.266713730310803, 20.0, 0.0, -3.416819556326382, 0.0, -0.06946841814603255, 20.0, 40.0, -0.2386346138226625, 62.989171800036544, -8.850425488626325, -10.81758073772793, 0.0, 80.0, 0.0, 0.0, 0.0, -8.466219471704346, 0.0, 0.0, 0.0, 0.0, -12.502574720433403, -46.23198551783003, -1.5019235455238666, 16.763978916855724, 0.0, 0.0, 0.0, 20.0, -13.382813194220613, 20.0, 0.0, -0.43747640154462974, 0.0, 0.0, -2.5898943973013786, 0.0, -4.881396357446215, 39.69441089195419, -36.61568165910088, 0.0, 40.0, -7.919005179991257, 40.0, 78.70008535446375, 0.0, -20.17759931417704, 80.0, -1.8848483677597672, 0.0, 0.0, -6.3191539104075565, -6.746337097812309, 0.0, 160.0, -10.271554281741341, 0.0, 20.0, 15.15050045654295, 0.0, 0.0, 0.0, 0.0, -8.415167376921767, 56.62791105948305, 0.0, -9.859265748269351, 60.0, -1.7776739968704913, -0.23329508766680163, 0.0, 35.440019852346346, -3.079466502944965, 0.0, 0.0, 56.34704273389529, 58.027770131948095, -15.578601552628292, 20.0, 47.11087924745065, -31.629836229830147, 0.0, 0.0, 0.0, 0.0, 58.49365430748699, 14.108648285363328, -12.990216666569063, -9.281923525047088, 0.0, 0.0, 0.0, 0.0, 19.080882390020427, 0.0, -20.68431068052915, 40.0, 58.38729731145586, -8.750931907708862, -0.37475175857090925, 0.0, 0.0, -0.01263017306087022, 0.0, 40.0, 11.848559738650163, 0.0, 60.0, -19.423953415619273, 0.0, 0.0, 40.0, 0.0, -0.0766537691819058, -1.9322325741930868, 80.0, 39.55133641442632, 0.0, -1.6808066939216915, 100.0, 40.0, -14.567487940016147, 80.0, 80.0, -7.937267675041411, 20.0, -15.736993255107492, 40.0, -10.73927106778247, 60.0, 0.0, -10.198158377972824, -0.3215134234189565, 0.0, 0.0, -21.276115325926455, 60.0, 0.0, 0.0, -13.651304404658426, -17.104182330705726, -8.737306882208008, -11.870921454881186, 0.0, 0.0, 0.0, 0.0, 79.36119830879896, -16.425524424484088, -0.13746855858751128, 60.0, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 80.0, 80.0, 80.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-5.6333641312133995, 0.0, -13.2401597861799, -0.5934908365602953, 0.0, -5.122702632490606, 0.0, 0.0, -20.0, -11.266713730310803, -10.0, 0.0, -3.416819556326382, 0.0, -0.06946841814603255, -10.0, -20.0, -0.2386346138226625, -57.01082819996346, -8.850425488626325, -10.81758073772793, 0.0, -40.0, 0.0, 0.0, 0.0, -8.466219471704346, 0.0, 0.0, 0.0, 0.0, -12.502574720433403, -46.23198551783003, -1.5019235455238666, -13.236021083144275, 0.0, 0.0, 0.0, -10.0, -13.382813194220613, -10.0, 0.0, -0.43747640154462974, 0.0, 0.0, -2.5898943973013786, 0.0, -4.881396357446215, -20.305589108045808, -36.61568165910088, 0.0, -20.0, -7.919005179991257, -20.0, -41.29991464553625, 0.0, -20.17759931417704, -40.0, -1.8848483677597672, 0.0, 0.0, -6.3191539104075565, -6.746337097812309, 0.0, -80.0, -10.271554281741341, 0.0, -10.0, -14.84949954345705, 0.0, 0.0, 0.0, 0.0, -8.415167376921767, -33.37208894051695, 0.0, -9.859265748269351, -30.0, -1.7776739968704913, -0.23329508766680163, 0.0, -24.559980147653654, -3.079466502944965, 0.0, 0.0, -33.65295726610471, -31.972229868051908, -15.578601552628292, -10.0, -42.88912075254935, -31.629836229830147, 0.0, 0.0, 0.0, 0.0, -31.506345692513015, -15.891351714636672, -12.990216666569063, -9.281923525047088, 0.0, 0.0, 0.0, 0.0, -10.919117609979576, 0.0, -20.68431068052915, -20.0, -31.612702688544147, -8.750931907708862, -0.37475175857090925, 0.0, 0.0, -0.01263017306087022, 0.0, -20.0, -18.151440261349837, 0.0, -30.0, -19.423953415619273, 0.0, 0.0, -20.0, 0.0, -0.0766537691819058, -1.9322325741930868, -40.0, -20.448663585573673, 0.0, -1.6808066939216915, -50.0, -20.0, -14.567487940016147, -40.0, -40.0, -7.937267675041411, -10.0, -15.736993255107492, -20.0, -10.73927106778247, -30.0, 0.0, -10.198158377972824, -0.3215134234189565, 0.0, 0.0, -21.276115325926455, -30.0, 0.0, 0.0, -13.651304404658426, -17.104182330705726, -8.737306882208008, -11.870921454881186, 0.0, 0.0, 0.0, 0.0, -40.63880169120104, -16.425524424484088, -0.13746855858751128, -30.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6827319614989003, "mean_inference_ms": 1.1954043610399077, "mean_action_processing_ms": 0.25234223194904326, "mean_env_wait_ms": 0.5115519376167671, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005290611290637358, "StateBufferConnector_ms": 0.0033989364718213493, "ViewRequirementAgentConnector_ms": 0.09488772462915492}, "num_episodes": 162, "episode_return_max": 160.0, "episode_return_min": -46.23198551783003, "episode_return_mean": 10.333458586867007}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1168000, "num_agent_steps_trained": 1168000, "num_env_steps_sampled": 292000, "num_env_steps_trained": 292000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 308.5069101385021, "num_env_steps_trained_throughput_per_sec": 308.5069101385021, "timesteps_total": 292000, "num_env_steps_sampled_lifetime": 292000, "num_agent_steps_sampled_lifetime": 1168000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1168000, "timers": {"training_iteration_time_ms": 13520.023, "restore_workers_time_ms": 0.014, "training_step_time_ms": 13519.978, "sample_time_ms": 1256.29, "learn_time_ms": 12247.22, "learn_throughput": 326.605, "synch_weights_time_ms": 14.982}, "counters": {"num_env_steps_sampled": 292000, "num_env_steps_trained": 292000, "num_agent_steps_sampled": 1168000, "num_agent_steps_trained": 1168000}, "done": false, "training_iteration": 73, "trial_id": "86f16_00000", "date": "2024-08-08_16-30-02", "timestamp": 1723149002, "time_this_iter_s": 13.012014865875244, "time_total_s": 1034.304417848587, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad1ed160>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1034.304417848587, "iterations_since_restore": 73, "perf": {"cpu_util_percent": 45.910526315789475, "ram_util_percent": 77.8}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5919587271591873, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.7302550917821573, "policy_loss": -0.018155159670834805, "vf_loss": 1.7477005761143163, "vf_explained_var": -1.0221562487013796e-07, "kl": 0.007096771358898954, "entropy": 0.5556611163502044, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 207270.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.686356672892968, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.0105216588824986, "policy_loss": -0.026724976333207452, "vf_loss": 3.0354179846743743, "vf_explained_var": 0.15840557695676882, "kl": 0.00914331837576962, "entropy": 1.0677263855313261, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 70560.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 296000, "num_env_steps_trained": 296000, "num_agent_steps_sampled": 1184000, "num_agent_steps_trained": 1184000}, "env_runners": {"episode_reward_max": 120.0, "episode_reward_min": -21.025750773718986, "episode_reward_mean": 12.688954223037316, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -60.0}, "policy_reward_max": {"adversary_policy": 60.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 7.716049382716049, "agent_policy": -10.459193925110833}, "custom_metrics": {}, "hist_stats": {"episode_reward": [60.0, -4.784144842893175, 0.0, -0.17041001310077353, 40.0, 34.026789179916854, -8.403218109948732, 0.0, 40.0, 40.0, -9.157567210736527, 40.0, -1.6330626215309507, -0.7410265684104533, 0.0, 60.0, -2.8319170507682245, 0.0, 0.0, 60.0, 0.0, 93.34479294497731, -10.269325964568466, 0.0, 20.0, 0.0, -5.8881683732083605, 0.0, -12.657819172628965, -2.7277464786045047, 0.0, 0.0, -0.001217003779724335, 0.0, 0.0, 40.0, 0.0, 0.0, 0.0, -12.502857718715198, -0.5518842252001877, 0.0, 100.0, 40.0, -10.171567946828533, -1.4344709979917836, 16.46072951391482, 0.0, 0.0, 0.0, 60.0, 0.0, 40.0, 0.0, -21.025750773718986, -14.145320021969557, 40.0, 0.0, -11.465472889814913, 0.0, 20.0, 0.0, 0.0, -1.066681246306882, -3.9935865763684335, 0.0, -1.004671843384366, 0.0, 0.0, 80.0, -3.1688287991131103, 0.0, 0.0, 75.26473637094006, -3.043098762100096, 40.0, 0.0, 20.0, -2.330455236402522, 0.0, 58.942684749037966, 0.0, 120.0, -0.3790872650692312, 53.78833182372917, 52.935224725185286, 60.0, 0.0, 79.26006194864965, -11.252472199734195, 0.0, 36.444593895319066, 34.42395555315058, 0.0, 40.0, -10.710823957014243, 40.0, 0.0, -4.360938146752702, 40.0, 0.0, -0.5155562088055443, -0.3979999175951221, 0.0, -10.767077257783043, -0.8085972718876699, -1.7431777145319083, 0.0, 0.0, -2.9446950938428724, 0.0, 0.0, 60.0, 0.0, -4.372015004215387, 0.0, 6.244722876684078, 59.884031949673044, 0.0, -20.414648594226517, 0.0, -0.4070008424207816, 33.79048151317377, -3.0739043841954383, 0.0, 40.0, 20.0, 0.0, -3.450178836475237, 9.360745046600357, -14.474242483211281, 20.0, 0.0, 20.0, 0.0, 0.0, -1.6761056808997443, 40.83138967076691, 38.15764905680182, -0.47612565428023723, 17.47420302634555, 40.0, 0.0, 35.929979643696264, -9.432302837282343, -6.028406781156853, -0.439293144508357, 0.0, 0.0, -0.5103030276967979, 39.98893459410252, 16.464309698374485, 11.304860352874288, -13.551109256966182, -14.379779921445671, -5.951860563205097, 0.0, 20.0, 0.0, 40.0, 58.9753484914269, 40.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0], "policy_agent_policy_reward": [-30.0, -4.784144842893175, 0.0, -0.17041001310077353, -20.0, -25.973210820083136, -8.403218109948732, 0.0, -20.0, -20.0, -9.157567210736527, -20.0, -1.6330626215309507, -0.7410265684104533, 0.0, -30.0, -2.8319170507682245, 0.0, 0.0, -30.0, 0.0, -56.655207055022686, -10.269325964568466, 0.0, -10.0, 0.0, -5.8881683732083605, 0.0, -12.657819172628965, -2.7277464786045047, 0.0, 0.0, -0.001217003779724335, 0.0, 0.0, -20.0, 0.0, 0.0, 0.0, -12.502857718715198, -0.5518842252001877, 0.0, -50.0, -20.0, -10.171567946828533, -1.4344709979917836, -13.539270486085185, 0.0, 0.0, 0.0, -30.0, 0.0, -20.0, 0.0, -21.025750773718986, -14.145320021969557, -20.0, 0.0, -11.465472889814913, 0.0, -10.0, 0.0, 0.0, -1.066681246306882, -3.9935865763684335, 0.0, -1.004671843384366, 0.0, 0.0, -40.0, -3.1688287991131103, 0.0, 0.0, -44.73526362905995, -3.043098762100096, -20.0, 0.0, -10.0, -2.330455236402522, 0.0, -31.05731525096203, 0.0, -60.0, -0.3790872650692312, -36.21166817627082, -37.06477527481471, -30.0, 0.0, -40.73993805135034, -11.252472199734195, 0.0, -53.55540610468094, -25.576044446849423, 0.0, -20.0, -10.710823957014243, -20.0, 0.0, -4.360938146752702, -20.0, 0.0, -0.5155562088055443, -0.3979999175951221, 0.0, -10.767077257783043, -0.8085972718876699, -1.7431777145319083, 0.0, 0.0, -2.9446950938428724, 0.0, 0.0, -30.0, 0.0, -4.372015004215387, 0.0, -23.755277123315924, -30.115968050326956, 0.0, -20.414648594226517, 0.0, -0.4070008424207816, -26.209518486826223, -3.0739043841954383, 0.0, -20.0, -10.0, 0.0, -3.450178836475237, -20.639254953399643, -14.474242483211281, -10.0, 0.0, -10.0, 0.0, 0.0, -1.6761056808997443, -49.16861032923309, -21.842350943198177, -0.47612565428023723, -42.52579697365445, -20.0, 0.0, -24.070020356303726, -9.432302837282343, -6.028406781156853, -0.439293144508357, 0.0, 0.0, -0.5103030276967979, -20.011065405897483, -13.535690301625513, -18.695139647125714, -13.551109256966182, -14.379779921445671, -5.951860563205097, 0.0, -10.0, 0.0, -20.0, -31.024651508573108, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.682921820939176, "mean_inference_ms": 1.1958825526342656, "mean_action_processing_ms": 0.2522013693473276, "mean_env_wait_ms": 0.5117764785293244, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0047555676213017215, "StateBufferConnector_ms": 0.0033644246466365863, "ViewRequirementAgentConnector_ms": 0.09880566302640939}, "num_episodes": 162, "episode_return_max": 120.0, "episode_return_min": -21.025750773718986, "episode_return_mean": 12.688954223037316}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1184000, "num_agent_steps_trained": 1184000, "num_env_steps_sampled": 296000, "num_env_steps_trained": 296000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 324.9578433784179, "num_env_steps_trained_throughput_per_sec": 324.9578433784179, "timesteps_total": 296000, "num_env_steps_sampled_lifetime": 296000, "num_agent_steps_sampled_lifetime": 1184000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1184000, "timers": {"training_iteration_time_ms": 12870.586, "restore_workers_time_ms": 0.014, "training_step_time_ms": 12870.541, "sample_time_ms": 1259.657, "learn_time_ms": 11595.07, "learn_throughput": 344.974, "synch_weights_time_ms": 14.345}, "counters": {"num_env_steps_sampled": 296000, "num_env_steps_trained": 296000, "num_agent_steps_sampled": 1184000, "num_agent_steps_trained": 1184000}, "done": false, "training_iteration": 74, "trial_id": "86f16_00000", "date": "2024-08-08_16-30-14", "timestamp": 1723149014, "time_this_iter_s": 12.313552856445312, "time_total_s": 1046.6179707050323, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad1ed3a0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1046.6179707050323, "iterations_since_restore": 74, "perf": {"cpu_util_percent": 39.4, "ram_util_percent": 78.94999999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6382877406393382, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.9924435157302423, "policy_loss": -0.01812440462580532, "vf_loss": 2.009917996580719, "vf_explained_var": -4.198956996836561e-07, "kl": 0.006499216230536261, "entropy": 0.549362367264768, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 210090.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.756513507415851, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.3438253903140622, "policy_loss": -0.02496572926271862, "vf_loss": 3.3668190034727257, "vf_explained_var": 0.12776108253747226, "kl": 0.009860573778011172, "entropy": 1.0854051858807603, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 71520.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 300000, "num_env_steps_trained": 300000, "num_agent_steps_sampled": 1200000, "num_agent_steps_trained": 1200000}, "env_runners": {"episode_reward_max": 100.0, "episode_reward_min": -38.27511303380439, "episode_reward_mean": 15.14656463427478, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -65.51086187831855}, "policy_reward_max": {"adversary_policy": 50.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 9.382716049382717, "agent_policy": -13.001583513873365}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-11.84239123694681, 18.865181099826067, 72.8449285453108, -0.04368019347351759, -3.3581131254068084, -1.038121651965851, 37.06889413096054, 60.0, -0.015694746231892376, 0.0, -0.06641369128758123, 79.53574761171708, 0.0, -9.669734323099563, 0.0, 50.00901069038008, 40.0, -17.667541979074702, 25.01077297118539, 0.0, 20.0, -4.271190893749924, 0.0, 0.0, -0.011147443577159688, 0.0, -1.7939177304064868, 0.0, 0.0, 80.0, 39.82866893652844, -0.8203216635341448, 58.76137725002497, 18.49600221060701, 0.0, -16.037607742716556, -8.77123986184647, -2.300891407588199, -7.087650468983746, 0.0, 0.0, 38.98142696932429, 20.0, 20.0, 0.0, -23.202248159832298, 40.0, 0.0, 40.0, 59.886834129556824, 100.0, 0.0, -2.070813281828113, 20.0, 24.489138121681442, 80.0, 60.0, 0.0, 77.88481231902743, -5.268547310212922, 60.0, -4.091252055649923, 78.8007378136584, 20.0, 0.0, 0.0, -12.254969492851117, 40.0, 58.71709192309261, 20.0, -12.47540657513622, -2.8427090574460747, 0.0, 0.0, 0.0, -1.1862934004723436, -2.715265018317628, 0.0, 20.0, -34.26006804776581, 0.0, -11.219827429805088, -18.42753527577777, 20.0, 30.353676479221747, 0.0, -4.432367252700062, 60.0, 0.0, 0.0, 39.78042982986417, 20.0, 16.44857992019403, 40.0, 60.0, 0.0, 0.0, -38.27511303380439, 0.0, 7.656255006205818, 51.156355315610014, 0.0, 0.0, 0.0, 20.0, 0.0, -0.08744033306981924, 0.0, 0.0, 60.0, -8.5154758416316, -9.15479231218816, 40.0, 20.0, 0.0, -18.370989428531335, 0.0, 80.0, 0.0, 0.0, 40.0, -8.72026308202619, 17.336079185634336, -2.703440948266464, 100.0, -3.846891874465669, 20.0, 60.0, -1.154549977038899, 100.0, -5.993994674466595, -2.9158954639533166, 6.63255569703357, -17.23241805751676, -3.9957262769810042, 18.12272312470432, -3.7393664660629238, 13.899914614580027, 0.0, -1.5586701073755616, -3.5953253947872534, 60.0, 60.0, 0.0, 80.0, -14.949457516231181, 0.0, 40.0, 0.0, -1.6113663310303168, 20.0, 18.7733045874939, 57.48845169734681, -2.588356224053958, 12.824851004140235, -1.0196192058532358, 19.515563181732922, 36.08731747829077, -0.15692685932658157, 0.0, -2.084171166073323, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-11.84239123694681, -11.134818900173935, -47.15507145468921, -0.04368019347351759, -3.3581131254068084, -1.038121651965851, -52.93110586903946, -30.0, -0.015694746231892376, 0.0, -0.06641369128758123, -40.464252388282915, 0.0, -9.669734323099563, 0.0, -39.99098930961992, -20.0, -17.667541979074702, -34.98922702881461, 0.0, -10.0, -4.271190893749924, 0.0, 0.0, -0.011147443577159688, 0.0, -1.7939177304064868, 0.0, 0.0, -40.0, -20.171331063471563, -0.8203216635341448, -61.238622749975015, -11.503997789392992, 0.0, -16.037607742716556, -8.77123986184647, -2.300891407588199, -7.087650468983746, 0.0, 0.0, -21.018573030675714, -10.0, -10.0, 0.0, -23.202248159832298, -20.0, 0.0, -20.0, -30.113165870443176, -50.0, 0.0, -2.070813281828113, -10.0, -65.51086187831855, -40.0, -30.0, 0.0, -42.11518768097257, -5.268547310212922, -30.0, -4.091252055649923, -41.19926218634159, -10.0, 0.0, 0.0, -12.254969492851117, -20.0, -31.282908076907393, -10.0, -12.47540657513622, -2.8427090574460747, 0.0, 0.0, 0.0, -1.1862934004723436, -2.715265018317628, 0.0, -10.0, -34.26006804776581, 0.0, -11.219827429805088, -18.42753527577777, -10.0, -29.646323520778253, 0.0, -4.432367252700062, -30.0, 0.0, 0.0, -20.219570170135828, -10.0, -13.551420079805968, -20.0, -30.0, 0.0, 0.0, -38.27511303380439, 0.0, -22.343744993794182, -38.84364468438998, 0.0, 0.0, 0.0, -10.0, 0.0, -0.08744033306981924, 0.0, 0.0, -30.0, -8.5154758416316, -9.15479231218816, -20.0, -10.0, 0.0, -18.370989428531335, 0.0, -40.0, 0.0, 0.0, -20.0, -8.72026308202619, -12.663920814365664, -32.70344094826646, -50.0, -3.846891874465669, -10.0, -30.0, -1.154549977038899, -50.0, -5.993994674466595, -2.9158954639533166, -23.36744430296643, -17.23241805751676, -3.9957262769810042, -11.877276875295681, -3.7393664660629238, -16.100085385419973, 0.0, -1.5586701073755616, -3.5953253947872534, -30.0, -30.0, 0.0, -40.0, -14.949457516231181, 0.0, -20.0, 0.0, -1.6113663310303168, -10.0, -11.226695412506102, -32.51154830265319, -2.588356224053958, -17.175148995859765, -1.0196192058532358, -10.484436818267076, -23.912682521709232, -0.15692685932658157, 0.0, -2.084171166073323, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6816475945527021, "mean_inference_ms": 1.1937618156707308, "mean_action_processing_ms": 0.25162423682481805, "mean_env_wait_ms": 0.5109261690286114, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004162611784758391, "StateBufferConnector_ms": 0.003200843010419681, "ViewRequirementAgentConnector_ms": 0.08640097983089494}, "num_episodes": 162, "episode_return_max": 100.0, "episode_return_min": -38.27511303380439, "episode_return_mean": 15.14656463427478}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1200000, "num_agent_steps_trained": 1200000, "num_env_steps_sampled": 300000, "num_env_steps_trained": 300000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 360.55233060544634, "num_env_steps_trained_throughput_per_sec": 360.55233060544634, "timesteps_total": 300000, "num_env_steps_sampled_lifetime": 300000, "num_agent_steps_sampled_lifetime": 1200000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1200000, "timers": {"training_iteration_time_ms": 11938.384, "restore_workers_time_ms": 0.013, "training_step_time_ms": 11938.342, "sample_time_ms": 1192.307, "learn_time_ms": 10730.831, "learn_throughput": 372.758, "synch_weights_time_ms": 13.787}, "counters": {"num_env_steps_sampled": 300000, "num_env_steps_trained": 300000, "num_agent_steps_sampled": 1200000, "num_agent_steps_trained": 1200000}, "done": false, "training_iteration": 75, "trial_id": "86f16_00000", "date": "2024-08-08_16-30-25", "timestamp": 1723149025, "time_this_iter_s": 11.098867893218994, "time_total_s": 1057.7168385982513, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad1ed5e0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1057.7168385982513, "iterations_since_restore": 75, "perf": {"cpu_util_percent": 30.125, "ram_util_percent": 78.35625}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5849938744771566, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.4670003345883484, "policy_loss": -0.01607679572075701, "vf_loss": 1.4823803191066633, "vf_explained_var": -5.092392576501725e-07, "kl": 0.0069681047559439465, "entropy": 0.5195994106907371, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 212910.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.804973265901208, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.051957079892357, "policy_loss": -0.024248106649853676, "vf_loss": 3.0744172112395365, "vf_explained_var": 0.08379848357290029, "kl": 0.008939880262667252, "entropy": 1.0607798662036658, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 72480.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 304000, "num_env_steps_trained": 304000, "num_agent_steps_sampled": 1216000, "num_agent_steps_trained": 1216000}, "env_runners": {"episode_reward_max": 120.0, "episode_reward_min": -35.10352734863429, "episode_reward_mean": 9.790331203310519, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 153, "episodes_timesteps_total": 3825, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -64.48831368234399}, "policy_reward_max": {"adversary_policy": 60.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 6.73202614379085, "agent_policy": -10.405747228062031}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-1.0941352092705448, 0.0, 40.0, 13.625534230447009, 11.244171396649076, -10.204230491507818, 0.0, -10.386346740660478, 20.0, -0.003183968250940472, 8.12813020550151, -2.588367631435191, 0.0, 0.0, 20.0, -10.857301677817379, 38.14214652963192, 0.0, -3.3165114589417755, 0.0, 0.0, 0.0, -0.6399988682944691, 0.0, 0.0, -18.811327726734795, 0.0, 0.0, 15.410121246720266, -25.12733491495964, 0.0, 38.72243064367256, 38.79631841251643, 0.0, -10.733014066583223, 20.0, -7.038011764960342, 0.0, -18.61108365554182, 100.0, 0.0, -0.2800827615000523, 59.79329048972208, 60.0, 0.0, 0.0, 40.0, 19.897213343827843, -2.8085739095360838, 0.0, 0.0, 117.10990635247364, 0.0, -0.3696844737722793, -4.8761227700587, 40.0, -7.343498234088862, 0.0, 0.0, 0.0, 53.58363456717974, 0.0, 0.0, -0.6208087904683879, 0.0, -19.73787652360053, 0.0, 40.0, 60.0, 0.0, 120.0, 6.819371837330706, 0.0, -13.072008199829845, 40.0, -19.79075487417498, 0.0, 20.0, -12.259066259434945, 0.0, 0.0, 0.0, 18.323553995882015, -0.897178294707891, 0.0, 40.0, 19.867251581979303, -21.469192183290907, -1.5840333301674459, 0.0, 0.0, 0.0, -13.516792247797184, -25.36103620078572, -35.10352734863429, -9.889042261327925, 0.0, 0.0, 100.0, 60.0, 20.0, 0.0, 39.911038293041194, 0.0, -19.933155116264885, -6.570992614713855, 0.0, -7.385897514119952, 0.0, -8.889569607973048, -15.056931380798167, 20.0, -4.6487982029180746, 60.0, -8.17982612891269, 0.0, 60.0, 20.0, 0.0, -0.054196376900194076, 0.0, -4.439403283531342, 0.0, 40.0, 0.0, 39.0700195597784, 20.0, 20.0, 36.688940660036344, 0.0, 20.0, -15.436579865619883, -6.615264169036809, 0.0, 0.0, 40.0, -2.317777655912738, 58.75351225316467, -4.3788480642171494, 0.0, -1.2091549645797794, -16.672689925389758, 85.511686317656, 0.0, 0.0, -0.6171248456591938, 0.0, 9.318738743980425, 0.0, 0.0, 20.0, 40.0, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-1.0941352092705448, 0.0, -20.0, -16.37446576955299, -18.75582860335092, -10.204230491507818, 0.0, -10.386346740660478, -10.0, -0.003183968250940472, -51.87186979449849, -2.588367631435191, 0.0, 0.0, -10.0, -10.857301677817379, -21.85785347036808, 0.0, -3.3165114589417755, 0.0, 0.0, 0.0, -0.6399988682944691, 0.0, 0.0, -18.811327726734795, 0.0, 0.0, -14.589878753279736, -25.12733491495964, 0.0, -21.27756935632744, -21.203681587483565, 0.0, -10.733014066583223, -10.0, -7.038011764960342, 0.0, -18.61108365554182, -50.0, 0.0, -0.2800827615000523, -30.206709510277914, -30.0, 0.0, 0.0, -20.0, -10.102786656172157, -2.8085739095360838, 0.0, 0.0, -62.890093647526356, 0.0, -0.3696844737722793, -4.8761227700587, -20.0, -7.343498234088862, 0.0, 0.0, 0.0, -36.416365432820264, 0.0, 0.0, -0.6208087904683879, 0.0, -19.73787652360053, 0.0, -20.0, -30.0, 0.0, -60.0, -23.18062816266929, 0.0, -13.072008199829845, -20.0, -19.79075487417498, 0.0, -10.0, -12.259066259434945, 0.0, 0.0, 0.0, -41.67644600411799, -0.897178294707891, 0.0, -20.0, -10.132748418020697, -21.469192183290907, -1.5840333301674459, 0.0, 0.0, 0.0, -13.516792247797184, -25.36103620078572, -35.10352734863429, -9.889042261327925, 0.0, 0.0, -50.0, -30.0, -10.0, 0.0, -20.088961706958806, 0.0, -19.933155116264885, -6.570992614713855, 0.0, -7.385897514119952, 0.0, -8.889569607973048, -15.056931380798167, -10.0, -4.6487982029180746, -30.0, -8.17982612891269, 0.0, -30.0, -10.0, 0.0, -0.054196376900194076, 0.0, -4.439403283531342, 0.0, -20.0, 0.0, -20.929980440221595, -10.0, -10.0, -23.311059339963656, 0.0, -10.0, -15.436579865619883, -6.615264169036809, 0.0, 0.0, -20.0, -2.317777655912738, -31.24648774683532, -4.3788480642171494, 0.0, -1.2091549645797794, -16.672689925389758, -64.48831368234399, 0.0, 0.0, -0.6171248456591938, 0.0, -20.681261256019575, 0.0, 0.0, -10.0, -20.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6805652515429074, "mean_inference_ms": 1.1918364590523929, "mean_action_processing_ms": 0.2511665000467592, "mean_env_wait_ms": 0.5102836393485887, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004281015957103056, "StateBufferConnector_ms": 0.003312459958145042, "ViewRequirementAgentConnector_ms": 0.08824526094922833}, "num_episodes": 153, "episode_return_max": 120.0, "episode_return_min": -35.10352734863429, "episode_return_mean": 9.790331203310519}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1216000, "num_agent_steps_trained": 1216000, "num_env_steps_sampled": 304000, "num_env_steps_trained": 304000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 357.3300468848812, "num_env_steps_trained_throughput_per_sec": 357.3300468848812, "timesteps_total": 304000, "num_env_steps_sampled_lifetime": 304000, "num_agent_steps_sampled_lifetime": 1216000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1216000, "timers": {"training_iteration_time_ms": 11886.633, "restore_workers_time_ms": 0.013, "training_step_time_ms": 11886.591, "sample_time_ms": 1178.595, "learn_time_ms": 10692.786, "learn_throughput": 374.084, "synch_weights_time_ms": 13.787}, "counters": {"num_env_steps_sampled": 304000, "num_env_steps_trained": 304000, "num_agent_steps_sampled": 1216000, "num_agent_steps_trained": 1216000}, "done": false, "training_iteration": 76, "trial_id": "86f16_00000", "date": "2024-08-08_16-30-37", "timestamp": 1723149037, "time_this_iter_s": 11.198990106582642, "time_total_s": 1068.915828704834, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad1eda60>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1068.915828704834, "iterations_since_restore": 76, "perf": {"cpu_util_percent": 31.68125, "ram_util_percent": 78.39375000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5771232790188163, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.8913434892681473, "policy_loss": -0.01693403001429665, "vf_loss": 1.9076167257119578, "vf_explained_var": -4.8822967718679e-07, "kl": 0.006607920577726394, "entropy": 0.518814642410329, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 215730.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.3703787859529255, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.752290476299822, "policy_loss": -0.022802434720021362, "vf_loss": 2.7732498295605184, "vf_explained_var": 0.07225302948306005, "kl": 0.009215357936207483, "entropy": 1.0384228503952424, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 73440.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 308000, "num_env_steps_trained": 308000, "num_agent_steps_sampled": 1232000, "num_agent_steps_trained": 1232000}, "env_runners": {"episode_reward_max": 200.0, "episode_reward_min": -22.491525574572105, "episode_reward_mean": 16.760605430999718, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -100.0}, "policy_reward_max": {"adversary_policy": 100.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 9.320987654320987, "agent_policy": -11.202357531963248}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 140.0, -5.227354103846817, 0.0, 0.0, 18.744744169538404, 0.0, 60.0, 0.0, 38.583011752504916, 55.82999428269742, 0.0, -3.9726434848044567, 0.0, 0.0, 57.551266617636436, -1.2187360332836028, 20.0, -2.666934998651808, 60.0, 0.0, 0.0, 0.0, -1.9748901590951151, -0.6140832494699822, 35.94743105126856, 80.0, -22.491525574572105, 0.0, 0.0, 0.0, 0.0, -1.0296531296619849, -22.481746994577033, 0.0, 0.0, 20.0, -1.2833669984283202, 40.0, 20.0, 40.0, -1.5023320183116717, -14.187576366216154, -1.5544324428757716, -4.85523479101404, 200.0, 40.0, 0.0, -1.2665101523017108, 0.0, 0.0, 120.0, 20.0, 40.0, 28.394969715508623, 0.0, 0.0, 0.0, -0.6970866657897834, 52.31772003933912, 0.0, 0.0, 0.0, -10.935692883153857, 0.0, -0.42858570716116207, 0.0, 38.48610522570163, 20.0, -0.9271700290636509, 40.0, -1.3461978739898373, 0.0, 0.0, 60.0, -4.654063637431488, -11.8612689918559, 0.0, 0.0, 20.0, 20.0, 18.743301505807942, -3.0494095722732366, -1.5321251040344197, 100.0, 0.0, 140.0, 57.26308112199855, 50.36419641486967, 27.937909127211658, 0.0, 0.0, -10.438064036301444, -3.6478564267840605, 0.0, 20.0, -0.9255101422233425, -5.171657554480623, 0.0, 80.0, -7.8010676860940515, 29.453886574084603, 0.0, -1.8778936252456946, 0.0, 38.985658759945956, 80.0, 0.0, -2.2898477925232097, 77.00896991607438, 39.869020686143344, 0.0, 0.0, 60.0, 0.0, 58.37806451875433, 0.0, 60.0, 0.0, 0.0, 49.91891428124474, 78.70591412568575, 20.0, 20.0, 40.0, 0.0, -1.398716844448269, 0.0, -4.721081335807271, 0.0, 0.0, 0.0, 0.0, 80.0, -8.030038964402742, 0.0, 0.0, 60.0, 0.0, 0.0, -1.7380959574597188, 0.0, 0.0, 0.0, 31.369390571682224, 0.0, -18.460498006598115, 20.0, -0.22665482574731444, 20.0, 0.0, -0.11669427137152466, 0.0, 0.0, 0.0, 0.0, 39.96682779560698, 0.0, 40.0, 60.0, 20.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 100.0, 100.0, 100.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0], "policy_agent_policy_reward": [0.0, 0.0, -70.0, -5.227354103846817, 0.0, 0.0, -11.255255830461593, 0.0, -30.0, 0.0, -21.416988247495084, -34.17000571730259, 0.0, -3.9726434848044567, 0.0, 0.0, -32.44873338236356, -1.2187360332836028, -10.0, -2.666934998651808, -30.0, 0.0, 0.0, 0.0, -1.9748901590951151, -0.6140832494699822, -24.052568948731434, -40.0, -22.491525574572105, 0.0, 0.0, 0.0, 0.0, -1.0296531296619849, -22.481746994577033, 0.0, 0.0, -10.0, -1.2833669984283202, -20.0, -10.0, -20.0, -1.5023320183116717, -14.187576366216154, -1.5544324428757716, -4.85523479101404, -100.0, -20.0, 0.0, -1.2665101523017108, 0.0, 0.0, -60.0, -10.0, -20.0, -31.605030284491377, 0.0, 0.0, 0.0, -0.6970866657897834, -37.68227996066088, 0.0, 0.0, 0.0, -10.935692883153857, 0.0, -0.42858570716116207, 0.0, -21.51389477429837, -10.0, -0.9271700290636509, -20.0, -1.3461978739898373, 0.0, 0.0, -30.0, -4.654063637431488, -11.8612689918559, 0.0, 0.0, -10.0, -10.0, -11.25669849419206, -3.0494095722732366, -1.5321251040344197, -50.0, 0.0, -70.0, -32.73691887800144, -39.63580358513033, -32.06209087278834, 0.0, 0.0, -10.438064036301444, -3.6478564267840605, 0.0, -10.0, -0.9255101422233425, -5.171657554480623, 0.0, -40.0, -7.8010676860940515, -30.546113425915408, 0.0, -1.8778936252456946, 0.0, -21.014341240054044, -40.0, 0.0, -2.2898477925232097, -42.99103008392562, -20.130979313856653, 0.0, 0.0, -30.0, 0.0, -31.621935481245675, 0.0, -30.0, 0.0, 0.0, -40.08108571875526, -41.29408587431424, -10.0, -10.0, -20.0, 0.0, -1.398716844448269, 0.0, -4.721081335807271, 0.0, 0.0, 0.0, 0.0, -40.0, -38.030038964402735, 0.0, 0.0, -30.0, 0.0, 0.0, -1.7380959574597188, 0.0, 0.0, 0.0, -28.630609428317776, 0.0, -18.460498006598115, -10.0, -0.22665482574731444, -10.0, 0.0, -0.11669427137152466, 0.0, 0.0, 0.0, 0.0, -20.03317220439302, 0.0, -20.0, -30.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6804018010034502, "mean_inference_ms": 1.191942487034542, "mean_action_processing_ms": 0.2510117220661428, "mean_env_wait_ms": 0.5103098439656821, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004533705887971101, "StateBufferConnector_ms": 0.003400849707332658, "ViewRequirementAgentConnector_ms": 0.09725233654917022}, "num_episodes": 162, "episode_return_max": 200.0, "episode_return_min": -22.491525574572105, "episode_return_mean": 16.760605430999718}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1232000, "num_agent_steps_trained": 1232000, "num_env_steps_sampled": 308000, "num_env_steps_trained": 308000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 330.6692369855826, "num_env_steps_trained_throughput_per_sec": 330.6692369855826, "timesteps_total": 308000, "num_env_steps_sampled_lifetime": 308000, "num_agent_steps_sampled_lifetime": 1232000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1232000, "timers": {"training_iteration_time_ms": 11919.955, "restore_workers_time_ms": 0.013, "training_step_time_ms": 11919.916, "sample_time_ms": 1192.665, "learn_time_ms": 10716.202, "learn_throughput": 373.267, "synch_weights_time_ms": 10.727}, "counters": {"num_env_steps_sampled": 308000, "num_env_steps_trained": 308000, "num_agent_steps_sampled": 1232000, "num_agent_steps_trained": 1232000}, "done": false, "training_iteration": 77, "trial_id": "86f16_00000", "date": "2024-08-08_16-30-49", "timestamp": 1723149049, "time_this_iter_s": 12.10910677909851, "time_total_s": 1081.0249354839325, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad1edee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1081.0249354839325, "iterations_since_restore": 77, "perf": {"cpu_util_percent": 35.94117647058824, "ram_util_percent": 78.24117647058823}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5361653007936816, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.487683612552095, "policy_loss": -0.01536685212635838, "vf_loss": 1.5024564124168234, "vf_explained_var": 1.1064482073411874e-06, "kl": 0.0059405288595297855, "entropy": 0.5089035427422388, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 218550.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.4837163091947634, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.5051201107601324, "policy_loss": -0.024324741982854902, "vf_loss": 2.5275630073000985, "vf_explained_var": 0.054156934221585594, "kl": 0.009409205443040388, "entropy": 1.030174408107996, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 74400.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 312000, "num_env_steps_trained": 312000, "num_agent_steps_sampled": 1248000, "num_agent_steps_trained": 1248000}, "env_runners": {"episode_reward_max": 180.0, "episode_reward_min": -35.745448019841675, "episode_reward_mean": 12.740374043689066, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -90.0}, "policy_reward_max": {"adversary_policy": 90.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 7.654320987654321, "agent_policy": -10.2225889192739}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, -0.03750850009276552, 0.0, 3.146500960670892, 60.0, 0.0, 80.0, 20.0, 40.0, 38.21162808868727, -24.234644695955907, 20.0, -23.564209223655862, 0.0, 0.0, -6.240939428633008, 40.0, 15.886012033078586, 40.682908249392476, -0.7227436824695599, 100.0, 0.0, -0.06914358528285813, -0.47903023306530956, -0.42683032693943135, 0.0, 0.0, 0.0, 0.0, -5.5946261384501, -1.0728407142673846, -2.363261271400744, -0.7783347351745529, 0.0, 0.0, -1.056683155444268, 0.0, 95.58482779506801, 0.0, 60.0, 18.61140267985118, 0.0, -0.36717642862023836, -1.147564652798947, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 19.157910862448755, 40.0, -0.15414795935714487, 18.780080164841664, -33.64528252971162, -11.097292937378572, 0.0, 19.590332889692753, 0.0, 100.0, 20.0, -0.20397255486173882, 37.20410430401148, 40.0, 140.0, 9.758315651446253, 0.0, -0.8505164552967115, 0.0, 0.0, -0.31849123959526104, -0.3947695572250065, -1.4173362426597813, 0.0, 0.0, 40.0, 40.0, 51.926864812534845, 80.0, -4.589501822086957, 58.36569725869904, 11.276687056231216, 1.8955159442761307, 18.470011838418557, 39.69287900701988, 0.0, -0.6452552622506125, 20.0, 19.735587740546297, 0.0, 0.0, 38.48840379580935, 0.0, 0.0, 0.0, 20.0, 60.0, -3.073797326240618, -2.9952051408311204, 20.0, -4.915525846710299, 0.0, 0.0, -9.811539327960078, 0.0, 0.0, 40.0, 20.0, -4.437330847640686, 0.0, 20.0, 0.0, -2.5812076810915685, -1.96943297222267, 60.0, 0.0, 40.0, 20.0, 0.0, 0.0, -35.745448019841675, 7.0374161067768775, 20.0, 0.0, -1.0522447111996724, 180.0, -6.159372433910671, 0.0, 0.0, -0.5671228913479798, -0.5859579780486046, -4.040731068739771, -1.004213726077644, 0.0, -0.974060783876467, 80.0, 0.0, 45.94341924005442, -4.292235656851285, 0.0, -1.5139365996230991, 40.0, 0.0, 80.0, 0.0, 0.0, 0.0, 0.0, -0.7765419615857128, 0.0, -7.942628059101044, -17.35623645510369, 0.0, 20.0, 39.37198493093075, -0.9166848827226048, -30.531815735482247, 0.0, -0.16252289397460262, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 70.0, 70.0, 70.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 90.0, 90.0, 90.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [0.0, 0.0, 0.0, -0.03750850009276552, 0.0, -26.853499039329108, -30.0, 0.0, -40.0, -10.0, -20.0, -21.78837191131273, -24.234644695955907, -10.0, -23.564209223655862, 0.0, 0.0, -6.240939428633008, -20.0, -14.113987966921416, -49.31709175060753, -0.7227436824695599, -50.0, 0.0, -0.06914358528285813, -0.47903023306530956, -0.42683032693943135, 0.0, 0.0, 0.0, 0.0, -5.5946261384501, -1.0728407142673846, -2.363261271400744, -0.7783347351745529, 0.0, 0.0, -1.056683155444268, 0.0, -54.415172204931984, 0.0, -30.0, -11.388597320148818, 0.0, -0.36717642862023836, -1.147564652798947, -10.0, 0.0, 0.0, 0.0, 0.0, 0.0, -10.842089137551245, -20.0, -0.15414795935714487, -11.219919835158333, -33.64528252971162, -11.097292937378572, 0.0, -10.409667110307245, 0.0, -50.0, -10.0, -0.20397255486173882, -22.795895695988516, -20.0, -70.0, -20.241684348553747, 0.0, -0.8505164552967115, 0.0, 0.0, -0.31849123959526104, -0.3947695572250065, -1.4173362426597813, 0.0, 0.0, -20.0, -20.0, -38.073135187465155, -40.0, -4.589501822086957, -31.63430274130095, -18.72331294376879, -28.10448405572387, -11.529988161581443, -20.30712099298012, 0.0, -0.6452552622506125, -10.0, -10.264412259453703, 0.0, 0.0, -51.51159620419066, 0.0, 0.0, 0.0, -10.0, -30.0, -3.073797326240618, -2.9952051408311204, -10.0, -4.915525846710299, 0.0, 0.0, -9.811539327960078, 0.0, 0.0, -20.0, -10.0, -4.437330847640686, 0.0, -10.0, 0.0, -2.5812076810915685, -1.96943297222267, -30.0, 0.0, -20.0, -10.0, 0.0, 0.0, -35.745448019841675, -22.962583893223123, -10.0, 0.0, -1.0522447111996724, -90.0, -6.159372433910671, 0.0, 0.0, -0.5671228913479798, -0.5859579780486046, -4.040731068739771, -1.004213726077644, 0.0, -0.974060783876467, -40.0, 0.0, -44.05658075994558, -4.292235656851285, 0.0, -1.5139365996230991, -20.0, 0.0, -40.0, 0.0, 0.0, 0.0, 0.0, -0.7765419615857128, 0.0, -7.942628059101044, -17.35623645510369, 0.0, -10.0, -20.628015069069246, -0.9166848827226048, -30.531815735482247, 0.0, -0.16252289397460262, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6799967064354281, "mean_inference_ms": 1.191086625115285, "mean_action_processing_ms": 0.25066231419420953, "mean_env_wait_ms": 0.5100817088705678, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004799056936193396, "StateBufferConnector_ms": 0.003308499300921405, "ViewRequirementAgentConnector_ms": 0.09741216530034572}, "num_episodes": 162, "episode_return_max": 180.0, "episode_return_min": -35.745448019841675, "episode_return_mean": 12.740374043689066}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1248000, "num_agent_steps_trained": 1248000, "num_env_steps_sampled": 312000, "num_env_steps_trained": 312000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 225.64048822394267, "num_env_steps_trained_throughput_per_sec": 225.64048822394267, "timesteps_total": 312000, "num_env_steps_sampled_lifetime": 312000, "num_agent_steps_sampled_lifetime": 1248000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1248000, "timers": {"training_iteration_time_ms": 12492.319, "restore_workers_time_ms": 0.013, "training_step_time_ms": 12492.281, "sample_time_ms": 1183.864, "learn_time_ms": 11297.091, "learn_throughput": 354.073, "synch_weights_time_ms": 10.996}, "counters": {"num_env_steps_sampled": 312000, "num_env_steps_trained": 312000, "num_agent_steps_sampled": 1248000, "num_agent_steps_trained": 1248000}, "done": false, "training_iteration": 78, "trial_id": "86f16_00000", "date": "2024-08-08_16-31-07", "timestamp": 1723149067, "time_this_iter_s": 17.74180769920349, "time_total_s": 1098.766743183136, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad104670>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1098.766743183136, "iterations_since_restore": 78, "perf": {"cpu_util_percent": 61.58076923076923, "ram_util_percent": 80.56538461538463}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5927033358801764, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.4491558532554207, "policy_loss": -0.01873570857767729, "vf_loss": 1.467189346898532, "vf_explained_var": -1.3584363545086368e-07, "kl": 0.0070221337339097314, "entropy": 0.5289502061639272, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 221370.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.5788821943104265, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.8727783280114334, "policy_loss": -0.02502077075090104, "vf_loss": 2.8959438472986223, "vf_explained_var": 0.0956326346223553, "kl": 0.009276299263646887, "entropy": 1.0464015534768503, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 75360.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 316000, "num_env_steps_trained": 316000, "num_agent_steps_sampled": 1264000, "num_agent_steps_trained": 1264000}, "env_runners": {"episode_reward_max": 120.0, "episode_reward_min": -52.000673720829184, "episode_reward_mean": 13.24143478617754, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -60.0}, "policy_reward_max": {"adversary_policy": 60.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 8.08641975308642, "agent_policy": -11.017824473081719}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-6.965464446095406, -52.000673720829184, 99.07556602514546, 60.0, 0.0, 60.0, 59.99573898682985, -11.248514353828073, 20.0, 0.0, -14.7466113196502, -9.825428367416293, 0.0, 59.66552883391827, -6.607155833357832, 0.0, -0.8737871330530333, -1.3355934004530867, -5.523342941127919, 0.0, -8.812257899096494, 18.928659893449755, -6.673398663033605, -0.421507171507185, 38.276256115628954, -0.24668677408473116, 58.94489207418537, 39.65914390736701, 0.0, 40.0, 0.0, -2.507176099346249, -0.4609273916159029, 0.0, 0.0, 0.0, 20.0, -5.465956429774865, 0.0, 0.0, -2.62228413959025, -4.38952026890069, 57.01639518961372, 0.0, -1.6486029973611982, 0.0, -10.247851459086547, 0.0, 0.0, 100.0, 60.0, 0.0, -1.5166837830074231, -3.2752356524627873, 60.0, -12.281312342542588, -2.9329706177773662, -0.42690213265797805, -0.6845170603396444, 0.0, -11.426662737944753, 0.0, 0.0, -17.426610993689525, 0.0, 0.0, -0.40080315501767827, -6.452557457827752, -3.8786744663374724, -0.4738383170419147, -0.1196754937108202, 0.0, 0.0, -32.45901805622783, 0.0, 20.0, 19.96493745431329, -1.1556548527238641, 36.20172974215165, 0.0, 60.0, 120.0, -6.4025460771857166, 0.0, 39.350716024290335, 59.10520769869473, -0.011271037015130325, -1.4306581610588687, 0.0, 0.0, 30.810948141844932, -13.577317323788561, 0.0, 39.563434532104935, 60.0, -5.472735903160493, 0.0, 0.0, 0.0, 60.0, 39.369776168405025, 0.0, 0.0, -14.169435016448555, 120.0, 40.0, 0.0, 0.0, 18.006499398996773, -0.01473622313985623, 80.0, -0.09586888012428241, 60.0, -3.2739892937755517, 0.0, 35.66960525796767, 0.0, -4.054330424902566, -8.325762869248322, 0.0, 11.820666537251022, 39.3414933387905, 40.0, -2.976625675829724, -14.95594082316888, -1.6786235196437016, 76.43353618616854, 18.18536946354366, -3.3159501836071446, 0.0, -5.821812260606992, 80.0, -16.23878637941626, 19.43364678125019, 40.0, 80.0, -9.394348486237067, 0.0, -5.369801673710276, 0.0, 100.0, 80.0, 0.0, -10.154357195803858, 0.0, 0.0, 0.0, 29.598793885214874, -0.838678879427559, -1.2959895623720397, 0.0, 0.0, 60.0, 0.0, 78.07706875689698, -22.574757951351675, 20.0, -0.7586221414631233, -4.966175586755119, -12.027836478391011, 0.0, -0.6523590971117299], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-6.965464446095406, -52.000673720829184, -50.92443397485454, -30.0, 0.0, -30.0, -30.004261013170158, -11.248514353828073, -10.0, 0.0, -14.7466113196502, -9.825428367416293, 0.0, -30.33447116608173, -6.607155833357832, 0.0, -0.8737871330530333, -1.3355934004530867, -5.523342941127919, 0.0, -8.812257899096494, -11.071340106550245, -6.673398663033605, -0.421507171507185, -21.723743884371046, -0.24668677408473116, -31.05510792581463, -20.340856092632993, 0.0, -20.0, 0.0, -2.507176099346249, -0.4609273916159029, 0.0, 0.0, 0.0, -10.0, -5.465956429774865, 0.0, 0.0, -2.62228413959025, -4.38952026890069, -32.98360481038629, 0.0, -1.6486029973611982, 0.0, -10.247851459086547, 0.0, 0.0, -50.0, -30.0, 0.0, -1.5166837830074231, -3.2752356524627873, -30.0, -12.281312342542588, -2.9329706177773662, -0.42690213265797805, -0.6845170603396444, 0.0, -11.426662737944753, 0.0, 0.0, -17.426610993689525, 0.0, 0.0, -0.40080315501767827, -6.452557457827752, -3.8786744663374724, -0.4738383170419147, -0.1196754937108202, 0.0, 0.0, -32.45901805622783, 0.0, -10.0, -10.03506254568671, -1.1556548527238641, -23.79827025784835, 0.0, -30.0, -60.0, -6.4025460771857166, 0.0, -20.649283975709665, -30.89479230130528, -0.011271037015130325, -1.4306581610588687, 0.0, 0.0, -29.189051858155068, -13.577317323788561, 0.0, -20.436565467895065, -30.0, -5.472735903160493, 0.0, 0.0, 0.0, -30.0, -20.630223831594975, 0.0, 0.0, -14.169435016448555, -60.0, -20.0, 0.0, 0.0, -11.993500601003229, -0.01473622313985623, -40.0, -0.09586888012428241, -30.0, -3.2739892937755517, 0.0, -24.330394742032336, 0.0, -4.054330424902566, -8.325762869248322, 0.0, -18.17933346274898, -20.6585066612095, -20.0, -2.976625675829724, -14.95594082316888, -1.6786235196437016, -43.56646381383146, -11.814630536456342, -3.3159501836071446, 0.0, -5.821812260606992, -40.0, -16.23878637941626, -10.56635321874981, -20.0, -40.0, -9.394348486237067, 0.0, -5.369801673710276, 0.0, -50.0, -40.0, 0.0, -10.154357195803858, 0.0, 0.0, 0.0, -30.401206114785126, -0.838678879427559, -1.2959895623720397, 0.0, 0.0, -30.0, 0.0, -41.92293124310303, -22.574757951351675, -10.0, -0.7586221414631233, -4.966175586755119, -12.027836478391011, 0.0, -0.6523590971117299]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6809037746997436, "mean_inference_ms": 1.1922339898173517, "mean_action_processing_ms": 0.2506207194339942, "mean_env_wait_ms": 0.510489077064645, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004567481853343823, "StateBufferConnector_ms": 0.004725103025083189, "ViewRequirementAgentConnector_ms": 0.11706587709026572}, "num_episodes": 162, "episode_return_max": 120.0, "episode_return_min": -52.000673720829184, "episode_return_mean": 13.24143478617754}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1264000, "num_agent_steps_trained": 1264000, "num_env_steps_sampled": 316000, "num_env_steps_trained": 316000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 247.2976552822671, "num_env_steps_trained_throughput_per_sec": 247.2976552822671, "timesteps_total": 316000, "num_env_steps_sampled_lifetime": 316000, "num_agent_steps_sampled_lifetime": 1264000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1264000, "timers": {"training_iteration_time_ms": 12959.986, "restore_workers_time_ms": 0.014, "training_step_time_ms": 12959.946, "sample_time_ms": 1210.549, "learn_time_ms": 11735.193, "learn_throughput": 340.855, "synch_weights_time_ms": 13.676}, "counters": {"num_env_steps_sampled": 316000, "num_env_steps_trained": 316000, "num_agent_steps_sampled": 1264000, "num_agent_steps_trained": 1264000}, "done": false, "training_iteration": 79, "trial_id": "86f16_00000", "date": "2024-08-08_16-31-23", "timestamp": 1723149083, "time_this_iter_s": 16.223648071289062, "time_total_s": 1114.990391254425, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad104280>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1114.990391254425, "iterations_since_restore": 79, "perf": {"cpu_util_percent": 58.94782608695652, "ram_util_percent": 81.7695652173913}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6585668036595304, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.800947237564317, "policy_loss": -0.017067917463256553, "vf_loss": 1.817385121123165, "vf_explained_var": -8.151252219017515e-07, "kl": 0.006300337901627616, "entropy": 0.5040413245241693, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 224190.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.8570803304513297, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.3472634876767793, "policy_loss": -0.02341461550022359, "vf_loss": 3.3690293413897354, "vf_explained_var": 0.09513513675580422, "kl": 0.00824385227441566, "entropy": 1.061985578077535, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 76320.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 320000, "num_env_steps_trained": 320000, "num_agent_steps_sampled": 1280000, "num_agent_steps_trained": 1280000}, "env_runners": {"episode_reward_max": 153.57912759461178, "episode_reward_min": -21.633096650540573, "episode_reward_mean": 12.639466441344243, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 157, "episodes_timesteps_total": 3925, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -86.42087240538828}, "policy_reward_max": {"adversary_policy": 80.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 8.21656050955414, "agent_policy": -12.010215087318178}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, -21.633096650540573, 0.0, 19.5631736466085, 80.0, -4.238916589169903, 60.0, 20.0, -14.308837889212441, 0.0, 60.0, 0.0, -21.506291814491917, 0.0, 0.0, -4.094028483418072, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, -1.2702414155130104, 86.2601710335448, -3.7125966083811477, -11.321946505808612, 0.0, -3.527801914652614, -1.273112716328293, -1.245881618778597, -1.7433627221852632, 0.0, -4.706518558431636, -3.882381059442924, 40.58070889253919, 40.0, 60.0, 0.0, -8.721176819479384, 23.904483731531272, -0.6758664820839233, -4.273499638811031, 153.57912759461178, 80.0, 80.0, 0.0, -15.335652692801451, 0.0, 20.0, 0.0, 36.07738543054282, -6.317849449694912, 0.0, -13.491285782415376, 0.0, -1.0859085644199473, -15.383874744358943, -1.5086678679166643, 17.055786612562457, -9.831185907020473, 0.0, 37.335697378895276, 0.0, 33.84316147057889, -11.393077043494939, -4.875933414341777, -1.472162125110048, -19.153745144864203, 0.0, 60.0, 20.0, 60.0, -3.238814661193288, 0.0, 0.0, -1.3955085067746864, 0.0, -1.5890476873367032, -0.10600086008620502, 0.0, -4.507456844992225, -14.499831768101364, -0.49873588791504275, -12.067441755514352, 40.0, -13.969069786550829, 0.0, -6.816954033511615, 0.0, 0.0, 0.0, 72.98165986103484, -0.28209106885278556, 58.256245392665335, -14.15977389916437, -10.979561932261548, 56.779414476961705, -10.586779530922076, -16.00673594202907, 0.0, 60.0, 33.78177762929198, 12.32810865687073, 74.70194622924694, 18.59955880480834, 20.0, 20.0, 0.0, 40.0, 0.0, 20.0, 0.0, -1.1714135688140492, -4.01577004416676, 0.0, -0.3183941691994774, 79.22806903553827, -0.4547559063853035, 0.0, -5.291684474642067, 0.0, 59.857575804764814, 0.0, 115.52290489643748, 0.0, 0.0, 40.0, 0.0, 14.043815701214974, 40.0, 40.0, 9.687737620603972, 20.0, 75.575417676446, 0.0, 20.0, -9.109106061159501, 0.0, -3.9382139272939973, -0.1399191054505633, -13.362326567029703, 0.0, 0.0, 41.590742066296755, 20.0, 20.57958634694048, -0.061879658621725175, 60.0, 20.0, -5.025629455932094, -0.8137738343473888, 0.0, -20.345836613358276, 0.0, 59.41938307528363, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 80.0, 80.0, 80.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [0.0, -21.633096650540573, 0.0, -10.436826353391499, -40.0, -4.238916589169903, -30.0, -10.0, -14.308837889212441, 0.0, -30.0, 0.0, -21.506291814491917, 0.0, 0.0, -4.094028483418072, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -10.0, -1.2702414155130104, -63.73982896645521, -3.7125966083811477, -11.321946505808612, 0.0, -3.527801914652614, -1.273112716328293, -1.245881618778597, -1.7433627221852632, 0.0, -4.706518558431636, -3.882381059442924, -79.4192911074608, -20.0, -30.0, 0.0, -8.721176819479384, -36.09551626846873, -0.6758664820839233, -4.273499638811031, -86.42087240538828, -40.0, -40.0, 0.0, -15.335652692801451, 0.0, -10.0, 0.0, -23.92261456945718, -6.317849449694912, 0.0, -13.491285782415376, 0.0, -1.0859085644199473, -15.383874744358943, -1.5086678679166643, -12.944213387437538, -9.831185907020473, 0.0, -22.66430262110472, 0.0, -26.156838529421105, -11.393077043494939, -4.875933414341777, -1.472162125110048, -19.153745144864203, 0.0, -30.0, -10.0, -30.0, -33.23881466119329, 0.0, 0.0, -1.3955085067746864, 0.0, -1.5890476873367032, -0.10600086008620502, 0.0, -4.507456844992225, -14.499831768101364, -0.49873588791504275, -12.067441755514352, -20.0, -13.969069786550829, 0.0, -6.816954033511615, 0.0, 0.0, 0.0, -47.01834013896515, -0.28209106885278556, -31.74375460733467, -14.15977389916437, -10.979561932261548, -33.220585523038295, -10.586779530922076, -16.00673594202907, 0.0, -30.0, -26.21822237070802, -17.67189134312927, -45.298053770753064, -11.40044119519166, -10.0, -10.0, 0.0, -20.0, 0.0, -10.0, 0.0, -1.1714135688140492, -4.01577004416676, 0.0, -0.3183941691994774, -40.77193096446174, -0.4547559063853035, 0.0, -5.291684474642067, 0.0, -30.14242419523519, 0.0, -64.47709510356253, 0.0, 0.0, -20.0, 0.0, -15.956184298785024, -20.0, -20.0, -20.31226237939603, -10.0, -44.42458232355402, 0.0, -10.0, -9.109106061159501, 0.0, -3.9382139272939973, -0.1399191054505633, -13.362326567029703, 0.0, 0.0, -48.409257933703245, -10.0, -39.42041365305952, -0.061879658621725175, -30.0, -10.0, -5.025629455932094, -0.8137738343473888, 0.0, -20.345836613358276, 0.0, -30.58061692471636, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6816823695338993, "mean_inference_ms": 1.1940541801088622, "mean_action_processing_ms": 0.250791708061246, "mean_env_wait_ms": 0.511176210928961, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005137996309122463, "StateBufferConnector_ms": 0.004140206962634044, "ViewRequirementAgentConnector_ms": 0.11362323335781219}, "num_episodes": 157, "episode_return_max": 153.57912759461178, "episode_return_min": -21.633096650540573, "episode_return_mean": 12.639466441344243}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1280000, "num_agent_steps_trained": 1280000, "num_env_steps_sampled": 320000, "num_env_steps_trained": 320000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 207.0528369773316, "num_env_steps_trained_throughput_per_sec": 207.0528369773316, "timesteps_total": 320000, "num_env_steps_sampled_lifetime": 320000, "num_agent_steps_sampled_lifetime": 1280000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1280000, "timers": {"training_iteration_time_ms": 13749.815, "restore_workers_time_ms": 0.014, "training_step_time_ms": 13749.772, "sample_time_ms": 1238.287, "learn_time_ms": 12494.926, "learn_throughput": 320.13, "synch_weights_time_ms": 16.013}, "counters": {"num_env_steps_sampled": 320000, "num_env_steps_trained": 320000, "num_agent_steps_sampled": 1280000, "num_agent_steps_trained": 1280000}, "done": false, "training_iteration": 80, "trial_id": "86f16_00000", "date": "2024-08-08_16-31-43", "timestamp": 1723149103, "time_this_iter_s": 19.34840703010559, "time_total_s": 1134.3387982845306, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad104700>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1134.3387982845306, "iterations_since_restore": 80, "perf": {"cpu_util_percent": 69.14285714285714, "ram_util_percent": 82.64642857142857}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5880407728466159, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.3446183551076456, "policy_loss": -0.016033737952218238, "vf_loss": 1.3600491282787728, "vf_explained_var": 3.9645543335177373e-07, "kl": 0.006029677715570276, "entropy": 0.5139623248408026, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 227010.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.601581142346064, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.7850614665697018, "policy_loss": -0.02960353253389864, "vf_loss": 2.8123080893109242, "vf_explained_var": 0.20155790727585554, "kl": 0.011784501809787665, "entropy": 1.057278329320252, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 77280.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 324000, "num_env_steps_trained": 324000, "num_agent_steps_sampled": 1296000, "num_agent_steps_trained": 1296000}, "env_runners": {"episode_reward_max": 100.0, "episode_reward_min": -31.257983615253472, "episode_reward_mean": 9.958971167276456, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 158, "episodes_timesteps_total": 3950, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -71.07645485312548}, "policy_reward_max": {"adversary_policy": 50.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 6.455696202531645, "agent_policy": -9.408117440318481}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, -21.856194867138004, -31.257983615253472, 40.0, -0.4679040003103885, -1.9531449887028662, 0.0, -0.17746796674774967, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, -0.8383907962690329, 13.844640559976932, -1.0282518580432776, 20.0, 20.0, 0.0, 0.0, 20.0, 100.0, 19.171135422378974, -10.749445132309756, 0.0, 20.0, 0.0, 9.352000398078566, 17.800319425418472, 0.0, -2.9133115607288707, -0.044838192274855304, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -7.179213395460444, 40.0, -1.0596292205490254, 0.0, 0.0, 18.923545146874517, 0.0, 0.0, -1.8561832809821677, 0.0, -5.917814155747067, -5.856164453139957, -21.85447826866474, 0.0, 13.149943055831564, 0.0, 20.0, -0.590734494291496, -27.3548062129714, 8.30416400842303, 14.320152901326335, -0.5197098720243054, 60.0, 0.0, -2.253226225293663, 60.0, 60.0, 40.0, 80.0, 0.0, 0.0, -0.1948442304036624, 0.0, 0.0, 0.0, 20.0, 0.0, -21.708141969203528, 0.0, 19.960868870028953, -1.5788564585365295, -24.69712871150163, 0.0, -2.5544281780550597, -7.064200323334097, 0.0, 0.0, 80.0, 0.0, 0.0, -4.806577210725515, 80.0, -1.2232168862906723, 40.0, 60.0, 0.0, 0.0, -4.556954922723306, 16.70054567139184, 0.0, 0.0, -15.390611553920289, 60.0, 60.0, 0.0, -3.0077497117917096, -25.214606817696712, 0.0, -0.6264105250433127, -5.879681905005178, 20.0, 34.92883241730303, -8.570306981008265, -0.5510246344061998, 0.0, -16.83880929034553, -0.016787467814870505, 0.0, -10.067990442248462, 0.0, 0.0, 100.0, -1.2134832148564922, 0.0, 46.540673594321404, -0.0011078694291244418, 40.0, 39.6499638104258, 0.0, 29.93039129532599, 0.0, 0.0, -0.1571592971214808, -0.5482468571004717, -8.932867910011254, -1.5479042261152542, 0.0, 0.0, 56.380873848078195, 0.0, 38.848543305737685, 50.93612641713759, -0.23042587896710875, -12.976417438754979, 0.0, 0.0, 0.0, 0.0, -3.807960747814514, -0.29249235353580927, 0.0, 59.96591021672566, 0.0, 80.0, 38.63999983493211, 56.90178055186165, 20.0, -0.7476797512347289], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [0.0, -21.856194867138004, -31.257983615253472, -20.0, -0.4679040003103885, -1.9531449887028662, 0.0, -0.17746796674774967, 0.0, 0.0, -10.0, -10.0, -10.0, 0.0, -0.8383907962690329, -16.15535944002307, -1.0282518580432776, -10.0, -10.0, 0.0, 0.0, -10.0, -50.0, -10.828864577621026, -10.749445132309756, 0.0, -10.0, 0.0, -20.647999601921434, -12.19968057458153, 0.0, -2.9133115607288707, -0.044838192274855304, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -7.179213395460444, -20.0, -1.0596292205490254, 0.0, 0.0, -71.07645485312548, 0.0, 0.0, -1.8561832809821677, 0.0, -5.917814155747067, -5.856164453139957, -21.85447826866474, 0.0, -16.850056944168436, 0.0, -10.0, -0.590734494291496, -27.3548062129714, -21.69583599157697, -15.679847098673667, -0.5197098720243054, -30.0, 0.0, -2.253226225293663, -30.0, -30.0, -20.0, -40.0, 0.0, 0.0, -0.1948442304036624, 0.0, 0.0, 0.0, -10.0, 0.0, -21.708141969203528, 0.0, -10.039131129971047, -1.5788564585365295, -24.69712871150163, 0.0, -2.5544281780550597, -7.064200323334097, 0.0, 0.0, -40.0, 0.0, 0.0, -4.806577210725515, -40.0, -1.2232168862906723, -20.0, -30.0, 0.0, 0.0, -4.556954922723306, -13.29945432860816, 0.0, 0.0, -15.390611553920289, -30.0, -30.0, 0.0, -3.0077497117917096, -25.214606817696712, 0.0, -0.6264105250433127, -5.879681905005178, -10.0, -25.07116758269697, -8.570306981008265, -0.5510246344061998, 0.0, -16.83880929034553, -0.016787467814870505, 0.0, -10.067990442248462, 0.0, 0.0, -50.0, -1.2134832148564922, 0.0, -43.459326405678596, -0.0011078694291244418, -20.0, -20.3500361895742, 0.0, -30.06960870467401, 0.0, 0.0, -0.1571592971214808, -0.5482468571004717, -8.932867910011254, -1.5479042261152542, 0.0, 0.0, -33.61912615192181, 0.0, -21.151456694262315, -39.06387358286241, -0.23042587896710875, -12.976417438754979, 0.0, 0.0, 0.0, 0.0, -3.807960747814514, -0.29249235353580927, 0.0, -30.034089783274332, 0.0, -40.0, -21.360000165067884, -33.09821944813836, -10.0, -0.7476797512347289]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6819274893904289, "mean_inference_ms": 1.19487894983902, "mean_action_processing_ms": 0.25087424835457833, "mean_env_wait_ms": 0.511613135471422, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006320355813714523, "StateBufferConnector_ms": 0.003802776336669922, "ViewRequirementAgentConnector_ms": 0.10667390461209454}, "num_episodes": 158, "episode_return_max": 100.0, "episode_return_min": -31.257983615253472, "episode_return_mean": 9.958971167276456}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1296000, "num_agent_steps_trained": 1296000, "num_env_steps_sampled": 324000, "num_env_steps_trained": 324000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 297.1227160346726, "num_env_steps_trained_throughput_per_sec": 297.1227160346726, "timesteps_total": 324000, "num_env_steps_sampled_lifetime": 324000, "num_agent_steps_sampled_lifetime": 1296000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1296000, "timers": {"training_iteration_time_ms": 13787.996, "restore_workers_time_ms": 0.014, "training_step_time_ms": 13787.948, "sample_time_ms": 1240.583, "learn_time_ms": 12530.344, "learn_throughput": 319.225, "synch_weights_time_ms": 16.323}, "counters": {"num_env_steps_sampled": 324000, "num_env_steps_trained": 324000, "num_agent_steps_sampled": 1296000, "num_agent_steps_trained": 1296000}, "done": false, "training_iteration": 81, "trial_id": "86f16_00000", "date": "2024-08-08_16-31-57", "timestamp": 1723149117, "time_this_iter_s": 13.502194166183472, "time_total_s": 1147.840992450714, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad1049d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1147.840992450714, "iterations_since_restore": 81, "perf": {"cpu_util_percent": 44.974999999999994, "ram_util_percent": 79.995}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5474939020126002, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.8875206116243457, "policy_loss": -0.015747379134442154, "vf_loss": 1.902620789049365, "vf_explained_var": -8.400873089513035e-07, "kl": 0.006471989782778965, "entropy": 0.5025938539534596, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 229830.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.2881749633699657, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.0253394418706496, "policy_loss": -0.024037158822951217, "vf_loss": 3.047570983444651, "vf_explained_var": 0.1179121699805061, "kl": 0.009028067403800742, "entropy": 1.059222114769121, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 78240.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 328000, "num_env_steps_trained": 328000, "num_agent_steps_sampled": 1312000, "num_agent_steps_trained": 1312000}, "env_runners": {"episode_reward_max": 160.0, "episode_reward_min": -26.41541200001509, "episode_reward_mean": 14.48285465328533, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -80.0}, "policy_reward_max": {"adversary_policy": 80.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 8.765432098765432, "agent_policy": -11.813441643010966}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-12.524875792008508, 0.0, 17.017939517942175, 40.0, 80.0, 60.0, 0.0, 40.0, -11.231829916706593, 40.0, 20.0, 14.804560177996194, 80.0, -3.7172123165430717, 0.0, 38.829796843764235, -2.026252760340917, 60.0, 0.0, 0.0, 20.0, 0.0, 20.0, -26.41541200001509, 0.0, -2.439540927133841, 56.00353614727059, 0.0, 0.0, 0.0, 0.0, -15.597444509560916, -7.606785586913, 0.0, -12.58627041680692, 60.0, 0.0, 40.0, 0.0, 0.0, 60.0, 60.0, 0.0, 0.0, 0.0, 54.880797612009886, -1.196184503228821, 20.0, 0.0, 0.0, 0.0, 3.6082729064243555, 0.0, 20.0, -8.4643311197242, -0.4344776596844169, 0.0, 0.0, -3.029507055651463, 35.842877654130014, 73.91207839686702, 0.0, 60.0, -1.2662327616947322, -8.739503785940219, -0.33876007666557406, -0.8633967457449354, 0.0, 0.0, -11.906670276524121, -22.232760470201022, 0.0, -14.969267115987998, 0.0, 40.0, 40.0, -1.168000972171186, 36.35685238397973, 59.64067312098889, 0.0, 119.4795712908479, -1.1012168467123353, 52.45141990742408, 0.0, 20.0, 0.0, -0.49268887323518085, 60.0, 32.01066188641084, -6.588426956444708, -0.011708783391976008, -1.8996382633449649, -0.021331083009360485, -6.753507893229075, 19.97371783122548, -3.6145242889779814, 17.2830394552793, 160.0, 19.825577063288954, 0.0, -14.747950116789994, 0.0, 20.0, 43.85860784968558, 20.0, 19.250999317674474, -12.916827830704795, 0.0, -6.236885043027975, 100.0, -2.248050591451104, 0.0, 11.453068243370478, -2.7528783129963164, 1.9851598803704924, 71.5012097605701, 40.0, 33.72674271308146, 19.567633338816734, 0.0, 0.0, 0.0, 0.0, 58.41575399504244, 0.0, 20.0, 6.599123499145407, 0.0, 0.0, 34.97017466998639, -1.3023976471469378, -2.0653097281320107, 52.10810200557175, 20.0, 0.0, 0.0, 0.0, 80.0, 0.0, -5.504968054688724, 10.237445559453189, 0.0, 0.0, 20.0, 39.94594899054548, 0.0, -4.401096161355385, -5.479430925714015, 40.0, 0.0, 0.0, -18.261879373686064, -0.9660283037364936, -0.6260903975194032, 0.0, 0.0, 17.718967158234353, -0.29030310063217324, 80.0, 0.0, 0.0, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 80.0, 80.0, 80.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-12.524875792008508, 0.0, -12.982060482057825, -20.0, -40.0, -30.0, 0.0, -20.0, -11.231829916706593, -20.0, -10.0, -15.195439822003808, -40.0, -3.7172123165430717, 0.0, -21.17020315623576, -32.02625276034092, -30.0, 0.0, 0.0, -10.0, 0.0, -10.0, -26.41541200001509, 0.0, -2.439540927133841, -33.996463852729406, 0.0, 0.0, 0.0, 0.0, -15.597444509560916, -7.606785586913, 0.0, -12.58627041680692, -30.0, 0.0, -20.0, 0.0, 0.0, -30.0, -30.0, 0.0, 0.0, 0.0, -65.11920238799013, -1.196184503228821, -10.0, 0.0, 0.0, 0.0, -26.39172709357564, 0.0, -10.0, -8.4643311197242, -0.4344776596844169, 0.0, 0.0, -3.029507055651463, -24.157122345869983, -46.08792160313298, 0.0, -30.0, -1.2662327616947322, -8.739503785940219, -0.33876007666557406, -0.8633967457449354, 0.0, 0.0, -11.906670276524121, -22.232760470201022, 0.0, -14.969267115987998, 0.0, -20.0, -20.0, -1.168000972171186, -23.64314761602027, -30.359326879011103, 0.0, -60.520428709152114, -1.1012168467123353, -37.54858009257592, 0.0, -10.0, 0.0, -0.49268887323518085, -30.0, -27.989338113589152, -6.588426956444708, -0.011708783391976008, -1.8996382633449649, -0.021331083009360485, -6.753507893229075, -10.026282168774523, -3.6145242889779814, -12.7169605447207, -80.0, -10.174422936711045, 0.0, -14.747950116789994, 0.0, -10.0, -46.14139215031442, -10.0, -10.749000682325528, -12.916827830704795, 0.0, -6.236885043027975, -50.0, -2.248050591451104, 0.0, -18.546931756629522, -2.7528783129963164, -28.014840119629508, -48.498790239429894, -20.0, -26.27325728691854, -10.432366661183265, 0.0, 0.0, 0.0, 0.0, -31.584246004957553, 0.0, -10.0, -23.400876500854586, 0.0, 0.0, -25.029825330013594, -1.3023976471469378, -2.0653097281320107, -37.89189799442825, -10.0, 0.0, 0.0, 0.0, -40.0, 0.0, -5.504968054688724, -19.762554440546815, 0.0, 0.0, -10.0, -20.05405100945452, 0.0, -4.401096161355385, -5.479430925714015, -20.0, 0.0, 0.0, -18.261879373686064, -0.9660283037364936, -0.6260903975194032, 0.0, 0.0, -42.28103284176562, -0.29030310063217324, -40.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6813713381350404, "mean_inference_ms": 1.1937451394234289, "mean_action_processing_ms": 0.2505431817989907, "mean_env_wait_ms": 0.5111256839893894, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005152931919804326, "StateBufferConnector_ms": 0.0031588990011332946, "ViewRequirementAgentConnector_ms": 0.09309767205038189}, "num_episodes": 162, "episode_return_max": 160.0, "episode_return_min": -26.41541200001509, "episode_return_mean": 14.48285465328533}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1312000, "num_agent_steps_trained": 1312000, "num_env_steps_sampled": 328000, "num_env_steps_trained": 328000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 281.8324257428071, "num_env_steps_trained_throughput_per_sec": 281.8324257428071, "timesteps_total": 328000, "num_env_steps_sampled_lifetime": 328000, "num_agent_steps_sampled_lifetime": 1312000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1312000, "timers": {"training_iteration_time_ms": 14053.615, "restore_workers_time_ms": 0.014, "training_step_time_ms": 14053.565, "sample_time_ms": 1239.336, "learn_time_ms": 12793.454, "learn_throughput": 312.66, "synch_weights_time_ms": 19.984}, "counters": {"num_env_steps_sampled": 328000, "num_env_steps_trained": 328000, "num_agent_steps_sampled": 1312000, "num_agent_steps_trained": 1312000}, "done": false, "training_iteration": 82, "trial_id": "86f16_00000", "date": "2024-08-08_16-32-11", "timestamp": 1723149131, "time_this_iter_s": 14.220355749130249, "time_total_s": 1162.0613481998444, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3acdbadc0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1162.0613481998444, "iterations_since_restore": 82, "perf": {"cpu_util_percent": 48.904999999999994, "ram_util_percent": 78.67}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5525527280326008, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.89583527851612, "policy_loss": -0.017406136365623895, "vf_loss": 1.9126126624168234, "vf_explained_var": -8.980855874135985e-08, "kl": 0.006287485725250883, "entropy": 0.5013281316199201, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 232650.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.599021794150273, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.991319970538219, "policy_loss": -0.027370619413947375, "vf_loss": 3.0167715630183616, "vf_explained_var": 0.09773496575653554, "kl": 0.009595142666622324, "entropy": 1.0677633944277962, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 79200.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 332000, "num_env_steps_trained": 332000, "num_agent_steps_sampled": 1328000, "num_agent_steps_trained": 1328000}, "env_runners": {"episode_reward_max": 160.0, "episode_reward_min": -37.532149276345784, "episode_reward_mean": 15.063602098364035, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -80.0}, "policy_reward_max": {"adversary_policy": 80.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 8.765432098765432, "agent_policy": -11.23269419793226}, "custom_metrics": {}, "hist_stats": {"episode_reward": [20.0, 0.0, 0.0, 0.0, -13.461898599263833, 0.0, 80.0, 60.0, -21.413446105421926, 0.0, 50.35976700364529, -28.44925207388202, 0.0, 0.0, -0.12107659316464292, 160.0, -5.370055496586904, -12.60679232324073, 0.0, -1.4737614131663357, 60.0, 0.0, -9.830044336410788, 0.0, -4.860977772027811, -8.941640271717066, -0.13292106383384739, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, -1.3271965232373695, 79.46560813526727, 19.937244339964472, 20.0, 0.0, 0.0, -4.738630585977716, -0.22956504981253123, 40.0, -1.8894873530738987, 18.666413161304533, -3.6683860447449317, 0.0, 20.0, 40.0, 40.0, 0.0, 0.0, -0.29725337997777324, 140.0, -0.5206365060130547, -4.558043431464058, 40.0, 0.0, -3.06545841698311, -3.827779756514565, 0.0, 80.0, 40.0, 0.0, 0.0, 39.00725337789151, 0.0, -0.3736792686504897, 0.0, 18.782226332280594, -0.0623523844608187, 0.0, 20.0, -0.13446897799850643, 18.27988021834955, -5.726178705641547, 19.824126351415792, 20.0, -10.140601846676315, -0.5952180300952392, -0.010097597286168325, 45.778977547570705, 0.0, 60.0, -37.532149276345784, 20.0, 0.0, -2.8601658009635633, 0.0, -24.279784165356556, 0.0, -9.187679056191564, 40.0, 20.0, 18.30376701408314, 0.0, 0.0, -11.998485601657375, 18.052025408840443, 55.43580799938579, 120.0, 0.0, -13.625062302561645, 20.0, -5.838178194564284, 40.0, -5.750348602847335, 0.0, 46.85908942777253, -2.31437433746782, 0.0, 0.0, 20.0, 80.0, -1.4361271933042719, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 56.982701487696225, 99.54514678547241, 40.0, 60.0, 20.0, 37.27602634324058, 20.0, -8.527894105304112, -7.874771439533683, 11.675199932815712, 80.0, -0.2598480361034805, 0.0, 0.0, 80.0, 0.0, -0.1642625333369685, 140.0, -7.977209336106701, -2.480391194442111, 0.0, -0.9155206374946145, 0.0, 0.0, 0.0, 0.0, 20.0, -1.5067854993456136, -11.805240808905108, 0.0, 0.0, 40.0, 0.0, -2.0129314443914903, 20.0, 49.66151049499564, 20.0, -0.934882341095753, 6.963004595252958, 60.0, 16.556755792372623, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 80.0, 80.0, 80.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-10.0, 0.0, 0.0, 0.0, -13.461898599263833, 0.0, -40.0, -30.0, -21.413446105421926, 0.0, -39.64023299635471, -28.44925207388202, 0.0, 0.0, -0.12107659316464292, -80.0, -5.370055496586904, -12.60679232324073, 0.0, -1.4737614131663357, -30.0, 0.0, -9.830044336410788, 0.0, -4.860977772027811, -8.941640271717066, -0.13292106383384739, -20.0, 0.0, 0.0, 0.0, -10.0, -10.0, -1.3271965232373695, -40.53439186473274, -10.062755660035524, -10.0, 0.0, 0.0, -4.738630585977716, -0.22956504981253123, -20.0, -1.8894873530738987, -11.333586838695467, -3.6683860447449317, 0.0, -10.0, -20.0, -20.0, 0.0, 0.0, -0.29725337997777324, -70.0, -0.5206365060130547, -4.558043431464058, -20.0, 0.0, -3.06545841698311, -3.827779756514565, 0.0, -40.0, -20.0, 0.0, 0.0, -20.992746622108495, 0.0, -0.3736792686504897, 0.0, -11.217773667719406, -0.0623523844608187, 0.0, -10.0, -0.13446897799850643, -11.72011978165045, -5.726178705641547, -10.175873648584208, -10.0, -10.140601846676315, -0.5952180300952392, -0.010097597286168325, -44.221022452429295, 0.0, -30.0, -37.532149276345784, -10.0, 0.0, -2.8601658009635633, 0.0, -24.279784165356556, 0.0, -9.187679056191564, -20.0, -10.0, -11.696232985916861, 0.0, 0.0, -11.998485601657375, -11.947974591159557, -34.56419200061422, -60.0, 0.0, -13.625062302561645, -10.0, -5.838178194564284, -20.0, -5.750348602847335, 0.0, -43.14091057222747, -2.31437433746782, 0.0, 0.0, -10.0, -40.0, -1.4361271933042719, -10.0, -10.0, 0.0, 0.0, 0.0, 0.0, -33.017298512303775, -50.454853214527596, -20.0, -30.0, -10.0, -22.72397365675942, -10.0, -8.527894105304112, -7.874771439533683, -18.324800067184285, -40.0, -0.2598480361034805, 0.0, 0.0, -40.0, 0.0, -0.1642625333369685, -70.0, -7.977209336106701, -2.480391194442111, 0.0, -0.9155206374946145, 0.0, 0.0, 0.0, 0.0, -10.0, -1.5067854993456136, -11.805240808905108, 0.0, 0.0, -20.0, 0.0, -2.0129314443914903, -10.0, -40.33848950500436, -10.0, -0.934882341095753, -23.036995404747042, -30.0, -13.443244207627378, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.682074574795823, "mean_inference_ms": 1.1950515739663317, "mean_action_processing_ms": 0.25066846523096165, "mean_env_wait_ms": 0.5116007340194966, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0054508079717188705, "StateBufferConnector_ms": 0.0035011473997139638, "ViewRequirementAgentConnector_ms": 0.10935642101146557}, "num_episodes": 162, "episode_return_max": 160.0, "episode_return_min": -37.532149276345784, "episode_return_mean": 15.063602098364035}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1328000, "num_agent_steps_trained": 1328000, "num_env_steps_sampled": 332000, "num_env_steps_trained": 332000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 212.29825677371974, "num_env_steps_trained_throughput_per_sec": 212.29825677371974, "timesteps_total": 332000, "num_env_steps_sampled_lifetime": 332000, "num_agent_steps_sampled_lifetime": 1328000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1328000, "timers": {"training_iteration_time_ms": 14641.189, "restore_workers_time_ms": 0.014, "training_step_time_ms": 14641.139, "sample_time_ms": 1252.821, "learn_time_ms": 13367.451, "learn_throughput": 299.234, "synch_weights_time_ms": 20.067}, "counters": {"num_env_steps_sampled": 332000, "num_env_steps_trained": 332000, "num_agent_steps_sampled": 1328000, "num_agent_steps_trained": 1328000}, "done": false, "training_iteration": 83, "trial_id": "86f16_00000", "date": "2024-08-08_16-32-30", "timestamp": 1723149150, "time_this_iter_s": 18.868157863616943, "time_total_s": 1180.9295060634613, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad1c58b0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1180.9295060634613, "iterations_since_restore": 83, "perf": {"cpu_util_percent": 68.42222222222223, "ram_util_percent": 81.62962962962963}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5845653602364638, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.4888203984456705, "policy_loss": -0.016762837298389472, "vf_loss": 1.5049405289457198, "vf_explained_var": -1.6197245171729555e-06, "kl": 0.006427047931094909, "entropy": 0.47631447110193, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 235470.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.5233348650236924, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.017840102190773, "policy_loss": -0.02781448166303259, "vf_loss": 3.0436491766323646, "vf_explained_var": 0.11825354595979055, "kl": 0.010027074500590061, "entropy": 1.0368474291016658, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 80160.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 336000, "num_env_steps_trained": 336000, "num_agent_steps_sampled": 1344000, "num_agent_steps_trained": 1344000}, "env_runners": {"episode_reward_max": 119.83940130971413, "episode_reward_min": -69.50790961474803, "episode_reward_mean": 10.98744011190018, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 157, "episodes_timesteps_total": 3925, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -69.50790961474803}, "policy_reward_max": {"adversary_policy": 60.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 7.197452229299363, "agent_policy": -10.60491657599791}, "custom_metrics": {}, "hist_stats": {"episode_reward": [20.0, 0.0, 60.0, 20.0, 0.0, 80.0, 0.0, 18.238760466325196, 40.0, -4.529334878672602, -7.499065250627981, -0.13010505328116428, 38.14529686931523, 0.0, 40.0, -2.0110697822210772, -14.467963789955068, 0.0, -0.3672324293532314, -8.873930866577332, 0.0, 0.0, -4.306107545939243, 32.08736079015649, -18.123423185664326, -21.252680466429517, -17.50025780860208, -5.410366204220925, 0.0, -0.5242684317621904, 0.0, 40.0, 0.0, -0.03349767560751116, 40.0, -18.819858627217663, -54.75863680797925, 20.0, -7.948326661079559, -9.35424180742487, 0.0, -69.50790961474803, 20.0, 40.0, 0.0, 79.96289497010655, 0.0, 80.0, -11.045968948055537, -19.2601731154476, 40.0, 0.0, 0.0, 60.0, 119.83940130971413, -9.542057724987211, 0.0, 60.0, 13.229074251033268, -33.32861478615123, 60.0, 59.40902075168363, -0.8389972872171048, 57.88929381926134, 20.0, -0.6249075693777262, -6.9258538558395415, 0.0, 0.0, 0.0, 0.0, 20.0, -9.575461650805101, 60.0, 17.92888468937083, 0.0, 0.0, -2.4136081888184497, 40.0, 0.0, 20.0, -22.95474998103106, 0.0, -0.14842299064664277, 0.0, 35.750903598808236, 0.0, -5.260329787885798, -2.295107754375464, 20.0, 0.0, 0.0, -0.046229251695871776, -2.6609996383568113, 59.63468190946855, -1.2837382632331573, -0.6030275532712692, 58.69014724895367, 0.0, -12.435340347377318, -2.8388447273936013, 0.0, 20.0, 40.0, -13.200570721283395, 60.0, 0.0, 60.0, 0.0, 20.0, 80.0, 16.214807901776393, 0.0, 0.0, -0.7463198758855794, 0.0, -16.821285029114243, 0.0, -12.28154626218528, 38.57943789183693, -2.6344456109731076, -0.7830065438705025, -0.09618127115808228, 0.0, -0.9335748749697725, -1.2389045125197584, 96.99186459137516, -1.101052847706283, 20.0, 0.0, -0.034137807850475044, 0.0, -3.6854039617546563, -0.11736448204300198, 14.668258782905895, 1.5037544586676113, 0.0, 0.0, 0.0, 0.0, -0.3818470684892328, 0.0, 0.0, 0.0, 0.0, -0.6248995807819457, 20.0, -2.344977558857609, 0.0, 38.71627996296189, -2.214735879876666, 80.0, -2.6739162039060282, 0.0, 60.0, 40.0, -1.0371462928370778], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-10.0, 0.0, -30.0, -10.0, 0.0, -40.0, 0.0, -11.761239533674804, -20.0, -4.529334878672602, -7.499065250627981, -0.13010505328116428, -21.854703130684765, 0.0, -20.0, -2.0110697822210772, -14.467963789955068, 0.0, -0.3672324293532314, -8.873930866577332, 0.0, 0.0, -4.306107545939243, -27.912639209843512, -18.123423185664326, -21.252680466429517, -17.50025780860208, -5.410366204220925, 0.0, -0.5242684317621904, 0.0, -20.0, 0.0, -0.03349767560751116, -20.0, -18.819858627217663, -54.75863680797925, -10.0, -7.948326661079559, -9.35424180742487, 0.0, -69.50790961474803, -10.0, -20.0, 0.0, -40.03710502989345, 0.0, -40.0, -11.045968948055537, -19.2601731154476, -20.0, 0.0, 0.0, -30.0, -60.16059869028587, -9.542057724987211, 0.0, -30.0, -16.770925748966732, -33.32861478615123, -30.0, -30.59097924831638, -0.8389972872171048, -32.11070618073866, -10.0, -0.6249075693777262, -6.9258538558395415, 0.0, 0.0, 0.0, 0.0, -10.0, -9.575461650805101, -30.0, -12.071115310629171, 0.0, 0.0, -2.4136081888184497, -20.0, 0.0, -10.0, -22.95474998103106, 0.0, -0.14842299064664277, 0.0, -24.249096401191764, 0.0, -5.260329787885798, -2.295107754375464, -10.0, 0.0, 0.0, -0.046229251695871776, -2.6609996383568113, -30.365318090531453, -1.2837382632331573, -0.6030275532712692, -31.309852751046325, 0.0, -12.435340347377318, -2.8388447273936013, 0.0, -10.0, -20.0, -13.200570721283395, -30.0, 0.0, -30.0, 0.0, -10.0, -40.0, -13.785192098223606, 0.0, 0.0, -0.7463198758855794, 0.0, -16.821285029114243, 0.0, -12.28154626218528, -21.42056210816307, -2.6344456109731076, -0.7830065438705025, -0.09618127115808228, 0.0, -0.9335748749697725, -1.2389045125197584, -53.008135408624845, -1.101052847706283, -10.0, 0.0, -0.034137807850475044, 0.0, -3.6854039617546563, -0.11736448204300198, -15.331741217094113, -28.49624554133239, 0.0, 0.0, 0.0, 0.0, -0.3818470684892328, 0.0, 0.0, 0.0, 0.0, -0.6248995807819457, -10.0, -2.344977558857609, 0.0, -21.28372003703811, -2.214735879876666, -40.0, -2.6739162039060282, 0.0, -30.0, -20.0, -1.0371462928370778]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6818787641404752, "mean_inference_ms": 1.1941392159931157, "mean_action_processing_ms": 0.25043728091998996, "mean_env_wait_ms": 0.5113090783410285, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004982720514771285, "StateBufferConnector_ms": 0.0033712690802896097, "ViewRequirementAgentConnector_ms": 0.09120588849304588}, "num_episodes": 157, "episode_return_max": 119.83940130971413, "episode_return_min": -69.50790961474803, "episode_return_mean": 10.98744011190018}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1344000, "num_agent_steps_trained": 1344000, "num_env_steps_sampled": 336000, "num_env_steps_trained": 336000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 262.71751644335706, "num_env_steps_trained_throughput_per_sec": 262.71751644335706, "timesteps_total": 336000, "num_env_steps_sampled_lifetime": 336000, "num_agent_steps_sampled_lifetime": 1344000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1344000, "timers": {"training_iteration_time_ms": 14932.808, "restore_workers_time_ms": 0.014, "training_step_time_ms": 14932.758, "sample_time_ms": 1244.176, "learn_time_ms": 13667.025, "learn_throughput": 292.675, "synch_weights_time_ms": 20.74}, "counters": {"num_env_steps_sampled": 336000, "num_env_steps_trained": 336000, "num_agent_steps_sampled": 1344000, "num_agent_steps_trained": 1344000}, "done": false, "training_iteration": 84, "trial_id": "86f16_00000", "date": "2024-08-08_16-32-46", "timestamp": 1723149166, "time_this_iter_s": 15.279537200927734, "time_total_s": 1196.209043264389, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad1c5af0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1196.209043264389, "iterations_since_restore": 84, "perf": {"cpu_util_percent": 50.4090909090909, "ram_util_percent": 80.82727272727271}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5761920926841438, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.6962789818116113, "policy_loss": -0.016846488698605278, "vf_loss": 1.7124704489893947, "vf_explained_var": -1.3004380760463417e-06, "kl": 0.006550215254795315, "entropy": 0.4705269233766177, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 238290.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.646273071318865, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.932884949321548, "policy_loss": -0.026891891118915132, "vf_loss": 2.957851819197337, "vf_explained_var": 0.04880846006174882, "kl": 0.009625125478030367, "entropy": 1.0113760594278574, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 81120.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 340000, "num_env_steps_trained": 340000, "num_agent_steps_sampled": 1360000, "num_agent_steps_trained": 1360000}, "env_runners": {"episode_reward_max": 80.0, "episode_reward_min": -19.725877544268748, "episode_reward_mean": 9.82697117970373, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -50.44246703842024}, "policy_reward_max": {"adversary_policy": 40.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 6.296296296296297, "agent_policy": -9.06191770918516}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.0, -0.07119690722286132, 20.0, -0.5299779789073755, 20.0, 29.894652312731967, 0.0, 0.0, -7.671297662494402, 28.731273103276678, 40.0, -3.8100747074196084, -0.7163805768501619, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -3.2406465282832255, 20.0, 20.0, 40.0, 0.0, 60.0, 34.38998707164216, 0.0, 0.0, -3.753146220756444, -1.6388038400284988, 0.0, 58.136111234823424, 0.0, 0.0, 0.0, -2.315115368489569, 0.0, 0.0, 40.0, 0.0, -1.3070214859765383, -3.3644921720612304, 39.719429916410945, 0.0, -8.495240191292694, -7.340261069020062, 0.0, 0.0, 0.0, 60.0, 35.73226493404008, -2.2768253356555466, 0.0, 0.0, -4.591788740285785, 36.508825205548625, 20.0, -6.352044564305175, -0.5739364890678478, 0.0, 0.0, -7.206477896436014, 5.886916611406859, -1.0048241331620145, -5.753851002640414, -2.81144220153124, -7.884562041862877, 40.0, -5.301464206084452, -1.337763283055451, -6.835075184117333, -1.7589706342365374, 20.0, 0.0, 0.0, 60.0, -19.725877544268748, 0.0, 40.0, 76.26559838118321, -1.9172304912648863, 19.095461326360955, -3.265777037258193, 0.0, -0.1662799435202833, 0.0, 33.43392608560884, -2.763448479080559, -0.0014847740440471213, 0.0, -2.222796421432867, -0.9539981263760422, -8.903620558546463, 5.8930925155710945, 71.30010219413, 20.0, 0.0, 0.0, 57.11154763214344, 32.76832726909355, 40.0, -2.1452843194133453, -5.151272727690996, -0.8637617434435607, -0.6393932029148552, -2.1916872081445082, -0.5094519956520682, -0.05695048725512519, 0.0, 0.0, 39.50033184546349, -13.326319908784924, -4.589704377738525, 0.0, 55.743670973850875, 20.0, -2.0384747565419206, 0.0, 0.0, -1.858324099750629, -0.006070332310320614, 0.0, 0.0, 0.0, 60.0, -13.16696594773331, -12.563719372259907, 0.0, 0.0, 11.457739691893543, 20.0, 0.0, 0.0, -2.141266941730747, 80.0, -7.651364440910803, 40.0, -10.738820631168416, -19.245872696433352, 0.0, 39.592408323606904, 0.0, -12.384787031809106, 39.95658004708264, -8.735013780042681, 0.0, 40.0, 40.0, 0.0, 40.0, -3.839325398931196, 0.0, 55.5201156376707, 0.0, 0.0, 39.55753296157976, 60.0, 16.3892641894033, 0.0, 0.0, -8.908803154823365], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-20.0, -0.07119690722286132, -10.0, -0.5299779789073755, -10.0, -30.105347687268036, 0.0, 0.0, -7.671297662494402, -31.26872689672332, -20.0, -3.8100747074196084, -0.7163805768501619, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -3.2406465282832255, -10.0, -10.0, -20.0, 0.0, -30.0, -25.61001292835784, 0.0, 0.0, -3.753146220756444, -1.6388038400284988, 0.0, -31.863888765176572, 0.0, 0.0, 0.0, -2.315115368489569, 0.0, 0.0, -20.0, 0.0, -1.3070214859765383, -3.3644921720612304, -20.280570083589055, 0.0, -8.495240191292694, -7.340261069020062, 0.0, 0.0, 0.0, -30.0, -24.26773506595992, -2.2768253356555466, 0.0, 0.0, -4.591788740285785, -23.491174794451368, -10.0, -6.352044564305175, -0.5739364890678478, 0.0, 0.0, -7.206477896436014, -24.11308338859314, -1.0048241331620145, -5.753851002640414, -2.81144220153124, -7.884562041862877, -20.0, -5.301464206084452, -1.337763283055451, -36.83507518411732, -1.7589706342365374, -10.0, 0.0, 0.0, -30.0, -19.725877544268748, 0.0, -20.0, -43.7344016188168, -1.9172304912648863, -10.904538673639045, -3.265777037258193, 0.0, -0.1662799435202833, 0.0, -26.566073914391175, -2.763448479080559, -0.0014847740440471213, 0.0, -2.222796421432867, -0.9539981263760422, -8.903620558546463, -24.106907484428902, -48.699897805869995, -10.0, 0.0, 0.0, -32.888452367856566, -27.231672730906457, -20.0, -2.1452843194133453, -35.151272727690994, -0.8637617434435607, -0.6393932029148552, -2.1916872081445082, -0.5094519956520682, -0.05695048725512519, 0.0, 0.0, -20.499668154536508, -13.326319908784924, -4.589704377738525, 0.0, -34.256329026149125, -10.0, -2.0384747565419206, 0.0, 0.0, -1.858324099750629, -0.006070332310320614, 0.0, 0.0, 0.0, -30.0, -13.16696594773331, -12.563719372259907, 0.0, 0.0, -18.542260308106457, -10.0, 0.0, 0.0, -2.141266941730747, -40.0, -7.651364440910803, -20.0, -10.738820631168416, -19.245872696433352, 0.0, -20.407591676393096, 0.0, -12.384787031809106, -20.043419952917365, -8.735013780042681, 0.0, -20.0, -20.0, 0.0, -20.0, -3.839325398931196, 0.0, -34.4798843623293, 0.0, 0.0, -50.44246703842024, -30.0, -13.610735810596701, 0.0, 0.0, -8.908803154823365]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6820197210403878, "mean_inference_ms": 1.194170131905416, "mean_action_processing_ms": 0.2503975327861735, "mean_env_wait_ms": 0.5113750808622202, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004955427146252291, "StateBufferConnector_ms": 0.0035050474567177854, "ViewRequirementAgentConnector_ms": 0.10068431312655225}, "num_episodes": 162, "episode_return_max": 80.0, "episode_return_min": -19.725877544268748, "episode_return_mean": 9.82697117970373}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1360000, "num_agent_steps_trained": 1360000, "num_env_steps_sampled": 340000, "num_env_steps_trained": 340000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 243.89232544682224, "num_env_steps_trained_throughput_per_sec": 243.89232544682224, "timesteps_total": 340000, "num_env_steps_sampled_lifetime": 340000, "num_agent_steps_sampled_lifetime": 1360000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1360000, "timers": {"training_iteration_time_ms": 15463.47, "restore_workers_time_ms": 0.015, "training_step_time_ms": 15463.414, "sample_time_ms": 1258.438, "learn_time_ms": 14181.468, "learn_throughput": 282.058, "synch_weights_time_ms": 22.61}, "counters": {"num_env_steps_sampled": 340000, "num_env_steps_trained": 340000, "num_agent_steps_sampled": 1360000, "num_agent_steps_trained": 1360000}, "done": false, "training_iteration": 85, "trial_id": "86f16_00000", "date": "2024-08-08_16-33-02", "timestamp": 1723149182, "time_this_iter_s": 16.415632724761963, "time_total_s": 1212.624675989151, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad1edc10>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1212.624675989151, "iterations_since_restore": 85, "perf": {"cpu_util_percent": 52.26521739130435, "ram_util_percent": 81.01739130434781}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.574687373949915, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.6082717676323357, "policy_loss": -0.017298984600326826, "vf_loss": 1.624926122853942, "vf_explained_var": 4.3686822796544285e-07, "kl": 0.00644631037315162, "entropy": 0.4696578843479461, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 241110.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.492633417621255, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.8420999867841603, "policy_loss": -0.02461131466552615, "vf_loss": 2.8648341468224925, "vf_explained_var": 0.09777088146656751, "kl": 0.009385787292265491, "entropy": 0.9838063029572368, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 82080.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 344000, "num_env_steps_trained": 344000, "num_agent_steps_sampled": 1376000, "num_agent_steps_trained": 1376000}, "env_runners": {"episode_reward_max": 140.0, "episode_reward_min": -34.3108337239318, "episode_reward_mean": 14.890600929250315, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 158, "episodes_timesteps_total": 3950, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -70.0}, "policy_reward_max": {"adversary_policy": 70.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 8.670886075949367, "agent_policy": -11.122057298597786}, "custom_metrics": {}, "hist_stats": {"episode_reward": [33.97602658627928, 60.0, 0.0, 0.0, -0.6800532827938244, 0.0, 60.0, 0.0, 0.0, 0.0, 60.0, 0.0, -0.951900559850759, -2.099397506542359, 20.0, 0.0, -11.177629739627255, 0.0, 0.0, -9.093230498613394, 0.0, 20.0, -23.618237462370217, -10.011515179231324, 0.0, 0.0, 0.0, 100.0, -0.6817258521171232, -8.54491932253956, 100.0, 20.0, -5.02950461559594, -2.5144331637549993, 0.0, 0.0, -2.006453961185597, -0.0531309666130142, 140.0, 80.0, 0.0, 40.0, 0.0, 0.0, 0.0, -0.5906790933268335, 20.0, 0.0, -8.615361917781664, 59.54555082064775, 51.86474361955655, 60.0, 0.0, 0.0, 60.0, 38.79447024088955, 0.0, -0.5756535147800768, 57.489121939918434, -34.3108337239318, 0.0, 0.0, 0.0, -7.830078969070748, -7.293675792421679, 0.0, 19.128629384733618, -2.86344535156121, 37.46171370690002, -20.39344112430097, 40.0, 40.0, 40.0, 60.0, 40.0, 0.0, -12.633721243490356, 0.0, 0.0, 100.0, -2.045450614207308, -2.476941003556667, 19.307653518985145, 80.0, 40.0, 80.0, 0.0, 140.0, 19.992917451345697, 0.0, 0.0, 20.0, 0.0, 20.0, 0.0, 0.0, -2.157684492509931, 0.0, 0.0, 47.49379792705693, 0.0, -0.35200515505101504, -7.734868247931672, -21.18713215236454, -1.9067493427589122, 0.0, -24.1320888301509, 0.0, -3.573859024542195, 0.0, -2.116900201910716, 60.0, 60.0, 60.0, -10.152127084071354, 0.0, 40.0, 0.0, 0.0, 0.0, -1.824557610928621, 0.0, -1.4367523750145184, 0.0, 60.0, -7.452563232611724, 40.0, 0.0, 0.0, -15.21643343867136, 74.73481340699198, 16.531580323261057, -1.0899447093334225, 26.78492200075841, 0.0, -11.110648578131153, 20.0, -2.390419208043123, 39.73700285301832, 38.29781395415185, 0.0, -2.899397346899751, 0.0, 0.0, -2.5029762057455778, 78.69097814459569, 0.0, 0.0, 20.0, 34.45717379560817, -0.20434334285575728, -1.413621977900943, -1.2218528315021804, 0.0, 20.0, -2.114229299822611, 0.0, 38.70860629486791], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0], "policy_agent_policy_reward": [-26.023973413720718, -30.0, 0.0, 0.0, -0.6800532827938244, 0.0, -30.0, 0.0, 0.0, 0.0, -30.0, 0.0, -0.951900559850759, -2.099397506542359, -10.0, 0.0, -11.177629739627255, 0.0, 0.0, -9.093230498613394, 0.0, -10.0, -23.618237462370217, -10.011515179231324, 0.0, 0.0, 0.0, -50.0, -0.6817258521171232, -8.54491932253956, -50.0, -10.0, -5.02950461559594, -2.5144331637549993, 0.0, 0.0, -2.006453961185597, -0.0531309666130142, -70.0, -40.0, 0.0, -20.0, 0.0, 0.0, 0.0, -0.5906790933268335, -10.0, 0.0, -8.615361917781664, -30.454449179352252, -38.13525638044346, -30.0, 0.0, 0.0, -30.0, -21.205529759110448, 0.0, -0.5756535147800768, -32.510878060081566, -34.3108337239318, 0.0, 0.0, 0.0, -7.830078969070748, -7.293675792421679, 0.0, -10.871370615266384, -2.86344535156121, -22.538286293099976, -20.39344112430097, -20.0, -20.0, -20.0, -30.0, -20.0, 0.0, -12.633721243490356, 0.0, 0.0, -50.0, -2.045450614207308, -2.476941003556667, -10.692346481014859, -40.0, -20.0, -40.0, 0.0, -70.0, -10.007082548654301, 0.0, 0.0, -10.0, 0.0, -10.0, 0.0, 0.0, -2.157684492509931, 0.0, 0.0, -42.50620207294307, 0.0, -0.35200515505101504, -7.734868247931672, -21.18713215236454, -1.9067493427589122, 0.0, -24.1320888301509, 0.0, -3.573859024542195, 0.0, -2.116900201910716, -30.0, -30.0, -30.0, -10.152127084071354, 0.0, -20.0, 0.0, 0.0, 0.0, -1.824557610928621, 0.0, -1.4367523750145184, 0.0, -30.0, -37.452563232611716, -20.0, 0.0, 0.0, -15.21643343867136, -45.26518659300803, -13.468419676738943, -1.0899447093334225, -33.215077999241586, 0.0, -11.110648578131153, -10.0, -2.390419208043123, -20.262997146981682, -21.702186045848148, 0.0, -2.899397346899751, 0.0, 0.0, -2.5029762057455778, -41.30902185540431, 0.0, 0.0, -10.0, -25.542826204391833, -0.20434334285575728, -1.413621977900943, -1.2218528315021804, 0.0, -10.0, -2.114229299822611, 0.0, -21.291393705132077]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6817009326780439, "mean_inference_ms": 1.1932647777443008, "mean_action_processing_ms": 0.25007491987221786, "mean_env_wait_ms": 0.5110511000922277, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004740832727166671, "StateBufferConnector_ms": 0.003325335587127299, "ViewRequirementAgentConnector_ms": 0.09535845321944997}, "num_episodes": 158, "episode_return_max": 140.0, "episode_return_min": -34.3108337239318, "episode_return_mean": 14.890600929250315}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1376000, "num_agent_steps_trained": 1376000, "num_env_steps_sampled": 344000, "num_env_steps_trained": 344000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 247.98759702535781, "num_env_steps_trained_throughput_per_sec": 247.98759702535781, "timesteps_total": 344000, "num_env_steps_sampled_lifetime": 344000, "num_agent_steps_sampled_lifetime": 1376000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1376000, "timers": {"training_iteration_time_ms": 15957.042, "restore_workers_time_ms": 0.015, "training_step_time_ms": 15956.984, "sample_time_ms": 1266.781, "learn_time_ms": 14666.147, "learn_throughput": 272.737, "synch_weights_time_ms": 23.164}, "counters": {"num_env_steps_sampled": 344000, "num_env_steps_trained": 344000, "num_agent_steps_sampled": 1376000, "num_agent_steps_trained": 1376000}, "done": false, "training_iteration": 86, "trial_id": "86f16_00000", "date": "2024-08-08_16-33-19", "timestamp": 1723149199, "time_this_iter_s": 16.143471002578735, "time_total_s": 1228.7681469917297, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad2ae1f0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1228.7681469917297, "iterations_since_restore": 86, "perf": {"cpu_util_percent": 52.387499999999996, "ram_util_percent": 80.35000000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5927551570407887, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.8049461747314912, "policy_loss": -0.018171996216732243, "vf_loss": 1.8225380466762164, "vf_explained_var": -4.0095748630821284e-07, "kl": 0.005801247801241037, "entropy": 0.4663022351708818, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 243930.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.4953070332606635, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.0272326700389387, "policy_loss": -0.028623277459701058, "vf_loss": 3.0536441572010515, "vf_explained_var": 0.06649031440416972, "kl": 0.011058976483506436, "entropy": 0.9857633815457424, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 83040.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 348000, "num_env_steps_trained": 348000, "num_agent_steps_sampled": 1392000, "num_agent_steps_trained": 1392000}, "env_runners": {"episode_reward_max": 140.0, "episode_reward_min": -42.51859828369951, "episode_reward_mean": 17.714791870955956, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -70.0}, "policy_reward_max": {"adversary_policy": 70.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 10.185185185185185, "agent_policy": -12.840763684599601}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 20.0, 60.0, -8.283248772605596, -4.7350467754118, -0.20307736858106717, 20.0, 0.0, 40.0, 60.0, 0.0, -1.0686125598584617, 19.912438603670687, 0.0, 0.0, 0.0, 119.63915424255026, 48.28937924502199, 60.0, 20.0, -8.18209342557119, 0.0, 0.0, 40.0, 80.0, -14.433164739751179, -1.2532278339312686, 52.58127912588804, 0.0, 0.0, -0.1225877951836496, 29.135825257496847, 34.168871689481634, 16.562108951212174, 0.0, 100.0, 0.0, -7.03837680452008, 80.0, 39.23458581993927, 0.0, -3.6534519652138426, -2.7110934083743534, -1.4726368001763346, 60.0, -2.347052645189458, 0.0, 40.0, 0.0, -4.561605036400625, 140.0, 40.0, 40.0, 18.10613690016295, 80.0, -42.51859828369951, -0.9442920253491904, -1.106879573294538, 17.101688236290176, 40.0, 60.0, 0.0, 80.0, -21.404604583399117, 0.0, 52.27580758431484, -1.2178563785513485, 0.0, -1.9650085294604536, 30.56122097211805, 20.0, -7.338787079441753, 0.0, 80.0, 0.0, 0.0, 0.0, 80.0, -0.1260019152979519, 0.0, -0.11106167435544712, -0.08456284249378943, 0.0, -7.131864638031932, 8.860321151506088, 0.0, 80.0, 40.0, -1.8273387212717562, -6.63306064799003, -0.2697187375314114, 0.0, 19.73951999510232, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 0.0, -16.64636800824451, -20.151872457670745, 40.0, -3.3249837087493628, 25.329896310149564, 20.0, 0.0, 40.0, 0.0, 0.0, 39.501159171299975, -1.1709410520291441, 0.0, 0.0, 40.0, 116.68110222740418, 0.0, 16.823788910139285, 60.0, 0.0, 0.0, 20.0, 16.105198011547973, -0.9788535904977325, 59.96937168405691, 40.0, 0.0, 1.6513171114937657, 38.60139109088599, 100.0, 0.0, 80.0, -13.863806295238957, 40.0, -1.16287871883337, 0.0, 19.484244374046124, 16.937064640703667, 0.0, 0.0, 0.0, 0.0, -1.2070501543389, 20.0, 19.77271335681929, 20.0, 0.0, 0.0, 0.0, 38.262139712063615, 0.0, 0.0, 0.0, 20.0, -11.700848672727547, -18.987623944107227, 99.84572646420536, -14.523738065044723, 80.0, -8.87329151628688], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [0.0, 0.0, 0.0, -10.0, -30.0, -8.283248772605596, -4.7350467754118, -0.20307736858106717, -10.0, 0.0, -20.0, -30.0, 0.0, -1.0686125598584617, -10.087561396329313, 0.0, 0.0, 0.0, -60.360845757449724, -41.710620754978024, -30.0, -10.0, -8.18209342557119, 0.0, 0.0, -20.0, -40.0, -14.433164739751179, -1.2532278339312686, -37.418720874111955, 0.0, 0.0, -0.1225877951836496, -30.864174742503156, -55.831128310518366, -13.437891048787822, 0.0, -50.0, 0.0, -7.03837680452008, -40.0, -20.76541418006073, 0.0, -3.6534519652138426, -2.7110934083743534, -1.4726368001763346, -30.0, -2.347052645189458, 0.0, -20.0, 0.0, -4.561605036400625, -70.0, -20.0, -20.0, -11.89386309983705, -40.0, -42.51859828369951, -0.9442920253491904, -1.106879573294538, -12.898311763709824, -20.0, -30.0, 0.0, -40.0, -21.404604583399117, 0.0, -37.72419241568516, -1.2178563785513485, 0.0, -1.9650085294604536, -29.43877902788195, -10.0, -7.338787079441753, 0.0, -40.0, 0.0, 0.0, 0.0, -40.0, -0.1260019152979519, 0.0, -0.11106167435544712, -0.08456284249378943, 0.0, -7.131864638031932, -21.139678848493915, 0.0, -40.0, -20.0, -1.8273387212717562, -6.63306064799003, -0.2697187375314114, 0.0, -10.26048000489768, 0.0, 0.0, 0.0, 0.0, -10.0, -10.0, 0.0, -16.64636800824451, -20.151872457670745, -20.0, -3.3249837087493628, -34.670103689850436, -10.0, 0.0, -20.0, 0.0, 0.0, -20.498840828700022, -1.1709410520291441, 0.0, 0.0, -20.0, -63.31889777259582, 0.0, -43.176211089860715, -30.0, 0.0, 0.0, -10.0, -13.894801988452029, -0.9788535904977325, -30.030628315943083, -20.0, 0.0, -28.34868288850624, -21.39860890911401, -50.0, 0.0, -40.0, -13.863806295238957, -20.0, -1.16287871883337, 0.0, -10.515755625953872, -13.062935359296334, 0.0, 0.0, 0.0, 0.0, -1.2070501543389, -10.0, -10.22728664318071, -10.0, 0.0, 0.0, 0.0, -21.73786028793639, 0.0, 0.0, 0.0, -10.0, -11.700848672727547, -18.987623944107227, -50.154273535794644, -14.523738065044723, -40.0, -8.87329151628688]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6813607844341811, "mean_inference_ms": 1.1924899118893477, "mean_action_processing_ms": 0.24982196076912483, "mean_env_wait_ms": 0.5107614280112466, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005250654102843485, "StateBufferConnector_ms": 0.003369502079339675, "ViewRequirementAgentConnector_ms": 0.0965190522464705}, "num_episodes": 162, "episode_return_max": 140.0, "episode_return_min": -42.51859828369951, "episode_return_mean": 17.714791870955956}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1392000, "num_agent_steps_trained": 1392000, "num_env_steps_sampled": 348000, "num_env_steps_trained": 348000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 244.6758708450045, "num_env_steps_trained_throughput_per_sec": 244.6758708450045, "timesteps_total": 348000, "num_env_steps_sampled_lifetime": 348000, "num_agent_steps_sampled_lifetime": 1392000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1392000, "timers": {"training_iteration_time_ms": 16382.19, "restore_workers_time_ms": 0.014, "training_step_time_ms": 16382.131, "sample_time_ms": 1262.351, "learn_time_ms": 15094.935, "learn_throughput": 264.99, "synch_weights_time_ms": 23.93}, "counters": {"num_env_steps_sampled": 348000, "num_env_steps_trained": 348000, "num_agent_steps_sampled": 1392000, "num_agent_steps_trained": 1392000}, "done": false, "training_iteration": 87, "trial_id": "86f16_00000", "date": "2024-08-08_16-33-35", "timestamp": 1723149215, "time_this_iter_s": 16.36250114440918, "time_total_s": 1245.130648136139, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad2ae5e0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1245.130648136139, "iterations_since_restore": 87, "perf": {"cpu_util_percent": 55.01304347826087, "ram_util_percent": 79.08260869565218}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6353654318297586, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.6374926221920243, "policy_loss": -0.01819358331081953, "vf_loss": 1.6549848551445818, "vf_explained_var": -2.587940675992492e-07, "kl": 0.0070134787236251165, "entropy": 0.47801163068688507, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 246750.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.646152897179127, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.235498214761416, "policy_loss": -0.0247484865009028, "vf_loss": 3.258454635118445, "vf_explained_var": 0.13670911621302367, "kl": 0.008960353736315103, "entropy": 0.9707461001351476, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 84000.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 352000, "num_env_steps_trained": 352000, "num_agent_steps_sampled": 1408000, "num_agent_steps_trained": 1408000}, "env_runners": {"episode_reward_max": 137.79643917880014, "episode_reward_min": -30.549287476252683, "episode_reward_mean": 12.143714340013178, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 157, "episodes_timesteps_total": 3925, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -72.20356082119987}, "policy_reward_max": {"adversary_policy": 70.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 7.643312101910828, "agent_policy": -10.786221965719305}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 4.389877173509737, -5.163773232851728, 40.0, 0.0, -7.295110954611857, 37.887189688405535, 0.0, 0.0, 79.87255948629411, 0.0, 0.0, 38.60848176984206, 40.0, 39.206456285983215, 0.0, 16.321146233350586, 0.0, 40.0, 0.0, 0.0, 0.0, 0.0, -4.1901003516941735, 0.0, -0.5646459363870138, -3.0512387769140057, 53.979954190219345, 80.0, 11.317172384859957, 60.0, -11.507573272793488, -5.979026693228706, -0.04918808208127401, 43.48451436926823, 0.0, 0.0, 80.0, 0.0, 0.0, 0.0, -0.8601865611650239, 0.0, -3.8262196470385814, 60.0, 0.0, 20.0, 20.0, 0.0, -1.247912651891101, 20.0, 0.0, 60.0, 0.0, 40.0, 40.0, 0.0, 137.79643917880014, -5.105168603147961, 0.0, 0.0, -7.9729989064412425, 80.0, 40.0, -0.6676787159929032, 56.03511256093509, -30.549287476252683, 19.10415984483453, -20.41795489466521, -0.8200991584344608, 0.0, 0.0, 16.93980862542256, 59.56944441852414, 20.0, 0.0, 0.0, -4.257397055552268, -0.019526167103190994, 20.0, 0.0, -14.245658789790605, 0.0, 40.0, -1.6523475484625427, 60.0, 36.91775990749584, -13.048556376161523, -25.30454934442935, -0.39932959985686467, -2.9970555003045405, -2.6069386472325085, 0.0, 0.0, 0.0, 40.0, 7.7755156707530295, -22.3626619385709, -0.24971636571409772, -8.220280156294388, -0.17838065476850629, 39.322490768267954, 0.0, -25.82782331077068, -2.142060673868956, -11.61577102432952, -6.513913766089766, 40.0, 80.0, 0.0, -9.779521565583108, 0.0, 12.227350672744901, 0.0, -2.5434005794662595, 0.0, 20.0, 0.0, 39.69274490465255, -28.474773566913193, 0.0, 34.56916812948391, 0.0, -0.43613226683656303, 60.0, 56.38083475538886, 0.0, 19.8199566049572, 59.37645091714198, 0.0, 0.0, 38.72538067657807, 40.0, 0.0, 0.0, -6.5276436101169, -3.9380554865213044, -3.6909135842838454, -5.215303172367337, -0.03747302049429302, 59.56975607246355, -18.535923169842782, 56.35662229710492, -6.673650711558118, 0.0, -25.13301056821737, 0.0, 40.0, -0.45680074568330453, 0.0, -0.0645225904923008, 0.0, -14.251720441458835, -0.3518211485698497, 30.494784457107063, -2.157183599023252, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [0.0, -25.61012282649026, -5.163773232851728, -20.0, 0.0, -7.295110954611857, -22.112810311594465, 0.0, 0.0, -40.12744051370589, 0.0, 0.0, -21.391518230157946, -20.0, -20.79354371401679, 0.0, -13.678853766649414, 0.0, -20.0, 0.0, 0.0, 0.0, 0.0, -4.1901003516941735, 0.0, -0.5646459363870138, -3.0512387769140057, -36.020045809780655, -40.0, -18.68282761514004, -30.0, -11.507573272793488, -5.979026693228706, -0.04918808208127401, -46.51548563073176, 0.0, 0.0, -40.0, 0.0, 0.0, 0.0, -0.8601865611650239, 0.0, -3.8262196470385814, -30.0, 0.0, -10.0, -10.0, 0.0, -1.247912651891101, -10.0, 0.0, -30.0, 0.0, -20.0, -20.0, 0.0, -72.20356082119987, -5.105168603147961, 0.0, 0.0, -7.9729989064412425, -40.0, -20.0, -0.6676787159929032, -33.96488743906492, -30.549287476252683, -10.895840155165466, -20.41795489466521, -0.8200991584344608, 0.0, 0.0, -13.060191374577435, -30.430555581475858, -10.0, 0.0, 0.0, -4.257397055552268, -0.019526167103190994, -10.0, 0.0, -14.245658789790605, 0.0, -20.0, -1.6523475484625427, -30.0, -23.082240092504158, -13.048556376161523, -25.30454934442935, -0.39932959985686467, -2.9970555003045405, -2.6069386472325085, 0.0, 0.0, 0.0, -20.0, -22.224484329246966, -22.3626619385709, -0.24971636571409772, -8.220280156294388, -0.17838065476850629, -20.677509231732042, 0.0, -25.82782331077068, -2.142060673868956, -11.61577102432952, -6.513913766089766, -20.0, -40.0, 0.0, -9.779521565583108, 0.0, -17.772649327255102, 0.0, -2.5434005794662595, 0.0, -10.0, 0.0, -20.30725509534745, -28.474773566913193, 0.0, -25.43083187051609, 0.0, -0.43613226683656303, -30.0, -33.61916524461114, 0.0, -10.180043395042803, -30.623549082858023, 0.0, 0.0, -21.27461932342193, -20.0, 0.0, 0.0, -6.5276436101169, -3.9380554865213044, -3.6909135842838454, -5.215303172367337, -0.03747302049429302, -30.430243927536445, -18.535923169842782, -33.64337770289508, -6.673650711558118, 0.0, -25.13301056821737, 0.0, -20.0, -0.45680074568330453, 0.0, -0.0645225904923008, 0.0, -14.251720441458835, -0.3518211485698497, -29.505215542892937, -2.157183599023252, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6815641835605102, "mean_inference_ms": 1.1926297153834666, "mean_action_processing_ms": 0.2498520528056067, "mean_env_wait_ms": 0.5110666795522308, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0060280417181124354, "StateBufferConnector_ms": 0.003971112002233031, "ViewRequirementAgentConnector_ms": 0.10254375494209825}, "num_episodes": 157, "episode_return_max": 137.79643917880014, "episode_return_min": -30.549287476252683, "episode_return_mean": 12.143714340013178}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1408000, "num_agent_steps_trained": 1408000, "num_env_steps_sampled": 352000, "num_env_steps_trained": 352000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 222.0731840651537, "num_env_steps_trained_throughput_per_sec": 222.0731840651537, "timesteps_total": 352000, "num_env_steps_sampled_lifetime": 352000, "num_agent_steps_sampled_lifetime": 1408000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1408000, "timers": {"training_iteration_time_ms": 16410.667, "restore_workers_time_ms": 0.014, "training_step_time_ms": 16410.607, "sample_time_ms": 1285.028, "learn_time_ms": 15100.115, "learn_throughput": 264.899, "synch_weights_time_ms": 24.554}, "counters": {"num_env_steps_sampled": 352000, "num_env_steps_trained": 352000, "num_agent_steps_sampled": 1408000, "num_agent_steps_trained": 1408000}, "done": false, "training_iteration": 88, "trial_id": "86f16_00000", "date": "2024-08-08_16-33-54", "timestamp": 1723149234, "time_this_iter_s": 18.052915811538696, "time_total_s": 1263.1835639476776, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad2aea60>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1263.1835639476776, "iterations_since_restore": 88, "perf": {"cpu_util_percent": 63.016000000000005, "ram_util_percent": 80.38000000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5542102449699073, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.7312004867174946, "policy_loss": -0.016925693023289348, "vf_loss": 1.7474512411770247, "vf_explained_var": -8.830787442254682e-08, "kl": 0.006749346554553371, "entropy": 0.44731618976550747, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 249570.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.780703767389059, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.3999469105154274, "policy_loss": -0.025585274706342413, "vf_loss": 3.4236837030698855, "vf_explained_var": 0.19692605802168447, "kl": 0.009242409111838564, "entropy": 0.9650247829034925, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 84960.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 356000, "num_env_steps_trained": 356000, "num_agent_steps_sampled": 1424000, "num_agent_steps_trained": 1424000}, "env_runners": {"episode_reward_max": 120.0, "episode_reward_min": -36.29192483232691, "episode_reward_mean": 10.635489623606283, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -71.06279598390415}, "policy_reward_max": {"adversary_policy": 60.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 7.345679012345679, "agent_policy": -11.401547413430752}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 40.0, -4.718820516054409, 0.0, -33.292218229392496, -3.3758918445680113, 20.0, 0.0, 36.32844627257391, -7.870532463447181, -36.29192483232691, -2.044569299076543, -4.530789105073527, -1.9041850435304764, -10.285225880212883, 0.0, 0.0, 108.93720401609585, -11.598603991987664, 20.0, 40.0, 19.71090878406433, -0.43188853375024316, -6.560685704765533, 0.0, 0.0, 0.0, 38.52496668118371, -30.36582715909721, 0.0, 0.0, 19.998480770943253, 0.0, -2.572268103720056, 0.0, 20.0, -24.472168438404374, 0.0, 0.0, 26.212994123542742, 36.65010135285558, -31.955997166541547, 20.0, 20.0, 0.0, 36.37947753455817, -27.595165901434793, 0.0, -7.180422432758453, 20.0, 60.0, 20.212606426538922, -0.20877078607384858, -5.907471955247333, 60.0, 80.0, 0.0, 29.444817245995637, 40.0, 0.0, 40.0, 0.0, -3.3492419396017707, 19.23384350235298, 0.0, 19.844994875795216, 40.0, 20.0, -15.951893941250452, 40.0, 0.0, 0.0, 40.0, 0.0, 51.91322506690582, -7.3861275726571325, -10.060038919849113, 0.0, -0.09549371310221821, 0.0, 0.0, 40.0, 13.934721633861301, 20.0, 0.0, 0.0, -5.982028412904164, -0.9746625009489451, 0.0, 0.0, 0.0, 0.0, -6.049751911597769, 0.0, -5.851223419951047, -0.14121755964428329, 0.0, -0.3135626868337027, 0.0, 36.97589846095243, -5.935506556124299, 0.0, -0.4799562778880446, 12.975555887872956, 46.195581398313436, -11.667607162042774, 0.0, -12.992366573139348, -1.665351502336636, -7.690085305575764, 0.0, 0.0, 0.0, -3.8283338632079653, 54.07101594363636, 0.0, 19.699148732874654, 60.0, 60.0, 0.0, 60.0, 39.764583858356616, -6.009021453709439, -7.629556962846791, -3.2361260104758576, 0.0, -1.3375861315905568, 120.0, 36.575059385398134, 0.0, 20.0, 0.0, -0.34221342347439787, 0.0, -0.9250567386892472, 40.0, -20.408105245806, 58.23254851961792, 0.0, 9.770399426741896, 100.0, -8.949001219799996, 0.0, 0.0, 0.0, 27.743734005349697, 0.0, 0.0, -11.558259703506156, 20.0, -14.203563685409092, 77.2018815165819, -5.4793577556118365, 0.0, 36.2606431491957, -1.7865762287382692, -2.529157050145225, -7.241504740598105, 0.0, 80.0, -4.63055599142119, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [0.0, -20.0, -4.718820516054409, 0.0, -33.292218229392496, -3.3758918445680113, -10.0, 0.0, -23.671553727426083, -7.870532463447181, -36.29192483232691, -2.044569299076543, -4.530789105073527, -31.90418504353048, -10.285225880212883, 0.0, 0.0, -71.06279598390415, -11.598603991987664, -10.0, -20.0, -10.28909121593567, -0.43188853375024316, -6.560685704765533, 0.0, 0.0, 0.0, -21.47503331881628, -30.36582715909721, 0.0, 0.0, -10.001519229056745, 0.0, -2.572268103720056, 0.0, -10.0, -24.472168438404374, 0.0, 0.0, -33.78700587645725, -23.34989864714442, -31.955997166541547, -10.0, -10.0, 0.0, -23.620522465441834, -27.595165901434793, 0.0, -7.180422432758453, -10.0, -30.0, -39.78739357346109, -0.20877078607384858, -5.907471955247333, -30.0, -40.0, 0.0, -30.555182754004363, -20.0, 0.0, -20.0, 0.0, -3.3492419396017707, -10.766156497647021, 0.0, -10.155005124204786, -20.0, -10.0, -15.951893941250452, -20.0, 0.0, 0.0, -20.0, 0.0, -38.08677493309418, -7.3861275726571325, -10.060038919849113, 0.0, -0.09549371310221821, 0.0, 0.0, -20.0, -16.065278366138696, -10.0, 0.0, 0.0, -5.982028412904164, -0.9746625009489451, 0.0, 0.0, 0.0, 0.0, -6.049751911597769, 0.0, -5.851223419951047, -0.14121755964428329, 0.0, -0.3135626868337027, 0.0, -23.024101539047567, -5.935506556124299, 0.0, -30.479956277888043, -17.024444112127046, -43.804418601686564, -11.667607162042774, 0.0, -12.992366573139348, -1.665351502336636, -7.690085305575764, 0.0, 0.0, 0.0, -3.8283338632079653, -35.92898405636364, 0.0, -10.300851267125347, -30.0, -30.0, 0.0, -30.0, -20.235416141643388, -6.009021453709439, -7.629556962846791, -33.236126010475864, 0.0, -1.3375861315905568, -60.0, -23.424940614601866, 0.0, -10.0, 0.0, -0.34221342347439787, 0.0, -0.9250567386892472, -20.0, -20.408105245806, -31.76745148038208, 0.0, -20.229600573258104, -50.0, -8.949001219799996, 0.0, 0.0, 0.0, -32.256265994650306, 0.0, 0.0, -11.558259703506156, -10.0, -14.203563685409092, -42.7981184834181, -5.4793577556118365, 0.0, -23.73935685080429, -1.7865762287382692, -2.529157050145225, -7.241504740598105, 0.0, -40.0, -4.63055599142119, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6813526599669542, "mean_inference_ms": 1.1923318969949648, "mean_action_processing_ms": 0.24962978129039365, "mean_env_wait_ms": 0.5108805524453837, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00632905665739083, "StateBufferConnector_ms": 0.0033582434242154344, "ViewRequirementAgentConnector_ms": 0.09436305658316907}, "num_episodes": 162, "episode_return_max": 120.0, "episode_return_min": -36.29192483232691, "episode_return_mean": 10.635489623606283}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1424000, "num_agent_steps_trained": 1424000, "num_env_steps_sampled": 356000, "num_env_steps_trained": 356000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 312.172658563555, "num_env_steps_trained_throughput_per_sec": 312.172658563555, "timesteps_total": 356000, "num_env_steps_sampled_lifetime": 356000, "num_agent_steps_sampled_lifetime": 1424000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1424000, "timers": {"training_iteration_time_ms": 16074.525, "restore_workers_time_ms": 0.014, "training_step_time_ms": 16074.466, "sample_time_ms": 1303.466, "learn_time_ms": 14747.784, "learn_throughput": 271.227, "synch_weights_time_ms": 22.481}, "counters": {"num_env_steps_sampled": 356000, "num_env_steps_trained": 356000, "num_agent_steps_sampled": 1424000, "num_agent_steps_trained": 1424000}, "done": false, "training_iteration": 89, "trial_id": "86f16_00000", "date": "2024-08-08_16-34-07", "timestamp": 1723149247, "time_this_iter_s": 12.827091932296753, "time_total_s": 1276.0106558799744, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad2aeca0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1276.0106558799744, "iterations_since_restore": 89, "perf": {"cpu_util_percent": 39.73157894736842, "ram_util_percent": 79.85789473684208}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5327036645659741, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.5356234860758409, "policy_loss": -0.015091685768041813, "vf_loss": 1.5501902333388091, "vf_explained_var": -4.2655366532346036e-07, "kl": 0.005249386850869609, "entropy": 0.4353490801884773, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 252390.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.731870193655292, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.9044733536740144, "policy_loss": -0.02487692112190416, "vf_loss": 2.927536222587029, "vf_explained_var": 0.12264017990479867, "kl": 0.009070216850979328, "entropy": 0.9708280234908064, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 85920.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 360000, "num_env_steps_trained": 360000, "num_agent_steps_sampled": 1440000, "num_agent_steps_trained": 1440000}, "env_runners": {"episode_reward_max": 140.0, "episode_reward_min": -28.05263878597219, "episode_reward_mean": 12.704662417075399, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -70.0}, "policy_reward_max": {"adversary_policy": 70.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 7.654320987654321, "agent_policy": -10.258300545887566}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-6.021909393139661, 40.0, -4.50679338033633, 40.0, 0.0, 0.0, -9.805512472018055, 0.0, -4.405114090031795, 20.0, 20.0, 0.0, -8.029027918968819, -3.30747219638661, -9.273000235142304, -0.2613151873321373, -3.896478011148383, 0.0, -1.336497833445941, 0.0, 0.0, -10.877834129139444, -9.909976775574215, 40.0, 0.0, 40.0, 58.472521098263925, 0.0, 40.0, 40.0, 60.0, 20.0, 40.0, 20.0, 60.0, -8.630606646850948, 20.0, 0.0, 0.0, 0.0, 91.41964814091295, 0.0, 0.0, 38.791613705531645, 98.91208134828436, 0.0, -5.310615327490609, -0.43264494937663156, -7.535719620008434, 140.0, 40.0, 28.656814579882333, -15.427762375015785, 20.0, 80.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -7.917320869289409, -18.69800502009084, -3.353481628242929, 60.0, 80.0, 120.0, -1.8895998515451318, 0.0, 60.0, 0.0, 0.0, 0.0, -4.658335531522384, 18.59232287182381, -16.73194511521069, 40.0, -15.99940658725237, 0.0, 0.0, 0.0, 46.02244211769486, 26.65992150625089, 0.0, -1.4680009335671529, -0.6302838204666583, 0.0, -4.9508012311498515, -8.278495317083973, -13.261161191645739, 120.0, 0.0, 0.0, 0.0, 60.0, -1.2688369690481316, 0.0, -0.11808889621363616, -2.5945920499233273, 20.0, 40.0, 0.0, 0.0, -2.5955079222467408, 0.0, -0.22452285991093612, 0.0, 9.527810941679714, -28.05263878597219, 0.0, 20.0, 0.0, -6.213572678983111, 0.0, 0.0, 18.050423703781934, 0.0, 0.0, 0.0, -0.07540443088469906, 0.0, 0.0, 79.90382384113732, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 80.0, -3.3119028071138557, 40.0, 40.0, -1.8117689289150751, -24.463746719672486, 20.0, 0.0, 0.0, 17.4383357728143, 0.0, -9.59810645451379, 0.0, 20.0, 40.0, 0.0, -19.41630313638441, 0.0, 0.0, 12.766994922181983, 0.0, -1.2265953004781183, 56.22967586409477, -0.7007664845454031, 55.38055257734506, -0.9191905628825559, 59.081876592740485, -8.35488539204451], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-6.021909393139661, -20.0, -4.50679338033633, -20.0, 0.0, 0.0, -9.805512472018055, 0.0, -4.405114090031795, -10.0, -10.0, 0.0, -8.029027918968819, -3.30747219638661, -9.273000235142304, -0.2613151873321373, -3.896478011148383, 0.0, -1.336497833445941, 0.0, 0.0, -10.877834129139444, -9.909976775574215, -20.0, 0.0, -20.0, -31.527478901736078, 0.0, -20.0, -20.0, -30.0, -10.0, -20.0, -10.0, -30.0, -8.630606646850948, -10.0, 0.0, 0.0, 0.0, -58.580351859087045, 0.0, 0.0, -21.20838629446835, -51.08791865171563, 0.0, -5.310615327490609, -0.43264494937663156, -7.535719620008434, -70.0, -20.0, -31.343185420117656, -15.427762375015785, -10.0, -40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -7.917320869289409, -18.69800502009084, -3.353481628242929, -30.0, -40.0, -60.0, -1.8895998515451318, 0.0, -30.0, 0.0, 0.0, 0.0, -4.658335531522384, -11.407677128176191, -16.73194511521069, -20.0, -15.99940658725237, 0.0, 0.0, 0.0, -43.97755788230515, -33.340078493749125, 0.0, -1.4680009335671529, -0.6302838204666583, 0.0, -4.9508012311498515, -8.278495317083973, -13.261161191645739, -60.0, 0.0, 0.0, 0.0, -30.0, -1.2688369690481316, 0.0, -0.11808889621363616, -2.5945920499233273, -10.0, -20.0, 0.0, 0.0, -2.5955079222467408, 0.0, -0.22452285991093612, 0.0, -20.472189058320286, -28.05263878597219, 0.0, -10.0, 0.0, -6.213572678983111, 0.0, 0.0, -11.949576296218066, 0.0, 0.0, 0.0, -0.07540443088469906, 0.0, 0.0, -40.09617615886267, -10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -40.0, -3.3119028071138557, -20.0, -20.0, -1.8117689289150751, -24.463746719672486, -10.0, 0.0, 0.0, -12.561664227185702, 0.0, -9.59810645451379, 0.0, -10.0, -20.0, 0.0, -19.41630313638441, 0.0, 0.0, -47.233005077818014, 0.0, -1.2265953004781183, -33.77032413590523, -0.7007664845454031, -34.61944742265494, -0.9191905628825559, -30.91812340725952, -8.35488539204451]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6806770182536553, "mean_inference_ms": 1.1908304371513139, "mean_action_processing_ms": 0.24931001026884225, "mean_env_wait_ms": 0.5103501063497139, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004806709878238631, "StateBufferConnector_ms": 0.00321085070386345, "ViewRequirementAgentConnector_ms": 0.09215069405826522}, "num_episodes": 162, "episode_return_max": 140.0, "episode_return_min": -28.05263878597219, "episode_return_mean": 12.704662417075399}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1440000, "num_agent_steps_trained": 1440000, "num_env_steps_sampled": 360000, "num_env_steps_trained": 360000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 329.7834580883684, "num_env_steps_trained_throughput_per_sec": 329.7834580883684, "timesteps_total": 360000, "num_env_steps_sampled_lifetime": 360000, "num_agent_steps_sampled_lifetime": 1440000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1440000, "timers": {"training_iteration_time_ms": 15355.567, "restore_workers_time_ms": 0.014, "training_step_time_ms": 15355.51, "sample_time_ms": 1276.761, "learn_time_ms": 14057.736, "learn_throughput": 284.541, "synch_weights_time_ms": 20.27}, "counters": {"num_env_steps_sampled": 360000, "num_env_steps_trained": 360000, "num_agent_steps_sampled": 1440000, "num_agent_steps_trained": 1440000}, "done": false, "training_iteration": 90, "trial_id": "86f16_00000", "date": "2024-08-08_16-34-19", "timestamp": 1723149259, "time_this_iter_s": 12.134950876235962, "time_total_s": 1288.1456067562103, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad2aee50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1288.1456067562103, "iterations_since_restore": 90, "perf": {"cpu_util_percent": 32.10588235294118, "ram_util_percent": 79.1470588235294}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5342501426947878, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.7338845864044015, "policy_loss": -0.016555519668296218, "vf_loss": 1.749815307356787, "vf_explained_var": -1.7858143393875014e-07, "kl": 0.006247988666171337, "entropy": 0.4512988488619209, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 255210.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.3778998095542194, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.8278644027809303, "policy_loss": -0.02482165773350668, "vf_loss": 2.8508658438920973, "vf_explained_var": 0.13187357901285093, "kl": 0.009101134268781475, "entropy": 0.9624631327887376, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 86880.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 364000, "num_env_steps_trained": 364000, "num_agent_steps_sampled": 1456000, "num_agent_steps_trained": 1456000}, "env_runners": {"episode_reward_max": 158.13690083030863, "episode_reward_min": -32.08236369626985, "episode_reward_mean": 13.78038569412497, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 158, "episodes_timesteps_total": 3950, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -81.86309916969137}, "policy_reward_max": {"adversary_policy": 80.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 8.037974683544304, "agent_policy": -10.333538356507944}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 76.46917690601853, 0.0, 0.0, 40.0, -0.3961962681938036, -4.905606222161489, 0.0, -1.0145507670703924, -0.7013128992840856, 60.0, -1.2885920078770718, -0.46292158780586457, 57.2065700694978, -11.679189569122945, 0.0, 0.0, 40.0, 0.0, 40.0, 39.86873382012296, 55.931681562099655, 80.0, 40.0, 20.0, -6.209068786992855, 16.379358179925585, -17.536234533893357, 0.0, 40.0, -15.731834568526171, -0.12889027042262247, 0.0, 0.0, 80.0, 0.0, -0.34441298095184036, 0.0, 29.0560957413916, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 40.0, 0.0, 0.0, 47.60914929052891, 38.93839093188192, 40.0, -0.8668742091845805, 0.0, 158.13690083030863, 40.0, 68.87733102833184, 20.0, -30.934546422519606, -10.230480756131492, 0.0, 15.12049062116592, 0.0, -11.296523681969427, 0.0, 33.885214949927025, -32.08236369626985, 0.0, 0.0, 0.0, -3.9759854104626386, 53.99017684702316, 0.0, 60.0, 0.0, -0.39909551713671276, -0.96324218403252, 20.0, 0.0, 20.0, 58.820814882149065, -2.5968418594205254, -4.415156858461587, -0.26064690649224675, 0.0, 49.824973259368, 118.9677674905664, 0.0, 120.0, 60.0, 40.0, 0.0, -0.37717611191361744, 0.0, 20.0, -7.458336193873815, -11.18821013625903, 0.0, 29.946707120409005, 0.0, 31.28245353254215, 0.0, 40.0, 59.994258481448185, 0.0, -1.6604787290845602, 0.0, 37.65107362345142, -0.06840568868405783, 0.0, -0.3395125748442418, 0.0, 20.0, 0.0, 54.76653646676772, 33.86333390626428, -0.9553090781332396, -0.4214987677290316, 58.96182129433356, 0.0, 0.0, 0.0, 0.0, -2.088016319713236, -3.5162818572905157, -13.759782900295834, 0.0, -1.0611296753956279, -0.30299561045327716, 0.0, 0.0, -0.05670639066993055, 0.0, 0.0, 0.0, -10.092611816148349, 39.87115680714933, 71.69951013911069, 0.0, 0.0, 32.66488422427927, -1.1755421028797042, 0.0, -2.393738686607123, -8.6649528113246, 0.0, 0.0, 0.0, -2.015642053695924, -1.50895453439303, -4.891427697796613, -0.06634463274878821, 0.0, 20.0, 0.0, 0.0, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 80.0, 80.0, 80.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [0.0, 0.0, -43.53082309398147, 0.0, 0.0, -20.0, -0.3961962681938036, -4.905606222161489, 0.0, -1.0145507670703924, -0.7013128992840856, -30.0, -1.2885920078770718, -0.46292158780586457, -32.7934299305022, -11.679189569122945, 0.0, 0.0, -20.0, 0.0, -20.0, -20.131266179877038, -34.068318437900345, -40.0, -20.0, -10.0, -6.209068786992855, -13.620641820074415, -17.536234533893357, 0.0, -20.0, -15.731834568526171, -0.12889027042262247, 0.0, 0.0, -40.0, 0.0, -0.34441298095184036, 0.0, -30.9439042586084, -10.0, 0.0, 0.0, 0.0, 0.0, 0.0, -10.0, -20.0, 0.0, 0.0, -42.390850709471096, -21.06160906811808, -20.0, -0.8668742091845805, 0.0, -81.86309916969137, -20.0, -51.122668971668155, -10.0, -30.934546422519606, -10.230480756131492, 0.0, -14.87950937883408, 0.0, -11.296523681969427, 0.0, -26.114785050072975, -32.08236369626985, 0.0, 0.0, 0.0, -3.9759854104626386, -36.00982315297684, 0.0, -30.0, 0.0, -0.39909551713671276, -0.96324218403252, -10.0, 0.0, -10.0, -31.179185117850935, -2.5968418594205254, -4.415156858461587, -0.26064690649224675, 0.0, -40.175026740632, -61.03223250943361, 0.0, -60.0, -30.0, -20.0, 0.0, -0.37717611191361744, 0.0, -10.0, -7.458336193873815, -11.18821013625903, 0.0, -30.053292879591, 0.0, -28.717546467457865, 0.0, -20.0, -30.00574151855181, 0.0, -1.6604787290845602, 0.0, -22.348926376548583, -0.06840568868405783, 0.0, -0.3395125748442418, 0.0, -10.0, 0.0, -35.23346353323227, -26.136666093735723, -0.9553090781332396, -0.4214987677290316, -31.03817870566644, 0.0, 0.0, 0.0, 0.0, -2.088016319713236, -3.5162818572905157, -13.759782900295834, 0.0, -1.0611296753956279, -0.30299561045327716, 0.0, 0.0, -0.05670639066993055, 0.0, 0.0, 0.0, -10.092611816148349, -20.128843192850667, -48.300489860889314, 0.0, 0.0, -27.335115775720737, -1.1755421028797042, 0.0, -2.393738686607123, -8.6649528113246, 0.0, 0.0, 0.0, -2.015642053695924, -1.50895453439303, -4.891427697796613, -0.06634463274878821, 0.0, -10.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6912514678153469, "mean_inference_ms": 1.1893325496850353, "mean_action_processing_ms": 0.2489749856509806, "mean_env_wait_ms": 0.5097937763012553, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004404783248901367, "StateBufferConnector_ms": 0.003368567816818817, "ViewRequirementAgentConnector_ms": 0.08536184890360772}, "num_episodes": 158, "episode_return_max": 158.13690083030863, "episode_return_min": -32.08236369626985, "episode_return_mean": 13.78038569412497}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1456000, "num_agent_steps_trained": 1456000, "num_env_steps_sampled": 364000, "num_env_steps_trained": 364000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 326.92829479343237, "num_env_steps_trained_throughput_per_sec": 326.92829479343237, "timesteps_total": 364000, "num_env_steps_sampled_lifetime": 364000, "num_agent_steps_sampled_lifetime": 1456000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1456000, "timers": {"training_iteration_time_ms": 15232.831, "restore_workers_time_ms": 0.014, "training_step_time_ms": 15232.78, "sample_time_ms": 1303.155, "learn_time_ms": 13909.347, "learn_throughput": 287.576, "synch_weights_time_ms": 19.686}, "counters": {"num_env_steps_sampled": 364000, "num_env_steps_trained": 364000, "num_agent_steps_sampled": 1456000, "num_agent_steps_trained": 1456000}, "done": false, "training_iteration": 91, "trial_id": "86f16_00000", "date": "2024-08-08_16-34-31", "timestamp": 1723149271, "time_this_iter_s": 12.240395784378052, "time_total_s": 1300.3860025405884, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad1c54c0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1300.3860025405884, "iterations_since_restore": 91, "perf": {"cpu_util_percent": 31.7111111111111, "ram_util_percent": 78.78333333333335}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.472270994517186, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.6250635775902593, "policy_loss": -0.012681333583297458, "vf_loss": 1.6372266547899719, "vf_explained_var": 6.06530101586741e-07, "kl": 0.005182575127228575, "entropy": 0.456703394123003, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 258030.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.525984851519267, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.8286800670127072, "policy_loss": -0.023087611763185124, "vf_loss": 2.8501059162120024, "vf_explained_var": 0.11006347456326088, "kl": 0.008308796151192802, "entropy": 0.9532576431209843, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 87840.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 368000, "num_env_steps_trained": 368000, "num_agent_steps_sampled": 1472000, "num_agent_steps_trained": 1472000}, "env_runners": {"episode_reward_max": 180.0, "episode_reward_min": -28.19121417092386, "episode_reward_mean": 11.296607924767967, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 157, "episodes_timesteps_total": 3925, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -90.0}, "policy_reward_max": {"adversary_policy": 90.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 7.13375796178344, "agent_policy": -10.104665960582352}, "custom_metrics": {}, "hist_stats": {"episode_reward": [120.0, 0.0, 15.713125864823173, 29.288709907376482, 34.84463682818442, -10.784384915406749, -4.604788323686953, 0.0, 58.883421488848086, 0.0, -28.19121417092386, 19.11120941339779, 18.744171411757996, 20.0, 0.0, -1.6565257395670852, -8.146327660152918, 0.0, 0.0, 0.0, 0.0, -2.7012489065770797, 20.0, -22.63823295951011, 20.0, -0.9786052940198953, 0.0, -3.0321542160767825, -0.2805299480089807, 40.0, -14.00167424439272, 20.0, -0.582650998810722, 18.26926096245279, 0.0, -2.420369598351643, -19.416569203626324, -1.7062278824926558, 0.0, -13.139668081703341, 40.0, 19.913126078011466, 27.82079641214522, 0.0, -2.7916487512143027, 20.0, -0.12966385078553633, 20.0, -3.3812716831070047, -11.341346271566522, -8.189854741386032, 0.0, 0.0, -1.2687667565498861, -3.693576760259174, 55.09417209442975, 0.0, 37.24133325669258, -0.7610075069669464, 40.0, 88.17743418709718, -0.8604339297116959, -1.705858251082084, 20.0, 0.0, -1.5420195328421171, -11.16029171666444, 0.0, -1.934601655307231, 0.0, 12.677311739468223, -0.07539517691665831, -1.2083540911871893, 0.0, -1.0127530566149556, 0.0, 120.0, 57.68908744952189, -4.266579309144134, 60.0, -6.57698245693055, 80.0, 0.0, 0.0, 0.0, -17.73981411832182, -4.665601270842074, 180.0, 0.0, -24.647908960803186, -3.0984441207121014, 16.198180779719063, -3.6777805649682187, 40.0, 0.0, 0.0, -1.0809408952196908, -8.843210928018683, 0.0, 36.91776613468263, 80.0, 0.0, 39.976755556513794, -0.14818679048393402, 16.360137285061725, 0.0, 0.0, 40.0, 0.0, 0.0, -1.5784029165634073, 0.0, -2.9659812244324675, -1.4491001846664642, -0.10244998429599583, 0.0, 60.0, -0.21553852910303872, -11.187817570040933, -1.94396412013573, 0.0, 0.0, 0.0, 0.0, 33.29505968271886, 0.0, -21.988515019547243, 19.09764290033344, 0.0, 160.0, -10.051034143012705, 20.0, 0.0, 0.0, 18.031499274284077, 40.0, 0.0, -17.979341017517704, -5.639452718109202, -1.0455460377952952, -2.357404668932721, 0.0, -7.435210846202606, 0.0, -0.3361735581607428, -4.210350444374814, 0.0, 0.0, 19.19664105849063, 4.4688943051932535, 40.0, 39.560314456028244, 19.944789846924284, -0.5436748619930332, 0.0, 20.0, 48.165388950211835], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 90.0, 90.0, 90.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 80.0, 80.0, 80.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0], "policy_agent_policy_reward": [-60.0, 0.0, -14.286874135176827, -30.711290092623525, -25.155363171815576, -10.784384915406749, -4.604788323686953, 0.0, -31.116578511151904, 0.0, -28.19121417092386, -10.888790586602209, -11.255828588242002, -10.0, 0.0, -1.6565257395670852, -8.146327660152918, 0.0, 0.0, 0.0, 0.0, -2.7012489065770797, -10.0, -22.63823295951011, -10.0, -0.9786052940198953, 0.0, -3.0321542160767825, -0.2805299480089807, -20.0, -14.00167424439272, -10.0, -0.582650998810722, -11.730739037547213, 0.0, -2.420369598351643, -19.416569203626324, -1.7062278824926558, 0.0, -13.139668081703341, -20.0, -10.086873921988532, -32.17920358785477, 0.0, -2.7916487512143027, -10.0, -0.12966385078553633, -10.0, -3.3812716831070047, -11.341346271566522, -8.189854741386032, 0.0, 0.0, -1.2687667565498861, -3.693576760259174, -34.90582790557024, 0.0, -22.75866674330742, -0.7610075069669464, -20.0, -61.82256581290282, -0.8604339297116959, -1.705858251082084, -10.0, 0.0, -1.5420195328421171, -11.16029171666444, 0.0, -1.934601655307231, 0.0, -17.322688260531784, -0.07539517691665831, -1.2083540911871893, 0.0, -1.0127530566149556, 0.0, -60.0, -32.31091255047811, -4.266579309144134, -30.0, -6.57698245693055, -40.0, 0.0, 0.0, 0.0, -17.73981411832182, -4.665601270842074, -90.0, 0.0, -24.647908960803186, -3.0984441207121014, -13.801819220280937, -3.6777805649682187, -20.0, 0.0, 0.0, -1.0809408952196908, -8.843210928018683, 0.0, -23.08223386531737, -40.0, 0.0, -20.023244443486202, -0.14818679048393402, -13.639862714938277, 0.0, 0.0, -20.0, 0.0, 0.0, -1.5784029165634073, 0.0, -2.9659812244324675, -1.4491001846664642, -0.10244998429599583, 0.0, -30.0, -0.21553852910303872, -11.187817570040933, -1.94396412013573, 0.0, 0.0, 0.0, 0.0, -26.704940317281142, 0.0, -21.988515019547243, -10.902357099666558, 0.0, -80.0, -10.051034143012705, -10.0, 0.0, 0.0, -11.968500725715923, -20.0, 0.0, -17.979341017517704, -5.639452718109202, -1.0455460377952952, -2.357404668932721, 0.0, -7.435210846202606, 0.0, -0.3361735581607428, -4.210350444374814, 0.0, 0.0, -10.80335894150937, -25.531105694806747, -20.0, -20.439685543971756, -10.055210153075716, -0.5436748619930332, 0.0, -10.0, -41.834611049788165]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6902150041047942, "mean_inference_ms": 1.187466849574147, "mean_action_processing_ms": 0.24855622991098128, "mean_env_wait_ms": 0.5091155193674883, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00425053250258136, "StateBufferConnector_ms": 0.003072790279509915, "ViewRequirementAgentConnector_ms": 0.0876064513139664}, "num_episodes": 157, "episode_return_max": 180.0, "episode_return_min": -28.19121417092386, "episode_return_mean": 11.296607924767967}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1472000, "num_agent_steps_trained": 1472000, "num_env_steps_sampled": 368000, "num_env_steps_trained": 368000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 343.1491432723211, "num_env_steps_trained_throughput_per_sec": 343.1491432723211, "timesteps_total": 368000, "num_env_steps_sampled_lifetime": 368000, "num_agent_steps_sampled_lifetime": 1472000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1472000, "timers": {"training_iteration_time_ms": 14979.221, "restore_workers_time_ms": 0.014, "training_step_time_ms": 14979.171, "sample_time_ms": 1296.693, "learn_time_ms": 13664.296, "learn_throughput": 292.734, "synch_weights_time_ms": 17.588}, "counters": {"num_env_steps_sampled": 368000, "num_env_steps_trained": 368000, "num_agent_steps_sampled": 1472000, "num_agent_steps_trained": 1472000}, "done": false, "training_iteration": 92, "trial_id": "86f16_00000", "date": "2024-08-08_16-34-43", "timestamp": 1723149283, "time_this_iter_s": 11.669296264648438, "time_total_s": 1312.0552988052368, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad2b3670>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1312.0552988052368, "iterations_since_restore": 92, "perf": {"cpu_util_percent": 28.894117647058824, "ram_util_percent": 78.7}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5304553614387698, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.5653141927000478, "policy_loss": -0.017918470601306843, "vf_loss": 1.5825483895151327, "vf_explained_var": -6.296110491380624e-07, "kl": 0.0068427292542410575, "entropy": 0.4611766624957957, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 260850.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.7098950199782847, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.783541140984744, "policy_loss": -0.023971108626089213, "vf_loss": 2.805770546135803, "vf_explained_var": 0.1134071317811807, "kl": 0.008708550105009396, "entropy": 0.9502879378075401, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 88800.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 372000, "num_env_steps_trained": 372000, "num_agent_steps_sampled": 1488000, "num_agent_steps_trained": 1488000}, "env_runners": {"episode_reward_max": 160.0, "episode_reward_min": -23.39747428545409, "episode_reward_mean": 14.565895768712869, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -80.0}, "policy_reward_max": {"adversary_policy": 80.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 8.518518518518519, "agent_policy": -10.98965978684269}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.0, -17.394637377385234, 0.0, -2.7667050196497156, -20.789976819780602, 0.0, 0.0, 19.41888231801426, 20.0, 0.0, -10.048103762670252, 20.0, -3.7083179924808305, 0.0, -18.5016147745343, 0.0, 0.0, 21.73314098124145, 0.0, 0.0, -0.0867230484479975, -9.233432125309601, 15.2858741321025, 0.0, 0.0, 60.0, 43.18393669078089, 0.0, 0.0, 18.830060764942466, -0.1067717181950234, 0.0, -6.158233140548041, 50.00415672737873, 20.0, 100.0, 0.0, -0.9084982730008195, 0.0, 0.0, 40.0, 0.0, 40.0, 0.0, -13.516872632525896, -3.107167398348289, 0.0, 20.0, 0.0, 32.71407309732683, 59.52833630666029, 0.0, 100.0, 19.364875926148827, 4.213730212503082, 34.00470548667364, 0.0, 59.86273114425449, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 67.16637840024023, 0.0, 20.0, 0.0, 40.0, -0.19062876632126136, -9.94228800908989, -23.39747428545409, 160.0, 0.0, 74.67622908918044, -10.923477879433186, -7.1975479398229485, 100.0, -1.5914621316975641, 0.0, 49.98732103721615, 0.0, -7.379955912300503, 0.0, 0.0, -2.289554567303169, 20.0, -0.19502004907451576, 20.0, 0.0, 20.0, 0.0, 160.0, 32.05467120313718, -0.041843306710233064, 20.0, 0.0, -0.15345345979583924, 0.0, 58.858413852657144, 0.0, 20.0, 0.0, 0.0, 0.0, 60.0, 0.0, -0.7923644327953439, 40.0, 0.0, 0.0, 20.0, 41.004287943054614, -5.455700789599605, -2.294454791590901, -3.956089660260198, 0.0, 0.0, 0.0, 9.400712507976557, 20.0, 120.0, 0.0, -1.4587843560737501, 0.0, 20.0, -0.7268426065220135, 0.0, -2.7698571340066866, -1.0387852491846528, 58.94185813179544, 20.0, 19.92257529687226, 57.276059326342654, 40.0, 0.0, 20.0, 33.86701266915684, -1.7181566322876185, 73.1130248832203, -5.049489976975183, -3.1988618842325147, 0.0, 0.0, -4.244878038076535, -10.954774147619794, 0.0, -2.792677918579949, -1.6202909239696595, 0.0, 57.64576674347536, 0.0, 66.58512958772161, 60.0, -0.31127682165097204, 0.0, 0.0, 0.0, 0.0, 39.04421582471531], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 80.0, 80.0, 80.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 80.0, 80.0, 80.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0], "policy_agent_policy_reward": [-20.0, -17.394637377385234, 0.0, -2.7667050196497156, -20.789976819780602, 0.0, 0.0, -10.581117681985742, -10.0, 0.0, -10.048103762670252, -10.0, -3.7083179924808305, 0.0, -18.5016147745343, 0.0, 0.0, -38.26685901875856, 0.0, 0.0, -0.0867230484479975, -9.233432125309601, -14.7141258678975, 0.0, 0.0, -30.0, -46.81606330921911, 0.0, 0.0, -11.169939235057534, -0.1067717181950234, 0.0, -6.158233140548041, -39.99584327262128, -10.0, -50.0, 0.0, -0.9084982730008195, 0.0, 0.0, -20.0, 0.0, -20.0, 0.0, -13.516872632525896, -3.107167398348289, 0.0, -10.0, 0.0, -27.28592690267317, -30.47166369333971, 0.0, -50.0, -10.635124073851172, -25.78626978749692, -25.995294513326357, 0.0, -30.137268855745514, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -52.833621599759766, 0.0, -10.0, 0.0, -20.0, -0.19062876632126136, -9.94228800908989, -23.39747428545409, -80.0, 0.0, -45.323770910819555, -10.923477879433186, -7.1975479398229485, -50.0, -1.5914621316975641, 0.0, -40.01267896278385, 0.0, -7.379955912300503, 0.0, 0.0, -2.289554567303169, -10.0, -0.19502004907451576, -10.0, 0.0, -10.0, 0.0, -80.0, -27.945328796862814, -0.041843306710233064, -10.0, 0.0, -0.15345345979583924, 0.0, -31.14158614734286, 0.0, -10.0, 0.0, 0.0, 0.0, -30.0, 0.0, -0.7923644327953439, -20.0, 0.0, 0.0, -10.0, -48.995712056945386, -5.455700789599605, -2.294454791590901, -3.956089660260198, 0.0, 0.0, 0.0, -20.599287492023443, -10.0, -60.0, 0.0, -1.4587843560737501, 0.0, -10.0, -0.7268426065220135, 0.0, -2.7698571340066866, -1.0387852491846528, -31.058141868204565, -10.0, -10.07742470312774, -32.723940673657346, -20.0, 0.0, -10.0, -26.132987330843157, -1.7181566322876185, -46.88697511677969, -5.049489976975183, -3.1988618842325147, 0.0, 0.0, -4.244878038076535, -10.954774147619794, 0.0, -2.792677918579949, -1.6202909239696595, 0.0, -32.35423325652463, 0.0, -53.414870412278404, -30.0, -0.31127682165097204, 0.0, 0.0, 0.0, 0.0, -20.955784175284695]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6890488834031366, "mean_inference_ms": 1.1853275311265365, "mean_action_processing_ms": 0.24809000099416717, "mean_env_wait_ms": 0.5083542919035599, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003994247059763214, "StateBufferConnector_ms": 0.0033719304167194133, "ViewRequirementAgentConnector_ms": 0.08924949316330898}, "num_episodes": 162, "episode_return_max": 160.0, "episode_return_min": -23.39747428545409, "episode_return_mean": 14.565895768712869}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1488000, "num_agent_steps_trained": 1488000, "num_env_steps_sampled": 372000, "num_env_steps_trained": 372000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 341.758041680948, "num_env_steps_trained_throughput_per_sec": 341.758041680948, "timesteps_total": 372000, "num_env_steps_sampled_lifetime": 372000, "num_agent_steps_sampled_lifetime": 1488000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1488000, "timers": {"training_iteration_time_ms": 14265.498, "restore_workers_time_ms": 0.014, "training_step_time_ms": 14265.449, "sample_time_ms": 1275.233, "learn_time_ms": 12972.123, "learn_throughput": 308.354, "synch_weights_time_ms": 17.585}, "counters": {"num_env_steps_sampled": 372000, "num_env_steps_trained": 372000, "num_agent_steps_sampled": 1488000, "num_agent_steps_trained": 1488000}, "done": false, "training_iteration": 93, "trial_id": "86f16_00000", "date": "2024-08-08_16-34-55", "timestamp": 1723149295, "time_this_iter_s": 11.710702657699585, "time_total_s": 1323.7660014629364, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad2b3ee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1323.7660014629364, "iterations_since_restore": 93, "perf": {"cpu_util_percent": 29.758823529411764, "ram_util_percent": 78.22352941176472}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5446094111400716, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.5436109869192678, "policy_loss": -0.01673932386802722, "vf_loss": 1.5597573136818323, "vf_explained_var": 1.3274715301838327e-06, "kl": 0.005929986747596366, "entropy": 0.4406699982200954, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 263670.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.55497624228398, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.702242528398832, "policy_loss": -0.023878329727691987, "vf_loss": 2.7242442866166434, "vf_explained_var": 0.15724836196750402, "kl": 0.009382861892154678, "entropy": 0.9105117718378702, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 89760.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 376000, "num_env_steps_trained": 376000, "num_agent_steps_sampled": 1504000, "num_agent_steps_trained": 1504000}, "env_runners": {"episode_reward_max": 100.0, "episode_reward_min": -30.880751439481006, "episode_reward_mean": 10.382578434077962, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -53.06286633779598}, "policy_reward_max": {"adversary_policy": 50.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 6.604938271604938, "agent_policy": -9.432236380736853}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 29.205481469299094, 100.0, 0.0, 0.0, -1.2778876262004812, 0.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.9842756768560934, -3.2738819893646545, 0.0, 0.0, 0.0, -0.34047279040754774, 0.0, 20.0, 58.898929560634706, -3.164266423924391, 0.0, 0.0, 0.0, 9.553219320711293, 0.0, 0.0, 0.0, 0.0, 19.747622009858397, -30.880751439481006, -1.393715646478375, -2.8407042691755047, 0.0, 0.0, 0.0, -5.468532643468648, -6.489950612753398, 20.0, -8.169939510721205, 20.0, 53.91053417381336, 14.425355395302546, -2.6372616711057386, 20.0, -12.666029501541512, 33.18953761176489, -0.49392218251586684, 20.0, 60.0, -12.716836762763824, -3.7249333259813, 20.0, 19.0153563607185, -14.391598763571231, 0.0, -18.8179160779286, 60.0, 40.0, 0.0, 0.0, 0.0, 0.0, -1.274653907387715, 20.0, 59.9777697165174, 0.0, 0.0, -8.111375000141118, 96.93713366220402, 60.0, 0.0, -1.7211630906940556, 33.801516926828356, 67.7781509843825, 0.0, -2.2646313942499807, 0.0, 0.0, 57.751218901915934, -13.427787073013654, 0.0, 13.86510711853549, -1.2274371403169848, -16.90015282612561, 59.71374363135819, 37.91257005143126, 40.0, 5.3761963522257945, 0.0, 27.218555945661862, 0.0, -0.14994697257460943, 0.0, -3.1896325964606986, 0.0, -4.431228839754801, 20.0, -1.8627281605039214, 0.0, 0.0, 0.0, 0.0, 0.0, -8.688029817609154, 0.0, 0.0, 0.0, 18.95138173351246, 40.0, 20.0, -27.573233458987115, -2.1300018441618365, -2.637294583725108, -9.926877409892361, 0.0, -11.821991327006902, 0.0, 60.0, 33.35345909502057, 13.42693121337812, 17.525753842939434, 0.0, -0.13984720084503244, -0.24802716207201314, 0.0, -2.968865494312318, 40.0, 20.0, 100.0, -12.48387005367335, -11.249340199353528, -6.358648427821636, 20.0, 0.0, 0.0, -1.378471076900032, 0.0, 0.0, 39.91175004584926, -3.619460879769009, 0.0, 0.0, 0.0, 0.0, 39.07835290780711, -0.09723400842798546, 80.0, -5.75343175865672, -2.0357673832291043, 20.0, 80.0, 20.0, 0.0, 17.081420721683482, -14.044715196762146, -4.661147168770508, -1.4155022394566197, 37.89602817417068], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0], "policy_agent_policy_reward": [0.0, 0.0, -30.79451853070091, -50.0, 0.0, 0.0, -1.2778876262004812, 0.0, -30.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.9842756768560934, -3.2738819893646545, 0.0, 0.0, 0.0, -0.34047279040754774, 0.0, -10.0, -31.1010704393653, -3.164266423924391, 0.0, 0.0, 0.0, -20.446780679288704, 0.0, 0.0, 0.0, 0.0, -10.252377990141605, -30.880751439481006, -1.393715646478375, -2.8407042691755047, 0.0, 0.0, 0.0, -5.468532643468648, -6.489950612753398, -10.0, -8.169939510721205, -10.0, -36.08946582618664, -45.57464460469747, -2.6372616711057386, -10.0, -12.666029501541512, -26.810462388235116, -0.49392218251586684, -10.0, -30.0, -12.716836762763824, -3.7249333259813, -10.0, -10.984643639281499, -14.391598763571231, 0.0, -18.8179160779286, -30.0, -20.0, 0.0, 0.0, 0.0, 0.0, -1.274653907387715, -10.0, -30.022230283482592, 0.0, 0.0, -8.111375000141118, -53.06286633779598, -30.0, 0.0, -1.7211630906940556, -26.19848307317164, -52.221849015617494, 0.0, -2.2646313942499807, 0.0, 0.0, -32.248781098084066, -13.427787073013654, 0.0, -16.13489288146451, -1.2274371403169848, -16.90015282612561, -30.28625636864181, -22.087429948568744, -20.0, -24.62380364777421, 0.0, -32.781444054338145, 0.0, -0.14994697257460943, 0.0, -3.1896325964606986, 0.0, -4.431228839754801, -10.0, -1.8627281605039214, 0.0, 0.0, 0.0, 0.0, 0.0, -8.688029817609154, 0.0, 0.0, 0.0, -11.048618266487539, -20.0, -10.0, -27.573233458987115, -2.1300018441618365, -2.637294583725108, -9.926877409892361, 0.0, -11.821991327006902, 0.0, -30.0, -26.64654090497943, -16.57306878662188, -12.474246157060564, 0.0, -0.13984720084503244, -0.24802716207201314, 0.0, -2.968865494312318, -20.0, -10.0, -50.0, -12.48387005367335, -11.249340199353528, -6.358648427821636, -10.0, 0.0, 0.0, -1.378471076900032, 0.0, 0.0, -20.088249954150744, -3.619460879769009, 0.0, 0.0, 0.0, 0.0, -20.92164709219289, -0.09723400842798546, -40.0, -5.75343175865672, -2.0357673832291043, -10.0, -40.0, -10.0, 0.0, -12.918579278316518, -14.044715196762146, -4.661147168770508, -1.4155022394566197, -22.10397182582932]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6880002941160482, "mean_inference_ms": 1.1834329109738226, "mean_action_processing_ms": 0.2477049302516013, "mean_env_wait_ms": 0.5077555215383889, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0040278022671923226, "StateBufferConnector_ms": 0.0030075326377962844, "ViewRequirementAgentConnector_ms": 0.08511006096262991}, "num_episodes": 162, "episode_return_max": 100.0, "episode_return_min": -30.880751439481006, "episode_return_mean": 10.382578434077962}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1504000, "num_agent_steps_trained": 1504000, "num_env_steps_sampled": 376000, "num_env_steps_trained": 376000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 333.5481013232009, "num_env_steps_trained_throughput_per_sec": 333.5481013232009, "timesteps_total": 376000, "num_env_steps_sampled_lifetime": 376000, "num_agent_steps_sampled_lifetime": 1504000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1504000, "timers": {"training_iteration_time_ms": 13942.177, "restore_workers_time_ms": 0.014, "training_step_time_ms": 13942.129, "sample_time_ms": 1271.936, "learn_time_ms": 12652.269, "learn_throughput": 316.149, "synch_weights_time_ms": 17.439}, "counters": {"num_env_steps_sampled": 376000, "num_env_steps_trained": 376000, "num_agent_steps_sampled": 1504000, "num_agent_steps_trained": 1504000}, "done": false, "training_iteration": 94, "trial_id": "86f16_00000", "date": "2024-08-08_16-35-07", "timestamp": 1723149307, "time_this_iter_s": 12.000180959701538, "time_total_s": 1335.766182422638, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad28f160>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1335.766182422638, "iterations_since_restore": 94, "perf": {"cpu_util_percent": 29.91764705882353, "ram_util_percent": 77.78823529411765}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.575356853737476, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.474873270316327, "policy_loss": -0.01586608811519406, "vf_loss": 1.4901558804807933, "vf_explained_var": 9.828425468282497e-08, "kl": 0.005834770321019871, "entropy": 0.4642061742167946, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 266490.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.4874506233880918, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.529319102441271, "policy_loss": -0.02838909213654309, "vf_loss": 2.5557509178916615, "vf_explained_var": 0.10389192731430133, "kl": 0.009786385424024028, "entropy": 0.9397183448076248, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 90720.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 380000, "num_env_steps_trained": 380000, "num_agent_steps_sampled": 1520000, "num_agent_steps_trained": 1520000}, "env_runners": {"episode_reward_max": 180.0, "episode_reward_min": -26.80130269704817, "episode_reward_mean": 14.253513127020456, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -90.0}, "policy_reward_max": {"adversary_policy": 90.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 8.024691358024691, "agent_policy": -9.820560947053615}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, -0.22673818219756559, -8.749756735864171, 78.1005961573461, 39.80711843078703, 0.0, 20.0, -0.9364473010103036, 60.0, -3.9723540651178917, -26.80130269704817, -12.434718013952526, 0.0, 0.0, 0.0, 40.0, 0.0, 0.0, 60.0, 0.0, 40.0, 60.0, 0.0, -2.065212190862913, 0.0, 119.72798813240553, 27.00546768139481, 35.33946364965185, 20.0, 0.0, 0.0, 0.0, 31.066184468491333, -2.5240353534735194, 40.0, 0.0, 0.0, -0.10461137162785294, 40.0, -0.013071421733699129, 180.0, -3.71831968073839, -3.9321727331980334, 0.0, -0.36240683927041384, 0.0, 0.0, 17.725029451971686, 108.15449221214067, 80.0, 0.0, -4.154535190749273, 20.0, 40.0, -0.24588517385037645, 60.0, 0.0, 0.0, 0.0, 100.0, 0.0, -2.450450985523526, -7.36869943313069, -14.80705879368443, 0.0, 0.0, 0.0, 40.0, 0.0, -6.333207266785163, -0.650217273448177, 60.0, 0.0, -1.5694514545761273, 0.0, 60.0, -1.5549804309798343, 40.0, 0.0, 19.998031731850435, 23.113985316740344, -3.3608964608008174, -0.6129194154498108, 60.0, 0.0, -8.757513500189887, 0.0, -6.032062932635487, 80.0, 0.0, -6.629332238976263, 60.0, -3.2205158537635015, 0.0, -0.06055784042372947, 0.0, 60.0, 0.0, 0.0, -0.1748345065034962, 40.0, 0.0, 0.0, 0.0, -6.982448796450801, 40.0, -16.138148892852936, -19.455959515914884, 0.0, 0.0, 0.0, 7.298160654190397, 0.0, 17.110883950798137, 0.0, -5.3824967853724095, 59.88104456033621, 0.0, 0.0, 38.057909357928445, 40.0, 0.0, 0.0, 0.0, -9.469694709050806, 60.0, 0.0, -3.936928318016415, 40.0, -1.0832870938825834, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 120.0, 0.0, 0.0, 0.0, 20.0, 0.0, 19.517035587987213, 0.0, -2.9474384734729555, 0.0, 0.0, 20.0, -0.8556253498497679, -1.15884583834017, 20.0, 80.0, 0.0, 20.0, 40.0, -0.17837181510873656, 20.0, 0.0, 0.0, -11.420753840827238, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 90.0, 90.0, 90.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 60.0, 60.0, 60.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [0.0, 0.0, -0.22673818219756559, -8.749756735864171, -41.899403842653896, -20.19288156921297, 0.0, -10.0, -0.9364473010103036, -30.0, -3.9723540651178917, -26.80130269704817, -12.434718013952526, 0.0, 0.0, 0.0, -20.0, 0.0, 0.0, -30.0, 0.0, -20.0, -30.0, 0.0, -2.065212190862913, 0.0, -60.27201186759449, -32.994532318605195, -24.660536350348156, -10.0, 0.0, 0.0, 0.0, -28.93381553150866, -2.5240353534735194, -20.0, 0.0, 0.0, -0.10461137162785294, -20.0, -0.013071421733699129, -90.0, -3.71831968073839, -3.9321727331980334, 0.0, -0.36240683927041384, 0.0, 0.0, -12.274970548028314, -71.84550778785932, -40.0, 0.0, -4.154535190749273, -10.0, -20.0, -0.24588517385037645, -30.0, 0.0, 0.0, 0.0, -50.0, 0.0, -2.450450985523526, -7.36869943313069, -14.80705879368443, 0.0, 0.0, 0.0, -20.0, 0.0, -6.333207266785163, -0.650217273448177, -30.0, 0.0, -1.5694514545761273, 0.0, -30.0, -1.5549804309798343, -20.0, 0.0, -10.001968268149566, -36.88601468325965, -3.3608964608008174, -0.6129194154498108, -30.0, 0.0, -8.757513500189887, 0.0, -6.032062932635487, -40.0, 0.0, -6.629332238976263, -30.0, -3.2205158537635015, 0.0, -0.06055784042372947, 0.0, -30.0, 0.0, 0.0, -0.1748345065034962, -20.0, 0.0, 0.0, 0.0, -6.982448796450801, -20.0, -16.138148892852936, -19.455959515914884, 0.0, 0.0, 0.0, -22.701839345809603, 0.0, -12.889116049201869, 0.0, -5.3824967853724095, -30.118955439663793, 0.0, 0.0, -21.942090642071555, -20.0, 0.0, 0.0, 0.0, -9.469694709050806, -30.0, 0.0, -3.936928318016415, -20.0, -1.0832870938825834, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -60.0, 0.0, 0.0, 0.0, -10.0, 0.0, -10.482964412012787, 0.0, -2.9474384734729555, 0.0, 0.0, -10.0, -0.8556253498497679, -1.15884583834017, -10.0, -40.0, 0.0, -10.0, -20.0, -0.17837181510873656, -10.0, 0.0, 0.0, -11.420753840827238, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.687005047764409, "mean_inference_ms": 1.181671582807831, "mean_action_processing_ms": 0.2473141587050936, "mean_env_wait_ms": 0.5072082385567772, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0044200891329918375, "StateBufferConnector_ms": 0.003087299841421622, "ViewRequirementAgentConnector_ms": 0.08358484433021074}, "num_episodes": 162, "episode_return_max": 180.0, "episode_return_min": -26.80130269704817, "episode_return_mean": 14.253513127020456}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1520000, "num_agent_steps_trained": 1520000, "num_env_steps_sampled": 380000, "num_env_steps_trained": 380000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 323.50582082196416, "num_env_steps_trained_throughput_per_sec": 323.50582082196416, "timesteps_total": 380000, "num_env_steps_sampled_lifetime": 380000, "num_agent_steps_sampled_lifetime": 1520000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1520000, "timers": {"training_iteration_time_ms": 13538.561, "restore_workers_time_ms": 0.013, "training_step_time_ms": 13538.518, "sample_time_ms": 1260.929, "learn_time_ms": 12261.356, "learn_throughput": 326.228, "synch_weights_time_ms": 15.784}, "counters": {"num_env_steps_sampled": 380000, "num_env_steps_trained": 380000, "num_agent_steps_sampled": 1520000, "num_agent_steps_trained": 1520000}, "done": false, "training_iteration": 95, "trial_id": "86f16_00000", "date": "2024-08-08_16-35-20", "timestamp": 1723149320, "time_this_iter_s": 12.370323896408081, "time_total_s": 1348.136506319046, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad28f3a0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1348.136506319046, "iterations_since_restore": 95, "perf": {"cpu_util_percent": 30.87222222222222, "ram_util_percent": 78.20555555555555}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5715940600379984, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.7728034759878266, "policy_loss": -0.015423734653336558, "vf_loss": 1.7876957740766781, "vf_explained_var": 3.389855648608918e-07, "kl": 0.0053143710091894955, "entropy": 0.4521409805467788, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 269310.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.443508342280984, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.93403727983435, "policy_loss": -0.020307017417265646, "vf_loss": 2.952752761294444, "vf_explained_var": 0.08541503517578046, "kl": 0.007957709690693395, "entropy": 0.9075820179656148, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 91680.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 384000, "num_env_steps_trained": 384000, "num_agent_steps_sampled": 1536000, "num_agent_steps_trained": 1536000}, "env_runners": {"episode_reward_max": 160.0, "episode_reward_min": -27.030682643603143, "episode_reward_mean": 14.262289954616415, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 153, "episodes_timesteps_total": 3825, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -93.79058023312581}, "policy_reward_max": {"adversary_policy": 80.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 8.431372549019608, "agent_policy": -11.031827692442407}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, -0.3997111422571631, 0.0, 40.0, 15.748494116499117, -7.739151969352793, 18.23177652471917, 0.0, 0.0, -3.8517273281537996, -1.6537157690581539, 18.70021175611538, -1.40309210062178, 100.0, 60.0, 58.41785081077764, 20.0, -1.4360520772480945, 0.0, 60.0, -1.9453433746928483, -6.681020351952354, -5.899413208836572, 20.0, 23.338524003970672, -10.667079005757683, -0.004730237602151854, 6.445558515066685, 40.0, -0.6651526327047741, 0.0, 35.66138467335682, 60.0, -13.038797695824979, 40.0, -1.0190160155226768, -3.0609882693599646, 40.0, 0.0, 60.0, 0.0, 20.0, 0.0, 0.0, 0.0, 0.0, 19.008129861683088, 0.0, 0.0, 40.0, -0.010567299612861403, -0.09687026662432818, 0.0, 0.0, 160.0, -11.936689504467225, -8.494086670968992, 0.0, 20.0, 59.911860984723404, 0.0, 40.0, -2.9081208715814935, -0.23470565001375787, 40.0, 57.81072666237763, 0.0, -0.3399765374221142, 60.0, 0.0, 0.0, 15.12314184288274, 77.27590218510713, -0.01482046692102168, 0.0, 0.0, 20.0, 0.0, 0.0, 0.0, -5.976045336728139, 0.0, 80.0, 20.0, 0.0, 0.0, 0.0, -16.35345532548322, 6.5892456529392085, 0.0, 40.0, -10.564603178165864, -7.917027435807104, 0.0, 60.0, 0.0, 0.0, 51.355354948423575, 146.2094197668742, -2.698077114431129, 0.0, -12.847800161195456, 0.0, -0.08171660027225136, 19.013980463061383, -0.6536061652718561, -0.14172859209634292, 59.41245305894137, 40.0, 39.78821823542252, 40.0, 0.0, 26.822981632465762, 39.05447411792767, -3.0171748841378863, 40.0, 20.0, 33.15924568540364, 0.0, 0.0, 0.0, 20.0, 0.0, 0.0, -3.1903187157043815, 0.0, 0.0, -3.309295825575825, -1.3048208168769726, 0.0, 0.0, 160.0, 38.60689033905235, 0.0, 0.0, -10.975303544302534, -20.359878971402782, 0.0, -4.485608152045995, -0.029222897783648394, 0.0, 0.0, -0.41263382751345334, -1.9682065018300343, -1.4479776687665735, -20.80240651273964, -0.25971143976660116, -9.469280946994887, 86.58590107417194, 0.0, -27.030682643603143, 18.70356906186816, -0.04752121246630603], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 80.0, 80.0, 80.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 80.0, 80.0, 80.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 80.0, 80.0, 80.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [0.0, -0.3997111422571631, 0.0, -20.0, -14.251505883500883, -7.739151969352793, -11.76822347528083, 0.0, 0.0, -3.8517273281537996, -1.6537157690581539, -11.29978824388462, -1.40309210062178, -50.0, -30.0, -31.582149189222367, -10.0, -1.4360520772480945, 0.0, -30.0, -1.9453433746928483, -6.681020351952354, -5.899413208836572, -10.0, -36.661475996029324, -10.667079005757683, -0.004730237602151854, -23.554441484933317, -20.0, -0.6651526327047741, 0.0, -24.33861532664318, -30.0, -13.038797695824979, -20.0, -1.0190160155226768, -3.0609882693599646, -20.0, 0.0, -30.0, 0.0, -10.0, 0.0, 0.0, 0.0, 0.0, -10.991870138316912, 0.0, 0.0, -20.0, -0.010567299612861403, -0.09687026662432818, 0.0, 0.0, -80.0, -11.936689504467225, -8.494086670968992, 0.0, -10.0, -30.08813901527659, 0.0, -20.0, -2.9081208715814935, -0.23470565001375787, -20.0, -32.18927333762237, 0.0, -0.3399765374221142, -30.0, 0.0, 0.0, -14.876858157117264, -42.72409781489287, -0.01482046692102168, 0.0, 0.0, -10.0, 0.0, 0.0, 0.0, -5.976045336728139, 0.0, -40.0, -10.0, 0.0, 0.0, 0.0, -16.35345532548322, -23.41075434706079, 0.0, -20.0, -10.564603178165864, -7.917027435807104, 0.0, -30.0, 0.0, 0.0, -38.644645051576425, -93.79058023312581, -2.698077114431129, 0.0, -12.847800161195456, 0.0, -0.08171660027225136, -40.98601953693861, -0.6536061652718561, -0.14172859209634292, -30.587546941058633, -20.0, -20.211781764577477, -20.0, 0.0, -33.17701836753424, -20.945525882072335, -3.0171748841378863, -20.0, -10.0, -26.84075431459636, 0.0, 0.0, 0.0, -10.0, 0.0, 0.0, -3.1903187157043815, 0.0, 0.0, -3.309295825575825, -1.3048208168769726, 0.0, 0.0, -80.0, -21.39310966094765, 0.0, 0.0, -10.975303544302534, -20.359878971402782, 0.0, -4.485608152045995, -0.029222897783648394, 0.0, 0.0, -0.41263382751345334, -1.9682065018300343, -1.4479776687665735, -20.80240651273964, -0.25971143976660116, -9.469280946994887, -63.414098925828036, 0.0, -27.030682643603143, -11.296430938131838, -0.04752121246630603]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.686061818065344, "mean_inference_ms": 1.180269746584796, "mean_action_processing_ms": 0.24693201484738864, "mean_env_wait_ms": 0.5067760676921638, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004063088909473295, "StateBufferConnector_ms": 0.003456757738699321, "ViewRequirementAgentConnector_ms": 0.08560317793702768}, "num_episodes": 153, "episode_return_max": 160.0, "episode_return_min": -27.030682643603143, "episode_return_mean": 14.262289954616415}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1536000, "num_agent_steps_trained": 1536000, "num_env_steps_sampled": 384000, "num_env_steps_trained": 384000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 335.88885463375203, "num_env_steps_trained_throughput_per_sec": 335.88885463375203, "timesteps_total": 384000, "num_env_steps_sampled_lifetime": 384000, "num_agent_steps_sampled_lifetime": 1536000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1536000, "timers": {"training_iteration_time_ms": 13116.445, "restore_workers_time_ms": 0.013, "training_step_time_ms": 13116.405, "sample_time_ms": 1260.461, "learn_time_ms": 11840.237, "learn_throughput": 337.831, "synch_weights_time_ms": 15.225}, "counters": {"num_env_steps_sampled": 384000, "num_env_steps_trained": 384000, "num_agent_steps_sampled": 1536000, "num_agent_steps_trained": 1536000}, "done": false, "training_iteration": 96, "trial_id": "86f16_00000", "date": "2024-08-08_16-35-32", "timestamp": 1723149332, "time_this_iter_s": 11.914214134216309, "time_total_s": 1360.0507204532623, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad2b3f70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1360.0507204532623, "iterations_since_restore": 96, "perf": {"cpu_util_percent": 29.98235294117647, "ram_util_percent": 78.31764705882352}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6022500592237668, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.6684459782449912, "policy_loss": -0.017144737507593124, "vf_loss": 1.6849327718957943, "vf_explained_var": -1.3353976797550282e-07, "kl": 0.0065794470191020684, "entropy": 0.4500348683050338, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 272130.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.4870098271717627, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.7779861272623143, "policy_loss": -0.02749262336656102, "vf_loss": 2.803760636597872, "vf_explained_var": 0.13224103165169557, "kl": 0.008590570198365767, "entropy": 0.9082443676888943, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 92640.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 388000, "num_env_steps_trained": 388000, "num_agent_steps_sampled": 1552000, "num_agent_steps_trained": 1552000}, "env_runners": {"episode_reward_max": 139.8355819441285, "episode_reward_min": -24.91880455495204, "episode_reward_mean": 12.956629717879578, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -70.1644180558715}, "policy_reward_max": {"adversary_policy": 70.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 7.530864197530864, "agent_policy": -9.635962874713014}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.864287179204574, 38.46401307680354, 0.0, 0.0, 0.0, -0.6848090202143475, -0.3693550855289707, 20.0, 0.0, 0.0, -14.374306991503563, 40.0, 0.0, 0.0, 0.0, 52.699842239518766, 60.0, 0.0, -3.0113944217335504, 35.57717465538013, 0.0, -11.95508596466333, 0.0, 20.0, 0.0, 18.43805333271708, 40.0, 0.0, 20.0, -24.91880455495204, -1.6762516146302398, -0.005894110796184071, 139.8355819441285, -0.1317538057726575, 40.0, 0.0, -7.339333285542846, 0.0, 0.0, 80.0, -10.03767438928533, -0.34042339232429497, 51.03703072640798, 38.735877721371104, 0.0, 0.0, -5.438642759143874, -0.999852021051868, -14.750028318952833, 0.0, -0.43030056535530714, 100.0, -0.6299941943746457, 0.0, 0.0, 0.0, -1.3045250454696533, 13.058841730662813, 0.0, -12.063450455599243, 20.0, 20.0, 0.0, 20.0, 20.0, 40.0, 20.0, 20.0, 20.0, -0.19497286401015557, 0.0, 80.0, -1.9370615172210381, 0.0, 20.0, 0.0, 40.0, 60.0, 0.0, 0.0, -11.690319271673246, -5.052704482236528, 0.0, -2.218482232252979, 19.997594946688153, -5.361154327313888, 18.456217581962544, -0.01353679970900079, 39.666946056611444, 0.0, 0.0, 60.0, 0.0, -15.433286157694987, 0.0, -6.359435988942064, 0.0, 39.6797293818539, 0.0, 0.0, -5.016547045778082, -12.896082320053749, 0.0, -12.632437886122243, -14.877455320357162, 100.0, 39.21596464496174, 39.05712121561338, 0.0, -9.571889312748729, 0.0, -1.1043029474693822, -0.5252378241531619, 40.0, 20.0, -4.4327062917363875, -0.6740596855524428, -1.2038312244657101, 0.0, 40.0, 0.0, 40.0, 0.0, 32.725529264715426, 0.0, 0.0, 0.0, -17.915963938529636, 0.0, 0.0, 0.0, -11.576192373561899, 34.90845356361782, -1.566371339660233, 0.0, 20.0, 0.0, 40.0, -0.43409408599919486, -0.5630829523583825, -0.4000674376907365, -5.727752793436769, 0.0, -1.9235684740907288, 40.0, 0.0, 37.74371409325127, 48.422808056483554, 0.0, 18.241473261034983, -3.4775577956893424, 0.0, 0.0, 0.0, 0.0, 69.58059562307983, 100.0, 39.827715434366844, 40.0, 0.0, 80.0, 39.98148325345903], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0], "policy_agent_policy_reward": [-21.135712820795426, -21.535986923196464, 0.0, 0.0, 0.0, -0.6848090202143475, -0.3693550855289707, -10.0, 0.0, 0.0, -14.374306991503563, -20.0, 0.0, 0.0, 0.0, -37.300157760481234, -30.0, 0.0, -3.0113944217335504, -24.422825344619874, 0.0, -11.95508596466333, 0.0, -10.0, 0.0, -11.561946667282921, -20.0, 0.0, -10.0, -24.91880455495204, -1.6762516146302398, -0.005894110796184071, -70.1644180558715, -0.1317538057726575, -20.0, 0.0, -7.339333285542846, 0.0, 0.0, -40.0, -10.03767438928533, -0.34042339232429497, -38.96296927359202, -21.264122278628907, 0.0, 0.0, -5.438642759143874, -0.999852021051868, -14.750028318952833, 0.0, -0.43030056535530714, -50.0, -0.6299941943746457, 0.0, 0.0, 0.0, -1.3045250454696533, -16.941158269337187, 0.0, -12.063450455599243, -10.0, -10.0, 0.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -0.19497286401015557, 0.0, -40.0, -1.9370615172210381, 0.0, -10.0, 0.0, -20.0, -30.0, 0.0, 0.0, -11.690319271673246, -5.052704482236528, 0.0, -2.218482232252979, -10.002405053311845, -5.361154327313888, -11.543782418037456, -0.01353679970900079, -20.333053943388556, 0.0, 0.0, -30.0, 0.0, -15.433286157694987, 0.0, -6.359435988942064, 0.0, -20.3202706181461, 0.0, 0.0, -5.016547045778082, -12.896082320053749, 0.0, -12.632437886122243, -14.877455320357162, -50.0, -20.784035355038263, -20.94287878438662, 0.0, -9.571889312748729, 0.0, -1.1043029474693822, -0.5252378241531619, -20.0, -10.0, -4.4327062917363875, -0.6740596855524428, -1.2038312244657101, 0.0, -20.0, 0.0, -20.0, 0.0, -27.274470735284563, 0.0, 0.0, 0.0, -17.915963938529636, 0.0, 0.0, 0.0, -11.576192373561899, -25.091546436382185, -1.566371339660233, 0.0, -10.0, 0.0, -20.0, -0.43409408599919486, -0.5630829523583825, -0.4000674376907365, -5.727752793436769, 0.0, -1.9235684740907288, -20.0, 0.0, -22.256285906748733, -41.577191943516446, 0.0, -11.758526738965013, -3.4775577956893424, 0.0, 0.0, 0.0, 0.0, -50.41940437692017, -50.0, -20.172284565633156, -20.0, 0.0, -40.0, -20.018516746540964]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.685351291470755, "mean_inference_ms": 1.17901595911363, "mean_action_processing_ms": 0.24662542140982743, "mean_env_wait_ms": 0.5064294348040718, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00458764441219377, "StateBufferConnector_ms": 0.0031037095152301555, "ViewRequirementAgentConnector_ms": 0.0914735558592243}, "num_episodes": 162, "episode_return_max": 139.8355819441285, "episode_return_min": -24.91880455495204, "episode_return_mean": 12.956629717879578}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1552000, "num_agent_steps_trained": 1552000, "num_env_steps_sampled": 388000, "num_env_steps_trained": 388000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 334.91839101902457, "num_env_steps_trained_throughput_per_sec": 334.91839101902457, "timesteps_total": 388000, "num_env_steps_sampled_lifetime": 388000, "num_agent_steps_sampled_lifetime": 1552000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1552000, "timers": {"training_iteration_time_ms": 12675.95, "restore_workers_time_ms": 0.013, "training_step_time_ms": 12675.911, "sample_time_ms": 1259.359, "learn_time_ms": 11401.462, "learn_throughput": 350.832, "synch_weights_time_ms": 14.632}, "counters": {"num_env_steps_sampled": 388000, "num_env_steps_trained": 388000, "num_agent_steps_sampled": 1552000, "num_agent_steps_trained": 1552000}, "done": false, "training_iteration": 97, "trial_id": "86f16_00000", "date": "2024-08-08_16-35-44", "timestamp": 1723149344, "time_this_iter_s": 11.949509859085083, "time_total_s": 1372.0002303123474, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad37a0d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1372.0002303123474, "iterations_since_restore": 97, "perf": {"cpu_util_percent": 31.976470588235294, "ram_util_percent": 78.5}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.608504281510064, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.8582454415500587, "policy_loss": -0.01975788873395757, "vf_loss": 1.877327127575029, "vf_explained_var": 1.38126366527368e-07, "kl": 0.006762014708714016, "entropy": 0.45999395708877144, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 274950.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.409972865320742, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.199757316832741, "policy_loss": -0.02918386723419341, "vf_loss": 3.2268828549732764, "vf_explained_var": 0.11904839656005303, "kl": 0.010291660115422966, "entropy": 0.9016829436644912, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 93600.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 392000, "num_env_steps_trained": 392000, "num_agent_steps_sampled": 1568000, "num_agent_steps_trained": 1568000}, "env_runners": {"episode_reward_max": 100.0, "episode_reward_min": -26.437402073147968, "episode_reward_mean": 13.477680187306495, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -57.7197823244982}, "policy_reward_max": {"adversary_policy": 50.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 8.333333333333334, "agent_policy": -11.522319812693505}, "custom_metrics": {}, "hist_stats": {"episode_reward": [20.0, -8.813644100323808, 37.655811572962556, 40.0, -6.825133066715933, 2.1879982170844077, 0.0, 0.0, 18.880992627800715, 40.0, 60.0, -8.600441339980298, 20.0, -12.329911021577884, 29.0529881408702, 42.34558949190594, 0.0, -1.9109253970315643, 20.0, -1.8561975091451588, 0.0, 0.0, 40.0, 10.163999025949574, -1.4739991284035447, -0.9533873949798632, -9.35963646612732, 17.256489429835838, 18.60669113721, 0.0, 20.0, -10.797442748795953, 0.0, 0.0, 50.93760455892261, 0.0, -14.098519206099267, 0.0, 0.0, 40.0, 12.440544514237814, 39.27281315063078, 0.0, 0.0, 20.0, 0.0, -0.5215705420718342, -9.31527548233087, -18.2902300182077, -26.437402073147968, 0.0, 0.0, 0.0, -16.231457374366304, -1.560062809588454, -20.290828538694857, 19.08988866995813, -5.905574674001676, 79.85974525837989, -1.5417975119704541, 0.0, 0.0, -0.8267080298354623, 20.0, 13.981443251710928, 0.0, 100.0, 0.0, 20.0, -25.608996116115282, -5.0707473348237055, 0.0, 96.73203778957605, 40.0, 19.765828550365626, 13.081864642079575, 36.57489661604475, 0.0, -12.997072004107363, 0.0, 0.0, -0.20220273905543817, 0.0, 20.0, 40.0, 60.0, -2.6049196543819564, 0.0, 0.0, 0.0, 20.0, 60.0, 0.0, 44.99410888649908, 0.0, 0.0, 0.0, 0.0, -0.5272472773913939, 80.0, 0.0, 0.0, 38.81523954512093, 0.0, -1.4015916331541012, 40.0, -7.600013277921766, 0.0, 70.71320461515197, 0.0, 19.992213793129945, -9.811854331918962, -0.5289718661940523, 0.0, 0.0, 0.0, 40.0, 40.0, 0.0, 20.0, 60.0, -0.3823702671128104, 17.677644203007816, 20.0, 0.0, 0.0, 0.0, 0.0, 40.0, 0.0, 59.73075954141555, 0.0, 18.599129254939267, 2.2802176755017998, 0.0, 0.0, -4.168147185546188, 12.95606580031488, 0.0, 0.0, 19.447488104132667, 60.0, 60.0, 0.0, 0.0, -2.909597293939089, 49.55893482574021, 0.0, 20.0, -4.257713020963478, 0.0, -0.25566836182785324, 18.169198124084694, -2.560377651106129, 99.71287344317679, -6.8502311042008195, -0.30268673929189527, 0.0, 80.0, 60.0, -1.1695618216402193, 100.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0], "policy_agent_policy_reward": [-10.0, -8.813644100323808, -52.34418842703746, -20.0, -6.825133066715933, -27.812001782915598, 0.0, 0.0, -11.119007372199286, -20.0, -30.0, -8.600441339980298, -10.0, -12.329911021577884, -30.947011859129812, -47.65441050809406, 0.0, -1.9109253970315643, -10.0, -1.8561975091451588, 0.0, 0.0, -20.0, -49.83600097405042, -1.4739991284035447, -0.9533873949798632, -9.35963646612732, -12.743510570164164, -11.39330886279, 0.0, -10.0, -10.797442748795953, 0.0, 0.0, -39.06239544107739, 0.0, -14.098519206099267, 0.0, 0.0, -20.0, -17.559455485762186, -20.72718684936922, 0.0, 0.0, -10.0, 0.0, -0.5215705420718342, -9.31527548233087, -18.2902300182077, -26.437402073147968, 0.0, 0.0, 0.0, -16.231457374366304, -1.560062809588454, -20.290828538694857, -10.910111330041868, -5.905574674001676, -40.14025474162011, -1.5417975119704541, 0.0, 0.0, -0.8267080298354623, -10.0, -16.018556748289072, 0.0, -50.0, 0.0, -10.0, -25.608996116115282, -35.07074733482369, 0.0, -53.26796221042397, -20.0, -10.234171449634372, -16.91813535792042, -23.425103383955253, 0.0, -12.997072004107363, 0.0, 0.0, -0.20220273905543817, 0.0, -10.0, -20.0, -30.0, -2.6049196543819564, 0.0, 0.0, 0.0, -10.0, -30.0, 0.0, -45.00589111350092, 0.0, 0.0, 0.0, 0.0, -0.5272472773913939, -40.0, 0.0, 0.0, -21.18476045487907, 0.0, -1.4015916331541012, -20.0, -7.600013277921766, 0.0, -49.28679538484806, 0.0, -10.007786206870055, -9.811854331918962, -0.5289718661940523, 0.0, 0.0, 0.0, -20.0, -20.0, 0.0, -10.0, -30.0, -0.3823702671128104, -12.322355796992184, -10.0, 0.0, 0.0, 0.0, 0.0, -20.0, 0.0, -30.26924045858444, 0.0, -11.400870745060733, -57.7197823244982, 0.0, 0.0, -4.168147185546188, -17.04393419968512, 0.0, 0.0, -10.55251189586733, -30.0, -30.0, 0.0, 0.0, -2.909597293939089, -40.44106517425979, 0.0, -10.0, -4.257713020963478, 0.0, -0.25566836182785324, -11.830801875915306, -2.560377651106129, -50.28712655682321, -6.8502311042008195, -0.30268673929189527, 0.0, -40.0, -30.0, -1.1695618216402193, -50.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6842817131899347, "mean_inference_ms": 1.1771296081841445, "mean_action_processing_ms": 0.2462253687499849, "mean_env_wait_ms": 0.5058981488010901, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004372111073246709, "StateBufferConnector_ms": 0.003443897506337107, "ViewRequirementAgentConnector_ms": 0.08609103567806291}, "num_episodes": 162, "episode_return_max": 100.0, "episode_return_min": -26.437402073147968, "episode_return_mean": 13.477680187306495}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1568000, "num_agent_steps_trained": 1568000, "num_env_steps_sampled": 392000, "num_env_steps_trained": 392000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 328.6615425615234, "num_env_steps_trained_throughput_per_sec": 328.6615425615234, "timesteps_total": 392000, "num_env_steps_sampled_lifetime": 392000, "num_agent_steps_sampled_lifetime": 1568000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1568000, "timers": {"training_iteration_time_ms": 12091.799, "restore_workers_time_ms": 0.013, "training_step_time_ms": 12091.762, "sample_time_ms": 1227.797, "learn_time_ms": 10849.358, "learn_throughput": 368.685, "synch_weights_time_ms": 14.076}, "counters": {"num_env_steps_sampled": 392000, "num_env_steps_trained": 392000, "num_agent_steps_sampled": 1568000, "num_agent_steps_trained": 1568000}, "done": false, "training_iteration": 98, "trial_id": "86f16_00000", "date": "2024-08-08_16-35-56", "timestamp": 1723149356, "time_this_iter_s": 12.177127838134766, "time_total_s": 1384.1773581504822, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad37a310>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1384.1773581504822, "iterations_since_restore": 98, "perf": {"cpu_util_percent": 34.45294117647059, "ram_util_percent": 78.94117647058823}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5754965445991104, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.646176133236141, "policy_loss": -0.017325903524162498, "vf_loss": 1.662880466719891, "vf_explained_var": 6.778443113286445e-07, "kl": 0.006215698089284935, "entropy": 0.4512641466572775, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 277770.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.4669110628465813, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.8068755360941093, "policy_loss": -0.02856387767436293, "vf_loss": 2.8337209622065225, "vf_explained_var": 0.10864578336477279, "kl": 0.008592246238154723, "entropy": 0.8791546884924173, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 94560.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 396000, "num_env_steps_trained": 396000, "num_agent_steps_sampled": 1584000, "num_agent_steps_trained": 1584000}, "env_runners": {"episode_reward_max": 100.0, "episode_reward_min": -24.223593764748877, "episode_reward_mean": 11.52942702124399, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -52.69080311188652}, "policy_reward_max": {"adversary_policy": 50.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 6.9753086419753085, "agent_policy": -9.396498904681938}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, -3.89680865892329, -12.165829980284357, -0.8605539538983797, 0.0, 20.0, 0.0, 0.0, 0.0, -0.8353289145637333, 40.0, -10.571293202151702, -24.223593764748877, 40.0, 20.0, 0.0, 0.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.5412620701475102, 60.0, -4.505681255929087, 56.64889230456576, 17.560766084064966, 0.0, 0.0, 20.0, 80.0, 0.0, 0.0, 60.0, -1.2388045767284084, 40.0, -14.138825106517004, 0.0, 57.15201033812165, -0.45341856232927524, 0.0, 26.936821960084217, 100.0, -15.877923044148144, 0.0, -2.3600984649238246, -5.969974244830518, 18.736830091032306, -1.0202816242158819, 0.0, 18.9814982029048, 20.0, -0.2253656855323527, 0.0, 0.0, 60.0, 37.30919688811348, 20.0, 0.0, -14.560293641651624, 0.0, 19.115233046103885, 0.0, -4.539492222829224, -5.059435558538984, -9.58035347269925, 0.0, 0.0, 40.0, 0.0, 19.24944148206677, 0.0, -2.2821944600355115, 0.0, 40.0, -5.569539053131135, 40.0, -19.748875876007368, 20.0, 80.0, -2.6637139211150433, 0.0, 0.0, -0.1638317889770391, 79.76508066596828, 0.0, 60.0, 80.0, -0.1059845504713286, -0.5841425211886286, -4.885222533176835, 0.0, 40.0, 0.0, 20.0, 20.0, 20.0, 40.0, -18.567883495299956, 40.0, -19.0592780601667, -4.484834874724076, 20.0, 18.212067052967924, 59.951730793959136, 60.0, -2.5846059284014578, 0.0, 19.508784769588996, -1.1333164786659833, 0.0, 0.0, 0.0, 0.0, 30.4175164864427, 0.0, -14.678168413551148, 11.851574584644116, -1.1738137296601892e-05, -0.005100295410379596, -16.57631812521067, 20.0, 0.0, 0.0, 78.8871989375248, 20.0, -2.9494342829315126, 0.0, -13.31871081733585, 0.0, 56.65721028743172, 0.0, 0.0, 20.0, 0.0, -23.11091053045255, -2.5513959611838084, 50.912382975574566, 20.0, -0.47517576392201777, 0.0, 0.0, -0.0021636203165675827, -0.6517120689633227, 20.0, -0.35639629882948776, 40.0, 0.0, 0.0, 97.43696509867067, 0.0, -4.241921636267141, 0.0, 17.830396099000875, -5.295145901126999, -5.563098758963029, 0.0, -0.5287655018725446, -0.5919494458784624, 20.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0], "policy_agent_policy_reward": [0.0, -3.89680865892329, -12.165829980284357, -0.8605539538983797, 0.0, -10.0, 0.0, 0.0, 0.0, -0.8353289145637333, -20.0, -10.571293202151702, -24.223593764748877, -20.0, -10.0, 0.0, 0.0, -10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.5412620701475102, -30.0, -4.505681255929087, -33.35110769543424, -12.43923391593503, 0.0, 0.0, -10.0, -40.0, 0.0, 0.0, -30.0, -1.2388045767284084, -20.0, -14.138825106517004, 0.0, -32.84798966187836, -0.45341856232927524, 0.0, -33.06317803991579, -50.0, -15.877923044148144, 0.0, -2.3600984649238246, -5.969974244830518, -11.263169908967694, -1.0202816242158819, 0.0, -11.018501797095201, -10.0, -0.2253656855323527, 0.0, 0.0, -30.0, -52.69080311188652, -10.0, 0.0, -14.560293641651624, 0.0, -10.884766953896117, 0.0, -4.539492222829224, -5.059435558538984, -9.58035347269925, 0.0, 0.0, -20.0, 0.0, -10.75055851793323, 0.0, -2.2821944600355115, 0.0, -20.0, -5.569539053131135, -20.0, -19.748875876007368, -10.0, -40.0, -2.6637139211150433, 0.0, 0.0, -0.1638317889770391, -40.234919334031716, 0.0, -30.0, -40.0, -0.1059845504713286, -0.5841425211886286, -4.885222533176835, 0.0, -20.0, 0.0, -10.0, -10.0, -10.0, -20.0, -18.567883495299956, -20.0, -19.0592780601667, -4.484834874724076, -10.0, -11.787932947032072, -30.048269206040864, -30.0, -2.5846059284014578, 0.0, -10.491215230411008, -1.1333164786659833, 0.0, 0.0, 0.0, 0.0, -29.582483513557314, 0.0, -14.678168413551148, -18.148425415355884, -1.1738137296601892e-05, -0.005100295410379596, -16.57631812521067, -10.0, 0.0, 0.0, -41.1128010624752, -10.0, -2.9494342829315126, 0.0, -13.31871081733585, 0.0, -33.34278971256828, 0.0, 0.0, -10.0, 0.0, -23.11091053045255, -2.5513959611838084, -39.087617024425434, -10.0, -0.47517576392201777, 0.0, 0.0, -0.0021636203165675827, -0.6517120689633227, -10.0, -0.35639629882948776, -20.0, 0.0, 0.0, -52.56303490132934, 0.0, -4.241921636267141, 0.0, -12.169603900999125, -5.295145901126999, -5.563098758963029, 0.0, -0.5287655018725446, -0.5919494458784624, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6836631089595504, "mean_inference_ms": 1.1762008363178913, "mean_action_processing_ms": 0.24598318427818108, "mean_env_wait_ms": 0.5055399193144244, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0040236814522448885, "StateBufferConnector_ms": 0.0033140182495117188, "ViewRequirementAgentConnector_ms": 0.09065152686319233}, "num_episodes": 162, "episode_return_max": 100.0, "episode_return_min": -24.223593764748877, "episode_return_mean": 11.52942702124399}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1584000, "num_agent_steps_trained": 1584000, "num_env_steps_sampled": 396000, "num_env_steps_trained": 396000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 335.5216051873288, "num_env_steps_trained_throughput_per_sec": 335.5216051873288, "timesteps_total": 396000, "num_env_steps_sampled_lifetime": 396000, "num_agent_steps_sampled_lifetime": 1584000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1584000, "timers": {"training_iteration_time_ms": 12002.63, "restore_workers_time_ms": 0.013, "training_step_time_ms": 12002.595, "sample_time_ms": 1187.803, "learn_time_ms": 10800.63, "learn_throughput": 370.349, "synch_weights_time_ms": 13.617}, "counters": {"num_env_steps_sampled": 396000, "num_env_steps_trained": 396000, "num_agent_steps_sampled": 1584000, "num_agent_steps_trained": 1584000}, "done": false, "training_iteration": 99, "trial_id": "86f16_00000", "date": "2024-08-08_16-36-08", "timestamp": 1723149368, "time_this_iter_s": 11.928247213363647, "time_total_s": 1396.1056053638458, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad37a4c0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1396.1056053638458, "iterations_since_restore": 99, "perf": {"cpu_util_percent": 30.87777777777778, "ram_util_percent": 78.66666666666667}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5315895078241403, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.6914724518009956, "policy_loss": -0.016495225591839337, "vf_loss": 1.7073544620199406, "vf_explained_var": -3.9155178881706075e-07, "kl": 0.006132177409841325, "entropy": 0.4480925441422361, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 280590.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.5509499420722324, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.8186074011027813, "policy_loss": -0.026768969891418238, "vf_loss": 2.8434393166253966, "vf_explained_var": 0.1326603834827741, "kl": 0.00968521067869445, "entropy": 0.8648428336406747, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 95520.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 400000, "num_env_steps_trained": 400000, "num_agent_steps_sampled": 1600000, "num_agent_steps_trained": 1600000}, "env_runners": {"episode_reward_max": 120.0, "episode_reward_min": -29.645995720438037, "episode_reward_mean": 15.633592977684449, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -60.0}, "policy_reward_max": {"adversary_policy": 60.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 8.950617283950617, "agent_policy": -11.218258874167402}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-2.4111124943468263, 0.0, -3.4691890301394626, -5.412891540231704, -29.645995720438037, 0.0, -8.19288481282269, 0.0, 0.0, 0.0, 40.0, 19.918875279055076, -10.981236394922893, 0.0, -0.7408217096745262, 0.0, 0.0, -0.16530614243776554, 0.0, 0.0, 12.931668935129304, 19.9686836440589, 0.0, -1.9414677974343486, 20.0, 0.0, 0.0, 0.0, 60.0, 27.702057400809714, -3.3843919395511017, 19.928677514477105, 20.0, 0.0, -7.214316170928963, 0.0, -3.4184705695169764, 20.0, 19.900870287127344, -1.395315416626054, -0.3360227763800039, 40.0, 60.0, 40.0, -1.743852099447707, 120.0, 19.694169840741985, 0.0, 0.0, 0.0, 36.811308371149934, -2.00648342534399, -2.1845968021074045, 0.0, 0.0, 0.0, 20.0, 0.0, 80.0, 20.0, -2.0088533302079723, 79.9743894498298, 0.0, -3.474645285881016, 34.61646478483993, -6.941695385172581, 0.0, -10.234963333831828, -0.5800241438662967, -0.3009460076092041, 40.0, 20.0, -1.0239929850730267, 80.0, 34.46111533001731, -13.842677740041182, 60.0, -16.907745817720294, -0.10058124278041203, 59.35426233234598, 30.476261286452342, 40.0, 40.0, 80.0, 80.0, 0.0, 120.0, 0.0, 0.0, 17.954814682402642, 59.25099361519587, 0.0, 58.3888141544343, 20.0, 0.0, 29.896797989309082, -3.4962095707103202, 0.0, 0.0, -1.0711564367795878, 20.0, -13.848324383228638, -1.8733239363314633, 79.3329048825927, -6.040028189375327, 0.0, 18.405308025937558, 40.0, 20.0, 18.72290222516385, -8.531285916634186, 0.0, 99.5444614252368, 0.0, -10.925598988789243, 35.39029164878417, -1.589908433006455, 0.0, -8.4099657367669, -0.0989806150458572, -5.906764653335893, 0.0, 20.0, -0.4661033515609414, 20.0, 0.0, 19.918164314793724, 20.0, -11.105942402996087, 0.0, 0.0, -6.55454738814145, -6.22197196517025, 39.98449660653824, 38.127319834840165, 60.0, 96.47569656739724, 60.0, 0.0, 0.0, 0.0, 0.0, 40.0, 0.0, -8.038329060440159, 14.859118962650694, 11.552309978614199, 3.4187691838914334, 0.0, 4.0211582416983624, 20.0, 0.0, 100.0, 0.0, -5.795387240190804, 0.0, 0.0, 0.0, -0.002655152501561675, 55.83277059647313, 15.863128528431368, 100.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0], "policy_agent_policy_reward": [-2.4111124943468263, 0.0, -3.4691890301394626, -5.412891540231704, -29.645995720438037, 0.0, -8.19288481282269, 0.0, 0.0, 0.0, -20.0, -10.081124720944924, -10.981236394922893, 0.0, -0.7408217096745262, 0.0, 0.0, -0.16530614243776554, 0.0, 0.0, -17.068331064870698, -10.031316355941103, 0.0, -1.9414677974343486, -10.0, 0.0, 0.0, 0.0, -30.0, -32.29794259919027, -3.3843919395511017, -10.071322485522895, -10.0, 0.0, -7.214316170928963, 0.0, -3.4184705695169764, -10.0, -10.099129712872653, -1.395315416626054, -0.3360227763800039, -20.0, -30.0, -20.0, -1.743852099447707, -60.0, -10.305830159258015, 0.0, 0.0, 0.0, -23.18869162885007, -2.00648342534399, -2.1845968021074045, 0.0, 0.0, 0.0, -10.0, 0.0, -40.0, -10.0, -2.0088533302079723, -40.02561055017021, 0.0, -3.474645285881016, -25.383535215160077, -6.941695385172581, 0.0, -10.234963333831828, -0.5800241438662967, -0.3009460076092041, -20.0, -10.0, -1.0239929850730267, -40.0, -25.538884669982693, -13.842677740041182, -30.0, -16.907745817720294, -0.10058124278041203, -30.645737667654018, -29.523738713547658, -20.0, -20.0, -40.0, -40.0, 0.0, -60.0, 0.0, 0.0, -12.045185317597362, -30.749006384804137, 0.0, -31.6111858455657, -10.0, 0.0, -30.103202010690918, -3.4962095707103202, 0.0, 0.0, -1.0711564367795878, -10.0, -13.848324383228638, -1.8733239363314633, -40.6670951174073, -6.040028189375327, 0.0, -11.594691974062442, -20.0, -10.0, -11.277097774836149, -8.531285916634186, 0.0, -50.455538574763196, 0.0, -10.925598988789243, -24.60970835121583, -1.589908433006455, 0.0, -8.4099657367669, -0.0989806150458572, -5.906764653335893, 0.0, -10.0, -0.4661033515609414, -10.0, 0.0, -10.081835685206276, -10.0, -11.105942402996087, 0.0, 0.0, -6.55454738814145, -6.22197196517025, -20.015503393461763, -21.87268016515983, -30.0, -53.524303432602764, -30.0, 0.0, 0.0, 0.0, 0.0, -20.0, 0.0, -8.038329060440159, -15.140881037349303, -18.447690021385803, -26.58123081610857, 0.0, -25.97884175830163, -10.0, 0.0, -50.0, 0.0, -5.795387240190804, 0.0, 0.0, 0.0, -0.002655152501561675, -34.16722940352687, -14.13687147156863, -50.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6825822298807996, "mean_inference_ms": 1.174312696649512, "mean_action_processing_ms": 0.24559009162547402, "mean_env_wait_ms": 0.50498027701669, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004024490898038134, "StateBufferConnector_ms": 0.0030366726863531417, "ViewRequirementAgentConnector_ms": 0.08393710042223518}, "num_episodes": 162, "episode_return_max": 120.0, "episode_return_min": -29.645995720438037, "episode_return_mean": 15.633592977684449}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1600000, "num_agent_steps_trained": 1600000, "num_env_steps_sampled": 400000, "num_env_steps_trained": 400000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 355.0381437303382, "num_env_steps_trained_throughput_per_sec": 355.0381437303382, "timesteps_total": 400000, "num_env_steps_sampled_lifetime": 400000, "num_agent_steps_sampled_lifetime": 1600000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1600000, "timers": {"training_iteration_time_ms": 11916.352, "restore_workers_time_ms": 0.013, "training_step_time_ms": 11916.317, "sample_time_ms": 1180.871, "learn_time_ms": 10721.277, "learn_throughput": 373.09, "synch_weights_time_ms": 13.657}, "counters": {"num_env_steps_sampled": 400000, "num_env_steps_trained": 400000, "num_agent_steps_sampled": 1600000, "num_agent_steps_trained": 1600000}, "done": false, "training_iteration": 100, "trial_id": "86f16_00000", "date": "2024-08-08_16-36-20", "timestamp": 1723149380, "time_this_iter_s": 11.27174997329712, "time_total_s": 1407.377355337143, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad37a8b0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1407.377355337143, "iterations_since_restore": 100, "perf": {"cpu_util_percent": 28.5125, "ram_util_percent": 78.92500000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5345156430722551, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.508414691834585, "policy_loss": -0.017402666755737276, "vf_loss": 1.5251459071399471, "vf_explained_var": -1.4644142583752356e-06, "kl": 0.006714481046328945, "entropy": 0.4643764683857877, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 283410.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.4875089696298045, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.8355000389118987, "policy_loss": -0.027147130342927994, "vf_loss": 2.8609258512655895, "vf_explained_var": 0.13163998126983642, "kl": 0.00860660851822507, "entropy": 0.8907171180471778, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 96480.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 404000, "num_env_steps_trained": 404000, "num_agent_steps_sampled": 1616000, "num_agent_steps_trained": 1616000}, "env_runners": {"episode_reward_max": 119.60186800339804, "episode_reward_min": -26.452775042833476, "episode_reward_mean": 10.576555193423344, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 153, "episodes_timesteps_total": 3825, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -60.39813199660197}, "policy_reward_max": {"adversary_policy": 60.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 6.73202614379085, "agent_policy": -9.619523237949204}, "custom_metrics": {}, "hist_stats": {"episode_reward": [39.60287437561836, 0.0, -16.43287150153762, 20.0, 40.0, -3.18647839037721, 0.0, -11.198771407087422, 40.0, 0.0, 40.0, -16.164814219690008, 0.0, 31.719154177591435, -12.920395237193038, 0.0, 0.0, -0.461559311186297, 99.10130852772356, -0.5753192744049873, -0.25053067055728073, 0.0, 0.0, -0.4465878695964898, 39.58316909715425, 0.0, -0.3994125180114272, 0.0, -2.7838021267048254, -5.476789418256624, 39.92496880674188, 18.370226791004924, 20.0, 19.75500487257962, 0.0, 60.0, 20.0, -5.025931238241565, -12.884589489835873, 60.0, 37.72994576470937, 38.814334621018226, 0.0, 0.0, 0.0, 0.0, -15.248117308227172, -6.182564487837171, 40.0, 20.0, -26.452775042833476, 0.0, -3.511611022000954, -2.747733742533792, 0.0, -13.413014633937621, 0.0, 20.0, 0.0, 14.090281774986513, 40.0, 91.30975795893784, 0.0, 0.0, -0.7752696761087052, 40.0, 80.0, -7.022465576844342, 60.0, 0.0, -10.120502767835164, 0.0, -13.307353260576075, 0.0, 0.0, 0.0, 0.0, 40.0, -5.545774840093133, -1.592379203892823, -6.200175126312346, -3.625132517486594, 20.0, -1.339486537116562, 3.4813044891670044, 119.60186800339804, 0.0, 0.0, 0.0, 20.0, 0.0, 37.80596585573388, 60.0, 100.0, 0.0, 0.0, -5.642845766721467, -3.143168321098325, -3.6965826033932254, 0.0, 59.49038708061765, 40.0, 0.0, 20.0, 0.0, -15.510131268859537, -0.27000056081339263, 0.0, -4.305704706210651, 57.95754327667008, 20.0, 0.0, 0.0, 0.0, -4.3975808175167455, 94.78904486350287, 0.0, 17.882211729542252, -8.230365906584478, -10.37950141997986, -0.06378045540124666, 0.0, 0.0, -0.292440528970066, 20.0, 0.0, 0.0, -4.23088880189281, 57.190340844735296, -13.228625203249726, -3.7915628052535695, 40.0, 0.0, 20.0, 0.0, 0.0, 0.0, -3.99031267028717, -8.958417900558413, 20.0, -11.515188601928548, 0.0, -18.968393464129367, -19.064211712822026, -13.236539802894235, 20.0, -1.00376356982539, -0.7745330129546457, 20.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-20.397125624381637, 0.0, -16.43287150153762, -10.0, -20.0, -3.18647839037721, 0.0, -11.198771407087422, -20.0, 0.0, -20.0, -16.164814219690008, 0.0, -28.280845822408573, -12.920395237193038, 0.0, 0.0, -0.461559311186297, -50.89869147227644, -0.5753192744049873, -0.25053067055728073, 0.0, 0.0, -0.4465878695964898, -20.416830902845753, 0.0, -0.3994125180114272, 0.0, -2.7838021267048254, -5.476789418256624, -20.07503119325812, -11.629773208995077, -10.0, -10.244995127420381, 0.0, -30.0, -10.0, -5.025931238241565, -12.884589489835873, -30.0, -22.27005423529063, -21.185665378981774, 0.0, 0.0, 0.0, 0.0, -15.248117308227172, -6.182564487837171, -20.0, -10.0, -26.452775042833476, 0.0, -3.511611022000954, -2.747733742533792, 0.0, -13.413014633937621, 0.0, -10.0, 0.0, -15.909718225013487, -20.0, -58.69024204106216, 0.0, 0.0, -0.7752696761087052, -20.0, -40.0, -7.022465576844342, -30.0, 0.0, -10.120502767835164, 0.0, -13.307353260576075, 0.0, 0.0, 0.0, 0.0, -20.0, -5.545774840093133, -1.592379203892823, -6.200175126312346, -3.625132517486594, -10.0, -1.339486537116562, -26.518695510833, -60.39813199660197, 0.0, 0.0, 0.0, -10.0, 0.0, -22.19403414426612, -30.0, -50.0, 0.0, 0.0, -5.642845766721467, -3.143168321098325, -3.6965826033932254, 0.0, -30.50961291938235, -20.0, 0.0, -10.0, 0.0, -15.510131268859537, -0.27000056081339263, 0.0, -4.305704706210651, -32.04245672332992, -10.0, 0.0, 0.0, 0.0, -34.39758081751675, -55.210955136497134, 0.0, -12.117788270457748, -8.230365906584478, -10.37950141997986, -0.06378045540124666, 0.0, 0.0, -0.292440528970066, -10.0, 0.0, 0.0, -4.23088880189281, -32.809659155264704, -13.228625203249726, -3.7915628052535695, -20.0, 0.0, -10.0, 0.0, 0.0, 0.0, -3.99031267028717, -8.958417900558413, -10.0, -11.515188601928548, 0.0, -18.968393464129367, -19.064211712822026, -13.236539802894235, -10.0, -1.00376356982539, -0.7745330129546457, -10.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6815473235703796, "mean_inference_ms": 1.1727462877257713, "mean_action_processing_ms": 0.2452166804980014, "mean_env_wait_ms": 0.5044305283626338, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004069244160371668, "StateBufferConnector_ms": 0.0032626725489797157, "ViewRequirementAgentConnector_ms": 0.08517059625363817}, "num_episodes": 153, "episode_return_max": 119.60186800339804, "episode_return_min": -26.452775042833476, "episode_return_mean": 10.576555193423344}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1616000, "num_agent_steps_trained": 1616000, "num_env_steps_sampled": 404000, "num_env_steps_trained": 404000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 343.98953130538155, "num_env_steps_trained_throughput_per_sec": 343.98953130538155, "timesteps_total": 404000, "num_env_steps_sampled_lifetime": 404000, "num_agent_steps_sampled_lifetime": 1616000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1616000, "timers": {"training_iteration_time_ms": 11855.668, "restore_workers_time_ms": 0.013, "training_step_time_ms": 11855.633, "sample_time_ms": 1134.864, "learn_time_ms": 10706.572, "learn_throughput": 373.602, "synch_weights_time_ms": 13.682}, "counters": {"num_env_steps_sampled": 404000, "num_env_steps_trained": 404000, "num_agent_steps_sampled": 1616000, "num_agent_steps_trained": 1616000}, "done": false, "training_iteration": 101, "trial_id": "86f16_00000", "date": "2024-08-08_16-36-32", "timestamp": 1723149392, "time_this_iter_s": 11.633127927780151, "time_total_s": 1419.010483264923, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad37aca0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1419.010483264923, "iterations_since_restore": 101, "perf": {"cpu_util_percent": 28.905882352941177, "ram_util_percent": 78.97058823529412}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5150164725140054, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.4809878068190094, "policy_loss": -0.017151997231627344, "vf_loss": 1.4974512410713425, "vf_explained_var": 3.061396010378574e-07, "kl": 0.006885617586598229, "entropy": 0.4454599505832009, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 286230.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.2996785935635367, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.5997522601857783, "policy_loss": -0.02432135033668601, "vf_loss": 2.622122324878971, "vf_explained_var": 0.11237359096606572, "kl": 0.009756414502246477, "entropy": 0.8853978367522359, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 97440.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 408000, "num_env_steps_trained": 408000, "num_agent_steps_sampled": 1632000, "num_agent_steps_trained": 1632000}, "env_runners": {"episode_reward_max": 100.0, "episode_reward_min": -32.09848383427034, "episode_reward_mean": 11.42365300660377, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -50.0}, "policy_reward_max": {"adversary_policy": 50.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 6.851851851851852, "agent_policy": -9.131902548951786}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-7.323578252334153, 0.0, 0.0, 20.0, 0.0, 40.0, 40.0, 40.0, 0.0, 20.0, -10.162070783470831, 20.0, -0.9686957043895283, 0.0, 0.0, 0.0, -1.2567622773868647, -21.421224902565594, 0.0, -17.88052138497702, 60.0, 0.0, -17.280858518466435, 35.237465859976744, 34.94412135792257, -2.0518229938854384, -0.14234018927293035, 20.0, 59.81430853064818, 40.0, 79.30653956678505, 0.0, -0.12071559370015472, -12.392905692498864, -15.576140689089408, 0.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 0.0, 0.0, 0.0, -6.794754826979892, 0.0, 100.0, -11.435511791243764, 53.884859524727275, 0.0, 0.0, 0.0, -5.140990264696144, 40.0, 0.0, 19.59716758730422, 48.310195896030116, 38.03639651386426, 0.0, -9.006261594122563, -19.36175427611281, 20.0, -0.8851821713150498, 0.0, -1.4548988664217177, 0.0, 0.0, 40.0, -6.7880293428029645, 0.0, 0.0, 0.0, -5.833079261758703, 0.0, 0.0, 80.0, 0.0, 0.0, 19.981606077673995, 0.0, 0.0, 79.28353069062564, -7.13423473544476, -32.09848383427034, -15.067128489301142, 77.66369833465913, -19.556357622697806, 40.0, -0.3352913618724951, 60.0, 0.0, 35.84851404663068, -1.2758439931421395, 39.616641025662446, -2.948334200573116, -3.0877462023375974, -0.2748523521171209, 0.0, -1.8351320081235611, 0.0, 80.0, 20.0, -0.02366344040270585, 0.0, 19.034353065317728, 0.0, 19.686068205541115, 20.0, -6.890933513569975, 18.41277231533614, 0.0, 0.0, 0.0, 0.0, 20.0, 0.0, 0.0, 0.0, 60.0, -1.2985432067317038, 21.34003271627184, 0.0, 0.0, 0.0, 33.77386611741766, 20.0, 0.0, 0.0, 0.0, 40.0, 0.0, 18.251236561331012, -0.9633896709088874, 59.94945324969707, 0.0, 40.0, 60.0, 0.0, -4.105152965803278, 0.0, 0.0, -3.2943997160483036, 0.0, 29.37890095183002, 0.0, -12.831310158886671, -1.6704955060089588, 60.0, 0.0, 0.0, 0.0, 20.0, 0.0, 0.0, 0.0, 0.0, -0.31477862082278985, 80.0, -1.77057118296163, 19.334801034073607], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0], "policy_agent_policy_reward": [-7.323578252334153, 0.0, 0.0, -10.0, 0.0, -20.0, -20.0, -20.0, 0.0, -10.0, -10.162070783470831, -10.0, -0.9686957043895283, 0.0, 0.0, 0.0, -1.2567622773868647, -21.421224902565594, 0.0, -17.88052138497702, -30.0, 0.0, -17.280858518466435, -24.762534140023256, -25.055878642077428, -2.0518229938854384, -0.14234018927293035, -10.0, -30.185691469351827, -20.0, -40.69346043321495, 0.0, -0.12071559370015472, -12.392905692498864, -15.576140689089408, 0.0, -30.0, 0.0, 0.0, 0.0, 0.0, 0.0, -10.0, 0.0, 0.0, 0.0, -6.794754826979892, 0.0, -50.0, -11.435511791243764, -36.115140475272725, 0.0, 0.0, 0.0, -5.140990264696144, -20.0, 0.0, -10.402832412695782, -41.689804103969884, -21.963603486135746, 0.0, -9.006261594122563, -19.36175427611281, -10.0, -0.8851821713150498, 0.0, -1.4548988664217177, 0.0, 0.0, -20.0, -6.7880293428029645, 0.0, 0.0, 0.0, -5.833079261758703, 0.0, 0.0, -40.0, 0.0, 0.0, -10.018393922326007, 0.0, 0.0, -40.71646930937437, -7.13423473544476, -32.09848383427034, -15.067128489301142, -42.33630166534086, -19.556357622697806, -20.0, -0.3352913618724951, -30.0, 0.0, -24.151485953369317, -1.2758439931421395, -20.383358974337554, -2.948334200573116, -3.0877462023375974, -0.2748523521171209, 0.0, -1.8351320081235611, 0.0, -40.0, -10.0, -0.02366344040270585, 0.0, -10.965646934682272, 0.0, -10.313931794458885, -10.0, -6.890933513569975, -11.58722768466386, 0.0, 0.0, 0.0, 0.0, -10.0, 0.0, 0.0, 0.0, -30.0, -1.2985432067317038, -38.65996728372815, 0.0, 0.0, 0.0, -26.226133882582342, -10.0, 0.0, 0.0, 0.0, -20.0, 0.0, -11.748763438668988, -0.9633896709088874, -30.050546750302928, 0.0, -20.0, -30.0, 0.0, -4.105152965803278, 0.0, 0.0, -3.2943997160483036, 0.0, -30.62109904816998, 0.0, -12.831310158886671, -1.6704955060089588, -30.0, 0.0, 0.0, 0.0, -10.0, 0.0, 0.0, 0.0, 0.0, -0.31477862082278985, -40.0, -1.77057118296163, -10.665198965926395]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.680605709021593, "mean_inference_ms": 1.1709210384477529, "mean_action_processing_ms": 0.24480515235322944, "mean_env_wait_ms": 0.5037907701292077, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004029421158778815, "StateBufferConnector_ms": 0.003006281676115813, "ViewRequirementAgentConnector_ms": 0.0822655948591821}, "num_episodes": 162, "episode_return_max": 100.0, "episode_return_min": -32.09848383427034, "episode_return_mean": 11.42365300660377}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1632000, "num_agent_steps_trained": 1632000, "num_env_steps_sampled": 408000, "num_env_steps_trained": 408000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 353.75949547464836, "num_env_steps_trained_throughput_per_sec": 353.75949547464836, "timesteps_total": 408000, "num_env_steps_sampled_lifetime": 408000, "num_agent_steps_sampled_lifetime": 1632000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1632000, "timers": {"training_iteration_time_ms": 11820.706, "restore_workers_time_ms": 0.013, "training_step_time_ms": 11820.672, "sample_time_ms": 1136.458, "learn_time_ms": 10671.389, "learn_throughput": 374.834, "synch_weights_time_ms": 12.411}, "counters": {"num_env_steps_sampled": 408000, "num_env_steps_trained": 408000, "num_agent_steps_sampled": 1632000, "num_agent_steps_trained": 1632000}, "done": false, "training_iteration": 102, "trial_id": "86f16_00000", "date": "2024-08-08_16-36-43", "timestamp": 1723149403, "time_this_iter_s": 11.313919067382812, "time_total_s": 1430.324402332306, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad28fca0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1430.324402332306, "iterations_since_restore": 102, "perf": {"cpu_util_percent": 28.0, "ram_util_percent": 78.59375}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5306163238348267, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.395347690032729, "policy_loss": -0.01818901551441547, "vf_loss": 1.41287123229064, "vf_explained_var": 6.117507921043018e-07, "kl": 0.006654725303699105, "entropy": 0.439118085410578, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 289050.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.389682982675731, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.597201511077583, "policy_loss": -0.028393733159100522, "vf_loss": 2.6239191379398106, "vf_explained_var": 0.10045996153106292, "kl": 0.008380564483811477, "entropy": 0.9033222276717424, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 98400.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 412000, "num_env_steps_trained": 412000, "num_agent_steps_sampled": 1648000, "num_agent_steps_trained": 1648000}, "env_runners": {"episode_reward_max": 120.0, "episode_reward_min": -38.18836283472324, "episode_reward_mean": 11.47912112363418, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -102.74477926001944}, "policy_reward_max": {"adversary_policy": 60.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 7.283950617283951, "agent_policy": -10.372730728217674}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, -3.8241181514791833, -28.155148934335564, -0.8374185776761744, 0.0, 60.0, -1.3180556209962824, 0.0, 0.0, 0.0, -24.219103363278805, 120.0, 58.05560736827536, 17.78946531559128, -0.062456873869726204, 100.0, 0.0, 0.0, 20.0, 0.0, 0.0, 0.0, -1.2667599465149881, 0.0, 0.0, 0.0, 0.0, -8.377309521018942, -3.3490685515542062, -0.25730578389044356, -4.286948076116298, 0.0, -2.4600067597576114, 40.0, 80.0, -18.576985918785187, -5.665562814887862, 60.0, 30.495427095841922, 20.0, 0.0, -4.014910711697321, -2.4919122245880203, 0.0, 47.25522073998057, 0.0, 0.0, 60.0, -0.09766102684142353, 0.0, 0.0, 19.776886417024382, 0.0, -5.222803376418064, 11.5576350682025, -5.229320286694544, -3.066287444380256, 20.0, 0.0, 40.0, -3.0738550654286882, 0.0, 0.0, 64.37900822315298, 0.0, 0.0, -18.86279531543006, 19.69925715822592, 0.0, -2.254825174808153, 0.0, 40.0, 42.18392747958053, 33.713943930186765, 0.0, -0.4004331915732062, 0.0, 100.0, 0.0, 0.0, -6.870849045429488, 0.0, 89.81802359843317, -13.895825305712604, -13.508035847665095, 100.0, 20.0, -0.028814304468033347, -0.9409818899375355, 0.0, 0.0, -10.891871040036385, 0.0, 40.0, -0.16955470584313237, -2.5112432439396493, 100.0, -38.18836283472324, 0.0, 0.0, 0.0, -8.071880711918274, -0.7230728922258023, 58.841178754935584, -9.148313741073023, 0.0, 0.0, 0.0, 0.0, -3.3409453110707226, 18.842270148390124, 0.0, 0.0, 0.0, 60.0, -2.176071617236948, 19.72551899478739, 0.0, 40.0, 0.0, -2.5826852826303, 0.0, 40.0, 0.0, -0.07704882791051526, 0.0, 54.416325751391895, -4.852873936199043, -11.044607994971761, 0.0, 0.0, 0.0, 60.0, 0.0, 60.0, 0.0, 20.0, -13.424162971002374, -23.017755811034153, 20.0, 0.0, 39.71031090334794, -8.850349329057005, 80.0, 31.39670177181656, 0.0, 0.0, 20.0, -0.8713504965659202, 0.0, 0.0, 35.050871172334475, 38.419988125291496, -3.008775784957807, 0.0, -1.8199559098319484, 0.0, 40.0, 0.0, 0.0, -4.123504440592075, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 60.0, 60.0, 60.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [0.0, -3.8241181514791833, -28.155148934335564, -0.8374185776761744, 0.0, -30.0, -1.3180556209962824, 0.0, 0.0, 0.0, -54.21910336327881, -60.0, -31.94439263172464, -12.210534684408717, -0.062456873869726204, -50.0, 0.0, 0.0, -10.0, 0.0, 0.0, 0.0, -1.2667599465149881, 0.0, 0.0, 0.0, 0.0, -8.377309521018942, -3.3490685515542062, -0.25730578389044356, -4.286948076116298, 0.0, -2.4600067597576114, -20.0, -40.0, -18.576985918785187, -5.665562814887862, -30.0, -29.504572904158078, -10.0, 0.0, -4.014910711697321, -2.4919122245880203, 0.0, -102.74477926001944, 0.0, 0.0, -30.0, -0.09766102684142353, 0.0, 0.0, -10.223113582975618, 0.0, -5.222803376418064, -18.4423649317975, -5.229320286694544, -3.066287444380256, -10.0, 0.0, -20.0, -3.0738550654286882, 0.0, 0.0, -55.620991776847035, 0.0, 0.0, -18.86279531543006, -10.300742841774083, 0.0, -2.254825174808153, 0.0, -20.0, -47.81607252041947, -26.286056069813228, 0.0, -0.4004331915732062, 0.0, -50.0, 0.0, 0.0, -6.870849045429488, 0.0, -60.18197640156683, -13.895825305712604, -13.508035847665095, -50.0, -10.0, -0.028814304468033347, -0.9409818899375355, 0.0, 0.0, -10.891871040036385, 0.0, -20.0, -0.16955470584313237, -2.5112432439396493, -50.0, -38.18836283472324, 0.0, 0.0, 0.0, -8.071880711918274, -0.7230728922258023, -31.158821245064416, -9.148313741073023, 0.0, 0.0, 0.0, 0.0, -3.3409453110707226, -11.157729851609876, 0.0, 0.0, 0.0, -30.0, -2.176071617236948, -10.27448100521261, 0.0, -20.0, 0.0, -2.5826852826303, 0.0, -20.0, 0.0, -0.07704882791051526, 0.0, -35.583674248608105, -4.852873936199043, -11.044607994971761, 0.0, 0.0, 0.0, -30.0, 0.0, -30.0, 0.0, -10.0, -13.424162971002374, -23.017755811034153, -10.0, 0.0, -20.28968909665206, -8.850349329057005, -40.0, -28.603298228183448, 0.0, 0.0, -10.0, -0.8713504965659202, 0.0, 0.0, -24.94912882766553, -21.580011874708507, -3.008775784957807, 0.0, -1.8199559098319484, 0.0, -20.0, 0.0, 0.0, -4.123504440592075, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6796029428561875, "mean_inference_ms": 1.169257682962086, "mean_action_processing_ms": 0.2444232831125646, "mean_env_wait_ms": 0.5032395555854537, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004179536560435354, "StateBufferConnector_ms": 0.0029488110247953437, "ViewRequirementAgentConnector_ms": 0.08199560789414394}, "num_episodes": 162, "episode_return_max": 120.0, "episode_return_min": -38.18836283472324, "episode_return_mean": 11.47912112363418}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1648000, "num_agent_steps_trained": 1648000, "num_env_steps_sampled": 412000, "num_env_steps_trained": 412000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 353.24580647861774, "num_env_steps_trained_throughput_per_sec": 353.24580647861774, "timesteps_total": 412000, "num_env_steps_sampled_lifetime": 412000, "num_agent_steps_sampled_lifetime": 1648000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1648000, "timers": {"training_iteration_time_ms": 11782.643, "restore_workers_time_ms": 0.013, "training_step_time_ms": 11782.609, "sample_time_ms": 1133.499, "learn_time_ms": 10636.407, "learn_throughput": 376.067, "synch_weights_time_ms": 12.29}, "counters": {"num_env_steps_sampled": 412000, "num_env_steps_trained": 412000, "num_agent_steps_sampled": 1648000, "num_agent_steps_trained": 1648000}, "done": false, "training_iteration": 103, "trial_id": "86f16_00000", "date": "2024-08-08_16-36-55", "timestamp": 1723149415, "time_this_iter_s": 11.32900595664978, "time_total_s": 1441.6534082889557, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad3888b0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1441.6534082889557, "iterations_since_restore": 103, "perf": {"cpu_util_percent": 30.118750000000002, "ram_util_percent": 78.4375}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5342706831951514, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.3402190102118972, "policy_loss": -0.015505198207898528, "vf_loss": 1.3551547724093105, "vf_explained_var": 3.0630869222870955e-07, "kl": 0.0056943455109299814, "entropy": 0.43328514870599655, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 291870.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.3237286751468975, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.269755527873834, "policy_loss": -0.024299568146428405, "vf_loss": 2.29236436933279, "vf_explained_var": 0.12672694524129233, "kl": 0.008453677040485373, "entropy": 0.9082058435305953, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 99360.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 416000, "num_env_steps_trained": 416000, "num_agent_steps_sampled": 1664000, "num_agent_steps_trained": 1664000}, "env_runners": {"episode_reward_max": 160.0, "episode_reward_min": -33.84837799292993, "episode_reward_mean": 9.645934606220921, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -80.0}, "policy_reward_max": {"adversary_policy": 80.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 5.802469135802469, "agent_policy": -7.761472801186486}, "custom_metrics": {}, "hist_stats": {"episode_reward": [160.0, 0.0, -0.6014357793634928, -0.2592257161186129, 0.0, -1.0199476020628506, -1.8627617014841236, -2.1326881820629207, -4.04638685571444, 0.0, 0.0, 0.0, 40.0, -1.0932235981091032, -6.64107789879948, -0.9705783630513487, 0.0, -24.045880980923158, 40.0, 0.0, 0.0, 0.0, 0.0, 60.0, 0.0, 0.0, 60.0, 20.0, -0.024372425126609754, 0.0, 0.0, -7.97634430026627, 0.0, 0.0, 17.312239671672536, 6.331258663074656, 33.37217262039725, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 0.0, 39.10388725015956, -5.56281127070128, 0.0, 40.0, 0.0, -27.90714037796887, 0.0, 0.0, -0.25748560257549347, -14.189965596758114, 0.0, 0.0, -0.8300922097822405, -0.17578542860140156, 20.0, 20.0, -0.24081191100255306, 33.70574413374339, 20.0, 0.0, 0.0, 0.0, 37.98993884375149, 40.0, 0.0, -2.4905313991370135, -0.1764350589245589, -2.9704686545734162, -1.2110978993184018, 0.0, 140.0, 0.0, 0.0, 60.0, 0.0, 20.0, 40.0, -2.868508809564551, 0.0, 0.0, 0.0, 0.0, 16.894234178491566, 0.0, 20.0, 0.0, 0.0, -3.391373462524503, 0.0, -17.919424953166377, 0.0, 0.0, 0.0, -1.586469152588309, 18.17956180351991, 0.0, -4.467763631811379, -14.437041509065942, 0.0, -13.478093814308872, 0.0, 0.0, 60.0, 0.0, 20.0, 0.0, -0.3852674730066574, 0.0, 20.0, 0.0, 0.0, 0.0, 0.0, 39.35224894999213, 20.0, -0.8947655051914505, 0.0, 0.0, 20.0, 71.03360541643251, 0.0, 0.0, 0.0, 0.0, 20.0, 0.0, 0.0, 39.65813703533361, 40.0, 0.0, 0.0, -0.01526163250438306, 0.0, -4.008680500695045, 19.04977456802011, 40.0, 0.0, 6.314610201439636, 60.0, 20.0, 20.0, -6.872330325395387, 40.0, 20.0, 0.0, -0.7122778407449548, -1.7489791415391553, 40.0, 0.0, -23.374510858725827, 20.0, 0.0, 91.51422690994788, 32.62167523407545, -3.0962338560739777, -33.84837799292993, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [80.0, 80.0, 80.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-80.0, 0.0, -0.6014357793634928, -0.2592257161186129, 0.0, -1.0199476020628506, -1.8627617014841236, -2.1326881820629207, -4.04638685571444, 0.0, 0.0, 0.0, -20.0, -1.0932235981091032, -6.64107789879948, -0.9705783630513487, 0.0, -24.045880980923158, -20.0, 0.0, 0.0, 0.0, 0.0, -30.0, 0.0, 0.0, -30.0, -10.0, -0.024372425126609754, 0.0, 0.0, -7.97634430026627, 0.0, 0.0, -12.687760328327464, -23.66874133692534, -26.627827379602756, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -20.0, 0.0, -20.89611274984044, -5.56281127070128, 0.0, -20.0, 0.0, -27.90714037796887, 0.0, 0.0, -0.25748560257549347, -14.189965596758114, 0.0, 0.0, -0.8300922097822405, -0.17578542860140156, -10.0, -10.0, -0.24081191100255306, -26.294255866256613, -10.0, 0.0, 0.0, 0.0, -22.010061156248508, -20.0, 0.0, -2.4905313991370135, -0.1764350589245589, -2.9704686545734162, -1.2110978993184018, 0.0, -70.0, 0.0, 0.0, -30.0, 0.0, -10.0, -20.0, -2.868508809564551, 0.0, 0.0, 0.0, 0.0, -13.105765821508431, 0.0, -10.0, 0.0, 0.0, -3.391373462524503, 0.0, -17.919424953166377, 0.0, 0.0, 0.0, -1.586469152588309, -11.820438196480087, 0.0, -4.467763631811379, -14.437041509065942, 0.0, -13.478093814308872, 0.0, 0.0, -30.0, 0.0, -10.0, 0.0, -0.3852674730066574, 0.0, -10.0, 0.0, 0.0, 0.0, 0.0, -20.64775105000787, -10.0, -0.8947655051914505, 0.0, 0.0, -10.0, -48.96639458356749, 0.0, 0.0, 0.0, 0.0, -10.0, 0.0, 0.0, -20.34186296466639, -20.0, 0.0, 0.0, -0.01526163250438306, 0.0, -4.008680500695045, -10.950225431979892, -20.0, 0.0, -23.685389798560376, -30.0, -10.0, -10.0, -6.872330325395387, -20.0, -10.0, 0.0, -0.7122778407449548, -1.7489791415391553, -20.0, 0.0, -23.374510858725827, -10.0, 0.0, -58.48577309005211, -27.37832476592457, -3.0962338560739777, -33.84837799292993, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6787579043768931, "mean_inference_ms": 1.167727123628102, "mean_action_processing_ms": 0.24408412297885174, "mean_env_wait_ms": 0.5026707008496452, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00401897194944782, "StateBufferConnector_ms": 0.0030487407872706283, "ViewRequirementAgentConnector_ms": 0.08645903917006505}, "num_episodes": 162, "episode_return_max": 160.0, "episode_return_min": -33.84837799292993, "episode_return_mean": 9.645934606220921}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1664000, "num_agent_steps_trained": 1664000, "num_env_steps_sampled": 416000, "num_env_steps_trained": 416000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 345.3853289151261, "num_env_steps_trained_throughput_per_sec": 345.3853289151261, "timesteps_total": 416000, "num_env_steps_sampled_lifetime": 416000, "num_agent_steps_sampled_lifetime": 1664000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1664000, "timers": {"training_iteration_time_ms": 11741.543, "restore_workers_time_ms": 0.013, "training_step_time_ms": 11741.509, "sample_time_ms": 1129.981, "learn_time_ms": 10599.13, "learn_throughput": 377.389, "synch_weights_time_ms": 11.984}, "counters": {"num_env_steps_sampled": 416000, "num_env_steps_trained": 416000, "num_agent_steps_sampled": 1664000, "num_agent_steps_trained": 1664000}, "done": false, "training_iteration": 104, "trial_id": "86f16_00000", "date": "2024-08-08_16-37-06", "timestamp": 1723149426, "time_this_iter_s": 11.587854862213135, "time_total_s": 1453.2412631511688, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad388af0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1453.2412631511688, "iterations_since_restore": 104, "perf": {"cpu_util_percent": 30.058823529411764, "ram_util_percent": 78.6470588235294}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5243672761934023, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.788183533447854, "policy_loss": -0.015169239773560342, "vf_loss": 1.8027666961893123, "vf_explained_var": -2.6420498570651874e-09, "kl": 0.005860767282052855, "entropy": 0.41569573098252005, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 294690.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.271914108966788, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.509174964266519, "policy_loss": -0.02544522240253476, "vf_loss": 2.5328529263536135, "vf_explained_var": 0.055119407425324125, "kl": 0.008836352249671919, "entropy": 0.9158169728393356, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 100320.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 420000, "num_env_steps_trained": 420000, "num_agent_steps_sampled": 1680000, "num_agent_steps_trained": 1680000}, "env_runners": {"episode_reward_max": 199.86433649666344, "episode_reward_min": -30.469753606341115, "episode_reward_mean": 14.77312302272448, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 157, "episodes_timesteps_total": 3925, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -100.13566350333657}, "policy_reward_max": {"adversary_policy": 100.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 8.40764331210191, "agent_policy": -10.449806913581252}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.7450254902115405, 40.0, -0.6360372109298129, 60.0, 51.97631986738118, 0.0, -0.8620544105690497, 0.0, 0.0, -1.8852108369847753, -4.860593752287627, 0.0, -0.30713612772402477, -2.3343322043896197, -8.127520602674702, 20.0, 93.06289829610137, 0.0, 0.0, 0.0, 20.0, 20.0, 0.0, 0.0, 40.0, -22.154586926726772, 0.0, -4.230954322146667, 58.77883758108551, -0.7465812688665696, 0.0, -0.3378021395627895, 0.0, 0.0, 29.661695755277016, 0.0, 60.0, 0.0, 0.0, 0.0, 0.0, -1.284286458105941, 20.0, -10.182241462507463, 0.0, 80.0, 0.0, 0.0, 13.890196559466908, -1.9347766838234004, 13.836482955990594, 0.0, -9.41425765890763, 0.0, -0.4859365335349686, -0.01339538446940236, 38.791218710077786, 40.0, 0.0, -3.023997328046323, 60.0, 0.0, 100.0, 0.0, 0.0, 40.0, 60.0, 80.0, -4.001346362900065, -2.1114756137944846, 20.0, 116.90468707518933, 20.0, -16.23381722410257, 0.0, 20.0, -1.3547078618588082, 40.0, 0.0, 40.0, -1.846817704597311, 0.0, 40.0, -6.033916065227967, 40.0, -4.507018423685168, -5.348879919711059, 40.0, 40.0, 60.0, -0.0062157215287617085, 0.0, 10.110247991083156, 0.0, 0.0, 0.0, 20.0, 45.417734862371674, -3.4561590414093457, 0.0, 0.0, 0.0, 0.0, 0.0, -8.70626958933383, 40.0, -13.224703590273629, 0.0, -4.3520122484689825, 199.86433649666344, 40.0, -3.165135518430162, -1.7656135527867856, 40.0, 0.0, 60.0, 39.8882481131506, 60.0, -9.456385277618033, -1.7659673755950456, -0.12735374745955874, -4.534704517158965, 0.0, 25.141083454783587, -1.2279420223139281, 0.0, 0.0, -9.498163036601762, 0.0, -30.469753606341115, 20.0, -0.35752182110110886, 0.0, -0.357991917893139, 19.74491724248359, 0.0, 0.0, -0.7606266992597144, 0.0, -5.858778374215298, 40.0, 0.0, 60.0, -1.253775298099603, 60.0, 0.0, -0.33149415801512316, 59.62964209526662, 19.81201778857882, 0.0, -0.3480888414526351, 20.0, -0.6276616619285524, -0.47322668157627756, 80.0, 0.0, 60.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 60.0, 60.0, 60.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 100.0, 100.0, 100.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0], "policy_agent_policy_reward": [-0.7450254902115405, -20.0, -0.6360372109298129, -30.0, -38.02368013261882, 0.0, -0.8620544105690497, 0.0, 0.0, -1.8852108369847753, -4.860593752287627, 0.0, -0.30713612772402477, -2.3343322043896197, -8.127520602674702, -10.0, -56.93710170389865, 0.0, 0.0, 0.0, -10.0, -10.0, 0.0, 0.0, -20.0, -22.154586926726772, 0.0, -4.230954322146667, -31.22116241891448, -0.7465812688665696, 0.0, -0.3378021395627895, 0.0, 0.0, -30.338304244722984, 0.0, -30.0, 0.0, 0.0, 0.0, 0.0, -1.284286458105941, -10.0, -10.182241462507463, 0.0, -40.0, 0.0, 0.0, -16.109803440533092, -1.9347766838234004, -16.163517044009403, 0.0, -9.41425765890763, 0.0, -0.4859365335349686, -0.01339538446940236, -21.208781289922218, -20.0, 0.0, -3.023997328046323, -30.0, 0.0, -50.0, 0.0, 0.0, -20.0, -30.0, -40.0, -4.001346362900065, -32.11147561379448, -10.0, -63.09531292481069, -10.0, -16.23381722410257, 0.0, -10.0, -1.3547078618588082, -20.0, 0.0, -20.0, -1.846817704597311, 0.0, -20.0, -6.033916065227967, -20.0, -4.507018423685168, -5.348879919711059, -20.0, -20.0, -30.0, -0.0062157215287617085, 0.0, -19.889752008916844, 0.0, 0.0, 0.0, -10.0, -44.582265137628326, -3.4561590414093457, 0.0, 0.0, 0.0, 0.0, 0.0, -8.70626958933383, -20.0, -13.224703590273629, 0.0, -4.3520122484689825, -100.13566350333657, -20.0, -3.165135518430162, -1.7656135527867856, -20.0, 0.0, -30.0, -20.111751886849394, -30.0, -9.456385277618033, -1.7659673755950456, -0.12735374745955874, -4.534704517158965, 0.0, -34.8589165452164, -1.2279420223139281, 0.0, 0.0, -9.498163036601762, 0.0, -30.469753606341115, -10.0, -0.35752182110110886, 0.0, -0.357991917893139, -10.255082757516409, 0.0, 0.0, -0.7606266992597144, 0.0, -5.858778374215298, -20.0, 0.0, -30.0, -1.253775298099603, -30.0, 0.0, -0.33149415801512316, -30.370357904733382, -10.187982211421179, 0.0, -0.3480888414526351, -10.0, -0.6276616619285524, -0.47322668157627756, -40.0, 0.0, -30.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6785007447586736, "mean_inference_ms": 1.1674925253474466, "mean_action_processing_ms": 0.24399704225521845, "mean_env_wait_ms": 0.5026336145851446, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004370652945937624, "StateBufferConnector_ms": 0.0034276846867458076, "ViewRequirementAgentConnector_ms": 0.09452059010791171}, "num_episodes": 157, "episode_return_max": 199.86433649666344, "episode_return_min": -30.469753606341115, "episode_return_mean": 14.77312302272448}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1680000, "num_agent_steps_trained": 1680000, "num_env_steps_sampled": 420000, "num_env_steps_trained": 420000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 215.01510462624347, "num_env_steps_trained_throughput_per_sec": 215.01510462624347, "timesteps_total": 420000, "num_env_steps_sampled_lifetime": 420000, "num_agent_steps_sampled_lifetime": 1680000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1680000, "timers": {"training_iteration_time_ms": 12365.433, "restore_workers_time_ms": 0.136, "training_step_time_ms": 12365.153, "sample_time_ms": 1140.127, "learn_time_ms": 11212.061, "learn_throughput": 356.759, "synch_weights_time_ms": 12.415}, "counters": {"num_env_steps_sampled": 420000, "num_env_steps_trained": 420000, "num_agent_steps_sampled": 1680000, "num_agent_steps_trained": 1680000}, "done": false, "training_iteration": 105, "trial_id": "86f16_00000", "date": "2024-08-08_16-37-25", "timestamp": 1723149445, "time_this_iter_s": 18.638883113861084, "time_total_s": 1471.88014626503, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad45d160>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1471.88014626503, "iterations_since_restore": 105, "perf": {"cpu_util_percent": 60.48148148148148, "ram_util_percent": 81.05185185185185}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5576993005284181, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.5757857237935913, "policy_loss": -0.01761647488002117, "vf_loss": 1.5927711286866073, "vf_explained_var": 1.4224796430438969e-08, "kl": 0.006310703632079169, "entropy": 0.4405066233366094, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 297510.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.4581241358071564, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.443417713791132, "policy_loss": -0.024668761382539137, "vf_loss": 2.4661241846779984, "vf_explained_var": 0.11961319881180922, "kl": 0.009811490085802808, "entropy": 0.9031785311177373, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 101280.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 424000, "num_env_steps_trained": 424000, "num_agent_steps_sampled": 1696000, "num_agent_steps_trained": 1696000}, "env_runners": {"episode_reward_max": 100.0, "episode_reward_min": -20.341183973449056, "episode_reward_mean": 11.873080562233104, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 158, "episodes_timesteps_total": 3950, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -50.0}, "policy_reward_max": {"adversary_policy": 50.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 6.962025316455696, "agent_policy": -9.012995387133984}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.27093240722927514, 0.0, 40.0, -11.119587587637163, 6.927163851554384, 20.0, 0.0, 40.0, -16.15185431380671, -1.6828427722835015, 0.0, 40.0, 60.0, 0.0, 30.041861635354188, 40.0, 0.0, 40.0, 20.0, -4.32332346527234, 20.0, 0.0, 0.0, 0.0, 20.0, 32.925543372466606, 0.0, -8.332191179982564, -1.4930962189326624, 23.520696471215803, 47.58979311422304, -20.341183973449056, -2.7883686142726463, 0.0, -0.3360836649258625, 0.0, 0.0, 0.0, 43.89484724666499, -1.8193872670467581, 0.0, 59.38151326633503, 60.0, 38.708800333497784, 19.54502068345344, 0.0, 0.0, 0.0, 0.0, 20.0, 0.0, 0.0, 0.0, 17.193317426351154, 20.0, 60.0, 0.0, -1.138188066336685, -0.09172456844791621, -2.585781007087069, 0.0, 0.0, 0.0, 59.84941611653147, 0.0, 0.0, -4.600557310795327, 0.0, -4.170976749284312, 0.0, -1.2905050663486795, 0.0, 0.0, 0.0, -1.8308766609687992, 0.0, 46.56903182593251, 0.0, -4.322003238301985, 0.0, 0.0, 0.0, 0.0, 15.46735089404801, 0.0, 0.0, 0.0, 0.0, -0.4359239258109793, -0.42837645296833093, -7.883170807770362, 0.0, -2.629890096406644, 0.0, 20.0, 0.0, 80.0, -2.2004715058145985, 20.0, 0.0, 20.0, 0.0, -6.031992675365343, -12.208299405504343, 40.0, -1.5198501290647703, 0.0, 0.0, 0.0, 0.0, 0.0, -7.902572441471366, -1.6945825629211586, -0.2935643679041, 100.0, 0.0, 18.909374104738028, -4.858415023888312, 80.0, -6.286517283788584, 0.0, 0.0, 20.0, -1.8040464686683522, 20.0, 0.0, 16.0218256888806, 80.0, 57.296431384783276, 60.0, 0.0, 60.0, -16.754051403136025, 0.0, 0.0, 55.31767627021998, 0.0, 40.0, 20.0, 80.0, 60.0, -2.36179304189855, 0.0, 0.0, 19.09311265801895, 0.0, -6.284340934853316, -0.26785054956759646, 0.0, 18.9766788425748, 0.0, 58.61349590138954, 0.0, 60.0, 0.0, 0.9327792389127108, 0.0, -0.2938282851035534], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-0.27093240722927514, 0.0, -20.0, -11.119587587637163, -23.072836148445617, -10.0, 0.0, -20.0, -16.15185431380671, -1.6828427722835015, 0.0, -20.0, -30.0, 0.0, -29.958138364645812, -20.0, 0.0, -20.0, -10.0, -4.32332346527234, -10.0, 0.0, 0.0, 0.0, -10.0, -27.074456627533397, 0.0, -8.332191179982564, -1.4930962189326624, -36.47930352878419, -42.41020688577696, -20.341183973449056, -2.7883686142726463, 0.0, -0.3360836649258625, 0.0, 0.0, 0.0, -46.10515275333501, -1.8193872670467581, 0.0, -30.618486733664977, -30.0, -21.291199666502216, -10.45497931654656, 0.0, 0.0, 0.0, 0.0, -10.0, 0.0, 0.0, 0.0, -12.806682573648846, -10.0, -30.0, 0.0, -1.138188066336685, -0.09172456844791621, -2.585781007087069, 0.0, 0.0, 0.0, -30.150583883468528, 0.0, 0.0, -4.600557310795327, 0.0, -4.170976749284312, 0.0, -1.2905050663486795, 0.0, 0.0, 0.0, -1.8308766609687992, 0.0, -43.43096817406749, 0.0, -4.322003238301985, 0.0, 0.0, 0.0, 0.0, -14.532649105951991, 0.0, 0.0, 0.0, 0.0, -0.4359239258109793, -0.42837645296833093, -7.883170807770362, 0.0, -2.629890096406644, 0.0, -10.0, 0.0, -40.0, -2.2004715058145985, -10.0, 0.0, -10.0, 0.0, -6.031992675365343, -12.208299405504343, -20.0, -1.5198501290647703, 0.0, 0.0, 0.0, 0.0, 0.0, -7.902572441471366, -1.6945825629211586, -0.2935643679041, -50.0, 0.0, -11.090625895261972, -4.858415023888312, -40.0, -36.286517283788584, 0.0, 0.0, -10.0, -1.8040464686683522, -10.0, 0.0, -13.978174311119396, -40.0, -32.703568615216724, -30.0, 0.0, -30.0, -16.754051403136025, 0.0, 0.0, -34.68232372978002, 0.0, -20.0, -10.0, -40.0, -30.0, -2.36179304189855, 0.0, 0.0, -10.906887341981054, 0.0, -6.284340934853316, -0.26785054956759646, 0.0, -11.023321157425203, 0.0, -31.386504098610466, 0.0, -30.0, 0.0, -29.067220761087288, 0.0, -0.2938282851035534]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6785062077877507, "mean_inference_ms": 1.1677484242367235, "mean_action_processing_ms": 0.24392240386341774, "mean_env_wait_ms": 0.5027632457640916, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006640561019318013, "StateBufferConnector_ms": 0.0039002563379987886, "ViewRequirementAgentConnector_ms": 0.10752572288996057}, "num_episodes": 158, "episode_return_max": 100.0, "episode_return_min": -20.341183973449056, "episode_return_mean": 11.873080562233104}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1696000, "num_agent_steps_trained": 1696000, "num_env_steps_sampled": 424000, "num_env_steps_trained": 424000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 312.8602557551644, "num_env_steps_trained_throughput_per_sec": 312.8602557551644, "timesteps_total": 424000, "num_env_steps_sampled_lifetime": 424000, "num_agent_steps_sampled_lifetime": 1696000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1696000, "timers": {"training_iteration_time_ms": 12453.09, "restore_workers_time_ms": 0.136, "training_step_time_ms": 12452.809, "sample_time_ms": 1176.236, "learn_time_ms": 11263.532, "learn_throughput": 355.128, "synch_weights_time_ms": 12.524}, "counters": {"num_env_steps_sampled": 424000, "num_env_steps_trained": 424000, "num_agent_steps_sampled": 1696000, "num_agent_steps_trained": 1696000}, "done": false, "training_iteration": 106, "trial_id": "86f16_00000", "date": "2024-08-08_16-37-38", "timestamp": 1723149458, "time_this_iter_s": 12.792284965515137, "time_total_s": 1484.672431230545, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad45d3a0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1484.672431230545, "iterations_since_restore": 106, "perf": {"cpu_util_percent": 38.42222222222222, "ram_util_percent": 77.18888888888891}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5601458647572403, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.2860038663267244, "policy_loss": -0.017208656232889925, "vf_loss": 1.30258200348269, "vf_explained_var": 2.388413070786929e-07, "kl": 0.0063052006454678055, "entropy": 0.43643986856472405, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 300330.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.1831931731353205, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.3256833410511413, "policy_loss": -0.02916274048523822, "vf_loss": 2.3531744575748843, "vf_explained_var": 0.17658354913194974, "kl": 0.008358122393448308, "entropy": 0.8907497830688953, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 102240.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 428000, "num_env_steps_trained": 428000, "num_agent_steps_sampled": 1712000, "num_agent_steps_trained": 1712000}, "env_runners": {"episode_reward_max": 100.0, "episode_reward_min": -59.10794626163698, "episode_reward_mean": 9.631146383901774, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -67.31798879353929}, "policy_reward_max": {"adversary_policy": 50.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 6.049382716049383, "agent_policy": -8.517001764246375}, "custom_metrics": {}, "hist_stats": {"episode_reward": [20.0, -23.559761750431235, 0.0, 19.093171849296812, 20.0, -2.2795285567761336, 37.471507455448375, 0.0, 0.0, 0.0, 0.0, 0.0, -6.379202241958703, 0.0, 3.2143271108790437, -2.07934912986119, 0.0, 0.0, 40.0, 0.0, 40.0, -21.028114876991, 40.0, 0.0, 0.0, 0.0, 10.401553361338355, 0.0, 0.0, 0.0, -3.3482790732526904, 0.0, 0.0, 0.0, 0.0, 0.0, 54.763369184570415, 60.0, 0.0, 0.0, 58.118504261769814, 0.0, 20.0, -12.643242713814839, 0.0, 0.0, 0.0, -1.9903722022089176, 0.0, -5.853149144579197, 0.0, 32.47072837919146, 0.0, 0.0, 40.0, -1.3061690528117242, 40.0, 0.0, 0.0, -19.095070303893905, 100.0, 39.49833462260961, -0.10087294811029657, -17.62507215823906, -7.715705068030496, 20.0, 20.0, 0.0, 40.0, 76.84920013468911, 0.0, -15.027334681376765, 19.736634399545814, 0.0, 0.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 0.0, 0.0, -5.878906342362588, 20.0, -15.356543002619226, 0.0, 40.0, 20.0, -2.722396992334036, 0.0, 0.0, 39.671901794564526, 0.0, 38.7418569587667, 0.0, 19.98425087141147, 20.0, 0.0, 40.0, 0.0, 0.0, 20.0, 0.0, 40.0, -0.8168714602925609, 0.0, 0.0, -1.147595984787897, -1.772162678818776, 0.0, 0.0, 40.0, 20.0, -59.10794626163698, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 40.0, -0.004638311818054852, -1.5976110405920396, 0.0, 80.0, -8.31497066503811, 0.0, -23.238834180034644, 0.0, 18.562450158757443, -0.28901858998199415, -6.950092550576659, 80.0, 0.0, 20.0, -12.62684609891918, 0.0, -0.24431347934456116, 40.0, 58.3572051978515, -22.97965018891127, -0.13272800872775603, 0.0, 56.178470076838224, -3.2933975456539697, -1.3712174076041816, 20.0, 20.0, 0.0, 0.0, 60.0, 0.0, -0.1327923014029675, 19.051537468471885, 0.0, 52.68201120646069, -2.3410859846340477, -4.250457321946482, 0.0, 20.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0], "policy_agent_policy_reward": [-10.0, -23.559761750431235, 0.0, -10.906828150703188, -10.0, -2.2795285567761336, -22.52849254455163, 0.0, 0.0, 0.0, 0.0, 0.0, -6.379202241958703, 0.0, -26.785672889120956, -2.07934912986119, 0.0, 0.0, -20.0, 0.0, -20.0, -21.028114876991, -20.0, 0.0, 0.0, 0.0, -19.59844663866165, 0.0, 0.0, 0.0, -3.3482790732526904, 0.0, 0.0, 0.0, 0.0, 0.0, -35.23663081542959, -30.0, 0.0, 0.0, -31.88149573823019, 0.0, -10.0, -12.643242713814839, 0.0, 0.0, 0.0, -1.9903722022089176, 0.0, -5.853149144579197, 0.0, -27.529271620808533, 0.0, 0.0, -20.0, -1.3061690528117242, -20.0, 0.0, 0.0, -19.095070303893905, -50.0, -20.50166537739039, -0.10087294811029657, -17.62507215823906, -7.715705068030496, -10.0, -10.0, 0.0, -20.0, -43.15079986531089, 0.0, -15.027334681376765, -10.263365600454183, 0.0, 0.0, -10.0, 0.0, 0.0, 0.0, 0.0, 0.0, -20.0, 0.0, 0.0, -5.878906342362588, -10.0, -15.356543002619226, 0.0, -20.0, -10.0, -2.722396992334036, 0.0, 0.0, -20.328098205435477, 0.0, -21.258143041233307, 0.0, -10.015749128588531, -10.0, 0.0, -20.0, 0.0, 0.0, -10.0, 0.0, -20.0, -0.8168714602925609, 0.0, 0.0, -1.147595984787897, -1.772162678818776, 0.0, 0.0, -20.0, -10.0, -59.10794626163698, 0.0, 0.0, 0.0, 0.0, 0.0, -10.0, -20.0, -0.004638311818054852, -1.5976110405920396, 0.0, -40.0, -8.31497066503811, 0.0, -23.238834180034644, 0.0, -11.437549841242559, -0.28901858998199415, -6.950092550576659, -40.0, 0.0, -10.0, -12.62684609891918, 0.0, -0.24431347934456116, -20.0, -31.642794802148497, -22.97965018891127, -0.13272800872775603, 0.0, -33.821529923161776, -3.2933975456539697, -1.3712174076041816, -10.0, -10.0, 0.0, 0.0, -30.0, 0.0, -0.1327923014029675, -10.948462531528115, 0.0, -67.31798879353929, -2.3410859846340477, -4.250457321946482, 0.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6779272982018069, "mean_inference_ms": 1.1666113245506284, "mean_action_processing_ms": 0.24365382968412275, "mean_env_wait_ms": 0.5023719790591854, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004015071892443998, "StateBufferConnector_ms": 0.0030758204283537686, "ViewRequirementAgentConnector_ms": 0.08641488758134253}, "num_episodes": 162, "episode_return_max": 100.0, "episode_return_min": -59.10794626163698, "episode_return_mean": 9.631146383901774}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1712000, "num_agent_steps_trained": 1712000, "num_env_steps_sampled": 428000, "num_env_steps_trained": 428000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 352.540279840295, "num_env_steps_trained_throughput_per_sec": 352.540279840295, "timesteps_total": 428000, "num_env_steps_sampled_lifetime": 428000, "num_agent_steps_sampled_lifetime": 1712000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1712000, "timers": {"training_iteration_time_ms": 12393.391, "restore_workers_time_ms": 0.136, "training_step_time_ms": 12393.11, "sample_time_ms": 1172.487, "learn_time_ms": 11207.592, "learn_throughput": 356.901, "synch_weights_time_ms": 12.515}, "counters": {"num_env_steps_sampled": 428000, "num_env_steps_trained": 428000, "num_agent_steps_sampled": 1712000, "num_agent_steps_trained": 1712000}, "done": false, "training_iteration": 107, "trial_id": "86f16_00000", "date": "2024-08-08_16-37-50", "timestamp": 1723149470, "time_this_iter_s": 11.351355075836182, "time_total_s": 1496.0237863063812, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad45d5e0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1496.0237863063812, "iterations_since_restore": 107, "perf": {"cpu_util_percent": 29.55625, "ram_util_percent": 76.66250000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.48297221778977845, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.3774629299733656, "policy_loss": -0.015686125280038314, "vf_loss": 1.3924811612841086, "vf_explained_var": -1.5429571165260694e-07, "kl": 0.006678942759152564, "entropy": 0.42342035831711816, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 303150.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.56915705713133, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.375760844287773, "policy_loss": -0.028998427287054557, "vf_loss": 2.4028304082031053, "vf_explained_var": 0.13160466930518547, "kl": 0.00964435794760724, "entropy": 0.8813366649051507, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 103200.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 432000, "num_env_steps_trained": 432000, "num_agent_steps_sampled": 1728000, "num_agent_steps_trained": 1728000}, "env_runners": {"episode_reward_max": 130.56311660626375, "episode_reward_min": -24.056353227742562, "episode_reward_mean": 9.756824147297282, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -79.43688339373627}, "policy_reward_max": {"adversary_policy": 70.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 6.049382716049383, "agent_policy": -8.391324000850863}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-9.603741767494572, 20.0, 0.0, 19.619318601954518, 0.0, -10.931747964581726, -6.839562273257065, 0.0, 0.0, 60.0, -7.449240022167631, 0.0, 59.91810707214178, 38.83356586173943, 0.0, -0.022256982308139772, 56.02637363348562, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 40.0, 40.0, -1.2023899955732176, 20.0, -0.1611461208001741, 20.0, -1.3363379219382554, -0.952152976005054, 20.0, 20.0, -4.6088073048312586, 40.0, -13.576104453400728, 60.0, -5.851173874435399, 39.60160860499575, 13.160114025128019, -8.357633797760943, 18.74057833102203, 0.0, 39.82653806119873, 0.0, 0.0, 0.0, 0.0, 79.84476892260824, -8.538921984584487, -5.727841348235521, 0.0, -3.986683043725211, -8.64884550579297, 0.0, 58.86677613760847, 0.0, -0.4524085401946931, 20.0, -16.48155090905726, 100.0, 100.0, 20.0, 0.0, -6.935889011847609, 130.56311660626375, -1.3336865962785205, 71.78369037825763, 0.0, -2.242027129163878, 0.0, -2.821013035951725, -0.3685970935755323, 0.0, 0.0, 0.0, -4.7372856313551335, -2.9443004791033403, -3.7820750257421705, -12.076030704533615, 0.0, 0.0, 0.0, -1.6494987711953801, -2.4577845423334153, 0.0, 0.0, -0.5031723787654951, 0.0, 0.0, 0.0, 40.0, 0.0, 22.77082993145054, 0.0, -0.019782187407270113, -5.322890151884465, -2.5207820113677446, 0.0, 0.0, 80.0, 0.0, 0.0, 0.0, 0.0, -0.5757314950518722, -6.172824706442494, -1.20816937847679, 16.517908316943462, 0.0, 0.0, 0.0, -2.9111690460572923, 0.0, -0.9729410146311035, 20.0, 0.0, 0.0, 20.0, -19.621454037235395, 16.406421623145178, 0.0, 0.0, -20.664662955907218, 0.0, -7.075360650972379, 20.0, 0.0, 60.0, -1.389426930126818, 17.305281747176554, 20.0, 60.0, 0.0, 99.99010163867747, -9.23822347865533, -3.235553388375095, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.6820296787412627, -13.40148125726251, -0.04298338070703678, 40.0, -4.421077145696012, -24.056353227742562, -0.0018800157204501566, 0.0, -0.6386112515849585, 0.0, 40.0, 0.0, -7.473498527694483, -1.217105990482451, 0.0, -2.2399394881853985, -1.4655589148597226, -6.02019013437904], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-9.603741767494572, -10.0, 0.0, -10.380681398045482, 0.0, -10.931747964581726, -6.839562273257065, 0.0, 0.0, -30.0, -7.449240022167631, 0.0, -30.081892927858217, -21.16643413826057, 0.0, -0.022256982308139772, -33.97362636651438, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -30.0, -20.0, -20.0, -1.2023899955732176, -10.0, -0.1611461208001741, -10.0, -1.3363379219382554, -0.952152976005054, -10.0, -10.0, -4.6088073048312586, -20.0, -13.576104453400728, -30.0, -5.851173874435399, -20.398391395004257, -16.839885974871983, -8.357633797760943, -11.25942166897797, 0.0, -20.173461938801264, 0.0, 0.0, 0.0, 0.0, -40.15523107739176, -8.538921984584487, -5.727841348235521, 0.0, -3.986683043725211, -8.64884550579297, 0.0, -31.133223862391525, 0.0, -0.4524085401946931, -10.0, -16.48155090905726, -50.0, -50.0, -10.0, 0.0, -6.935889011847609, -79.43688339373627, -1.3336865962785205, -48.21630962174236, 0.0, -2.242027129163878, 0.0, -2.821013035951725, -0.3685970935755323, 0.0, 0.0, 0.0, -4.7372856313551335, -2.9443004791033403, -3.7820750257421705, -12.076030704533615, 0.0, 0.0, 0.0, -1.6494987711953801, -2.4577845423334153, 0.0, 0.0, -0.5031723787654951, 0.0, 0.0, 0.0, -20.0, 0.0, -37.229170068549465, 0.0, -0.019782187407270113, -5.322890151884465, -2.5207820113677446, 0.0, 0.0, -40.0, 0.0, 0.0, 0.0, 0.0, -0.5757314950518722, -6.172824706442494, -1.20816937847679, -13.482091683056536, 0.0, 0.0, 0.0, -2.9111690460572923, 0.0, -0.9729410146311035, -10.0, 0.0, 0.0, -10.0, -19.621454037235395, -43.59357837685481, 0.0, 0.0, -20.664662955907218, 0.0, -7.075360650972379, -10.0, 0.0, -30.0, -1.389426930126818, -12.694718252823446, -10.0, -30.0, 0.0, -50.00989836132253, -9.23822347865533, -3.235553388375095, -20.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.6820296787412627, -13.40148125726251, -0.04298338070703678, -20.0, -4.421077145696012, -24.056353227742562, -0.0018800157204501566, 0.0, -0.6386112515849585, 0.0, -20.0, 0.0, -7.473498527694483, -1.217105990482451, 0.0, -2.2399394881853985, -1.4655589148597226, -6.02019013437904]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6771263653748608, "mean_inference_ms": 1.1651792316650347, "mean_action_processing_ms": 0.2433438723417368, "mean_env_wait_ms": 0.5018952242723352, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004128173545554832, "StateBufferConnector_ms": 0.003104518961023401, "ViewRequirementAgentConnector_ms": 0.08824092370492441}, "num_episodes": 162, "episode_return_max": 130.56311660626375, "episode_return_min": -24.056353227742562, "episode_return_mean": 9.756824147297282}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1728000, "num_agent_steps_trained": 1728000, "num_env_steps_sampled": 432000, "num_env_steps_trained": 432000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 354.7493500909381, "num_env_steps_trained_throughput_per_sec": 354.7493500909381, "timesteps_total": 432000, "num_env_steps_sampled_lifetime": 432000, "num_agent_steps_sampled_lifetime": 1728000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1728000, "timers": {"training_iteration_time_ms": 12303.89, "restore_workers_time_ms": 0.136, "training_step_time_ms": 12303.609, "sample_time_ms": 1175.067, "learn_time_ms": 11115.751, "learn_throughput": 359.85, "synch_weights_time_ms": 12.296}, "counters": {"num_env_steps_sampled": 432000, "num_env_steps_trained": 432000, "num_agent_steps_sampled": 1728000, "num_agent_steps_trained": 1728000}, "done": false, "training_iteration": 108, "trial_id": "86f16_00000", "date": "2024-08-08_16-38-01", "timestamp": 1723149481, "time_this_iter_s": 11.283406972885132, "time_total_s": 1507.3071932792664, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad45de50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1507.3071932792664, "iterations_since_restore": 108, "perf": {"cpu_util_percent": 30.88125, "ram_util_percent": 76.525}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5626626436591994, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.4055388977552983, "policy_loss": -0.018062686830831703, "vf_loss": 1.4228538710808922, "vf_explained_var": 3.419657970996613e-07, "kl": 0.007477118942384094, "entropy": 0.43375612977125966, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 305970.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.4941857036203148, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.34147735008349, "policy_loss": -0.025031214298845347, "vf_loss": 2.3648818504065274, "vf_explained_var": 0.09754138588905334, "kl": 0.008133564474949081, "entropy": 0.8987459641570846, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 104160.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 436000, "num_env_steps_trained": 436000, "num_agent_steps_sampled": 1744000, "num_agent_steps_trained": 1744000}, "env_runners": {"episode_reward_max": 140.0, "episode_reward_min": -19.122484704799685, "episode_reward_mean": 13.037172670275229, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 157, "episodes_timesteps_total": 3925, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -70.0}, "policy_reward_max": {"adversary_policy": 70.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 7.197452229299363, "agent_policy": -8.55518401762286}, "custom_metrics": {}, "hist_stats": {"episode_reward": [12.175394650018173, 0.0, -3.275643018963577, 0.0, 0.0, 0.0, 0.0, -9.756279543849823, 0.0, -3.8000185425899087, 60.0, -4.354205586923951, 40.0, 80.0, 0.0, 31.672875683698994, 20.0, 0.0, 53.4696933107896, 0.0, -4.381119650635332, 35.48909238771411, -5.925980425607615, 0.0, 0.0, 20.0, -0.17800809447152233, 0.0, 38.083102665262004, 0.0, 0.0, 40.0, -0.18369508295402848, 0.0, 140.0, -19.122484704799685, 0.0, -0.20051413701551946, 0.0, 79.18047691682929, 0.0, -0.027081500937319314, -3.2282511578448116, -4.190351295943432, 0.0, -10.483460373817861, 0.0, 32.87688743691222, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 0.0, 19.76035150738257, 0.0, 0.0, 39.739142696734234, -0.6151885227272458, 0.0, 57.59815114833961, -10.4295773506218, 19.05212975791899, 0.0, 0.0, 40.0, -0.04259435691451818, 0.0, -0.3160853796870877, -0.9798685691898801, 37.0224086790477, 0.0, 60.0, 60.0, 0.0, 20.0, -4.022878855183536, 0.0, -3.300961758801392, 80.0, 0.0, 0.0, -3.4155225566980434, 40.0, 0.0, 0.0, 0.0, 0.0, -3.9150885039462517, 0.0, 59.890789867246696, 0.0, 0.0, 20.0, 39.63496160183804, 40.0, 60.0, 0.0, 0.0, 40.0, 0.0, -0.7294825853025055, -0.1870546429405695, 20.0, -13.599584487436859, -1.6261737429814926, -0.07436002424264898, 0.0, 40.0, -0.40200723484368206, 20.0, 0.0, 0.0, 0.0, 28.8731663517458, 60.0, 40.0, 0.0, 0.0, 60.0, -0.06613990054604946, 0.0, 0.0, -0.8955275884766833, -2.1020664889278997, 0.0, -1.620892881005106, -19.059878567501922, 20.0, 0.0, 20.0, 0.0, 0.0, -2.482784966559791, 0.0, 80.0, 0.0, 29.476513074234845, 0.0, 0.0, 0.0, -0.6934467042351122, 0.0, -2.355353992273086, -0.7636117625792993, 0.0, 100.0, 60.0, 20.0, 0.0, 0.0, 0.0, 75.64419603747477, 0.0, 0.0, 40.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0], "policy_agent_policy_reward": [-17.824605349981827, 0.0, -3.275643018963577, 0.0, 0.0, 0.0, 0.0, -9.756279543849823, 0.0, -3.8000185425899087, -30.0, -4.354205586923951, -20.0, -40.0, 0.0, -28.32712431630101, -10.0, 0.0, -36.5303066892104, 0.0, -4.381119650635332, -24.51090761228589, -5.925980425607615, 0.0, 0.0, -10.0, -0.17800809447152233, 0.0, -21.916897334737996, 0.0, 0.0, -20.0, -0.18369508295402848, 0.0, -70.0, -19.122484704799685, 0.0, -0.20051413701551946, 0.0, -40.819523083170694, 0.0, -0.027081500937319314, -3.2282511578448116, -4.190351295943432, 0.0, -10.483460373817861, 0.0, -27.12311256308777, 0.0, 0.0, 0.0, 0.0, 0.0, -30.0, 0.0, -10.23964849261743, 0.0, 0.0, -20.26085730326577, -0.6151885227272458, 0.0, -32.40184885166038, -10.4295773506218, -10.94787024208101, 0.0, 0.0, -20.0, -0.04259435691451818, 0.0, -0.3160853796870877, -0.9798685691898801, -22.9775913209523, 0.0, -30.0, -30.0, 0.0, -10.0, -4.022878855183536, 0.0, -3.300961758801392, -40.0, 0.0, 0.0, -3.4155225566980434, -20.0, 0.0, 0.0, 0.0, 0.0, -3.9150885039462517, 0.0, -30.1092101327533, 0.0, 0.0, -10.0, -20.36503839816196, -20.0, -30.0, 0.0, 0.0, -20.0, 0.0, -0.7294825853025055, -0.1870546429405695, -10.0, -13.599584487436859, -1.6261737429814926, -0.07436002424264898, 0.0, -20.0, -0.40200723484368206, -10.0, 0.0, 0.0, 0.0, -31.126833648254205, -30.0, -20.0, 0.0, 0.0, -30.0, -0.06613990054604946, 0.0, 0.0, -0.8955275884766833, -2.1020664889278997, 0.0, -1.620892881005106, -19.059878567501922, -10.0, 0.0, -10.0, 0.0, 0.0, -2.482784966559791, 0.0, -40.0, 0.0, -30.523486925765155, 0.0, 0.0, 0.0, -0.6934467042351122, 0.0, -2.355353992273086, -0.7636117625792993, 0.0, -50.0, -30.0, -10.0, 0.0, 0.0, 0.0, -44.355803962525236, 0.0, 0.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6764617701244988, "mean_inference_ms": 1.1638255059566316, "mean_action_processing_ms": 0.24305166710743648, "mean_env_wait_ms": 0.5014900064054449, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004103684880930907, "StateBufferConnector_ms": 0.0031410508854374003, "ViewRequirementAgentConnector_ms": 0.08625604544475579}, "num_episodes": 157, "episode_return_max": 140.0, "episode_return_min": -19.122484704799685, "episode_return_mean": 13.037172670275229}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1744000, "num_agent_steps_trained": 1744000, "num_env_steps_sampled": 436000, "num_env_steps_trained": 436000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 345.41646061084214, "num_env_steps_trained_throughput_per_sec": 345.41646061084214, "timesteps_total": 436000, "num_env_steps_sampled_lifetime": 436000, "num_agent_steps_sampled_lifetime": 1744000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1744000, "timers": {"training_iteration_time_ms": 12269.739, "restore_workers_time_ms": 0.136, "training_step_time_ms": 12269.458, "sample_time_ms": 1168.921, "learn_time_ms": 11087.725, "learn_throughput": 360.759, "synch_weights_time_ms": 12.364}, "counters": {"num_env_steps_sampled": 436000, "num_env_steps_trained": 436000, "num_agent_steps_sampled": 1744000, "num_agent_steps_trained": 1744000}, "done": false, "training_iteration": 109, "trial_id": "86f16_00000", "date": "2024-08-08_16-38-13", "timestamp": 1723149493, "time_this_iter_s": 11.585624694824219, "time_total_s": 1518.8928179740906, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3aca8a3a0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1518.8928179740906, "iterations_since_restore": 109, "perf": {"cpu_util_percent": 29.776470588235295, "ram_util_percent": 75.81176470588235}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.49869983783322025, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.3306512737527807, "policy_loss": -0.014945753529446583, "vf_loss": 1.3450336140521029, "vf_explained_var": 6.127442028505582e-08, "kl": 0.005634134064968671, "entropy": 0.4414771725945439, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 308790.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.5180274044473965, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.359480460671087, "policy_loss": -0.03108260684578757, "vf_loss": 2.388374765838186, "vf_explained_var": 0.1315924300501744, "kl": 0.010941601474237696, "entropy": 0.9191259451210498, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 105120.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 440000, "num_env_steps_trained": 440000, "num_agent_steps_sampled": 1760000, "num_agent_steps_trained": 1760000}, "env_runners": {"episode_reward_max": 120.0, "episode_reward_min": -27.763531154650835, "episode_reward_mean": 11.445908412863394, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -60.0}, "policy_reward_max": {"adversary_policy": 60.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 6.790123456790123, "agent_policy": -8.924461957506978}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, -0.4097643140679019, 0.0, -7.841534593400314, 0.0, 0.0, 0.0, 0.0, -2.1653883686115067, 0.0, -1.2517406727183722, 20.0, 0.0, 20.0, -1.346776409085264, 20.0, -0.3283774266646644, 0.0, 0.0, 40.0, 0.0, -3.6169120579539147, -19.229681833354594, 0.0, -1.3226166229197833, 19.744109676999525, 0.0, 0.0, 0.0, 17.688362656453968, 60.0, 0.0, -5.337775730311922, 39.096102944934394, 0.0, 0.0, -1.215874407511831, 39.681895454706236, -14.670533040154536, 57.48864191702474, 0.0, 0.0, 40.0, -11.853895628706443, 60.0, -0.021682712391163372, 20.0, 18.691599623149397, 0.0, 20.0, 0.0, -0.22729746141792684, 0.0, 0.0, -3.7406976287564944, 0.0, -22.02984727919024, 0.0, 0.0, 120.0, -9.166369908702801, 0.0, 20.0, 0.0, -19.826528827235734, 0.0, -1.4193577705347538, 40.0, 0.0, -27.763531154650835, 0.0, 40.0, 0.0, 40.0, 0.0, 0.0, 40.0, -1.6709417059927223, -4.743501868257184, 79.58983574708108, 0.0, 0.0, -2.3559046358200666, 0.0, 120.0, 60.0, -4.972883595378875, 20.0, -4.2086333274948196, -12.11227976169209, 34.94053811790253, 20.0, 18.967099543296598, -1.278517572676482, 40.0, -2.8416206514044293, 0.0, 6.559702475236143, 16.023168816553394, 40.0, 0.0, 40.0, -0.5892956566706242, 20.0, 19.83788117801884, 39.99270880497847, 0.0, -2.391996985437238, 0.0, -1.7474277299816598, 40.0, 0.0, -1.108141894001432, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0879801630425079, 92.34361704484216, 0.0, -14.534599266800889, -10.883376754845472, 40.0, 60.0, 60.0, 0.0, -7.903692132516921, -3.978890245225289, 0.0, 0.0, -2.4150237469990055, 40.0, 20.0, 60.0, 20.0, -2.4514098329588254, 0.0, 0.0, 0.0, 0.0, 15.756981185687623, 20.0, 0.0, -0.04635449000767178, 0.0, -11.392772565335903, 9.680815475985735, -0.5454411558629846, 0.0, 0.0, 80.0, 0.0, 0.0, 16.613221505148438, -4.395271502197677, 60.0, 19.725522888286974, -6.529527071786717, 60.0, 0.0, 32.78702598831198], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0], "policy_agent_policy_reward": [0.0, -0.4097643140679019, 0.0, -7.841534593400314, 0.0, 0.0, 0.0, 0.0, -2.1653883686115067, 0.0, -1.2517406727183722, -10.0, 0.0, -10.0, -1.346776409085264, -10.0, -0.3283774266646644, 0.0, 0.0, -20.0, 0.0, -3.6169120579539147, -19.229681833354594, 0.0, -1.3226166229197833, -10.255890323000475, 0.0, 0.0, 0.0, -12.311637343546032, -30.0, 0.0, -5.337775730311922, -20.9038970550656, 0.0, 0.0, -1.215874407511831, -20.318104545293767, -14.670533040154536, -32.511358082975256, 0.0, 0.0, -20.0, -11.853895628706443, -30.0, -0.021682712391163372, -10.0, -11.308400376850603, 0.0, -10.0, 0.0, -0.22729746141792684, 0.0, 0.0, -3.7406976287564944, 0.0, -22.02984727919024, 0.0, 0.0, -60.0, -9.166369908702801, 0.0, -10.0, 0.0, -19.826528827235734, 0.0, -1.4193577705347538, -20.0, 0.0, -27.763531154650835, 0.0, -20.0, 0.0, -20.0, 0.0, 0.0, -20.0, -1.6709417059927223, -4.743501868257184, -40.41016425291891, 0.0, 0.0, -2.3559046358200666, 0.0, -60.0, -30.0, -4.972883595378875, -10.0, -4.2086333274948196, -12.11227976169209, -25.059461882097473, -10.0, -11.032900456703402, -1.278517572676482, -20.0, -2.8416206514044293, 0.0, -23.440297524763857, -13.976831183446606, -20.0, 0.0, -20.0, -0.5892956566706242, -10.0, -10.16211882198116, -20.007291195021534, 0.0, -2.391996985437238, 0.0, -1.7474277299816598, -20.0, 0.0, -1.108141894001432, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0879801630425079, -57.656382955157866, 0.0, -14.534599266800889, -10.883376754845472, -20.0, -30.0, -30.0, 0.0, -7.903692132516921, -33.97889024522529, 0.0, 0.0, -2.4150237469990055, -20.0, -10.0, -30.0, -10.0, -2.4514098329588254, 0.0, 0.0, 0.0, 0.0, -14.243018814312377, -10.0, 0.0, -0.04635449000767178, 0.0, -11.392772565335903, -20.31918452401426, -0.5454411558629846, 0.0, 0.0, -40.0, 0.0, 0.0, -13.386778494851562, -4.395271502197677, -30.0, -10.274477111713026, -6.529527071786717, -30.0, 0.0, -27.212974011688015]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.675699684345211, "mean_inference_ms": 1.1624002768147446, "mean_action_processing_ms": 0.24273966660138993, "mean_env_wait_ms": 0.5009909468885699, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004134354767975984, "StateBufferConnector_ms": 0.0030787638676019365, "ViewRequirementAgentConnector_ms": 0.08675566426029911}, "num_episodes": 162, "episode_return_max": 120.0, "episode_return_min": -27.763531154650835, "episode_return_mean": 11.445908412863394}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1760000, "num_agent_steps_trained": 1760000, "num_env_steps_sampled": 440000, "num_env_steps_trained": 440000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 332.7180927417383, "num_env_steps_trained_throughput_per_sec": 332.7180927417383, "timesteps_total": 440000, "num_env_steps_sampled_lifetime": 440000, "num_agent_steps_sampled_lifetime": 1760000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1760000, "timers": {"training_iteration_time_ms": 12345.318, "restore_workers_time_ms": 0.136, "training_step_time_ms": 12345.037, "sample_time_ms": 1170.434, "learn_time_ms": 11161.717, "learn_throughput": 358.368, "synch_weights_time_ms": 12.438}, "counters": {"num_env_steps_sampled": 440000, "num_env_steps_trained": 440000, "num_agent_steps_sampled": 1760000, "num_agent_steps_trained": 1760000}, "done": false, "training_iteration": 110, "trial_id": "86f16_00000", "date": "2024-08-08_16-38-25", "timestamp": 1723149505, "time_this_iter_s": 12.02835202217102, "time_total_s": 1530.9211699962616, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x309c54820>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1530.9211699962616, "iterations_since_restore": 110, "perf": {"cpu_util_percent": 30.352941176470587, "ram_util_percent": 75.61176470588234}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5443849083802379, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.8210056355447635, "policy_loss": -0.019429496496070363, "vf_loss": 1.8397514037629392, "vf_explained_var": -9.260279067019199e-07, "kl": 0.0068372302703733285, "entropy": 0.42417267542992926, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 311610.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.3545428110907474, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.6537233415991066, "policy_loss": -0.026171086969164512, "vf_loss": 2.6780932993938524, "vf_explained_var": 0.031249321872989337, "kl": 0.009005641697001703, "entropy": 0.9042281534522771, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 106080.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 444000, "num_env_steps_trained": 444000, "num_agent_steps_sampled": 1776000, "num_agent_steps_trained": 1776000}, "env_runners": {"episode_reward_max": 120.0, "episode_reward_min": -23.55402642036196, "episode_reward_mean": 13.78064094025641, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 158, "episodes_timesteps_total": 3950, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -68.00476503228839}, "policy_reward_max": {"adversary_policy": 60.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 7.784810126582278, "agent_policy": -9.573789439490426}, "custom_metrics": {}, "hist_stats": {"episode_reward": [20.0, -1.4628738807827923, 0.0, 0.0, 0.0, -1.4143809849456823, 0.0, 40.0, 57.27787026748654, 0.0, -23.55402642036196, 0.0, -4.164535780341413, 60.0, 0.0, 60.0, 84.7600318787106, 20.0, 0.0, 0.0, 0.0, 20.0, 60.0, 0.0, 0.0, 60.0, -9.42380167443843, 0.0, 0.0, -11.200322464188813, -10.334180391500114, 80.0, 0.0, 0.0, 20.0, 0.0, -5.107975313345167, 20.0, 0.0, 0.0, 0.0, 0.0, 120.0, 0.0, 0.0, 0.0, 80.0, 0.0, 19.295184771611098, -6.94355186102297, 20.0, 0.0, 0.0, 20.0, 0.0, 60.0, 0.0, 0.0, 0.0, 20.0, 0.0, 0.0, 59.08128125967673, 0.0, 0.0, 20.0, 0.0, 40.0, 0.0, 0.0, 20.0, 60.0, 0.0, -12.437237406266672, -0.18454268576589494, 0.0, 17.45144852612176, 20.0, 40.0, 0.0, 0.0, 0.0, 37.53567156349901, 0.0, 0.0, 0.0, -2.8237051637692527, 0.0, 20.0, 8.01349757030378, -0.08541721789959489, 0.0, 0.0, 0.0, 0.0, 20.0, -4.581983419037243, 60.0, -7.429734577529812, 0.0, 0.0, 0.0, -12.811161603718277, 0.0, -0.23217268929460966, -10.877604747992944, 0.0, -0.42840892295626487, 0.0, 30.66324627127648, 39.39161437098862, 60.0, 0.0, 0.0, 81.99523496771161, 0.0, 40.0, 0.0, 0.0, 0.0, 60.0, 80.0, 39.7544202713203, -0.9824673185912258, -9.114149352166308, -1.0870836324075661, 19.041072896235224, 0.0, 0.0, 0.0, -15.76099153990032, -3.5693720984907156, 78.7751125564024, 40.0, -7.406133091408667, 0.0, 0.0, 0.0, 0.0, -0.8341426578511191, 0.0, -0.2911269119427218, -2.3038425303154932, -4.251754056604247, -1.142585112604071, -0.5120168148254023, 20.0, 60.0, -12.08069613372361, -5.801710507860861, 95.40652502499775, 40.0, -0.4652546719789874, 60.0, 0.0, 100.0, 20.0, 40.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0], "policy_agent_policy_reward": [-10.0, -1.4628738807827923, 0.0, 0.0, 0.0, -1.4143809849456823, 0.0, -20.0, -32.72212973251346, 0.0, -23.55402642036196, 0.0, -4.164535780341413, -30.0, 0.0, -30.0, -65.2399681212894, -10.0, 0.0, 0.0, 0.0, -10.0, -30.0, 0.0, 0.0, -30.0, -9.42380167443843, 0.0, 0.0, -11.200322464188813, -10.334180391500114, -40.0, 0.0, 0.0, -10.0, 0.0, -5.107975313345167, -10.0, 0.0, 0.0, 0.0, 0.0, -60.0, 0.0, 0.0, 0.0, -40.0, 0.0, -10.704815228388904, -6.94355186102297, -10.0, 0.0, 0.0, -10.0, 0.0, -30.0, 0.0, 0.0, 0.0, -10.0, 0.0, 0.0, -30.91871874032327, 0.0, 0.0, -10.0, 0.0, -20.0, 0.0, 0.0, -10.0, -30.0, 0.0, -12.437237406266672, -0.18454268576589494, 0.0, -12.548551473878241, -10.0, -20.0, 0.0, 0.0, 0.0, -22.464328436500992, 0.0, 0.0, 0.0, -2.8237051637692527, 0.0, -10.0, -21.986502429696216, -0.08541721789959489, 0.0, 0.0, 0.0, 0.0, -10.0, -34.58198341903724, -30.0, -7.429734577529812, 0.0, 0.0, 0.0, -12.811161603718277, 0.0, -0.23217268929460966, -10.877604747992944, 0.0, -0.42840892295626487, 0.0, -29.336753728723522, -20.60838562901138, -30.0, 0.0, 0.0, -68.00476503228839, 0.0, -20.0, 0.0, 0.0, 0.0, -30.0, -40.0, -20.2455797286797, -0.9824673185912258, -9.114149352166308, -1.0870836324075661, -10.958927103764776, 0.0, 0.0, 0.0, -15.76099153990032, -3.5693720984907156, -41.2248874435976, -20.0, -7.406133091408667, 0.0, 0.0, 0.0, 0.0, -0.8341426578511191, 0.0, -0.2911269119427218, -2.3038425303154932, -4.251754056604247, -1.142585112604071, -0.5120168148254023, -10.0, -30.0, -12.08069613372361, -5.801710507860861, -54.59347497500225, -20.0, -0.4652546719789874, -30.0, 0.0, -50.0, -10.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6752655923156138, "mean_inference_ms": 1.1618550423616187, "mean_action_processing_ms": 0.24256908621860526, "mean_env_wait_ms": 0.5008256510627717, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004449977150446252, "StateBufferConnector_ms": 0.0034908705119845234, "ViewRequirementAgentConnector_ms": 0.09453281571593465}, "num_episodes": 158, "episode_return_max": 120.0, "episode_return_min": -23.55402642036196, "episode_return_mean": 13.78064094025641}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1776000, "num_agent_steps_trained": 1776000, "num_env_steps_sampled": 444000, "num_env_steps_trained": 444000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 329.92482915789213, "num_env_steps_trained_throughput_per_sec": 329.92482915789213, "timesteps_total": 444000, "num_env_steps_sampled_lifetime": 444000, "num_agent_steps_sampled_lifetime": 1776000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1776000, "timers": {"training_iteration_time_ms": 12394.89, "restore_workers_time_ms": 0.136, "training_step_time_ms": 12394.608, "sample_time_ms": 1180.636, "learn_time_ms": 11200.842, "learn_throughput": 357.116, "synch_weights_time_ms": 12.694}, "counters": {"num_env_steps_sampled": 444000, "num_env_steps_trained": 444000, "num_agent_steps_sampled": 1776000, "num_agent_steps_trained": 1776000}, "done": false, "training_iteration": 111, "trial_id": "86f16_00000", "date": "2024-08-08_16-38-38", "timestamp": 1723149518, "time_this_iter_s": 12.129422187805176, "time_total_s": 1543.0505921840668, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x309c54a60>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1543.0505921840668, "iterations_since_restore": 111, "perf": {"cpu_util_percent": 30.99444444444445, "ram_util_percent": 75.9388888888889}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5385683155070383, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.884933792318858, "policy_loss": -0.01863691344822539, "vf_loss": 1.9028885932256143, "vf_explained_var": -1.1334182522821087e-06, "kl": 0.00682114449257766, "entropy": 0.3990314138062457, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 314430.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.0585372482736903, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.5417885715452333, "policy_loss": -0.026578561399461857, "vf_loss": 2.5668640934551754, "vf_explained_var": 0.045784492790699, "kl": 0.007515199331664476, "entropy": 0.8890498222783207, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 107040.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 448000, "num_env_steps_trained": 448000, "num_agent_steps_sampled": 1792000, "num_agent_steps_trained": 1792000}, "env_runners": {"episode_reward_max": 100.0, "episode_reward_min": -30.58901785299541, "episode_reward_mean": 14.150396447813229, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -50.891050679611986}, "policy_reward_max": {"adversary_policy": 50.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 8.024691358024691, "agent_policy": -9.923677626260845}, "custom_metrics": {}, "hist_stats": {"episode_reward": [58.21652875255323, 20.0, 0.0, 0.0, 59.54040941473971, -4.232656948221467, -15.59244678533667, 40.0, 13.705808210621989, -27.702069782639764, 0.0, 0.0, 59.31379811576963, 40.0, 0.0, 0.0, 36.32112673784885, 0.0, 0.0, 35.208333093418396, 0.0, 20.0, 0.0, -3.095367670984608, 32.614632000964335, 25.75177798716156, 0.0, 0.0, 60.0, 0.0, 0.0, 0.0, -1.520072756835421, -1.2209457858654948, 0.0, 15.439365457924605, 0.0, -0.2855439914657565, 0.0, 0.0, -2.445526700724894, 39.108949320388014, 0.0, 0.0, -1.7714891055045923, 0.0, 60.0, 0.0, 60.0, 0.0, 0.0, 40.0, 20.0, 0.0, 77.78871265146813, 40.0, 40.0, 0.0, 12.915629734737283, 20.0, 20.0, 19.161294437181418, 0.0, -8.607576119874784, -8.458232891373067, -5.615830408401431, 0.0, 0.0, 0.0, 0.0, 20.0, 0.0, -1.7941180888577413, 0.0, 0.0, 0.0, 0.0, -0.5504070738139455, -0.36879171999266824, 69.66158047281475, 40.0, 0.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.01963668757882786, 40.0, -1.0458162368639468, -4.501206675205349, 60.0, -7.66929061726545, 80.0, 20.0, 38.62811595454372, 40.0, 20.0, -3.504229983420985, 0.0, -1.4949396181923158, 99.74465507929116, -2.267333758185192, -6.966197001033902, -7.541153688569912, 0.0, -0.675896091452991, 18.542509590961426, 40.0, -0.7447334723649424, 39.620328644622354, 40.0, 40.0, -16.823258634242865, 0.0, 0.0, 0.0, 38.42846729016753, 20.0, 60.0, 0.0, 0.0, 0.0, 60.0, -0.06719093986300329, 16.618099221108086, -1.0869070330875796, 75.17149570608561, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 39.50112063902945, 0.0, 20.0, -0.4303124894428112, 0.0, 0.0, 36.73621082806198, 0.0, -1.6737035603713424, -30.58901785299541, 0.0, 19.96177127569242, 40.0, 100.0, 100.0, 0.0, 16.302861051792398, -0.8274563238852406, 38.441535860803576, 0.0, 0.0, 20.0, 0.0, 20.0, 51.108463509905945], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0], "policy_agent_policy_reward": [-31.78347124744677, -10.0, 0.0, 0.0, -30.45959058526028, -4.232656948221467, -15.59244678533667, -20.0, -16.29419178937801, -27.702069782639764, 0.0, 0.0, -30.686201884230375, -20.0, 0.0, 0.0, -23.67887326215115, 0.0, 0.0, -24.791666906581607, 0.0, -10.0, 0.0, -3.095367670984608, -27.385367999035655, -34.24822201283844, 0.0, 0.0, -30.0, 0.0, 0.0, 0.0, -1.520072756835421, -1.2209457858654948, 0.0, -14.560634542075393, 0.0, -0.2855439914657565, 0.0, 0.0, -2.445526700724894, -50.891050679611986, 0.0, 0.0, -1.7714891055045923, 0.0, -30.0, 0.0, -30.0, 0.0, 0.0, -20.0, -10.0, 0.0, -42.21128734853187, -20.0, -20.0, 0.0, -17.084370265262717, -10.0, -10.0, -10.838705562818582, 0.0, -8.607576119874784, -8.458232891373067, -5.615830408401431, 0.0, 0.0, 0.0, 0.0, -10.0, 0.0, -1.7941180888577413, 0.0, 0.0, 0.0, 0.0, -0.5504070738139455, -0.36879171999266824, -50.33841952718527, -20.0, 0.0, -10.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.01963668757882786, -20.0, -1.0458162368639468, -4.501206675205349, -30.0, -7.66929061726545, -40.0, -10.0, -21.371884045456277, -20.0, -10.0, -3.504229983420985, 0.0, -1.4949396181923158, -50.25534492070883, -2.267333758185192, -6.966197001033902, -7.541153688569912, 0.0, -0.675896091452991, -11.457490409038575, -20.0, -0.7447334723649424, -20.379671355377646, -20.0, -20.0, -16.823258634242865, 0.0, 0.0, 0.0, -21.57153270983246, -10.0, -30.0, 0.0, 0.0, 0.0, -30.0, -0.06719093986300329, -13.381900778891914, -1.0869070330875796, -44.828504293914385, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -20.498879360970548, 0.0, -10.0, -0.4303124894428112, 0.0, 0.0, -23.263789171938022, 0.0, -1.6737035603713424, -30.58901785299541, 0.0, -10.038228724307581, -20.0, -50.0, -50.0, 0.0, -43.6971389482076, -0.8274563238852406, -21.558464139196424, 0.0, 0.0, -10.0, 0.0, -10.0, -38.891536490094055]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6748163772606439, "mean_inference_ms": 1.161189978066402, "mean_action_processing_ms": 0.24238603868531788, "mean_env_wait_ms": 0.5006777822481334, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004230605231391059, "StateBufferConnector_ms": 0.003329839235470619, "ViewRequirementAgentConnector_ms": 0.08918797528302227}, "num_episodes": 162, "episode_return_max": 100.0, "episode_return_min": -30.58901785299541, "episode_return_mean": 14.150396447813229}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1792000, "num_agent_steps_trained": 1792000, "num_env_steps_sampled": 448000, "num_env_steps_trained": 448000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 347.04176509163887, "num_env_steps_trained_throughput_per_sec": 347.04176509163887, "timesteps_total": 448000, "num_env_steps_sampled_lifetime": 448000, "num_agent_steps_sampled_lifetime": 1792000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1792000, "timers": {"training_iteration_time_ms": 12416.777, "restore_workers_time_ms": 0.136, "training_step_time_ms": 12416.495, "sample_time_ms": 1181.172, "learn_time_ms": 11222.109, "learn_throughput": 356.439, "synch_weights_time_ms": 12.746}, "counters": {"num_env_steps_sampled": 448000, "num_env_steps_trained": 448000, "num_agent_steps_sampled": 1792000, "num_agent_steps_trained": 1792000}, "done": false, "training_iteration": 112, "trial_id": "86f16_00000", "date": "2024-08-08_16-38-49", "timestamp": 1723149529, "time_this_iter_s": 11.532948970794678, "time_total_s": 1554.5835411548615, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x309c54d30>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1554.5835411548615, "iterations_since_restore": 112, "perf": {"cpu_util_percent": 30.58235294117647, "ram_util_percent": 75.76470588235293}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5151178556131133, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.2878867819588236, "policy_loss": -0.01527852927407263, "vf_loss": 1.3025450649202293, "vf_explained_var": -2.6498703246421003e-07, "kl": 0.006202437348310357, "entropy": 0.4352103628271015, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 317250.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.238455883413553, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.4706902132680018, "policy_loss": -0.030460582521239607, "vf_loss": 2.4992250818759203, "vf_explained_var": 0.07011015017827352, "kl": 0.009628595310389173, "entropy": 0.9009816554064553, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 108000.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 452000, "num_env_steps_trained": 452000, "num_agent_steps_sampled": 1808000, "num_agent_steps_trained": 1808000}, "env_runners": {"episode_reward_max": 120.0, "episode_reward_min": -23.771366178706685, "episode_reward_mean": 10.856209170468277, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 157, "episodes_timesteps_total": 3925, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -72.38020056347224}, "policy_reward_max": {"adversary_policy": 60.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 6.751592356687898, "agent_policy": -9.398567899595418}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 40.0, 0.0, -1.166284623375673, 20.0, 60.0, -0.34487409500649435, -6.345037130641369, 40.0, 0.0, 0.0, 0.0, -23.771366178706685, 77.61979943652777, 0.0, 0.0, 20.0, 40.0, -13.569508512341336, 0.0, 80.0, -1.9353862479684092, 0.0, 53.93402275226341, 59.36286238375047, 0.0, 0.0, 0.0, -1.1180523370261175, -16.439653313155695, 0.0, 20.0, 0.0, 0.0, 0.0, 0.0, -0.2229124087579426, -0.6164457702585424, 40.0, 40.0, 0.0, 0.0, -15.295159291834683, 108.56128869805747, 0.0, 40.0, 0.0, -1.7304681183936044, 0.0, 40.0, 0.0, 20.0, -7.538288046214188, -9.036489665958658, -14.125574475554396, 0.0, 0.0, 0.0, 0.0, -15.341320190166401, 120.0, 40.0, 60.0, -9.540191875836255, 0.0, 20.0, 40.0, 0.0, 59.085465424812725, -19.58161433925245, 0.0, 20.0, 0.0, 57.299914323078745, -7.836579913009112, -0.2739006662221044, 0.0, 0.0, 0.0, 40.0, -2.367716506520451, 0.0, -3.5264675452004313, -4.604214574943599, 15.210014148625106, -17.363418918637578, 60.0, 20.0, 0.0, 0.0, -10.491944302339503, -0.6077466539785037, 0.0, 0.0, 20.0, 0.0, 6.699943338479651, -20.513609907099095, -0.6372224127959765, 33.370591886046, 0.0, 49.34770874926496, 20.0, 20.0, 0.0, 120.0, 36.460455129533536, 0.0, 0.0, 0.0, -2.0194703333522557, -4.589599546737497, -4.0090052337754365, 0.0, -0.7406223407872203, 0.0, 0.0, 0.0, 20.0, -3.857076679688439, 18.033161619843362, 0.0, 18.717549923565702, 0.0, -8.278993915400154, 0.0, 0.0, -0.09007329287329502, 40.0, -10.401172793285202, 0.0, 0.0, 0.0, -3.6302585446985005, 0.0, 0.0, 20.0, 0.0, 40.0, 0.0, 0.0, 0.0, 20.0, 0.0, -3.305853223017892, 37.3364034733229, 16.91531112428864, -5.04610796646849, 40.0, 20.0, 20.0, 20.0, 0.0, -11.619970756661212], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [0.0, 0.0, 0.0, 0.0, -20.0, 0.0, -1.166284623375673, -10.0, -30.0, -0.34487409500649435, -6.345037130641369, -20.0, 0.0, 0.0, 0.0, -23.771366178706685, -72.38020056347224, 0.0, 0.0, -10.0, -20.0, -13.569508512341336, 0.0, -40.0, -1.9353862479684092, 0.0, -36.06597724773658, -30.63713761624954, 0.0, 0.0, 0.0, -1.1180523370261175, -16.439653313155695, 0.0, -10.0, 0.0, 0.0, 0.0, 0.0, -0.2229124087579426, -0.6164457702585424, -20.0, -20.0, 0.0, 0.0, -15.295159291834683, -71.43871130194253, 0.0, -20.0, 0.0, -1.7304681183936044, 0.0, -20.0, 0.0, -10.0, -7.538288046214188, -9.036489665958658, -14.125574475554396, 0.0, 0.0, 0.0, 0.0, -15.341320190166401, -60.0, -20.0, -30.0, -9.540191875836255, 0.0, -10.0, -20.0, 0.0, -30.914534575187268, -19.58161433925245, 0.0, -10.0, 0.0, -32.70008567692125, -7.836579913009112, -0.2739006662221044, 0.0, 0.0, 0.0, -20.0, -2.367716506520451, 0.0, -3.5264675452004313, -4.604214574943599, -14.789985851374892, -17.363418918637578, -30.0, -10.0, 0.0, 0.0, -10.491944302339503, -0.6077466539785037, 0.0, 0.0, -10.0, 0.0, -23.300056661520344, -20.513609907099095, -30.637222412795982, -56.629408113953986, 0.0, -40.652291250735054, -10.0, -10.0, 0.0, -60.0, -23.539544870466454, 0.0, 0.0, 0.0, -2.0194703333522557, -4.589599546737497, -4.0090052337754365, 0.0, -0.7406223407872203, 0.0, 0.0, 0.0, -10.0, -3.857076679688439, -11.966838380156641, 0.0, -11.282450076434303, 0.0, -8.278993915400154, 0.0, 0.0, -0.09007329287329502, -20.0, -10.401172793285202, 0.0, 0.0, 0.0, -3.6302585446985005, 0.0, 0.0, -10.0, 0.0, -20.0, 0.0, 0.0, 0.0, -10.0, 0.0, -3.305853223017892, -22.6635965266771, -13.084688875711361, -5.04610796646849, -20.0, -10.0, -10.0, -10.0, 0.0, -11.619970756661212]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6740866326553414, "mean_inference_ms": 1.1600007687810798, "mean_action_processing_ms": 0.2421363509981477, "mean_env_wait_ms": 0.5002515012043832, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003962531970564727, "StateBufferConnector_ms": 0.0032490226113872163, "ViewRequirementAgentConnector_ms": 0.08630760156424941}, "num_episodes": 157, "episode_return_max": 120.0, "episode_return_min": -23.771366178706685, "episode_return_mean": 10.856209170468277}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1808000, "num_agent_steps_trained": 1808000, "num_env_steps_sampled": 452000, "num_env_steps_trained": 452000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 347.78157102710225, "num_env_steps_trained_throughput_per_sec": 347.78157102710225, "timesteps_total": 452000, "num_env_steps_sampled_lifetime": 452000, "num_agent_steps_sampled_lifetime": 1808000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1808000, "timers": {"training_iteration_time_ms": 12434.569, "restore_workers_time_ms": 0.136, "training_step_time_ms": 12434.285, "sample_time_ms": 1177.7, "learn_time_ms": 11243.388, "learn_throughput": 355.765, "synch_weights_time_ms": 12.725}, "counters": {"num_env_steps_sampled": 452000, "num_env_steps_trained": 452000, "num_agent_steps_sampled": 1808000, "num_agent_steps_trained": 1808000}, "done": false, "training_iteration": 113, "trial_id": "86f16_00000", "date": "2024-08-08_16-39-01", "timestamp": 1723149541, "time_this_iter_s": 11.508306980133057, "time_total_s": 1566.0918481349945, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad4545e0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1566.0918481349945, "iterations_since_restore": 113, "perf": {"cpu_util_percent": 29.537499999999998, "ram_util_percent": 75.6875}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5506993641086081, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.917433498176277, "policy_loss": -0.017894416237382072, "vf_loss": 1.934674202106523, "vf_explained_var": -1.5755071707651125e-07, "kl": 0.006537122099158177, "entropy": 0.40532365275401594, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 320070.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.1934427145247657, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.1569538223246734, "policy_loss": -0.028928589365629403, "vf_loss": 3.184015535314878, "vf_explained_var": 0.06339185331016779, "kl": 0.00933439640082128, "entropy": 0.912695826900502, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 108960.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 456000, "num_env_steps_trained": 456000, "num_agent_steps_sampled": 1824000, "num_agent_steps_trained": 1824000}, "env_runners": {"episode_reward_max": 195.09547588589788, "episode_reward_min": -27.729246104440683, "episode_reward_mean": 12.554915263657294, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -104.90452411410212}, "policy_reward_max": {"adversary_policy": 100.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 7.901234567901234, "agent_policy": -11.14878844004641}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-13.934427486508802, 0.0, -0.04559169394085516, 54.065487926518344, 0.0, 0.0, 17.34617911017546, -1.5357635857238994, 0.0, 0.0, 0.0, 18.091592878773998, 24.568743407806544, 0.0, -10.377629608616319, 0.0, 0.0, 0.0, -6.277161612012549, 60.0, 34.532174188611116, 60.0, -9.697922808503524, 20.0, 0.0, 0.0, 0.0, -9.87791419198582, 40.0, -0.31296713943635424, 5.004955075853818, 20.0, 0.0, 7.416449573011322, 19.31824193285736, 0.0, 20.0, 34.633425136566, 40.0, -7.505301438278114, 0.0, -7.808535322411383, 0.0, -0.589047851797948, -4.913190920063321, 19.637556782845202, 20.0, 40.0, 0.0, 0.0, 140.0, -2.081877108937751, 0.0, 79.85569467268532, 40.0, 20.0, 0.0, 120.0, 40.0, 0.0, -4.635491063960081, 15.135647116003693, 0.0, 0.0, 20.0, 0.0, 0.0, -4.20396970102534, 39.88178266444024, 195.09547588589788, 27.79104121476052, 0.0, 0.0, 0.0, 0.0, -21.247395363508897, 0.0, -6.289386892310976, -1.1963758262784208, 0.0, 59.59427464277152, 0.0, 60.0, 0.0, 19.05554466171289, 40.0, 30.730893221305724, 0.0, -12.70725585523433, -11.158026082314157, 0.0, 40.0, -8.967628000177594, 30.17633127571507, 0.0, 0.0, 0.0, 0.0, -2.9195843931225927, -1.9038298917639762, -27.729246104440683, 60.0, 0.0, 20.0, 40.0, -15.464364364876822, 20.0, 0.0, -4.442949639075185, 0.0, 38.439635677237646, 0.0, -0.041879238923748785, -2.058560649647345, 0.0, -25.27277850782867, 0.0, 40.0, 4.203427902273059, 0.0, -21.940140285564098, -25.260093178949894, 0.0, 19.520669531556802, 0.0, 0.0, -2.771674067543079, 60.0, 16.39552647049015, -21.160952011967833, 0.0, 27.3508274442985, 120.0, 14.097975947370244, 40.0, 0.0, 0.0, -0.09337024320044573, -3.986383867038481, 80.0, 0.0, 0.0, 0.0, 39.42810493791535, 0.0, 0.0, -22.33936527536952, 0.0, 39.997567382381405, 0.0, -10.504843098287225, 0.0, 0.0, -4.216865621499906, 0.0, 40.0, 0.0028988913619691914, 0.0, 0.0, 60.0, 20.0, -0.002112848589710392], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 100.0, 100.0, 100.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 60.0, 60.0, 60.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-13.934427486508802, 0.0, -0.04559169394085516, -35.93451207348164, 0.0, 0.0, -12.653820889824546, -1.5357635857238994, 0.0, 0.0, 0.0, -11.908407121226002, -35.43125659219344, 0.0, -10.377629608616319, 0.0, 0.0, 0.0, -6.277161612012549, -30.0, -25.467825811388888, -30.0, -9.697922808503524, -10.0, 0.0, 0.0, 0.0, -9.87791419198582, -20.0, -0.31296713943635424, -24.99504492414618, -10.0, 0.0, -22.583550426988676, -10.681758067142638, 0.0, -10.0, -25.366574863434003, -20.0, -7.505301438278114, 0.0, -7.808535322411383, 0.0, -0.589047851797948, -4.913190920063321, -10.362443217154798, -10.0, -20.0, 0.0, 0.0, -70.0, -2.081877108937751, 0.0, -40.144305327314676, -20.0, -10.0, 0.0, -60.0, -20.0, 0.0, -4.635491063960081, -14.864352883996304, 0.0, 0.0, -10.0, 0.0, 0.0, -4.20396970102534, -20.118217335559763, -104.90452411410212, -32.208958785239474, 0.0, 0.0, 0.0, 0.0, -21.247395363508897, 0.0, -6.289386892310976, -1.1963758262784208, 0.0, -30.405725357228476, 0.0, -30.0, 0.0, -10.94445533828711, -20.0, -29.26910677869428, 0.0, -12.70725585523433, -11.158026082314157, 0.0, -20.0, -8.967628000177594, -29.82366872428493, 0.0, 0.0, 0.0, 0.0, -2.9195843931225927, -1.9038298917639762, -27.729246104440683, -30.0, 0.0, -10.0, -20.0, -15.464364364876822, -10.0, 0.0, -4.442949639075185, 0.0, -21.56036432276235, 0.0, -0.041879238923748785, -2.058560649647345, 0.0, -25.27277850782867, 0.0, -20.0, -25.796572097726944, 0.0, -21.940140285564098, -25.260093178949894, 0.0, -10.479330468443198, 0.0, 0.0, -32.77167406754307, -30.0, -13.604473529509852, -21.160952011967833, 0.0, -32.6491725557015, -60.0, -15.902024052629756, -20.0, 0.0, 0.0, -0.09337024320044573, -3.986383867038481, -40.0, 0.0, 0.0, 0.0, -20.571895062084653, 0.0, 0.0, -22.33936527536952, 0.0, -20.002432617618595, 0.0, -10.504843098287225, 0.0, 0.0, -4.216865621499906, 0.0, -20.0, -29.997101108638034, 0.0, 0.0, -30.0, -10.0, -0.002112848589710392]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6731355167337533, "mean_inference_ms": 1.1583453688142882, "mean_action_processing_ms": 0.2417711574408062, "mean_env_wait_ms": 0.49964384628032865, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0040071246064739465, "StateBufferConnector_ms": 0.003041897291018639, "ViewRequirementAgentConnector_ms": 0.08371825571413394}, "num_episodes": 162, "episode_return_max": 195.09547588589788, "episode_return_min": -27.729246104440683, "episode_return_mean": 12.554915263657294}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1824000, "num_agent_steps_trained": 1824000, "num_env_steps_sampled": 456000, "num_env_steps_trained": 456000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 357.6270614876574, "num_env_steps_trained_throughput_per_sec": 357.6270614876574, "timesteps_total": 456000, "num_env_steps_sampled_lifetime": 456000, "num_agent_steps_sampled_lifetime": 1824000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1824000, "timers": {"training_iteration_time_ms": 12394.925, "restore_workers_time_ms": 0.136, "training_step_time_ms": 12394.642, "sample_time_ms": 1175.973, "learn_time_ms": 11205.397, "learn_throughput": 356.971, "synch_weights_time_ms": 12.797}, "counters": {"num_env_steps_sampled": 456000, "num_env_steps_trained": 456000, "num_agent_steps_sampled": 1824000, "num_agent_steps_trained": 1824000}, "done": false, "training_iteration": 114, "trial_id": "86f16_00000", "date": "2024-08-08_16-39-12", "timestamp": 1723149552, "time_this_iter_s": 11.190271854400635, "time_total_s": 1577.2821199893951, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad454670>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1577.2821199893951, "iterations_since_restore": 114, "perf": {"cpu_util_percent": 28.23125, "ram_util_percent": 75.75}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.542364118924589, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.6580486041222904, "policy_loss": -0.01741768937055946, "vf_loss": 1.674839317291341, "vf_explained_var": -8.321611593801079e-07, "kl": 0.006269793181179987, "entropy": 0.3897185259782676, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 322890.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.4494916585584483, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.01790685535719, "policy_loss": -0.029691668498223103, "vf_loss": 3.0457625813782214, "vf_explained_var": 0.0737470996255676, "kl": 0.009179721720131368, "entropy": 0.9034536217028896, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 109920.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 460000, "num_env_steps_trained": 460000, "num_agent_steps_sampled": 1840000, "num_agent_steps_trained": 1840000}, "env_runners": {"episode_reward_max": 133.58716262594413, "episode_reward_min": -41.370459540612956, "episode_reward_mean": 11.946740659566945, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -76.41283737405588}, "policy_reward_max": {"adversary_policy": 70.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 7.345679012345679, "agent_policy": -10.090296377470091}, "custom_metrics": {}, "hist_stats": {"episode_reward": [39.666235062663446, 0.0, 0.0, 0.0, 133.58716262594413, -19.83667766644013, 0.0, 40.0, 36.60324102485848, -1.6794545716667209, 0.0, 60.0, -0.7498783962114508, 60.0, -0.027933099307680953, 0.0, 36.21449514542289, 40.0, 0.0, 0.0, 20.0, 0.0, 0.0, 0.0, -0.9432716023874888, 30.38471202260094, -7.9072237177051825, 0.0, -14.09344289837572, -0.6224441683685278, 0.0, 20.0, -9.900254253499007, 19.469421525820948, 20.0, 0.0, 15.869716818492822, 60.0, 0.0, -6.801823678566806, 60.0, 36.71543704054635, -7.234059469844232, 0.0, 15.914735010360118, 0.0, 0.0, 60.0, 0.0, -1.8400542211202897, -34.22908221233589, -26.874370821879236, -2.1855650666645854, 0.0, 16.11220406954147, 0.0, -3.094865253021204, 40.0, 20.0, -9.112569775360143, 20.0, 0.0, -0.4854506394956326, 0.0, 0.0, 0.0, 58.351833523780996, -0.047401533335393875, -0.5479891569659157, 0.0, 20.0, -0.6745908690727742, 0.0, 40.0, 0.0, 0.0, -3.0705409372610974, 0.0, 40.0, 0.0, 40.0, 0.0, 40.0, 0.0, -0.29749329869839136, 40.0, 0.0, 0.0, -0.021747165807778357, 20.0, 60.0, -4.590595198857359, -5.238492541099087, -1.4207350786505235, 0.0, -0.7367269876800298, -12.586438467069147, 0.0, -2.0215359369357766, 58.309843859179644, 0.0, -0.026456377825996302, 0.0, -4.256074962083641, 19.93692212528108, 0.0, -13.662505834533379, 0.0, 40.0, 20.0, 38.54294089138662, 19.506431476054964, 20.0, 0.0, 40.0, 0.0, 20.0, 46.305999485914555, 0.0, 44.508075818346384, 0.0, -41.370459540612956, 0.0, 40.0, -0.6996580311198453, 40.0, -2.872293739549912, 3.9944814108655144, 36.29624485758907, 0.0, 39.76654312093675, -0.0370200021931022, 60.0, 57.832717286762694, -9.037307205382739, 0.0, 40.0, 60.0, 80.0, 0.0, 0.0, -12.553352341718561, 0.0, 19.342931718946623, 38.56155389765011, 60.0, -0.0858338501401179, -8.132592000567753, -4.3869187031971935, 0.0, -1.9455831285782277, -8.744292908725136, -8.475642203704693, 37.84673936179894, -21.176234054040947, 0.0, 0.0, 0.0, -5.209275034607568, 0.0, -1.9131912954668817, 19.18876756683141], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0], "policy_agent_policy_reward": [-20.33376493733655, 0.0, 0.0, 0.0, -76.41283737405588, -19.83667766644013, 0.0, -20.0, -23.396758975141523, -1.6794545716667209, 0.0, -30.0, -0.7498783962114508, -30.0, -0.027933099307680953, 0.0, -23.78550485457711, -20.0, 0.0, 0.0, -10.0, 0.0, 0.0, 0.0, -0.9432716023874888, -29.61528797739906, -7.9072237177051825, 0.0, -14.09344289837572, -0.6224441683685278, 0.0, -10.0, -9.900254253499007, -10.530578474179054, -10.0, 0.0, -14.130283181507178, -30.0, 0.0, -6.801823678566806, -30.0, -23.284562959453655, -7.234059469844232, 0.0, -14.08526498963988, 0.0, 0.0, -30.0, 0.0, -1.8400542211202897, -34.22908221233589, -26.874370821879236, -2.1855650666645854, 0.0, -43.88779593045852, 0.0, -3.094865253021204, -20.0, -10.0, -9.112569775360143, -10.0, 0.0, -0.4854506394956326, 0.0, 0.0, 0.0, -31.648166476219007, -0.047401533335393875, -0.5479891569659157, 0.0, -10.0, -0.6745908690727742, 0.0, -20.0, 0.0, 0.0, -3.0705409372610974, 0.0, -20.0, 0.0, -20.0, 0.0, -20.0, 0.0, -0.29749329869839136, -20.0, 0.0, 0.0, -0.021747165807778357, -10.0, -30.0, -4.590595198857359, -5.238492541099087, -1.4207350786505235, 0.0, -0.7367269876800298, -12.586438467069147, 0.0, -2.0215359369357766, -31.690156140820363, 0.0, -0.026456377825996302, 0.0, -4.256074962083641, -10.063077874718921, 0.0, -13.662505834533379, 0.0, -20.0, -10.0, -21.45705910861338, -10.493568523945038, -10.0, 0.0, -20.0, 0.0, -10.0, -43.694000514085445, 0.0, -45.491924181653616, 0.0, -41.370459540612956, 0.0, -20.0, -0.6996580311198453, -20.0, -2.872293739549912, -26.00551858913449, -23.70375514241093, 0.0, -20.23345687906324, -0.0370200021931022, -30.0, -32.1672827132373, -9.037307205382739, 0.0, -20.0, -30.0, -40.0, 0.0, 0.0, -12.553352341718561, 0.0, -10.657068281053379, -21.438446102349893, -30.0, -0.0858338501401179, -8.132592000567753, -4.3869187031971935, 0.0, -1.9455831285782277, -8.744292908725136, -8.475642203704693, -22.153260638201058, -21.176234054040947, 0.0, 0.0, 0.0, -5.209275034607568, 0.0, -1.9131912954668817, -10.811232433168591]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.67230402783511, "mean_inference_ms": 1.1567904447200916, "mean_action_processing_ms": 0.24143840989669993, "mean_env_wait_ms": 0.4991264343300495, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003963856049525885, "StateBufferConnector_ms": 0.002980526582694348, "ViewRequirementAgentConnector_ms": 0.08400369573522497}, "num_episodes": 162, "episode_return_max": 133.58716262594413, "episode_return_min": -41.370459540612956, "episode_return_mean": 11.946740659566945}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1840000, "num_agent_steps_trained": 1840000, "num_env_steps_sampled": 460000, "num_env_steps_trained": 460000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 352.0885600560766, "num_env_steps_trained_throughput_per_sec": 352.0885600560766, "timesteps_total": 460000, "num_env_steps_sampled_lifetime": 460000, "num_agent_steps_sampled_lifetime": 1840000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1840000, "timers": {"training_iteration_time_ms": 11670.659, "restore_workers_time_ms": 0.013, "training_step_time_ms": 11670.622, "sample_time_ms": 1160.98, "learn_time_ms": 10496.973, "learn_throughput": 381.062, "synch_weights_time_ms": 12.336}, "counters": {"num_env_steps_sampled": 460000, "num_env_steps_trained": 460000, "num_agent_steps_sampled": 1840000, "num_agent_steps_trained": 1840000}, "done": false, "training_iteration": 115, "trial_id": "86f16_00000", "date": "2024-08-08_16-39-24", "timestamp": 1723149564, "time_this_iter_s": 11.365862846374512, "time_total_s": 1588.6479828357697, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad45de50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1588.6479828357697, "iterations_since_restore": 115, "perf": {"cpu_util_percent": 27.741176470588236, "ram_util_percent": 75.76470588235296}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5730967818211157, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.8367762243705439, "policy_loss": -0.018805212032954797, "vf_loss": 1.854942375844252, "vf_explained_var": -6.093835154323713e-07, "kl": 0.006390577414328102, "entropy": 0.4036918575247974, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 325710.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.4848053413132827, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.2628536069144807, "policy_loss": -0.03022805495420471, "vf_loss": 3.2909854240715504, "vf_explained_var": 0.05604310277849436, "kl": 0.010481239286024409, "entropy": 0.906783144424359, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 110880.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 464000, "num_env_steps_trained": 464000, "num_agent_steps_sampled": 1856000, "num_agent_steps_trained": 1856000}, "env_runners": {"episode_reward_max": 107.88620786148408, "episode_reward_min": -32.31138599846695, "episode_reward_mean": 11.708784920237868, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 158, "episodes_timesteps_total": 3950, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -72.11379213851592}, "policy_reward_max": {"adversary_policy": 60.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 7.468354430379747, "agent_policy": -10.696278370901373}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-1.57678936278292, 0.0, 0.0, 0.0, 60.0, -0.764867219896167, -4.5433137108580635, 40.0, 0.0, -10.905887486852128, 0.0, -0.30726256602390367, 60.0, -11.566371195502331, 35.13458962428847, -2.6713275503921707, 12.721616734529665, 0.0, 40.0, -16.636392419458048, 59.01481194709848, 0.0, -4.907175247499577, -0.06650812784023907, 100.0, 20.0, 20.0, -12.776044477420848, 0.0, -2.269317980773965, 20.0, -11.895421102506717, -12.458260838696269, 0.0, 0.0, 0.0, 52.65028851472037, 0.0, -5.918080423249372, 0.0, 79.01342088796248, 20.0, 0.0, 34.19148591267421, -10.279391354180643, -6.686092958513472, 0.0, 20.0, 0.0, 0.0, 0.0, -32.31138599846695, 40.0, 20.0, -5.595415625247405, -18.87707380729585, 107.88620786148408, -14.029533421509454, 0.0, 0.0, 80.0, 40.0, 0.0, -2.998583473080637, 0.0, -0.6019252585929258, 20.0, -5.937700492869834, 0.0, 20.0, -6.735538306327634, 0.0, 39.87944736212551, 100.0, -31.314376992547498, 0.0, -0.5843515256984955, 0.0, 17.824796600223532, 20.0, 0.0, 0.0, 0.0, 0.0, -6.3502466298438005, 40.0, 0.0, -1.1522402743675675, 0.0, 14.284291325243434, 0.0, -12.712049913277857, -7.191411480671274, -4.235143674961837, 0.0, 40.0, 60.0, 40.0, -9.68685683129844, 0.0, 0.0, 19.81787976734536, -2.463644785389638, 40.0, -14.576454950028001, 60.0, 40.0, 0.0, 0.0, -2.767447401719152, 60.0, -5.800187485442331, 20.0, 39.25963663606485, 0.0, 0.0, 0.0, 0.0, -31.056201355194183, -2.264104891427282, -11.035518120356377, -2.5505394098004732, 0.0, 0.0, 0.0, -1.0352861015246562, 94.11056677330652, 0.0, -15.449731003512637, 19.012138558310536, 100.0, 19.75164477110932, -12.130455601955914, 28.10660423236601, -6.172079741174361, 40.0, -6.4504929114628835, -1.6417498631611005, 0.0, 0.0, 0.0, -3.2527058684530124, 0.0, 20.0, 39.84360899768532, -23.402300556292484, 0.0, 60.0, 20.0, 36.95532550399636, 19.120893162447505, 20.0, 40.0, 0.0, 20.0, 20.0, 0.0, 20.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0], "policy_agent_policy_reward": [-1.57678936278292, 0.0, 0.0, 0.0, -30.0, -0.764867219896167, -4.5433137108580635, -20.0, 0.0, -10.905887486852128, 0.0, -0.30726256602390367, -30.0, -11.566371195502331, -24.865410375711527, -2.6713275503921707, -17.27838326547034, 0.0, -20.0, -16.636392419458048, -30.985188052901513, 0.0, -4.907175247499577, -0.06650812784023907, -50.0, -10.0, -10.0, -12.776044477420848, 0.0, -2.269317980773965, -10.0, -11.895421102506717, -12.458260838696269, 0.0, 0.0, 0.0, -37.34971148527963, 0.0, -5.918080423249372, 0.0, -40.98657911203751, -10.0, 0.0, -25.80851408732579, -10.279391354180643, -6.686092958513472, 0.0, -10.0, 0.0, 0.0, 0.0, -32.31138599846695, -20.0, -10.0, -5.595415625247405, -18.87707380729585, -72.11379213851592, -14.029533421509454, 0.0, 0.0, -40.0, -20.0, 0.0, -2.998583473080637, 0.0, -0.6019252585929258, -10.0, -5.937700492869834, 0.0, -10.0, -6.735538306327634, 0.0, -20.12055263787449, -50.0, -31.314376992547498, 0.0, -0.5843515256984955, 0.0, -12.17520339977646, -10.0, 0.0, 0.0, 0.0, 0.0, -6.3502466298438005, -20.0, 0.0, -1.1522402743675675, 0.0, -15.71570867475657, 0.0, -12.712049913277857, -7.191411480671274, -4.235143674961837, 0.0, -20.0, -30.0, -20.0, -9.68685683129844, 0.0, 0.0, -10.182120232654642, -2.463644785389638, -20.0, -14.576454950028001, -30.0, -20.0, 0.0, 0.0, -2.767447401719152, -30.0, -5.800187485442331, -10.0, -50.74036336393515, 0.0, 0.0, 0.0, 0.0, -31.056201355194183, -2.264104891427282, -11.035518120356377, -2.5505394098004732, 0.0, 0.0, 0.0, -1.0352861015246562, -55.88943322669349, 0.0, -15.449731003512637, -10.987861441689464, -50.0, -10.248355228890679, -12.130455601955914, -31.89339576763399, -6.172079741174361, -20.0, -6.4504929114628835, -1.6417498631611005, 0.0, 0.0, 0.0, -3.2527058684530124, 0.0, -10.0, -20.156391002314674, -23.402300556292484, 0.0, -30.0, -10.0, -23.044674496003633, -10.879106837552495, -10.0, -20.0, 0.0, -10.0, -10.0, 0.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6713506151670499, "mean_inference_ms": 1.1551052005174143, "mean_action_processing_ms": 0.24108327088595688, "mean_env_wait_ms": 0.4985306711914249, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004603666595265835, "StateBufferConnector_ms": 0.003079975707621514, "ViewRequirementAgentConnector_ms": 0.08181695696673816}, "num_episodes": 158, "episode_return_max": 107.88620786148408, "episode_return_min": -32.31138599846695, "episode_return_mean": 11.708784920237868}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1856000, "num_agent_steps_trained": 1856000, "num_env_steps_sampled": 464000, "num_env_steps_trained": 464000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 332.67142941641714, "num_env_steps_trained_throughput_per_sec": 332.67142941641714, "timesteps_total": 464000, "num_env_steps_sampled_lifetime": 464000, "num_agent_steps_sampled_lifetime": 1856000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1856000, "timers": {"training_iteration_time_ms": 11594.525, "restore_workers_time_ms": 0.013, "training_step_time_ms": 11594.481, "sample_time_ms": 1119.827, "learn_time_ms": 10461.808, "learn_throughput": 382.343, "synch_weights_time_ms": 12.51}, "counters": {"num_env_steps_sampled": 464000, "num_env_steps_trained": 464000, "num_agent_steps_sampled": 1856000, "num_agent_steps_trained": 1856000}, "done": false, "training_iteration": 116, "trial_id": "86f16_00000", "date": "2024-08-08_16-39-36", "timestamp": 1723149576, "time_this_iter_s": 12.032370328903198, "time_total_s": 1600.6803531646729, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x309c743a0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1600.6803531646729, "iterations_since_restore": 116, "perf": {"cpu_util_percent": 31.629411764705885, "ram_util_percent": 76.07647058823528}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5176032836397066, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.6728737240987466, "policy_loss": -0.017553915749287483, "vf_loss": 1.6897624851329953, "vf_explained_var": -1.343006783343376e-07, "kl": 0.006651523760910165, "entropy": 0.4216160622894341, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 328530.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.4950157394011816, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.9072853727887074, "policy_loss": -0.0304923356360329, "vf_loss": 2.9358903450270493, "vf_explained_var": 0.08044965801139672, "kl": 0.009436837706605439, "entropy": 0.9025554429739714, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 111840.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 468000, "num_env_steps_trained": 468000, "num_agent_steps_sampled": 1872000, "num_agent_steps_trained": 1872000}, "env_runners": {"episode_reward_max": 100.0, "episode_reward_min": -23.66871096996349, "episode_reward_mean": 10.19928384107812, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 157, "episodes_timesteps_total": 3925, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -50.0}, "policy_reward_max": {"adversary_policy": 50.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 6.369426751592357, "agent_policy": -8.908996413698949}, "custom_metrics": {}, "hist_stats": {"episode_reward": [20.0, -3.15063920541572, 0.0, 80.0, 40.0, 37.953347678263995, 18.809162972173347, -0.21545688476009128, 59.62389886945073, 15.365266356687613, 0.0, -16.672204360955227, 19.97196982086295, 0.0, 40.0, 0.0, 0.0, 40.0, 0.0, 0.0, 0.0, 40.0, 34.92457762801433, 40.0, 0.0, 20.0, -13.043476633620791, 0.0, 20.0, -7.597374508116542, 80.0, 20.0, 0.0, -6.94828599121792, -8.523757584588427, 16.608101761198945, 14.009992744729434, 0.0, 0.0, -1.35855171881742, 59.61924209522094, 20.0, -0.37266387059355366, 18.096568456337625, 57.71693272360416, 20.0, 0.0, 0.0, 0.0, 0.0, 40.0, 0.0, -12.701132814440022, -3.6820240561998716, 19.098671114050056, 39.806332900552164, 0.0, 60.0, 20.0, 0.0, 20.0, 0.0, 0.0, 40.0, 0.0, 20.0, 0.0, 0.0, 26.230403199887462, 0.0, 0.0, -18.05321137950642, 100.0, 38.24525764639848, 40.0, -11.40672461287196, -0.16910647846572924, -2.583174620312712, -4.411062498363769, -0.005755104728492055, 0.0, -1.7756808627511733, 0.0, 60.0, 0.0, 0.0, 0.0, -10.25289861172098, -20.38951905995896, 0.0, 48.80974382439012, 0.0, -12.281805286862305, -2.4620555416126786, -1.1820239140676247, 0.0, 60.0, 20.0, 40.0, 0.0, 0.0, 20.0, 40.0, 0.0, 0.0, 0.0, -23.66871096996349, -7.875768933323362, 20.0, -21.50620356954587, -1.120247675921603, 20.0, -9.848340186275864, 0.0, 0.0, 20.0, -1.9267692857361984, -5.068186052924309, -5.8903013475970285, 0.0, 0.0, 40.0, 20.0, -0.28091163439121547, 0.0, -0.6570456434291505, 0.0, 0.0, -17.394435197262606, -0.09746854317656983, -3.8685000431444174, 20.0, 40.0, -6.878631985739871, 0.0, 0.0, -0.6590856467837458, -1.4856767883521171, -23.302144822885413, 0.0, 0.0, 0.0, 20.0, 37.8160070914964, 0.0, 15.631298586107572, -18.03246123071349, 20.0, 0.0, 0.0, 0.0, 15.628027293863644, 20.0, 0.0, -14.09080811960435, 40.0, -9.786956437305744], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-10.0, -3.15063920541572, 0.0, -40.0, -20.0, -22.046652321736005, -11.190837027826657, -0.21545688476009128, -30.37610113054928, -14.634733643312389, 0.0, -16.672204360955227, -10.02803017913705, 0.0, -20.0, 0.0, 0.0, -20.0, 0.0, 0.0, 0.0, -20.0, -25.07542237198567, -20.0, 0.0, -10.0, -13.043476633620791, 0.0, -10.0, -7.597374508116542, -40.0, -10.0, 0.0, -6.94828599121792, -8.523757584588427, -13.391898238801055, -15.990007255270568, 0.0, 0.0, -1.35855171881742, -30.380757904779056, -10.0, -0.37266387059355366, -11.90343154366237, -32.28306727639584, -10.0, 0.0, 0.0, 0.0, 0.0, -20.0, 0.0, -12.701132814440022, -3.6820240561998716, -10.901328885949942, -20.193667099447836, 0.0, -30.0, -10.0, 0.0, -10.0, 0.0, 0.0, -20.0, 0.0, -10.0, 0.0, 0.0, -33.76959680011254, 0.0, 0.0, -18.05321137950642, -50.0, -21.75474235360152, -20.0, -11.40672461287196, -0.16910647846572924, -2.583174620312712, -4.411062498363769, -0.005755104728492055, 0.0, -1.7756808627511733, 0.0, -30.0, 0.0, 0.0, 0.0, -10.25289861172098, -20.38951905995896, 0.0, -41.19025617560989, 0.0, -12.281805286862305, -2.4620555416126786, -1.1820239140676247, 0.0, -30.0, -10.0, -20.0, 0.0, 0.0, -10.0, -20.0, 0.0, 0.0, 0.0, -23.66871096996349, -7.875768933323362, -10.0, -21.50620356954587, -1.120247675921603, -10.0, -9.848340186275864, 0.0, 0.0, -10.0, -1.9267692857361984, -5.068186052924309, -5.8903013475970285, 0.0, 0.0, -20.0, -10.0, -0.28091163439121547, 0.0, -0.6570456434291505, 0.0, 0.0, -17.394435197262606, -0.09746854317656983, -3.8685000431444174, -10.0, -20.0, -6.878631985739871, 0.0, 0.0, -0.6590856467837458, -1.4856767883521171, -23.302144822885413, 0.0, 0.0, 0.0, -10.0, -22.183992908503594, 0.0, -14.368701413892431, -18.03246123071349, -10.0, 0.0, 0.0, 0.0, -14.37197270613636, -10.0, 0.0, -14.09080811960435, -20.0, -9.786956437305744]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6708308618516176, "mean_inference_ms": 1.1544159700392769, "mean_action_processing_ms": 0.24088139519919685, "mean_env_wait_ms": 0.498319405470535, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004028438762494713, "StateBufferConnector_ms": 0.003233305208242623, "ViewRequirementAgentConnector_ms": 0.08239131064931299}, "num_episodes": 157, "episode_return_max": 100.0, "episode_return_min": -23.66871096996349, "episode_return_mean": 10.19928384107812}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1872000, "num_agent_steps_trained": 1872000, "num_env_steps_sampled": 468000, "num_env_steps_trained": 468000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 348.8616313476451, "num_env_steps_trained_throughput_per_sec": 348.8616313476451, "timesteps_total": 468000, "num_env_steps_sampled_lifetime": 468000, "num_agent_steps_sampled_lifetime": 1872000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1872000, "timers": {"training_iteration_time_ms": 11606.489, "restore_workers_time_ms": 0.013, "training_step_time_ms": 11606.445, "sample_time_ms": 1116.926, "learn_time_ms": 10476.624, "learn_throughput": 381.802, "synch_weights_time_ms": 12.563}, "counters": {"num_env_steps_sampled": 468000, "num_env_steps_trained": 468000, "num_agent_steps_sampled": 1872000, "num_agent_steps_trained": 1872000}, "done": false, "training_iteration": 117, "trial_id": "86f16_00000", "date": "2024-08-08_16-39-48", "timestamp": 1723149588, "time_this_iter_s": 11.471398115158081, "time_total_s": 1612.151751279831, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x309c745e0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1612.151751279831, "iterations_since_restore": 117, "perf": {"cpu_util_percent": 28.28235294117647, "ram_util_percent": 76.55882352941175}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5495901379073765, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.6748202316515834, "policy_loss": -0.018403131166862735, "vf_loss": 1.6926159870328632, "vf_explained_var": -6.019646394337322e-08, "kl": 0.00607374290551006, "entropy": 0.39950060694352957, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 331350.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.307397744307915, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.5257084065427384, "policy_loss": -0.029153393965195087, "vf_loss": 2.5531310151020685, "vf_explained_var": 0.11852079158027967, "kl": 0.00865394908393594, "entropy": 0.9252958407004674, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 112800.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 472000, "num_env_steps_trained": 472000, "num_agent_steps_sampled": 1888000, "num_agent_steps_trained": 1888000}, "env_runners": {"episode_reward_max": 120.0, "episode_reward_min": -35.217184458746985, "episode_reward_mean": 12.527524483164537, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -61.29442568276619}, "policy_reward_max": {"adversary_policy": 60.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 7.345679012345679, "agent_policy": -9.509512553872499}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-8.297220783997457, 0.0, 0.0, -7.8384365477571425, -9.22045567914422, 0.0, 20.0, 56.102151209589266, -2.499085065451874, -3.2897980547891805, 88.70557431723381, 40.0, 0.0, 40.0, 0.0, 0.0, 0.45684304060347714, 56.272210476780515, -0.17261325928164983, 40.0, 19.372350522381808, 58.240986311651326, -1.093148452569872, 0.0, -2.438479935764729, 29.36813776721109, 99.54061306367859, -0.9421019985063617, 60.0, -18.35417736045953, -0.27297662916847987, 17.20601777028049, 0.0, 0.0, 0.0, 20.0, -1.8345570022647983, 20.0, -5.186250324267271, -7.5742325683560185, 0.0, 39.96007841365813, 0.0, 40.0, -0.39051395733228356, 0.0, 120.0, 59.100021425352395, 0.0, 0.0, 40.0, -0.6051971673167467, 0.0, 60.0, 32.32323614117443, 0.0, 0.0, -9.965888342271487, 0.0, 0.0, -1.3424969682548127, -22.070023082179013, 20.0, 0.0, -0.026755368512400013, -5.340353108931128, 0.0, -1.0943009989395747, 40.0, 19.725537874444733, -35.217184458746985, -3.938841395020062, 60.0, 0.0, 0.0, -0.8391396552761499, -14.198187360867902, 0.0, -0.49430804164071973, 60.0, 0.0, 0.0, 40.0, 0.0, 19.709831238053845, -0.3469957823530201, 0.0, 0.0, 0.0, 40.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 0.0, 0.0, 40.0, 0.0, 0.0, -15.162664807202889, 60.0, 40.0, 34.2664630603218, 40.0, -8.701859981458037, 0.0, 19.42506132474377, 60.0, 18.339375838375215, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, -0.1196340827550102, 0.0, 20.0, 18.877978353548034, 20.0, 0.0, -2.922111763707691, 0.0, 40.0, -18.505891267713757, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.2568990223586, 0.0, -16.348207053869448, 0.0, 0.0, 0.0, 0.0, 0.0, 39.39307354635502, 60.0, -11.630192003475178, 0.0, -0.9864731126894488, 0.0, 0.0, 0.0, 60.0, 19.538447290780706, 20.0, 0.0, -0.5491243742203611, 19.541956805110594, 39.44463498853894, -0.08337894633977827, -7.960074705797292, 0.0, 20.0, 39.14481791907828], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0], "policy_agent_policy_reward": [-8.297220783997457, 0.0, 0.0, -7.8384365477571425, -9.22045567914422, 0.0, -10.0, -33.897848790410734, -2.499085065451874, -3.2897980547891805, -61.29442568276619, -20.0, 0.0, -20.0, 0.0, 0.0, -29.543156959396523, -33.727789523219485, -0.17261325928164983, -20.0, -10.62764947761819, -31.759013688348663, -1.093148452569872, 0.0, -2.438479935764729, -30.63186223278891, -50.459386936321415, -0.9421019985063617, -30.0, -18.35417736045953, -0.27297662916847987, -12.793982229719514, 0.0, 0.0, 0.0, -10.0, -1.8345570022647983, -10.0, -5.186250324267271, -7.5742325683560185, 0.0, -20.03992158634187, 0.0, -20.0, -0.39051395733228356, 0.0, -60.0, -30.899978574647598, 0.0, 0.0, -20.0, -0.6051971673167467, 0.0, -30.0, -27.676763858825574, 0.0, 0.0, -9.965888342271487, 0.0, 0.0, -1.3424969682548127, -22.070023082179013, -10.0, 0.0, -0.026755368512400013, -5.340353108931128, 0.0, -1.0943009989395747, -20.0, -10.274462125555269, -35.217184458746985, -3.938841395020062, -30.0, 0.0, 0.0, -0.8391396552761499, -14.198187360867902, 0.0, -0.49430804164071973, -30.0, 0.0, 0.0, -20.0, 0.0, -10.290168761946159, -0.3469957823530201, 0.0, 0.0, 0.0, -20.0, -10.0, -10.0, 0.0, 0.0, 0.0, -20.0, 0.0, 0.0, -20.0, 0.0, 0.0, -15.162664807202889, -30.0, -20.0, -25.733536939678206, -20.0, -8.701859981458037, 0.0, -10.57493867525623, -30.0, -11.660624161624789, 0.0, 0.0, 0.0, 0.0, 0.0, -20.0, -0.1196340827550102, 0.0, -10.0, -11.122021646451968, -10.0, 0.0, -2.922111763707691, 0.0, -20.0, -18.505891267713757, -20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -56.7431009776414, 0.0, -16.348207053869448, 0.0, 0.0, 0.0, 0.0, 0.0, -20.606926453644977, -30.0, -11.630192003475178, 0.0, -0.9864731126894488, 0.0, 0.0, 0.0, -30.0, -10.461552709219294, -10.0, 0.0, -0.5491243742203611, -10.458043194889404, -20.555365011461067, -0.08337894633977827, -7.960074705797292, 0.0, -10.0, -20.85518208092172]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6698224298693829, "mean_inference_ms": 1.152700171640421, "mean_action_processing_ms": 0.2405256579478073, "mean_env_wait_ms": 0.4977086320491283, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003975924150443372, "StateBufferConnector_ms": 0.003320052299970462, "ViewRequirementAgentConnector_ms": 0.08316981939621913}, "num_episodes": 162, "episode_return_max": 120.0, "episode_return_min": -35.217184458746985, "episode_return_mean": 12.527524483164537}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1888000, "num_agent_steps_trained": 1888000, "num_env_steps_sampled": 472000, "num_env_steps_trained": 472000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 359.649419537126, "num_env_steps_trained_throughput_per_sec": 359.649419537126, "timesteps_total": 472000, "num_env_steps_sampled_lifetime": 472000, "num_agent_steps_sampled_lifetime": 1888000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1888000, "timers": {"training_iteration_time_ms": 11591.126, "restore_workers_time_ms": 0.013, "training_step_time_ms": 11591.083, "sample_time_ms": 1112.317, "learn_time_ms": 10465.811, "learn_throughput": 382.197, "synch_weights_time_ms": 12.621}, "counters": {"num_env_steps_sampled": 472000, "num_env_steps_trained": 472000, "num_agent_steps_sampled": 1888000, "num_agent_steps_trained": 1888000}, "done": false, "training_iteration": 118, "trial_id": "86f16_00000", "date": "2024-08-08_16-39-59", "timestamp": 1723149599, "time_this_iter_s": 11.128120183944702, "time_total_s": 1623.2798714637756, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x309c74af0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1623.2798714637756, "iterations_since_restore": 118, "perf": {"cpu_util_percent": 30.95, "ram_util_percent": 76.5625}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4970511757365778, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.9947506635007284, "policy_loss": -0.015871889849774647, "vf_loss": 1.0099734042764557, "vf_explained_var": 5.423811310571982e-07, "kl": 0.006491494294864961, "entropy": 0.4256547680032169, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 334170.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.496988662953178, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.9544535507758458, "policy_loss": -0.025139765859542727, "vf_loss": 1.9776933259641132, "vf_explained_var": 0.132830839479963, "kl": 0.009499952279459333, "entropy": 0.9461611924692989, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 113760.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 476000, "num_env_steps_trained": 476000, "num_agent_steps_sampled": 1904000, "num_agent_steps_trained": 1904000}, "env_runners": {"episode_reward_max": 80.0, "episode_reward_min": -26.827918056366844, "episode_reward_mean": 7.571995111326652, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -56.82791805636685}, "policy_reward_max": {"adversary_policy": 40.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 4.753086419753086, "agent_policy": -6.6872641479326065}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, -5.564160244809549, 0.0, 0.0, 40.0, 60.0, 0.0, -0.011307141692306066, -0.9399405625373447, 0.0, -5.508605899944044, 0.0, 0.0, -1.5158670705510313, 39.13879182936715, 80.0, 0.0, -1.0621610601799092, 0.0, 0.0, -1.178446847159338, 0.0, 0.0, 0.0, 20.0, 0.0, 0.0, -16.342638849210804, 0.0, 20.0, -5.9955326431728455, 0.0, 20.0, 0.0, 0.0, -7.381733014317487, 60.0, 14.957281866730913, 19.973581304583686, 0.0, 0.0, 0.0, 0.0, 60.0, -0.2047447518573009, 0.0, 20.0, 0.0, 0.0, -6.229428614626145, 0.0, 0.0, 20.0, -20.56195777705458, 0.0, 0.0, 75.3233117216425, 0.0, 38.89936102703437, 0.0, 40.0, 40.0, 0.0, -2.799945822045892, 0.0, 20.0, 20.0, -21.070888314444208, 16.22555726589334, 58.453668585614366, -3.874275601309227, 0.0, -5.936975863685973, 0.0, 0.0, 0.0, 0.0, 0.0, -0.08227332177479618, 58.7554138470698, 59.63296128198505, -8.726186198030465, -0.27406006003859673, 0.0, 0.0, -0.8937430537607638, 20.0, -4.568718786563446, 0.0, 0.0, 0.0, 0.0, -0.8566911054200743, 40.0, 0.0, 0.0, -26.827918056366844, -1.9792123276039952, -1.4026080673008674, -0.2032993873005151, 0.0, 0.0, 80.0, 0.0, 0.0, -19.68074589214713, 0.0, 0.0, 0.0, 60.0, -2.906388114744778, -3.0728773447802387, 0.0, 0.0, 40.0, 0.0, -5.44380228787008, -0.001342866151694544, -1.416875580391025, 0.0, 0.0, -0.9322061925502712, 39.08047594169019, 40.0, 0.0, -3.7478479260751025, -0.2703653534517547, 0.0, 40.0, 0.0, -1.0510467012088398, 0.0, 0.0, -12.075562608482574, 20.0, -15.94536273263619, 37.80829032152937, 0.0, -0.26967553779883136, -0.454926890368742, -8.366937918801385, 0.0, -5.91527173461575, 60.0, -0.01662711129697958, -9.346613454616618, -1.8629135184659318, -0.6200652060779688, 40.0, 20.0, 0.0, 0.0, 20.0, -0.5638068927805162, 20.0, 0.0, 0.0, -0.6784520262457661, -4.913865665080204, 0.0, 0.0, -0.03858695882617558], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [0.0, -5.564160244809549, 0.0, 0.0, -20.0, -30.0, 0.0, -0.011307141692306066, -0.9399405625373447, 0.0, -5.508605899944044, 0.0, 0.0, -1.5158670705510313, -20.861208170632846, -40.0, 0.0, -1.0621610601799092, 0.0, 0.0, -1.178446847159338, 0.0, 0.0, 0.0, -10.0, 0.0, 0.0, -16.342638849210804, 0.0, -10.0, -5.9955326431728455, 0.0, -10.0, 0.0, 0.0, -7.381733014317487, -30.0, -15.042718133269089, -10.026418695416314, 0.0, 0.0, 0.0, 0.0, -30.0, -0.2047447518573009, 0.0, -10.0, 0.0, 0.0, -6.229428614626145, 0.0, 0.0, -10.0, -20.56195777705458, 0.0, 0.0, -44.676688278357524, 0.0, -21.100638972965633, 0.0, -20.0, -20.0, 0.0, -2.799945822045892, 0.0, -10.0, -10.0, -21.070888314444208, -13.774442734106664, -31.546331414385637, -3.874275601309227, 0.0, -5.936975863685973, 0.0, 0.0, 0.0, 0.0, 0.0, -0.08227332177479618, -31.244586152930204, -30.36703871801496, -8.726186198030465, -0.27406006003859673, 0.0, 0.0, -0.8937430537607638, -10.0, -4.568718786563446, 0.0, 0.0, 0.0, 0.0, -0.8566911054200743, -20.0, 0.0, 0.0, -56.82791805636685, -1.9792123276039952, -31.402608067300868, -0.2032993873005151, 0.0, 0.0, -40.0, 0.0, 0.0, -19.68074589214713, 0.0, 0.0, 0.0, -30.0, -2.906388114744778, -3.0728773447802387, 0.0, 0.0, -20.0, 0.0, -5.44380228787008, -0.001342866151694544, -1.416875580391025, 0.0, 0.0, -0.9322061925502712, -20.919524058309808, -20.0, 0.0, -3.7478479260751025, -0.2703653534517547, 0.0, -20.0, 0.0, -1.0510467012088398, 0.0, 0.0, -12.075562608482574, -10.0, -15.94536273263619, -22.19170967847063, 0.0, -0.26967553779883136, -0.454926890368742, -8.366937918801385, 0.0, -5.91527173461575, -30.0, -0.01662711129697958, -9.346613454616618, -1.8629135184659318, -0.6200652060779688, -20.0, -10.0, 0.0, 0.0, -10.0, -0.5638068927805162, -10.0, 0.0, 0.0, -0.6784520262457661, -4.913865665080204, 0.0, 0.0, -0.03858695882617558]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6690202988470004, "mean_inference_ms": 1.151433249674022, "mean_action_processing_ms": 0.24025710125945915, "mean_env_wait_ms": 0.4972397796342138, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003987771493417246, "StateBufferConnector_ms": 0.003299816155139311, "ViewRequirementAgentConnector_ms": 0.08468936990808558}, "num_episodes": 162, "episode_return_max": 80.0, "episode_return_min": -26.827918056366844, "episode_return_mean": 7.571995111326652}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1904000, "num_agent_steps_trained": 1904000, "num_env_steps_sampled": 476000, "num_env_steps_trained": 476000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 356.61077335397454, "num_env_steps_trained_throughput_per_sec": 356.61077335397454, "timesteps_total": 476000, "num_env_steps_sampled_lifetime": 476000, "num_agent_steps_sampled_lifetime": 1904000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1904000, "timers": {"training_iteration_time_ms": 11554.775, "restore_workers_time_ms": 0.013, "training_step_time_ms": 11554.732, "sample_time_ms": 1113.923, "learn_time_ms": 10427.826, "learn_throughput": 383.589, "synch_weights_time_ms": 12.651}, "counters": {"num_env_steps_sampled": 476000, "num_env_steps_trained": 476000, "num_agent_steps_sampled": 1904000, "num_agent_steps_trained": 1904000}, "done": false, "training_iteration": 119, "trial_id": "86f16_00000", "date": "2024-08-08_16-40-10", "timestamp": 1723149610, "time_this_iter_s": 11.221511840820312, "time_total_s": 1634.501383304596, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x309c74b80>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1634.501383304596, "iterations_since_restore": 119, "perf": {"cpu_util_percent": 28.025000000000002, "ram_util_percent": 76.61875}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5141209499897264, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.842926166201314, "policy_loss": -0.017610506890903075, "vf_loss": 1.8598274970308264, "vf_explained_var": 1.035260815992423e-07, "kl": 0.007091726319697346, "entropy": 0.398218332135931, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 336990.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.276681363147994, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.750154153505961, "policy_loss": -0.025953805550428418, "vf_loss": 2.7746487156798443, "vf_explained_var": 0.0781267074868083, "kl": 0.007296181939655579, "entropy": 0.9496093422795335, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 114720.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 480000, "num_env_steps_trained": 480000, "num_agent_steps_sampled": 1920000, "num_agent_steps_trained": 1920000}, "env_runners": {"episode_reward_max": 134.61179654049164, "episode_reward_min": -27.90245843628549, "episode_reward_mean": 12.322124304826994, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -77.32610163733433}, "policy_reward_max": {"adversary_policy": 70.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 7.592592592592593, "agent_policy": -10.455653472950784}, "custom_metrics": {}, "hist_stats": {"episode_reward": [19.009508800224218, 79.37158265450572, -0.0070309542115876145, 0.0, -0.19083898591726323, 39.67876423096032, -26.13634365074887, 0.0, -7.363533350112407, 0.0, 0.0, 0.0, 0.0, 40.0, 0.0, -2.518235813604292, 39.66872352497917, -0.8766860370198626, -1.0332845274951974, 20.0, 19.230017062471056, -2.143883019236309, 0.0, 0.0, 0.0, 20.0, 0.0, -4.777486409876758, 0.0, -0.3803710052846443, 0.0, 0.0, 0.0, 72.67389836266567, 60.0, -4.003190581199162, -9.724439256305327, 0.0, 0.0, 0.0, 37.25802856530429, -27.90245843628549, -12.128854073684895, -2.037370487621931, -0.06796544239106361, -24.159088616013214, 55.39023418102789, 0.0, 38.39247446942768, 0.0, -2.166324955922322, 0.0, 0.0, 3.9612312019177036, 26.64527786622317, 60.0, 80.0, 0.0, -3.3589184953928117, 0.0, -11.091424278800497, 0.0, 39.99829791979424, -0.7849554276286352, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.56248345565784, 20.0, 0.0, 26.547223818167048, 0.0, 20.0, 40.0, 117.67056552017141, 60.0, 27.885379323148634, -1.6095482148332851, 0.0, 0.0, -17.35753050496676, 20.0, -8.801396337885791, -5.819292714087862, 40.0, 60.0, 0.0, 0.0, 134.61179654049164, -8.9817317448874, -8.187681337073906, 0.0, -9.112966148378591, -13.271479489963818, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, -10.195074518316353, 59.63616395343642, 59.93207132901068, 51.14415544030894, 0.0, -5.313424717250243, -0.17898008281460598, -0.32660459179621015, 40.0, 40.0, 0.0, 20.0, 39.903020162428945, 19.35790006339256, -3.8689478706305467, 0.0, 0.0, -0.2342353412396181, -1.394782990540182, 40.0, 0.0, 0.0, 0.0, 15.08678433961137, -4.349861008139638, -0.5865054466541397, 0.0, 38.8812131712503, 56.76432658043945, 20.0, -0.2597499066663522, 0.0, -0.22640697064284176, -2.5334471383568222, 0.0, 20.0, 0.0, 26.461382029826723, 0.0, 60.0, 0.0, -14.833587740843479, 0.0, 0.0, 20.0, 60.0, 0.0, 0.0, 0.0, -6.595499363486949, 0.0, 0.0, 59.05497614716887, 40.0, 0.0, -18.320610546369, 8.947842637832373, 40.0, 7.67084256070563], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 60.0, 60.0, 60.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0], "policy_agent_policy_reward": [-10.990491199775782, -40.62841734549429, -0.0070309542115876145, 0.0, -0.19083898591726323, -20.32123576903968, -26.13634365074887, 0.0, -7.363533350112407, 0.0, 0.0, 0.0, 0.0, -20.0, 0.0, -2.518235813604292, -20.33127647502083, -0.8766860370198626, -1.0332845274951974, -10.0, -10.769982937528946, -2.143883019236309, 0.0, 0.0, 0.0, -10.0, 0.0, -4.777486409876758, 0.0, -0.3803710052846443, 0.0, 0.0, 0.0, -77.32610163733433, -30.0, -4.003190581199162, -9.724439256305327, 0.0, 0.0, 0.0, -22.741971434695706, -27.90245843628549, -12.128854073684895, -2.037370487621931, -0.06796544239106361, -24.159088616013214, -34.609765818972114, 0.0, -21.607525530572314, 0.0, -2.166324955922322, 0.0, 0.0, -26.0387687980823, -33.354722133776825, -30.0, -40.0, 0.0, -3.3589184953928117, 0.0, -11.091424278800497, 0.0, -20.00170208020576, -0.7849554276286352, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -59.43751654434217, -10.0, 0.0, -33.45277618183295, 0.0, -10.0, -20.0, -62.32943447982857, -30.0, -32.11462067685137, -1.6095482148332851, 0.0, 0.0, -17.35753050496676, -10.0, -8.801396337885791, -5.819292714087862, -20.0, -30.0, 0.0, 0.0, -75.38820345950836, -8.9817317448874, -8.187681337073906, 0.0, -9.112966148378591, -13.271479489963818, 0.0, 0.0, 0.0, 0.0, 0.0, -30.0, -10.195074518316353, -30.363836046563573, -30.067928670989325, -38.85584455969106, 0.0, -5.313424717250243, -0.17898008281460598, -0.32660459179621015, -20.0, -20.0, 0.0, -10.0, -20.096979837571055, -10.64209993660744, -3.8689478706305467, 0.0, 0.0, -0.2342353412396181, -1.394782990540182, -20.0, 0.0, 0.0, 0.0, -14.913215660388632, -4.349861008139638, -0.5865054466541397, 0.0, -21.1187868287497, -33.235673419560555, -10.0, -0.2597499066663522, 0.0, -0.22640697064284176, -2.5334471383568222, 0.0, -10.0, 0.0, -33.538617970173284, 0.0, -30.0, 0.0, -14.833587740843479, 0.0, 0.0, -10.0, -30.0, 0.0, 0.0, 0.0, -6.595499363486949, 0.0, 0.0, -30.94502385283113, -20.0, 0.0, -18.320610546369, -21.052157362167623, -20.0, -22.32915743929437]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6682746767361329, "mean_inference_ms": 1.1501298323357152, "mean_action_processing_ms": 0.23998212269525482, "mean_env_wait_ms": 0.4968018462560662, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004178359184736087, "StateBufferConnector_ms": 0.0030151119938603152, "ViewRequirementAgentConnector_ms": 0.08578734633363323}, "num_episodes": 162, "episode_return_max": 134.61179654049164, "episode_return_min": -27.90245843628549, "episode_return_mean": 12.322124304826994}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1920000, "num_agent_steps_trained": 1920000, "num_env_steps_sampled": 480000, "num_env_steps_trained": 480000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 357.38067218951903, "num_env_steps_trained_throughput_per_sec": 357.38067218951903, "timesteps_total": 480000, "num_env_steps_sampled_lifetime": 480000, "num_agent_steps_sampled_lifetime": 1920000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1920000, "timers": {"training_iteration_time_ms": 11471.811, "restore_workers_time_ms": 0.013, "training_step_time_ms": 11471.768, "sample_time_ms": 1112.735, "learn_time_ms": 10346.017, "learn_throughput": 386.622, "synch_weights_time_ms": 12.655}, "counters": {"num_env_steps_sampled": 480000, "num_env_steps_trained": 480000, "num_agent_steps_sampled": 1920000, "num_agent_steps_trained": 1920000}, "done": false, "training_iteration": 120, "trial_id": "86f16_00000", "date": "2024-08-08_16-40-22", "timestamp": 1723149622, "time_this_iter_s": 11.198416233062744, "time_total_s": 1645.6997995376587, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x309c74f70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1645.6997995376587, "iterations_since_restore": 120, "perf": {"cpu_util_percent": 29.018749999999997, "ram_util_percent": 76.7875}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5330527946088753, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.844078649274001, "policy_loss": -0.019270980632484145, "vf_loss": 1.8626532946918029, "vf_explained_var": -8.86312613250516e-07, "kl": 0.006963323621799236, "entropy": 0.40494978802001225, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 339810.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.1671702675521374, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.8755525302141907, "policy_loss": -0.0316535756457597, "vf_loss": 2.9051840623219807, "vf_explained_var": 0.059008946145574254, "kl": 0.010110181524485284, "entropy": 0.9403626214712858, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 115680.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 484000, "num_env_steps_trained": 484000, "num_agent_steps_sampled": 1936000, "num_agent_steps_trained": 1936000}, "env_runners": {"episode_reward_max": 154.70473166406452, "episode_reward_min": -29.29922887287681, "episode_reward_mean": 13.461534611944895, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 153, "episodes_timesteps_total": 3825, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -85.29526833593548}, "policy_reward_max": {"adversary_policy": 80.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 7.908496732026144, "agent_policy": -10.263955584133539}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 40.0, 0.0, -1.8752234389917521, 35.01575348145438, 0.8561200481684159, 0.0, 0.0, 60.0, 38.35732648513439, 0.0, -6.20501454235464, 80.0, 0.0, 0.0, 0.0, 40.0, 57.623687625106264, 0.0, 20.0, 20.0, 0.0, -0.3418084328482218, 0.0, 0.0, 11.207156483821068, 80.0, 0.0, -9.090892936530155, 39.298503051205465, 0.0, 0.0, 20.0, 80.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 0.0, -4.912602113423823, 0.0, 80.0, 0.0, 40.0, 40.0, 0.0, 2.802277505566658, 0.0, 0.0, 58.17952722270024, 0.0, 0.0, 0.0, 60.0, 40.0, 20.0, 40.0, 0.0, 40.0, -6.271698450409263, 60.0, 19.838880284822086, -10.224578479939792, 0.0, 0.0, 0.0, 0.0, -0.3438908229542259, -0.27949880338710154, 0.0, -0.21830815328237274, 40.0, 60.0, 40.0, 0.0, 19.734485901076603, 0.0, 0.0, 40.0, 0.0, 20.0, 0.0, 0.0, -11.860828545183463, 0.0, 0.0, 60.0, -1.2700280144254394, -1.227971950957789, -0.6962541971011116, 80.0, 60.0, 0.0, 18.05457413559678, 40.0, 0.0, 80.0, -29.29922887287681, 0.0, -9.369886443084479, 26.31897100558426, 60.0, -5.417214801032038, -19.324945468610256, 0.0, -14.68095828824832, 0.0, 40.0, 0.0, 0.0, -24.542113166554824, -0.2512398659167814, -0.11136584213217726, 0.0, -1.8781648362724812, 0.0, 0.0, -0.22656501680339947, 11.576613487250766, 0.0, -3.3248249745416114, 0.0, 57.15664269787277, 0.0, -19.87952950442928, 0.0, 20.0, -6.853328209344138, -6.491639202059233, -5.21951855519006, -11.819646128701686, -5.214130776772008, -15.487806176034361, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, -2.7642569255851432, 0.0, -6.881150220906992, 154.70473166406452, -15.221779515875198, 14.356310611280211, 59.2171939564209, 80.0, 34.393931653203325, 0.0, 0.0, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 80.0, 80.0, 80.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [0.0, -20.0, 0.0, -1.8752234389917521, -24.984246518545618, -29.143879951831583, 0.0, 0.0, -30.0, -21.642673514865614, 0.0, -6.20501454235464, -40.0, 0.0, 0.0, 0.0, -20.0, -32.376312374893736, 0.0, -10.0, -10.0, 0.0, -0.3418084328482218, 0.0, 0.0, -18.792843516178934, -40.0, 0.0, -9.090892936530155, -20.701496948794535, 0.0, 0.0, -10.0, -40.0, 0.0, 0.0, 0.0, 0.0, 0.0, -20.0, 0.0, -4.912602113423823, 0.0, -40.0, 0.0, -20.0, -20.0, 0.0, -27.19772249443335, 0.0, 0.0, -31.820472777299763, 0.0, 0.0, 0.0, -30.0, -20.0, -10.0, -20.0, 0.0, -20.0, -6.271698450409263, -30.0, -10.161119715177914, -10.224578479939792, 0.0, 0.0, 0.0, 0.0, -0.3438908229542259, -0.27949880338710154, 0.0, -0.21830815328237274, -20.0, -30.0, -20.0, 0.0, -10.265514098923399, 0.0, 0.0, -20.0, 0.0, -10.0, 0.0, 0.0, -11.860828545183463, 0.0, 0.0, -30.0, -1.2700280144254394, -1.227971950957789, -0.6962541971011116, -40.0, -30.0, 0.0, -11.945425864403218, -20.0, 0.0, -40.0, -29.29922887287681, 0.0, -9.369886443084479, -33.68102899441574, -30.0, -5.417214801032038, -19.324945468610256, 0.0, -14.68095828824832, 0.0, -20.0, 0.0, 0.0, -24.542113166554824, -0.2512398659167814, -0.11136584213217726, 0.0, -1.8781648362724812, 0.0, 0.0, -0.22656501680339947, -18.423386512749232, 0.0, -3.3248249745416114, 0.0, -32.84335730212723, 0.0, -19.87952950442928, 0.0, -10.0, -6.853328209344138, -6.491639202059233, -5.21951855519006, -11.819646128701686, -5.214130776772008, -15.487806176034361, 0.0, 0.0, 0.0, 0.0, -10.0, -10.0, -2.7642569255851432, 0.0, -6.881150220906992, -85.29526833593548, -15.221779515875198, -15.643689388719789, -30.782806043579097, -40.0, -25.606068346796672, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6674778729934698, "mean_inference_ms": 1.1487602640185235, "mean_action_processing_ms": 0.23970554374389721, "mean_env_wait_ms": 0.4963827235312797, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0041492624220505255, "StateBufferConnector_ms": 0.003054251078686683, "ViewRequirementAgentConnector_ms": 0.08612660800709444}, "num_episodes": 153, "episode_return_max": 154.70473166406452, "episode_return_min": -29.29922887287681, "episode_return_mean": 13.461534611944895}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1936000, "num_agent_steps_trained": 1936000, "num_env_steps_sampled": 484000, "num_env_steps_trained": 484000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 364.49498281081867, "num_env_steps_trained_throughput_per_sec": 364.49498281081867, "timesteps_total": 484000, "num_env_steps_sampled_lifetime": 484000, "num_agent_steps_sampled_lifetime": 1936000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1936000, "timers": {"training_iteration_time_ms": 11356.822, "restore_workers_time_ms": 0.013, "training_step_time_ms": 11356.779, "sample_time_ms": 1099.597, "learn_time_ms": 10244.342, "learn_throughput": 390.459, "synch_weights_time_ms": 12.438}, "counters": {"num_env_steps_sampled": 484000, "num_env_steps_trained": 484000, "num_agent_steps_sampled": 1936000, "num_agent_steps_trained": 1936000}, "done": false, "training_iteration": 121, "trial_id": "86f16_00000", "date": "2024-08-08_16-40-33", "timestamp": 1723149633, "time_this_iter_s": 10.979995250701904, "time_total_s": 1656.6797947883606, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x309c8b820>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1656.6797947883606, "iterations_since_restore": 121, "perf": {"cpu_util_percent": 27.549999999999997, "ram_util_percent": 76.85}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4921252415693821, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.2302519723878684, "policy_loss": -0.015023681665159735, "vf_loss": 1.244699320281651, "vf_explained_var": -3.3215850803023534e-07, "kl": 0.005763352576141615, "entropy": 0.4166323965534251, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 342630.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.2897741203506787, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.08660188006858, "policy_loss": -0.030238144693915576, "vf_loss": 2.1148512632275622, "vf_explained_var": 0.11127080010871092, "kl": 0.009943772340007505, "entropy": 0.9629523520047466, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 116640.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 488000, "num_env_steps_trained": 488000, "num_agent_steps_sampled": 1952000, "num_agent_steps_trained": 1952000}, "env_runners": {"episode_reward_max": 80.0, "episode_reward_min": -32.99634369798009, "episode_reward_mean": 7.861162493112808, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -40.81876266292469}, "policy_reward_max": {"adversary_policy": 40.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 4.938271604938271, "agent_policy": -6.953652321702007}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, -0.8273567399649018, 40.0, -0.01795250104727475, 0.0, 0.0, 0.0, 0.0, 18.940023292984083, 0.0, -32.99634369798009, 20.0, -1.2723048277452775, 39.98184369666173, 0.0, -2.5925853404863437, 0.0, 0.0, -1.3608237917703214, -5.315164829408583, 0.0, 80.0, 0.0, -20.702146811380796, 0.0, 0.0, 0.0, -5.6275698920260835, 0.0, -4.639631122817108, 0.0, -12.794291515359989, 60.0, -0.12651910349356088, 39.88467999439119, 39.733568228301415, 20.0, -1.789999646820043, -17.929980453762767, 0.0, 0.0, -0.11984829528505214, 5.947360383764625, 0.0, 37.25711361721322, 0.0, -1.3356554159210632, 0.0, -9.37946437802411, -0.5964238404776068, 20.0, 0.0, -4.202067335203189, 40.0, 0.0, -9.334012921500703, 0.0, 19.60296902463408, -4.644426203815351, -11.34967840118686, -1.7407223595944166, -13.04973749255033, 19.835329394136018, 20.0, -1.9678467783137399, 0.0, -4.7694147061116885, -0.009209409083081876, 0.0, 0.0, -4.764448203406696, 0.0, 0.0, 0.0, 37.49629189580821, 0.0, 0.0, 20.0, 0.0, -1.453690639904911, -6.707454038775467, 0.0, 20.0, 20.0, 17.3687961627626, 40.0, 0.0, 40.0, -7.0920392525617295, 0.0, 20.0, 20.0, 0.0, 20.0, 0.0, 19.974162614602136, 0.0, 60.0, 0.0, 0.0, 15.025162766946504, 0.0, 39.85671604434762, 20.0, 0.0, 0.0, 0.0, 0.0, 39.29441187484049, 20.0, 40.0, 40.0, -1.3971744094216665, 0.0, 32.47364861843948, -1.8948527899563439, 0.0, 20.0, 0.0, 49.18123733707531, 0.0, -22.43819429765456, -4.515411572542905, 0.0, -10.989213640704392, 19.000108789081995, 0.0, 20.0, 0.0, 0.0, 40.0, 0.0, -2.9971668663996978, 0.0, 20.0, -3.816363435932196, 79.90945230860444, -1.6301110732195712, -3.9123456162533063, -6.56575392311372, 0.0, -7.461984923635436, 0.0, 80.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.35898146782081364, -0.06426073016528089, 0.0, 80.0, 0.0, 40.0, 0.0, -15.680755910916195, 0.0, 0.0, 0.0, 0.0, -3.023171556805095], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [0.0, -0.8273567399649018, -20.0, -0.01795250104727475, 0.0, 0.0, 0.0, 0.0, -11.059976707015917, 0.0, -32.99634369798009, -10.0, -1.2723048277452775, -20.018156303338277, 0.0, -2.5925853404863437, 0.0, 0.0, -1.3608237917703214, -5.315164829408583, 0.0, -40.0, 0.0, -20.702146811380796, 0.0, 0.0, 0.0, -5.6275698920260835, 0.0, -4.639631122817108, 0.0, -12.794291515359989, -30.0, -0.12651910349356088, -20.11532000560881, -20.266431771698585, -10.0, -1.789999646820043, -17.929980453762767, 0.0, 0.0, -0.11984829528505214, -24.052639616235375, 0.0, -22.74288638278678, 0.0, -1.3356554159210632, 0.0, -9.37946437802411, -0.5964238404776068, -10.0, 0.0, -4.202067335203189, -20.0, 0.0, -9.334012921500703, 0.0, -10.397030975365919, -4.644426203815351, -11.34967840118686, -1.7407223595944166, -13.04973749255033, -10.164670605863982, -10.0, -1.9678467783137399, 0.0, -4.7694147061116885, -0.009209409083081876, 0.0, 0.0, -4.764448203406696, 0.0, 0.0, 0.0, -22.503708104191787, 0.0, 0.0, -10.0, 0.0, -1.453690639904911, -6.707454038775467, 0.0, -10.0, -10.0, -12.6312038372374, -20.0, 0.0, -20.0, -7.0920392525617295, 0.0, -10.0, -10.0, 0.0, -10.0, 0.0, -10.025837385397864, 0.0, -30.0, 0.0, 0.0, -14.974837233053496, 0.0, -20.143283955652375, -10.0, 0.0, 0.0, 0.0, 0.0, -20.70558812515951, -10.0, -20.0, -20.0, -1.3971744094216665, 0.0, -27.52635138156052, -1.8948527899563439, 0.0, -10.0, 0.0, -40.81876266292469, 0.0, -22.43819429765456, -4.515411572542905, 0.0, -10.989213640704392, -10.999891210918005, 0.0, -10.0, 0.0, 0.0, -20.0, 0.0, -2.9971668663996978, 0.0, -10.0, -3.816363435932196, -40.090547691395564, -1.6301110732195712, -3.9123456162533063, -6.56575392311372, 0.0, -7.461984923635436, 0.0, -40.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.35898146782081364, -0.06426073016528089, 0.0, -40.0, 0.0, -20.0, 0.0, -15.680755910916195, 0.0, 0.0, 0.0, 0.0, -3.023171556805095]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6667784624045552, "mean_inference_ms": 1.147362845958481, "mean_action_processing_ms": 0.23943747766240686, "mean_env_wait_ms": 0.4959496459364519, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004124347074532214, "StateBufferConnector_ms": 0.002999217421920211, "ViewRequirementAgentConnector_ms": 0.08506877922717436}, "num_episodes": 162, "episode_return_max": 80.0, "episode_return_min": -32.99634369798009, "episode_return_mean": 7.861162493112808}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1952000, "num_agent_steps_trained": 1952000, "num_env_steps_sampled": 488000, "num_env_steps_trained": 488000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 355.6985332506003, "num_env_steps_trained_throughput_per_sec": 355.6985332506003, "timesteps_total": 488000, "num_env_steps_sampled_lifetime": 488000, "num_agent_steps_sampled_lifetime": 1952000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1952000, "timers": {"training_iteration_time_ms": 11328.771, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11328.728, "sample_time_ms": 1096.074, "learn_time_ms": 10219.898, "learn_throughput": 391.393, "synch_weights_time_ms": 12.337}, "counters": {"num_env_steps_sampled": 488000, "num_env_steps_trained": 488000, "num_agent_steps_sampled": 1952000, "num_agent_steps_trained": 1952000}, "done": false, "training_iteration": 122, "trial_id": "86f16_00000", "date": "2024-08-08_16-40-44", "timestamp": 1723149644, "time_this_iter_s": 11.25102424621582, "time_total_s": 1667.9308190345764, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x309c74d30>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1667.9308190345764, "iterations_since_restore": 122, "perf": {"cpu_util_percent": 28.925, "ram_util_percent": 76.54374999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5033343161410051, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.473167466187308, "policy_loss": -0.017563492213441917, "vf_loss": 1.490008126336632, "vf_explained_var": -7.955529165606127e-07, "kl": 0.007228341627107034, "entropy": 0.3990911031340031, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 345450.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.253440695690612, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.5395205341279508, "policy_loss": -0.03259157038652726, "vf_loss": 2.570453984042009, "vf_explained_var": 0.0842112097889185, "kl": 0.008290569882446466, "entropy": 0.9582793489719431, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 117600.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 492000, "num_env_steps_trained": 492000, "num_agent_steps_sampled": 1968000, "num_agent_steps_trained": 1968000}, "env_runners": {"episode_reward_max": 66.93491965129404, "episode_reward_min": -21.29077036446581, "episode_reward_mean": 9.074924360195174, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -53.06508034870597}, "policy_reward_max": {"adversary_policy": 40.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 5.802469135802469, "agent_policy": -8.332483047212232}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.0, 20.0, -1.208031462815069, -3.8675000976614555, -2.035819814362797, -0.3582211551649084, -0.2309529947024036, -6.509280500887263, 0.0, 0.0, 66.93491965129404, 57.56546274906884, 14.888896197979424, 0.0, 0.0, 0.0, 39.98454977206963, 32.679308328107446, 0.0, 60.0, 38.24393200132089, 0.0, 0.0, 0.0, -2.1005629672444903, -6.402625745023883, 0.0, 0.0, 0.0, -21.29077036446581, 20.0, 0.0, -0.0737189503097857, -2.463149301775961, 20.0, 0.0, 20.0, 0.0, -3.20616725255892, -12.805229547524528, -7.476353024549171, 39.425135153902204, -0.23044359373359025, 20.0, -10.711714960479677, -12.850245518678523, -3.759222245125678, -10.800845021067023, 60.0, 0.0, 0.0, 38.82324586648937, -0.8080229369747272, 0.0, 0.0, 10.001263874077708, -17.504861328642015, -1.3214309403322122, 60.0, 0.0, 60.0, -1.4761875874147767, -5.3472248998800795, 8.635086370273113, 20.0, 0.0, -13.861836720433743, -2.262033857587797, 19.970861357064653, -11.052973381614432, 20.0, 20.0, 0.0, 18.26840553295902, -14.255273796828691, -0.22454032412383862, 0.0, 40.0, 37.51816175586987, 0.0, 39.815099838091655, 0.0, 0.0, 20.0, -2.2108447417549, 55.041708862021814, 39.369537214298944, 0.0, -8.992312107059785, 48.878514999561595, -7.906824225493581, -15.182488425447035, 0.0, 20.0, -14.291223505801673, 20.0, 0.0, 20.0, 20.0, 0.0, 0.0, 0.0, 60.0, 40.0, 0.0, 0.0, 0.0, 15.315957059827806, 0.0, 20.0, -20.008746184691102, 20.0, 0.0, 60.0, 0.0, -4.881195244435581, 20.0, 40.0, -8.65495480765569, -3.209800291839831, 0.0, -0.408381856451665, 21.75903488367737, 0.0, -1.1248248364925295, -16.613404984060505, 60.0, 0.0, 0.0, 40.0, 0.0, 0.0, -0.495704360141076, -0.026906687530441342, -5.389102677852722, -0.1395525107852802, 33.85507647569733, 0.0, 60.0, 40.0, -5.762452514539412, 0.0, 0.0, 0.0, 0.0, -1.1485051674442548, 0.0, 0.0, 0.0, 0.0, -12.258801383164423, 0.0, 0.0, 0.0, 0.0, -0.3464993407680217, 0.0, 20.0, -1.2886454466616992, 0.0, 0.0, 40.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0], "policy_agent_policy_reward": [-20.0, -10.0, -1.208031462815069, -3.8675000976614555, -2.035819814362797, -0.3582211551649084, -0.2309529947024036, -6.509280500887263, 0.0, 0.0, -53.06508034870597, -32.43453725093116, -15.111103802020576, 0.0, 0.0, 0.0, -20.015450227930376, -27.320691671892554, 0.0, -30.0, -21.75606799867911, 0.0, 0.0, 0.0, -2.1005629672444903, -6.402625745023883, 0.0, 0.0, 0.0, -21.29077036446581, -10.0, 0.0, -0.0737189503097857, -2.463149301775961, -10.0, 0.0, -10.0, 0.0, -3.20616725255892, -12.805229547524528, -7.476353024549171, -20.574864846097796, -0.23044359373359025, -10.0, -10.711714960479677, -12.850245518678523, -3.759222245125678, -10.800845021067023, -30.0, 0.0, 0.0, -21.176754133510627, -0.8080229369747272, 0.0, 0.0, -19.998736125922292, -17.504861328642015, -1.3214309403322122, -30.0, 0.0, -30.0, -1.4761875874147767, -5.3472248998800795, -21.36491362972689, -10.0, 0.0, -13.861836720433743, -2.262033857587797, -10.029138642935346, -11.052973381614432, -10.0, -10.0, 0.0, -11.731594467040981, -14.255273796828691, -0.22454032412383862, 0.0, -20.0, -22.481838244130124, 0.0, -20.184900161908345, 0.0, 0.0, -10.0, -2.2108447417549, -34.958291137978186, -20.63046278570106, 0.0, -8.992312107059785, -41.121485000438405, -7.906824225493581, -15.182488425447035, 0.0, -10.0, -14.291223505801673, -10.0, 0.0, -10.0, -10.0, 0.0, 0.0, 0.0, -30.0, -20.0, 0.0, 0.0, 0.0, -14.684042940172187, 0.0, -10.0, -20.008746184691102, -10.0, 0.0, -30.0, 0.0, -4.881195244435581, -10.0, -20.0, -8.65495480765569, -3.209800291839831, 0.0, -0.408381856451665, -38.24096511632263, 0.0, -1.1248248364925295, -16.613404984060505, -30.0, 0.0, 0.0, -20.0, 0.0, 0.0, -0.495704360141076, -0.026906687530441342, -5.389102677852722, -0.1395525107852802, -26.14492352430267, 0.0, -30.0, -20.0, -5.762452514539412, 0.0, 0.0, 0.0, 0.0, -1.1485051674442548, 0.0, 0.0, 0.0, 0.0, -12.258801383164423, 0.0, 0.0, 0.0, 0.0, -0.3464993407680217, 0.0, -10.0, -1.2886454466616992, 0.0, 0.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6660885757354033, "mean_inference_ms": 1.1461543521228321, "mean_action_processing_ms": 0.23927628629840617, "mean_env_wait_ms": 0.4955311350820975, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004060768786771798, "StateBufferConnector_ms": 0.0031987090169647596, "ViewRequirementAgentConnector_ms": 0.08480681313408746}, "num_episodes": 162, "episode_return_max": 66.93491965129404, "episode_return_min": -21.29077036446581, "episode_return_mean": 9.074924360195174}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1968000, "num_agent_steps_trained": 1968000, "num_env_steps_sampled": 492000, "num_env_steps_trained": 492000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 366.59262582981836, "num_env_steps_trained_throughput_per_sec": 366.59262582981836, "timesteps_total": 492000, "num_env_steps_sampled_lifetime": 492000, "num_agent_steps_sampled_lifetime": 1968000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1968000, "timers": {"training_iteration_time_ms": 11269.753, "restore_workers_time_ms": 0.013, "training_step_time_ms": 11269.711, "sample_time_ms": 1096.12, "learn_time_ms": 10160.651, "learn_throughput": 393.676, "synch_weights_time_ms": 12.486}, "counters": {"num_env_steps_sampled": 492000, "num_env_steps_trained": 492000, "num_agent_steps_sampled": 1968000, "num_agent_steps_trained": 1968000}, "done": false, "training_iteration": 123, "trial_id": "86f16_00000", "date": "2024-08-08_16-40-55", "timestamp": 1723149655, "time_this_iter_s": 10.917122840881348, "time_total_s": 1678.8479418754578, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x309c8b8b0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1678.8479418754578, "iterations_since_restore": 123, "perf": {"cpu_util_percent": 28.21875, "ram_util_percent": 76.63125}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.549704121433674, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.4626051543663579, "policy_loss": -0.018254363408199914, "vf_loss": 1.480136303170353, "vf_explained_var": -3.384148820917657e-07, "kl": 0.007232135838747466, "entropy": 0.39164443085802364, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 348270.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.168314963703354, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.3047395402410378, "policy_loss": -0.029306545678021698, "vf_loss": 2.3321020090952516, "vf_explained_var": 0.12631731294095516, "kl": 0.009720383483594806, "entropy": 0.9546590150023501, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 118560.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 496000, "num_env_steps_trained": 496000, "num_agent_steps_sampled": 1984000, "num_agent_steps_trained": 1984000}, "env_runners": {"episode_reward_max": 100.0, "episode_reward_min": -30.35256180177025, "episode_reward_mean": 13.787121360459732, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -55.012546102493275}, "policy_reward_max": {"adversary_policy": 50.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 7.901234567901234, "agent_policy": -9.916582343243974}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 20.0, -0.0014042741013586824, 45.00993084296644, -0.6133845620624201, 98.32585206789997, 0.0, -5.85037783917431, 40.0, 100.0, 40.0, 0.0, 20.0, -0.6960892241455618, 0.0, 39.98978568852478, 37.36564684947025, 40.0, 20.0, 0.0, 40.0, -10.041102749584562, 0.0, 0.0, 100.0, -3.1364274562892875, 11.632783657039086, -0.1689533269328669, 39.94976376959737, 0.0, -0.619801180748285, -0.4752607594138447, 40.0, 0.0, 0.0, 0.0, 60.0, 0.0, 60.0, 60.0, -1.2705285437896652, 17.517268033946205, 65.72818402228827, 0.0, 20.0, 0.0, -0.18745246625495038, 0.0, 20.0, 40.0, 40.0, 0.0, 60.0, 0.0, 60.0, 33.617750674818744, 0.0, 0.0, 45.08942568911914, 0.0, 0.0, 94.98745389750673, 0.0, 0.0, -5.9764976598439095, -8.259765689338135, -0.233219569637394, -19.710447270499607, -1.6737142701164276, 0.0, 80.0, 20.0, 0.0, 0.0, -0.6347049834876928, 0.0, 0.0, 20.0, -7.668333608784089, 0.0, -3.2574978764092988, 0.0, 0.0, 0.0, 15.91699470945607, 0.0, -3.3903555429778285, -2.2153368311322774, -0.8194124988561602, -0.679970048981603, 0.0, -1.1545495898899227, -0.3206773952166353, -3.9530976190427367, 8.637549880013037, -1.8010914385308607, -4.336927986558653, 0.0, -1.9329954929000293, -0.8835914166778958, 0.0, 0.0, 0.0, 0.0, -0.12863357235835315, -3.1395385512063614, 0.0, 20.0, 0.0, 0.0, 0.0, -0.4091018303914107, 0.0, 0.0, 0.0, -9.61499193614869, 14.0796463166737, -4.057560248990005, 60.0, -1.266566356623483, -0.26496257294068015, 0.0, -4.952172032118152, 20.0, 0.0, 33.24059786356271, 0.0, 0.0, 20.0, -10.64638871632953, 0.0, 60.0, 40.0, 0.0, 3.886770718568874, 0.0, -0.3838615563375003, 0.0, 0.0, 0.0, 51.127289683319965, 0.0, -0.06153809214590078, 60.0, 0.0, -30.35256180177025, 24.679651157757903, -0.3223918816586746, -10.248209389189965, 13.721812439649977, 0.0, -1.7013862243185118, 40.0, 60.0, 0.0, 20.0, 60.0, 98.66026324976713, 29.86207311643577, 60.0, 60.0, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [0.0, -10.0, -0.0014042741013586824, -44.99006915703356, -0.6133845620624201, -51.67414793210002, 0.0, -5.85037783917431, -20.0, -50.0, -20.0, 0.0, -10.0, -0.6960892241455618, 0.0, -20.010214311475217, -22.634353150529748, -20.0, -10.0, 0.0, -20.0, -10.041102749584562, 0.0, 0.0, -50.0, -3.1364274562892875, -18.367216342960912, -0.1689533269328669, -20.050236230402632, 0.0, -0.619801180748285, -0.4752607594138447, -20.0, 0.0, 0.0, 0.0, -30.0, 0.0, -30.0, -30.0, -1.2705285437896652, -12.482731966053798, -54.27181597771171, 0.0, -10.0, 0.0, -0.18745246625495038, 0.0, -10.0, -20.0, -20.0, 0.0, -30.0, 0.0, -30.0, -26.382249325181263, 0.0, 0.0, -44.910574310880875, 0.0, 0.0, -55.012546102493275, 0.0, 0.0, -5.9764976598439095, -8.259765689338135, -0.233219569637394, -19.710447270499607, -1.6737142701164276, 0.0, -40.0, -10.0, 0.0, 0.0, -0.6347049834876928, 0.0, 0.0, -10.0, -7.668333608784089, 0.0, -3.2574978764092988, 0.0, 0.0, 0.0, -14.08300529054393, 0.0, -3.3903555429778285, -2.2153368311322774, -0.8194124988561602, -0.679970048981603, 0.0, -1.1545495898899227, -0.3206773952166353, -3.9530976190427367, -21.36245011998696, -1.8010914385308607, -4.336927986558653, 0.0, -1.9329954929000293, -0.8835914166778958, 0.0, 0.0, 0.0, 0.0, -0.12863357235835315, -3.1395385512063614, 0.0, -10.0, 0.0, 0.0, 0.0, -0.4091018303914107, 0.0, 0.0, 0.0, -9.61499193614869, -15.9203536833263, -4.057560248990005, -30.0, -1.266566356623483, -0.26496257294068015, 0.0, -4.952172032118152, -10.0, 0.0, -26.759402136437288, 0.0, 0.0, -10.0, -10.64638871632953, 0.0, -30.0, -20.0, 0.0, -26.11322928143113, 0.0, -0.3838615563375003, 0.0, 0.0, 0.0, -38.872710316680035, 0.0, -0.06153809214590078, -30.0, 0.0, -30.35256180177025, -35.32034884224212, -0.3223918816586746, -10.248209389189965, -16.27818756035002, 0.0, -1.7013862243185118, -20.0, -30.0, 0.0, -10.0, -30.0, -51.33973675023287, -30.13792688356423, -30.0, -30.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6653611948534842, "mean_inference_ms": 1.144877739628823, "mean_action_processing_ms": 0.23901311696252614, "mean_env_wait_ms": 0.49509026879509155, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004004843441056617, "StateBufferConnector_ms": 0.0031884805655773775, "ViewRequirementAgentConnector_ms": 0.08340507377812892}, "num_episodes": 162, "episode_return_max": 100.0, "episode_return_min": -30.35256180177025, "episode_return_mean": 13.787121360459732}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1984000, "num_agent_steps_trained": 1984000, "num_env_steps_sampled": 496000, "num_env_steps_trained": 496000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 350.6113153606509, "num_env_steps_trained_throughput_per_sec": 350.6113153606509, "timesteps_total": 496000, "num_env_steps_sampled_lifetime": 496000, "num_agent_steps_sampled_lifetime": 1984000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1984000, "timers": {"training_iteration_time_ms": 11292.134, "restore_workers_time_ms": 0.013, "training_step_time_ms": 11292.092, "sample_time_ms": 1100.426, "learn_time_ms": 10178.84, "learn_throughput": 392.972, "synch_weights_time_ms": 12.376}, "counters": {"num_env_steps_sampled": 496000, "num_env_steps_trained": 496000, "num_agent_steps_sampled": 1984000, "num_agent_steps_trained": 1984000}, "done": false, "training_iteration": 124, "trial_id": "86f16_00000", "date": "2024-08-08_16-41-07", "timestamp": 1723149667, "time_this_iter_s": 11.413579940795898, "time_total_s": 1690.2615218162537, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad10e790>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1690.2615218162537, "iterations_since_restore": 124, "perf": {"cpu_util_percent": 29.281250000000004, "ram_util_percent": 76.83749999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5059405088054796, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.6795135689754013, "policy_loss": -0.018525459385371323, "vf_loss": 1.6973441192655698, "vf_explained_var": -3.477148975886352e-07, "kl": 0.006949103069088655, "entropy": 0.3949429991925862, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 351090.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.462982490286231, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.7046547188734014, "policy_loss": -0.02923973722596808, "vf_loss": 2.7321969027320545, "vf_explained_var": 0.06174520949522654, "kl": 0.008487806567608482, "entropy": 0.9872871791323026, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 119520.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 500000, "num_env_steps_trained": 500000, "num_agent_steps_sampled": 2000000, "num_agent_steps_trained": 2000000}, "env_runners": {"episode_reward_max": 120.0, "episode_reward_min": -40.324721768458154, "episode_reward_mean": 14.84533704890196, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -68.98091734794617}, "policy_reward_max": {"adversary_policy": 60.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 8.580246913580247, "agent_policy": -10.89540369183878}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-2.8103410993314895, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 75.2425497443631, 16.867534260775454, 118.74080326215181, 0.0, 40.0, 19.574714866755123, -0.24801954868397758, 80.0, 40.0, 0.0, 40.0, 40.0, 0.0, 0.0, -0.5084009180331406, 0.0, 0.0, 80.0, -2.3392091667402326, 56.541029960821675, 0.0, -11.716389044192782, 0.0, 0.0, 40.0, -1.2779380742007584, 0.0, 98.74835390948311, 1.0064036252711188, 0.0, 0.0, 0.0, -1.4085306888747373, -12.58717543742742, 0.0, 60.0, -3.979575631366118, 0.0, 0.0, -5.932094344960799, 0.0, 0.0, 0.0, 0.0, 0.0, -4.316407650345231, 0.0, -0.9751893634263631, 0.0, 24.43468166546494, -3.1627009836391364, 38.57802838777776, 0.0, 0.0, 0.0, 33.62674567086908, 60.0, 0.0, 40.0, 60.0, 0.0, 0.0, -0.4959531531628225, 37.58516301050629, 0.0, 0.0, 0.0, 15.229082718970993, -5.5851476517483984, 0.0, -0.2537599418028269, 20.0, 0.0, 0.0, -0.10098937275541897, 20.0, 0.0, 0.0, 0.0, 20.0, -2.769169001539409, 58.451462002254644, 39.925263477896316, 120.0, 0.0, -0.14666909967099406, 0.0, 17.538660861032994, 0.0, 17.456561876874165, 20.0, 0.0, -2.413645281815099, -0.1949370682528262, 20.0, 20.0, 25.622037165754218, -0.08815054823463453, -2.4101568423279773, 0.0, 60.0, 0.0, 0.0, -3.940591824949018, -0.17444894157462865, 60.0, -9.97256880364116, 17.59682937309873, 0.0, 0.0, 19.347199577916193, 60.0, 0.0, -3.8465379070020402, 0.0, 80.0, -3.0493717630856993, -7.0778168711280935, 60.0, 0.0, 80.0, -0.19860238609876624, 21.396549472429477, -6.280445362417552, 0.0, 111.01908265205383, 38.58560650503488, 12.265653799327863, 0.0, 37.91353297257754, 20.0, -6.328460980586238, 0.0, 32.18845646392982, 19.926412964518097, 120.0, -4.7655747833696145, 80.0, 10.276859074820473, -0.4072928826811373, 0.0, -0.07258990369389262, -40.324721768458154, 0.0, 3.7374767318448816, 0.0, 40.0, -1.4670639311789069, -5.56995497835988, 3.168647409424201, 0.0, 0.0, 19.650187148731767, -18.100375689855618, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-2.8103410993314895, -30.0, 0.0, 0.0, 0.0, 0.0, 0.0, -44.75745025563691, -13.13246573922455, -61.2591967378482, 0.0, -20.0, -10.425285133244873, -0.24801954868397758, -40.0, -20.0, 0.0, -20.0, -20.0, 0.0, 0.0, -0.5084009180331406, 0.0, 0.0, -40.0, -2.3392091667402326, -33.458970039178325, 0.0, -11.716389044192782, 0.0, 0.0, -20.0, -1.2779380742007584, 0.0, -51.251646090516886, -28.993596374728885, 0.0, 0.0, 0.0, -1.4085306888747373, -12.58717543742742, 0.0, -30.0, -3.979575631366118, 0.0, 0.0, -5.932094344960799, 0.0, 0.0, 0.0, 0.0, 0.0, -4.316407650345231, 0.0, -0.9751893634263631, 0.0, -35.56531833453506, -3.1627009836391364, -21.421971612222237, 0.0, 0.0, 0.0, -26.373254329130923, -30.0, 0.0, -20.0, -30.0, 0.0, 0.0, -0.4959531531628225, -22.414836989493708, 0.0, 0.0, 0.0, -14.770917281029, -5.5851476517483984, 0.0, -0.2537599418028269, -10.0, 0.0, 0.0, -0.10098937275541897, -10.0, 0.0, 0.0, 0.0, -10.0, -2.769169001539409, -31.548537997745356, -20.074736522103684, -60.0, 0.0, -0.14666909967099406, 0.0, -12.461339138967007, 0.0, -12.543438123125831, -10.0, 0.0, -2.413645281815099, -0.1949370682528262, -10.0, -10.0, -34.37796283424578, -0.08815054823463453, -2.4101568423279773, 0.0, -30.0, 0.0, 0.0, -3.940591824949018, -0.17444894157462865, -30.0, -9.97256880364116, -12.403170626901272, 0.0, 0.0, -10.652800422083805, -30.0, 0.0, -3.8465379070020402, 0.0, -40.0, -3.0493717630856993, -7.0778168711280935, -30.0, 0.0, -40.0, -0.19860238609876624, -38.603450527570516, -6.280445362417552, 0.0, -68.98091734794617, -21.41439349496512, -17.73434620067214, 0.0, -22.086467027422465, -10.0, -6.328460980586238, 0.0, -57.81154353607017, -10.073587035481905, -60.0, -4.7655747833696145, -40.0, -19.72314092517952, -0.4072928826811373, 0.0, -0.07258990369389262, -40.324721768458154, 0.0, -26.262523268155118, 0.0, -20.0, -1.4670639311789069, -5.56995497835988, -26.831352590575797, 0.0, 0.0, -10.349812851268233, -18.100375689855618, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6648634310893561, "mean_inference_ms": 1.144066593797869, "mean_action_processing_ms": 0.23883910629228158, "mean_env_wait_ms": 0.49491412960298914, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004343706884501893, "StateBufferConnector_ms": 0.0031789879740020373, "ViewRequirementAgentConnector_ms": 0.08877589378827884}, "num_episodes": 162, "episode_return_max": 120.0, "episode_return_min": -40.324721768458154, "episode_return_mean": 14.84533704890196}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2000000, "num_agent_steps_trained": 2000000, "num_env_steps_sampled": 500000, "num_env_steps_trained": 500000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 356.47113629156445, "num_env_steps_trained_throughput_per_sec": 356.47113629156445, "timesteps_total": 500000, "num_env_steps_sampled_lifetime": 500000, "num_agent_steps_sampled_lifetime": 2000000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2000000, "timers": {"training_iteration_time_ms": 11278.166, "restore_workers_time_ms": 0.013, "training_step_time_ms": 11278.124, "sample_time_ms": 1105.456, "learn_time_ms": 10159.838, "learn_throughput": 393.707, "synch_weights_time_ms": 12.379}, "counters": {"num_env_steps_sampled": 500000, "num_env_steps_trained": 500000, "num_agent_steps_sampled": 2000000, "num_agent_steps_trained": 2000000}, "done": false, "training_iteration": 125, "trial_id": "86f16_00000", "date": "2024-08-08_16-41-18", "timestamp": 1723149678, "time_this_iter_s": 11.227210998535156, "time_total_s": 1701.4887328147888, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad10e9d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1701.4887328147888, "iterations_since_restore": 125, "perf": {"cpu_util_percent": 28.48235294117647, "ram_util_percent": 76.84705882352941}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.508596337993517, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.6306916534689302, "policy_loss": -0.017373981681183405, "vf_loss": 1.6474401594899224, "vf_explained_var": 7.955740529594692e-08, "kl": 0.006254764946439327, "entropy": 0.3872560788870703, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 353910.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.2412037044763564, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.5512328375130893, "policy_loss": -0.027300679053587372, "vf_loss": 2.576914269477129, "vf_explained_var": 0.09255305081605911, "kl": 0.008096244976490422, "entropy": 0.9603257795174917, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 120480.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 504000, "num_env_steps_trained": 504000, "num_agent_steps_sampled": 2016000, "num_agent_steps_trained": 2016000}, "env_runners": {"episode_reward_max": 99.23554836096233, "episode_reward_min": -21.786644664706117, "episode_reward_mean": 11.310703504216413, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 153, "episodes_timesteps_total": 3825, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -50.94895548686303}, "policy_reward_max": {"adversary_policy": 50.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 6.73202614379085, "agent_policy": -8.885374927156137}, "custom_metrics": {}, "hist_stats": {"episode_reward": [3.8357071264014353, 0.0, 0.0, 0.0, -1.345415019358679, 0.0, 0.0, 0.0, 40.0, 80.0, -0.554480275704724, 0.0, 0.0, 0.0, 0.0, -21.786644664706117, -2.99741565865806, 0.0, -14.543942288015229, 39.866662818072456, 99.23554836096233, 16.791544553315127, 0.0, 0.0, 40.0, -0.2017754157178231, -1.448056639780262, 40.0, 0.0, 60.0, 0.0, 20.0, 0.0, 32.08372388407835, 0.0, 58.447258848915936, 40.0, -0.862714953175463, -0.0393308956421945, 38.481213784547286, 20.0, -4.230496753419728, 0.0, -9.325826498830429, 19.315222890273358, 49.43662309658007, 19.45025100786122, 0.0, -9.458197086388003, 0.0, -20.100066391280812, 20.0, 0.0, -6.374966570906399, 0.9375684318314619, 0.0, 40.0, 0.0, 0.0, 0.0, 37.75977560094954, -7.926416914518584, -2.9555272651762774, 0.0, 0.0, -4.345739026072179, 0.0, 0.0, 14.841152085947316, 0.0, 0.0, 40.0, 40.0, 0.0, 20.0, -11.52308830322992, -14.343042333028276, 20.0, 5.819692604187435, 0.0, -7.803139855481629, 40.0, 0.0, -14.56178881318878, 0.0, 40.0, 37.98372346402532, 40.0, -0.343761541083184, 20.0, 0.0, 99.05104451313697, 40.0, 0.0, -12.568335735345059, 0.0, 0.0, 0.0, -4.6466189634920685, 40.0, 39.86892289103191, 0.0, 18.831277368971882, 0.0, -0.060875948946012004, 17.6721827354058, 0.0, -0.3171985202814176, 40.0, 60.0, 0.0, 20.0, 20.0, 19.99151355320515, 20.0, 0.0, 0.0, 0.0, -3.7179515394273133, 0.0, -10.68693292636423, 0.0, 0.0, 0.0, 60.0, 0.0, -15.182697542255886, -2.635482500398891, 0.0, -2.3619407647718162, 0.0, 40.0, 12.355372300329908, 20.0, 40.0, 0.0, 0.0, -14.856512371184524, 0.0, -1.2948452570332758, 0.0, 0.0, -4.698686541540534, 58.90694634699924, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 60.0, 40.0, 39.67461965248527], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0], "policy_agent_policy_reward": [-26.164292873598562, 0.0, 0.0, 0.0, -1.345415019358679, 0.0, 0.0, 0.0, -20.0, -40.0, -0.554480275704724, 0.0, 0.0, 0.0, 0.0, -21.786644664706117, -2.99741565865806, 0.0, -14.543942288015229, -20.13333718192754, -50.76445163903767, -13.208455446684871, 0.0, 0.0, -20.0, -0.2017754157178231, -1.448056639780262, -20.0, 0.0, -30.0, 0.0, -10.0, 0.0, -27.916276115921644, 0.0, -31.552741151084064, -20.0, -0.862714953175463, -0.0393308956421945, -21.518786215452714, -10.0, -4.230496753419728, 0.0, -9.325826498830429, -10.684777109726642, -40.56337690341993, -10.54974899213878, 0.0, -9.458197086388003, 0.0, -20.100066391280812, -10.0, 0.0, -6.374966570906399, -29.062431568168535, 0.0, -20.0, 0.0, 0.0, 0.0, -22.240224399050458, -7.926416914518584, -2.9555272651762774, 0.0, 0.0, -4.345739026072179, 0.0, 0.0, -15.158847914052686, 0.0, 0.0, -20.0, -20.0, 0.0, -10.0, -11.52308830322992, -14.343042333028276, -10.0, -24.180307395812566, 0.0, -7.803139855481629, -20.0, 0.0, -14.56178881318878, 0.0, -20.0, -22.016276535974676, -20.0, -0.343761541083184, -10.0, 0.0, -50.94895548686303, -20.0, 0.0, -12.568335735345059, 0.0, 0.0, 0.0, -4.6466189634920685, -20.0, -20.131077108968093, 0.0, -11.168722631028116, 0.0, -0.060875948946012004, -12.327817264594199, 0.0, -0.3171985202814176, -20.0, -30.0, 0.0, -10.0, -10.0, -10.008486446794851, -10.0, 0.0, 0.0, 0.0, -3.7179515394273133, 0.0, -10.68693292636423, 0.0, 0.0, 0.0, -30.0, 0.0, -15.182697542255886, -2.635482500398891, 0.0, -2.3619407647718162, 0.0, -20.0, -17.644627699670092, -10.0, -20.0, 0.0, 0.0, -14.856512371184524, 0.0, -1.2948452570332758, 0.0, 0.0, -4.698686541540534, -31.093053653000755, 0.0, 0.0, 0.0, 0.0, 0.0, -10.0, -30.0, -20.0, -20.32538034751473]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6641198714600225, "mean_inference_ms": 1.142966999775504, "mean_action_processing_ms": 0.23860433059199568, "mean_env_wait_ms": 0.49452224851066634, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004335789898641748, "StateBufferConnector_ms": 0.00303290248696321, "ViewRequirementAgentConnector_ms": 0.08598776424632353}, "num_episodes": 153, "episode_return_max": 99.23554836096233, "episode_return_min": -21.786644664706117, "episode_return_mean": 11.310703504216413}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2016000, "num_agent_steps_trained": 2016000, "num_env_steps_sampled": 504000, "num_env_steps_trained": 504000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 357.2596702635994, "num_env_steps_trained_throughput_per_sec": 357.2596702635994, "timesteps_total": 504000, "num_env_steps_sampled_lifetime": 504000, "num_agent_steps_sampled_lifetime": 2016000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2016000, "timers": {"training_iteration_time_ms": 11195.408, "restore_workers_time_ms": 0.013, "training_step_time_ms": 11195.372, "sample_time_ms": 1104.761, "learn_time_ms": 10077.902, "learn_throughput": 396.908, "synch_weights_time_ms": 12.264}, "counters": {"num_env_steps_sampled": 504000, "num_env_steps_trained": 504000, "num_agent_steps_sampled": 2016000, "num_agent_steps_trained": 2016000}, "done": false, "training_iteration": 126, "trial_id": "86f16_00000", "date": "2024-08-08_16-41-30", "timestamp": 1723149690, "time_this_iter_s": 11.202270984649658, "time_total_s": 1712.6910037994385, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad10ec10>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1712.6910037994385, "iterations_since_restore": 126, "perf": {"cpu_util_percent": 28.299999999999997, "ram_util_percent": 76.9375}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.48828613286217054, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.432737219777513, "policy_loss": -0.017907078260248725, "vf_loss": 1.4499390513550305, "vf_explained_var": 4.603507670950382e-08, "kl": 0.007052443149916195, "entropy": 0.3897262455512446, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 356730.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.216523965758582, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.455420779498915, "policy_loss": -0.028047035920705336, "vf_loss": 2.4815286715825398, "vf_explained_var": 0.13568025001635153, "kl": 0.009695715115194441, "entropy": 0.9808046537761886, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 121440.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 508000, "num_env_steps_trained": 508000, "num_agent_steps_sampled": 2032000, "num_agent_steps_trained": 2032000}, "env_runners": {"episode_reward_max": 120.0, "episode_reward_min": -25.19241386960386, "episode_reward_mean": 8.931111239506633, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -60.0}, "policy_reward_max": {"adversary_policy": 60.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 5.679012345679013, "agent_policy": -8.105925797530404}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-1.1247944263620024, 20.0, 0.0, 0.0, -1.9306029778151268, 20.0, -2.040667731503982, 0.0, 0.0, 36.660641576770686, 0.0, 3.1387463209949766, 20.0, 12.716046488312463, 13.029842847069467, -0.41689000603615356, 0.0, 0.0, -15.958658820121931, -1.2445413390520588, -0.31689183992647085, 40.0, 20.0, 0.0, 38.65759546185552, 0.0, -16.810883496985774, 0.0, -3.2565212513966193, 20.0, 55.87594263249957, 0.0, 19.93959490980614, 40.0, -3.846758167885171, 18.33707669109674, 20.0, -1.9459262875147287, 0.0, -9.62399024074651, 20.0, 0.0, -1.1975592067601226, 20.0, 40.0, 0.0, -5.183997458827362, 0.0, -17.69259177615216, -1.5105429715288055, 0.0, -8.5170833337349, 0.0, 0.0, -0.7577504062203588, 20.0, -0.03663860470814684, -1.3982553697483602, 0.0, -25.19241386960386, 13.512127351966658, -9.19724804644298, -1.103557187436669, 0.0, 49.94889002544837, 0.0, 0.0, 0.0, 14.256986137361444, 0.0, 40.0, -0.17149250664438065, 0.0, 0.0, 0.0, -1.9449420268722528, 40.0, 20.0, 0.0, -0.8424431283838352, -1.0690809306795257, -1.0193069478653438, 13.547085129514969, 0.0, 0.0, 0.0, 0.0, -6.027383826093136, 0.0, 0.0, 0.0, -3.5426559791739223, 20.0, 40.0, 33.72498604733945, 40.0, 0.0, 120.0, -1.5017220877298476, 0.0, 0.0, -13.834636191159145, -7.099138353994976, 0.0, 0.0, -0.8159924669008978, -6.372822383568918, 40.0, -1.6891430049601108, -10.05484092770563, 0.0, -1.6521968913019436, 79.56672501377207, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 60.0, -4.463191798997771, 40.0, 0.0, 80.0, 0.0, 0.0, 0.0, 60.0, 60.0, 0.0, -2.0587169060557073, 0.0, -17.78590371919688, 0.0, -0.5350090510498062, -9.911349063168288, -8.851310103653082, 20.0, 0.0, 60.0, 0.0, 0.0, 19.92868401903324, -4.733365606738435, 0.0, -0.12407451917077927, -10.824652916181584, -11.529826594829123, 0.0, 17.56554657891365, 40.0, 47.04610750827376, -0.5811993521893843, -6.573275383751506, -1.4300374590785092, 60.0, 0.0, 10.706894083191983, 40.0, -0.472413455806715, -3.5026096237348714, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-1.1247944263620024, -10.0, 0.0, 0.0, -1.9306029778151268, -10.0, -2.040667731503982, 0.0, 0.0, -23.339358423229314, 0.0, -26.861253679005024, -10.0, -47.28395351168753, -16.970157152930533, -0.41689000603615356, 0.0, 0.0, -15.958658820121931, -1.2445413390520588, -0.31689183992647085, -20.0, -10.0, 0.0, -21.342404538144482, 0.0, -16.810883496985774, 0.0, -3.2565212513966193, -10.0, -34.12405736750043, 0.0, -10.060405090193859, -20.0, -3.846758167885171, -11.66292330890326, -10.0, -1.9459262875147287, 0.0, -9.62399024074651, -10.0, 0.0, -1.1975592067601226, -10.0, -20.0, 0.0, -5.183997458827362, 0.0, -17.69259177615216, -1.5105429715288055, 0.0, -8.5170833337349, 0.0, 0.0, -0.7577504062203588, -10.0, -0.03663860470814684, -1.3982553697483602, 0.0, -25.19241386960386, -16.48787264803334, -9.19724804644298, -1.103557187436669, 0.0, -40.05110997455162, 0.0, 0.0, 0.0, -15.743013862638556, 0.0, -20.0, -0.17149250664438065, 0.0, 0.0, 0.0, -1.9449420268722528, -20.0, -10.0, 0.0, -0.8424431283838352, -1.0690809306795257, -1.0193069478653438, -16.45291487048503, 0.0, 0.0, 0.0, 0.0, -6.027383826093136, 0.0, 0.0, 0.0, -3.5426559791739223, -10.0, -20.0, -26.275013952660565, -20.0, 0.0, -60.0, -1.5017220877298476, 0.0, 0.0, -13.834636191159145, -7.099138353994976, 0.0, 0.0, -0.8159924669008978, -6.372822383568918, -20.0, -1.6891430049601108, -10.05484092770563, 0.0, -1.6521968913019436, -40.433274986227914, 0.0, 0.0, 0.0, 0.0, 0.0, -20.0, -30.0, -4.463191798997771, -20.0, 0.0, -40.0, 0.0, 0.0, 0.0, -30.0, -30.0, 0.0, -2.0587169060557073, 0.0, -17.78590371919688, 0.0, -0.5350090510498062, -9.911349063168288, -8.851310103653082, -10.0, 0.0, -30.0, 0.0, 0.0, -10.07131598096676, -4.733365606738435, 0.0, -0.12407451917077927, -10.824652916181584, -11.529826594829123, 0.0, -12.43445342108635, -20.0, -42.95389249172625, -0.5811993521893843, -6.573275383751506, -1.4300374590785092, -30.0, 0.0, -19.293105916808017, -20.0, -0.472413455806715, -3.5026096237348714, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6634928373767726, "mean_inference_ms": 1.1419076842880551, "mean_action_processing_ms": 0.2383720987480518, "mean_env_wait_ms": 0.4941653872981203, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004328253828449014, "StateBufferConnector_ms": 0.0031710406880319855, "ViewRequirementAgentConnector_ms": 0.08578455006634747}, "num_episodes": 162, "episode_return_max": 120.0, "episode_return_min": -25.19241386960386, "episode_return_mean": 8.931111239506633}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2032000, "num_agent_steps_trained": 2032000, "num_env_steps_sampled": 508000, "num_env_steps_trained": 508000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 358.194758382417, "num_env_steps_trained_throughput_per_sec": 358.194758382417, "timesteps_total": 508000, "num_env_steps_sampled_lifetime": 508000, "num_agent_steps_sampled_lifetime": 2032000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2032000, "timers": {"training_iteration_time_ms": 11165.532, "restore_workers_time_ms": 0.013, "training_step_time_ms": 11165.496, "sample_time_ms": 1102.337, "learn_time_ms": 10050.41, "learn_throughput": 397.994, "synch_weights_time_ms": 12.301}, "counters": {"num_env_steps_sampled": 508000, "num_env_steps_trained": 508000, "num_agent_steps_sampled": 2032000, "num_agent_steps_trained": 2032000}, "done": false, "training_iteration": 127, "trial_id": "86f16_00000", "date": "2024-08-08_16-41-41", "timestamp": 1723149701, "time_this_iter_s": 11.173985958099365, "time_total_s": 1723.8649897575378, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad11b160>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1723.8649897575378, "iterations_since_restore": 127, "perf": {"cpu_util_percent": 28.493750000000002, "ram_util_percent": 77.09375}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.49197664057954826, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.3937887146540568, "policy_loss": -0.016820793877626566, "vf_loss": 1.409906914830208, "vf_explained_var": -5.41197492721233e-07, "kl": 0.007025921689650544, "entropy": 0.3922928566522632, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 359550.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.1423556472485266, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.095208728623887, "policy_loss": -0.0331525121073355, "vf_loss": 2.126207134251793, "vf_explained_var": 0.09297447428107261, "kl": 0.01077055564129591, "entropy": 0.9501759880532821, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 122400.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 512000, "num_env_steps_trained": 512000, "num_agent_steps_sampled": 2048000, "num_agent_steps_trained": 2048000}, "env_runners": {"episode_reward_max": 92.4309398494711, "episode_reward_min": -19.372051040099095, "episode_reward_mean": 11.507044042655624, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -66.47922831624537}, "policy_reward_max": {"adversary_policy": 50.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 6.728395061728395, "agent_policy": -8.67814114252956}, "custom_metrics": {}, "hist_stats": {"episode_reward": [20.0, 36.53832803654875, 0.0, 0.0, 0.0, 0.0, 20.0, 0.0, 0.0, 79.5464706528853, -13.044684463070467, 40.0, 0.0, 20.0, 59.78880574484941, -0.9045642169031243, 0.0, 0.0, 60.0, -0.9934094028860119, 0.0, -3.263198735690777, 0.0, -1.2341212148631586, 0.0, 0.0, 0.0, 40.0, -1.3802284655562391, 20.0, 40.0, 0.0, 0.0, 60.0, 0.0, -4.678929533640463, 40.0, -0.7492027285953318, 0.0, -1.3599824182844489, -9.115769501471778, -1.416853408120029, 18.37321093386774, 60.0, 46.304293350183436, 0.0, 0.0, 20.0, 60.66182132465129, 0.0, 0.0, 55.80279632174742, 20.0, 20.0, 18.507533661965212, -0.04053607876516874, 0.0, 80.0, -5.745028570417326, 0.0, -15.764718536641896, -14.621017473064441, -1.2232855735383674, 0.0, 0.0, -1.3295763766106306, -13.676340118544896, -3.563809097262296, 0.0, -6.809505981717324, -7.340811765412758, 0.0, 0.0, -0.6587255722904861, -0.6407110198390265, 0.0, -4.1788711121998805, -8.909338097045223, 0.0, 0.0, -0.6972655755729296, 0.0, 39.62391119230561, 0.0, 40.0, 20.0, 0.0, 83.5207716837546, -3.0686162151131757, 0.0, 12.710236055759939, 0.0, 0.0, 0.0, 0.0, 19.849382200568357, 0.0, -1.2584260213622656, 0.0, 20.0, 20.0, 0.0, 60.0, 51.163333490593686, -11.226117671141576, 38.83866839867365, 0.0, 0.0, -0.9949740476182112, 0.0, 92.4309398494711, 0.0, 0.0, 55.37089903068083, 0.0, 0.0, 20.0, 0.0, 0.0, 0.0, 0.0, -1.9079766087245051, 60.0, 5.586971671286513, 0.0, 0.0, 58.33062314772807, 0.0, 40.0, 10.06946487002335, 20.0, -16.25524199574033, 0.0, -0.7964980753442119, 20.0, -0.9171375304148421, 60.0, -0.8318864231292733, 0.0, 0.0, 3.8960572612350286, 20.0, 0.0, -2.367906448188685, 20.0, -0.3904682089418432, 0.0, 0.0, 0.0, 0.0, 0.0, 80.0, 0.0, -0.045598644745626915, -19.372051040099095, 0.0, 60.0, 0.0, 80.0, 0.0, 0.0, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-10.0, -23.461671963451252, 0.0, 0.0, 0.0, 0.0, -10.0, 0.0, 0.0, -40.4535293471147, -13.044684463070467, -20.0, 0.0, -10.0, -30.211194255150584, -0.9045642169031243, 0.0, 0.0, -30.0, -0.9934094028860119, 0.0, -3.263198735690777, 0.0, -1.2341212148631586, 0.0, 0.0, 0.0, -20.0, -1.3802284655562391, -10.0, -20.0, 0.0, 0.0, -30.0, 0.0, -4.678929533640463, -20.0, -0.7492027285953318, 0.0, -1.3599824182844489, -9.115769501471778, -1.416853408120029, -11.62678906613226, -30.0, -43.695706649816564, 0.0, 0.0, -10.0, -59.33817867534868, 0.0, 0.0, -34.197203678252585, -10.0, -10.0, -11.49246633803479, -0.04053607876516874, 0.0, -40.0, -5.745028570417326, 0.0, -15.764718536641896, -14.621017473064441, -1.2232855735383674, 0.0, 0.0, -1.3295763766106306, -13.676340118544896, -3.563809097262296, 0.0, -6.809505981717324, -7.340811765412758, 0.0, 0.0, -0.6587255722904861, -0.6407110198390265, 0.0, -4.1788711121998805, -8.909338097045223, 0.0, 0.0, -0.6972655755729296, 0.0, -20.376088807694387, 0.0, -20.0, -10.0, 0.0, -66.47922831624537, -3.0686162151131757, 0.0, -17.289763944240057, 0.0, 0.0, 0.0, 0.0, -10.150617799431643, 0.0, -1.2584260213622656, 0.0, -10.0, -10.0, 0.0, -30.0, -38.83666650940632, -11.226117671141576, -21.161331601326353, 0.0, 0.0, -0.9949740476182112, 0.0, -57.5690601505289, 0.0, 0.0, -34.62910096931917, 0.0, 0.0, -10.0, 0.0, 0.0, 0.0, 0.0, -1.9079766087245051, -30.0, -24.413028328713487, 0.0, 0.0, -31.669376852271917, 0.0, -20.0, -19.930535129976654, -10.0, -16.25524199574033, 0.0, -0.7964980753442119, -10.0, -0.9171375304148421, -30.0, -0.8318864231292733, 0.0, 0.0, -26.10394273876497, -10.0, 0.0, -2.367906448188685, -10.0, -0.3904682089418432, 0.0, 0.0, 0.0, 0.0, 0.0, -40.0, 0.0, -0.045598644745626915, -19.372051040099095, 0.0, -30.0, 0.0, -40.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6627421941649213, "mean_inference_ms": 1.140653041764817, "mean_action_processing_ms": 0.23810058890773636, "mean_env_wait_ms": 0.49376545589938947, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003941412325258608, "StateBufferConnector_ms": 0.0030033382368676457, "ViewRequirementAgentConnector_ms": 0.08431776070300444}, "num_episodes": 162, "episode_return_max": 92.4309398494711, "episode_return_min": -19.372051040099095, "episode_return_mean": 11.507044042655624}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2048000, "num_agent_steps_trained": 2048000, "num_env_steps_sampled": 512000, "num_env_steps_trained": 512000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 359.1886914631344, "num_env_steps_trained_throughput_per_sec": 359.1886914631344, "timesteps_total": 512000, "num_env_steps_sampled_lifetime": 512000, "num_agent_steps_sampled_lifetime": 2048000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2048000, "timers": {"training_iteration_time_ms": 11166.959, "restore_workers_time_ms": 0.013, "training_step_time_ms": 11166.923, "sample_time_ms": 1101.536, "learn_time_ms": 10052.686, "learn_throughput": 397.904, "synch_weights_time_ms": 12.307}, "counters": {"num_env_steps_sampled": 512000, "num_env_steps_trained": 512000, "num_agent_steps_sampled": 2048000, "num_agent_steps_trained": 2048000}, "done": false, "training_iteration": 128, "trial_id": "86f16_00000", "date": "2024-08-08_16-41-52", "timestamp": 1723149712, "time_this_iter_s": 11.1422598361969, "time_total_s": 1735.0072495937347, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad11b670>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1735.0072495937347, "iterations_since_restore": 128, "perf": {"cpu_util_percent": 30.94375, "ram_util_percent": 77.10624999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4758165162135946, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.5250728230315742, "policy_loss": -0.017946759419571873, "vf_loss": 1.542285387080612, "vf_explained_var": -4.4323028402125585e-08, "kl": 0.00734194506945639, "entropy": 0.3901311372822904, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 362370.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.141642446567615, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.2390938052907585, "policy_loss": -0.028307305471874617, "vf_loss": 2.2658484815309445, "vf_explained_var": 0.058175177313387394, "kl": 0.007763136436605017, "entropy": 0.9349667218203346, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 123360.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 516000, "num_env_steps_trained": 516000, "num_agent_steps_sampled": 2064000, "num_agent_steps_trained": 2064000}, "env_runners": {"episode_reward_max": 114.5501472800161, "episode_reward_min": -52.01104375702215, "episode_reward_mean": 14.649729866003993, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -65.4498527199839}, "policy_reward_max": {"adversary_policy": 60.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 8.209876543209877, "agent_policy": -9.979899763625637}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.0, 39.8164700758607, 0.0, 0.0, 0.0, 59.006032482900935, 80.0, 0.0, -0.32556080918334174, 60.0, 0.0, 0.0, 0.0, 0.0, 40.0, -14.199048530967177, -5.047044575524883, 0.0, 15.213844716747223, 0.0, 18.398393589007522, 55.09470916758397, 0.0, 0.0, 0.0, -1.234072676717065, 20.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.182278303433717, 0.0, -1.542084689725578, 91.8255702767531, 0.0, -0.25053342117903665, -2.562546010850172, 40.0, 0.0, -4.677450998552079, -8.128853399222129, 0.0, 0.0, 80.0, 79.95458427018858, 0.0, 80.0, 15.4923730582213, 60.0, -1.7770414636176002, 0.0, 0.0, 0.0, 17.154397524500766, 0.0, 40.0, 60.0, 114.5501472800161, -2.552764051520956, -2.4393964963315247, 0.0, -10.67609869773344, 0.0, -3.6357682378418037, 0.0, -7.766126484018376, 0.0, 0.0, 40.0, 52.84574904643743, 60.0, 100.0, 60.0, 0.0, 0.0, -0.5609240807972793, 40.0, -1.0325968825819931, -4.831678916811064, -0.18893012563155676, 0.0, 0.0, 20.0, 80.0, 0.0, 0.0, 40.0, -0.7861360836262077, 20.0, 0.0, 20.0, 40.0, 38.08637958880833, -52.01104375702215, 40.0, 0.0, 60.0, 0.0, -7.777103159001355, -6.136971226589729, 0.0, 19.009687450949706, 0.0, -2.30942502260565, 60.0, -3.2463206270235094, 0.0, 0.0, 20.0, -0.7500658088839107, -0.8602929879558219, -0.7530876686787069, -0.20581272287379937, 40.0, 40.0, 0.0, -1.0262751410384063, 0.0, 0.0, 0.0, 80.0, -8.028896096770666, -2.912416317094163, -0.7121353819920939, 60.0, -1.1066536788000692, 20.0, 0.0, 52.55064539106195, 0.0, 0.0, 0.0, -0.6174001670379559, 0.0, 0.0, 78.40807139378703, 40.0, 0.0, -5.2545068353448166, 0.0, 20.0, 0.0, 0.0, -0.35510140480860874, 0.0, 20.0, 0.0, 9.736364696817587, 0.0, 0.0, 0.0, 0.0, 59.79442234193124, 0.0, 20.0, -4.104393499706872, -12.982884347623436, 29.282742412797077, 13.583374314994698], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0], "policy_agent_policy_reward": [-20.0, -20.1835299241393, 0.0, 0.0, 0.0, -30.99396751709906, -40.0, 0.0, -0.32556080918334174, -30.0, 0.0, 0.0, 0.0, 0.0, -20.0, -14.199048530967177, -5.047044575524883, 0.0, -14.786155283252777, 0.0, -41.60160641099247, -34.905290832416036, 0.0, 0.0, 0.0, -1.234072676717065, -10.0, -30.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.182278303433717, 0.0, -1.542084689725578, -58.1744297232469, 0.0, -0.25053342117903665, -2.562546010850172, -20.0, 0.0, -4.677450998552079, -8.128853399222129, 0.0, 0.0, -40.0, -40.045415729811424, 0.0, -40.0, -14.5076269417787, -30.0, -1.7770414636176002, 0.0, 0.0, 0.0, -12.845602475499238, 0.0, -20.0, -30.0, -65.4498527199839, -2.552764051520956, -2.4393964963315247, 0.0, -10.67609869773344, 0.0, -3.6357682378418037, 0.0, -7.766126484018376, 0.0, 0.0, -20.0, -37.15425095356257, -30.0, -50.0, -30.0, 0.0, 0.0, -0.5609240807972793, -20.0, -1.0325968825819931, -4.831678916811064, -0.18893012563155676, 0.0, 0.0, -10.0, -40.0, 0.0, 0.0, -20.0, -0.7861360836262077, -10.0, 0.0, -10.0, -20.0, -21.913620411191665, -52.01104375702215, -20.0, 0.0, -30.0, 0.0, -7.777103159001355, -6.136971226589729, 0.0, -10.990312549050294, 0.0, -2.30942502260565, -30.0, -3.2463206270235094, 0.0, 0.0, -10.0, -0.7500658088839107, -0.8602929879558219, -0.7530876686787069, -0.20581272287379937, -20.0, -20.0, 0.0, -1.0262751410384063, 0.0, 0.0, 0.0, -40.0, -8.028896096770666, -2.912416317094163, -0.7121353819920939, -30.0, -1.1066536788000692, -10.0, 0.0, -37.44935460893806, 0.0, 0.0, 0.0, -0.6174001670379559, 0.0, 0.0, -41.59192860621298, -20.0, 0.0, -5.2545068353448166, 0.0, -10.0, 0.0, 0.0, -0.35510140480860874, 0.0, -10.0, 0.0, -20.26363530318242, 0.0, 0.0, 0.0, 0.0, -30.205577658068766, 0.0, -10.0, -4.104393499706872, -12.982884347623436, -30.717257587202926, -16.4166256850053]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6621283951197229, "mean_inference_ms": 1.139559012104894, "mean_action_processing_ms": 0.23782001861517074, "mean_env_wait_ms": 0.4934099075156928, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004059664997053735, "StateBufferConnector_ms": 0.0031464629703097874, "ViewRequirementAgentConnector_ms": 0.08464271639600213}, "num_episodes": 162, "episode_return_max": 114.5501472800161, "episode_return_min": -52.01104375702215, "episode_return_mean": 14.649729866003993}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2064000, "num_agent_steps_trained": 2064000, "num_env_steps_sampled": 516000, "num_env_steps_trained": 516000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 358.09474193615796, "num_env_steps_trained_throughput_per_sec": 358.09474193615796, "timesteps_total": 516000, "num_env_steps_sampled_lifetime": 516000, "num_agent_steps_sampled_lifetime": 2064000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2064000, "timers": {"training_iteration_time_ms": 11162.31, "restore_workers_time_ms": 0.013, "training_step_time_ms": 11162.274, "sample_time_ms": 1103.624, "learn_time_ms": 10045.694, "learn_throughput": 398.181, "synch_weights_time_ms": 12.551}, "counters": {"num_env_steps_sampled": 516000, "num_env_steps_trained": 516000, "num_agent_steps_sampled": 2064000, "num_agent_steps_trained": 2064000}, "done": false, "training_iteration": 129, "trial_id": "86f16_00000", "date": "2024-08-08_16-42-04", "timestamp": 1723149724, "time_this_iter_s": 11.181227207183838, "time_total_s": 1746.1884768009186, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3aca40d30>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1746.1884768009186, "iterations_since_restore": 129, "perf": {"cpu_util_percent": 30.0875, "ram_util_percent": 77.7125}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5134564371977715, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.2822816349513142, "policy_loss": -0.018381230853925665, "vf_loss": 1.2999963061183903, "vf_explained_var": -9.98906209959206e-08, "kl": 0.0066655746825683175, "entropy": 0.37867449697450545, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 365190.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.4251827004055184, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.434945556645592, "policy_loss": -0.03478120243914115, "vf_loss": 2.467880354076624, "vf_explained_var": 0.08219998888671398, "kl": 0.00923205764077416, "entropy": 0.9586716038485368, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 124320.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 520000, "num_env_steps_trained": 520000, "num_agent_steps_sampled": 2080000, "num_agent_steps_trained": 2080000}, "env_runners": {"episode_reward_max": 80.0, "episode_reward_min": -34.461577074048506, "episode_reward_mean": 9.258918353463292, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 157, "episodes_timesteps_total": 3925, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -62.044859472843214}, "policy_reward_max": {"adversary_policy": 40.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 5.923566878980892, "agent_policy": -8.511782283479382}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.048261110817701125, -1.248346235225778, 0.0, -9.282148301218925, -0.387925391986198, 20.0, 40.0, 0.0, -32.43629413087705, 58.52259482304002, -3.919933376912046, 60.0, 75.83452007205238, 0.0, 27.955140527156782, 0.0, -1.8234526625479797, 60.0, 40.0, 0.0, 0.0, -0.8448610135257384, -0.5467938301595932, 0.0, -9.847587383200995, 40.0, 0.0, 0.0, 7.028732318632435, -0.006931170522969099, 0.0, 0.0, 0.0, -1.7573106156149498, 0.0, -2.3252927403288193, 54.37961705652982, 35.31602970074086, 0.0, -0.49239034122237735, 20.0, 0.0, 0.0, 19.954483430150624, 0.0, 56.008444749014565, 80.0, 0.0, 0.0, 0.0, 0.0, -34.461577074048506, 0.0, -0.301018985183682, 57.99936631613815, 17.273998687296388, -2.5842754917316584, 0.0, 0.0, 16.5797142960811, -0.6376019128359101, 19.90626693933406, 0.0, 0.0, 0.0, 0.0, -1.172159061379966, 40.0, -0.07959556544625102, 20.0, -4.782595642065507, 20.0, 0.0, 0.0, 0.0, 0.0, -1.5808537017438085, 19.305022255234988, -0.8301790282704546, 0.0, 0.0, 0.0, 18.711372406445886, 19.689060429178138, 17.0825344883404, 40.0, -25.215415696845838, -0.7548423612269761, 0.0, 0.0, 0.0, -1.4715848493573602, 0.0, 0.0, -9.265953354173948, 0.0, 40.0, 18.678828386620978, 40.0, 0.0, 56.31917942646341, 49.58463518952875, 0.0, 20.0, 60.0, 20.0, 40.0, 0.0, -10.003424426457778, 20.0, -7.13337754885303, 0.0, -7.770545265305301, 0.0, -3.130080517756743, 0.0, 0.0, 0.0, -0.155136094601398, -8.5622169562953, 0.0, 0.0, -21.744445097144027, 0.0, 20.0, -7.829893617712619, 0.0, -0.921199040226095, -10.292958398955975, 34.41575675213972, -6.747387079363045, 40.0, 60.0, 0.0, 35.0943300978764, 0.0, -9.051021813715096, -22.534432975744675, 0.0, 20.0, 0.0, 0.0, 0.0, 40.0, -0.671246699255329, 80.0, 0.0, 0.0, -4.600408232754402, -26.96472695500828, 20.0, 0.0, 0.0, -5.77176510663889, 0.0, 0.0, 40.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0], "policy_agent_policy_reward": [-0.048261110817701125, -1.248346235225778, 0.0, -9.282148301218925, -0.387925391986198, -10.0, -20.0, 0.0, -32.43629413087705, -31.477405176959977, -3.919933376912046, -30.0, -44.16547992794763, 0.0, -62.044859472843214, 0.0, -1.8234526625479797, -30.0, -20.0, 0.0, 0.0, -0.8448610135257384, -0.5467938301595932, 0.0, -9.847587383200995, -20.0, 0.0, 0.0, -22.971267681367568, -0.006931170522969099, 0.0, 0.0, 0.0, -1.7573106156149498, 0.0, -2.3252927403288193, -35.6203829434702, -24.683970299259144, 0.0, -0.49239034122237735, -10.0, 0.0, 0.0, -10.045516569849378, 0.0, -33.991555250985435, -40.0, 0.0, 0.0, 0.0, 0.0, -34.461577074048506, 0.0, -0.301018985183682, -32.00063368386185, -12.726001312703612, -2.5842754917316584, 0.0, 0.0, -13.420285703918895, -0.6376019128359101, -10.093733060665942, 0.0, 0.0, 0.0, 0.0, -1.172159061379966, -20.0, -0.07959556544625102, -10.0, -4.782595642065507, -10.0, 0.0, 0.0, 0.0, 0.0, -1.5808537017438085, -10.694977744765016, -0.8301790282704546, 0.0, 0.0, 0.0, -11.288627593554114, -10.310939570821859, -12.917465511659596, -20.0, -25.215415696845838, -0.7548423612269761, 0.0, 0.0, 0.0, -1.4715848493573602, 0.0, 0.0, -9.265953354173948, 0.0, -20.0, -11.321171613379022, -20.0, 0.0, -33.6808205735366, -40.41536481047125, 0.0, -10.0, -30.0, -10.0, -20.0, 0.0, -10.003424426457778, -10.0, -7.13337754885303, 0.0, -7.770545265305301, 0.0, -3.130080517756743, 0.0, 0.0, 0.0, -0.155136094601398, -8.5622169562953, 0.0, 0.0, -21.744445097144027, 0.0, -10.0, -7.829893617712619, 0.0, -0.921199040226095, -10.292958398955975, -25.58424324786028, -6.747387079363045, -20.0, -30.0, 0.0, -24.9056699021236, 0.0, -9.051021813715096, -22.534432975744675, 0.0, -10.0, 0.0, 0.0, 0.0, -20.0, -0.671246699255329, -40.0, 0.0, 0.0, -4.600408232754402, -26.96472695500828, -10.0, 0.0, 0.0, -5.77176510663889, 0.0, 0.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6616454669731147, "mean_inference_ms": 1.138721684214702, "mean_action_processing_ms": 0.23764220978404083, "mean_env_wait_ms": 0.49313596841665847, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004090700939202764, "StateBufferConnector_ms": 0.0030841037725946705, "ViewRequirementAgentConnector_ms": 0.08284195213560845}, "num_episodes": 157, "episode_return_max": 80.0, "episode_return_min": -34.461577074048506, "episode_return_mean": 9.258918353463292}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2080000, "num_agent_steps_trained": 2080000, "num_env_steps_sampled": 520000, "num_env_steps_trained": 520000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 356.0878242157318, "num_env_steps_trained_throughput_per_sec": 356.0878242157318, "timesteps_total": 520000, "num_env_steps_sampled_lifetime": 520000, "num_agent_steps_sampled_lifetime": 2080000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2080000, "timers": {"training_iteration_time_ms": 11166.374, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11166.336, "sample_time_ms": 1102.313, "learn_time_ms": 10051.114, "learn_throughput": 397.966, "synch_weights_time_ms": 12.5}, "counters": {"num_env_steps_sampled": 520000, "num_env_steps_trained": 520000, "num_agent_steps_sampled": 2080000, "num_agent_steps_trained": 2080000}, "done": false, "training_iteration": 130, "trial_id": "86f16_00000", "date": "2024-08-08_16-42-15", "timestamp": 1723149735, "time_this_iter_s": 11.239760160446167, "time_total_s": 1757.4282369613647, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad11bb80>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1757.4282369613647, "iterations_since_restore": 130, "perf": {"cpu_util_percent": 27.975, "ram_util_percent": 78.82499999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5179210243654166, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.7492300079012593, "policy_loss": -0.019240666500041723, "vf_loss": 1.7676289154705427, "vf_explained_var": 1.4543956053172443e-07, "kl": 0.00841755600823247, "entropy": 0.39102402382285883, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 368010.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.3781967349350452, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.737282944470644, "policy_loss": -0.030080422534471532, "vf_loss": 2.7656900002310674, "vf_explained_var": 0.10735353815058866, "kl": 0.008366851276463295, "entropy": 0.9557937229673068, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 125280.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 524000, "num_env_steps_trained": 524000, "num_agent_steps_sampled": 2096000, "num_agent_steps_trained": 2096000}, "env_runners": {"episode_reward_max": 100.0, "episode_reward_min": -34.971688860300354, "episode_reward_mean": 10.182903951060608, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 158, "episodes_timesteps_total": 3950, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -50.0}, "policy_reward_max": {"adversary_policy": 50.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 6.2025316455696204, "agent_policy": -8.424690985648253}, "custom_metrics": {}, "hist_stats": {"episode_reward": [39.20742376557728, 40.0, -6.990862662601233, -2.3666830314142553, -5.747183267943542, 0.0, 0.0, -0.12340476067295936, 19.391505541794373, -10.233570026547882, -5.776001200894674, 19.517363434866297, -6.520732101217145, 20.0, 0.0, 38.45445618816211, -5.694558502932718, 17.761433450660398, -1.062150555407112, 40.0, 0.0, 0.0, 45.33588927977511, 0.0, -25.606297627192134, 0.0, 0.0, 0.0, -14.481362322672181, 0.0, 19.818142288385538, -4.595058055773993, 20.0, -10.600954036732915, -1.892509692614427, 0.0, 20.0, 0.0, -2.3148871648974234, 20.0, 0.0, 0.0, 20.0, -1.9455132077322723, 0.0, -8.916561573953423, 12.751836310825237, 16.73668621699432, 0.0, 20.0, -1.2484943214132094, 40.0, 20.0, 0.0, 79.58934195561304, -34.971688860300354, 38.668905283472974, 0.0, -4.734456270160762, 57.66175566431602, 0.0, 0.0, 0.0, 46.23496725164219, 40.0, -0.2097758636181557, 0.0, 0.0, 0.0, 0.0, -0.24617977701314797, 14.215161756608097, 0.0, 0.0, 20.0, 40.0, 35.39155183289646, -0.3571767467512377, 59.878430619688054, 37.02532362514397, 0.0, 20.0, -1.02432326496333, 0.0, 20.0, 0.0, 0.0, -13.827219302933141, -1.3938004790539071, -0.03324191003344579, -2.401769292121579, 0.0, -12.70673604522003, 0.0, 0.0, 20.0, 0.0, 0.0, 20.0, 40.0, -0.011557794318831638, 0.0, 0.0, 40.0, 0.0, 0.0, 16.017960811486347, -6.642224367200403, 20.0, 0.0, 58.39060363582129, 20.0, -3.934972228408121, 20.0, -3.166561838986345, -2.2032335727504204, -8.052040936528169, 60.0, -3.4868091258731164, 40.0, 0.0, 0.0, 40.0, 79.29431308198747, 35.841369796377386, 0.0, -2.5988129493549064, -2.797509162936117, 100.0, 0.0, 0.0, -3.415244701916013, 0.0, 40.0, 0.0, -3.453757402634423, -7.095798338338347, 0.0, 0.0, 40.0, -11.797380530643158, -1.339165433275744, 0.0, 19.91986414067098, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, -0.3127643571311245, 25.912872282440368, 14.365253272814567, -9.021778890204335, 0.0, -1.1308236651618009, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-20.792576234422718, -20.0, -6.990862662601233, -2.3666830314142553, -5.747183267943542, 0.0, 0.0, -0.12340476067295936, -10.608494458205627, -10.233570026547882, -5.776001200894674, -10.482636565133706, -6.520732101217145, -10.0, 0.0, -21.54554381183789, -5.694558502932718, -12.2385665493396, -1.062150555407112, -20.0, 0.0, 0.0, -44.66411072022489, 0.0, -25.606297627192134, 0.0, 0.0, 0.0, -14.481362322672181, 0.0, -10.181857711614464, -4.595058055773993, -10.0, -10.600954036732915, -1.892509692614427, 0.0, -10.0, 0.0, -2.3148871648974234, -10.0, 0.0, 0.0, -10.0, -1.9455132077322723, 0.0, -8.916561573953423, -17.248163689174763, -13.263313783005684, 0.0, -10.0, -1.2484943214132094, -20.0, -10.0, 0.0, -40.41065804438697, -34.971688860300354, -21.33109471652702, 0.0, -4.734456270160762, -32.338244335683974, 0.0, 0.0, 0.0, -43.765032748357825, -20.0, -0.2097758636181557, 0.0, 0.0, 0.0, 0.0, -0.24617977701314797, -15.784838243391905, 0.0, 0.0, -10.0, -20.0, -24.608448167103546, -0.3571767467512377, -30.121569380311946, -22.97467637485603, 0.0, -10.0, -1.02432326496333, 0.0, -10.0, 0.0, 0.0, -13.827219302933141, -1.3938004790539071, -0.03324191003344579, -2.401769292121579, 0.0, -12.70673604522003, 0.0, 0.0, -10.0, 0.0, 0.0, -10.0, -20.0, -0.011557794318831638, 0.0, 0.0, -20.0, 0.0, 0.0, -13.982039188513655, -6.642224367200403, -10.0, 0.0, -31.6093963641787, -10.0, -3.934972228408121, -10.0, -3.166561838986345, -2.2032335727504204, -8.052040936528169, -30.0, -3.4868091258731164, -20.0, 0.0, 0.0, -20.0, -40.70568691801253, -24.158630203622614, 0.0, -2.5988129493549064, -2.797509162936117, -50.0, 0.0, 0.0, -3.415244701916013, 0.0, -20.0, 0.0, -3.453757402634423, -7.095798338338347, 0.0, 0.0, -20.0, -11.797380530643158, -1.339165433275744, 0.0, -10.08013585932902, 0.0, 0.0, 0.0, 0.0, 0.0, -30.0, -30.0, -0.3127643571311245, -34.08712771755963, -15.634746727185433, -9.021778890204335, 0.0, -1.1308236651618009, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6606744694021105, "mean_inference_ms": 1.1369983272579436, "mean_action_processing_ms": 0.23728941409150528, "mean_env_wait_ms": 0.49250733075229514, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004350233681594269, "StateBufferConnector_ms": 0.003108570847330214, "ViewRequirementAgentConnector_ms": 0.0855337969864471}, "num_episodes": 158, "episode_return_max": 100.0, "episode_return_min": -34.971688860300354, "episode_return_mean": 10.182903951060608}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2096000, "num_agent_steps_trained": 2096000, "num_env_steps_sampled": 524000, "num_env_steps_trained": 524000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 354.1904644887305, "num_env_steps_trained_throughput_per_sec": 354.1904644887305, "timesteps_total": 524000, "num_env_steps_sampled_lifetime": 524000, "num_agent_steps_sampled_lifetime": 2096000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2096000, "timers": {"training_iteration_time_ms": 11198.301, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11198.263, "sample_time_ms": 1110.475, "learn_time_ms": 10075.036, "learn_throughput": 397.021, "synch_weights_time_ms": 12.348}, "counters": {"num_env_steps_sampled": 524000, "num_env_steps_trained": 524000, "num_agent_steps_sampled": 2096000, "num_agent_steps_trained": 2096000}, "done": false, "training_iteration": 131, "trial_id": "86f16_00000", "date": "2024-08-08_16-42-27", "timestamp": 1723149747, "time_this_iter_s": 11.299283981323242, "time_total_s": 1768.727520942688, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3aca619d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1768.727520942688, "iterations_since_restore": 131, "perf": {"cpu_util_percent": 28.05294117647059, "ram_util_percent": 79.08235294117647}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5258775550317257, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.5430350993119233, "policy_loss": -0.017450829362331607, "vf_loss": 1.5597850176142463, "vf_explained_var": 2.2370764549742353e-07, "kl": 0.007009086643146875, "entropy": 0.3699147324507118, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 370830.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.264332062130173, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.450853165611625, "policy_loss": -0.029867463798048752, "vf_loss": 2.4790558071186144, "vf_explained_var": 0.09775103032588958, "kl": 0.008324063118583584, "entropy": 0.9613654289394618, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 126240.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 528000, "num_env_steps_trained": 528000, "num_agent_steps_sampled": 2112000, "num_agent_steps_trained": 2112000}, "env_runners": {"episode_reward_max": 100.0, "episode_reward_min": -33.820206183110734, "episode_reward_mean": 11.89191764163459, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -51.53060514277081}, "policy_reward_max": {"adversary_policy": 50.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 6.9753086419753085, "agent_policy": -9.034008284291334}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 20.0, -1.0201849837572063, 40.0, -1.9023511447524655, 0.0, 0.0, -4.763056841478837, 0.0, 0.0, 0.0, 60.0, 39.9068196751453, 20.0, 0.0, 100.0, 0.0, 0.0, 80.0, 40.0, 4.33543619411302, 59.54014331577203, 0.0, -2.937605020276396, 40.0, -10.33793018152597, 40.0, -0.31048883018901297, -10.663642835965096, 0.0, -4.773998860712041, 0.0, -2.192971708033318, -2.1335127151809163, 0.0, 60.0, 39.86225955136041, 39.75096659854521, 0.0, 0.0, 18.909940213803132, 0.0, 0.0, 40.0, 0.0, 0.0, -20.789752741038857, 0.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 0.0, 0.0, 40.0, 4.458712057566529, -1.6454573043368437, -33.820206183110734, -3.3048131102605485, 0.0, -8.6596942061041, -20.89261524054149, 0.0, 0.0, 0.0, -13.373149389583872, 0.0, 20.0, -1.0230016838869527, -1.9125954074685814, -4.650860732342921, 20.0, 0.0, -0.3941876447564441, 0.0, 40.0, 20.0, 40.0, 38.604873591029424, 60.0, -0.4676603872819862, 0.0, 0.0, -11.150127687562971, -5.669400299286917, 40.0, 0.0, -0.6443493193151861, 0.0, -9.0921937452847, -0.22327100923681287, 0.0, 0.0, 0.0, -1.7431742751428025, 40.0, -4.395561090961723, 0.0, -0.8265664416112384, 37.49817106051731, 0.0, -1.5209439661933843, 0.0, 36.21321903533985, 0.0, -13.972826824651705, 19.52063072818653, -1.7634286023143786, 20.0, 0.0, 17.682436456702828, 0.0, 77.87441341475632, 40.0, 40.0, 20.0, -18.33017794938096, 0.0, 0.0, -0.1370876537592558, -6.430360609271332, 0.0, 1.397644710065126, 34.028782207325776, 60.0, 39.543761504206174, 0.0, -0.47076297974609105, 0.0, 40.0, 0.0, -3.9488563104708896, 38.4693948572292, -1.0009272580952844, 0.0, 40.0, 19.03545386041485, 0.0, 39.79430396017841, -0.6370356017209278, 0.0, 40.0, 0.0, 0.0, 60.0, 0.0, 80.0, -0.8311870802013843, 0.0, 40.0, 0.0, -3.1212936840028673, 20.0, 40.0, 60.0, 0.0, -2.057435506658314], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [0.0, 0.0, -10.0, -1.0201849837572063, -20.0, -1.9023511447524655, 0.0, 0.0, -4.763056841478837, 0.0, 0.0, 0.0, -30.0, -20.093180324854703, -10.0, 0.0, -50.0, 0.0, 0.0, -40.0, -20.0, -25.664563805886978, -30.45985668422797, 0.0, -2.937605020276396, -20.0, -10.33793018152597, -20.0, -0.31048883018901297, -10.663642835965096, 0.0, -4.773998860712041, 0.0, -2.192971708033318, -2.1335127151809163, 0.0, -30.0, -20.13774044863959, -20.24903340145479, 0.0, 0.0, -11.090059786196866, 0.0, 0.0, -20.0, 0.0, 0.0, -20.789752741038857, 0.0, -10.0, 0.0, 0.0, 0.0, 0.0, 0.0, -20.0, -20.0, 0.0, 0.0, -20.0, -25.541287942433467, -1.6454573043368437, -33.820206183110734, -3.3048131102605485, 0.0, -8.6596942061041, -20.89261524054149, 0.0, 0.0, 0.0, -13.373149389583872, 0.0, -10.0, -1.0230016838869527, -1.9125954074685814, -4.650860732342921, -10.0, 0.0, -0.3941876447564441, 0.0, -20.0, -10.0, -20.0, -21.395126408970576, -30.0, -0.4676603872819862, 0.0, 0.0, -11.150127687562971, -5.669400299286917, -20.0, 0.0, -0.6443493193151861, 0.0, -9.0921937452847, -0.22327100923681287, 0.0, 0.0, 0.0, -1.7431742751428025, -20.0, -4.395561090961723, 0.0, -0.8265664416112384, -22.501828939482696, 0.0, -1.5209439661933843, 0.0, -23.786780964660146, 0.0, -13.972826824651705, -10.479369271813471, -1.7634286023143786, -10.0, 0.0, -12.317563543297172, 0.0, -42.125586585243674, -20.0, -20.0, -10.0, -18.33017794938096, 0.0, 0.0, -0.1370876537592558, -6.430360609271332, 0.0, -28.602355289934877, -25.97121779267422, -30.0, -20.45623849579383, 0.0, -0.47076297974609105, 0.0, -20.0, 0.0, -3.9488563104708896, -51.53060514277081, -1.0009272580952844, 0.0, -20.0, -10.964546139585146, 0.0, -20.20569603982159, -0.6370356017209278, 0.0, -20.0, 0.0, 0.0, -30.0, 0.0, -40.0, -0.8311870802013843, 0.0, -20.0, 0.0, -3.1212936840028673, -10.0, -20.0, -30.0, 0.0, -2.057435506658314]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6602965665590865, "mean_inference_ms": 1.136268202844885, "mean_action_processing_ms": 0.23713494487945339, "mean_env_wait_ms": 0.4923177598355436, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00459117653929157, "StateBufferConnector_ms": 0.0031226946983808354, "ViewRequirementAgentConnector_ms": 0.08676545119579927}, "num_episodes": 162, "episode_return_max": 100.0, "episode_return_min": -33.820206183110734, "episode_return_mean": 11.89191764163459}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2112000, "num_agent_steps_trained": 2112000, "num_env_steps_sampled": 528000, "num_env_steps_trained": 528000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 339.6648279948888, "num_env_steps_trained_throughput_per_sec": 339.6648279948888, "timesteps_total": 528000, "num_env_steps_sampled_lifetime": 528000, "num_agent_steps_sampled_lifetime": 2112000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2112000, "timers": {"training_iteration_time_ms": 11251.385, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11251.347, "sample_time_ms": 1108.57, "learn_time_ms": 10130.046, "learn_throughput": 394.865, "synch_weights_time_ms": 12.374}, "counters": {"num_env_steps_sampled": 528000, "num_env_steps_trained": 528000, "num_agent_steps_sampled": 2112000, "num_agent_steps_trained": 2112000}, "done": false, "training_iteration": 132, "trial_id": "86f16_00000", "date": "2024-08-08_16-42-39", "timestamp": 1723149759, "time_this_iter_s": 11.782545804977417, "time_total_s": 1780.5100667476654, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3aca61c10>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1780.5100667476654, "iterations_since_restore": 132, "perf": {"cpu_util_percent": 30.088235294117645, "ram_util_percent": 79.28235294117648}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.44636793536603026, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.9406846689945417, "policy_loss": -0.015028392147803918, "vf_loss": 0.9550919769397864, "vf_explained_var": 1.5364048328805478e-07, "kl": 0.0062108521295608145, "entropy": 0.404289070849723, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 373650.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.5884308661023776, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.4249448838333287, "policy_loss": -0.03147448207018897, "vf_loss": 2.4540936486174663, "vf_explained_var": 0.10697141271084547, "kl": 0.011628529874487014, "entropy": 0.956448004146417, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 127200.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 532000, "num_env_steps_trained": 532000, "num_agent_steps_sampled": 2128000, "num_agent_steps_trained": 2128000}, "env_runners": {"episode_reward_max": 100.0, "episode_reward_min": -23.735159890192367, "episode_reward_mean": 5.85647532636991, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -50.0}, "policy_reward_max": {"adversary_policy": 50.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 4.506172839506172, "agent_policy": -7.662043192148606}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, -3.2612318135110363, 38.09770130460112, -9.668185402549351, 0.0, -1.769018803522826, 0.0, 19.219352390674363, -6.498684420779367, -12.984077520792182, 0.0, 0.0, -11.282974738174488, 0.0, 20.0, -0.6754121991057327, 20.0, 0.0, -13.455579852516324, -18.060117669319222, -7.430316708157864, 0.0, 20.0, 0.0, 22.195974828864284, 0.0, -4.680199987879021, 0.0, -14.49768120982534, -1.0817598590840083, -15.58343405782222, -1.2782400941892913, 0.0, 60.0, 20.0, 60.0, 40.0, -1.7535400097690568, 0.0, -3.908854956695169, -2.401534123319416, -9.448006776563108, 0.0, 39.777851762633794, 0.0, 100.0, 0.0, 0.0, 0.0, 0.0, 13.276559451635329, -0.4305055713735295, 0.0, 0.0, 40.0, -13.785505128794684, 0.0, 20.0, 0.0, -0.631072745030643, 0.0, -20.602825966459342, 0.0, -0.29589900038410333, 0.0, 0.0, -23.501819023532878, 20.0, -6.237533904279666, -11.69316989857953, 60.0, 0.0, -2.8257219630306665, -2.9930896844338823, -16.137457846373714, 0.0, 0.0, 16.095425055515804, -1.722408686920771, 0.0, -5.705951973068662, 0.0, 20.0, 0.0, 13.665991392416299, 0.0, 40.0, 17.07044508720779, 60.0, 0.6901561750198097, 32.98156614379233, 0.0, 20.0, -4.1531066464098165, -8.459373782045418, 0.0, -8.844540185195871, 0.0, 20.0, 0.0, 0.0, -8.063927543105741, 17.893047227181334, 0.0, 16.75437151328685, -1.4174012769417144, 0.0, -0.3276158578616284, 0.0, 0.0, 0.0, 0.0, -9.975186365507955, -6.217241338845924, 60.0, 0.0, 0.0, 40.0, -2.998445721161782, -1.3444519037181457, 16.795882691933045, 20.0, -23.735159890192367, -4.930462397974537, 0.0, -11.067873667505639, 40.0, 0.0, 0.0, 59.66248899418343, -12.32031147425062, -0.7479310612919421, 0.0, 40.0, -17.28773069735108, -0.9021667799849775, -12.221531407935807, 0.0, 0.0, 0.0, -2.377526151033739, 0.0, -15.411801708365882, 20.0, -12.803710436814416, 0.0, -14.174689480482593, -4.107789053163616, 0.0, 20.0, 40.0, -1.597091090405569, 80.0, 0.0, -1.4318890320930633, 0.0, 0.0, -0.24397229576262114, 0.0, 0.0, 60.0, -1.983072305780459], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [0.0, -3.2612318135110363, -21.902298695398887, -9.668185402549351, 0.0, -1.769018803522826, 0.0, -10.780647609325637, -6.498684420779367, -12.984077520792182, 0.0, 0.0, -11.282974738174488, 0.0, -10.0, -0.6754121991057327, -10.0, 0.0, -13.455579852516324, -18.060117669319222, -7.430316708157864, 0.0, -10.0, 0.0, -37.80402517113573, 0.0, -4.680199987879021, 0.0, -14.49768120982534, -1.0817598590840083, -15.58343405782222, -1.2782400941892913, 0.0, -30.0, -10.0, -30.0, -20.0, -1.7535400097690568, 0.0, -3.908854956695169, -2.401534123319416, -9.448006776563108, 0.0, -20.222148237366206, 0.0, -50.0, 0.0, 0.0, 0.0, 0.0, -16.723440548364675, -0.4305055713735295, 0.0, 0.0, -20.0, -13.785505128794684, 0.0, -10.0, 0.0, -0.631072745030643, 0.0, -20.602825966459342, 0.0, -0.29589900038410333, 0.0, 0.0, -23.501819023532878, -10.0, -6.237533904279666, -11.69316989857953, -30.0, 0.0, -2.8257219630306665, -2.9930896844338823, -16.137457846373714, 0.0, 0.0, -13.904574944484201, -1.722408686920771, 0.0, -5.705951973068662, 0.0, -10.0, 0.0, -16.3340086075837, 0.0, -20.0, -12.929554912792206, -30.0, -29.309843824980184, -27.018433856207675, 0.0, -10.0, -4.1531066464098165, -8.459373782045418, 0.0, -8.844540185195871, 0.0, -10.0, 0.0, 0.0, -8.063927543105741, -12.106952772818662, 0.0, -13.245628486713144, -1.4174012769417144, 0.0, -0.3276158578616284, 0.0, 0.0, 0.0, 0.0, -9.975186365507955, -6.217241338845924, -30.0, 0.0, 0.0, -20.0, -2.998445721161782, -1.3444519037181457, -13.204117308066955, -10.0, -23.735159890192367, -4.930462397974537, 0.0, -11.067873667505639, -20.0, 0.0, 0.0, -30.337511005816577, -12.32031147425062, -0.7479310612919421, 0.0, -20.0, -17.28773069735108, -0.9021667799849775, -12.221531407935807, 0.0, 0.0, 0.0, -2.377526151033739, 0.0, -15.411801708365882, -10.0, -12.803710436814416, 0.0, -14.174689480482593, -4.107789053163616, 0.0, -10.0, -20.0, -1.597091090405569, -40.0, 0.0, -1.4318890320930633, 0.0, 0.0, -0.24397229576262114, 0.0, 0.0, -30.0, -1.983072305780459]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.659704305835242, "mean_inference_ms": 1.1352205329244367, "mean_action_processing_ms": 0.23689963395704122, "mean_env_wait_ms": 0.4919393993484544, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004427742075037073, "StateBufferConnector_ms": 0.003253972088849103, "ViewRequirementAgentConnector_ms": 0.08533861902025011}, "num_episodes": 162, "episode_return_max": 100.0, "episode_return_min": -23.735159890192367, "episode_return_mean": 5.85647532636991}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2128000, "num_agent_steps_trained": 2128000, "num_env_steps_sampled": 532000, "num_env_steps_trained": 532000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 348.59366592457366, "num_env_steps_trained_throughput_per_sec": 348.59366592457366, "timesteps_total": 532000, "num_env_steps_sampled_lifetime": 532000, "num_agent_steps_sampled_lifetime": 2128000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2128000, "timers": {"training_iteration_time_ms": 11307.723, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11307.685, "sample_time_ms": 1109.498, "learn_time_ms": 10185.563, "learn_throughput": 392.713, "synch_weights_time_ms": 12.303}, "counters": {"num_env_steps_sampled": 532000, "num_env_steps_trained": 532000, "num_agent_steps_sampled": 2128000, "num_agent_steps_trained": 2128000}, "done": false, "training_iteration": 133, "trial_id": "86f16_00000", "date": "2024-08-08_16-42-50", "timestamp": 1723149770, "time_this_iter_s": 11.481250047683716, "time_total_s": 1791.9913167953491, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3aca61ee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1791.9913167953491, "iterations_since_restore": 133, "perf": {"cpu_util_percent": 29.08125, "ram_util_percent": 79.20625000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.44972416578349494, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.2744430789710781, "policy_loss": -0.016365032189472824, "vf_loss": 1.2901060135229259, "vf_explained_var": -6.010346378840453e-07, "kl": 0.007020977668359128, "entropy": 0.4118348945011484, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 376470.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.4547450246910256, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.2135320611763745, "policy_loss": -0.03303454300573018, "vf_loss": 2.2445857936516402, "vf_explained_var": 0.15125951822847128, "kl": 0.00990403653188802, "entropy": 0.9336286295205355, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 128160.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 536000, "num_env_steps_trained": 536000, "num_agent_steps_sampled": 2144000, "num_agent_steps_trained": 2144000}, "env_runners": {"episode_reward_max": 97.83901948454614, "episode_reward_min": -45.580753725811526, "episode_reward_mean": 8.882058393923732, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 157, "episodes_timesteps_total": 3925, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -54.53049195931576}, "policy_reward_max": {"adversary_policy": 50.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 5.923566878980892, "agent_policy": -8.888642243018943}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, -15.364551447772994, 20.0, 0.0, -4.774538156366862, 0.0, 26.973237182675916, -2.732442129118577, -7.276835529968331, 0.0, 0.0, 0.0, 57.94509432945317, -12.173746135689603, 0.0, 40.0, -0.8194632818520953, -8.202802208164648, 19.445203740654406, 0.0, 9.438494392032778, -12.549110630230683, 0.0, 0.0, -9.30687799832414, 0.0, -45.580753725811526, 0.0, 20.0, 20.0, -1.6610231722059354, -8.530697859840346, 0.0, 80.0, 40.0, -2.1658896582064537, 28.864209949806412, 0.0, 0.0, 95.46950804068426, 19.12687808191034, 59.774479510404475, 60.0, 78.58409333969988, 0.0, 20.0, 19.349936325042012, -4.959283790781265, 0.0, 0.0, -16.980978078239644, 0.0, 39.18145999592309, 0.0, -4.682681922246985, 0.0, 0.0, 0.0, 19.692405210912334, 0.0, -0.7570691719098344, 60.0, 0.0, 20.0, -5.199794819006637, 0.0, 16.591081496906224, 20.0, 0.0, -5.493710653270674, -8.824600174697833, 97.83901948454614, 0.0, 20.0, -8.202554779235541, -0.8808260366835907, 0.0, 20.0, 0.0, 19.097532136293818, 0.0, -3.615378362807286, 0.0, 0.0, 17.801356193097515, 0.0, 0.0, 0.0, 60.0, 60.0, 0.0, 0.0, 0.0, 39.76414505031587, -4.516810149961807, 0.0, 74.56861462716654, 0.0, 0.0, 0.0, 0.0, -2.279322925767089, 0.0, 0.0, 40.0, 0.0, -1.1258614486329976, 0.0, -0.1435663128114506, -34.98004032218563, 0.0, 0.0, -7.1556875850766035, -11.9860501080544, 0.0, 12.560815743522554, -0.5498749358403887, 0.0, -9.096509168386833, -1.7648351440666388, 55.082550307576675, 0.0, 0.0, -3.87388163689502, 0.0, 40.0, 0.0, -2.6567599324574322, 0.0, 0.0, 0.0, 20.0, -8.378896799996092, 0.0, -4.4818280141437645, 29.28352295506776, -3.109942699294374, 0.0, -16.103857741874116, 37.262064653915786, 40.0, -0.8469660008557012, 0.0, 0.0, 0.0, -0.8847601471269484, -9.75428873745953, 52.045908949571036, 0.0, 0.0, 3.8950156836773093, 39.271889998487815, 0.0, 0.0, 40.0, 0.0, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [0.0, -15.364551447772994, -10.0, 0.0, -4.774538156366862, 0.0, -33.026762817324084, -2.732442129118577, -7.276835529968331, 0.0, 0.0, 0.0, -32.05490567054682, -12.173746135689603, 0.0, -20.0, -0.8194632818520953, -8.202802208164648, -10.554796259345595, 0.0, -20.56150560796722, -12.549110630230683, 0.0, 0.0, -9.30687799832414, 0.0, -45.580753725811526, 0.0, -10.0, -10.0, -1.6610231722059354, -8.530697859840346, 0.0, -40.0, -20.0, -2.1658896582064537, -31.13579005019358, 0.0, 0.0, -54.53049195931576, -10.873121918089657, -30.225520489595525, -30.0, -41.41590666030013, 0.0, -10.0, -10.650063674957988, -4.959283790781265, 0.0, 0.0, -16.980978078239644, 0.0, -20.818540004076905, 0.0, -4.682681922246985, 0.0, 0.0, 0.0, -10.307594789087666, 0.0, -0.7570691719098344, -30.0, 0.0, -10.0, -5.199794819006637, 0.0, -43.40891850309377, -10.0, 0.0, -5.493710653270674, -8.824600174697833, -52.16098051545386, 0.0, -10.0, -8.202554779235541, -0.8808260366835907, 0.0, -10.0, 0.0, -10.902467863706182, 0.0, -3.615378362807286, 0.0, 0.0, -12.198643806902485, 0.0, 0.0, 0.0, -30.0, -30.0, 0.0, 0.0, 0.0, -20.235854949684132, -4.516810149961807, 0.0, -45.431385372833454, 0.0, 0.0, 0.0, 0.0, -32.27932292576709, 0.0, 0.0, -20.0, 0.0, -1.1258614486329976, 0.0, -0.1435663128114506, -34.98004032218563, 0.0, 0.0, -7.1556875850766035, -11.9860501080544, 0.0, -17.43918425647745, -0.5498749358403887, 0.0, -9.096509168386833, -1.7648351440666388, -34.917449692423325, 0.0, 0.0, -3.87388163689502, 0.0, -20.0, 0.0, -2.6567599324574322, 0.0, 0.0, 0.0, -10.0, -8.378896799996092, 0.0, -4.4818280141437645, -30.71647704493224, -3.109942699294374, 0.0, -16.103857741874116, -22.73793534608421, -20.0, -0.8469660008557012, 0.0, 0.0, 0.0, -0.8847601471269484, -9.75428873745953, -37.954091050428964, 0.0, 0.0, -26.104984316322692, -20.728110001512185, 0.0, 0.0, -20.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6592948568581087, "mean_inference_ms": 1.1344443012571848, "mean_action_processing_ms": 0.23673987481947642, "mean_env_wait_ms": 0.49170948073579873, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0040744520296716385, "StateBufferConnector_ms": 0.0030936708875522493, "ViewRequirementAgentConnector_ms": 0.08253405807883876}, "num_episodes": 157, "episode_return_max": 97.83901948454614, "episode_return_min": -45.580753725811526, "episode_return_mean": 8.882058393923732}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2144000, "num_agent_steps_trained": 2144000, "num_env_steps_sampled": 536000, "num_env_steps_trained": 536000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 358.56064322177156, "num_env_steps_trained_throughput_per_sec": 358.56064322177156, "timesteps_total": 536000, "num_env_steps_sampled_lifetime": 536000, "num_agent_steps_sampled_lifetime": 2144000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2144000, "timers": {"training_iteration_time_ms": 11282.431, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11282.392, "sample_time_ms": 1105.263, "learn_time_ms": 10164.568, "learn_throughput": 393.524, "synch_weights_time_ms": 12.237}, "counters": {"num_env_steps_sampled": 536000, "num_env_steps_trained": 536000, "num_agent_steps_sampled": 2144000, "num_agent_steps_trained": 2144000}, "done": false, "training_iteration": 134, "trial_id": "86f16_00000", "date": "2024-08-08_16-43-02", "timestamp": 1723149782, "time_this_iter_s": 11.162700891494751, "time_total_s": 1803.1540176868439, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x309cc68b0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1803.1540176868439, "iterations_since_restore": 134, "perf": {"cpu_util_percent": 28.243750000000002, "ram_util_percent": 79.21875}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4859536985609126, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.4650246998097034, "policy_loss": -0.018029545700939825, "vf_loss": 1.4823803190009814, "vf_explained_var": -2.2757560648816698e-07, "kl": 0.006739255505393238, "entropy": 0.39173357966521105, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 379290.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.320281905060013, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.4488111520806948, "policy_loss": -0.0279855710939349, "vf_loss": 2.4751742418855427, "vf_explained_var": 0.16531761878480514, "kl": 0.00811237819255884, "entropy": 0.9212132777397831, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 129120.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 540000, "num_env_steps_trained": 540000, "num_agent_steps_sampled": 2160000, "num_agent_steps_trained": 2160000}, "env_runners": {"episode_reward_max": 119.73295129758415, "episode_reward_min": -41.54753154176554, "episode_reward_mean": 9.602223876901334, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -68.42856181110668}, "policy_reward_max": {"adversary_policy": 60.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 6.234567901234568, "agent_policy": -9.10147982680237}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-12.456204414550358, 54.44153036599396, 40.0, 0.0, 119.73295129758415, -14.697440642876234, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 19.546535002966518, 56.255277975039405, 60.0, 111.57143818889332, 39.38784680808901, -1.3423524954803512, -2.1524933874624717, 58.16883377038728, 0.0, 20.0, 0.0, 0.0, -0.015078687274103775, 99.01445609812322, -4.492085575608138, 40.0, 0.0, -5.151107941925322, -0.17343508335984414, 20.0, -13.159572070428958, 0.0, -12.332973453630832, 0.0, 0.0, 20.0, 0.0, -0.3568949503058605, 0.0, 0.0, 0.0, -5.000597570127535, 40.0, 0.0, 80.0, 0.0, -0.38920363708508376, 0.0, -3.1545467137491157, -5.291623729572667, -29.667267009952994, 0.0, 0.0, 18.37742510397997, 0.0, 45.434767835699084, 20.0, 2.8835946645932236, 0.0, 40.0, 0.0, 40.0, 80.0, 17.388453111713513, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, -1.8649908362373935, 57.62606536882455, 40.0, 0.0, 0.0, 20.0, -1.821242949967432, 0.0, 0.0, 0.0, 0.0, 40.0, -0.20805280743010024, 14.140733244982703, -0.03937100451502529, 0.0, 56.82675207319106, 19.511552657446956, 0.0, -10.583933132683782, -6.70091740121417, -15.616068844910659, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, -1.0092157271573465, 20.0, 38.76971109592145, 0.0, 0.0, 0.0, 0.0, -8.602123247453395, 0.0, 0.0, -0.9060646101139158, 33.10394757835651, 0.0, 0.0, 0.0, 0.0, 40.0, -41.54753154176554, -3.8507490723522224, -25.094606728909394, 0.0, 0.0, 0.0, 0.0, -0.10840504218632141, 40.0, -2.713024711221861, 20.0, -9.539527332919594, 20.0, -1.3157111691079126, 19.161178440052005, 40.0, -9.854441179284072, -2.4393306356030764, 20.0, 0.0, 0.0, 20.0, 0.0, -16.55395196579155, -1.1821062914883014, -4.548029678165271, 0.0, -3.5658635857525907, 19.70548769264694, 35.44717372682735, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 0.0, -0.1738822235448445, 0.0, -19.68257610512187, -1.9214194437243126, -35.64918416413703, 0.0, -4.0102452471471866], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-12.456204414550358, -35.55846963400604, -20.0, 0.0, -60.26704870241585, -14.697440642876234, 0.0, 0.0, 0.0, 0.0, 0.0, -20.0, -10.453464997033484, -33.74472202496061, -30.0, -68.42856181110668, -20.612153191910995, -1.3423524954803512, -2.1524933874624717, -61.83116622961272, 0.0, -10.0, 0.0, 0.0, -0.015078687274103775, -50.98554390187678, -4.492085575608138, -20.0, 0.0, -5.151107941925322, -0.17343508335984414, -10.0, -13.159572070428958, 0.0, -12.332973453630832, 0.0, 0.0, -10.0, 0.0, -0.3568949503058605, 0.0, 0.0, 0.0, -5.000597570127535, -20.0, 0.0, -40.0, 0.0, -0.38920363708508376, 0.0, -3.1545467137491157, -5.291623729572667, -29.667267009952994, 0.0, 0.0, -11.62257489602003, 0.0, -44.5652321643009, -10.0, -27.116405335406778, 0.0, -20.0, 0.0, -20.0, -40.0, -12.611546888286485, -10.0, 0.0, 0.0, 0.0, 0.0, 0.0, -10.0, -1.8649908362373935, -32.37393463117545, -20.0, 0.0, 0.0, -10.0, -1.821242949967432, 0.0, 0.0, 0.0, 0.0, -20.0, -0.20805280743010024, -15.859266755017298, -0.03937100451502529, 0.0, -33.17324792680894, -10.488447342553044, 0.0, -10.583933132683782, -6.70091740121417, -15.616068844910659, 0.0, 0.0, 0.0, 0.0, 0.0, -10.0, -1.0092157271573465, -10.0, -21.230288904078545, 0.0, 0.0, 0.0, 0.0, -38.60212324745339, 0.0, 0.0, -0.9060646101139158, -26.896052421643486, 0.0, 0.0, 0.0, 0.0, -20.0, -41.54753154176554, -3.8507490723522224, -25.094606728909394, 0.0, 0.0, 0.0, 0.0, -0.10840504218632141, -20.0, -2.713024711221861, -10.0, -9.539527332919594, -10.0, -1.3157111691079126, -10.838821559947997, -20.0, -9.854441179284072, -2.4393306356030764, -10.0, 0.0, 0.0, -10.0, 0.0, -16.55395196579155, -1.1821062914883014, -4.548029678165271, 0.0, -3.5658635857525907, -10.29451230735306, -24.55282627317265, 0.0, 0.0, 0.0, 0.0, -10.0, -10.0, 0.0, -0.1738822235448445, 0.0, -19.68257610512187, -1.9214194437243126, -35.64918416413703, 0.0, -4.0102452471471866]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6584455498014431, "mean_inference_ms": 1.1329490804148947, "mean_action_processing_ms": 0.2364192807100143, "mean_env_wait_ms": 0.49116351227310934, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003958337100935571, "StateBufferConnector_ms": 0.003039836883544922, "ViewRequirementAgentConnector_ms": 0.08320918789616337}, "num_episodes": 162, "episode_return_max": 119.73295129758415, "episode_return_min": -41.54753154176554, "episode_return_mean": 9.602223876901334}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2160000, "num_agent_steps_trained": 2160000, "num_env_steps_sampled": 540000, "num_env_steps_trained": 540000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 358.70829559286875, "num_env_steps_trained_throughput_per_sec": 358.70829559286875, "timesteps_total": 540000, "num_env_steps_sampled_lifetime": 540000, "num_agent_steps_sampled_lifetime": 2160000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2160000, "timers": {"training_iteration_time_ms": 11275.432, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11275.394, "sample_time_ms": 1102.146, "learn_time_ms": 10160.816, "learn_throughput": 393.669, "synch_weights_time_ms": 12.153}, "counters": {"num_env_steps_sampled": 540000, "num_env_steps_trained": 540000, "num_agent_steps_sampled": 2160000, "num_agent_steps_trained": 2160000}, "done": false, "training_iteration": 135, "trial_id": "86f16_00000", "date": "2024-08-08_16-43-13", "timestamp": 1723149793, "time_this_iter_s": 11.156970024108887, "time_total_s": 1814.3109877109528, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x309cc6940>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1814.3109877109528, "iterations_since_restore": 135, "perf": {"cpu_util_percent": 27.587500000000002, "ram_util_percent": 78.96875}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5387220179411114, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.5058608939884401, "policy_loss": -0.017524847919649793, "vf_loss": 1.5225971483381082, "vf_explained_var": -4.015915782739085e-09, "kl": 0.007885923085441664, "entropy": 0.37803147940348225, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 382110.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.2934323015933233, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.5541697602408626, "policy_loss": -0.030562084039168744, "vf_loss": 2.582521182671189, "vf_explained_var": 0.12273953395585219, "kl": 0.011053240672283712, "entropy": 0.9429949969674151, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 130080.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 544000, "num_env_steps_trained": 544000, "num_agent_steps_sampled": 2176000, "num_agent_steps_trained": 2176000}, "env_runners": {"episode_reward_max": 120.0, "episode_reward_min": -23.857861613200882, "episode_reward_mean": 8.500769147783018, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 158, "episodes_timesteps_total": 3950, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -60.0}, "policy_reward_max": {"adversary_policy": 60.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 5.3164556962025316, "agent_policy": -7.448597940824577}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, -0.5060483660727211, 19.0690026316621, 0.0, 0.0, 0.0, -0.6354027429806863, -3.2513484021680585, 0.0, 0.0, 0.0, 20.0, 40.0, 0.0, 40.0, 40.0, 0.0, 26.807546060478966, -1.995495788968622, 16.907268911597452, -3.0592095924781244, 20.0, 0.0, 0.0, 60.0, 0.0, -1.9440940909681625, 0.0, 0.0, -1.6719544483148485, -8.001539047968407, -5.294276487189611, 0.0, 0.0, 0.0, -0.8988417027653672, 0.0, 0.0, 120.0, -0.08621078959902495, -1.360237530855698, -0.4945200242094461, 0.0, 0.0, -1.9953396402582912, -18.811183679102953, 19.23118687513256, -5.120439624772377, 60.0, -0.045141165905271396, 0.0, 0.0, 20.0, -4.3847620695488025, -8.633895273068097, 20.0, -9.263435551647888, 0.0, -0.7254707301338992, 20.0, 60.0, 0.0, 0.0, 6.983683515025825, 20.0, -0.643878861680458, 0.0, 0.0, 0.0, -9.070906595526596, 19.97863129117751, 0.0, 0.0, -6.35827097660365, 40.0, 60.0, 0.0, 20.0, -2.5476501687147763, 0.0, 0.0, 0.0, 0.0, 40.0, 0.0, 0.0, 0.0, 40.0, -9.122265239517212, 40.0, -23.857861613200882, 19.087466850597977, 0.0, 39.993862949905306, 0.0, 0.0, -0.007562183749940665, -2.4649249326212335, 0.0, 40.0, 0.0, -12.600037979258845, 0.0, 20.0, 0.0, 0.0, 35.70887302395211, 32.76856787528635, 0.0, -0.752596774149451, -7.274938657620762, -1.4100863918829043, 40.0, -0.44243304779050585, 19.439224379567996, -1.6985950010783946, 0.0, 31.13511446640249, 20.0, 0.0, -7.2241454877226206, -0.2921410547948089, 40.0, 20.0, 0.0, -0.6376373319427908, 0.0, 0.0, 49.07470466918584, -8.983615007384833, -1.957265916344182, -6.155785591788141, 20.0, -3.643647593385282, -0.5864907853956847, -17.87637250684512, -12.722215355152688, 0.0, -3.056556840935568, 17.582564115904177, 38.59659086441994, 39.72473342759095, 40.0, 39.78984634909771, -19.584598312742962, 0.0, -0.16813483498036352, -0.2509398568325094, 60.0, 20.0, 9.716552766722128, -6.522479163972993, -2.7992023987592116, 18.832420182152475, -5.131793170139267, -0.900073584523079, -2.3823658901289617, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [0.0, -0.5060483660727211, -10.930997368337898, 0.0, 0.0, 0.0, -0.6354027429806863, -3.2513484021680585, 0.0, 0.0, 0.0, -10.0, -20.0, 0.0, -20.0, -20.0, 0.0, -33.19245393952103, -1.995495788968622, -13.092731088402548, -3.0592095924781244, -10.0, 0.0, 0.0, -30.0, 0.0, -1.9440940909681625, 0.0, 0.0, -1.6719544483148485, -8.001539047968407, -5.294276487189611, 0.0, 0.0, 0.0, -0.8988417027653672, 0.0, 0.0, -60.0, -0.08621078959902495, -1.360237530855698, -0.4945200242094461, 0.0, 0.0, -1.9953396402582912, -18.811183679102953, -10.768813124867439, -5.120439624772377, -30.0, -0.045141165905271396, 0.0, 0.0, -10.0, -4.3847620695488025, -8.633895273068097, -10.0, -9.263435551647888, 0.0, -0.7254707301338992, -10.0, -30.0, 0.0, 0.0, -23.016316484974183, -10.0, -0.643878861680458, 0.0, 0.0, 0.0, -9.070906595526596, -10.02136870882249, 0.0, 0.0, -6.35827097660365, -20.0, -30.0, 0.0, -10.0, -2.5476501687147763, 0.0, 0.0, 0.0, 0.0, -20.0, 0.0, 0.0, 0.0, -20.0, -9.122265239517212, -20.0, -23.857861613200882, -10.912533149402025, 0.0, -20.00613705009469, 0.0, 0.0, -0.007562183749940665, -2.4649249326212335, 0.0, -20.0, 0.0, -12.600037979258845, 0.0, -10.0, 0.0, 0.0, -24.291126976047895, -27.231432124713645, 0.0, -0.752596774149451, -7.274938657620762, -1.4100863918829043, -20.0, -0.44243304779050585, -10.560775620432004, -1.6985950010783946, 0.0, -28.864885533597516, -10.0, 0.0, -7.2241454877226206, -0.2921410547948089, -20.0, -10.0, 0.0, -0.6376373319427908, 0.0, 0.0, -40.92529533081416, -8.983615007384833, -1.957265916344182, -6.155785591788141, -10.0, -3.643647593385282, -0.5864907853956847, -17.87637250684512, -12.722215355152688, 0.0, -3.056556840935568, -12.417435884095823, -21.403409135580066, -20.275266572409052, -20.0, -20.210153650902292, -19.584598312742962, 0.0, -0.16813483498036352, -0.2509398568325094, -30.0, -10.0, -20.283447233277876, -6.522479163972993, -2.7992023987592116, -11.167579817847525, -5.131793170139267, -0.900073584523079, -2.3823658901289617, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6576328367290597, "mean_inference_ms": 1.1316824737231241, "mean_action_processing_ms": 0.23612209136709636, "mean_env_wait_ms": 0.490664719923276, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004426512537123282, "StateBufferConnector_ms": 0.003287082985986637, "ViewRequirementAgentConnector_ms": 0.08359385442130174}, "num_episodes": 158, "episode_return_max": 120.0, "episode_return_min": -23.857861613200882, "episode_return_mean": 8.500769147783018}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2176000, "num_agent_steps_trained": 2176000, "num_env_steps_sampled": 544000, "num_env_steps_trained": 544000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 369.0991617000695, "num_env_steps_trained_throughput_per_sec": 369.0991617000695, "timesteps_total": 544000, "num_env_steps_sampled_lifetime": 544000, "num_agent_steps_sampled_lifetime": 2176000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2176000, "timers": {"training_iteration_time_ms": 11239.518, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11239.481, "sample_time_ms": 1099.574, "learn_time_ms": 10127.516, "learn_throughput": 394.964, "synch_weights_time_ms": 12.111}, "counters": {"num_env_steps_sampled": 544000, "num_env_steps_trained": 544000, "num_agent_steps_sampled": 2176000, "num_agent_steps_trained": 2176000}, "done": false, "training_iteration": 136, "trial_id": "86f16_00000", "date": "2024-08-08_16-43-24", "timestamp": 1723149804, "time_this_iter_s": 10.842065811157227, "time_total_s": 1825.15305352211, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x309cc6e50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1825.15305352211, "iterations_since_restore": 136, "perf": {"cpu_util_percent": 27.84375, "ram_util_percent": 78.875}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.49970741399319457, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.2936781976873992, "policy_loss": -0.017150346100898394, "vf_loss": 1.3101636376998103, "vf_explained_var": -6.845445497661617e-07, "kl": 0.006649059892353988, "entropy": 0.4146698481330635, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 384930.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.2805775520702203, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.283314396161586, "policy_loss": -0.028452081541278554, "vf_loss": 2.3100179315855107, "vf_explained_var": 0.16419854387640953, "kl": 0.008742725597686596, "entropy": 0.9057774101694425, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 131040.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 548000, "num_env_steps_trained": 548000, "num_agent_steps_sampled": 2192000, "num_agent_steps_trained": 2192000}, "env_runners": {"episode_reward_max": 80.0, "episode_reward_min": -28.311561911083366, "episode_reward_mean": 8.01276304332707, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -40.0}, "policy_reward_max": {"adversary_policy": 40.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 5.1234567901234565, "agent_policy": -7.357607327043302}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-6.947219455515007, 0.0, 39.691654088626535, 0.0, 19.82973285091704, 40.0, -12.836118122545605, 0.0, 0.0, -6.37189389527038, 0.0, -2.0979538284814714, -21.426848062782046, 20.0, 0.0, -0.41284831281848344, 0.0, -3.94562604483949, 18.070112964153417, 0.0, 60.0, -0.3620325353842069, 0.0, -4.487281337645701, -0.8503472866757777, -5.166922408973365, 3.307232032078732, 0.0, 40.0, 0.0, 40.0, 33.57301361746248, -0.8462602652482443, 0.0, 0.0, 20.0, 0.0, 60.0, 0.0, 0.0, 0.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 80.0, -25.7732728714384, -9.095076980238256, 0.0, 0.0, 0.0, 20.0, -28.311561911083366, 0.0, 0.0, 0.0, 20.0, 0.0, 0.0, -13.601174740861557, 0.0, 40.0, -4.0696474462116425, 40.0, 0.0, 0.0, -0.04014271801368596, -7.862252454916017, 0.0, -5.38339573183319, -7.76398810558578, 16.738461524433657, 40.0, 0.0, 40.0, -7.388695763049907, 20.0, 0.0, 0.0, -4.7441827021864595, 0.0, 80.0, -10.321915350783085, 0.0, 0.0, -0.37880897257229984, 0.0, 60.0, 58.81440926552821, 15.820119497946997, 20.0, 31.096596895891935, -0.13560387448073752, 28.580734107728368, 0.0, 40.0, 0.0, -2.638605556521973, 20.0, 19.59598231092587, 38.682510852761894, -0.6055212513001562, 0.0, 0.0, 0.0, -16.296982180525966, 39.33757828312956, 0.0, 0.0, 0.0, -5.401678036010468, 20.0, 0.0, -3.44776431557396, 20.0, -0.34551958777416236, -3.4355947241266653, -0.31195972864873855, 0.0, 33.95852644053819, -0.36951504448774153, -8.19589338305605, -5.861509843070195, -4.1657819512411045, -6.942687133595509, -1.2066982729479148, 40.0, 0.0, -8.91292974325151, 20.0, 0.0, -0.6290505215971565, 20.0, 0.0, 12.474702769702779, 0.0, -1.549331922825622, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 40.0, 0.0, 8.814316807429808, 0.0, 33.71332516892546, 0.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 60.0, 0.0, 0.0, 6.906697916793456], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0], "policy_agent_policy_reward": [-6.947219455515007, 0.0, -20.308345911373465, 0.0, -10.170267149082958, -20.0, -12.836118122545605, 0.0, 0.0, -6.37189389527038, 0.0, -2.0979538284814714, -21.426848062782046, -10.0, 0.0, -0.41284831281848344, 0.0, -3.94562604483949, -11.929887035846585, 0.0, -30.0, -0.3620325353842069, 0.0, -4.487281337645701, -0.8503472866757777, -5.166922408973365, -26.69276796792127, 0.0, -20.0, 0.0, -20.0, -26.426986382537525, -0.8462602652482443, 0.0, 0.0, -10.0, 0.0, -30.0, 0.0, 0.0, 0.0, -10.0, 0.0, 0.0, 0.0, 0.0, 0.0, -40.0, -25.7732728714384, -9.095076980238256, 0.0, 0.0, 0.0, -10.0, -28.311561911083366, 0.0, 0.0, 0.0, -10.0, 0.0, 0.0, -13.601174740861557, 0.0, -20.0, -4.0696474462116425, -20.0, 0.0, 0.0, -0.04014271801368596, -7.862252454916017, 0.0, -5.38339573183319, -7.76398810558578, -13.261538475566343, -20.0, 0.0, -20.0, -7.388695763049907, -10.0, 0.0, 0.0, -4.7441827021864595, 0.0, -40.0, -10.321915350783085, 0.0, 0.0, -0.37880897257229984, 0.0, -30.0, -31.1855907344718, -14.179880502053004, -10.0, -28.903403104108072, -0.13560387448073752, -31.419265892271632, 0.0, -20.0, 0.0, -2.638605556521973, -10.0, -10.404017689074129, -21.3174891472381, -0.6055212513001562, 0.0, 0.0, 0.0, -16.296982180525966, -20.66242171687044, 0.0, 0.0, 0.0, -5.401678036010468, -10.0, 0.0, -3.44776431557396, -10.0, -0.34551958777416236, -3.4355947241266653, -0.31195972864873855, 0.0, -26.041473559461803, -0.36951504448774153, -8.19589338305605, -5.861509843070195, -4.1657819512411045, -6.942687133595509, -1.2066982729479148, -20.0, 0.0, -8.91292974325151, -10.0, 0.0, -0.6290505215971565, -10.0, 0.0, -17.525297230297223, 0.0, -1.549331922825622, 0.0, 0.0, 0.0, 0.0, 0.0, -10.0, -20.0, 0.0, -21.185683192570192, 0.0, -26.286674831074542, 0.0, -10.0, 0.0, 0.0, 0.0, 0.0, 0.0, -10.0, -30.0, 0.0, 0.0, -23.09330208320655]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6573338246113426, "mean_inference_ms": 1.1311702047506078, "mean_action_processing_ms": 0.2359958120439068, "mean_env_wait_ms": 0.49051104844302723, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004524949156207803, "StateBufferConnector_ms": 0.003992922512101539, "ViewRequirementAgentConnector_ms": 0.08185123219902132}, "num_episodes": 162, "episode_return_max": 80.0, "episode_return_min": -28.311561911083366, "episode_return_mean": 8.01276304332707}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2192000, "num_agent_steps_trained": 2192000, "num_env_steps_sampled": 548000, "num_env_steps_trained": 548000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 354.8690325496188, "num_env_steps_trained_throughput_per_sec": 354.8690325496188, "timesteps_total": 548000, "num_env_steps_sampled_lifetime": 548000, "num_agent_steps_sampled_lifetime": 2192000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2192000, "timers": {"training_iteration_time_ms": 11249.984, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11249.946, "sample_time_ms": 1101.187, "learn_time_ms": 10136.462, "learn_throughput": 394.615, "synch_weights_time_ms": 12.019}, "counters": {"num_env_steps_sampled": 548000, "num_env_steps_trained": 548000, "num_agent_steps_sampled": 2192000, "num_agent_steps_trained": 2192000}, "done": false, "training_iteration": 137, "trial_id": "86f16_00000", "date": "2024-08-08_16-43-35", "timestamp": 1723149815, "time_this_iter_s": 11.278518199920654, "time_total_s": 1836.4315717220306, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3aca618b0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1836.4315717220306, "iterations_since_restore": 137, "perf": {"cpu_util_percent": 29.387500000000003, "ram_util_percent": 78.9875}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.48656047981575873, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.673765730118075, "policy_loss": -0.017071538622113743, "vf_loss": 1.6900856973431635, "vf_explained_var": -4.959867355671335e-07, "kl": 0.007515740491251198, "entropy": 0.3985394093584507, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 387750.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.2592019997537136, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.5821583098421494, "policy_loss": -0.03294285536103416, "vf_loss": 2.6131582683573167, "vf_explained_var": 0.08738706136743228, "kl": 0.009714491911776823, "entropy": 0.9492359691609938, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 132000.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 552000, "num_env_steps_trained": 552000, "num_agent_steps_sampled": 2208000, "num_agent_steps_trained": 2208000}, "env_runners": {"episode_reward_max": 120.0, "episode_reward_min": -23.800120281832605, "episode_reward_mean": 11.545222698450232, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 157, "episodes_timesteps_total": 3925, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -60.0}, "policy_reward_max": {"adversary_policy": 60.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 7.006369426751593, "agent_policy": -9.473885581804545}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 60.0, -4.229235288704251, -5.889046605351131, 0.0, 0.0, 0.0, 0.0, 0.0, -0.04154180036490929, 20.0, 0.0, -6.510973705283768, 20.0, 78.36558180589682, 40.0, 11.149523402794966, -22.381723015842567, 40.0, -2.781765653492841, 40.0, 0.0, 0.0, 59.091405525938654, 0.0, 20.0, 0.0, 0.0, 32.38230707354004, 18.45708292685687, 0.0, 0.0, 19.36733892129979, -18.798170580329128, -1.030740588134309, 0.0, 120.0, -7.127117601180669, 39.5944088739574, -4.076326332827308, 0.0, -4.523895689532443, -9.318934156036612, -1.041723544818246, 40.0, 0.0, 0.0, -23.800120281832605, 0.0, 0.0, 0.0, 9.316473471747065, 0.0, -2.4497434795252104, -15.292955167166244, 40.0, 20.0, 0.0, -1.897898263610125, 58.63872616744871, 0.0, 16.293235940648238, -0.9303174514951607, 0.0, 0.0, -1.193225257228132, 18.710218367480365, 0.0, 0.0, 0.0, -2.2297499832242194, 0.0, 0.0, 15.379714000608125, 0.0, 0.0, -6.037223149473803, 30.701638256740026, 0.0, 20.0, 100.0, 39.10779008089809, 55.148544925788414, -0.02892037751858867, 60.0, 0.0, 20.0, 20.0, -0.257346545278081, 0.0, -1.3534457994233473, 0.0, -1.2673192690837298, 39.51960606069676, -11.160992021049864, 95.38213849362816, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 80.0, -0.7736911727303775, 0.0, -20.308231674901258, -1.1390465948472361, 60.0, 0.0, 0.0, 20.0, 0.0, -5.959489028566024, 0.0, -1.8983079944175951, -14.398170201951753, 0.0, -4.223026317613481, 60.0, -14.726689394970514, 17.92882092263509, 0.0, 4.363151702262245, 40.0, 120.0, -1.7337013015289282, 14.007954619743423, 40.0, 20.0, 0.0, 0.0, 0.0, 0.0, 39.267034043558326, 37.106021245585865, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, -1.2651691472530446, -0.19873496846465222, 20.0, 0.0, -8.956638867565449, -6.610149955810842, 0.0, -8.02718606452399, 20.0, -1.030891738969174, -0.23357419623387776, -5.400737312280489, 0.0, 20.0, 59.96133262728613, -4.106198259917277], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [0.0, -30.0, -4.229235288704251, -5.889046605351131, 0.0, 0.0, 0.0, 0.0, 0.0, -0.04154180036490929, -10.0, 0.0, -6.510973705283768, -10.0, -41.63441819410317, -20.0, -18.850476597205034, -22.381723015842567, -20.0, -2.781765653492841, -20.0, 0.0, 0.0, -30.90859447406134, 0.0, -10.0, 0.0, 0.0, -27.61769292645996, -11.54291707314313, 0.0, 0.0, -10.632661078700211, -18.798170580329128, -1.030740588134309, 0.0, -60.0, -37.127117601180665, -20.4055911260426, -4.076326332827308, 0.0, -4.523895689532443, -9.318934156036612, -1.041723544818246, -20.0, 0.0, 0.0, -23.800120281832605, 0.0, 0.0, 0.0, -20.683526528252937, 0.0, -2.4497434795252104, -15.292955167166244, -20.0, -10.0, 0.0, -1.897898263610125, -31.361273832551294, 0.0, -13.706764059351762, -0.9303174514951607, 0.0, 0.0, -1.193225257228132, -11.289781632519635, 0.0, 0.0, 0.0, -2.2297499832242194, 0.0, 0.0, -14.620285999391873, 0.0, 0.0, -6.037223149473803, -29.298361743259974, 0.0, -10.0, -50.0, -20.89220991910191, -34.851455074211586, -0.02892037751858867, -30.0, 0.0, -10.0, -10.0, -0.257346545278081, 0.0, -1.3534457994233473, 0.0, -1.2673192690837298, -20.48039393930324, -11.160992021049864, -54.61786150637184, -10.0, 0.0, 0.0, 0.0, 0.0, 0.0, -40.0, -0.7736911727303775, 0.0, -50.30823167490126, -1.1390465948472361, -30.0, 0.0, 0.0, -10.0, 0.0, -5.959489028566024, 0.0, -1.8983079944175951, -14.398170201951753, 0.0, -4.223026317613481, -30.0, -14.726689394970514, -12.07117907736491, 0.0, -25.636848297737753, -20.0, -60.0, -1.7337013015289282, -15.992045380256577, -20.0, -10.0, 0.0, 0.0, 0.0, 0.0, -20.732965956441667, -22.89397875441413, 0.0, -10.0, -10.0, -10.0, 0.0, 0.0, -1.2651691472530446, -0.19873496846465222, -10.0, 0.0, -8.956638867565449, -6.610149955810842, 0.0, -8.02718606452399, -10.0, -1.030891738969174, -0.23357419623387776, -5.400737312280489, 0.0, -10.0, -30.038667372713864, -4.106198259917277]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6570127783983211, "mean_inference_ms": 1.1306008770028733, "mean_action_processing_ms": 0.23589393527318978, "mean_env_wait_ms": 0.49031708039229677, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004243015483686119, "StateBufferConnector_ms": 0.003227914214893511, "ViewRequirementAgentConnector_ms": 0.08579348302950525}, "num_episodes": 157, "episode_return_max": 120.0, "episode_return_min": -23.800120281832605, "episode_return_mean": 11.545222698450232}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2208000, "num_agent_steps_trained": 2208000, "num_env_steps_sampled": 552000, "num_env_steps_trained": 552000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 366.8122228733479, "num_env_steps_trained_throughput_per_sec": 366.8122228733479, "timesteps_total": 552000, "num_env_steps_sampled_lifetime": 552000, "num_agent_steps_sampled_lifetime": 2208000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2208000, "timers": {"training_iteration_time_ms": 11226.839, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11226.802, "sample_time_ms": 1101.501, "learn_time_ms": 10112.783, "learn_throughput": 395.539, "synch_weights_time_ms": 12.237}, "counters": {"num_env_steps_sampled": 552000, "num_env_steps_trained": 552000, "num_agent_steps_sampled": 2208000, "num_agent_steps_trained": 2208000}, "done": false, "training_iteration": 138, "trial_id": "86f16_00000", "date": "2024-08-08_16-43-46", "timestamp": 1723149826, "time_this_iter_s": 10.90960693359375, "time_total_s": 1847.3411786556244, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad3df820>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1847.3411786556244, "iterations_since_restore": 138, "perf": {"cpu_util_percent": 28.30625, "ram_util_percent": 78.98125}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5597097906237798, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.8683256570329057, "policy_loss": -0.02243915024150512, "vf_loss": 1.8899601062772968, "vf_explained_var": 2.0550920608195853e-07, "kl": 0.008046986188807755, "entropy": 0.38040690831047425, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 390570.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.169394525513053, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.4015161018818616, "policy_loss": -0.028431546517822426, "vf_loss": 2.428021072347959, "vf_explained_var": 0.07602928628524144, "kl": 0.00963287804374626, "entropy": 0.9661899711936712, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 132960.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 556000, "num_env_steps_trained": 556000, "num_agent_steps_sampled": 2224000, "num_agent_steps_trained": 2224000}, "env_runners": {"episode_reward_max": 99.61934623558739, "episode_reward_min": -33.16408278448881, "episode_reward_mean": 15.297270335924686, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -51.37200411504128}, "policy_reward_max": {"adversary_policy": 50.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 8.333333333333334, "agent_policy": -9.702729664075314}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-1.6441010267156786, -2.9752023884098193, 0.0, 0.0, 57.54557132707383, 0.0, 0.0, 80.0, 20.0, 38.23603909008702, 0.0, 0.0, 40.0, -3.363565576454379, 60.0, 40.0, -0.2043500047955049, -0.5861682691458991, -1.401944636736977, 99.61934623558739, 0.0, 0.0, 0.0, 0.0, -1.062222215195847, 0.0, 39.7800994918405, 0.0, 40.0, 0.0, -0.6637228699115483, 47.05234466965659, 54.883924550315015, 0.0, -0.3337662240454087, 20.83052654553465, 20.0, -0.6444513673518926, 0.0, 0.0, 60.0, -3.5665070388237528, 40.0, 0.0, -4.941570604359878, 0.0, 0.0, 60.0, -5.008828106647631, 36.64618715127375, 0.0, 0.0, -0.03479973906784006, 0.0, -1.7365497234591365, 40.0, 0.0, -1.658958063448358, 0.0, -0.6670376567166558, 40.0, 40.0, -1.6610012325997825, 0.0, 0.0, 60.0, -1.8732825436752953, 0.0, 0.0, -1.5925106043300763, -1.541181596078488, 20.0, 0.0, 39.86077227207999, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, -6.906833352916511, 40.0, 33.328788304985196, 60.0, -0.026980814767700867, 0.0, 0.0, 60.0, 60.0, -33.16408278448881, 0.0, -0.0015646291347704011, 0.0, 40.0, 0.0, 0.0, 0.0, 60.0, -1.3669138610406617, 40.0, -18.24063964585121, 40.0, 0.0, 0.0, -6.625151973573495, -3.524859161816922, 0.0, 0.0, 0.0, 37.90673287061944, 0.0, -9.954277033817354, -3.0576313987537436, 40.0, -5.092207719335109, 40.0, 60.0, 54.180225270020344, 19.900611991279206, 37.03992574790857, -9.242733971260227, -1.621471843454283, -0.6095008214746866, -2.1894896484153517, 0.0, 0.0, 18.54536277512343, 20.0, 20.0, 0.0, 60.0, 40.0, 0.0, 79.99821022687324, 0.0, -4.90372299160095, 40.0, 40.0, 0.0, 0.0, -0.9419622489428481, 40.0, 0.0, 0.0, 0.0, -1.7276824334297258, 0.0, 40.0, -1.5855441562244477, 0.0, 20.0, 98.62799588495872, 12.897667491951744, 40.0, 40.0, 40.0, 0.0, 0.0, 39.222434500899354, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-1.6441010267156786, -2.9752023884098193, 0.0, 0.0, -32.45442867292617, 0.0, 0.0, -40.0, -10.0, -21.763960909912985, 0.0, 0.0, -20.0, -3.363565576454379, -30.0, -20.0, -0.2043500047955049, -0.5861682691458991, -1.401944636736977, -50.380653764412614, 0.0, 0.0, 0.0, 0.0, -1.062222215195847, 0.0, -20.219900508159498, 0.0, -20.0, 0.0, -0.6637228699115483, -42.947655330343416, -35.11607544968499, 0.0, -0.3337662240454087, -39.16947345446536, -10.0, -0.6444513673518926, 0.0, 0.0, -30.0, -3.5665070388237528, -20.0, 0.0, -4.941570604359878, 0.0, 0.0, -30.0, -5.008828106647631, -23.35381284872625, 0.0, 0.0, -0.03479973906784006, 0.0, -1.7365497234591365, -20.0, 0.0, -1.658958063448358, 0.0, -0.6670376567166558, -20.0, -20.0, -1.6610012325997825, 0.0, 0.0, -30.0, -1.8732825436752953, 0.0, 0.0, -1.5925106043300763, -1.541181596078488, -10.0, 0.0, -20.13922772792001, 0.0, 0.0, 0.0, 0.0, -20.0, -20.0, -20.0, 0.0, -6.906833352916511, -20.0, -26.671211695014808, -30.0, -0.026980814767700867, 0.0, 0.0, -30.0, -30.0, -33.16408278448881, 0.0, -0.0015646291347704011, 0.0, -20.0, 0.0, 0.0, 0.0, -30.0, -1.3669138610406617, -20.0, -18.24063964585121, -20.0, 0.0, 0.0, -6.625151973573495, -3.524859161816922, 0.0, 0.0, 0.0, -22.093267129380557, 0.0, -9.954277033817354, -3.0576313987537436, -20.0, -5.092207719335109, -20.0, -30.0, -35.81977472997965, -10.099388008720792, -22.96007425209143, -9.242733971260227, -1.621471843454283, -0.6095008214746866, -2.1894896484153517, 0.0, 0.0, -11.454637224876569, -10.0, -10.0, 0.0, -30.0, -20.0, 0.0, -40.00178977312677, 0.0, -4.90372299160095, -20.0, -20.0, 0.0, 0.0, -0.9419622489428481, -20.0, 0.0, 0.0, 0.0, -1.7276824334297258, 0.0, -20.0, -1.5855441562244477, 0.0, -10.0, -51.37200411504128, -17.10233250804826, -20.0, -20.0, -20.0, 0.0, 0.0, -20.777565499100646, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6562326526096123, "mean_inference_ms": 1.1292211312020153, "mean_action_processing_ms": 0.2355848284409603, "mean_env_wait_ms": 0.48983848303881505, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004140241646472319, "StateBufferConnector_ms": 0.0030143761340482734, "ViewRequirementAgentConnector_ms": 0.08402194505856361}, "num_episodes": 162, "episode_return_max": 99.61934623558739, "episode_return_min": -33.16408278448881, "episode_return_mean": 15.297270335924686}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2224000, "num_agent_steps_trained": 2224000, "num_env_steps_sampled": 556000, "num_env_steps_trained": 556000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 359.4859089851764, "num_env_steps_trained_throughput_per_sec": 359.4859089851764, "timesteps_total": 556000, "num_env_steps_sampled_lifetime": 556000, "num_agent_steps_sampled_lifetime": 2224000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2224000, "timers": {"training_iteration_time_ms": 11222.517, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11222.479, "sample_time_ms": 1100.851, "learn_time_ms": 10109.285, "learn_throughput": 395.676, "synch_weights_time_ms": 12.039}, "counters": {"num_env_steps_sampled": 556000, "num_env_steps_trained": 556000, "num_agent_steps_sampled": 2224000, "num_agent_steps_trained": 2224000}, "done": false, "training_iteration": 139, "trial_id": "86f16_00000", "date": "2024-08-08_16-43-58", "timestamp": 1723149838, "time_this_iter_s": 11.13409686088562, "time_total_s": 1858.47527551651, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad3e0550>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1858.47527551651, "iterations_since_restore": 139, "perf": {"cpu_util_percent": 31.225, "ram_util_percent": 79.13125}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.49869725900233214, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.4453410710426087, "policy_loss": -0.017575830794887986, "vf_loss": 1.4622857563884546, "vf_explained_var": -4.44900059530921e-07, "kl": 0.006311458505946743, "entropy": 0.38186583068776636, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 393390.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.583083579192559, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.3681827739501995, "policy_loss": -0.0297665834693665, "vf_loss": 2.396325879419843, "vf_explained_var": 0.09610404409468173, "kl": 0.00811740476144583, "entropy": 0.9497562081242601, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 133920.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 560000, "num_env_steps_trained": 560000, "num_agent_steps_sampled": 2240000, "num_agent_steps_trained": 2240000}, "env_runners": {"episode_reward_max": 120.0, "episode_reward_min": -18.13989812575167, "episode_reward_mean": 12.27622168343467, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -60.0}, "policy_reward_max": {"adversary_policy": 60.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 7.407407407407407, "agent_policy": -9.946000538787553}, "custom_metrics": {}, "hist_stats": {"episode_reward": [20.0, 15.338822171146724, -7.819387562275083, 0.0, 0.0, 15.034062387893409, 60.0, 60.0, 20.0, 20.0, -15.791473085051145, 0.0, -1.316331061175624, 0.0, 60.0, 0.0, 36.196955253135926, -1.0755317480595494, 0.0, 0.0, 0.0, 38.75278500727694, -12.403252262863234, 58.83351648075981, 18.603977902079265, 0.0, 38.75878301986926, -14.437739663414007, 120.0, 99.1745894210732, -2.322180724718555, 20.0, 0.0, 0.0, -16.19002747089452, 0.0, 39.83540306972968, 20.0, 0.0, 0.0, 20.0, -13.994397091341881, 20.0, 8.76657667358168, 20.0, 0.0, 0.0, -7.469852442724521, -2.6274897324173407, 0.0, 40.0, 0.0, 40.0, -0.25907414627607595, 0.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.4545103262027559, 20.0, 80.0, -2.7314546421371877, -0.8711962234465576, 18.93565186324446, -3.4666766813330474, 79.6255297124737, 0.0, 54.63066024767103, 19.6190030476207, 11.584838966785528, 0.0, 65.71893398772836, 58.479966626649784, 0.0, 39.634271095183834, 20.0, -3.8147868053367064, -7.464539095418957, -4.686420399877589, -8.823178071748018, -10.651347935244846, 14.508825464990544, -1.544745539810195, 40.0, -0.8445020014935656, -3.0146146918619214, 20.0, 0.0, 19.683600700220484, 0.0, 0.0, -3.157956162234527, 55.22079749923367, -18.13989812575167, -0.5898728108530427, 60.0, 0.0, 7.00702850451323, 60.0, 20.0, 0.0, 0.0, -0.4168346302601622, 0.0, 19.628959349505756, -2.097374175898824, 0.0, -4.7483698950808835, 0.0, -6.506617582025849, -0.40381719393461357, -0.6763754362485774, -1.6029165816888613, 74.37765667402965, 39.507331215216496, 0.0, -5.853954218366756, 0.0, -1.8482518952717173, -1.8492527959304328, 0.0, 0.0, -0.33285923258708494, 0.0, 0.0, 0.0, -10.326300623297435, 0.0, 0.0, 0.0, 14.094737216182708, 0.0, 0.0, 39.824541723741085, 80.0, -1.499739171414468, 41.935390702374455, 0.0, 15.058387618118745, 0.0, 60.0, 0.0, 0.0, 0.0, 20.0, -0.18353418996691295, 20.0, 39.63627234698658, 20.0, -1.1468400895393271, -0.4898466928847689, 0.0, -2.3146223242413058], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-10.0, -14.661177828853278, -7.819387562275083, 0.0, 0.0, -14.965937612106595, -30.0, -30.0, -10.0, -10.0, -15.791473085051145, 0.0, -1.316331061175624, 0.0, -30.0, 0.0, -23.803044746864078, -1.0755317480595494, 0.0, 0.0, 0.0, -21.24721499272306, -12.403252262863234, -31.166483519240188, -11.396022097920735, 0.0, -21.241216980130737, -14.437739663414007, -60.0, -50.825410578926814, -2.322180724718555, -10.0, 0.0, 0.0, -16.19002747089452, 0.0, -20.16459693027032, -10.0, 0.0, 0.0, -10.0, -43.99439709134187, -10.0, -21.23342332641833, -10.0, 0.0, 0.0, -7.469852442724521, -2.6274897324173407, 0.0, -20.0, 0.0, -20.0, -0.25907414627607595, 0.0, -10.0, -10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.4545103262027559, -10.0, -40.0, -2.7314546421371877, -0.8711962234465576, -11.064348136755543, -3.4666766813330474, -40.3744702875263, 0.0, -35.369339752328976, -10.380996952379299, -48.41516103321448, 0.0, -54.28106601227164, -31.52003337335022, 0.0, -20.365728904816166, -10.0, -3.8147868053367064, -7.464539095418957, -4.686420399877589, -8.823178071748018, -10.651347935244846, -15.491174535009453, -1.544745539810195, -20.0, -0.8445020014935656, -3.0146146918619214, -10.0, 0.0, -10.316399299779517, 0.0, 0.0, -3.157956162234527, -34.77920250076634, -18.13989812575167, -0.5898728108530427, -30.0, 0.0, -22.992971495486767, -30.0, -10.0, 0.0, 0.0, -0.4168346302601622, 0.0, -10.371040650494246, -2.097374175898824, 0.0, -4.7483698950808835, 0.0, -6.506617582025849, -0.40381719393461357, -0.6763754362485774, -1.6029165816888613, -45.62234332597034, -50.492668784783504, 0.0, -5.853954218366756, 0.0, -31.848251895271716, -1.8492527959304328, 0.0, 0.0, -0.33285923258708494, 0.0, 0.0, 0.0, -10.326300623297435, 0.0, 0.0, 0.0, -15.90526278381729, 0.0, 0.0, -20.175458276258915, -40.0, -1.499739171414468, -48.064609297625545, 0.0, -14.941612381881255, 0.0, -30.0, 0.0, 0.0, 0.0, -10.0, -0.18353418996691295, -10.0, -20.36372765301342, -10.0, -1.1468400895393271, -0.4898466928847689, 0.0, -2.3146223242413058]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6579063268276509, "mean_inference_ms": 1.12856223999359, "mean_action_processing_ms": 0.23782975838896572, "mean_env_wait_ms": 0.48958711422169293, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004568879986986702, "StateBufferConnector_ms": 0.003285614060766903, "ViewRequirementAgentConnector_ms": 0.08810059523876802}, "num_episodes": 162, "episode_return_max": 120.0, "episode_return_min": -18.13989812575167, "episode_return_mean": 12.27622168343467}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2240000, "num_agent_steps_trained": 2240000, "num_env_steps_sampled": 560000, "num_env_steps_trained": 560000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 343.441889897268, "num_env_steps_trained_throughput_per_sec": 343.441889897268, "timesteps_total": 560000, "num_env_steps_sampled_lifetime": 560000, "num_agent_steps_sampled_lifetime": 2240000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2240000, "timers": {"training_iteration_time_ms": 11263.878, "restore_workers_time_ms": 0.013, "training_step_time_ms": 11263.843, "sample_time_ms": 1132.87, "learn_time_ms": 10118.626, "learn_throughput": 395.311, "synch_weights_time_ms": 12.072}, "counters": {"num_env_steps_sampled": 560000, "num_env_steps_trained": 560000, "num_agent_steps_sampled": 2240000, "num_agent_steps_trained": 2240000}, "done": false, "training_iteration": 140, "trial_id": "86f16_00000", "date": "2024-08-08_16-44-09", "timestamp": 1723149849, "time_this_iter_s": 11.653106927871704, "time_total_s": 1870.1283824443817, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad3e0790>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1870.1283824443817, "iterations_since_restore": 140, "perf": {"cpu_util_percent": 30.137500000000003, "ram_util_percent": 79.1}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5036756378169178, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.5097920295405896, "policy_loss": -0.01842959489737776, "vf_loss": 1.527546911797625, "vf_explained_var": 1.9067145408468043e-07, "kl": 0.00674713354518205, "entropy": 0.39084227105193103, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 396210.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.3117982452735304, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.5463452386359373, "policy_loss": -0.03094103658174087, "vf_loss": 2.5755218284825485, "vf_explained_var": 0.14237407905360064, "kl": 0.008822245175459214, "entropy": 0.9792934817572435, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 134880.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 564000, "num_env_steps_trained": 564000, "num_agent_steps_sampled": 2256000, "num_agent_steps_trained": 2256000}, "env_runners": {"episode_reward_max": 120.0, "episode_reward_min": -44.39803084545719, "episode_reward_mean": 11.320405058959917, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 158, "episodes_timesteps_total": 3950, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -63.84302652082989}, "policy_reward_max": {"adversary_policy": 60.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 6.89873417721519, "agent_policy": -9.375797472685653}, "custom_metrics": {}, "hist_stats": {"episode_reward": [39.230729231465034, -2.8491919030648365, -16.06732138060707, 80.0, 0.0, -14.071311766428938, 35.27569855730417, -1.5804891446803149, 20.0, -5.515750990727814, -0.9027217128332177, 30.16332041257967, -44.39803084545719, 0.0, -0.0002657473468992144, 20.0, 39.75960977719936, -0.16779357179497856, 59.888723833263256, 0.0, 0.0, 58.19696844055147, 13.128682295811714, 0.0, 0.0, -9.124905459587668, 0.0, 0.0, -1.711747204296331, -3.906623453753618, -9.95489287069389, 56.15697347917011, 40.0, 0.0, 20.0, 0.0, -10.086006919931354, 2.588382521301387, -0.17888180016441768, 0.0, -10.235990993726992, -2.6125382906444887, 60.0, 0.0, 0.0, 20.0, -6.915494891308542, 39.690398036453296, 36.41729675388347, -3.0876939615677115, -3.864674825101111, 0.0, 20.0, 100.0, 40.0, 14.543106869716999, 0.0, 0.0, 0.0, 39.924920741395354, 0.0, 0.0, 0.0, 0.0, 0.0, -2.5353340648803444, -0.6671144212684565, 0.0, -0.48450634343805143, 39.942963484113974, 20.0, 20.0, -1.8362364271756892, 0.0, 0.0, 0.0, 72.3587533873907, -2.6011748158871777, -9.66162521314277, 0.0, 60.0, 0.0, 59.10977705532419, 20.0, 0.0, 0.0, -0.9836640874972202, 0.0, 0.0, -2.757684865678817, 0.0, 20.0, 0.0, 35.940267684622455, 20.192951221277205, 0.0, 40.0, 0.0, 0.0, 0.0, 20.0, 60.0, -21.01454982962054, 40.0, 40.0, 0.0, -1.5812830209694084, 38.073997692480674, 20.0, 0.0, 0.9441828116528137, 0.0, -0.6803565714406212, -9.721663953053714, -0.44095300693949846, -1.4069433572321333, -1.3711952712261255, 0.0, -0.9422538173219208, 0.0, 0.0, 0.0, 20.0, 78.84655305706208, 0.0, 20.0, 20.0, 19.900950203038413, 20.0, 18.64518537914317, 0.0, 0.0, 20.0, 0.0, 0.0, 0.0, -19.22995970100753, -6.349044271567012, 0.0, 120.0, 0.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 19.6666799753215, 40.0, 0.0, 60.0, -0.5365181821061893, 38.211339235658485, -6.140023866343272], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-20.769270768534966, -2.8491919030648365, -16.06732138060707, -40.0, 0.0, -14.071311766428938, -24.724301442695836, -1.5804891446803149, -10.0, -5.515750990727814, -0.9027217128332177, -29.836679587420328, -44.39803084545719, 0.0, -0.0002657473468992144, -10.0, -20.240390222800638, -0.16779357179497856, -30.111276166736747, 0.0, 0.0, -31.803031559448527, -16.871317704188286, 0.0, 0.0, -9.124905459587668, 0.0, 0.0, -1.711747204296331, -3.906623453753618, -9.95489287069389, -63.84302652082989, -20.0, 0.0, -10.0, 0.0, -10.086006919931354, -27.41161747869861, -0.17888180016441768, 0.0, -10.235990993726992, -2.6125382906444887, -30.0, 0.0, 0.0, -10.0, -6.915494891308542, -20.309601963546704, -23.582703246116527, -3.0876939615677115, -3.864674825101111, 0.0, -10.0, -50.0, -20.0, -15.456893130283003, 0.0, 0.0, 0.0, -20.07507925860465, 0.0, 0.0, 0.0, 0.0, 0.0, -2.5353340648803444, -0.6671144212684565, 0.0, -0.48450634343805143, -20.057036515886026, -10.0, -10.0, -1.8362364271756892, 0.0, 0.0, 0.0, -47.641246612609294, -2.6011748158871777, -9.66162521314277, 0.0, -30.0, 0.0, -30.890222944675813, -10.0, 0.0, 0.0, -0.9836640874972202, 0.0, 0.0, -2.757684865678817, 0.0, -10.0, 0.0, -24.05973231537754, -39.80704877872279, 0.0, -20.0, 0.0, 0.0, 0.0, -10.0, -30.0, -21.01454982962054, -20.0, -20.0, 0.0, -1.5812830209694084, -21.926002307519326, -10.0, 0.0, -29.055817188347184, 0.0, -0.6803565714406212, -39.72166395305371, -0.44095300693949846, -1.4069433572321333, -1.3711952712261255, 0.0, -0.9422538173219208, 0.0, 0.0, 0.0, -10.0, -41.15344694293792, 0.0, -10.0, -10.0, -10.099049796961587, -10.0, -11.354814620856828, 0.0, 0.0, -10.0, 0.0, 0.0, 0.0, -19.22995970100753, -6.349044271567012, 0.0, -60.0, 0.0, -10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -10.3333200246785, -20.0, 0.0, -30.0, -0.5365181821061893, -21.788660764341515, -6.140023866343272]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6571783855695361, "mean_inference_ms": 1.1271310297338977, "mean_action_processing_ms": 0.23744153991293715, "mean_env_wait_ms": 0.4890645310305629, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003987324388721321, "StateBufferConnector_ms": 0.0030093555209002917, "ViewRequirementAgentConnector_ms": 0.08335060711148419}, "num_episodes": 158, "episode_return_max": 120.0, "episode_return_min": -44.39803084545719, "episode_return_mean": 11.320405058959917}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2256000, "num_agent_steps_trained": 2256000, "num_env_steps_sampled": 564000, "num_env_steps_trained": 564000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 364.3603484184365, "num_env_steps_trained_throughput_per_sec": 364.3603484184365, "timesteps_total": 564000, "num_env_steps_sampled_lifetime": 564000, "num_agent_steps_sampled_lifetime": 2256000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2256000, "timers": {"training_iteration_time_ms": 11232.357, "restore_workers_time_ms": 0.013, "training_step_time_ms": 11232.321, "sample_time_ms": 1125.018, "learn_time_ms": 10094.731, "learn_throughput": 396.246, "synch_weights_time_ms": 12.266}, "counters": {"num_env_steps_sampled": 564000, "num_env_steps_trained": 564000, "num_agent_steps_sampled": 2256000, "num_agent_steps_trained": 2256000}, "done": false, "training_iteration": 141, "trial_id": "86f16_00000", "date": "2024-08-08_16-44-21", "timestamp": 1723149861, "time_this_iter_s": 10.991841077804565, "time_total_s": 1881.1202235221863, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad3e0b80>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1881.1202235221863, "iterations_since_restore": 141, "perf": {"cpu_util_percent": 27.700000000000003, "ram_util_percent": 79.16250000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.45867341502655484, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.3934752858276909, "policy_loss": -0.017062835533383256, "vf_loss": 1.4097591607494557, "vf_explained_var": -1.9718146493248906e-07, "kl": 0.007789607014801465, "entropy": 0.3950127354750397, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 399030.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.2930797879894573, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.5946239129329722, "policy_loss": -0.03460732793852609, "vf_loss": 2.6274853674074015, "vf_explained_var": 0.12583309467881917, "kl": 0.008729361909913646, "entropy": 0.9626200523848335, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 135840.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 568000, "num_env_steps_trained": 568000, "num_agent_steps_sampled": 2272000, "num_agent_steps_trained": 2272000}, "env_runners": {"episode_reward_max": 134.56235986551275, "episode_reward_min": -28.125221572952135, "episode_reward_mean": 9.90592824714331, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 157, "episodes_timesteps_total": 3925, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -75.43764013448724}, "policy_reward_max": {"adversary_policy": 70.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 6.43312101910828, "agent_policy": -9.39343481018153}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, -23.063004182388052, -1.128479243353272, -2.6653374118936637, -2.4735833094061297, 0.0, 40.0, 0.0, -1.8150916145977547, 0.0, 40.0, 20.0, 0.0, 0.0, -6.875833079500525, 0.0, 0.0, 60.0, -0.030365839107459047, 0.0, 20.0, 40.0, 79.65368958018473, 0.0, 20.0, -4.232967084138776, 0.0, 0.0, 20.0, 0.0, 0.0, -1.4494946507196516, -8.217871613517413, 0.0, 0.0, 40.0, -12.349613304521327, 0.0, 25.15480063064228, -6.632737937998354, 15.418864514160285, 20.0, 60.0, 20.0, 0.0, 20.0, 34.892833285207416, 40.0, 0.0, -0.6375767259431897, 20.0, -27.97699684891361, 0.0, 20.0, 20.0, 0.0, 0.0, 0.0, 80.0, 0.0, 0.0, -2.356299531231204, 0.0, 0.0, -1.5928402134366548, -9.600054761463593, 20.0, 0.0, -15.276655360597308, 0.0, -0.08767335144942878, 93.42933409356849, 0.0, 31.75299879238512, 0.0, 0.0, 0.0, -4.565417723129386, -20.51425747385386, 0.0, 100.0, -2.9563698960752545, 0.0, 39.62985902448759, -3.093047691260718, 0.0, 36.89881767224927, 0.0, -0.9290180526765413, 0.0, 19.346861315852287, -0.9076351172975872, 40.0, 0.0, -8.280423971220422, 0.0, -0.11141745301389117, 0.0, 0.0, 0.0, 0.0, -13.821157114949756, 0.0, 60.0, 18.501330496613235, -0.21401943159906067, 0.0, 20.0, -8.447334971511532, 32.4086138181091, 0.0, 35.90910525133895, -5.494471910196474, 40.0, 40.0, 80.0, 0.0, 13.288980299715272, 0.0, -15.858527984399107, -0.6330536407007092, -1.0575440380197143, 0.0, -9.288530443103197, -0.3511529070104502, -13.365207111083413, -6.927550580885226, 16.90291720086886, -28.125221572952135, 19.577218948651186, -3.4369016737702944, 0.0, 0.0, -6.245397093588554, 0.0, 0.0, 20.0, 0.0, 0.0, 60.0, 0.0, 0.0, -3.6787294842811447, 20.0, -3.2992436540802625, 0.0, -2.6169044979843528, 33.32811039398395, 134.56235986551275, 20.0, 0.0, -1.0639470641891868, 16.201591004137175, 0.0, 22.899148091638846, 20.0, -10.781740860797637], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 70.0, 70.0, 70.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [0.0, -23.063004182388052, -1.128479243353272, -2.6653374118936637, -2.4735833094061297, 0.0, -20.0, 0.0, -1.8150916145977547, 0.0, -20.0, -10.0, 0.0, 0.0, -6.875833079500525, 0.0, 0.0, -30.0, -0.030365839107459047, 0.0, -10.0, -20.0, -40.346310419815275, 0.0, -10.0, -4.232967084138776, 0.0, 0.0, -10.0, 0.0, 0.0, -1.4494946507196516, -8.217871613517413, 0.0, 0.0, -20.0, -12.349613304521327, 0.0, -34.84519936935772, -6.632737937998354, -44.58113548583971, -10.0, -30.0, -10.0, 0.0, -10.0, -25.107166714792584, -20.0, 0.0, -0.6375767259431897, -10.0, -27.97699684891361, 0.0, -10.0, -10.0, 0.0, 0.0, 0.0, -40.0, 0.0, 0.0, -2.356299531231204, 0.0, 0.0, -1.5928402134366548, -9.600054761463593, -10.0, 0.0, -15.276655360597308, 0.0, -0.08767335144942878, -56.570665906431515, 0.0, -28.247001207614883, 0.0, 0.0, 0.0, -4.565417723129386, -20.51425747385386, 0.0, -50.0, -2.9563698960752545, 0.0, -20.37014097551241, -3.093047691260718, 0.0, -23.10118232775073, 0.0, -0.9290180526765413, 0.0, -10.653138684147713, -0.9076351172975872, -20.0, 0.0, -8.280423971220422, 0.0, -0.11141745301389117, 0.0, 0.0, 0.0, 0.0, -13.821157114949756, 0.0, -30.0, -11.498669503386767, -0.21401943159906067, 0.0, -10.0, -8.447334971511532, -27.591386181890886, 0.0, -24.09089474866106, -5.494471910196474, -20.0, -20.0, -40.0, 0.0, -16.711019700284723, 0.0, -15.858527984399107, -0.6330536407007092, -1.0575440380197143, 0.0, -9.288530443103197, -0.3511529070104502, -13.365207111083413, -6.927550580885226, -13.09708279913114, -28.125221572952135, -10.422781051348814, -3.4369016737702944, 0.0, 0.0, -36.24539709358856, 0.0, 0.0, -10.0, 0.0, 0.0, -30.0, 0.0, 0.0, -3.6787294842811447, -10.0, -3.2992436540802625, 0.0, -2.6169044979843528, -26.67188960601606, -75.43764013448724, -10.0, 0.0, -1.0639470641891868, -13.798408995862827, 0.0, -67.10085190836116, -10.0, -10.781740860797637]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6570655015787138, "mean_inference_ms": 1.127033747377596, "mean_action_processing_ms": 0.23756570942066016, "mean_env_wait_ms": 0.48910569120905417, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004299962596528849, "StateBufferConnector_ms": 0.003383341868212269, "ViewRequirementAgentConnector_ms": 0.0852337308750031}, "num_episodes": 157, "episode_return_max": 134.56235986551275, "episode_return_min": -28.125221572952135, "episode_return_mean": 9.90592824714331}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2272000, "num_agent_steps_trained": 2272000, "num_env_steps_sampled": 568000, "num_env_steps_trained": 568000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 348.2893415325696, "num_env_steps_trained_throughput_per_sec": 348.2893415325696, "timesteps_total": 568000, "num_env_steps_sampled_lifetime": 568000, "num_agent_steps_sampled_lifetime": 2272000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2272000, "timers": {"training_iteration_time_ms": 11203.196, "restore_workers_time_ms": 0.013, "training_step_time_ms": 11203.16, "sample_time_ms": 1126.231, "learn_time_ms": 10064.651, "learn_throughput": 397.431, "synch_weights_time_ms": 11.976}, "counters": {"num_env_steps_sampled": 568000, "num_env_steps_trained": 568000, "num_agent_steps_sampled": 2272000, "num_agent_steps_trained": 2272000}, "done": false, "training_iteration": 142, "trial_id": "86f16_00000", "date": "2024-08-08_16-44-32", "timestamp": 1723149872, "time_this_iter_s": 11.501689195632935, "time_total_s": 1892.6219127178192, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad44d700>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1892.6219127178192, "iterations_since_restore": 142, "perf": {"cpu_util_percent": 28.929411764705883, "ram_util_percent": 79.22941176470589}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.41833803901541317, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.2304411719876824, "policy_loss": -0.01511336161494123, "vf_loss": 1.2448655437598837, "vf_explained_var": -1.0735811071192965e-06, "kl": 0.006889886516954963, "entropy": 0.3884026193132637, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 401850.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.406635807702939, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.1671340092395743, "policy_loss": -0.035994168176936604, "vf_loss": 2.201268123773237, "vf_explained_var": 0.1019022108366092, "kl": 0.009300291353836313, "entropy": 0.961424778526028, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 136800.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 572000, "num_env_steps_trained": 572000, "num_agent_steps_sampled": 2288000, "num_agent_steps_trained": 2288000}, "env_runners": {"episode_reward_max": 118.85610114901158, "episode_reward_min": -25.691398710606673, "episode_reward_mean": 8.95759609535686, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -61.143898850988435}, "policy_reward_max": {"adversary_policy": 60.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 5.555555555555555, "agent_policy": -7.709070571309804}, "custom_metrics": {}, "hist_stats": {"episode_reward": [18.77462217829858, -8.103467522185232, -0.21783901746552536, 0.0, 0.0, 0.0, -2.8019661472956416, 40.0, -1.4949485443122457, 0.0, 0.0, -3.7502790066826446, 0.0, 20.0, 0.0, 0.0, 6.141940067806704, -6.186814990090993, -0.6888404747804167, 20.0, 0.0, 0.0, 0.0, 30.198216181211766, 19.769328234286565, 18.479535827431242, -5.788923471217889, 20.0, 100.0, 94.97304039444502, 100.0, 0.0, 14.704893464464178, -9.183260562015446, 0.0, 0.0, -0.05335841965362964, -0.07365862162264092, 44.29765699297126, -0.032485689772848714, 0.0, -4.506346129327642, 39.39846949622237, 0.0, 0.0, -1.8736045526926604, -1.5228276473087354, 80.0, 0.0, 54.66278496492911, 0.0, -4.82413360923063, 40.0, 0.0, 0.0, 0.0, -1.4579224810259472, -6.066701871140406, 20.0, 35.51829240706692, -9.361692420174165, -0.2743089707443547, 0.0, 80.0, 78.42454769741067, -0.9646948133575162, 0.0, 0.0, -0.7856304248273205, 0.0, 0.0, 48.33150048197722, -0.5612723402893471, 0.0, 20.0, -2.1785690582387134, 0.0, -0.8049063342645613, 0.0, 0.0, 0.0, -1.7806224861619857, -1.0856130324546998, 0.0, 0.0, 0.0, 20.0, -21.080058874862484, -0.8038568625316722, -8.469053974752908, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, -4.026417049710619, 20.0, -2.6285146486533395, 40.0, -4.3510326468591956, -6.784473707437177, -4.520203787450198, 60.0, 0.0, -1.2935493005191423, 0.0, 0.0, -1.0850777204701623, 0.0, 59.090569110067364, -1.2829165990918312, -9.633280118967184, 0.0, 0.0, 0.0, -1.1746696638507659, 0.0, 60.0, 0.0, 0.0, 0.0, -1.7787258168319575, -3.916099452368125, 0.0, -18.413857559924885, 18.015291733533168, -2.2394281961923, -1.4014368612362227, -2.128811805298376, 19.9291331299928, -25.691398710606673, 20.0, 0.0, 0.0, 20.0, -0.16011280168759634, 20.0, 37.03729330284072, -3.442271923109719, 0.0, 0.0, 0.0, 0.0, 20.0, 0.0, -0.7609212471005244, 0.0, -7.388474241926858, 118.85610114901158, 0.0, -2.0458589096718365, 0.0, -0.7461793043779741, -1.4660351873914057, 20.0, -1.319481898744549, -1.7124352530246445, -0.7078726954859038, 33.40454609231439, 20.0, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-11.225377821701427, -8.103467522185232, -0.21783901746552536, 0.0, 0.0, 0.0, -2.8019661472956416, -20.0, -1.4949485443122457, 0.0, 0.0, -3.7502790066826446, 0.0, -10.0, 0.0, 0.0, -23.858059932193296, -6.186814990090993, -0.6888404747804167, -10.0, 0.0, 0.0, 0.0, -29.801783818788234, -10.230671765713433, -41.52046417256876, -5.788923471217889, -10.0, -50.0, -55.026959605554985, -50.0, 0.0, -15.295106535535822, -9.183260562015446, 0.0, 0.0, -0.05335841965362964, -0.07365862162264092, -45.702343007028745, -0.032485689772848714, 0.0, -4.506346129327642, -20.60153050377763, 0.0, 0.0, -1.8736045526926604, -1.5228276473087354, -40.0, 0.0, -35.33721503507089, 0.0, -4.82413360923063, -20.0, 0.0, 0.0, 0.0, -1.4579224810259472, -6.066701871140406, -10.0, -24.48170759293308, -9.361692420174165, -0.2743089707443547, 0.0, -40.0, -41.575452302589326, -0.9646948133575162, 0.0, 0.0, -0.7856304248273205, 0.0, 0.0, -41.66849951802276, -0.5612723402893471, 0.0, -10.0, -2.1785690582387134, 0.0, -0.8049063342645613, 0.0, 0.0, 0.0, -1.7806224861619857, -1.0856130324546998, 0.0, 0.0, 0.0, -10.0, -21.080058874862484, -0.8038568625316722, -8.469053974752908, 0.0, 0.0, 0.0, 0.0, 0.0, -10.0, -4.026417049710619, -10.0, -2.6285146486533395, -20.0, -4.3510326468591956, -6.784473707437177, -4.520203787450198, -30.0, 0.0, -1.2935493005191423, 0.0, 0.0, -1.0850777204701623, 0.0, -30.909430889932636, -1.2829165990918312, -9.633280118967184, 0.0, 0.0, 0.0, -1.1746696638507659, 0.0, -30.0, 0.0, 0.0, 0.0, -1.7787258168319575, -3.916099452368125, 0.0, -18.413857559924885, -11.984708266466834, -2.2394281961923, -1.4014368612362227, -2.128811805298376, -10.070866870007201, -25.691398710606673, -10.0, 0.0, 0.0, -10.0, -0.16011280168759634, -10.0, -22.962706697159273, -3.442271923109719, 0.0, 0.0, 0.0, 0.0, -10.0, 0.0, -0.7609212471005244, 0.0, -7.388474241926858, -61.143898850988435, 0.0, -2.0458589096718365, 0.0, -0.7461793043779741, -1.4660351873914057, -10.0, -1.319481898744549, -1.7124352530246445, -0.7078726954859038, -56.59545390768561, -10.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6563792733558339, "mean_inference_ms": 1.1256301243780393, "mean_action_processing_ms": 0.23717126344910971, "mean_env_wait_ms": 0.488595040943696, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004836144270720305, "StateBufferConnector_ms": 0.0030440312844735606, "ViewRequirementAgentConnector_ms": 0.08478363355000813}, "num_episodes": 162, "episode_return_max": 118.85610114901158, "episode_return_min": -25.691398710606673, "episode_return_mean": 8.95759609535686}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2288000, "num_agent_steps_trained": 2288000, "num_env_steps_sampled": 572000, "num_env_steps_trained": 572000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 356.94144627229167, "num_env_steps_trained_throughput_per_sec": 356.94144627229167, "timesteps_total": 572000, "num_env_steps_sampled_lifetime": 572000, "num_agent_steps_sampled_lifetime": 2288000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2288000, "timers": {"training_iteration_time_ms": 11176.36, "restore_workers_time_ms": 0.013, "training_step_time_ms": 11176.324, "sample_time_ms": 1128.687, "learn_time_ms": 10035.368, "learn_throughput": 398.59, "synch_weights_time_ms": 11.925}, "counters": {"num_env_steps_sampled": 572000, "num_env_steps_trained": 572000, "num_agent_steps_sampled": 2288000, "num_agent_steps_trained": 2288000}, "done": false, "training_iteration": 143, "trial_id": "86f16_00000", "date": "2024-08-08_16-44-44", "timestamp": 1723149884, "time_this_iter_s": 11.212162017822266, "time_total_s": 1903.8340747356415, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad44d790>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1903.8340747356415, "iterations_since_restore": 143, "perf": {"cpu_util_percent": 27.650000000000002, "ram_util_percent": 79.35}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.48391636278718075, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.3886056385353103, "policy_loss": -0.0171355947853786, "vf_loss": 1.4050494975232064, "vf_explained_var": -4.947396880345987e-07, "kl": 0.006917365304359028, "entropy": 0.3816233309870916, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 404670.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.3337514707197746, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.5830284897858897, "policy_loss": -0.03462604888093968, "vf_loss": 2.6156783013294143, "vf_explained_var": 0.07798923552036285, "kl": 0.009881171141747832, "entropy": 0.9886795000483592, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 137760.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 576000, "num_env_steps_trained": 576000, "num_agent_steps_sampled": 2304000, "num_agent_steps_trained": 2304000}, "env_runners": {"episode_reward_max": 138.0872819622419, "episode_reward_min": -36.493638310047004, "episode_reward_mean": 9.032068505839609, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -78.7682525525326}, "policy_reward_max": {"adversary_policy": 70.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 5.987654320987654, "agent_policy": -8.930894457123353}, "custom_metrics": {}, "hist_stats": {"episode_reward": [79.40715851735081, 0.0, 0.0, 0.0, 19.48267094752418, -13.826054226196748, 76.69649867139165, 0.0, 20.0, 18.80723086514523, 0.0, -0.49131070629260254, 0.0, 0.0, -1.2557830758678123, -5.568559909751042, -1.6713037962924804, -0.14485729344150933, -1.4656347642903134, 0.0, 37.45874584831384, -12.601985758275887, 0.0, 58.644457296417244, 0.0, 13.251428522991285, 20.0, 0.0, -1.8387075749708204, -5.540554203370039, -0.001984290234641195, 0.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 20.0, 38.87122856037987, 54.39005073666537, -5.142686709620404, -1.1503642870170339, -0.8342944486137172, 0.0, 39.5880491192206, 19.573186305608726, 0.0, 41.23174744746739, -0.010255826109168975, 0.0, 120.0, -0.3674685769526198, 0.0, 19.816932603532827, 0.0, -10.962858787006024, 0.0, 0.0, -5.084029349041866, 0.0, 0.0, 40.0, 0.0, 20.0, -7.486717912247714, 20.0, 138.0872819622419, 40.0, 110.87037715636788, -3.5695309534958994, 40.0, 0.0, 0.0, -0.688840894751237, 20.0, 100.0, 0.0, 0.0, 0.0, 0.0, -4.6233950813635225, 0.0, -2.308059165582196, -0.10472071132915484, -4.6579378625781995, 0.0, 43.89704434512153, 0.0, -0.867083419169502, -0.41700685435592577, 0.0, -1.7233993344220933, -14.614132956161662, -1.482229303773367, -0.7123874858994506, 20.0, -32.15131854482495, -0.011913521526206727, 0.0, 18.002321610068194, -0.5632295944995458, 0.0, 60.0, 0.0, -2.4265588862146856, 0.0, 0.0, -3.488157864436301, 0.0, 60.0, 0.0, 20.0, -10.521249516848338, 0.0, 0.0, 0.0, -12.86606365475493, 0.0, 0.0, 0.0, 20.0, 15.988211649140734, 0.0, -1.6657468749980808, 40.0, 0.0, 0.0, -5.422875680433105, -11.346173357171237, -1.305588310012109, 59.99507012346358, 19.62208064935884, 0.0, 40.0, 0.0, -0.1899520843646907, -1.8120694998836395, -2.275369086129052, -36.493638310047004, -29.556098961398746, -12.426399634631341, 35.46067097139061, -11.547931401064682, 0.0, 0.0, -20.770949633280505, 0.0, 0.0, 0.0, -9.90168613132257, -3.0464048910883665, -13.081182323345406, 0.0, 0.0, 0.0, -4.010570248002211, 0.0, -17.852082434393157, 0.0, 20.0, 40.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 70.0, 70.0, 70.0, 20.0, 20.0, 20.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0], "policy_agent_policy_reward": [-40.592841482649185, 0.0, 0.0, 0.0, -10.51732905247582, -13.826054226196748, -43.30350132860834, 0.0, -10.0, -11.192769134854771, 0.0, -0.49131070629260254, 0.0, 0.0, -1.2557830758678123, -5.568559909751042, -1.6713037962924804, -0.14485729344150933, -1.4656347642903134, 0.0, -22.541254151686157, -12.601985758275887, 0.0, -31.355542703582756, 0.0, -16.74857147700871, -10.0, 0.0, -1.8387075749708204, -5.540554203370039, -0.001984290234641195, 0.0, -20.0, -20.0, 0.0, 0.0, 0.0, 0.0, -10.0, -21.128771439620134, -35.60994926333463, -5.142686709620404, -1.1503642870170339, -0.8342944486137172, 0.0, -20.4119508807794, -10.426813694391274, 0.0, -78.7682525525326, -0.010255826109168975, 0.0, -60.0, -0.3674685769526198, 0.0, -10.183067396467175, 0.0, -10.962858787006024, 0.0, 0.0, -5.084029349041866, 0.0, 0.0, -20.0, 0.0, -10.0, -7.486717912247714, -10.0, -71.91271803775811, -20.0, -69.12962284363209, -3.5695309534958994, -20.0, 0.0, 0.0, -0.688840894751237, -10.0, -50.0, 0.0, 0.0, 0.0, 0.0, -4.6233950813635225, 0.0, -2.308059165582196, -0.10472071132915484, -4.6579378625781995, 0.0, -46.102955654878464, 0.0, -0.867083419169502, -0.41700685435592577, 0.0, -1.7233993344220933, -14.614132956161662, -1.482229303773367, -0.7123874858994506, -10.0, -32.15131854482495, -0.011913521526206727, 0.0, -41.99767838993181, -0.5632295944995458, 0.0, -30.0, 0.0, -2.4265588862146856, 0.0, 0.0, -3.488157864436301, 0.0, -30.0, 0.0, -10.0, -10.521249516848338, 0.0, 0.0, 0.0, -12.86606365475493, 0.0, 0.0, 0.0, -10.0, -14.011788350859264, 0.0, -1.6657468749980808, -20.0, 0.0, 0.0, -5.422875680433105, -11.346173357171237, -1.305588310012109, -30.004929876536423, -10.37791935064116, 0.0, -20.0, 0.0, -0.1899520843646907, -1.8120694998836395, -2.275369086129052, -36.493638310047004, -29.556098961398746, -12.426399634631341, -24.539329028609387, -11.547931401064682, 0.0, 0.0, -20.770949633280505, 0.0, 0.0, 0.0, -9.90168613132257, -3.0464048910883665, -13.081182323345406, 0.0, 0.0, 0.0, -4.010570248002211, 0.0, -17.852082434393157, 0.0, -10.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.655856304089298, "mean_inference_ms": 1.1247074775024284, "mean_action_processing_ms": 0.2369785464933318, "mean_env_wait_ms": 0.48826828866821115, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004099327840922791, "StateBufferConnector_ms": 0.0031109209413881654, "ViewRequirementAgentConnector_ms": 0.08355651372744713}, "num_episodes": 162, "episode_return_max": 138.0872819622419, "episode_return_min": -36.493638310047004, "episode_return_mean": 9.032068505839609}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2304000, "num_agent_steps_trained": 2304000, "num_env_steps_sampled": 576000, "num_env_steps_trained": 576000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 357.30048213114884, "num_env_steps_trained_throughput_per_sec": 357.30048213114884, "timesteps_total": 576000, "num_env_steps_sampled_lifetime": 576000, "num_agent_steps_sampled_lifetime": 2304000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2304000, "timers": {"training_iteration_time_ms": 11180.295, "restore_workers_time_ms": 0.013, "training_step_time_ms": 11180.259, "sample_time_ms": 1129.143, "learn_time_ms": 10038.757, "learn_throughput": 398.456, "synch_weights_time_ms": 12.014}, "counters": {"num_env_steps_sampled": 576000, "num_env_steps_trained": 576000, "num_agent_steps_sampled": 2304000, "num_agent_steps_trained": 2304000}, "done": false, "training_iteration": 144, "trial_id": "86f16_00000", "date": "2024-08-08_16-44-55", "timestamp": 1723149895, "time_this_iter_s": 11.201128959655762, "time_total_s": 1915.0352036952972, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad454670>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1915.0352036952972, "iterations_since_restore": 144, "perf": {"cpu_util_percent": 27.625, "ram_util_percent": 79.29374999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.485662047226801, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.4167605210280587, "policy_loss": -0.01628481027544707, "vf_loss": 1.4323563091298368, "vf_explained_var": -2.576949748587101e-07, "kl": 0.006890206760244897, "entropy": 0.37985494167458084, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 407490.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.3426943918069205, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.6745283148251473, "policy_loss": -0.033093790694450335, "vf_loss": 2.7055210477982956, "vf_explained_var": 0.1296086157982548, "kl": 0.010505307112018818, "entropy": 0.914156439776222, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 138720.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 580000, "num_env_steps_trained": 580000, "num_agent_steps_sampled": 2320000, "num_agent_steps_trained": 2320000}, "env_runners": {"episode_reward_max": 99.73790709778254, "episode_reward_min": -67.13353631805494, "episode_reward_mean": 9.926627288680216, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -74.38249302220751}, "policy_reward_max": {"adversary_policy": 50.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 6.851851851851852, "agent_policy": -10.62892826687534}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, -13.994510871691062, -54.97749985113982, -5.253092083589312, 0.0, 0.0, 6.173580153208904, 20.0, 0.0, 60.0, -9.630190471084251, 0.0, 0.0, 0.0, 7.08610009847476, 0.0, 40.0, 0.0, 40.0, 40.0, 0.0, -6.536711594942667, 0.0, -1.482907172100043, -0.7401511054082222, -6.332645310348713, -1.2705812012958784, -8.370436844065381, 77.51980971746956, 0.0, -0.7589282604440073, -4.807825905823266, 0.0, 0.0, 0.0, 0.0, 0.0, 36.503315966518954, 20.0, 18.067149453942736, -1.3644505008738228, 0.0, 0.0, 19.896429592328268, -67.13353631805494, -29.161880549413695, -9.112370117873837, 98.49823353831788, -0.47811175913705206, 40.0, 0.0, 40.0, -1.254638209179978, 0.0, 0.0, 0.0, 39.81848831821633, 0.0, 0.0, 0.0, -6.299174716715296, 0.0, 0.0, 0.0, -1.3382300695958294, -1.2607234493592823, 97.90109766468967, 0.0, -1.7152400233212806, 0.0, -0.36847226023853263, 18.533913510459772, -3.4788643393302614, 0.0, -0.389903106713555, 0.0, 0.0, 59.86476794557464, 0.0, -16.252478759948257, -2.878543995341129, 75.95959637266397, 0.0, 0.0, 0.0, -26.553587107667497, 31.850966410483917, -46.2781336042497, 60.0, -5.224792401528896, -2.203130229881005, 0.0, 40.0, 34.77612694019325, 0.0, -1.693582606993077, 20.0, 0.0, 0.0, -1.036559957457367, 0.0, -11.2482551281148, 20.0, 0.0, 0.0, 98.2277994419802, 38.977692770616, -9.78158432599124, 20.0, 60.0, 0.0, -2.623616704175368, 14.6021303679641, 0.0, -10.429787179641508, 60.0, -1.1896309946820316, -6.345556344035232, 0.0, 40.0, 0.0, -1.3093339926949221, -14.738564279775291, 39.7145663681509, 18.962164734415897, 99.73790709778254, 0.0, -7.070242080634502, 17.2662573208718, -0.36786063063008245, 20.0, 40.0, -0.30000313314215377, -33.51591117155965, -3.9615941912656014, 40.0, -21.123145957069575, 80.0, 0.0, 0.0, 0.0, 0.0, 45.617506977792516, -7.687427890658694, 60.0, 0.0, 0.0, -3.204946707074564, 20.0, -0.5043054471043595, -2.018683227173592, -1.411507768663549, -12.286111683470114, 94.19746751710892, 40.0, -0.24138903879204698, 60.0, 40.0, 0.0, -8.213108063885585, -2.4349968179889845], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [0.0, 0.0, -13.994510871691062, -54.97749985113982, -5.253092083589312, 0.0, 0.0, -23.8264198467911, -10.0, 0.0, -30.0, -9.630190471084251, 0.0, 0.0, 0.0, -22.913899901525237, 0.0, -20.0, 0.0, -20.0, -20.0, 0.0, -6.536711594942667, 0.0, -1.482907172100043, -0.7401511054082222, -6.332645310348713, -1.2705812012958784, -8.370436844065381, -42.480190282530444, 0.0, -0.7589282604440073, -4.807825905823266, 0.0, 0.0, 0.0, 0.0, 0.0, -23.496684033481042, -10.0, -11.932850546057262, -1.3644505008738228, 0.0, 0.0, -10.103570407671734, -67.13353631805494, -29.161880549413695, -9.112370117873837, -51.501766461682124, -0.47811175913705206, -20.0, 0.0, -20.0, -1.254638209179978, 0.0, 0.0, 0.0, -20.181511681783668, 0.0, 0.0, 0.0, -6.299174716715296, 0.0, 0.0, 0.0, -1.3382300695958294, -1.2607234493592823, -52.09890233531034, 0.0, -1.7152400233212806, 0.0, -0.36847226023853263, -11.466086489540226, -3.4788643393302614, 0.0, -0.389903106713555, 0.0, 0.0, -30.13523205442536, 0.0, -16.252478759948257, -2.878543995341129, -44.04040362733601, 0.0, 0.0, 0.0, -26.553587107667497, -28.14903358951609, -46.2781336042497, -30.0, -5.224792401528896, -2.203130229881005, 0.0, -20.0, -25.22387305980675, 0.0, -1.693582606993077, -10.0, 0.0, 0.0, -1.036559957457367, 0.0, -11.2482551281148, -10.0, 0.0, 0.0, -51.772200558019804, -21.022307229384, -9.78158432599124, -10.0, -30.0, 0.0, -2.623616704175368, -15.3978696320359, 0.0, -10.429787179641508, -30.0, -1.1896309946820316, -6.345556344035232, 0.0, -20.0, 0.0, -1.3093339926949221, -14.738564279775291, -20.285433631849102, -11.037835265584103, -50.262092902217454, 0.0, -7.070242080634502, -12.733742679128198, -0.36786063063008245, -10.0, -20.0, -0.30000313314215377, -33.51591117155965, -3.9615941912656014, -20.0, -21.123145957069575, -40.0, 0.0, 0.0, 0.0, 0.0, -74.38249302220751, -7.687427890658694, -30.0, 0.0, 0.0, -3.204946707074564, -10.0, -0.5043054471043595, -2.018683227173592, -1.411507768663549, -12.286111683470114, -55.80253248289108, -20.0, -0.24138903879204698, -30.0, -20.0, 0.0, -8.213108063885585, -2.4349968179889845]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6553234707585069, "mean_inference_ms": 1.1238629290093975, "mean_action_processing_ms": 0.23677917170166646, "mean_env_wait_ms": 0.48797392089958735, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003985195984075099, "StateBufferConnector_ms": 0.0030261498910409434, "ViewRequirementAgentConnector_ms": 0.0844822253709958}, "num_episodes": 162, "episode_return_max": 99.73790709778254, "episode_return_min": -67.13353631805494, "episode_return_mean": 9.926627288680216}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2320000, "num_agent_steps_trained": 2320000, "num_env_steps_sampled": 580000, "num_env_steps_trained": 580000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 362.12281661228957, "num_env_steps_trained_throughput_per_sec": 362.12281661228957, "timesteps_total": 580000, "num_env_steps_sampled_lifetime": 580000, "num_agent_steps_sampled_lifetime": 2320000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2320000, "timers": {"training_iteration_time_ms": 11169.78, "restore_workers_time_ms": 0.013, "training_step_time_ms": 11169.744, "sample_time_ms": 1132.068, "learn_time_ms": 10025.285, "learn_throughput": 398.991, "synch_weights_time_ms": 12.011}, "counters": {"num_env_steps_sampled": 580000, "num_env_steps_trained": 580000, "num_agent_steps_sampled": 2320000, "num_agent_steps_trained": 2320000}, "done": false, "training_iteration": 145, "trial_id": "86f16_00000", "date": "2024-08-08_16-45-06", "timestamp": 1723149906, "time_this_iter_s": 11.050836324691772, "time_total_s": 1926.086040019989, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad44dca0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1926.086040019989, "iterations_since_restore": 145, "perf": {"cpu_util_percent": 27.28125, "ram_util_percent": 79.36875}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5103128666309178, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.6249000885807876, "policy_loss": -0.01855097663578914, "vf_loss": 1.6426750885679366, "vf_explained_var": -1.9352486793031085e-07, "kl": 0.007759740875585543, "entropy": 0.3955740562144746, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 410310.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.291423374786973, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.5731711824114125, "policy_loss": -0.028862033443632147, "vf_loss": 2.600399061789115, "vf_explained_var": 0.09455801999817291, "kl": 0.008170768998443606, "entropy": 0.9435115134343505, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 139680.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 584000, "num_env_steps_trained": 584000, "num_agent_steps_sampled": 2336000, "num_agent_steps_trained": 2336000}, "env_runners": {"episode_reward_max": 140.0, "episode_reward_min": -39.10757194600336, "episode_reward_mean": 12.184292688717138, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 153, "episodes_timesteps_total": 3825, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -73.74558219389908}, "policy_reward_max": {"adversary_policy": 70.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 7.450980392156863, "agent_policy": -10.168648487753451}, "custom_metrics": {}, "hist_stats": {"episode_reward": [60.0, 18.629133217495074, 0.0, 40.0, -2.67962702814599, -4.305252192459627, 60.0, -4.683904366887039, 0.0, 0.0, 0.0, 40.0, -4.7374506876736415, -39.10757194600336, 0.0, -3.220888859811681, -6.572712500865183, 20.0, 60.0, -3.716767310149277, 59.48688756240904, 20.0, -1.6332694855446317, 15.89356872723923, -12.056666317095916, 37.201710080967345, 20.0, -0.6817949796810419, 20.0, 0.0, 60.0, 0.0, 0.0, 0.0, -19.53353291938614, 0.0, -0.8386956258805012, 0.0, -0.5292899960707798, 20.0, 40.0, 0.0, 80.0, -0.7515400792710225, 0.0, 20.0, 0.0, -0.8574120068392499, 0.0, -9.043774693669226, 0.0, 27.086866939054165, 12.293738507847499, 0.0, -8.922440321318081, 0.0, 0.0, -0.9128940671203067, -0.09866980278118165, 39.77039004120881, -1.673065652687863, 0.0, 0.0, 140.0, 0.0, -4.400802757774818, 80.0, -6.397360083474162, -0.06423690053751874, 0.0, 39.6238610876393, -0.3623979718371384, -0.14264189811761696, 0.0, 31.424206644844126, 0.0, -6.618369258062149, 0.0, 40.0, -2.2749752590573418, -2.7636470998417924, 0.0, 19.851230255690698, 0.0, -3.8381628672012544, -15.395090891513332, -5.298365030601854, -2.9930668306762858, 0.0, 27.63463506763877, 0.0, 54.34382016246761, 0.0, 20.0, 0.0, -0.540344398765209, 0.0, 0.0, 60.0, 40.0, 0.0, -3.0613507632956694, 0.0, 0.0, 40.0, -4.8123001045562015, 0.0, -12.330537612917828, 99.87496346507922, 0.0, 50.41901477772738, 32.896379096978464, -1.9030199657820246, -2.5695049183724885, -24.86656772384599, 40.0, 60.0, 0.0, -0.26861348444532585, 18.798991800386318, 0.0, 0.0, 40.0, 40.0, 76.25441780610093, -1.4957188275369637, 40.0, 0.0, 0.0, 20.0, 20.0, 0.0, 31.528716903322604, 39.46021932235086, 40.0, 0.0, 0.0, 20.0, -18.197349962652062, 0.0, 0.0, -17.888515818528322, 0.0, -1.4047599349860218, 0.0, 59.80257311352028, -1.121151247764327, 40.0, 0.0, 0.0, 0.0, -0.5124707547604035, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-30.0, -11.370866782504924, 0.0, -20.0, -2.67962702814599, -4.305252192459627, -30.0, -4.683904366887039, 0.0, 0.0, 0.0, -20.0, -4.7374506876736415, -39.10757194600336, 0.0, -3.220888859811681, -6.572712500865183, -10.0, -30.0, -3.716767310149277, -30.513112437590962, -10.0, -1.6332694855446317, -14.10643127276077, -12.056666317095916, -52.798289919032655, -10.0, -0.6817949796810419, -10.0, 0.0, -30.0, 0.0, 0.0, 0.0, -19.53353291938614, 0.0, -0.8386956258805012, 0.0, -0.5292899960707798, -10.0, -20.0, 0.0, -40.0, -0.7515400792710225, 0.0, -10.0, 0.0, -0.8574120068392499, 0.0, -9.043774693669226, 0.0, -32.91313306094584, -17.706261492152503, 0.0, -8.922440321318081, 0.0, 0.0, -0.9128940671203067, -0.09866980278118165, -20.22960995879119, -1.673065652687863, 0.0, 0.0, -70.0, 0.0, -34.40080275777482, -40.0, -6.397360083474162, -0.06423690053751874, 0.0, -20.3761389123607, -0.3623979718371384, -0.14264189811761696, 0.0, -28.575793355155866, 0.0, -6.618369258062149, 0.0, -20.0, -2.2749752590573418, -2.7636470998417924, 0.0, -10.148769744309302, 0.0, -3.8381628672012544, -15.395090891513332, -5.298365030601854, -2.9930668306762858, 0.0, -32.36536493236123, 0.0, -35.6561798375324, 0.0, -10.0, 0.0, -0.540344398765209, 0.0, 0.0, -30.0, -20.0, 0.0, -3.0613507632956694, 0.0, 0.0, -20.0, -4.8123001045562015, 0.0, -12.330537612917828, -50.125036534920795, 0.0, -39.58098522227262, -27.103620903021536, -1.9030199657820246, -2.5695049183724885, -24.86656772384599, -20.0, -30.0, 0.0, -0.26861348444532585, -11.201008199613684, 0.0, 0.0, -20.0, -20.0, -73.74558219389908, -1.4957188275369637, -20.0, 0.0, 0.0, -10.0, -10.0, 0.0, -28.471283096677396, -20.53978067764914, -20.0, 0.0, 0.0, -10.0, -18.197349962652062, 0.0, 0.0, -17.888515818528322, 0.0, -1.4047599349860218, 0.0, -30.197426886479718, -1.121151247764327, -20.0, 0.0, 0.0, 0.0, -0.5124707547604035, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6547464742552221, "mean_inference_ms": 1.1229302622162236, "mean_action_processing_ms": 0.2365471433576594, "mean_env_wait_ms": 0.48762470696186766, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003954631830352584, "StateBufferConnector_ms": 0.003052692787320006, "ViewRequirementAgentConnector_ms": 0.08334186342027453}, "num_episodes": 153, "episode_return_max": 140.0, "episode_return_min": -39.10757194600336, "episode_return_mean": 12.184292688717138}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2336000, "num_agent_steps_trained": 2336000, "num_env_steps_sampled": 584000, "num_env_steps_trained": 584000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 351.8709564435002, "num_env_steps_trained_throughput_per_sec": 351.8709564435002, "timesteps_total": 584000, "num_env_steps_sampled_lifetime": 584000, "num_agent_steps_sampled_lifetime": 2336000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2336000, "timers": {"training_iteration_time_ms": 11222.841, "restore_workers_time_ms": 0.013, "training_step_time_ms": 11222.804, "sample_time_ms": 1130.343, "learn_time_ms": 10079.884, "learn_throughput": 396.83, "synch_weights_time_ms": 12.2}, "counters": {"num_env_steps_sampled": 584000, "num_env_steps_trained": 584000, "num_agent_steps_sampled": 2336000, "num_agent_steps_trained": 2336000}, "done": false, "training_iteration": 146, "trial_id": "86f16_00000", "date": "2024-08-08_16-45-18", "timestamp": 1723149918, "time_this_iter_s": 11.373888969421387, "time_total_s": 1937.4599289894104, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad12faf0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1937.4599289894104, "iterations_since_restore": 146, "perf": {"cpu_util_percent": 27.68125, "ram_util_percent": 79.40625}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.46394481483503436, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.1608400327305421, "policy_loss": -0.01694690229987118, "vf_loss": 1.1771387411136154, "vf_explained_var": 3.342721479158875e-07, "kl": 0.006481921645998431, "entropy": 0.38210674577148246, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 413130.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.4767602949092784, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.1407621790344518, "policy_loss": -0.03371950928703882, "vf_loss": 2.172432859117786, "vf_explained_var": 0.15115051021178563, "kl": 0.01024416251661355, "entropy": 0.9512325184419751, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 140640.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 588000, "num_env_steps_trained": 588000, "num_agent_steps_sampled": 2352000, "num_agent_steps_trained": 2352000}, "env_runners": {"episode_reward_max": 92.16646884213581, "episode_reward_min": -33.5533876934063, "episode_reward_mean": 7.186742945122128, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -57.83353115786419}, "policy_reward_max": {"adversary_policy": 50.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 4.8765432098765435, "agent_policy": -7.442886684507503}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, -19.10299966522047, 0.0, 0.0, -2.6796683584689216, 20.0, 16.093667716607985, 20.0, 40.0, -2.439300861402872, 0.0, 0.0, 0.0, -1.7669510144406564, 0.0, -12.757493825820486, -2.367982610863928, -0.9265179758078435, 50.277122930346934, 0.0, 0.0, 40.0, 40.0, 0.0, 20.0, -3.0199162330772578, -7.500333911346743, 92.16646884213581, -11.327632145196425, 0.0, 0.0, 0.0, 0.0, -3.7861091575519383, -2.1751975811762736, 40.0, 0.0, -5.221944832463554, 40.0, -4.440291484659644, 0.0, 0.0, -12.206764047299902, -2.5359339314907303, 0.0, 0.0, 0.0, 39.10988980667403, -3.243827453632325, 0.0, 0.0, -1.0655982700080369, 0.0, 0.0, -18.283572860443236, 39.60956887079242, 0.0, 8.771456835903594, -14.446199696503552, -13.583280999459024, 58.80189848764985, -15.113081991266913, 0.0, -2.2396007686407176, 0.0, 0.0, 40.0, 0.0, -12.569599580637316, 20.0, 0.0, 40.0, 0.0, -4.008086131257114, 0.0, -25.995314953153454, 0.0, -1.6421143178149078, 0.0, 40.0, 0.0, 59.15990317833701, 0.0, -0.015465654362813996, -12.127622866397935, 40.0, 0.0, 0.0, 0.0, 0.0, -0.08411953870269495, 20.0, 0.0, 0.0, -19.992004537051244, 0.0, 0.0, 80.0, 0.0, 0.0, 0.0, 0.0, -33.5533876934063, -1.3673282959542177, 13.906091595375981, 0.0, 20.0, 0.0, 0.0, 37.252910073676794, -1.7391787968625438, 0.0, -2.9909886822719027, -8.757345189828202, 20.0, 39.0389564374506, -0.9261506895395011, -6.1473915323135095, 0.0, -2.540915813178432, 40.0, 19.731679588464786, 0.0, -15.975452902049739, 20.0, 54.11707722383668, 27.384997466384633, 0.0, 18.379702090103958, -4.390815485151502, 0.0, -4.5476868105469155, 40.0, -0.33321197699688, 19.482655678893472, 0.0, -6.320113604626087, 38.823003501742576, 57.69749642965594, 0.0, -3.7469571458807787, 0.0, -3.107020584221609, 0.0, 0.0, 0.0, -1.296433831321805, 0.0, -2.7097581427533415, 0.0, 16.254058867301662, 78.65158202621264, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, -1.3431661052405375, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [0.0, -19.10299966522047, 0.0, 0.0, -2.6796683584689216, -10.0, -13.906332283392015, -10.0, -20.0, -2.439300861402872, 0.0, 0.0, 0.0, -1.7669510144406564, 0.0, -12.757493825820486, -2.367982610863928, -0.9265179758078435, -39.722877069653066, 0.0, 0.0, -20.0, -20.0, 0.0, -10.0, -3.0199162330772578, -7.500333911346743, -57.83353115786419, -11.327632145196425, 0.0, 0.0, 0.0, 0.0, -3.7861091575519383, -2.1751975811762736, -20.0, 0.0, -5.221944832463554, -20.0, -4.440291484659644, 0.0, 0.0, -12.206764047299902, -2.5359339314907303, 0.0, 0.0, 0.0, -20.890110193325967, -3.243827453632325, 0.0, 0.0, -1.0655982700080369, 0.0, 0.0, -18.283572860443236, -20.390431129207577, 0.0, -21.228543164096404, -14.446199696503552, -13.583280999459024, -31.198101512350146, -15.113081991266913, 0.0, -2.2396007686407176, 0.0, 0.0, -20.0, 0.0, -12.569599580637316, -10.0, 0.0, -20.0, 0.0, -4.008086131257114, 0.0, -25.995314953153454, 0.0, -1.6421143178149078, 0.0, -20.0, 0.0, -30.840096821662993, 0.0, -0.015465654362813996, -12.127622866397935, -20.0, 0.0, 0.0, 0.0, 0.0, -0.08411953870269495, -10.0, 0.0, 0.0, -19.992004537051244, 0.0, 0.0, -40.0, 0.0, 0.0, 0.0, 0.0, -33.5533876934063, -1.3673282959542177, -16.093908404624024, 0.0, -10.0, 0.0, 0.0, -22.747089926323206, -1.7391787968625438, 0.0, -2.9909886822719027, -8.757345189828202, -10.0, -20.961043562549396, -0.9261506895395011, -6.1473915323135095, 0.0, -2.540915813178432, -20.0, -10.268320411535216, 0.0, -15.975452902049739, -10.0, -35.882922776163326, -32.61500253361535, 0.0, -11.620297909896042, -4.390815485151502, 0.0, -4.5476868105469155, -20.0, -0.33321197699688, -10.517344321106526, 0.0, -6.320113604626087, -21.176996498257427, -32.302503570344065, 0.0, -3.7469571458807787, 0.0, -3.107020584221609, 0.0, 0.0, 0.0, -1.296433831321805, 0.0, -2.7097581427533415, 0.0, -13.745941132698341, -41.34841797378736, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -20.0, -1.3431661052405375, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6542352042395928, "mean_inference_ms": 1.1220208476796196, "mean_action_processing_ms": 0.2363532249560299, "mean_env_wait_ms": 0.4873298716674873, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003938616057972849, "StateBufferConnector_ms": 0.003049697405026283, "ViewRequirementAgentConnector_ms": 0.08536040047068655}, "num_episodes": 162, "episode_return_max": 92.16646884213581, "episode_return_min": -33.5533876934063, "episode_return_mean": 7.186742945122128}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2352000, "num_agent_steps_trained": 2352000, "num_env_steps_sampled": 588000, "num_env_steps_trained": 588000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 355.65035862839653, "num_env_steps_trained_throughput_per_sec": 355.65035862839653, "timesteps_total": 588000, "num_env_steps_sampled_lifetime": 588000, "num_agent_steps_sampled_lifetime": 2352000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2352000, "timers": {"training_iteration_time_ms": 11220.364, "restore_workers_time_ms": 0.013, "training_step_time_ms": 11220.329, "sample_time_ms": 1131.091, "learn_time_ms": 10076.718, "learn_throughput": 396.955, "synch_weights_time_ms": 12.142}, "counters": {"num_env_steps_sampled": 588000, "num_env_steps_trained": 588000, "num_agent_steps_sampled": 2352000, "num_agent_steps_trained": 2352000}, "done": false, "training_iteration": 147, "trial_id": "86f16_00000", "date": "2024-08-08_16-45-29", "timestamp": 1723149929, "time_this_iter_s": 11.253162860870361, "time_total_s": 1948.7130918502808, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad12fee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1948.7130918502808, "iterations_since_restore": 147, "perf": {"cpu_util_percent": 27.7625, "ram_util_percent": 79.375}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5024889194426384, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.5218194992618357, "policy_loss": -0.01875417379843313, "vf_loss": 1.5397920359956456, "vf_explained_var": 2.906043478783141e-07, "kl": 0.007816373663693135, "entropy": 0.38648820536356443, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 415950.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.2990537793685992, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.3508812839786213, "policy_loss": -0.03321332523337332, "vf_loss": 2.3822308509921033, "vf_explained_var": 0.0909011992936333, "kl": 0.009318785445636498, "entropy": 0.935089078048865, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 141600.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 592000, "num_env_steps_trained": 592000, "num_agent_steps_sampled": 2368000, "num_agent_steps_trained": 2368000}, "env_runners": {"episode_reward_max": 100.0, "episode_reward_min": -34.578848631850065, "episode_reward_mean": 11.937140018177004, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -50.0}, "policy_reward_max": {"adversary_policy": 50.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 7.222222222222222, "agent_policy": -9.729526648489664}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, -5.874357976984632, 0.0, 0.0, 40.0, 20.0, -0.6247703525400938, -4.645622341086596, -1.7987975666370992, 0.0, 53.49372427705721, 40.0, 60.0, 20.0, -1.6689062820582956, 60.0, 0.0, -0.9929023503811307, -0.7734476635476972, 19.984138351546026, -32.24845320427989, 0.0, 0.0, 0.0, -10.458755881974783, 0.0, -0.18760093561129398, 40.0, 60.0, 40.0, 0.0, -0.961296661431118, 0.0, 60.0, 0.0, -0.6994205857049463, 0.0, 18.894810077435476, 0.0, -4.886030774066236, 60.0, -0.033470080624778964, 0.0, 0.0, -10.664180910375746, -7.6821423362182735, 0.0, 80.0, 0.0, -4.488336992788918, -5.884205765373975, -9.257760543000465, -1.7355140043891726, 40.0, 0.0, 40.0, 0.0, 0.0, 0.0, 19.254807779734065, -0.2485355738121875, -1.5031714717494227, 0.0, 0.0, -17.36197729523842, 0.0, -16.872910506138677, 60.0, -0.8045868972874504, 0.0, 40.0, 40.0, 0.0, 0.0, 20.0, 0.0, 40.0, 34.323391028569716, -5.452905552230267, 0.0, -5.731968945675796, 20.0, -4.891396521501618, -3.294191140345193, -1.4378271094634731, 39.47515570151243, -14.423681061180716, -3.721714712635513, 0.0, -0.402683776574172, -1.9055359739623914, 0.0, 0.0, 80.0, 0.0, 60.0, 39.58288924953595, 0.0, -0.5692842687165034, 0.0, -1.6156975236639315, -0.5381868266689582, 40.0, 20.0, 19.874570048408398, 40.0, 58.7544964321455, 0.0, -0.08967388039670676, 0.0, 26.21023850033174, 100.0, -8.008554534918584, 0.0, 0.0, 11.487129766586348, 20.0, 59.09693722436196, 60.0, 0.0, 0.0, 19.709951778961504, 0.0, 59.60065259437971, -16.962144049179205, 0.0, 0.0, 59.20775292018013, 13.353684476648764, 0.0, 76.92370424388034, 60.0, 0.0, -10.562364456304591, 0.0, 0.0, -20.44666187124426, 0.0, 0.0, -3.7983981435663816, -21.59965099603017, 20.0, 0.0, -2.6278244965380972, 0.0, -0.996483525324513, 0.0, -0.1830529460515673, 18.979850946217017, -34.578848631850065, 60.0, 40.0, 0.0, 0.0, 0.0, 35.42309211889631, 40.0, 44.656176056121446, 0.0, -7.763483538147371, -0.5111011923640851, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [0.0, -5.874357976984632, 0.0, 0.0, -20.0, -10.0, -0.6247703525400938, -4.645622341086596, -1.7987975666370992, 0.0, -36.50627572294279, -20.0, -30.0, -10.0, -1.6689062820582956, -30.0, 0.0, -0.9929023503811307, -0.7734476635476972, -10.015861648453974, -32.24845320427989, 0.0, 0.0, 0.0, -10.458755881974783, 0.0, -0.18760093561129398, -20.0, -30.0, -20.0, 0.0, -0.961296661431118, 0.0, -30.0, 0.0, -0.6994205857049463, 0.0, -41.10518992256452, 0.0, -4.886030774066236, -30.0, -0.033470080624778964, 0.0, 0.0, -10.664180910375746, -7.6821423362182735, 0.0, -40.0, 0.0, -4.488336992788918, -5.884205765373975, -9.257760543000465, -1.7355140043891726, -20.0, 0.0, -20.0, 0.0, 0.0, 0.0, -10.745192220265935, -0.2485355738121875, -1.5031714717494227, 0.0, 0.0, -17.36197729523842, 0.0, -16.872910506138677, -30.0, -0.8045868972874504, 0.0, -20.0, -20.0, 0.0, 0.0, -10.0, 0.0, -20.0, -25.676608971430284, -5.452905552230267, 0.0, -5.731968945675796, -10.0, -4.891396521501618, -3.294191140345193, -1.4378271094634731, -20.524844298487572, -14.423681061180716, -3.721714712635513, 0.0, -0.402683776574172, -1.9055359739623914, 0.0, 0.0, -40.0, 0.0, -30.0, -20.417110750464047, 0.0, -0.5692842687165034, 0.0, -1.6156975236639315, -0.5381868266689582, -20.0, -10.0, -10.1254299515916, -20.0, -31.24550356785449, 0.0, -0.08967388039670676, 0.0, -33.78976149966825, -50.0, -8.008554534918584, 0.0, 0.0, -18.51287023341365, -10.0, -30.903062775638034, -30.0, 0.0, 0.0, -10.290048221038496, 0.0, -30.399347405620283, -16.962144049179205, 0.0, 0.0, -30.792247079819866, -16.64631552335123, 0.0, -43.07629575611966, -30.0, 0.0, -10.562364456304591, 0.0, 0.0, -20.44666187124426, 0.0, 0.0, -3.7983981435663816, -21.59965099603017, -10.0, 0.0, -2.6278244965380972, 0.0, -0.996483525324513, 0.0, -0.1830529460515673, -11.020149053782983, -34.578848631850065, -30.0, -20.0, 0.0, 0.0, 0.0, -24.57690788110369, -20.0, -45.343823943878554, 0.0, -7.763483538147371, -0.5111011923640851, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6537922791018509, "mean_inference_ms": 1.1213849678253751, "mean_action_processing_ms": 0.23620176524553732, "mean_env_wait_ms": 0.4871831573677862, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004031555152233736, "StateBufferConnector_ms": 0.00320680347489722, "ViewRequirementAgentConnector_ms": 0.0837740338878867}, "num_episodes": 162, "episode_return_max": 100.0, "episode_return_min": -34.578848631850065, "episode_return_mean": 11.937140018177004}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2368000, "num_agent_steps_trained": 2368000, "num_env_steps_sampled": 592000, "num_env_steps_trained": 592000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 346.5896396586323, "num_env_steps_trained_throughput_per_sec": 346.5896396586323, "timesteps_total": 592000, "num_env_steps_sampled_lifetime": 592000, "num_agent_steps_sampled_lifetime": 2368000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2368000, "timers": {"training_iteration_time_ms": 11283.991, "restore_workers_time_ms": 0.013, "training_step_time_ms": 11283.955, "sample_time_ms": 1137.941, "learn_time_ms": 10133.656, "learn_throughput": 394.724, "synch_weights_time_ms": 11.984}, "counters": {"num_env_steps_sampled": 592000, "num_env_steps_trained": 592000, "num_agent_steps_sampled": 2368000, "num_agent_steps_trained": 2368000}, "done": false, "training_iteration": 148, "trial_id": "86f16_00000", "date": "2024-08-08_16-45-41", "timestamp": 1723149941, "time_this_iter_s": 11.545828104019165, "time_total_s": 1960.2589199543, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad12ff70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1960.2589199543, "iterations_since_restore": 148, "perf": {"cpu_util_percent": 30.42941176470588, "ram_util_percent": 79.41764705882353}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5261212612667405, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.184600271274012, "policy_loss": -0.018419653704432864, "vf_loss": 1.2022846483592446, "vf_explained_var": -2.0698875400191504e-07, "kl": 0.007352773636119133, "entropy": 0.37275738607273035, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 418770.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.419711356361707, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.3658108623543135, "policy_loss": -0.030013261561786447, "vf_loss": 2.394122047784428, "vf_explained_var": 0.15723479545364777, "kl": 0.008510382738090455, "entropy": 0.9523455892379086, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 142560.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 596000, "num_env_steps_trained": 596000, "num_agent_steps_sampled": 2384000, "num_agent_steps_trained": 2384000}, "env_runners": {"episode_reward_max": 100.0, "episode_reward_min": -39.9654127863951, "episode_reward_mean": 7.486330281475621, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -63.85896708387786}, "policy_reward_max": {"adversary_policy": 50.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 5.246913580246914, "agent_policy": -8.25441045926512}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 20.0, 40.0, 0.0, 0.0, 10.051960117802004, 0.0, 60.0, 0.0, -10.79686724350953, -9.277963675535931, 7.732230367307404, 38.54302347755261, 19.823307599707494, 0.0, 18.090882998181794, -5.979839098846077, 0.0, -1.498242886591452, 0.0, -22.554892781269654, 16.904533988588696, 20.0, -2.203088234494702, 34.80322336474759, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 0.0, 0.0, -7.193215839445024, 20.0, 36.62877696757213, 0.0, 20.0, 38.31592862810793, 0.0, -3.136623663477043, -1.3690073434313643, 0.0, 0.0, -39.9654127863951, -1.3810279977326507, 0.0, -0.3062574734560519, 32.31398077704423, 37.79620457606305, 0.0, 0.0, 0.0, 0.0, 40.0, -6.658780208321839, 60.0, -1.304371215607597, 0.0, -7.823779382912168, 0.0, 20.0, 0.0, 20.0, 0.0, 19.028655098459712, 0.0, 0.0, 0.0, -12.66980324393741, 17.030209576895714, 0.0, 58.518961734887206, 0.0, 20.0, 38.38543754775409, 0.0, 0.0, 0.0, 10.624982034933456, 0.0, 26.14103291612214, 20.0, 0.0, 38.452628536678674, -0.10875615324991594, 40.0, -0.1373335774280171, 0.0, 0.0, 0.0, 39.14190755673093, -1.9712998201170728, -7.982609641238827, 60.0, -4.740927827909256, -0.614172335023595, 0.0, 0.0, 20.0, 87.6386833651718, 0.0, 20.0, 0.0, 0.0, -0.24722624138733718, 0.0, 0.0, 20.0, 20.0, 0.0, 0.0, -22.500102913365595, -0.17797167436568784, -0.09316704687535204, -1.8141939042812927, 40.0, 40.0, 0.0, 0.0, 40.0, 39.41796817493303, -0.6652675628155258, 0.0, 20.0, 60.0, 0.0, 0.0, -15.243537697289035, 0.0, 8.907895201462981, -14.253775339224498, -2.5270684048062586, 0.0, -0.8261288415685308, 0.0, 100.0, 0.0, -0.042863496571186044, 0.0, -0.8599367796416724, 0.0, -11.341944769981827, -15.241208701397577, 0.0, 0.0, 0.0, 0.0, -20.87662819725736, 0.0, 0.0, -13.779442717360345, 0.0, -14.397282717518557, -6.111311591800365, 0.0, -2.4215128123667444, -16.87579829357373, -0.07792659868325336, -9.58830201963134, -1.8700382559607587], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [0.0, 0.0, -10.0, -20.0, 0.0, 0.0, -19.948039882197996, 0.0, -30.0, 0.0, -10.79686724350953, -9.277963675535931, -22.267769632692588, -21.456976522447377, -10.176692400292506, 0.0, -11.909117001818206, -5.979839098846077, 0.0, -61.498242886591456, 0.0, -22.554892781269654, -13.095466011411311, -10.0, -2.203088234494702, -25.196776635252405, 0.0, 0.0, 0.0, 0.0, 0.0, -10.0, 0.0, 0.0, -7.193215839445024, -10.0, -23.37122303242787, 0.0, -10.0, -21.68407137189207, 0.0, -3.136623663477043, -1.3690073434313643, 0.0, 0.0, -39.9654127863951, -1.3810279977326507, 0.0, -0.3062574734560519, -27.686019222955768, -22.203795423936953, 0.0, 0.0, 0.0, 0.0, -20.0, -6.658780208321839, -30.0, -1.304371215607597, 0.0, -7.823779382912168, 0.0, -10.0, 0.0, -10.0, 0.0, -10.971344901540288, 0.0, 0.0, 0.0, -12.66980324393741, -12.969790423104286, 0.0, -31.481038265112797, 0.0, -10.0, -21.614562452245913, 0.0, 0.0, 0.0, -19.375017965066544, 0.0, -63.85896708387786, -10.0, 0.0, -21.547371463321326, -0.10875615324991594, -20.0, -0.1373335774280171, 0.0, 0.0, 0.0, -20.858092443269072, -1.9712998201170728, -7.982609641238827, -30.0, -4.740927827909256, -0.614172335023595, 0.0, 0.0, -10.0, -62.361316634828235, 0.0, -10.0, 0.0, 0.0, -0.24722624138733718, 0.0, 0.0, -10.0, -10.0, 0.0, 0.0, -22.500102913365595, -0.17797167436568784, -0.09316704687535204, -1.8141939042812927, -20.0, -20.0, 0.0, 0.0, -20.0, -20.58203182506697, -0.6652675628155258, 0.0, -10.0, -30.0, 0.0, 0.0, -15.243537697289035, 0.0, -21.09210479853702, -14.253775339224498, -2.5270684048062586, 0.0, -0.8261288415685308, 0.0, -50.0, 0.0, -0.042863496571186044, 0.0, -0.8599367796416724, 0.0, -11.341944769981827, -15.241208701397577, 0.0, 0.0, 0.0, 0.0, -20.87662819725736, 0.0, 0.0, -13.779442717360345, 0.0, -14.397282717518557, -6.111311591800365, 0.0, -2.4215128123667444, -16.87579829357373, -0.07792659868325336, -9.58830201963134, -1.8700382559607587]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6533065183429572, "mean_inference_ms": 1.1204987330769782, "mean_action_processing_ms": 0.2359878578354121, "mean_env_wait_ms": 0.48686886093441484, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004442312099315502, "StateBufferConnector_ms": 0.0032616250308943385, "ViewRequirementAgentConnector_ms": 0.08315672109156479}, "num_episodes": 162, "episode_return_max": 100.0, "episode_return_min": -39.9654127863951, "episode_return_mean": 7.486330281475621}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2384000, "num_agent_steps_trained": 2384000, "num_env_steps_sampled": 596000, "num_env_steps_trained": 596000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 355.40914656340493, "num_env_steps_trained_throughput_per_sec": 355.40914656340493, "timesteps_total": 596000, "num_env_steps_sampled_lifetime": 596000, "num_agent_steps_sampled_lifetime": 2384000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2384000, "timers": {"training_iteration_time_ms": 11296.754, "restore_workers_time_ms": 0.013, "training_step_time_ms": 11296.718, "sample_time_ms": 1135.377, "learn_time_ms": 10148.991, "learn_throughput": 394.128, "synch_weights_time_ms": 11.97}, "counters": {"num_env_steps_sampled": 596000, "num_env_steps_trained": 596000, "num_agent_steps_sampled": 2384000, "num_agent_steps_trained": 2384000}, "done": false, "training_iteration": 149, "trial_id": "86f16_00000", "date": "2024-08-08_16-45-52", "timestamp": 1723149952, "time_this_iter_s": 11.259525060653687, "time_total_s": 1971.5184450149536, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad404550>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1971.5184450149536, "iterations_since_restore": 149, "perf": {"cpu_util_percent": 31.06875, "ram_util_percent": 79.475}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4516744573382621, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.3734929432682956, "policy_loss": -0.017281749769417792, "vf_loss": 1.3900247487087622, "vf_explained_var": 6.797888600234445e-07, "kl": 0.007499459736581833, "entropy": 0.3831147018370899, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 421590.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.393464456126094, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.4415494967252016, "policy_loss": -0.029788818544572375, "vf_loss": 2.469550175840656, "vf_explained_var": 0.0868558224911491, "kl": 0.008940658123689124, "entropy": 0.9201850607370337, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 143520.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 600000, "num_env_steps_trained": 600000, "num_agent_steps_sampled": 2400000, "num_agent_steps_trained": 2400000}, "env_runners": {"episode_reward_max": 100.0, "episode_reward_min": -24.490498794727294, "episode_reward_mean": 10.976023927263986, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -58.10666127061931}, "policy_reward_max": {"adversary_policy": 50.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 6.9753086419753085, "agent_policy": -9.949901998661943}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 18.6609548045143, 40.0, 19.72257753908962, 39.59860427259021, 0.0, -1.539557851831961, 60.0, 0.0, 20.0, 0.0, -8.024773603750258, 0.0, 0.0, 0.0, 80.0, -0.38055641788102834, 60.0, 99.51526341462763, 60.0, -0.19510823907763708, 0.0, 0.0, 53.19040242262489, 0.0, 20.0, -0.347588028753687, -13.872628620472632, -23.196932028095212, 0.0, -15.24345102029555, -0.5226331631919456, 60.0, 0.0, 0.0, 20.0, 20.0, 0.0, 0.0, 58.14596280133073, 20.0, -2.758652873609149, 98.66242688070793, 0.0, 19.345740622181747, 0.0, 0.0, 20.0, -5.579399022684986, -0.628117202539501, -24.10107901751749, 0.0, 0.0, 0.0, 0.0, 0.0, 1.5397890416841453, 20.0, 40.0, 0.0, 0.0, 20.0, 20.0, 0.0, -4.181647141044186, -2.018252592380204, -0.5765508676289266, 31.893338729380677, 0.0, 0.0, -2.896094691059954, 0.0, 0.0, 95.3982469231569, 57.79322196488985, 0.0, -4.9433296131585855, 0.0, 0.0, 0.0, 20.0, 0.0, -24.490498794727294, 4.376942660385714, -12.251314502616518, -1.035811668282789, 0.0, 40.0, 0.0, 0.0, -5.138274969271011, -9.143596558650211, -11.704598488113358, 0.0, 0.0, 9.886619649912694, 80.0, -9.025673230066843, -1.7166998894479013, 33.025829722081966, 0.0, -5.1686820549036305, 0.0, 0.0, 0.0, 40.0, 0.0, -0.49905164514828404, 20.0, 40.0, 0.0, 60.0, -3.454856930272161, 0.0, 39.23914843434368, 60.0, -0.5911303247338118, 44.606810807854565, 20.0, -0.4720841154530486, 0.0, 0.0, 0.0, -6.030891387693239, 15.206460956560036, 60.0, -3.867980889705369, 6.5945634099769235, -10.146347312509176, -11.535052323460468, 0.0, 0.0, -2.723240636612384, -5.350228208846398, 0.0, 60.0, 100.0, -7.405068707043164, -0.04000295074122362, -0.6680592408817865, 0.0, 0.0, 0.0, -15.56344579671062, -15.579748014519678, -0.9095903620243551, 0.0, 40.0, -4.904516761358408, 54.80699018937925, -12.136223623148153, 18.403495173446412, 0.0, -5.591932199456489, 20.0, 0.0, -1.8903645473195363, 0.0, 20.0, 0.0, -1.456196075264291, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [0.0, -11.3390451954857, -20.0, -10.277422460910378, -20.40139572740979, 0.0, -1.539557851831961, -30.0, 0.0, -10.0, 0.0, -8.024773603750258, 0.0, 0.0, 0.0, -40.0, -0.38055641788102834, -30.0, -50.484736585372374, -30.0, -0.19510823907763708, 0.0, 0.0, -36.809597577375115, 0.0, -10.0, -0.347588028753687, -13.872628620472632, -23.196932028095212, 0.0, -15.24345102029555, -0.5226331631919456, -30.0, 0.0, 0.0, -10.0, -10.0, 0.0, 0.0, -31.854037198669282, -10.0, -2.758652873609149, -51.33757311929207, 0.0, -10.654259377818253, 0.0, 0.0, -10.0, -5.579399022684986, -0.628117202539501, -24.10107901751749, 0.0, 0.0, 0.0, 0.0, 0.0, -28.46021095831585, -10.0, -20.0, 0.0, 0.0, -10.0, -10.0, 0.0, -4.181647141044186, -2.018252592380204, -0.5765508676289266, -58.10666127061931, 0.0, 0.0, -2.896094691059954, 0.0, 0.0, -54.60175307684312, -32.206778035110155, 0.0, -4.9433296131585855, 0.0, 0.0, 0.0, -10.0, 0.0, -24.490498794727294, -25.623057339614288, -12.251314502616518, -1.035811668282789, 0.0, -20.0, 0.0, 0.0, -5.138274969271011, -9.143596558650211, -11.704598488113358, 0.0, 0.0, -20.113380350087308, -40.0, -9.025673230066843, -1.7166998894479013, -26.974170277918038, 0.0, -5.1686820549036305, 0.0, 0.0, 0.0, -20.0, 0.0, -0.49905164514828404, -10.0, -20.0, 0.0, -30.0, -3.454856930272161, 0.0, -20.760851565656317, -30.0, -0.5911303247338118, -45.39318919214545, -10.0, -0.4720841154530486, 0.0, 0.0, 0.0, -6.030891387693239, -14.793539043439965, -30.0, -3.867980889705369, -53.40543659002307, -10.146347312509176, -11.535052323460468, 0.0, 0.0, -2.723240636612384, -5.350228208846398, 0.0, -30.0, -50.0, -7.405068707043164, -0.04000295074122362, -0.6680592408817865, 0.0, 0.0, 0.0, -15.56344579671062, -15.579748014519678, -0.9095903620243551, 0.0, -20.0, -4.904516761358408, -35.19300981062075, -12.136223623148153, -11.596504826553593, 0.0, -35.591932199456494, -10.0, 0.0, -1.8903645473195363, 0.0, -10.0, 0.0, -1.456196075264291, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6527576263312669, "mean_inference_ms": 1.1196176751391407, "mean_action_processing_ms": 0.23580873178070838, "mean_env_wait_ms": 0.48655909940201963, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0041288358193856695, "StateBufferConnector_ms": 0.0033500753803017698, "ViewRequirementAgentConnector_ms": 0.08701696807955518}, "num_episodes": 162, "episode_return_max": 100.0, "episode_return_min": -24.490498794727294, "episode_return_mean": 10.976023927263986}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2400000, "num_agent_steps_trained": 2400000, "num_env_steps_sampled": 600000, "num_env_steps_trained": 600000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 344.20534570670344, "num_env_steps_trained_throughput_per_sec": 344.20534570670344, "timesteps_total": 600000, "num_env_steps_sampled_lifetime": 600000, "num_agent_steps_sampled_lifetime": 2400000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2400000, "timers": {"training_iteration_time_ms": 11294.171, "restore_workers_time_ms": 0.013, "training_step_time_ms": 11294.134, "sample_time_ms": 1102.449, "learn_time_ms": 10178.505, "learn_throughput": 392.985, "synch_weights_time_ms": 12.549}, "counters": {"num_env_steps_sampled": 600000, "num_env_steps_trained": 600000, "num_agent_steps_sampled": 2400000, "num_agent_steps_trained": 2400000}, "done": false, "training_iteration": 150, "trial_id": "86f16_00000", "date": "2024-08-08_16-46-04", "timestamp": 1723149964, "time_this_iter_s": 11.647471904754639, "time_total_s": 1983.1659169197083, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad404a60>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1983.1659169197083, "iterations_since_restore": 150, "perf": {"cpu_util_percent": 33.143750000000004, "ram_util_percent": 80.3375}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4873065513235035, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.2739599702628792, "policy_loss": -0.019082927866426052, "vf_loss": 1.2922946216261133, "vf_explained_var": -6.484647169180795e-08, "kl": 0.007482767597708839, "entropy": 0.4074666304685545, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 424410.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.5144603638599317, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.537294265193244, "policy_loss": -0.030048711852092916, "vf_loss": 2.565493698666493, "vf_explained_var": 0.11848179114361604, "kl": 0.009246406427612928, "entropy": 0.928153467302521, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 144480.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 604000, "num_env_steps_trained": 604000, "num_agent_steps_sampled": 2416000, "num_agent_steps_trained": 2416000}, "env_runners": {"episode_reward_max": 119.47404179940781, "episode_reward_min": -25.25734356311, "episode_reward_mean": 9.268879906563845, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 153, "episodes_timesteps_total": 3825, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -60.52595820059219}, "policy_reward_max": {"adversary_policy": 60.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 5.816993464052287, "agent_policy": -8.182100485593018}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, -2.936428421291197, 40.0, 60.0, -0.2949107268658524, -11.644298832308927, 0.0, 0.0, 0.0, -25.25734356311, 17.67453439943964, -3.2402225831498166, 79.05206692537286, -2.695329242455432, -14.483553676395196, -13.072056086893244, -16.321629358575304, 0.0, 32.674728218995874, 0.0, 0.0, 0.0, -3.3696149498050594, 40.0, 0.0, -0.12168917363010956, 0.0, 0.0, 0.0, 80.0, -0.055497085467571816, 0.0, 18.625624033902792, 53.82779400377553, 20.0, 0.0, 40.0, -0.32821372472189414, 0.0, 0.0, 0.0, -7.959674072424079, 0.0, -0.04953895887726989, -3.5501380170228045, -11.264582495141008, 0.0, -0.06418899318589633, 0.0, 45.796568041814126, 20.0, 0.0, -14.415767054973573, 0.0, -17.094468417310694, 0.0, 119.47404179940781, -1.3192649771177434, 21.722510890317785, 0.0, -4.509294275303512, -3.006251248097594, -1.608760562389383, -10.481540228564624, 96.63272996268097, 37.928231143448166, 20.0, 39.89734614784039, -0.7680926647303399, 19.02119528073119, -3.083676789905919, 20.0, 20.0, -0.38803053320246916, 20.0, -6.088062344996226, 0.0, 0.0, -0.5107084453333965, -1.0436878343544198, 0.0, -6.041295423999175, 0.0, 0.0, 0.0, -2.3152320996043194, 0.0, -0.14666652890236276, 20.0, 0.0, -5.459839271678083, 0.0, 60.0, 0.0, 0.0, 80.0, 0.0, -5.960122503152443, -14.261355690064583, -0.9495361045000605, -0.04953722819121764, 40.0, 39.662842060112844, 0.0, 0.0, 0.0, 0.0, 20.0, 39.112612441645595, 20.0, 18.416269194356747, -2.4538915954720073, -9.659159507200313, -3.3731005144083808, 0.0, 59.06052402705564, 0.0, 0.0, -6.441976552827054, 0.0, -10.690237232986888, 0.0, 18.431435118124934, 0.0, 20.0, 0.0, 0.0, 37.52798800694788, -2.2064268823544086, 0.0, 0.0, -20.014417053799356, 40.0, 0.0, 18.064106207969097, 0.0, 40.0, -4.539155695220954, -0.12300551069153953, -5.421322621987008, 20.0, 0.0, 0.0, 20.0, 12.69586269449031, 0.0, 0.0, 58.15566801595071, 0.0, 0.0, 60.0, -4.183259555471884, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [0.0, -2.936428421291197, -20.0, -30.0, -0.2949107268658524, -11.644298832308927, 0.0, 0.0, 0.0, -25.25734356311, -12.325465600560362, -3.2402225831498166, -40.94793307462714, -2.695329242455432, -14.483553676395196, -13.072056086893244, -16.321629358575304, 0.0, -27.325271781004137, 0.0, 0.0, 0.0, -3.3696149498050594, -20.0, 0.0, -0.12168917363010956, 0.0, 0.0, 0.0, -40.0, -0.055497085467571816, 0.0, -11.374375966097208, -36.172205996224456, -10.0, 0.0, -20.0, -0.32821372472189414, 0.0, 0.0, 0.0, -7.959674072424079, 0.0, -0.04953895887726989, -3.5501380170228045, -11.264582495141008, 0.0, -0.06418899318589633, 0.0, -44.203431958185874, -10.0, 0.0, -14.415767054973573, 0.0, -17.094468417310694, 0.0, -60.52595820059219, -1.3192649771177434, -38.277489109682215, 0.0, -4.509294275303512, -3.006251248097594, -1.608760562389383, -10.481540228564624, -53.36727003731902, -22.071768856551834, -10.0, -20.102653852159612, -0.7680926647303399, -10.978804719268808, -3.083676789905919, -10.0, -10.0, -0.38803053320246916, -10.0, -6.088062344996226, 0.0, 0.0, -0.5107084453333965, -1.0436878343544198, 0.0, -6.041295423999175, 0.0, 0.0, 0.0, -2.3152320996043194, 0.0, -0.14666652890236276, -10.0, 0.0, -5.459839271678083, 0.0, -30.0, 0.0, 0.0, -40.0, 0.0, -5.960122503152443, -14.261355690064583, -0.9495361045000605, -0.04953722819121764, -20.0, -20.337157939887156, 0.0, 0.0, 0.0, 0.0, -10.0, -20.88738755835441, -10.0, -11.583730805643254, -2.4538915954720073, -9.659159507200313, -3.3731005144083808, 0.0, -30.93947597294436, 0.0, 0.0, -6.441976552827054, 0.0, -10.690237232986888, 0.0, -11.568564881875066, 0.0, -10.0, 0.0, 0.0, -22.47201199305212, -2.2064268823544086, 0.0, 0.0, -20.014417053799356, -20.0, 0.0, -11.935893792030901, 0.0, -20.0, -4.539155695220954, -0.12300551069153953, -5.421322621987008, -10.0, 0.0, 0.0, -10.0, -17.30413730550969, 0.0, 0.0, -31.84433198404929, 0.0, 0.0, -30.0, -4.183259555471884, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6522973829762686, "mean_inference_ms": 1.1189090190268551, "mean_action_processing_ms": 0.23565139484722492, "mean_env_wait_ms": 0.48630235753228396, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004025534087536382, "StateBufferConnector_ms": 0.0031204005472021167, "ViewRequirementAgentConnector_ms": 0.08543394749460656}, "num_episodes": 153, "episode_return_max": 119.47404179940781, "episode_return_min": -25.25734356311, "episode_return_mean": 9.268879906563845}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2416000, "num_agent_steps_trained": 2416000, "num_env_steps_sampled": 604000, "num_env_steps_trained": 604000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 361.3372368250907, "num_env_steps_trained_throughput_per_sec": 361.3372368250907, "timesteps_total": 604000, "num_env_steps_sampled_lifetime": 604000, "num_agent_steps_sampled_lifetime": 2416000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2416000, "timers": {"training_iteration_time_ms": 11303.356, "restore_workers_time_ms": 0.013, "training_step_time_ms": 11303.319, "sample_time_ms": 1103.685, "learn_time_ms": 10186.417, "learn_throughput": 392.68, "synch_weights_time_ms": 12.575}, "counters": {"num_env_steps_sampled": 604000, "num_env_steps_trained": 604000, "num_agent_steps_sampled": 2416000, "num_agent_steps_trained": 2416000}, "done": false, "training_iteration": 151, "trial_id": "86f16_00000", "date": "2024-08-08_16-46-15", "timestamp": 1723149975, "time_this_iter_s": 11.075608015060425, "time_total_s": 1994.2415249347687, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3aca61700>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 1994.2415249347687, "iterations_since_restore": 151, "perf": {"cpu_util_percent": 28.6375, "ram_util_percent": 80.55625}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4786553515187392, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.1859483225971248, "policy_loss": -0.017366046485398624, "vf_loss": 1.202607860463731, "vf_explained_var": -4.04571810512678e-07, "kl": 0.007065116444587857, "entropy": 0.3767559789279674, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 427230.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.40859725077947, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.4918819171066087, "policy_loss": -0.03790354145943032, "vf_loss": 2.5279655072217184, "vf_explained_var": 0.11912808883935214, "kl": 0.00909971519552889, "entropy": 0.949279254488647, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 145440.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 608000, "num_env_steps_trained": 608000, "num_agent_steps_sampled": 2432000, "num_agent_steps_trained": 2432000}, "env_runners": {"episode_reward_max": 100.0, "episode_reward_min": -31.991567073387763, "episode_reward_mean": 9.84648878243027, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -55.59225556312766}, "policy_reward_max": {"adversary_policy": 50.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 6.481481481481482, "agent_policy": -9.597955662014174}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, -1.6471711131602962, -1.1466072635898028, 0.0, 0.0, 60.0, -13.727585826100348, -0.36438078357696413, 0.0, -3.060695795873782, -7.436048730608638, -0.11635509559842605, 20.0, 59.60023841396445, 0.0, 0.0, 0.0, -1.3061490599119907, 50.30640499440993, -2.0609931676275615, -7.334924506225526, -2.219999846509121, -0.2826166890608739, 0.0, -1.8125247505102593, 20.0, 0.0, 0.0, -0.9195281556922319, 0.0, -1.5777956531033144, 31.867268524543917, -0.6649985147738202, 0.0, -31.086825886353374, -1.292578408178452, -3.8967489959421373, 0.0, -27.565297158211788, 20.0, -3.038733062706962, 0.0, -12.114350602001327, 35.277124956105155, -25.946385781862897, 0.0, -0.8808397498443321, 0.0, 0.0, 0.0, 0.0, 100.0, -17.32367995170765, 11.825850735888828, 15.35434297672661, -0.337144934669521, -2.21521798866081, -7.116574504726703, 0.0, 0.0, 0.0, 0.0, 0.0, 52.115283301586736, 0.0, 0.0, -5.3459178966966645, 57.053448051848804, -5.808215750063802, 60.0, -5.163918451403839, 0.0, 59.744347030094644, 59.582183267478115, -3.4876278196815944, 0.0, 100.0, 0.0, 20.0, 0.0, 0.0, 0.0, -8.501801105785109, 0.0, 16.454910550749474, 0.0, 28.669895080565382, -0.6016828934188623, 59.75428435695669, -0.2567649278338757, 20.0, 20.0, 0.0, 0.0, 0.0, 41.83295017119948, 0.0, -10.089405520225089, 0.0, 36.85044593709868, 0.0, 20.0, -1.8633513960159787, -4.001634531818659, 0.0, 0.0, 19.188314197092254, 94.40774443687235, -12.36568562818282, 80.0, -1.3703413837116107, 0.0, 20.0, 69.64803760296276, 0.0, 0.0, 100.0, 48.29389645550232, -2.696670795163775, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, -2.5493208198449313, -2.8935425039554543, 0.0, 0.0, 19.842064245819167, 10.275456144588581, 40.0, -31.991567073387763, 40.0, -0.7977358364045439, 0.0, -17.538737979542116, 0.0, 0.0, 0.0, 40.0, 60.0, 0.0, -5.076003485064774, -15.329389138818524, 0.0, -18.412616448211036, 0.0, 0.0, 60.0, -1.1461647819843157, -1.5349725480496845, 0.0, 0.0, 4.051070058538351, 0.0, -9.54855804483517, 40.0, 60.0, 0.0, 0.0, 40.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0], "policy_agent_policy_reward": [0.0, -1.6471711131602962, -1.1466072635898028, 0.0, 0.0, -30.0, -13.727585826100348, -0.36438078357696413, 0.0, -3.060695795873782, -7.436048730608638, -0.11635509559842605, -10.0, -30.39976158603555, 0.0, 0.0, 0.0, -1.3061490599119907, -39.69359500559007, -2.0609931676275615, -7.334924506225526, -2.219999846509121, -0.2826166890608739, 0.0, -1.8125247505102593, -10.0, 0.0, 0.0, -0.9195281556922319, 0.0, -1.5777956531033144, -28.13273147545608, -0.6649985147738202, 0.0, -31.086825886353374, -1.292578408178452, -3.8967489959421373, 0.0, -27.565297158211788, -10.0, -3.038733062706962, 0.0, -12.114350602001327, -24.722875043894845, -25.946385781862897, 0.0, -0.8808397498443321, 0.0, 0.0, 0.0, 0.0, -50.0, -17.32367995170765, -18.174149264111172, -14.645657023273392, -0.337144934669521, -2.21521798866081, -7.116574504726703, 0.0, 0.0, 0.0, 0.0, 0.0, -37.884716698413264, 0.0, 0.0, -5.3459178966966645, -32.946551948151196, -5.808215750063802, -30.0, -5.163918451403839, 0.0, -30.255652969905352, -30.417816732521892, -3.4876278196815944, 0.0, -50.0, 0.0, -10.0, 0.0, 0.0, 0.0, -8.501801105785109, 0.0, -13.54508944925053, 0.0, -31.330104919434625, -0.6016828934188623, -30.24571564304331, -0.2567649278338757, -10.0, -10.0, 0.0, 0.0, 0.0, -48.167049828800515, 0.0, -10.089405520225089, 0.0, -23.149554062901323, 0.0, -10.0, -1.8633513960159787, -4.001634531818659, 0.0, 0.0, -10.811685802907746, -55.59225556312766, -42.36568562818283, -40.0, -1.3703413837116107, 0.0, -10.0, -50.35196239703725, 0.0, 0.0, -50.0, -41.70610354449769, -2.696670795163775, -10.0, 0.0, 0.0, 0.0, 0.0, 0.0, -2.5493208198449313, -2.8935425039554543, 0.0, 0.0, -10.157935754180832, -19.72454385541142, -20.0, -31.991567073387763, -20.0, -0.7977358364045439, 0.0, -17.538737979542116, 0.0, 0.0, 0.0, -20.0, -30.0, 0.0, -5.076003485064774, -15.329389138818524, 0.0, -18.412616448211036, 0.0, 0.0, -30.0, -1.1461647819843157, -1.5349725480496845, 0.0, 0.0, -25.948929941461646, 0.0, -9.54855804483517, -20.0, -30.0, 0.0, 0.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.652016380693474, "mean_inference_ms": 1.1182902225146678, "mean_action_processing_ms": 0.235503745682143, "mean_env_wait_ms": 0.4861399838855687, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003963782463544681, "StateBufferConnector_ms": 0.0031624311282310957, "ViewRequirementAgentConnector_ms": 0.08743979312755444}, "num_episodes": 162, "episode_return_max": 100.0, "episode_return_min": -31.991567073387763, "episode_return_mean": 9.84648878243027}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2432000, "num_agent_steps_trained": 2432000, "num_env_steps_sampled": 608000, "num_env_steps_trained": 608000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 356.59538662438274, "num_env_steps_trained_throughput_per_sec": 356.59538662438274, "timesteps_total": 608000, "num_env_steps_sampled_lifetime": 608000, "num_agent_steps_sampled_lifetime": 2432000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2432000, "timers": {"training_iteration_time_ms": 11276.605, "restore_workers_time_ms": 0.013, "training_step_time_ms": 11276.568, "sample_time_ms": 1106.553, "learn_time_ms": 10156.558, "learn_throughput": 393.834, "synch_weights_time_ms": 12.732}, "counters": {"num_env_steps_sampled": 608000, "num_env_steps_trained": 608000, "num_agent_steps_sampled": 2432000, "num_agent_steps_trained": 2432000}, "done": false, "training_iteration": 152, "trial_id": "86f16_00000", "date": "2024-08-08_16-46-27", "timestamp": 1723149987, "time_this_iter_s": 11.222394943237305, "time_total_s": 2005.463919878006, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x309c9f0d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 2005.463919878006, "iterations_since_restore": 152, "perf": {"cpu_util_percent": 28.16875, "ram_util_percent": 80.125}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4860662734519083, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.4205621008754623, "policy_loss": -0.017836282307493453, "vf_loss": 1.4376662235310738, "vf_explained_var": 1.9200304721264128e-07, "kl": 0.007321615438428397, "entropy": 0.3770974391107018, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 430050.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.266607250024875, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.2180377354845406, "policy_loss": -0.029814565037183154, "vf_loss": 2.246172521325449, "vf_explained_var": 0.09780974425375462, "kl": 0.008398884810258692, "entropy": 0.9290629291906953, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 146400.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 612000, "num_env_steps_trained": 612000, "num_agent_steps_sampled": 2448000, "num_agent_steps_trained": 2448000}, "env_runners": {"episode_reward_max": 120.0, "episode_reward_min": -23.105404914419683, "episode_reward_mean": 11.182237338612643, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -60.0}, "policy_reward_max": {"adversary_policy": 60.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 6.419753086419753, "agent_policy": -8.077021920646617}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-17.485254695682567, 60.0, 20.0, 0.0, 0.0, -2.3089277880686456, 0.0, -17.56608815699229, 0.0, 20.0, 0.0, 80.0, 0.0, -1.983491130898728, -0.8259022234195534, -7.2190095458267995, 0.0, -6.6495177196999045, -23.105404914419683, 0.0, 0.0, 0.0, 0.0, 20.0, 0.0, 0.0, 0.0, -8.12096883603712, 60.0, 0.0, 0.0, 12.43809795639265, 0.0, 0.0, 0.0, 20.0, 0.0, 0.0, 60.0, -13.469168818094316, 0.0, 0.0, 0.0, -3.9334483942432046, -0.115477781677773, -0.08430609526091315, 0.0, 0.0, -5.486375574643007, 14.754357623560558, -0.13874860185537297, -1.5054309365204166, 0.0, 0.0, -2.57537408893311, 0.0, 20.0, 0.0, 40.0, 0.0, -9.285918260982431, 0.0, 120.0, 80.0, 0.0, -13.360087042389415, 0.0, 0.0, -14.993901772430007, 0.0, -2.5350749476502763, 0.0, 0.0, 20.0, 39.991079959739665, 0.0, 0.0, 20.0, -0.7840761331243074, 0.0, 50.72255499951116, -1.5864954169135148, 0.0, 40.0, 60.0, 40.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, -0.571309770957672, 35.4383317557487, -0.899788303772393, 0.0, 60.0, 0.0, 40.0, 20.0, 0.0, 0.0, 60.0, 0.0, 40.0, 40.0, 60.0, -0.7691118139592013, 0.0, 0.0, 0.0, 20.0, -20.33212607835954, 0.0, -0.11799177820513207, 20.0, 60.0, 60.0, 0.0, 0.0, 0.0, -1.0455710868506318, -0.10483720860236079, 0.0, 20.0, 40.0, -16.036341321223276, 0.0, 20.0, 0.0, 0.0, -5.673687816725411, 19.82980558478647, 0.0, -6.643460442201563, 0.0, 0.0, -0.09910935190845516, 20.0, -1.9256021654623767, 0.0, 0.0, 0.0, 0.0, -1.7191840826677995, 0.0, 0.0, 0.0, 0.0, 80.0, 5.99911782381189, 0.0, 60.0, 68.94888389394318, 0.0, 60.0, 35.47551130530272, 38.98127804911011, 0.0, 0.0, 20.0, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-17.485254695682567, -30.0, -10.0, 0.0, 0.0, -2.3089277880686456, 0.0, -17.56608815699229, 0.0, -10.0, 0.0, -40.0, 0.0, -1.983491130898728, -0.8259022234195534, -7.2190095458267995, 0.0, -6.6495177196999045, -23.105404914419683, 0.0, 0.0, 0.0, 0.0, -10.0, 0.0, 0.0, 0.0, -8.12096883603712, -30.0, 0.0, 0.0, -17.561902043607347, 0.0, 0.0, 0.0, -10.0, 0.0, 0.0, -30.0, -13.469168818094316, 0.0, 0.0, 0.0, -3.9334483942432046, -0.115477781677773, -0.08430609526091315, 0.0, 0.0, -5.486375574643007, -15.24564237643944, -0.13874860185537297, -1.5054309365204166, 0.0, 0.0, -2.57537408893311, 0.0, -10.0, 0.0, -20.0, 0.0, -9.285918260982431, 0.0, -60.0, -40.0, 0.0, -13.360087042389415, 0.0, 0.0, -14.993901772430007, 0.0, -2.5350749476502763, 0.0, 0.0, -10.0, -20.008920040260335, 0.0, 0.0, -10.0, -0.7840761331243074, 0.0, -39.27744500048885, -1.5864954169135148, 0.0, -20.0, -30.0, -20.0, 0.0, 0.0, 0.0, 0.0, -30.0, -30.0, -0.571309770957672, -24.561668244251305, -0.899788303772393, 0.0, -30.0, 0.0, -20.0, -10.0, 0.0, 0.0, -30.0, 0.0, -20.0, -20.0, -30.0, -0.7691118139592013, 0.0, 0.0, 0.0, -10.0, -20.33212607835954, 0.0, -0.11799177820513207, -10.0, -30.0, -30.0, 0.0, 0.0, 0.0, -1.0455710868506318, -0.10483720860236079, 0.0, -10.0, -20.0, -16.036341321223276, 0.0, -10.0, 0.0, 0.0, -5.673687816725411, -10.170194415213528, 0.0, -6.643460442201563, 0.0, 0.0, -0.09910935190845516, -10.0, -1.9256021654623767, 0.0, 0.0, 0.0, 0.0, -1.7191840826677995, 0.0, 0.0, 0.0, 0.0, -40.0, -24.00088217618811, 0.0, -30.0, -51.05111610605682, 0.0, -30.0, -24.524488694697286, -21.01872195088989, 0.0, 0.0, -10.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6515125018049621, "mean_inference_ms": 1.1176065109643054, "mean_action_processing_ms": 0.23532748775557358, "mean_env_wait_ms": 0.48586949825193243, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004227441034199279, "StateBufferConnector_ms": 0.0030661806648160203, "ViewRequirementAgentConnector_ms": 0.08407544206689906}, "num_episodes": 162, "episode_return_max": 120.0, "episode_return_min": -23.105404914419683, "episode_return_mean": 11.182237338612643}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2448000, "num_agent_steps_trained": 2448000, "num_env_steps_sampled": 612000, "num_env_steps_trained": 612000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 366.7083467729764, "num_env_steps_trained_throughput_per_sec": 366.7083467729764, "timesteps_total": 612000, "num_env_steps_sampled_lifetime": 612000, "num_agent_steps_sampled_lifetime": 2448000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2448000, "timers": {"training_iteration_time_ms": 11246.758, "restore_workers_time_ms": 0.013, "training_step_time_ms": 11246.721, "sample_time_ms": 1107.576, "learn_time_ms": 10125.802, "learn_throughput": 395.03, "synch_weights_time_ms": 12.624}, "counters": {"num_env_steps_sampled": 612000, "num_env_steps_trained": 612000, "num_agent_steps_sampled": 2448000, "num_agent_steps_trained": 2448000}, "done": false, "training_iteration": 153, "trial_id": "86f16_00000", "date": "2024-08-08_16-46-38", "timestamp": 1723149998, "time_this_iter_s": 10.914204120635986, "time_total_s": 2016.378123998642, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x309cc01f0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 2016.378123998642, "iterations_since_restore": 153, "perf": {"cpu_util_percent": 27.6375, "ram_util_percent": 80.0125}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4806714065320103, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.2916001724858657, "policy_loss": -0.01663377851264094, "vf_loss": 1.30753176721698, "vf_explained_var": -5.833011992434238e-07, "kl": 0.007021831587026703, "entropy": 0.3859923589631175, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 432870.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.2979269072413446, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.0625912494647007, "policy_loss": -0.031060597582351572, "vf_loss": 2.0919415480146806, "vf_explained_var": 0.11244474581132333, "kl": 0.00855150750502105, "entropy": 0.9517178370306889, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 147360.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 616000, "num_env_steps_trained": 616000, "num_agent_steps_sampled": 2464000, "num_agent_steps_trained": 2464000}, "env_runners": {"episode_reward_max": 100.0, "episode_reward_min": -32.04344204012019, "episode_reward_mean": 11.997618229792948, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -57.02055784462491}, "policy_reward_max": {"adversary_policy": 50.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 6.9753086419753085, "agent_policy": -8.928307696132979}, "custom_metrics": {}, "hist_stats": {"episode_reward": [20.0, 0.0, 0.0, 0.0, 60.0, 71.38411143015112, 0.0, -0.0604120074628367, -0.07248357452923515, 0.0, -1.4389815237430659, 40.0, 0.0, 0.0, -3.0167851377381094, 58.840792629767606, -7.342806706202548, 20.0, 19.76413847465845, -4.966258397374329, 0.0, -9.97272991558157, -3.477126373774218, 0.0, 19.801776654636434, 0.0, -0.6868164091104612, 0.0, 20.0, -1.333289784154219, 0.0, -0.33083136431463545, 17.148596908078485, 0.0, 20.0, -11.628459187132485, -1.4204175475000813, 0.0, 38.5975833112541, 0.0, 3.2679584756082534, 0.0, 79.29835761877442, 0.0, -12.7137409495939, 0.0, 0.0, 74.37488101905747, -32.04344204012019, 0.0, 0.0, 0.0, 0.0, -0.14042813591182424, 40.0, 40.0, -6.4597852593163205, 0.0, 60.0, 0.0, 0.0, 20.0, 0.0, 92.9794421553751, 60.0, 0.0, 40.0, 13.066794705478154, -20.194586155811386, 0.0, 0.0, -12.079764645335217, -5.679285386406022, 18.902025088352314, -1.7225204722871146, 20.0, 18.874828419949395, 0.0, -4.060773110966759, 0.0, 60.0, 20.0, 0.0, -0.6520767491225032, 53.758698439936, -1.691257068493467, 0.0, 0.0, 0.0, 40.0, 0.0, -2.1669052659098638, 34.7424445558405, 0.0, 20.0, 20.0, 58.412990232300004, 0.0, 60.0, 20.0, 0.0, 0.0, 59.96506989297106, 0.0, -0.5374077466383809, 0.0, 0.0, 0.0, -1.9713410583981006, 39.567212415411845, 20.0, -10.175943768450155, 80.0, 19.8679979340201, 27.984483102584576, 59.09424488992559, 0.0, -2.3434279554338246, 59.91302796617859, -0.01033187877128694, 18.20888015550311, 0.0, 0.0, 0.0, 20.0, 0.0, 60.0, 20.0, 0.0, -11.68720878764501, 20.0, 0.0, -17.159180159605764, 0.0, 0.0, 15.164873018723068, 58.22669342100052, 0.0, 0.0, 0.0, 13.12952869808775, 0.0, 0.0, 0.0, 40.0, 0.0, -0.8138573460674359, 0.0, 18.56073347858839, 19.23806537797058, 0.0, 0.0, 20.0, -10.941256025354626, -14.52329183130066, -0.6184030263561735, 100.0, -0.871644002113301, 0.0, -1.516820489698335, 0.0, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-10.0, 0.0, 0.0, 0.0, -30.0, -48.61588856984887, 0.0, -0.0604120074628367, -0.07248357452923515, 0.0, -1.4389815237430659, -20.0, 0.0, 0.0, -3.0167851377381094, -31.1592073702324, -7.342806706202548, -10.0, -10.235861525341555, -4.966258397374329, 0.0, -9.97272991558157, -3.477126373774218, 0.0, -10.198223345363568, 0.0, -0.6868164091104612, 0.0, -10.0, -1.333289784154219, 0.0, -0.33083136431463545, -12.851403091921519, 0.0, -10.0, -11.628459187132485, -1.4204175475000813, 0.0, -21.4024166887459, 0.0, -26.732041524391747, 0.0, -40.70164238122558, 0.0, -12.7137409495939, 0.0, 0.0, -45.62511898094256, -32.04344204012019, 0.0, 0.0, 0.0, 0.0, -0.14042813591182424, -20.0, -20.0, -6.4597852593163205, 0.0, -30.0, 0.0, 0.0, -10.0, 0.0, -57.02055784462491, -30.0, 0.0, -20.0, -16.933205294521848, -20.194586155811386, 0.0, 0.0, -12.079764645335217, -5.679285386406022, -11.097974911647686, -1.7225204722871146, -10.0, -11.125171580050605, 0.0, -4.060773110966759, 0.0, -30.0, -10.0, 0.0, -0.6520767491225032, -36.241301560064, -1.691257068493467, 0.0, 0.0, 0.0, -20.0, 0.0, -2.1669052659098638, -25.2575554441595, 0.0, -10.0, -10.0, -31.5870097677, 0.0, -30.0, -10.0, 0.0, 0.0, -30.03493010702895, 0.0, -0.5374077466383809, 0.0, 0.0, 0.0, -1.9713410583981006, -20.432787584588155, -10.0, -10.175943768450155, -40.0, -10.132002065979904, -32.015516897415424, -30.905755110074402, 0.0, -2.3434279554338246, -30.086972033821407, -0.01033187877128694, -11.79111984449689, 0.0, 0.0, 0.0, -10.0, 0.0, -30.0, -10.0, 0.0, -11.68720878764501, -10.0, 0.0, -17.159180159605764, 0.0, 0.0, -14.835126981276929, -31.77330657899947, 0.0, 0.0, 0.0, -16.87047130191225, 0.0, 0.0, 0.0, -20.0, 0.0, -0.8138573460674359, 0.0, -11.439266521411612, -10.761934622029418, 0.0, 0.0, -10.0, -10.941256025354626, -14.52329183130066, -0.6184030263561735, -50.0, -0.871644002113301, 0.0, -1.516820489698335, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6511081086331345, "mean_inference_ms": 1.1168930914383837, "mean_action_processing_ms": 0.23515151251094912, "mean_env_wait_ms": 0.4856334077013545, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004599344583205235, "StateBufferConnector_ms": 0.0030527144302556542, "ViewRequirementAgentConnector_ms": 0.08485942711064845}, "num_episodes": 162, "episode_return_max": 100.0, "episode_return_min": -32.04344204012019, "episode_return_mean": 11.997618229792948}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2464000, "num_agent_steps_trained": 2464000, "num_env_steps_sampled": 616000, "num_env_steps_trained": 616000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 362.2303203321016, "num_env_steps_trained_throughput_per_sec": 362.2303203321016, "timesteps_total": 616000, "num_env_steps_sampled_lifetime": 616000, "num_agent_steps_sampled_lifetime": 2464000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2464000, "timers": {"training_iteration_time_ms": 11231.522, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11231.483, "sample_time_ms": 1111.225, "learn_time_ms": 10106.899, "learn_throughput": 395.769, "synch_weights_time_ms": 12.563}, "counters": {"num_env_steps_sampled": 616000, "num_env_steps_trained": 616000, "num_agent_steps_sampled": 2464000, "num_agent_steps_trained": 2464000}, "done": false, "training_iteration": 154, "trial_id": "86f16_00000", "date": "2024-08-08_16-46-50", "timestamp": 1723150010, "time_this_iter_s": 11.048894882202148, "time_total_s": 2027.4270188808441, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3aca3f4c0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 2027.4270188808441, "iterations_since_restore": 154, "perf": {"cpu_util_percent": 28.176470588235293, "ram_util_percent": 80.6470588235294}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4632444477039026, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.5531069134778164, "policy_loss": -0.01797585440741799, "vf_loss": 1.570247857494557, "vf_explained_var": -8.029717925592518e-08, "kl": 0.008349086317727577, "entropy": 0.3754617343557642, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 435690.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.1233914584542313, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.278957610577345, "policy_loss": -0.032965437378152274, "vf_loss": 2.310017374282082, "vf_explained_var": 0.051648050112028915, "kl": 0.009528391514842601, "entropy": 0.9861254292850693, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 148320.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 620000, "num_env_steps_trained": 620000, "num_agent_steps_sampled": 2480000, "num_agent_steps_trained": 2480000}, "env_runners": {"episode_reward_max": 138.53682112873128, "episode_reward_min": -21.587815678287992, "episode_reward_mean": 12.624243619410347, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 157, "episodes_timesteps_total": 3925, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -71.46317887126872}, "policy_reward_max": {"adversary_policy": 70.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 7.13375796178344, "agent_policy": -8.77703026593997}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.2166432430668086, 37.80025745423203, -1.2079211673772394, -3.2748916829624077, 0.0, -0.8083942575471614, 0.0, 34.86525471063647, 0.0, 0.0, 0.0, -3.5586628452581364, -0.8756332891670993, -13.06525823485379, 0.0, 0.0, -3.5617055697527, 14.921863393943083, 0.0, 0.0, -1.9865348668945326, 0.0, 0.0, 0.0, 40.0, 80.0, 0.0, 80.0, -8.771284671606624, 40.0, 0.0, 0.0, 0.0, 0.0, 34.32746860239813, -21.587815678287992, -0.6253056421457559, 19.070805258617145, 40.0, 39.41466472925427, -2.7037077209515323, 0.0, 20.0, -2.2316265271783733, -8.715953677967583, 60.0, 15.769209491895056, 0.0, 0.0, 0.0, -2.335017628985903, -7.7669021734688215, 19.828717432358076, -0.5811149363781154, 0.0, 0.0, -17.23686979079125, -0.4896540049793807, -12.309485061954105, 0.0, 0.0, 53.90701837692792, 0.0, 60.0, 0.0, -1.3588227694059385, 0.0, -5.3912272189936665, -0.6660144216508135, 0.0, 0.0, 60.0, 120.0, -4.305708308802755, 0.0, -2.5791935125986205, 0.0, 0.0, -8.4616873748586, -1.739838923304864, 0.0, 0.0, 0.0, 40.0, 0.0, 0.0, 58.663986851274686, 19.74727245854155, 0.0, 138.53682112873128, -15.630002772838163, 0.0, 0.0, 50.25730098711439, 0.0, 20.0, 20.0, 50.20226254836367, 0.0, -2.9502327547179306, 0.0, 0.0, 40.0, -0.9013781053013503, 20.0, -3.3434512975766353, -4.719084508678847, 59.70062624897557, 80.0, 0.0, 0.0, 40.0, 0.0, 60.0, 39.91894619018021, 0.0, 80.0, 0.0, 39.993577264165594, 20.0, -10.517090411717414, 31.566152154721305, 0.0, 0.0, 40.0, 0.0, 0.0, -0.22454439141719296, 0.0, 0.0, -5.611571127672877, 80.0, 20.0, 0.0, 0.0, 60.0, 0.0, 0.0, 40.0, -3.313874099384657, 20.0, 0.0, -1.3682677809140131, 0.0, 40.0, -4.885731065873852, -1.5464135141084834, 20.0, -0.7468497963408272, 0.0, 20.0, 0.0, 0.0, 40.0, 17.685409792826995, 0.0, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-0.2166432430668086, -22.19974254576797, -1.2079211673772394, -3.2748916829624077, 0.0, -0.8083942575471614, 0.0, -25.13474528936353, 0.0, 0.0, 0.0, -3.5586628452581364, -0.8756332891670993, -13.06525823485379, 0.0, 0.0, -3.5617055697527, -15.078136606056917, 0.0, 0.0, -1.9865348668945326, 0.0, 0.0, 0.0, -20.0, -40.0, 0.0, -40.0, -8.771284671606624, -20.0, 0.0, 0.0, 0.0, 0.0, -25.672531397601873, -21.587815678287992, -0.6253056421457559, -10.929194741382855, -20.0, -20.58533527074573, -2.7037077209515323, 0.0, -10.0, -2.2316265271783733, -8.715953677967583, -30.0, -14.230790508104944, 0.0, 0.0, 0.0, -2.335017628985903, -7.7669021734688215, -10.171282567641924, -0.5811149363781154, 0.0, 0.0, -17.23686979079125, -0.4896540049793807, -12.309485061954105, 0.0, 0.0, -36.09298162307208, 0.0, -30.0, 0.0, -1.3588227694059385, 0.0, -5.3912272189936665, -0.6660144216508135, 0.0, 0.0, -30.0, -60.0, -4.305708308802755, 0.0, -2.5791935125986205, 0.0, 0.0, -8.4616873748586, -1.739838923304864, 0.0, 0.0, 0.0, -20.0, 0.0, 0.0, -31.336013148725318, -10.252727541458452, 0.0, -71.46317887126872, -15.630002772838163, 0.0, 0.0, -39.74269901288561, 0.0, -10.0, -10.0, -39.79773745163633, 0.0, -2.9502327547179306, 0.0, 0.0, -20.0, -0.9013781053013503, -10.0, -3.3434512975766353, -4.719084508678847, -30.299373751024426, -40.0, 0.0, 0.0, -20.0, 0.0, -30.0, -20.081053809819792, 0.0, -40.0, 0.0, -20.006422735834402, -10.0, -10.517090411717414, -28.433847845278706, 0.0, 0.0, -20.0, 0.0, 0.0, -0.22454439141719296, 0.0, 0.0, -5.611571127672877, -40.0, -10.0, 0.0, 0.0, -30.0, 0.0, 0.0, -20.0, -3.313874099384657, -10.0, 0.0, -1.3682677809140131, 0.0, -20.0, -4.885731065873852, -1.5464135141084834, -10.0, -0.7468497963408272, 0.0, -10.0, 0.0, 0.0, -20.0, -12.314590207173005, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.650856412626936, "mean_inference_ms": 1.1165389421837733, "mean_action_processing_ms": 0.23514882046339106, "mean_env_wait_ms": 0.4855462814026348, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0041982930177336284, "StateBufferConnector_ms": 0.0031529718143924784, "ViewRequirementAgentConnector_ms": 0.08512044408518797}, "num_episodes": 157, "episode_return_max": 138.53682112873128, "episode_return_min": -21.587815678287992, "episode_return_mean": 12.624243619410347}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2480000, "num_agent_steps_trained": 2480000, "num_env_steps_sampled": 620000, "num_env_steps_trained": 620000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 358.5631490778749, "num_env_steps_trained_throughput_per_sec": 358.5631490778749, "timesteps_total": 620000, "num_env_steps_sampled_lifetime": 620000, "num_agent_steps_sampled_lifetime": 2480000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2480000, "timers": {"training_iteration_time_ms": 11242.488, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11242.449, "sample_time_ms": 1104.506, "learn_time_ms": 10124.531, "learn_throughput": 395.08, "synch_weights_time_ms": 12.651}, "counters": {"num_env_steps_sampled": 620000, "num_env_steps_trained": 620000, "num_agent_steps_sampled": 2480000, "num_agent_steps_trained": 2480000}, "done": false, "training_iteration": 155, "trial_id": "86f16_00000", "date": "2024-08-08_16-47-01", "timestamp": 1723150021, "time_this_iter_s": 11.160737037658691, "time_total_s": 2038.5877559185028, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3aca3f430>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 2038.5877559185028, "iterations_since_restore": 155, "perf": {"cpu_util_percent": 28.41875, "ram_util_percent": 80.70625}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5245089473718024, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.8298182128169012, "policy_loss": -0.02071949092923921, "vf_loss": 1.8497709809888339, "vf_explained_var": -1.8724735746992396e-07, "kl": 0.0076671902065277246, "entropy": 0.3570514828547941, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 438510.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.235558579613765, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.823126273105542, "policy_loss": -0.0323688413433653, "vf_loss": 2.853721100712816, "vf_explained_var": 0.10013892396042744, "kl": 0.008870067269700532, "entropy": 0.9492774280409019, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 149280.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 624000, "num_env_steps_trained": 624000, "num_agent_steps_sampled": 2496000, "num_agent_steps_trained": 2496000}, "env_runners": {"episode_reward_max": 115.11133590843643, "episode_reward_min": -27.6616331413487, "episode_reward_mean": 11.66448778706394, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 158, "episodes_timesteps_total": 3950, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -64.88866409156356}, "policy_reward_max": {"adversary_policy": 60.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 7.151898734177215, "agent_policy": -9.791208415467704}, "custom_metrics": {}, "hist_stats": {"episode_reward": [36.54388892740512, 0.0, 0.0, 80.0, 0.0, -0.30188428480306007, -1.0152790784718058, -0.721541677395986, 18.253420562885157, 20.0, 51.70567925260073, 0.0, 80.0, 0.0, -18.33525207702062, 0.0, 20.0, -2.6686485367617543, 0.0, -8.465569411136183, 0.0, 18.458703433738773, 0.0, 30.979416865235372, 0.0, 0.0, 80.0, 24.665226532228175, 19.90578303297158, 0.0, 36.02927746465203, 80.0, -8.511055417802917, -0.3464065878156386, -0.9070089587438368, 0.0, -1.485049706791931, -17.382791999818192, -0.24554703779259834, 40.0, 0.0, 20.0, 40.0, 0.0, 20.0, 0.0, -3.269762895566016, 59.94763201984148, 0.0, 20.646780676485108, -1.2186969274027881, 40.0, -5.454355799266482, -0.49418698152981166, 0.0, -0.18298180325357238, 20.0, 20.0, -12.660466482943058, 0.0, 0.0, 37.46681851355827, 50.562251829788366, 32.75986998226726, -23.478251780740873, 0.0, 0.0, 60.0, 17.892402609789098, 39.9612279018683, 0.0, 0.0, 0.0, 0.0, 20.0, 40.0, -16.453718864854306, 0.0, 20.0, -6.640301657344506, 0.0, 0.0, -2.4036175901800503, 20.0, 0.0, 20.0, 0.0, 40.0, 0.0, -9.587274663085381, -0.8153347470916861, -0.21447652991398614, 0.0, -27.6616331413487, -0.7245229293056998, -7.841202785756748, -1.4685402958081184, -2.592339248616322, 0.0, 0.0, -1.995611006283745, 40.0, 14.724821536819238, 0.0, -1.7224698340110922, -1.4455313922202684, 40.0, 0.0, 0.0, 20.0, -4.469458553940739, -4.007349743276471, 0.0, -0.8276264337472328, 115.11133590843643, -1.6384065432431483, -3.8253503671998397, 0.0, -5.3531534930305575, 0.0, 0.0, -3.600762750551774, 95.65329663461061, -0.9298584379066677, 40.0, 35.11210027211979, -1.946910218960436, 13.813202734723532, 39.262167167291395, 0.0, 0.0, -0.8349295142294266, -1.05743616794577, 0.0, 0.0, -0.411012094704557, 19.575551838910176, 20.0, 58.545013420573525, 0.0, 19.772487293431098, 15.991316498863556, 0.0, 40.0, -25.18430561569905, 20.0, 60.0, 0.0, 59.657846191280214, 0.0, -5.12356690482378, 0.0, -1.5145123967350493, -0.301944297931408, 0.0, -6.860935774476161, 36.59038269300815, 20.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0], "policy_agent_policy_reward": [-23.45611107259489, 0.0, 0.0, -40.0, 0.0, -0.30188428480306007, -1.0152790784718058, -0.721541677395986, -11.746579437114848, -10.0, -38.29432074739927, 0.0, -40.0, 0.0, -18.33525207702062, 0.0, -10.0, -2.6686485367617543, 0.0, -8.465569411136183, 0.0, -11.541296566261227, 0.0, -29.020583134764628, 0.0, 0.0, -40.0, -35.33477346777183, -10.094216967028421, 0.0, -23.970722535347967, -40.0, -8.511055417802917, -0.3464065878156386, -30.907008958743837, 0.0, -1.485049706791931, -17.382791999818192, -0.24554703779259834, -20.0, 0.0, -10.0, -20.0, 0.0, -10.0, 0.0, -3.269762895566016, -30.05236798015853, 0.0, -39.35321932351489, -1.2186969274027881, -20.0, -5.454355799266482, -0.49418698152981166, 0.0, -0.18298180325357238, -10.0, -10.0, -12.660466482943058, 0.0, 0.0, -22.533181486441727, -39.437748170211634, -27.24013001773274, -23.478251780740873, 0.0, 0.0, -30.0, -12.107597390210904, -20.0387720981317, 0.0, 0.0, 0.0, 0.0, -10.0, -20.0, -16.453718864854306, 0.0, -10.0, -6.640301657344506, 0.0, 0.0, -2.4036175901800503, -10.0, 0.0, -10.0, 0.0, -20.0, 0.0, -9.587274663085381, -0.8153347470916861, -0.21447652991398614, 0.0, -27.6616331413487, -0.7245229293056998, -7.841202785756748, -1.4685402958081184, -2.592339248616322, 0.0, 0.0, -1.995611006283745, -20.0, -15.275178463180758, 0.0, -1.7224698340110922, -1.4455313922202684, -20.0, 0.0, 0.0, -10.0, -4.469458553940739, -34.00734974327647, 0.0, -0.8276264337472328, -64.88866409156356, -1.6384065432431483, -3.8253503671998397, 0.0, -5.3531534930305575, 0.0, 0.0, -3.600762750551774, -54.346703365389374, -0.9298584379066677, -20.0, -24.887899727880214, -1.946910218960436, -16.186797265276468, -20.737832832708605, 0.0, 0.0, -0.8349295142294266, -1.05743616794577, 0.0, 0.0, -0.411012094704557, -10.424448161089824, -10.0, -31.454986579426468, 0.0, -10.227512706568904, -14.008683501136444, 0.0, -20.0, -25.18430561569905, -10.0, -30.0, 0.0, -30.342153808719793, 0.0, -5.12356690482378, 0.0, -1.5145123967350493, -0.301944297931408, 0.0, -6.860935774476161, -23.40961730699185, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6498595719853646, "mean_inference_ms": 1.1147424060061542, "mean_action_processing_ms": 0.2345980468958401, "mean_env_wait_ms": 0.4848527278566971, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004566093034382108, "StateBufferConnector_ms": 0.0031695335726194744, "ViewRequirementAgentConnector_ms": 0.08447057084192204}, "num_episodes": 158, "episode_return_max": 115.11133590843643, "episode_return_min": -27.6616331413487, "episode_return_mean": 11.66448778706394}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2496000, "num_agent_steps_trained": 2496000, "num_env_steps_sampled": 624000, "num_env_steps_trained": 624000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 360.77059796833095, "num_env_steps_trained_throughput_per_sec": 360.77059796833095, "timesteps_total": 624000, "num_env_steps_sampled_lifetime": 624000, "num_agent_steps_sampled_lifetime": 2496000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2496000, "timers": {"training_iteration_time_ms": 11214.445, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11214.407, "sample_time_ms": 1108.89, "learn_time_ms": 10092.208, "learn_throughput": 396.345, "synch_weights_time_ms": 12.545}, "counters": {"num_env_steps_sampled": 624000, "num_env_steps_trained": 624000, "num_agent_steps_sampled": 2496000, "num_agent_steps_trained": 2496000}, "done": false, "training_iteration": 156, "trial_id": "86f16_00000", "date": "2024-08-08_16-47-12", "timestamp": 1723150032, "time_this_iter_s": 11.093998908996582, "time_total_s": 2049.6817548274994, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x309cc0dc0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 2049.6817548274994, "iterations_since_restore": 156, "perf": {"cpu_util_percent": 29.431250000000002, "ram_util_percent": 80.76875}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.47799826697677583, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.2684641778257721, "policy_loss": -0.017167665533216154, "vf_loss": 1.2850084957924295, "vf_explained_var": -8.468086837876773e-07, "kl": 0.006233457236099091, "entropy": 0.37360313184929234, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 441330.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.293772909293572, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.1048246244279047, "policy_loss": -0.02836468068417162, "vf_loss": 2.1315735545009376, "vf_explained_var": 0.11586960392693678, "kl": 0.008078756050200298, "entropy": 0.9506704809765021, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 150240.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 628000, "num_env_steps_trained": 628000, "num_agent_steps_sampled": 2512000, "num_agent_steps_trained": 2512000}, "env_runners": {"episode_reward_max": 115.83872178518328, "episode_reward_min": -20.107988867117907, "episode_reward_mean": 9.269795471192745, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -65.60743795265891}, "policy_reward_max": {"adversary_policy": 60.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 5.493827160493828, "agent_policy": -7.211686010288736}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-10.09088856378862, -2.5534572185316353, 0.0, 0.0, 0.0, -0.7239114355841925, 20.0, 0.0, 0.0, 0.0, 40.0, 0.0, 40.0, 114.3925620473411, -1.3563363929002492, -3.659437896545326, 115.83872178518328, 39.06136346201548, 19.690149873982797, 0.0, 0.0, 0.0, 40.0, 0.0, 0.0, 60.0, 36.41915307712121, 0.0, -16.927079108659, 40.0, -1.7361732327095547, 0.0, 20.0, 0.0, 0.0, -0.709622858210115, 0.0, 8.152948264544568, 0.0, 40.0, -0.4504976376322367, 0.0, 0.0, 0.0, 20.12940585158819, -5.258439842080725, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, -17.882338801076358, 40.0, 0.0, 0.0, -2.161887030367896, 0.0, 0.0, 0.0, 60.0, -3.639315388248993, 0.0, 19.941187158504338, 0.0, -0.06106663209059282, 0.0, -0.09293141420496642, 0.0, 8.929074946963695, 0.0, 0.0, -8.979041412315274, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, -6.1132914290649465, 0.0, 0.0, 0.0, 0.0, 0.0, -2.7049050120981857, 60.0, 0.0, 20.0, -8.08817906255263, 0.0, 0.0, -0.3378017943418754, 0.0, -3.5597361969050416, 0.0, 0.0, 20.0, -1.9772574922421848, 56.26657636961541, 0.0, 40.0, 20.0, 0.0, -16.567570053548828, 0.0, 0.0, 0.0, 20.0, -16.16935699744287, -4.225129504354291, -0.2560393802316574, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.1493841421817066, 0.0, 40.0, -0.14788415055565052, -0.258919675402155, 38.12843989704748, -0.5615744465219752, 0.0, 60.0, 0.0, -0.3391262612387058, -1.278882832945325, 40.0, 78.49493571988154, 0.0, 17.612654200394392, 0.0, 40.0, 0.0, 39.05489766152675, -10.572455167221477, 43.36986328756159, 0.0, -0.06286971448796974, -20.107988867117907, 40.0, 0.0, 0.0, -8.463140483427082, -9.974913637481826, 0.0, 0.0, 0.0, 20.0, 0.0, 38.81607525911586, -3.0997422234155856, 0.0, 0.0, 20.0, 58.707430860562795], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0], "policy_agent_policy_reward": [-10.09088856378862, -2.5534572185316353, 0.0, 0.0, 0.0, -0.7239114355841925, -10.0, 0.0, 0.0, 0.0, -20.0, 0.0, -20.0, -65.60743795265891, -1.3563363929002492, -3.659437896545326, -64.16127821481672, -20.93863653798452, -10.309850126017201, 0.0, 0.0, 0.0, -20.0, 0.0, 0.0, -30.0, -23.580846922878795, 0.0, -16.927079108659, -20.0, -1.7361732327095547, 0.0, -10.0, 0.0, 0.0, -0.709622858210115, 0.0, -21.847051735455434, 0.0, -20.0, -0.4504976376322367, 0.0, 0.0, 0.0, -39.87059414841181, -5.258439842080725, 0.0, 0.0, -10.0, -10.0, -10.0, 0.0, 0.0, -17.882338801076358, -20.0, 0.0, 0.0, -2.161887030367896, 0.0, 0.0, 0.0, -30.0, -3.639315388248993, 0.0, -10.058812841495662, 0.0, -0.06106663209059282, 0.0, -0.09293141420496642, 0.0, -21.070925053036305, 0.0, 0.0, -8.979041412315274, 0.0, 0.0, 0.0, 0.0, -10.0, -10.0, -6.1132914290649465, 0.0, 0.0, 0.0, 0.0, 0.0, -2.7049050120981857, -30.0, 0.0, -10.0, -8.08817906255263, 0.0, 0.0, -0.3378017943418754, 0.0, -3.5597361969050416, 0.0, 0.0, -10.0, -1.9772574922421848, -33.733423630384586, 0.0, -20.0, -10.0, 0.0, -16.567570053548828, 0.0, 0.0, 0.0, -10.0, -16.16935699744287, -4.225129504354291, -0.2560393802316574, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.1493841421817066, 0.0, -20.0, -0.14788415055565052, -0.258919675402155, -21.87156010295252, -0.5615744465219752, 0.0, -30.0, 0.0, -0.3391262612387058, -1.278882832945325, -20.0, -41.50506428011847, 0.0, -12.387345799605605, 0.0, -20.0, 0.0, -20.945102338473248, -10.572455167221477, -46.63013671243841, 0.0, -0.06286971448796974, -20.107988867117907, -20.0, 0.0, 0.0, -8.463140483427082, -9.974913637481826, 0.0, 0.0, 0.0, -10.0, 0.0, -21.18392474088413, -3.0997422234155856, 0.0, 0.0, -10.0, -31.292569139437198]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6496446311678067, "mean_inference_ms": 1.1144235959630937, "mean_action_processing_ms": 0.23457310270537152, "mean_env_wait_ms": 0.4847681985109413, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004149071964216821, "StateBufferConnector_ms": 0.0030096666312512056, "ViewRequirementAgentConnector_ms": 0.08578168021308051}, "num_episodes": 162, "episode_return_max": 115.83872178518328, "episode_return_min": -20.107988867117907, "episode_return_mean": 9.269795471192745}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2512000, "num_agent_steps_trained": 2512000, "num_env_steps_sampled": 628000, "num_env_steps_trained": 628000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 355.1814649699301, "num_env_steps_trained_throughput_per_sec": 355.1814649699301, "timesteps_total": 628000, "num_env_steps_sampled_lifetime": 628000, "num_agent_steps_sampled_lifetime": 2512000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2512000, "timers": {"training_iteration_time_ms": 11215.93, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11215.892, "sample_time_ms": 1106.162, "learn_time_ms": 10096.343, "learn_throughput": 396.183, "synch_weights_time_ms": 12.576}, "counters": {"num_env_steps_sampled": 628000, "num_env_steps_trained": 628000, "num_agent_steps_sampled": 2512000, "num_agent_steps_trained": 2512000}, "done": false, "training_iteration": 157, "trial_id": "86f16_00000", "date": "2024-08-08_16-47-24", "timestamp": 1723150044, "time_this_iter_s": 11.26752519607544, "time_total_s": 2060.949280023575, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad583430>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 2060.949280023575, "iterations_since_restore": 157, "perf": {"cpu_util_percent": 27.91875, "ram_util_percent": 80.7875}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4579262763526, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.4465960583788284, "policy_loss": -0.01672021435038682, "vf_loss": 1.46252585704445, "vf_explained_var": -2.3085174831092782e-07, "kl": 0.007904128339706433, "entropy": 0.3959307539547589, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 444150.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.1167240063349406, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.4877079146293304, "policy_loss": -0.03270499451609794, "vf_loss": 2.5184115418310586, "vf_explained_var": 0.09288710113614798, "kl": 0.010006823524615975, "entropy": 0.9563867491359512, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 151200.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 632000, "num_env_steps_trained": 632000, "num_agent_steps_sampled": 2528000, "num_agent_steps_trained": 2528000}, "env_runners": {"episode_reward_max": 100.0, "episode_reward_min": -23.3498798895379, "episode_reward_mean": 9.403834431186715, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -51.806824002124465}, "policy_reward_max": {"adversary_policy": 50.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 5.7407407407407405, "agent_policy": -7.818387791035507}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 60.0, 0.0, -10.06327249155601, 0.0, 60.0, 40.0, 0.0, -1.8652583099025843, 0.0, 0.0, 0.0, 0.0, 57.99179051030747, -0.8477922412240224, -0.4798610183604146, 0.0, 0.0, 0.0, -11.195329991748517, 0.0, 0.0, 0.0, -8.632641955858963, 0.0, 0.0, -2.011331840719116, 0.0, -1.8310286299537792, 0.0, 74.50175517919956, 80.0, 38.10446765937813, 0.0, 0.0, -0.974278401957076, 16.69002895453519, 20.0, -0.2187424099432167, 100.0, 0.0, 0.0, 0.0, 0.0, 37.415764662321834, 40.0, 40.0, -23.3498798895379, -1.310691285790728, 40.0, 20.0, 0.0, 60.0, 38.193175997875535, -9.270985150689569, 40.0, -2.2210480539020185, -0.16877722947883922, 20.0, -10.058627424844811, 0.0, 20.0, -21.40085811778866, 20.0, 0.0, 20.0, 0.0, 0.0, -4.837550035631409, 0.0, -12.745906910512414, 20.0, 0.0, 0.0, 0.0, 0.0, 40.0, 80.0, 0.0, 0.0, -3.778223189258399, 0.0, 20.0, 0.0, 0.0, -9.131928391421326, -7.352825050932351, 12.753191035213685, 9.962790575494441, 3.2042792374342355, 38.36633139664091, 0.0, -1.004309670042659, 0.0, -5.149599549361598, -0.4922801357255713, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 100.0, -1.5683408515845765, -0.19980596371903858, -10.049160130801676, 19.137885215897057, 0.0, 0.0, 0.0, 54.76366515840706, 20.0, 0.0, 20.0, -23.043268984506568, 0.0, 0.0, 0.0, -0.11038454444494028, -8.858866563415033, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -9.464620866951227, -0.00782499016549476, 40.0, 0.0, 0.0, 16.983902625423184, 38.84161146910097, 0.0, 0.0, 0.0, 0.0, 60.0, 0.0, 40.0, -2.2710281047278835, -0.4120259227640466, 0.0, 0.0, 20.0, 0.0, 0.0, -1.3557095287367071, 38.028578856984026, 0.0, 0.0, 10.962704300498643, -13.77533537696405, 60.0, 40.0, -10.88588048284652, -0.9810720542603102, -9.104393240434074, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [0.0, 0.0, 0.0, -30.0, 0.0, -10.06327249155601, 0.0, -30.0, -20.0, 0.0, -1.8652583099025843, 0.0, 0.0, 0.0, 0.0, -32.00820948969253, -0.8477922412240224, -0.4798610183604146, 0.0, 0.0, 0.0, -11.195329991748517, 0.0, 0.0, 0.0, -8.632641955858963, 0.0, 0.0, -2.011331840719116, 0.0, -1.8310286299537792, 0.0, -45.498244820800444, -40.0, -21.89553234062187, 0.0, 0.0, -0.974278401957076, -13.309971045464813, -10.0, -0.2187424099432167, -50.0, 0.0, 0.0, 0.0, 0.0, -22.58423533767817, -20.0, -20.0, -23.3498798895379, -1.310691285790728, -20.0, -10.0, 0.0, -30.0, -51.806824002124465, -9.270985150689569, -20.0, -2.2210480539020185, -0.16877722947883922, -10.0, -10.058627424844811, 0.0, -10.0, -21.40085811778866, -10.0, 0.0, -10.0, 0.0, 0.0, -4.837550035631409, 0.0, -12.745906910512414, -10.0, 0.0, 0.0, 0.0, 0.0, -20.0, -40.0, 0.0, 0.0, -3.778223189258399, 0.0, -10.0, 0.0, 0.0, -9.131928391421326, -7.352825050932351, -17.246808964786315, -20.03720942450556, -26.795720762565765, -21.63366860335909, 0.0, -1.004309670042659, 0.0, -5.149599549361598, -0.4922801357255713, 0.0, 0.0, 0.0, 0.0, 0.0, -10.0, -50.0, -1.5683408515845765, -0.19980596371903858, -10.049160130801676, -10.862114784102939, 0.0, 0.0, 0.0, -35.236334841592935, -10.0, 0.0, -10.0, -23.043268984506568, 0.0, 0.0, 0.0, -0.11038454444494028, -8.858866563415033, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -9.464620866951227, -0.00782499016549476, -20.0, 0.0, 0.0, -13.016097374576818, -21.158388530899032, 0.0, 0.0, 0.0, 0.0, -30.0, 0.0, -20.0, -2.2710281047278835, -0.4120259227640466, 0.0, 0.0, -10.0, 0.0, 0.0, -1.3557095287367071, -21.971421143015974, 0.0, 0.0, -19.037295699501357, -13.77533537696405, -30.0, -20.0, -10.88588048284652, -0.9810720542603102, -9.104393240434074, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6492119591702545, "mean_inference_ms": 1.1136968378218555, "mean_action_processing_ms": 0.23440348625197907, "mean_env_wait_ms": 0.4845447331660203, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004094765510088132, "StateBufferConnector_ms": 0.00308111861900047, "ViewRequirementAgentConnector_ms": 0.08645948068595227}, "num_episodes": 162, "episode_return_max": 100.0, "episode_return_min": -23.3498798895379, "episode_return_mean": 9.403834431186715}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2528000, "num_agent_steps_trained": 2528000, "num_env_steps_sampled": 632000, "num_env_steps_trained": 632000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 356.3339168366808, "num_env_steps_trained_throughput_per_sec": 356.3339168366808, "timesteps_total": 632000, "num_env_steps_sampled_lifetime": 632000, "num_agent_steps_sampled_lifetime": 2528000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2528000, "timers": {"training_iteration_time_ms": 11184.372, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11184.331, "sample_time_ms": 1105.955, "learn_time_ms": 10065.016, "learn_throughput": 397.416, "synch_weights_time_ms": 12.552}, "counters": {"num_env_steps_sampled": 632000, "num_env_steps_trained": 632000, "num_agent_steps_sampled": 2528000, "num_agent_steps_trained": 2528000}, "done": false, "training_iteration": 158, "trial_id": "86f16_00000", "date": "2024-08-08_16-47-35", "timestamp": 1723150055, "time_this_iter_s": 11.23128604888916, "time_total_s": 2072.180566072464, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad583e50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 2072.180566072464, "iterations_since_restore": 158, "perf": {"cpu_util_percent": 27.65, "ram_util_percent": 80.76875000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4685221958879038, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.4383072676810813, "policy_loss": -0.01768105107224183, "vf_loss": 1.4551658539907306, "vf_explained_var": -5.592057045469892e-07, "kl": 0.008224638971630066, "entropy": 0.37395408190522633, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 446970.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.1642438006276885, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.2439544474085173, "policy_loss": -0.037115339078203156, "vf_loss": 2.279233679920435, "vf_explained_var": 0.10743469608326753, "kl": 0.009180537127190528, "entropy": 0.9596623004724582, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 152160.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 636000, "num_env_steps_trained": 636000, "num_agent_steps_sampled": 2544000, "num_agent_steps_trained": 2544000}, "env_runners": {"episode_reward_max": 129.81588255136813, "episode_reward_min": -27.411379194068648, "episode_reward_mean": 10.794299736601706, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 157, "episodes_timesteps_total": 3925, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -80.18411744863188}, "policy_reward_max": {"adversary_policy": 70.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 6.560509554140127, "agent_policy": -8.887228925818675}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.16252785319397, -0.29605177411158423, 0.0, 0.0, 0.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 19.954086675863223, 20.0, 0.0, 60.0, 60.0, 5.2895495538595965, 0.0, 0.0, 0.0, 60.0, 80.0, -4.662257994032515, 0.0, 0.0, 59.54266996768263, 0.0, -0.22256319334352903, -27.411379194068648, -0.3193763258495297, 0.0, 18.47745648455016, 0.0, 0.0, 0.0, 0.0, 0.0, -0.6501778817691428, 0.0, -0.05641898547466995, 0.0, 19.70999510339232, 0.0, -4.027042564313267, 0.0, 0.0, 0.0, 0.0, -0.22035345218818225, 20.0, -1.605612057938931, 34.944355416144326, -13.476001456917778, 0.0, -7.022981700253041, 60.0, 20.0, 0.0, 15.551632313757041, 0.0, -1.546556386027118, 25.91343509173258, -5.391585782591848, 36.84437219996051, 0.0, 0.0, 40.0, -9.628082727627099, -0.039161751351690643, 0.0, 20.0, -0.3052142048955153, 60.0, 0.0, 51.806627943251776, -18.573667717364106, 0.0, 0.0, 0.0, 0.0, 0.0, -0.0009708563920074464, 20.0, -0.009804099120361842, -1.8928421109493598, 34.31222797235747, 0.0, 54.23001099118929, 19.6174270850285, 0.0, 0.0, -1.5385816659226026, 78.45913933030975, -1.4685338384515287, 0.0, 0.0, 17.85781954791341, 60.0, 129.81588255136813, 0.0, 40.0, 0.0, -7.34386248021257, 0.0, -9.186748734879298, 0.0, 0.0, 0.0, 14.389394306021883, 60.0, 0.0, 20.0, 0.0, 19.995591486757753, -0.44606138623615066, 60.0, 0.0, 0.0, 80.0, 20.0, 0.0, 0.0, 0.0, 40.0, 0.0, -4.2889817772476775, 19.629141528089516, 0.0, -0.8458740808828136, 31.892663329437198, -0.0822487597190047, 0.0, -12.923580334671808, 20.0, -12.626200385785646, 0.0, -10.81521343769206, 0.0, 0.0, 60.0, -7.900540533807773, 60.0, 40.0, 20.0, 0.0, -0.016608066107474118, 0.0, 0.0, -12.37636442559194, 0.0, 0.0, -1.9222994036655139, -7.372127171557319, 10.467318669966573, -13.64633805634854], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-21.83747214680603, -0.29605177411158423, 0.0, 0.0, 0.0, -20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -10.045913324136775, -10.0, 0.0, -30.0, -30.0, -24.710450446140403, 0.0, 0.0, 0.0, -30.0, -40.0, -4.662257994032515, 0.0, 0.0, -30.457330032317365, 0.0, -0.22256319334352903, -27.411379194068648, -0.3193763258495297, 0.0, -11.522543515449842, 0.0, 0.0, 0.0, 0.0, 0.0, -0.6501778817691428, 0.0, -0.05641898547466995, 0.0, -10.29000489660768, 0.0, -4.027042564313267, 0.0, 0.0, 0.0, 0.0, -0.22035345218818225, -10.0, -1.605612057938931, -25.055644583855678, -13.476001456917778, 0.0, -7.022981700253041, -30.0, -10.0, 0.0, -44.44836768624296, 0.0, -1.546556386027118, -34.08656490826742, -5.391585782591848, -23.155627800039483, 0.0, 0.0, -20.0, -9.628082727627099, -0.039161751351690643, 0.0, -10.0, -0.3052142048955153, -30.0, 0.0, -38.193372056748224, -18.573667717364106, 0.0, 0.0, 0.0, 0.0, 0.0, -0.0009708563920074464, -10.0, -0.009804099120361842, -1.8928421109493598, -25.687772027642527, 0.0, -35.769989008810704, -10.3825729149715, 0.0, 0.0, -1.5385816659226026, -41.54086066969025, -61.46853383845153, 0.0, 0.0, -12.142180452086588, -30.0, -80.18411744863188, 0.0, -20.0, 0.0, -7.34386248021257, 0.0, -9.186748734879298, 0.0, 0.0, 0.0, -15.610605693978117, -30.0, 0.0, -10.0, 0.0, -10.004408513242248, -0.44606138623615066, -30.0, 0.0, 0.0, -40.0, -10.0, 0.0, 0.0, 0.0, -20.0, 0.0, -4.2889817772476775, -10.370858471910484, 0.0, -0.8458740808828136, -28.107336670562805, -0.0822487597190047, 0.0, -12.923580334671808, -10.0, -12.626200385785646, 0.0, -10.81521343769206, 0.0, 0.0, -30.0, -7.900540533807773, -30.0, -20.0, -10.0, 0.0, -0.016608066107474118, 0.0, 0.0, -12.37636442559194, 0.0, 0.0, -1.9222994036655139, -7.372127171557319, -19.532681330033427, -13.64633805634854]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6489667045669416, "mean_inference_ms": 1.1134137165784856, "mean_action_processing_ms": 0.23439460199443893, "mean_env_wait_ms": 0.4844859712327168, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004003609821295283, "StateBufferConnector_ms": 0.0030301179096197625, "ViewRequirementAgentConnector_ms": 0.08310907205958275}, "num_episodes": 157, "episode_return_max": 129.81588255136813, "episode_return_min": -27.411379194068648, "episode_return_mean": 10.794299736601706}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2544000, "num_agent_steps_trained": 2544000, "num_env_steps_sampled": 636000, "num_env_steps_trained": 636000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 356.48997397871307, "num_env_steps_trained_throughput_per_sec": 356.48997397871307, "timesteps_total": 636000, "num_env_steps_sampled_lifetime": 636000, "num_agent_steps_sampled_lifetime": 2544000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2544000, "timers": {"training_iteration_time_ms": 11180.96, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11180.919, "sample_time_ms": 1107.37, "learn_time_ms": 10060.263, "learn_throughput": 397.604, "synch_weights_time_ms": 12.466}, "counters": {"num_env_steps_sampled": 636000, "num_env_steps_trained": 636000, "num_agent_steps_sampled": 2544000, "num_agent_steps_trained": 2544000}, "done": false, "training_iteration": 159, "trial_id": "86f16_00000", "date": "2024-08-08_16-47-47", "timestamp": 1723150067, "time_this_iter_s": 11.227142095565796, "time_total_s": 2083.40770816803, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x309cc01f0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 2083.40770816803, "iterations_since_restore": 159, "perf": {"cpu_util_percent": 29.46875, "ram_util_percent": 80.94999999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4703416554376166, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.4614882706961734, "policy_loss": -0.01709652193233698, "vf_loss": 1.477883052572291, "vf_explained_var": 9.60437964040337e-08, "kl": 0.0070174183093958615, "entropy": 0.36690333059704894, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 449790.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.0860163858160377, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.231234204955399, "policy_loss": -0.02806183431627384, "vf_loss": 2.257627928753694, "vf_explained_var": 0.06378832987199227, "kl": 0.008340559026185376, "entropy": 0.9340171269451578, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 153120.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 640000, "num_env_steps_trained": 640000, "num_agent_steps_sampled": 2560000, "num_agent_steps_trained": 2560000}, "env_runners": {"episode_reward_max": 120.0, "episode_reward_min": -23.452691280068684, "episode_reward_mean": 13.556289496788114, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -64.43299011112482}, "policy_reward_max": {"adversary_policy": 60.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 7.592592592592593, "agent_policy": -9.221488280989664}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 40.0, 59.75789940464148, 0.0, -2.8734720213570264, -1.8752839715836678, -15.093834917982115, 0.0, 40.0, -7.117407236817407, -3.436007704688837, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 120.0, 99.72626356478203, -16.862286986757653, 0.0, 0.0, -12.615707707690895, 28.535700533145743, 0.0, -6.004672404463, 57.11012563793146, 0.0, 0.0, 60.0, 13.367878117889617, 0.0, 0.0, 0.0, 0.0, -23.452691280068684, -2.9160634478802603, 20.0, 40.0, 0.0, 20.0, 0.0, 0.0, 60.0, 20.0, 40.0, 77.7709107003508, 0.0, -1.1531426232187658, 0.0, 0.0, 18.53457775418888, -1.857587030702037, 60.0, -10.736451783154305, 20.0, 40.0, 0.0, 0.0, 40.0, 20.0, 0.0, 0.0, 60.0, 0.0, 38.18899993925907, 0.0, 0.0, 0.0, -1.2098946092479301, 0.0, 120.0, -2.1384071745368516, 40.0, 39.23136803495566, 0.0, -0.38891134901227087, -7.346604609122672, -1.2894464807127215, 115.56700988887518, -1.1794418006009422, 57.15397824327577, 0.0, 0.0, 40.0, 0.0, 0.0, 60.0, -2.9423511068333204, -0.4541983307269093, 60.0, 0.0, 0.0, 0.0, 20.0, 20.0, 60.0, 40.0, 0.0, -4.576983410794902, -9.483642161686383, 17.435825075150593, 40.0, -0.512985676476656, 0.0, -5.543354125135, -2.9784377597871616, 40.0, 60.0, 0.0, 80.0, 0.0, -8.767690036170968, 0.0, 0.0, 0.0, 0.0, 0.0, -7.910669854034401, 0.0, -15.806883417481885, 0.0, 0.0, -0.6221726965161289, 0.0, 0.0, 0.0, -0.27950736823479483, 80.0, -0.4907370864495897, 0.0, 0.0, -3.392135637521304, 0.0, 56.45849304936107, 0.0, -1.8747112552532597, 19.763982195328637, -0.1706368700628258, 0.0, 0.0, -8.962383037296693, 0.0, 0.0, 30.563503865177672, 0.0, 44.713559629819756, 0.0, 0.0, 0.0, 0.0, -1.5025054487509482, 20.0, 40.0, -0.36850944374367534, 20.0, -1.5733672919040764, 0.0, 0.0, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 60.0, 60.0, 60.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [0.0, 0.0, -20.0, -30.242100595358526, 0.0, -2.8734720213570264, -1.8752839715836678, -15.093834917982115, 0.0, -20.0, -7.117407236817407, -3.436007704688837, -30.0, 0.0, 0.0, 0.0, 0.0, 0.0, -10.0, -60.0, -50.27373643521797, -16.862286986757653, 0.0, 0.0, -12.615707707690895, -31.464299466854264, 0.0, -6.004672404463, -32.88987436206854, 0.0, 0.0, -30.0, -16.63212188211038, 0.0, 0.0, 0.0, 0.0, -23.452691280068684, -2.9160634478802603, -10.0, -20.0, 0.0, -10.0, 0.0, 0.0, -30.0, -10.0, -20.0, -42.2290892996492, 0.0, -1.1531426232187658, 0.0, 0.0, -11.465422245811117, -1.857587030702037, -30.0, -10.736451783154305, -10.0, -20.0, 0.0, 0.0, -20.0, -10.0, 0.0, 0.0, -30.0, 0.0, -21.811000060740938, 0.0, 0.0, 0.0, -1.2098946092479301, 0.0, -60.0, -2.1384071745368516, -20.0, -20.768631965044342, 0.0, -0.38891134901227087, -7.346604609122672, -1.2894464807127215, -64.43299011112482, -1.1794418006009422, -32.84602175672422, 0.0, 0.0, -20.0, 0.0, 0.0, -30.0, -2.9423511068333204, -0.4541983307269093, -30.0, 0.0, 0.0, 0.0, -10.0, -10.0, -30.0, -20.0, 0.0, -4.576983410794902, -9.483642161686383, -12.564174924849413, -20.0, -0.512985676476656, 0.0, -5.543354125135, -2.9784377597871616, -20.0, -30.0, 0.0, -40.0, 0.0, -8.767690036170968, 0.0, 0.0, 0.0, 0.0, 0.0, -7.910669854034401, 0.0, -15.806883417481885, 0.0, 0.0, -0.6221726965161289, 0.0, 0.0, 0.0, -0.27950736823479483, -40.0, -0.4907370864495897, 0.0, 0.0, -3.392135637521304, 0.0, -33.54150695063894, 0.0, -1.8747112552532597, -10.236017804671363, -0.1706368700628258, 0.0, 0.0, -8.962383037296693, 0.0, 0.0, -29.436496134822328, 0.0, -45.286440370180244, 0.0, 0.0, 0.0, 0.0, -1.5025054487509482, -10.0, -20.0, -0.36850944374367534, -10.0, -1.5733672919040764, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6483242714475763, "mean_inference_ms": 1.1121483003617756, "mean_action_processing_ms": 0.23404925405666607, "mean_env_wait_ms": 0.48402398523094714, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00455688547205042, "StateBufferConnector_ms": 0.003169568968407902, "ViewRequirementAgentConnector_ms": 0.08700011688985942}, "num_episodes": 162, "episode_return_max": 120.0, "episode_return_min": -23.452691280068684, "episode_return_mean": 13.556289496788114}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2560000, "num_agent_steps_trained": 2560000, "num_env_steps_sampled": 640000, "num_env_steps_trained": 640000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 349.9552168635818, "num_env_steps_trained_throughput_per_sec": 349.9552168635818, "timesteps_total": 640000, "num_env_steps_sampled_lifetime": 640000, "num_agent_steps_sampled_lifetime": 2560000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2560000, "timers": {"training_iteration_time_ms": 11161.866, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11161.826, "sample_time_ms": 1107.831, "learn_time_ms": 10041.533, "learn_throughput": 398.346, "synch_weights_time_ms": 11.891}, "counters": {"num_env_steps_sampled": 640000, "num_env_steps_trained": 640000, "num_agent_steps_sampled": 2560000, "num_agent_steps_trained": 2560000}, "done": false, "training_iteration": 160, "trial_id": "86f16_00000", "date": "2024-08-08_16-47-58", "timestamp": 1723150078, "time_this_iter_s": 11.435471773147583, "time_total_s": 2094.8431799411774, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad583ee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 2094.8431799411774, "iterations_since_restore": 160, "perf": {"cpu_util_percent": 32.487500000000004, "ram_util_percent": 81.59374999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4784908778331381, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.4493888428659303, "policy_loss": -0.019011710299730485, "vf_loss": 1.4675956708319644, "vf_explained_var": 5.118601711083811e-07, "kl": 0.00804879782956424, "entropy": 0.3817092003657463, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 452610.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.30196083933115, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.316662752255797, "policy_loss": -0.03082093624107074, "vf_loss": 2.3457353126257656, "vf_explained_var": 0.03307927660644054, "kl": 0.00874184961643139, "entropy": 0.9206755238274733, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 154080.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 644000, "num_env_steps_trained": 644000, "num_agent_steps_sampled": 2576000, "num_agent_steps_trained": 2576000}, "env_runners": {"episode_reward_max": 100.0, "episode_reward_min": -25.594429115990874, "episode_reward_mean": 12.677211694441514, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 158, "episodes_timesteps_total": 3950, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -50.0}, "policy_reward_max": {"adversary_policy": 50.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 7.468354430379747, "agent_policy": -9.727851596697727}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.4481879892222995, -8.405794668650636, 0.0, 0.0, -7.776195716397904, 20.0, 0.0, -1.5017502210207667, 0.0, 40.0, -5.58269687965687, -2.4099712943339537, 0.0, 19.81875568962597, -4.463443187828916, 0.0, 0.0, 12.044833865600525, 0.0, 0.0, 16.26226941357004, 0.0, -12.559723311196477, 0.0, -11.486841281854922, 14.5976577432072, 58.88888887240266, 40.0, 0.0, -7.334330634364608, 36.29064067394927, -5.810625659083283, 59.12641534088766, 80.0, -16.175339852316863, 0.0, 39.49472702857854, 0.0, 40.0, 0.0, -0.22704392336355683, -10.301382092729119, -2.530031180412343, 0.0, 0.0, 39.04292249518973, 100.0, 76.13784772938641, 0.0, 47.82305692351555, 0.0, 20.0, 0.0, -5.415026407085035, 19.345436602895404, 0.0, 16.732026010337023, 0.0, 0.0, -1.017257139442026, 0.0, 80.0, 0.0, 100.0, 55.96725814319819, -5.952463365857548, 0.0, -9.503993128625751, 60.0, 0.0, -0.13551762214493834, 38.43006023430325, -1.4271478971241625, -0.9810687576309474, 56.3755347536413, 0.0, 20.0, -0.8385234712838874, -20.627592249315853, 60.0, 0.0, -1.4981239606456187, 53.216051865733306, 0.0, 20.0, 0.0, 39.98730665341844, -0.45142539738739496, -5.1389162752242346, 55.80480401825851, -11.234338103858, 0.0, 40.0, 0.0, -25.594429115990874, -3.1966857553715684, 0.0, -6.052990823144382, 0.0, 20.0, -7.494999011149739, 0.0, 20.0, 60.0, 0.0, 40.0, 0.0, 0.0, -1.208403633265126, 40.0, 60.0, 0.0, -4.130780637419921, 0.0, 40.0, 0.0, 20.0, 0.0, 0.0, 17.73468518681977, 55.76565922898087, 0.0, -13.443745453416277, -1.9295199960073672, 0.0, 40.0, 0.0, 0.0, 20.0, 0.0, 20.0, 20.0, 0.0, 0.0, 0.0, -3.9604899453387477, -3.149761421049803, 0.0, -6.530532513815884, 0.0, -3.5836897036396023, 0.0, -1.0150782868015384, 0.0, 80.0, 80.0, 0.0, -3.0302083208841735, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 20.0, -0.33132446638765023, 20.0, 20.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0], "policy_agent_policy_reward": [-0.4481879892222995, -8.405794668650636, 0.0, 0.0, -7.776195716397904, -10.0, 0.0, -1.5017502210207667, 0.0, -20.0, -5.58269687965687, -2.4099712943339537, 0.0, -10.18124431037403, -4.463443187828916, 0.0, 0.0, -17.955166134399473, 0.0, 0.0, -13.737730586429963, 0.0, -12.559723311196477, 0.0, -11.486841281854922, -15.4023422567928, -31.11111112759734, -20.0, 0.0, -7.334330634364608, -23.70935932605073, -5.810625659083283, -30.873584659112336, -40.0, -46.17533985231687, 0.0, -20.50527297142146, 0.0, -20.0, 0.0, -0.22704392336355683, -10.301382092729119, -2.530031180412343, 0.0, 0.0, -20.95707750481028, -50.0, -43.86215227061359, 0.0, -42.17694307648445, 0.0, -10.0, 0.0, -5.415026407085035, -10.654563397104598, 0.0, -13.267973989662973, 0.0, 0.0, -1.017257139442026, 0.0, -40.0, 0.0, -50.0, -34.03274185680181, -5.952463365857548, 0.0, -9.503993128625751, -30.0, 0.0, -0.13551762214493834, -21.569939765696752, -1.4271478971241625, -0.9810687576309474, -33.624465246358696, 0.0, -10.0, -0.8385234712838874, -20.627592249315853, -30.0, 0.0, -1.4981239606456187, -36.783948134266694, 0.0, -10.0, 0.0, -20.012693346581557, -0.45142539738739496, -5.1389162752242346, -34.19519598174149, -11.234338103858, 0.0, -20.0, 0.0, -25.594429115990874, -3.1966857553715684, 0.0, -6.052990823144382, 0.0, -10.0, -7.494999011149739, 0.0, -10.0, -30.0, 0.0, -20.0, 0.0, 0.0, -1.208403633265126, -20.0, -30.0, 0.0, -4.130780637419921, 0.0, -20.0, 0.0, -10.0, 0.0, 0.0, -12.265314813180229, -34.23434077101913, 0.0, -13.443745453416277, -1.9295199960073672, 0.0, -20.0, 0.0, 0.0, -10.0, 0.0, -10.0, -10.0, 0.0, 0.0, 0.0, -3.9604899453387477, -3.149761421049803, 0.0, -6.530532513815884, 0.0, -3.5836897036396023, 0.0, -1.0150782868015384, 0.0, -40.0, -40.0, 0.0, -33.03020832088418, -20.0, -20.0, 0.0, 0.0, 0.0, 0.0, -10.0, -0.33132446638765023, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.647662347178252, "mean_inference_ms": 1.1108107285334359, "mean_action_processing_ms": 0.23369037340137935, "mean_env_wait_ms": 0.4835559062977325, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004209823246243634, "StateBufferConnector_ms": 0.003029877626443211, "ViewRequirementAgentConnector_ms": 0.08468771282630631}, "num_episodes": 158, "episode_return_max": 100.0, "episode_return_min": -25.594429115990874, "episode_return_mean": 12.677211694441514}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2576000, "num_agent_steps_trained": 2576000, "num_env_steps_sampled": 644000, "num_env_steps_trained": 644000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 345.66899244214994, "num_env_steps_trained_throughput_per_sec": 345.66899244214994, "timesteps_total": 644000, "num_env_steps_sampled_lifetime": 644000, "num_agent_steps_sampled_lifetime": 2576000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2576000, "timers": {"training_iteration_time_ms": 11212.043, "restore_workers_time_ms": 0.015, "training_step_time_ms": 11212.002, "sample_time_ms": 1105.541, "learn_time_ms": 10094.253, "learn_throughput": 396.265, "synch_weights_time_ms": 11.658}, "counters": {"num_env_steps_sampled": 644000, "num_env_steps_trained": 644000, "num_agent_steps_sampled": 2576000, "num_agent_steps_trained": 2576000}, "done": false, "training_iteration": 161, "trial_id": "86f16_00000", "date": "2024-08-08_16-48-10", "timestamp": 1723150090, "time_this_iter_s": 11.577452898025513, "time_total_s": 2106.420632839203, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x309cadca0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 2106.420632839203, "iterations_since_restore": 161, "perf": {"cpu_util_percent": 36.752941176470586, "ram_util_percent": 81.37647058823529}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4680322935817935, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.3842867723593475, "policy_loss": -0.018974031619100124, "vf_loss": 1.4024638002857248, "vf_explained_var": 2.2332719031800616e-07, "kl": 0.007970031061978982, "entropy": 0.36595621402804734, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 455430.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.6083317724366983, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.2351230539381506, "policy_loss": -0.030851203933222375, "vf_loss": 2.2643458471943934, "vf_explained_var": 0.16428756564855576, "kl": 0.008142067810255487, "entropy": 0.8994421216348807, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 155040.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 648000, "num_env_steps_trained": 648000, "num_agent_steps_sampled": 2592000, "num_agent_steps_trained": 2592000}, "env_runners": {"episode_reward_max": 99.31078219926273, "episode_reward_min": -25.56470277495461, "episode_reward_mean": 8.360552628641194, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -50.689217800737254}, "policy_reward_max": {"adversary_policy": 50.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 5.308641975308642, "agent_policy": -7.565373297284732}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-9.525466274991512, 0.0, 0.0, -2.3407437338824666, -2.0007498690614245, 0.0, -0.8857461458551863, 0.0, -8.530785463044328, 0.0, -2.4962963800363704, -0.3720902868754339, 0.0, 54.96444741249167, -1.0481332943036592, 5.594965982844947, -3.5870823641894267, 0.0, 0.0, 0.0, -0.08253771990835657, -13.939066029129132, 0.0, -8.426967463412034, -21.738396581975437, 20.0, 0.0, 39.771471896643945, -0.7166072391011569, 0.0, 0.0, 0.0, 0.0, 60.0, 20.0, 38.856568223933664, 0.0, -6.934179610695639, 0.0, -25.56470277495461, 20.0, -2.2476707594988388, 20.0, 40.0, -2.178858769401459, 20.0, 0.0, 0.0, -0.05995273931178491, -3.0268748306280218, 0.0, 0.0, 40.0, 20.0, -22.495591099065734, 0.0, 0.0, -9.678032623013777, 0.0, 0.0, 53.81448754689773, 0.0, 14.27264334142366, 55.25198456688719, 0.0, 19.116808569678213, -0.009872705435841622, -0.4203834329432865, 0.0, 80.0, -1.817335884430874, 0.0, 0.0, 0.0, -3.9899721069050296, 40.0, -4.539999017374703, -7.313532532826464, 0.0, 0.0, -0.511970271004627, -16.967798859731452, 13.76808588471108, 0.0, 70.81352554559416, -8.04498711500006, 20.0, 0.0, 0.0, 0.0, -11.002800225897737, 0.0, 0.0, -4.052312277957897, 20.0, -3.086702543434863, -3.188054510421174, -1.3167522150100908, 0.0, 0.0, 80.0, -0.17634345990153455, 19.78417343376961, -0.1382028608997099, -1.288498101850717, -0.8716538709826971, 0.0, 40.0, -2.2707716007236844, -0.3972937673501009, -0.0865621606274003, 20.0, 60.0, 0.0, 27.933784602789046, 60.0, -9.483321413021251, 20.0, -8.413249763381277, 18.717635897422774, -4.348951680074131, -3.0499248919455053, 20.0, 40.0, -2.3564807509412606, 20.0, 99.31078219926273, 0.0, 19.923884119306557, -1.9810215779573004, 20.0, 0.0, 0.0, 0.0, 20.0, 40.0, 0.0, 60.0, 0.0, -4.282382307607062, 20.0, 0.0, 20.0, 38.65232782950147, -1.466489435237962, 7.476561941045365, 0.0, 20.0, 0.0, 0.0, 0.0, -4.638999047498869, 0.0, 20.0, 0.0, 0.0, -1.1663078614373978, 0.0, 7.434873937902435, -8.212901050313128, 20.0, -2.281125739771971], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-9.525466274991512, 0.0, 0.0, -2.3407437338824666, -2.0007498690614245, 0.0, -0.8857461458551863, 0.0, -8.530785463044328, 0.0, -2.4962963800363704, -0.3720902868754339, 0.0, -35.035552587508334, -1.0481332943036592, -24.405034017155053, -3.5870823641894267, 0.0, 0.0, 0.0, -0.08253771990835657, -13.939066029129132, 0.0, -8.426967463412034, -21.738396581975437, -10.0, 0.0, -20.22852810335605, -0.7166072391011569, 0.0, 0.0, 0.0, 0.0, -30.0, -10.0, -21.143431776066336, 0.0, -6.934179610695639, 0.0, -25.56470277495461, -10.0, -2.2476707594988388, -10.0, -20.0, -2.178858769401459, -10.0, 0.0, 0.0, -0.05995273931178491, -3.0268748306280218, 0.0, 0.0, -20.0, -10.0, -22.495591099065734, 0.0, 0.0, -9.678032623013777, 0.0, 0.0, -36.18551245310226, 0.0, -15.727356658576339, -34.748015433112805, 0.0, -10.883191430321785, -0.009872705435841622, -0.4203834329432865, 0.0, -40.0, -1.817335884430874, 0.0, 0.0, 0.0, -3.9899721069050296, -20.0, -4.539999017374703, -7.313532532826464, 0.0, 0.0, -0.511970271004627, -16.967798859731452, -16.23191411528892, 0.0, -49.18647445440584, -8.04498711500006, -10.0, 0.0, 0.0, 0.0, -11.002800225897737, 0.0, 0.0, -4.052312277957897, -10.0, -3.086702543434863, -3.188054510421174, -1.3167522150100908, 0.0, 0.0, -40.0, -0.17634345990153455, -10.215826566230389, -0.1382028608997099, -1.288498101850717, -0.8716538709826971, 0.0, -20.0, -2.2707716007236844, -0.3972937673501009, -0.0865621606274003, -10.0, -30.0, 0.0, -32.066215397210954, -30.0, -9.483321413021251, -10.0, -8.413249763381277, -11.28236410257722, -4.348951680074131, -3.0499248919455053, -10.0, -20.0, -2.3564807509412606, -10.0, -50.689217800737254, 0.0, -10.076115880693443, -1.9810215779573004, -10.0, 0.0, 0.0, 0.0, -10.0, -20.0, 0.0, -30.0, 0.0, -4.282382307607062, -10.0, 0.0, -10.0, -21.347672170498527, -1.466489435237962, -22.523438058954635, 0.0, -10.0, 0.0, 0.0, 0.0, -4.638999047498869, 0.0, -10.0, 0.0, 0.0, -1.1663078614373978, 0.0, -22.565126062097566, -8.212901050313128, -10.0, -2.281125739771971]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6474602173067266, "mean_inference_ms": 1.1105339890731492, "mean_action_processing_ms": 0.2336965564111054, "mean_env_wait_ms": 0.4835055132102684, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003927725332754629, "StateBufferConnector_ms": 0.0029705188892505787, "ViewRequirementAgentConnector_ms": 0.08179545402526855}, "num_episodes": 162, "episode_return_max": 99.31078219926273, "episode_return_min": -25.56470277495461, "episode_return_mean": 8.360552628641194}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2592000, "num_agent_steps_trained": 2592000, "num_env_steps_sampled": 648000, "num_env_steps_trained": 648000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 359.78418202198935, "num_env_steps_trained_throughput_per_sec": 359.78418202198935, "timesteps_total": 648000, "num_env_steps_sampled_lifetime": 648000, "num_agent_steps_sampled_lifetime": 2592000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2592000, "timers": {"training_iteration_time_ms": 11202.101, "restore_workers_time_ms": 0.015, "training_step_time_ms": 11202.06, "sample_time_ms": 1103.257, "learn_time_ms": 10086.453, "learn_throughput": 396.572, "synch_weights_time_ms": 11.881}, "counters": {"num_env_steps_sampled": 648000, "num_env_steps_trained": 648000, "num_agent_steps_sampled": 2592000, "num_agent_steps_trained": 2592000}, "done": false, "training_iteration": 162, "trial_id": "86f16_00000", "date": "2024-08-08_16-48-21", "timestamp": 1723150101, "time_this_iter_s": 11.12288522720337, "time_total_s": 2117.5435180664062, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x309cadee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 2117.5435180664062, "iterations_since_restore": 162, "perf": {"cpu_util_percent": 27.5, "ram_util_percent": 81.34375}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.43064402494553133, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.9640053031820778, "policy_loss": -0.0168508410128494, "vf_loss": 0.9800993645656193, "vf_explained_var": -2.4349131482712764e-07, "kl": 0.0075678051479099616, "entropy": 0.39599763556575096, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 458250.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.375771035750707, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.9088635347395515, "policy_loss": -0.0345605240460524, "vf_loss": 1.9413996911918123, "vf_explained_var": 0.1220421364530921, "kl": 0.010121831442086572, "entropy": 0.9149199976275365, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 156000.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 652000, "num_env_steps_trained": 652000, "num_agent_steps_sampled": 2608000, "num_agent_steps_trained": 2608000}, "env_runners": {"episode_reward_max": 80.0, "episode_reward_min": -31.117962638476207, "episode_reward_mean": 6.433105464408297, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 157, "episodes_timesteps_total": 3925, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -45.18322200527955}, "policy_reward_max": {"adversary_policy": 40.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 4.45859872611465, "agent_policy": -6.942690713935653}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-3.8235447065943866, 36.979936914629334, 0.0, -3.870653848766482, 0.0, -1.782864351129403, 0.0, 18.602222487383244, 32.58848939714928, -4.349811829975482, -14.35245714324575, -8.961335673989241, -0.9403963806361892, -0.7984362506296749, 0.0, -2.3547926081984025, 0.0, -0.16285860829629017, 19.41566126282988, 0.0, -0.9158293040211918, 0.0, 20.0, -2.9323073970915887, 0.0, 0.0, -12.18012048923413, 17.25692188119263, 0.0, 0.0, 0.0, -16.483877650257114, 60.0, 19.410612877520094, -10.350868838355225, -1.3845538801237434, 20.0, 0.0, 0.0, -2.427470585261069, -0.9350105650835272, 52.666282144472135, 20.0, 0.0, -0.7811152550462075, 56.239373219328115, 0.0, -11.562645879639188, 46.321647018013955, 0.0, 0.0, 0.0, -0.05146895472955215, 0.0, 60.0, -1.737914380736223, 0.0, -2.807026830207422, 20.0, 40.0, -31.117962638476207, 0.0, 40.0, 0.0, 0.0, 0.0, 20.0, 0.0, 0.0, 0.0, 40.0, 0.0, -6.143709334963295, 40.0, -7.010495591122519, 0.0, 0.0, -4.672953327835545, 0.0, 0.0, 0.0, 40.0, 0.0, -11.500979414764668, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -4.987479078511926, 0.0, -13.098925356646378, -10.59997258272702, -1.32615181557316, 0.0, -0.8241174634977455, 0.0, -4.474480421762417, -4.960978218981053, -1.9074629967475687, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 58.31491434360382, 20.0, 40.0, -16.867282312848417, 40.0, 0.0, 0.0, -1.7022885880096206, -9.048738513555161, 10.431890523804359, 40.0, 0.0, 19.29152304750825, -7.571614455895874, 0.0, -2.2414731416309297, 0.0, -3.111859191545012, 0.0, 27.211736812160527, 0.0, 0.0, -0.2204078404197285, -14.603481420098264, 20.0, -15.56043583751011, -2.8679326732336774, 0.0, 18.107344041592164, -1.6622131417491337, -0.72274442984541, 0.0, 44.81677799472045, 0.0, 0.0, 20.0, 0.0, 0.0, 0.0, 0.0, 20.0, 80.0, 59.2737677500087, 20.0, -2.1780426046159684, 0.0, 0.0, 0.0, 0.0, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-3.8235447065943866, -23.020063085370662, 0.0, -3.870653848766482, 0.0, -1.782864351129403, 0.0, -11.397777512616754, -27.41151060285072, -4.349811829975482, -14.35245714324575, -8.961335673989241, -0.9403963806361892, -0.7984362506296749, 0.0, -2.3547926081984025, 0.0, -0.16285860829629017, -10.584338737170123, 0.0, -0.9158293040211918, 0.0, -10.0, -2.9323073970915887, 0.0, 0.0, -12.18012048923413, -12.743078118807368, 0.0, 0.0, 0.0, -16.483877650257114, -30.0, -10.589387122479904, -10.350868838355225, -1.3845538801237434, -10.0, 0.0, 0.0, -2.427470585261069, -0.9350105650835272, -37.333717855527865, -10.0, 0.0, -0.7811152550462075, -33.76062678067187, 0.0, -11.562645879639188, -43.678352981986045, 0.0, 0.0, 0.0, -0.05146895472955215, 0.0, -30.0, -1.737914380736223, 0.0, -2.807026830207422, -10.0, -20.0, -31.117962638476207, 0.0, -20.0, 0.0, 0.0, 0.0, -10.0, 0.0, 0.0, 0.0, -20.0, 0.0, -6.143709334963295, -20.0, -7.010495591122519, 0.0, 0.0, -4.672953327835545, 0.0, 0.0, 0.0, -20.0, 0.0, -11.500979414764668, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -4.987479078511926, 0.0, -13.098925356646378, -10.59997258272702, -1.32615181557316, 0.0, -0.8241174634977455, 0.0, -4.474480421762417, -4.960978218981053, -1.9074629967475687, -20.0, 0.0, 0.0, 0.0, 0.0, 0.0, -31.685085656396186, -10.0, -20.0, -16.867282312848417, -20.0, 0.0, 0.0, -1.7022885880096206, -9.048738513555161, -19.568109476195637, -20.0, 0.0, -10.708476952491749, -7.571614455895874, 0.0, -2.2414731416309297, 0.0, -3.111859191545012, 0.0, -32.788263187839476, 0.0, 0.0, -0.2204078404197285, -14.603481420098264, -10.0, -15.56043583751011, -2.8679326732336774, 0.0, -11.892655958407834, -31.662213141749138, -0.72274442984541, 0.0, -45.18322200527955, 0.0, 0.0, -10.0, 0.0, 0.0, 0.0, 0.0, -10.0, -40.0, -30.726232249991295, -10.0, -2.1780426046159684, 0.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6472505599750086, "mean_inference_ms": 1.1103344951033294, "mean_action_processing_ms": 0.23373473580626206, "mean_env_wait_ms": 0.483480586513394, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004030564788040841, "StateBufferConnector_ms": 0.003073777362799189, "ViewRequirementAgentConnector_ms": 0.08319927628632563}, "num_episodes": 157, "episode_return_max": 80.0, "episode_return_min": -31.117962638476207, "episode_return_mean": 6.433105464408297}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2608000, "num_agent_steps_trained": 2608000, "num_env_steps_sampled": 652000, "num_env_steps_trained": 652000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 353.53493506879374, "num_env_steps_trained_throughput_per_sec": 353.53493506879374, "timesteps_total": 652000, "num_env_steps_sampled_lifetime": 652000, "num_agent_steps_sampled_lifetime": 2608000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2608000, "timers": {"training_iteration_time_ms": 11242.746, "restore_workers_time_ms": 0.015, "training_step_time_ms": 11242.704, "sample_time_ms": 1104.349, "learn_time_ms": 10125.982, "learn_throughput": 395.023, "synch_weights_time_ms": 11.875}, "counters": {"num_env_steps_sampled": 652000, "num_env_steps_trained": 652000, "num_agent_steps_sampled": 2608000, "num_agent_steps_trained": 2608000}, "done": false, "training_iteration": 163, "trial_id": "86f16_00000", "date": "2024-08-08_16-48-33", "timestamp": 1723150113, "time_this_iter_s": 11.321774244308472, "time_total_s": 2128.8652923107147, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x309c9d1f0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 2128.8652923107147, "iterations_since_restore": 163, "perf": {"cpu_util_percent": 27.856250000000003, "ram_util_percent": 81.41250000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4828532609639438, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.311010681293535, "policy_loss": -0.02012645296830063, "vf_loss": 1.3302397310733796, "vf_explained_var": -4.103631837993649e-07, "kl": 0.008974049661221216, "entropy": 0.40445933673821444, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 461070.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.508393160253763, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.16918261051178, "policy_loss": -0.0326669318669398, "vf_loss": 2.199876713814835, "vf_explained_var": 0.17665763621528943, "kl": 0.00986415631472634, "entropy": 0.9304607500632603, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 156960.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 656000, "num_env_steps_trained": 656000, "num_agent_steps_sampled": 2624000, "num_agent_steps_trained": 2624000}, "env_runners": {"episode_reward_max": 100.0, "episode_reward_min": -29.208105965886585, "episode_reward_mean": 10.60381666373553, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -51.089839805249035}, "policy_reward_max": {"adversary_policy": 50.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 6.481481481481482, "agent_policy": -8.840627780708914}, "custom_metrics": {}, "hist_stats": {"episode_reward": [20.0, 40.0, 60.0, 0.0, 0.0, 0.0, 0.0, 5.328376489348054, -4.51599306373648, -26.73016216512349, 0.0, 0.0, 48.97293658510305, 0.0, -5.5811185524056715, 0.0, 20.0, 0.0, 11.084266204540135, 0.0, 0.0, 0.0, -2.731559232619227, 20.0, -8.974263380360544, 0.0, 0.0, 20.0, -0.063318506193204, 0.0, 40.0, 0.0, -0.10255866350043497, 60.0, 0.0, 40.0, 0.0, -24.31956247367224, -16.937828110572706, 40.0, 0.0, 0.0, 0.0, -6.322681649305701, 0.0, -3.876010489721594, 60.0, -1.6426727617825987, 0.0, 60.0, 0.0, -11.906851819611896, 0.0, 0.0, 0.0, 60.0, 0.0, 20.0, 0.0, 0.0, 0.0, 58.720460021695146, 20.0, 60.0, 58.901451548508156, 0.0, 0.0, 0.0, 49.25996858158465, 0.0, 0.0, -8.474190448997923, 0.0, 0.0, 45.95906549272143, -11.523637009926196, -1.9698181425162231, 0.0, -1.4063026035436932, 100.0, 0.0, 0.0, 0.0, 50.10015160353594, 0.0, 40.0, 0.0, 0.0, 0.0, 0.0, 60.0, -3.5602458511982222, 0.0, -6.164545299728028, -3.6055017285600375, 37.83377257150729, -0.40296620024509955, 20.0, -4.260969919505415, -4.327211661652389, 0.0, 0.0, -11.920849081734666, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, -3.2799399643273253, 0.0, 40.0, 20.0, 0.0, -1.013382312492399, -5.068810712866116, -1.1919896404871444, 0.0, 60.0, 0.0, -2.062219718058805, -2.5752033993531347, -29.208105965886585, 29.358635516120337, -4.415509832813968, 68.91016019475097, 20.0, 0.0, 60.0, 0.0, -2.9623427184477222, 40.0, 0.0, 0.0, 0.0, -0.01827027527956715, 40.0, -3.5334247141544255, 80.0, -6.653256775134379, 80.0, 0.0, -0.29617258180413386, -3.527392843788225, 0.0, 0.0, 40.0, 0.0, 0.0, -7.225228209044398, 0.0, 0.0, 0.0, -0.5741327118961359, 0.0, 39.761835188387685, -0.009798214414439288, 60.0, -1.0218763369233286, 33.46583942876304, 14.706061687599503, -8.586805845623443], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-10.0, -20.0, -30.0, 0.0, 0.0, 0.0, 0.0, -24.671623510651948, -4.51599306373648, -26.73016216512349, 0.0, 0.0, -41.02706341489695, 0.0, -5.5811185524056715, 0.0, -10.0, 0.0, -18.915733795459868, 0.0, 0.0, 0.0, -2.731559232619227, -10.0, -8.974263380360544, 0.0, 0.0, -10.0, -0.063318506193204, 0.0, -20.0, 0.0, -0.10255866350043497, -30.0, 0.0, -20.0, 0.0, -24.31956247367224, -16.937828110572706, -20.0, 0.0, 0.0, 0.0, -6.322681649305701, 0.0, -3.876010489721594, -30.0, -1.6426727617825987, 0.0, -30.0, 0.0, -11.906851819611896, 0.0, 0.0, 0.0, -30.0, 0.0, -10.0, 0.0, 0.0, 0.0, -31.27953997830485, -10.0, -30.0, -31.098548451491848, 0.0, 0.0, 0.0, -40.740031418415334, 0.0, 0.0, -8.474190448997923, 0.0, 0.0, -44.04093450727857, -11.523637009926196, -1.9698181425162231, 0.0, -31.406302603543697, -50.0, 0.0, 0.0, 0.0, -39.89984839646406, 0.0, -20.0, 0.0, 0.0, 0.0, 0.0, -30.0, -3.5602458511982222, 0.0, -6.164545299728028, -3.6055017285600375, -22.16622742849271, -0.40296620024509955, -10.0, -4.260969919505415, -4.327211661652389, 0.0, 0.0, -11.920849081734666, 0.0, 0.0, 0.0, 0.0, 0.0, -10.0, -3.2799399643273253, 0.0, -20.0, -10.0, 0.0, -1.013382312492399, -5.068810712866116, -1.1919896404871444, 0.0, -30.0, 0.0, -2.062219718058805, -2.5752033993531347, -29.208105965886585, -30.641364483879663, -4.415509832813968, -51.089839805249035, -10.0, 0.0, -30.0, 0.0, -2.9623427184477222, -20.0, 0.0, 0.0, 0.0, -0.01827027527956715, -20.0, -3.5334247141544255, -40.0, -6.653256775134379, -40.0, 0.0, -0.29617258180413386, -3.527392843788225, 0.0, 0.0, -20.0, 0.0, 0.0, -7.225228209044398, 0.0, 0.0, 0.0, -0.5741327118961359, 0.0, -20.238164811612315, -0.009798214414439288, -30.0, -1.0218763369233286, -26.53416057123696, -15.293938312400496, -8.586805845623443]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6466258185748177, "mean_inference_ms": 1.1091025695600507, "mean_action_processing_ms": 0.23339064026351056, "mean_env_wait_ms": 0.4830531916993004, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00421883147439839, "StateBufferConnector_ms": 0.003394079797061873, "ViewRequirementAgentConnector_ms": 0.08604438216597945}, "num_episodes": 162, "episode_return_max": 100.0, "episode_return_min": -29.208105965886585, "episode_return_mean": 10.60381666373553}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2624000, "num_agent_steps_trained": 2624000, "num_env_steps_sampled": 656000, "num_env_steps_trained": 656000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 358.18331046529113, "num_env_steps_trained_throughput_per_sec": 358.18331046529113, "timesteps_total": 656000, "num_env_steps_sampled_lifetime": 656000, "num_agent_steps_sampled_lifetime": 2624000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2624000, "timers": {"training_iteration_time_ms": 11255.222, "restore_workers_time_ms": 0.013, "training_step_time_ms": 11255.182, "sample_time_ms": 1101.37, "learn_time_ms": 10141.446, "learn_throughput": 394.421, "synch_weights_time_ms": 11.907}, "counters": {"num_env_steps_sampled": 656000, "num_env_steps_trained": 656000, "num_agent_steps_sampled": 2624000, "num_agent_steps_trained": 2624000}, "done": false, "training_iteration": 164, "trial_id": "86f16_00000", "date": "2024-08-08_16-48-44", "timestamp": 1723150124, "time_this_iter_s": 11.172659873962402, "time_total_s": 2140.037952184677, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x309c9d700>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 2140.037952184677, "iterations_since_restore": 164, "perf": {"cpu_util_percent": 27.958823529411767, "ram_util_percent": 81.40588235294118}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4906936001904467, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.4026885561486508, "policy_loss": -0.018135237156913835, "vf_loss": 1.4200650117921492, "vf_explained_var": -1.5110411542527218e-07, "kl": 0.0075878316752737525, "entropy": 0.3832921049167924, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 463890.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.484355151777466, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.318273123105367, "policy_loss": -0.031664654123111785, "vf_loss": 2.348015319928527, "vf_explained_var": 0.11974198265622059, "kl": 0.009612297660391296, "entropy": 0.9055368303631742, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 157920.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 660000, "num_env_steps_trained": 660000, "num_agent_steps_sampled": 2640000, "num_agent_steps_trained": 2640000}, "env_runners": {"episode_reward_max": 120.0, "episode_reward_min": -31.706930720150318, "episode_reward_mean": 9.865921700602545, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -69.83657190547368}, "policy_reward_max": {"adversary_policy": 60.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 6.234567901234568, "agent_policy": -8.83778200310116}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 20.0, 40.0, 0.0, 0.0, 58.13123349058817, -12.633013957636685, 40.0, 76.41874528386873, -0.9470955368412881, 0.0, -4.1363715183570156, 0.0, 0.0, 0.0, -0.08975620945187779, 0.0, 0.0, 0.0, -7.324577061652981, -1.2047027491736662, 20.0, -15.585635359093219, 20.0, 39.33269813179651, 35.16967640984214, -3.9293282817988437, 60.0, 39.74968367871223, 0.0, -13.34811389182752, -13.707180907609269, -1.8086527707134215, 0.0, 0.0, 0.0, 0.0, 14.992114015548745, -5.129784275773567, 0.0, 20.0, 19.607840677620864, -2.6591207084577864, -0.3589213105983402, 0.0, 20.0, 0.0, 0.0, 0.0, 0.0, -0.543526803750336, 40.0, -28.626783387516966, 0.0, 0.0, 0.0, -25.24329002475345, 0.0, 19.631744139888877, 0.0, 0.0, 40.0, -7.304632542019581, -0.46375010617280443, 39.00356083940527, -8.636042262518977, 17.705123478010616, 60.0, 40.0, 0.0, -4.970840939510254, -2.965021730827475, -0.37160532281754977, -24.6724145576132, -1.8493741729837543, 0.0, -31.706930720150318, 40.0, 20.0, 114.44017433626568, 23.48382173985474, -0.14573989703800638, 0.0, 80.0, 53.80540790893224, 0.0, 0.0, -1.1445202417341283, -9.806786564237825, -16.37616805054408, 0.0, 0.0, -0.9180236866596259, 14.899122874202451, 0.0, 0.0, -4.912984871558563, 0.0, 0.0, -9.163239674741797, 0.0, 19.89461997642194, 12.99788373346886, -3.869176772458882, 0.0, -2.1618280509925447, 0.0, 40.0, 0.0, -2.890515657948536, 0.0, 0.0, -4.849312239768103, 0.0, 0.0, 51.602767277385425, 20.0, 0.0, 0.0, 0.0, 0.0, 40.0, 0.0, 0.0, 0.0, 60.0, 0.0, 13.551975010118824, -5.477839266863169, 40.0, 0.0, 0.0, -5.7650671005092, 0.0, 32.19099540806977, -4.154022724353994, 0.0, -0.46385474913474, 0.0, 59.34421487513188, 0.0, -0.2311988339877613, -0.27984522493503694, 20.0, 0.0, 0.0, 0.0, 0.0, -10.103257159151894, 20.0, -4.9076680058099935, 120.0, 60.0, 40.0, 20.0, 40.0, 20.0, 50.163428094526324, 0.0, 0.0, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [0.0, 0.0, -10.0, -20.0, 0.0, 0.0, -31.868766509411838, -12.633013957636685, -20.0, -43.58125471613127, -0.9470955368412881, 0.0, -4.1363715183570156, 0.0, 0.0, 0.0, -0.08975620945187779, 0.0, 0.0, 0.0, -7.324577061652981, -1.2047027491736662, -10.0, -15.585635359093219, -10.0, -20.66730186820349, -24.83032359015786, -3.9293282817988437, -30.0, -20.250316321287773, 0.0, -13.34811389182752, -13.707180907609269, -1.8086527707134215, 0.0, 0.0, 0.0, 0.0, -15.007885984451253, -5.129784275773567, 0.0, -10.0, -10.392159322379136, -2.6591207084577864, -0.3589213105983402, 0.0, -10.0, 0.0, 0.0, 0.0, 0.0, -0.543526803750336, -20.0, -28.626783387516966, 0.0, 0.0, 0.0, -25.24329002475345, 0.0, -10.368255860111127, 0.0, 0.0, -20.0, -7.304632542019581, -0.46375010617280443, -20.99643916059473, -8.636042262518977, -12.294876521989384, -30.0, -20.0, 0.0, -4.970840939510254, -2.965021730827475, -0.37160532281754977, -24.6724145576132, -1.8493741729837543, 0.0, -31.706930720150318, -20.0, -10.0, -65.5598256637343, -36.51617826014526, -0.14573989703800638, 0.0, -40.0, -36.19459209106776, 0.0, 0.0, -1.1445202417341283, -9.806786564237825, -16.37616805054408, 0.0, 0.0, -0.9180236866596259, -15.100877125797552, 0.0, 0.0, -4.912984871558563, 0.0, 0.0, -9.163239674741797, 0.0, -10.10538002357806, -17.00211626653114, -3.869176772458882, 0.0, -2.1618280509925447, 0.0, -20.0, 0.0, -2.890515657948536, 0.0, 0.0, -4.849312239768103, 0.0, 0.0, -38.397232722614575, -10.0, 0.0, 0.0, 0.0, 0.0, -20.0, 0.0, 0.0, 0.0, -30.0, 0.0, -16.448024989881173, -5.477839266863169, -20.0, 0.0, 0.0, -5.7650671005092, 0.0, -27.809004591930236, -4.154022724353994, 0.0, -0.46385474913474, 0.0, -30.65578512486811, 0.0, -0.2311988339877613, -0.27984522493503694, -10.0, 0.0, 0.0, 0.0, 0.0, -10.103257159151894, -10.0, -4.9076680058099935, -60.0, -30.0, -20.0, -10.0, -20.0, -10.0, -69.83657190547368, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6462593548431358, "mean_inference_ms": 1.1084864924561806, "mean_action_processing_ms": 0.23326154705756905, "mean_env_wait_ms": 0.4828367133108927, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004602803124321831, "StateBufferConnector_ms": 0.003195839163697796, "ViewRequirementAgentConnector_ms": 0.08901401802345559}, "num_episodes": 162, "episode_return_max": 120.0, "episode_return_min": -31.706930720150318, "episode_return_mean": 9.865921700602545}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2640000, "num_agent_steps_trained": 2640000, "num_env_steps_sampled": 660000, "num_env_steps_trained": 660000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 355.2581187938887, "num_env_steps_trained_throughput_per_sec": 355.2581187938887, "timesteps_total": 660000, "num_env_steps_sampled_lifetime": 660000, "num_agent_steps_sampled_lifetime": 2640000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2640000, "timers": {"training_iteration_time_ms": 11265.601, "restore_workers_time_ms": 0.013, "training_step_time_ms": 11265.561, "sample_time_ms": 1107.229, "learn_time_ms": 10145.898, "learn_throughput": 394.248, "synch_weights_time_ms": 11.974}, "counters": {"num_env_steps_sampled": 660000, "num_env_steps_trained": 660000, "num_agent_steps_sampled": 2640000, "num_agent_steps_trained": 2640000}, "done": false, "training_iteration": 165, "trial_id": "86f16_00000", "date": "2024-08-08_16-48-56", "timestamp": 1723150136, "time_this_iter_s": 11.26568078994751, "time_total_s": 2151.3036329746246, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x309c9dc10>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 2151.3036329746246, "iterations_since_restore": 165, "perf": {"cpu_util_percent": 28.731249999999996, "ram_util_percent": 81.35624999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.42541675700786263, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.2451334486405055, "policy_loss": -0.015979327485857016, "vf_loss": 1.2603150855564902, "vf_explained_var": -3.614324204465176e-07, "kl": 0.007976879420382773, "entropy": 0.38368630693525285, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 466710.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.428109744936228, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.936276913387701, "policy_loss": -0.034977283763388795, "vf_loss": 1.969367771440496, "vf_explained_var": 0.06427518793692191, "kl": 0.009432137115189695, "entropy": 0.955171751913925, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 158880.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 664000, "num_env_steps_trained": 664000, "num_agent_steps_sampled": 2656000, "num_agent_steps_trained": 2656000}, "env_runners": {"episode_reward_max": 136.6716532300187, "episode_reward_min": -23.012871631163332, "episode_reward_mean": 10.422588713377722, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 158, "episodes_timesteps_total": 3950, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -73.32834676998128}, "policy_reward_max": {"adversary_policy": 70.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 6.075949367088608, "agent_policy": -7.8052593878881}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 100.0, -1.2543498732962843, 20.0, 40.0, -23.012871631163332, 0.0, -6.680962154982304, -1.499451763866143, 57.79433532426442, -2.511148479064439, 0.0, 80.0, -2.3554767813318813, 0.0, 0.0, 20.0, 18.634350426256397, 0.0, 99.91356488836294, 0.0, 0.0, 0.0, 60.0, 0.0, -1.089982671856744, 39.75760384162102, 0.0, 0.0, 0.0, -1.1645286105948687, 0.0, 40.0, 0.0, 0.0, 0.0, 19.923465296708724, -0.36073308837746176, 20.0, 0.0, 0.0, -14.036812166004406, 20.0, 0.0, 59.838911984144275, 40.0, -0.7168166233752593, 136.6716532300187, 0.0, -1.1639935666769075, -0.20350673957875265, 0.0, 0.0, 0.0, 0.0, -7.604311531795467, 0.0, 0.0, -1.406847468489164, 0.0, 39.51844091113259, 0.0, 0.0, -19.098690265966596, -2.1331837947536734, 0.0, -18.62318306724415, 35.05694976463238, 38.49836309935227, 19.97302613611641, -5.177453731409029, 0.0, 0.0, 0.0, -1.241074468164285, 0.0, 60.0, 0.0, 0.0, -0.3079664287838213, 42.72281867842087, 0.0, -0.952568418222679, -5.080867826040687, 0.0, 0.0, 0.0, 0.0, -0.22872961079704046, 97.57836088521555, 0.0, 0.0, 0.0, 0.0, -0.16974693005490815, 40.0, 0.0, -0.29889290218043096, 0.0, 0.0, 0.0, 40.0, 8.469232260776232, 100.0, 60.0, 0.0, -4.762053307084703, 0.0, 0.0, -5.136189053821451, 0.0, 0.0, 0.0, -5.706568357506893, 0.0, 0.0, -0.7365168279596879, 40.0, 40.0, -10.640410432256646, 0.0, -18.691112670966866, 39.50041531625102, 0.0, 20.0, 40.0, 0.0, 19.73444082869979, -6.402012851060254, 0.0, -0.3546970847593378, 0.0, -0.02596752802149549, 0.0, -0.36971482414503987, 20.0, 34.59246626641374, 37.185689031689286, 0.0, 0.0, 0.0, -2.9253922658896014, 0.0, 20.0, -9.295453059034028, 20.0, 0.0, 45.803495136481075, 0.0, 0.0, 0.0, -0.584655620914855, -0.3936721153860012, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, -50.0, -1.2543498732962843, -10.0, -20.0, -23.012871631163332, 0.0, -6.680962154982304, -1.499451763866143, -32.20566467573558, -2.511148479064439, 0.0, -40.0, -2.3554767813318813, 0.0, 0.0, -10.0, -11.365649573743603, 0.0, -50.086435111637066, 0.0, 0.0, 0.0, -30.0, 0.0, -1.089982671856744, -20.24239615837898, 0.0, 0.0, 0.0, -1.1645286105948687, 0.0, -20.0, 0.0, 0.0, 0.0, -10.076534703291276, -0.36073308837746176, -10.0, 0.0, 0.0, -14.036812166004406, -10.0, 0.0, -30.161088015855725, -20.0, -0.7168166233752593, -73.32834676998128, 0.0, -1.1639935666769075, -0.20350673957875265, 0.0, 0.0, 0.0, 0.0, -7.604311531795467, 0.0, 0.0, -1.406847468489164, 0.0, -20.481559088867407, 0.0, 0.0, -19.098690265966596, -2.1331837947536734, 0.0, -18.62318306724415, -24.94305023536763, -21.50163690064773, -10.026973863883589, -5.177453731409029, 0.0, 0.0, 0.0, -1.241074468164285, 0.0, -30.0, 0.0, 0.0, -0.3079664287838213, -47.27718132157913, 0.0, -0.952568418222679, -5.080867826040687, 0.0, 0.0, 0.0, 0.0, -0.22872961079704046, -52.42163911478444, 0.0, 0.0, 0.0, 0.0, -0.16974693005490815, -20.0, 0.0, -0.29889290218043096, 0.0, 0.0, 0.0, -20.0, -21.53076773922377, -50.0, -30.0, 0.0, -4.762053307084703, 0.0, 0.0, -5.136189053821451, 0.0, 0.0, 0.0, -5.706568357506893, 0.0, 0.0, -0.7365168279596879, -20.0, -20.0, -10.640410432256646, 0.0, -18.691112670966866, -20.49958468374898, 0.0, -10.0, -20.0, 0.0, -10.265559171300211, -6.402012851060254, 0.0, -0.3546970847593378, 0.0, -0.02596752802149549, 0.0, -0.36971482414503987, -10.0, -25.40753373358626, -22.814310968310714, 0.0, 0.0, 0.0, -2.9253922658896014, 0.0, -10.0, -9.295453059034028, -10.0, 0.0, -44.196504863518925, 0.0, 0.0, 0.0, -30.58465562091486, -0.3936721153860012, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6455184344699005, "mean_inference_ms": 1.1071753761841907, "mean_action_processing_ms": 0.2329130755810368, "mean_env_wait_ms": 0.4823902678287837, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004082691820361946, "StateBufferConnector_ms": 0.0029147425784340386, "ViewRequirementAgentConnector_ms": 0.08114802686473992}, "num_episodes": 158, "episode_return_max": 136.6716532300187, "episode_return_min": -23.012871631163332, "episode_return_mean": 10.422588713377722}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2656000, "num_agent_steps_trained": 2656000, "num_env_steps_sampled": 664000, "num_env_steps_trained": 664000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 360.54612417691635, "num_env_steps_trained_throughput_per_sec": 360.54612417691635, "timesteps_total": 664000, "num_env_steps_sampled_lifetime": 664000, "num_agent_steps_sampled_lifetime": 2656000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2656000, "timers": {"training_iteration_time_ms": 11266.291, "restore_workers_time_ms": 0.013, "training_step_time_ms": 11266.251, "sample_time_ms": 1109.091, "learn_time_ms": 10144.877, "learn_throughput": 394.288, "synch_weights_time_ms": 11.791}, "counters": {"num_env_steps_sampled": 664000, "num_env_steps_trained": 664000, "num_agent_steps_sampled": 2656000, "num_agent_steps_trained": 2656000}, "done": false, "training_iteration": 166, "trial_id": "86f16_00000", "date": "2024-08-08_16-49-07", "timestamp": 1723150147, "time_this_iter_s": 11.100109100341797, "time_total_s": 2162.4037420749664, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x309cadb80>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 2162.4037420749664, "iterations_since_restore": 166, "perf": {"cpu_util_percent": 27.36875, "ram_util_percent": 81.10624999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4940282015724385, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.5368312960609476, "policy_loss": -0.018612122026966483, "vf_loss": 1.5546874999577271, "vf_explained_var": -4.030922625927215e-07, "kl": 0.007559179019354863, "entropy": 0.3942065237684453, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 469530.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.279240196943283, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.302905271326502, "policy_loss": -0.03138686774667197, "vf_loss": 2.3324512840559084, "vf_explained_var": 0.11029576566070318, "kl": 0.009204281364237085, "entropy": 0.9085025883590182, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 159840.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 668000, "num_env_steps_trained": 668000, "num_agent_steps_sampled": 2672000, "num_agent_steps_trained": 2672000}, "env_runners": {"episode_reward_max": 120.0, "episode_reward_min": -16.3999411726815, "episode_reward_mean": 8.50037321337906, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 157, "episodes_timesteps_total": 3925, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -60.0}, "policy_reward_max": {"adversary_policy": 60.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 5.159235668789809, "agent_policy": -6.977333792990369}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, -5.229889823136588, 0.0, 60.0, 0.0, 0.0, 0.0, 39.15557636342641, -0.47137535791372587, 0.0, 0.0, 0.0, 0.0, -1.5935164022190718, 0.0, 56.298818511534876, 22.076347855082247, 16.724891712898067, -5.2178801059711555, 0.0, 0.0, -8.63483592554983, 0.0, -0.05524720447835252, 0.0, -4.515005198353043, 120.0, 20.0, 0.0, 20.0, 20.0, 0.0, 20.0, 80.0, 48.861376846135606, 0.0, -5.776525485117209, 16.165958952282303, -6.646913640807628, -7.528000130144788, 0.0, -11.54845744565128, 50.29975216178153, 40.0, 40.0, 0.0, 0.0, 54.98609465293529, 0.0, -0.9467328388694551, 0.0, 41.970058433069916, 0.0, 0.0, 0.0, -5.291270274253801, -3.4135631282603467, 20.0, -14.748367626488276, 0.0, 0.0, 19.866552121873752, 11.782461939550046, 38.764376402312955, 0.0, 0.0, -1.4490407539160144, -16.3999411726815, 0.0, 0.0, -13.756543499240712, -0.37869170395526397, 20.0, 20.0, 37.74009902907208, 0.0, -6.441725359736978, 0.0, 60.0, 0.0, -1.636272435903745, 0.0, -3.0403904011987706, 20.0, 0.0, -1.9109747710091596, 0.0, 20.0, 0.0, 0.0, 20.0, -1.791792208840981, 20.0, 0.0, -1.9291361447035338, 0.0, -3.4660725705823983, 0.0, 0.0, -1.193598157338327, 0.0, -10.362894411256763, 0.0, -5.478583923230056, 18.406376260989283, 0.0, 0.0, 20.0, 20.0, 0.0, -12.635230576123696, -1.6179547752808798, 0.0, 0.0, 0.0, 20.0, 0.0, 0.0, 0.0, 38.80761795140147, 0.0, 0.0, 0.0, 0.0, -0.18178935862865342, 0.0, 0.0, -3.8612530230784854, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, -4.716126089200276, -7.336872276180308, 0.0, 0.0, 0.0, 0.0, -0.0036740291851888873, 80.0, 0.0, -2.6546519390313312, 0.0, 20.0, 20.0, -1.1990866586704663, 35.614879615434134, -0.10819074451070554, 40.0, 60.0, 0.0, 20.0, -7.79457673856895, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [0.0, -5.229889823136588, 0.0, -30.0, 0.0, 0.0, 0.0, -20.84442363657359, -0.47137535791372587, 0.0, 0.0, 0.0, 0.0, -1.5935164022190718, 0.0, -33.701181488465124, -37.92365214491775, -13.275108287101927, -5.2178801059711555, 0.0, 0.0, -8.63483592554983, 0.0, -0.05524720447835252, 0.0, -4.515005198353043, -60.0, -10.0, 0.0, -10.0, -10.0, 0.0, -10.0, -40.0, -41.138623153864394, 0.0, -5.776525485117209, -13.834041047717704, -6.646913640807628, -7.528000130144788, 0.0, -11.54845744565128, -39.70024783821847, -20.0, -20.0, 0.0, 0.0, -35.01390534706471, 0.0, -0.9467328388694551, 0.0, -48.029941566930084, 0.0, 0.0, 0.0, -5.291270274253801, -3.4135631282603467, -10.0, -14.748367626488276, 0.0, 0.0, -10.133447878126248, -18.217538060449954, -21.235623597687045, 0.0, 0.0, -1.4490407539160144, -16.3999411726815, 0.0, 0.0, -13.756543499240712, -0.37869170395526397, -10.0, -10.0, -22.259900970927923, 0.0, -6.441725359736978, 0.0, -30.0, 0.0, -1.636272435903745, 0.0, -3.0403904011987706, -10.0, 0.0, -1.9109747710091596, 0.0, -10.0, 0.0, 0.0, -10.0, -1.791792208840981, -10.0, 0.0, -1.9291361447035338, 0.0, -3.4660725705823983, 0.0, 0.0, -1.193598157338327, 0.0, -10.362894411256763, 0.0, -5.478583923230056, -11.593623739010717, 0.0, 0.0, -10.0, -10.0, 0.0, -12.635230576123696, -1.6179547752808798, 0.0, 0.0, 0.0, -10.0, 0.0, 0.0, 0.0, -21.192382048598535, 0.0, 0.0, 0.0, 0.0, -0.18178935862865342, 0.0, 0.0, -3.8612530230784854, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -30.0, -4.716126089200276, -7.336872276180308, 0.0, 0.0, 0.0, 0.0, -0.0036740291851888873, -40.0, 0.0, -2.6546519390313312, 0.0, -10.0, -10.0, -1.1990866586704663, -24.385120384565866, -0.10819074451070554, -20.0, -30.0, 0.0, -10.0, -7.79457673856895, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.645586010149913, "mean_inference_ms": 1.1075305604639687, "mean_action_processing_ms": 0.23309831588648008, "mean_env_wait_ms": 0.48257107122298515, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004048711934666725, "StateBufferConnector_ms": 0.00297005768794163, "ViewRequirementAgentConnector_ms": 0.08197248361672566}, "num_episodes": 157, "episode_return_max": 120.0, "episode_return_min": -16.3999411726815, "episode_return_mean": 8.50037321337906}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2672000, "num_agent_steps_trained": 2672000, "num_env_steps_sampled": 668000, "num_env_steps_trained": 668000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 370.02374698332636, "num_env_steps_trained_throughput_per_sec": 370.02374698332636, "timesteps_total": 668000, "num_env_steps_sampled_lifetime": 668000, "num_agent_steps_sampled_lifetime": 2672000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2672000, "timers": {"training_iteration_time_ms": 11221.118, "restore_workers_time_ms": 0.013, "training_step_time_ms": 11221.078, "sample_time_ms": 1109.321, "learn_time_ms": 10099.537, "learn_throughput": 396.058, "synch_weights_time_ms": 11.777}, "counters": {"num_env_steps_sampled": 668000, "num_env_steps_trained": 668000, "num_agent_steps_sampled": 2672000, "num_agent_steps_trained": 2672000}, "done": false, "training_iteration": 167, "trial_id": "86f16_00000", "date": "2024-08-08_16-49-18", "timestamp": 1723150158, "time_this_iter_s": 10.815362930297852, "time_total_s": 2173.2191050052643, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x309c62160>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 2173.2191050052643, "iterations_since_restore": 167, "perf": {"cpu_util_percent": 28.119999999999994, "ram_util_percent": 81.08}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4992179438577476, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.681157896197434, "policy_loss": -0.019596057217270927, "vf_loss": 1.6999667553191489, "vf_explained_var": -1.052127662279927e-06, "kl": 0.00787198475180447, "entropy": 0.3759525648351257, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 472350.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.4542654532939197, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.648533232572178, "policy_loss": -0.03467776649049483, "vf_loss": 2.681281561156114, "vf_explained_var": 0.0915559017409881, "kl": 0.009647233347495763, "entropy": 0.9282565684989095, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 160800.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 672000, "num_env_steps_trained": 672000, "num_agent_steps_sampled": 2688000, "num_agent_steps_trained": 2688000}, "env_runners": {"episode_reward_max": 118.16483308965093, "episode_reward_min": -26.23428116705673, "episode_reward_mean": 13.83774783214735, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -61.83516691034906}, "policy_reward_max": {"adversary_policy": 60.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 8.024691358024691, "agent_policy": -10.236326241926722}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 40.0, 0.0, -1.5790818128048667, 0.0, -3.7957864301572393, -0.6299194775566697, 0.0, 0.0, -6.340950984716491, 40.0, 20.0, 0.0, 27.744690500623392, -8.494546164391313, 60.0, 0.0, 39.97028917915852, 0.0, 0.0, 20.0, 60.0, 0.0, 0.0, 40.0, 0.0, -1.3538524108120886, -22.755817735917482, 60.0, 0.0, 0.0, -1.1061860053676953, -2.011879799414565, 0.0, -4.641585926940938, 0.0, 80.0, 0.0, 40.0, 0.0, 100.0, 98.80964475921171, 0.0, -1.03055631433282, -0.04148501242359548, -7.8980445041380705, -9.293622815949496, 0.0, 58.21253595615917, 0.0, 0.0, 0.0, 0.0, -1.3803911531840907, 14.447010877669378, 33.280764190789846, 0.0, 0.0, -0.04774014790272063, 0.0, -2.8840049101211678, 0.0, 40.0, -6.499004788179669, 0.0, 97.36735650881886, -0.046310604991888216, 0.0, -8.71512218885045, 58.39590181738733, 60.0, -14.087216381965474, 18.417941019396082, 39.170549247490854, 0.0, 0.0, -14.807476278881014, 118.16483308965093, 20.0, -2.7317307694334345, 20.0, 0.0, -17.36255156932381, 39.781880713766185, 60.0, 0.0, 20.0, -4.15134336833367, 0.0, -8.202127593448845, 18.38415836089723, 60.0, 0.0, 80.0, 0.0, 0.0, -0.5040230722980088, 0.0, 20.0, 0.0, 20.0, 0.0, -0.22757018825524056, -0.2050177871402259, 80.0, 39.61758553574848, -26.23428116705673, -19.236264441917594, -6.892062712836729, -6.797920504872939, -1.26684766906077, -7.4910797360260695, 0.0, 20.0, -7.741201620933149, -1.2725744828854424, -1.4701851797478838, 18.02698782453878, 0.0, 40.0, 39.1630062502099, -16.526940422380182, -0.721943414483992, 60.0, 30.893879971321542, 0.0, 59.72003482397976, -0.09758509448419272, 0.0, 20.0, 0.0, 39.93041573295047, 0.0, -0.09811526343697419, 0.0, 40.0, 57.222061975928895, 38.2600069281725, -0.181062500822885, 0.0, 0.0, 18.31104209323768, 0.0, -0.29148853784317863, 0.0, 60.0, -7.617915628515199, 20.0, 100.0, 0.0, 0.0, 20.0, -7.462186449657541, -18.337742942069646, -15.424594101940498, 80.0, 0.0, 0.0, 20.0, 0.0, 16.409509518968136, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [0.0, -20.0, 0.0, -1.5790818128048667, 0.0, -3.7957864301572393, -0.6299194775566697, 0.0, 0.0, -6.340950984716491, -20.0, -10.0, 0.0, -32.255309499376615, -8.494546164391313, -30.0, 0.0, -20.02971082084148, 0.0, 0.0, -10.0, -30.0, 0.0, 0.0, -20.0, 0.0, -1.3538524108120886, -22.755817735917482, -30.0, 0.0, 0.0, -1.1061860053676953, -2.011879799414565, 0.0, -4.641585926940938, 0.0, -40.0, 0.0, -20.0, 0.0, -50.0, -51.19035524078829, 0.0, -1.03055631433282, -0.04148501242359548, -7.8980445041380705, -9.293622815949496, 0.0, -31.787464043840835, 0.0, 0.0, 0.0, 0.0, -1.3803911531840907, -15.55298912233062, -26.71923580921016, 0.0, 0.0, -0.04774014790272063, 0.0, -2.8840049101211678, 0.0, -20.0, -6.499004788179669, 0.0, -52.63264349118114, -0.046310604991888216, 0.0, -8.71512218885045, -31.60409818261267, -30.0, -14.087216381965474, -11.58205898060392, -20.829450752509143, 0.0, 0.0, -14.807476278881014, -61.83516691034906, -10.0, -2.7317307694334345, -10.0, 0.0, -17.36255156932381, -20.218119286233815, -30.0, 0.0, -10.0, -4.15134336833367, 0.0, -8.202127593448845, -11.615841639102767, -30.0, 0.0, -40.0, 0.0, 0.0, -0.5040230722980088, 0.0, -10.0, 0.0, -10.0, 0.0, -0.22757018825524056, -0.2050177871402259, -40.0, -20.382414464251518, -26.23428116705673, -19.236264441917594, -6.892062712836729, -6.797920504872939, -1.26684766906077, -7.4910797360260695, 0.0, -10.0, -7.741201620933149, -1.2725744828854424, -1.4701851797478838, -11.973012175461223, 0.0, -20.0, -20.836993749790096, -16.526940422380182, -0.721943414483992, -30.0, -29.10612002867845, 0.0, -30.279965176020237, -0.09758509448419272, 0.0, -10.0, 0.0, -20.069584267049528, 0.0, -0.09811526343697419, 0.0, -20.0, -32.777938024071105, -21.7399930718275, -0.181062500822885, 0.0, 0.0, -11.68895790676232, 0.0, -0.29148853784317863, 0.0, -30.0, -7.617915628515199, -10.0, -50.0, 0.0, 0.0, -10.0, -7.462186449657541, -18.337742942069646, -15.424594101940498, -40.0, 0.0, 0.0, -10.0, 0.0, -13.590490481031866, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6449712894121443, "mean_inference_ms": 1.1062867182539162, "mean_action_processing_ms": 0.23274889477033778, "mean_env_wait_ms": 0.48211697641862217, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004149807824028863, "StateBufferConnector_ms": 0.0030276951966462314, "ViewRequirementAgentConnector_ms": 0.08417860961254732}, "num_episodes": 162, "episode_return_max": 118.16483308965093, "episode_return_min": -26.23428116705673, "episode_return_mean": 13.83774783214735}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2688000, "num_agent_steps_trained": 2688000, "num_env_steps_sampled": 672000, "num_env_steps_trained": 672000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 362.32380269365717, "num_env_steps_trained_throughput_per_sec": 362.32380269365717, "timesteps_total": 672000, "num_env_steps_sampled_lifetime": 672000, "num_agent_steps_sampled_lifetime": 2688000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2688000, "timers": {"training_iteration_time_ms": 11202.558, "restore_workers_time_ms": 0.013, "training_step_time_ms": 11202.521, "sample_time_ms": 1104.737, "learn_time_ms": 10085.402, "learn_throughput": 396.613, "synch_weights_time_ms": 11.884}, "counters": {"num_env_steps_sampled": 672000, "num_env_steps_trained": 672000, "num_agent_steps_sampled": 2688000, "num_agent_steps_trained": 2688000}, "done": false, "training_iteration": 168, "trial_id": "86f16_00000", "date": "2024-08-08_16-49-29", "timestamp": 1723150169, "time_this_iter_s": 11.046199083328247, "time_total_s": 2184.2653040885925, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x309c7f0d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 2184.2653040885925, "iterations_since_restore": 168, "perf": {"cpu_util_percent": 27.7625, "ram_util_percent": 81.0}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.43773502749225773, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.3500626014479509, "policy_loss": -0.01838456596254457, "vf_loss": 1.367621527749596, "vf_explained_var": 2.210233228426453e-07, "kl": 0.008256388738742518, "entropy": 0.40816644544297076, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 475170.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.252035654336214, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.3040154959385593, "policy_loss": -0.04214057749874579, "vf_loss": 2.343844674155116, "vf_explained_var": 0.15144809999813635, "kl": 0.011556968398592235, "entropy": 0.9393705890203515, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 161760.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 676000, "num_env_steps_trained": 676000, "num_agent_steps_sampled": 2704000, "num_agent_steps_trained": 2704000}, "env_runners": {"episode_reward_max": 120.0, "episode_reward_min": -40.36820049442869, "episode_reward_mean": 9.195646903366226, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -60.0}, "policy_reward_max": {"adversary_policy": 60.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 5.925925925925926, "agent_policy": -8.58213087441155}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.192679495883354, -0.2688767463539188, 40.0, -2.381041573832454, 18.267067724966466, 0.0, 0.0, -26.862864440707828, 0.0, -0.5343514496527912, 0.0, 0.0, -0.10687595575301301, 0.0, 60.0, -1.8987172464232482, -11.671682731746568, -0.4073373468426289, 40.0, 20.0, 0.0, -6.7332623604234945, -0.2738137650755157, -6.994988009582459, 0.0, -0.9641453099698039, 0.0, 10.929928050165234, 20.0, 0.0, 20.0, 35.32036671537586, 0.0, 0.0, 18.972420214116312, 0.0, -11.389292315335004, 0.0, 59.42783020816093, 20.0, 0.0, 33.856354936275714, 0.0, 0.0, 20.0, 19.627697942271553, -0.1689636486731294, 60.0, -19.541449544160393, -2.634888443240463, 60.0, 0.0, -3.490420013970522, -0.7919860182986949, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.225252841763046, 0.0, 20.0, 0.0, 0.0, 39.743432855679885, -0.23616635028808175, -40.36820049442869, -1.5976261828631455, 39.35390259929054, 0.0, 39.64977148191542, -8.822006227251617, 0.0, -9.824806124201693, 0.0, -23.460527828713943, -4.98487957610488, 40.0, 20.0, -2.1235937624561947, 39.31668461198359, 0.0, -3.137120576147386, 0.0, 98.18941314015031, -9.388060994457952, 0.0, -28.93776727113968, 0.0, 59.17729356884888, 120.0, 0.0, -0.1724021943659826, -0.4291229493783255, 0.0, 54.498527451849526, 0.0, 0.0, -0.8228514736227088, -0.19100921795545567, 60.0, -6.889495204284507, 0.0, 0.0, 60.0, -10.31344307071045, 0.0, 0.0, 0.0, -3.485520007784748, -1.3996220210902754, -16.787579411096726, 40.0, -10.876600348044013, -5.177745701130929, 40.0, -14.01049483085894, 60.0, -1.2219178277158482, 0.0, -0.9203672103670824, 35.05218025882822, -7.738428941254652, 40.0, -1.3480273474206672, -2.5468987393009996, 120.0, 0.0, 0.0, 0.0, -3.306624909877099, 20.0, 0.0, 0.0, 60.0, -3.144160119946453, 0.0, 0.0, -11.469945565032553, -11.647017135867792, 0.0, -3.1672471202781827, -8.04588448951791, 60.0, 0.0, 0.0, 20.0, 20.0, 0.0, 0.0, 36.19146100978475, 15.380238121632335, 0.0, -1.7364157728698137, 0.0, 0.0, -2.036587022773706, -1.346078259446134, 0.0, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-21.807320504116646, -0.2688767463539188, -20.0, -2.381041573832454, -11.732932275033535, 0.0, 0.0, -26.862864440707828, 0.0, -0.5343514496527912, 0.0, 0.0, -0.10687595575301301, 0.0, -30.0, -1.8987172464232482, -11.671682731746568, -0.4073373468426289, -20.0, -10.0, 0.0, -6.7332623604234945, -0.2738137650755157, -6.994988009582459, 0.0, -0.9641453099698039, 0.0, -19.070071949834766, -10.0, 0.0, -10.0, -24.679633284624153, 0.0, 0.0, -11.027579785883688, 0.0, -11.389292315335004, 0.0, -30.572169791839073, -10.0, 0.0, -26.14364506372428, 0.0, 0.0, -10.0, -10.372302057728445, -0.1689636486731294, -30.0, -19.541449544160393, -2.634888443240463, -30.0, 0.0, -3.490420013970522, -0.7919860182986949, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.225252841763046, 0.0, -10.0, 0.0, 0.0, -20.25656714432012, -0.23616635028808175, -40.36820049442869, -1.5976261828631455, -20.646097400709458, 0.0, -20.350228518084577, -8.822006227251617, 0.0, -9.824806124201693, 0.0, -23.460527828713943, -4.98487957610488, -20.0, -10.0, -2.1235937624561947, -20.68331538801641, 0.0, -3.137120576147386, 0.0, -51.8105868598497, -9.388060994457952, 0.0, -28.93776727113968, 0.0, -30.822706431151126, -60.0, 0.0, -0.1724021943659826, -0.4291229493783255, 0.0, -35.501472548150474, 0.0, 0.0, -0.8228514736227088, -0.19100921795545567, -30.0, -6.889495204284507, 0.0, 0.0, -30.0, -40.31344307071045, 0.0, 0.0, 0.0, -3.485520007784748, -1.3996220210902754, -16.787579411096726, -20.0, -10.876600348044013, -5.177745701130929, -20.0, -14.01049483085894, -30.0, -1.2219178277158482, 0.0, -0.9203672103670824, -24.947819741171777, -7.738428941254652, -20.0, -1.3480273474206672, -2.5468987393009996, -60.0, 0.0, 0.0, 0.0, -3.306624909877099, -10.0, 0.0, 0.0, -30.0, -3.144160119946453, 0.0, 0.0, -11.469945565032553, -11.647017135867792, 0.0, -3.1672471202781827, -8.04588448951791, -30.0, 0.0, 0.0, -10.0, -10.0, 0.0, 0.0, -23.80853899021525, -14.619761878367665, 0.0, -1.7364157728698137, 0.0, 0.0, -2.036587022773706, -1.346078259446134, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6445667834680986, "mean_inference_ms": 1.1055836887749368, "mean_action_processing_ms": 0.23259625339156303, "mean_env_wait_ms": 0.481903418396109, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0038726830188138984, "StateBufferConnector_ms": 0.003103194413361726, "ViewRequirementAgentConnector_ms": 0.08203475563614457}, "num_episodes": 162, "episode_return_max": 120.0, "episode_return_min": -40.36820049442869, "episode_return_mean": 9.195646903366226}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2704000, "num_agent_steps_trained": 2704000, "num_env_steps_sampled": 676000, "num_env_steps_trained": 676000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 360.2598767955858, "num_env_steps_trained_throughput_per_sec": 360.2598767955858, "timesteps_total": 676000, "num_env_steps_sampled_lifetime": 676000, "num_agent_steps_sampled_lifetime": 2704000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2704000, "timers": {"training_iteration_time_ms": 11190.816, "restore_workers_time_ms": 0.013, "training_step_time_ms": 11190.779, "sample_time_ms": 1104.069, "learn_time_ms": 10074.418, "learn_throughput": 397.045, "synch_weights_time_ms": 11.842}, "counters": {"num_env_steps_sampled": 676000, "num_env_steps_trained": 676000, "num_agent_steps_sampled": 2704000, "num_agent_steps_trained": 2704000}, "done": false, "training_iteration": 169, "trial_id": "86f16_00000", "date": "2024-08-08_16-49-40", "timestamp": 1723150180, "time_this_iter_s": 11.10814905166626, "time_total_s": 2195.373453140259, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x309c7f310>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 2195.373453140259, "iterations_since_restore": 169, "perf": {"cpu_util_percent": 27.53125, "ram_util_percent": 81.03125}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5520182972364391, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.6667224756792083, "policy_loss": -0.021546969716998595, "vf_loss": 1.6874261228328056, "vf_explained_var": 1.514000250092635e-07, "kl": 0.008433236008187994, "entropy": 0.3914933294586256, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 477990.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.2614511653780935, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.6161710785080987, "policy_loss": -0.032580288721995504, "vf_loss": 2.6467000798632703, "vf_explained_var": 0.0997157508507371, "kl": 0.010256422942489086, "entropy": 0.9518770894656579, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 162720.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 680000, "num_env_steps_trained": 680000, "num_agent_steps_sampled": 2720000, "num_agent_steps_trained": 2720000}, "env_runners": {"episode_reward_max": 120.0, "episode_reward_min": -32.08334578225019, "episode_reward_mean": 12.335527686017322, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -62.12975227608721}, "policy_reward_max": {"adversary_policy": 60.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 7.530864197530864, "agent_policy": -10.257064906575271}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.0, -4.557657368921791, 0.0, 0.0, -4.0723563870749615, 0.0, 20.0, 0.0, 0.0, 56.39175587280306, -3.716064379626615, -0.017717784118750357, 40.0, 0.0, 39.299313221852714, 0.0, 40.0, 39.40920857466945, 40.0, 20.0, -0.4915710647989724, -0.8605978406982229, -0.05917701535017361, 58.935990501316695, 0.0, 0.0, -11.688603805611796, 20.0, 33.26448409502598, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.20143159514029896, -11.466948899025457, 0.0, 0.0, 99.66890622996478, 0.0, 120.0, 0.0, 40.0, 0.0, 0.0, -1.5717303400045335, -9.28215410258419, 39.73561159805737, -10.466638407085899, 0.0, -25.863399420200697, 60.0, 0.0, -0.0784897713366095, 20.0, 0.0, 0.0, 0.0, 20.0, 0.0, 40.0, 18.011614245302894, 0.0, 0.0, -4.35816491755664, 0.0, 40.0, 0.0, 0.0, 0.0, 0.0, -3.2170850598760437, 0.0, -7.257712899434484, 0.0, -8.730165313469685, -11.730000063993707, 12.84647830876807, 0.0, -9.209679796197463, 0.0, 0.0, -2.169931088371171, 0.0, 0.0, 0.0, 0.0, -1.4550786445385167, -5.386004922357699, 20.0, -0.2678734525952142, 73.3755505969798, 0.0, 36.80904699519019, 16.517622812018633, -0.642006300788095, -10.372217293033373, 40.0, 60.0, 16.935189705402998, 0.0, 0.0, 60.0, 0.0, 57.870247723912804, 0.0, 0.0, 13.555539343089926, -0.34367724678573297, 60.0, 0.0, 20.0, 0.0, 0.0, 20.0, 40.0, 0.0, 80.0, 60.0, 0.0, -0.6326188701404722, 60.0, 56.91080706892546, 0.0, 0.0, 0.0, 0.0, 35.21708957066866, -32.08334578225019, 40.0, 36.51887316630369, 9.112612936649407, 30.01585356808682, -3.4283972967795937, 0.0, 40.0, 12.151288936545743, 20.0, 0.0, 0.0, -0.12594275931389842, -0.058415333876218334, 20.0, 40.0, -5.370577581077754, 0.0, 60.0, -10.516506091864791, -1.789778574581432, 13.03226760461899, -1.2516913465271684, -16.89202022558986, 29.069124618124324, 19.834492781283505, -21.01209861671808, 60.0, 0.0, 20.0, 20.0, -13.437957281459667, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-20.0, -4.557657368921791, 0.0, 0.0, -4.0723563870749615, 0.0, -10.0, 0.0, 0.0, -33.60824412719694, -3.716064379626615, -0.017717784118750357, -20.0, 0.0, -20.70068677814729, 0.0, -20.0, -20.59079142533055, -20.0, -10.0, -0.4915710647989724, -0.8605978406982229, -0.05917701535017361, -31.064009498683298, 0.0, 0.0, -11.688603805611796, -10.0, -26.73551590497402, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.20143159514029896, -11.466948899025457, 0.0, 0.0, -50.33109377003522, 0.0, -60.0, 0.0, -20.0, 0.0, 0.0, -1.5717303400045335, -9.28215410258419, -20.264388401942632, -10.466638407085899, 0.0, -25.863399420200697, -30.0, 0.0, -0.0784897713366095, -10.0, 0.0, 0.0, 0.0, -10.0, 0.0, -20.0, -11.988385754697106, 0.0, 0.0, -4.35816491755664, 0.0, -20.0, 0.0, 0.0, 0.0, 0.0, -3.2170850598760437, 0.0, -7.257712899434484, 0.0, -8.730165313469685, -11.730000063993707, -17.15352169123193, 0.0, -9.209679796197463, 0.0, 0.0, -2.169931088371171, 0.0, 0.0, 0.0, 0.0, -1.4550786445385167, -5.386004922357699, -10.0, -0.2678734525952142, -46.6244494030202, 0.0, -23.190953004809806, -43.48237718798137, -0.642006300788095, -10.372217293033373, -20.0, -30.0, -13.064810294597002, 0.0, 0.0, -30.0, 0.0, -62.12975227608721, 0.0, 0.0, -46.444460656910074, -0.34367724678573297, -30.0, 0.0, -10.0, 0.0, 0.0, -10.0, -20.0, 0.0, -40.0, -30.0, 0.0, -0.6326188701404722, -30.0, -33.08919293107454, 0.0, 0.0, 0.0, 0.0, -24.78291042933134, -32.08334578225019, -20.0, -23.48112683369631, -20.887387063350594, -59.98414643191318, -3.4283972967795937, 0.0, -20.0, -17.848711063454264, -10.0, 0.0, 0.0, -0.12594275931389842, -0.058415333876218334, -10.0, -20.0, -5.370577581077754, 0.0, -30.0, -10.516506091864791, -1.789778574581432, -16.96773239538101, -1.2516913465271684, -16.89202022558986, -30.93087538187567, -10.165507218716495, -21.01209861671808, -30.0, 0.0, -10.0, -10.0, -13.437957281459667, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6441441971026913, "mean_inference_ms": 1.1049360298569373, "mean_action_processing_ms": 0.23244853975951407, "mean_env_wait_ms": 0.4817321714599941, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004075412397031431, "StateBufferConnector_ms": 0.002991711651837384, "ViewRequirementAgentConnector_ms": 0.08534538893052089}, "num_episodes": 162, "episode_return_max": 120.0, "episode_return_min": -32.08334578225019, "episode_return_mean": 12.335527686017322}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2720000, "num_agent_steps_trained": 2720000, "num_env_steps_sampled": 680000, "num_env_steps_trained": 680000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 358.237237543676, "num_env_steps_trained_throughput_per_sec": 358.237237543676, "timesteps_total": 680000, "num_env_steps_sampled_lifetime": 680000, "num_agent_steps_sampled_lifetime": 2720000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2720000, "timers": {"training_iteration_time_ms": 11164.392, "restore_workers_time_ms": 0.013, "training_step_time_ms": 11164.354, "sample_time_ms": 1103.528, "learn_time_ms": 10048.586, "learn_throughput": 398.066, "synch_weights_time_ms": 11.791}, "counters": {"num_env_steps_sampled": 680000, "num_env_steps_trained": 680000, "num_agent_steps_sampled": 2720000, "num_agent_steps_trained": 2720000}, "done": false, "training_iteration": 170, "trial_id": "86f16_00000", "date": "2024-08-08_16-49-52", "timestamp": 1723150192, "time_this_iter_s": 11.172142267227173, "time_total_s": 2206.545595407486, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x309c7f5e0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 2206.545595407486, "iterations_since_restore": 170, "perf": {"cpu_util_percent": 30.03125, "ram_util_percent": 81.05625}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.49786910269383, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.6492816145538438, "policy_loss": -0.01906381554161413, "vf_loss": 1.6676640070921986, "vf_explained_var": -6.753079434658619e-08, "kl": 0.006814227390372741, "entropy": 0.3753539430017167, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 480810.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.329121684655547, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.6795139795169236, "policy_loss": -0.033672879874939096, "vf_loss": 2.711298721159498, "vf_explained_var": 0.12575682650009792, "kl": 0.009440708260685304, "entropy": 0.9433667567869027, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 163680.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 684000, "num_env_steps_trained": 684000, "num_agent_steps_sampled": 2736000, "num_agent_steps_trained": 2736000}, "env_runners": {"episode_reward_max": 115.59321513345394, "episode_reward_min": -29.530501784975186, "episode_reward_mean": 11.49180404138669, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 153, "episodes_timesteps_total": 3825, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -66.12303021817387}, "policy_reward_max": {"adversary_policy": 60.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 7.0588235294117645, "agent_policy": -9.684666546848602}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-19.39593628773573, 0.0, 18.871920860028283, 40.0, -0.007691990198953613, 40.0, 20.0, 0.0, 40.0, 60.0, 0.0, 60.0, 18.028022007087564, 39.26169405847718, 17.829702536576846, -0.1805951364017011, 0.0, -0.3965325628805272, 0.0, 60.0, 0.0, -0.42905422209303934, 0.0, -12.456674844804857, 20.0, -4.75290601837598, -6.868085054782272, 0.0, 0.0, -15.889954176538541, -4.055211239899472, -9.09616723221422, -11.39388980087217, 0.0, 0.0, 31.428402272705316, 0.0, 40.0, -2.876816784364178, 20.0, 0.0, 58.99640131847394, 59.77739542663751, 19.338880073434257, 18.777787442036846, -0.5541034109945286, -9.61023180610326, 19.716884302915403, 0.0, 80.0, 0.0, 0.0, 60.0, 0.0, 0.0, 0.0, -0.28758367713162536, 0.0, -25.087325656911347, -3.4861025281400444, 0.0, 0.0, -2.8875397435629884, -0.07046416514442155, 60.0, -0.1635553416289537, 0.0, 0.0, 113.87696978182613, 20.0, -19.38827256833738, -7.046317282691757, -6.801043172001938, 27.624553921180485, 0.0, 19.763578631897396, 20.0, 0.0, -1.408651074911459, -7.080933206442703, 80.0, 0.0, 0.0, 0.0, 51.65734814991933, 58.88152779832684, 18.69681348277075, -11.496810007481566, 20.0, 0.0, -0.9792595049527653, 0.0, -16.3441527364285, 0.0, 40.0, 0.0, 0.0, 56.70422946058753, -0.037834920928182525, 0.0, -1.0317765878588836, 0.0, 0.0, -2.812905965771402, -11.588315892952789, 0.0, -5.507147227272781, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 59.45045379356023, 20.0, 40.0, 0.0, -5.3407402241687025, -9.590778457630776, -0.7258568710368407, 0.0, -8.050836593612061, -8.379187056059592, 0.0, 40.0, 0.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 37.47797249112367, 20.0, 0.0, -13.255251595352828, 10.68095736446068, 0.0, -10.989469137233815, -0.29335730583813, 0.0, 115.59321513345394, 100.0, 0.0, 60.0, 0.0, 0.0, -0.5390017473544906, -5.204085587700099, -29.530501784975186, 40.0, -0.819783785542918], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-19.39593628773573, 0.0, -11.128079139971717, -20.0, -0.007691990198953613, -20.0, -10.0, 0.0, -20.0, -30.0, 0.0, -30.0, -11.971977992912437, -20.738305941522817, -12.170297463423156, -0.1805951364017011, 0.0, -0.3965325628805272, 0.0, -30.0, 0.0, -0.42905422209303934, 0.0, -12.456674844804857, -10.0, -4.75290601837598, -6.868085054782272, 0.0, 0.0, -15.889954176538541, -4.055211239899472, -9.09616723221422, -11.39388980087217, 0.0, 0.0, -28.571597727294677, 0.0, -20.0, -2.876816784364178, -10.0, 0.0, -31.00359868152606, -30.222604573362485, -10.661119926565743, -11.222212557963152, -0.5541034109945286, -9.61023180610326, -10.283115697084597, 0.0, -40.0, 0.0, 0.0, -30.0, 0.0, 0.0, 0.0, -0.28758367713162536, 0.0, -25.087325656911347, -3.4861025281400444, 0.0, 0.0, -2.8875397435629884, -0.07046416514442155, -30.0, -0.1635553416289537, 0.0, 0.0, -66.12303021817387, -10.0, -19.38827256833738, -7.046317282691757, -6.801043172001938, -32.375446078819515, 0.0, -10.236421368102603, -10.0, 0.0, -1.408651074911459, -7.080933206442703, -40.0, 0.0, 0.0, 0.0, -38.342651850080664, -31.11847220167316, -11.303186517229252, -11.496810007481566, -10.0, 0.0, -0.9792595049527653, 0.0, -16.3441527364285, 0.0, -20.0, 0.0, 0.0, -33.295770539412466, -0.037834920928182525, 0.0, -1.0317765878588836, 0.0, 0.0, -2.812905965771402, -11.588315892952789, 0.0, -5.507147227272781, 0.0, 0.0, 0.0, 0.0, -10.0, -10.0, -30.54954620643978, -10.0, -20.0, 0.0, -5.3407402241687025, -9.590778457630776, -0.7258568710368407, 0.0, -8.050836593612061, -38.3791870560596, 0.0, -20.0, 0.0, -30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -22.522027508876327, -10.0, 0.0, -13.255251595352828, -19.31904263553932, 0.0, -10.989469137233815, -0.29335730583813, 0.0, -64.40678486654605, -50.0, 0.0, -30.0, 0.0, 0.0, -0.5390017473544906, -5.204085587700099, -29.530501784975186, -20.0, -0.819783785542918]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6436945679809941, "mean_inference_ms": 1.104266625207476, "mean_action_processing_ms": 0.2322757080903859, "mean_env_wait_ms": 0.4815176379944947, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004307195252063228, "StateBufferConnector_ms": 0.0032646204131880617, "ViewRequirementAgentConnector_ms": 0.08259996090059966}, "num_episodes": 153, "episode_return_max": 115.59321513345394, "episode_return_min": -29.530501784975186, "episode_return_mean": 11.49180404138669}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2736000, "num_agent_steps_trained": 2736000, "num_env_steps_sampled": 684000, "num_env_steps_trained": 684000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 366.24295061797926, "num_env_steps_trained_throughput_per_sec": 366.24295061797926, "timesteps_total": 684000, "num_env_steps_sampled_lifetime": 684000, "num_agent_steps_sampled_lifetime": 2736000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2736000, "timers": {"training_iteration_time_ms": 11099.386, "restore_workers_time_ms": 0.013, "training_step_time_ms": 11099.351, "sample_time_ms": 1102.843, "learn_time_ms": 9984.406, "learn_throughput": 400.625, "synch_weights_time_ms": 11.711}, "counters": {"num_env_steps_sampled": 684000, "num_env_steps_trained": 684000, "num_agent_steps_sampled": 2736000, "num_agent_steps_trained": 2736000}, "done": false, "training_iteration": 171, "trial_id": "86f16_00000", "date": "2024-08-08_16-50-03", "timestamp": 1723150203, "time_this_iter_s": 10.927001953125, "time_total_s": 2217.472597360611, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x309c7fb80>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 2217.472597360611, "iterations_since_restore": 171, "perf": {"cpu_util_percent": 29.2, "ram_util_percent": 81.33125}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4777885434316828, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.1268699238063595, "policy_loss": -0.01888178704968647, "vf_loss": 1.1449929816767257, "vf_explained_var": -2.8415774622707503e-07, "kl": 0.007587296128372145, "entropy": 0.4042854895828463, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 483630.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.1517861367513738, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.8627308162860572, "policy_loss": -0.03373927669623906, "vf_loss": 1.8945864188484847, "vf_explained_var": 0.07014547778914372, "kl": 0.009418377514684549, "entropy": 0.9606278449296951, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 164640.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 688000, "num_env_steps_trained": 688000, "num_agent_steps_sampled": 2752000, "num_agent_steps_trained": 2752000}, "env_runners": {"episode_reward_max": 100.0, "episode_reward_min": -22.26383301798223, "episode_reward_mean": 8.566853633474409, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -56.727204890776875}, "policy_reward_max": {"adversary_policy": 50.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 5.061728395061729, "agent_policy": -6.618331551710775}, "custom_metrics": {}, "hist_stats": {"episode_reward": [100.0, 0.0, 0.0, 19.335532904392746, -0.031832228986976574, -2.6487102336030137, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 0.0, -3.9163773572003713, 0.0, -0.47223119977575556, -2.4460827255721416, 20.0, 6.218697954330272, -3.2852432482339746, 74.71865213600594, 0.0, 60.0, 60.0, 0.0, 36.1686519076811, 0.0, 100.0, 0.0, 0.0, 0.0, -0.10484477292214134, 0.0, 0.0, 0.0, 0.0, 0.0, -1.3836456887681936, 20.0, 0.0, 0.0, 80.0, -8.558718227097913, -10.646037953833373, -0.4835595757190525, -2.2005854321500844, 59.90743712892173, -1.0249658981705922, 20.0, 0.0, 0.0, 0.0, 40.0, 0.0, 0.0, -10.465426112580431, -1.4283012789699312, 40.0, 80.0, 0.0, 0.0, 0.0, 0.0, -6.731046834545802, 0.0, 0.0, 40.0, 38.667961281525706, -0.19526156595858768, -4.675418038161263, 0.0, 0.0, 0.0, -8.763165960270035, -1.3938101122166624, -0.6512881462415887, 0.0, 39.48919165509516, 20.0, 60.0, 60.0, 0.0, 0.0, 0.0, 17.489394020618697, -0.009263270416500768, 40.0, 0.0, -18.29842320814432, -0.542534416720073, 17.906992193075432, 0.0, -0.2336947056417582, 0.0, 0.0, 40.0, -0.4734004696374128, -10.329023091877414, 0.0, 0.0, 0.0, -0.07303553166905119, 0.0, -0.7941577814366063, 0.0, -2.9421206276610548, 0.0, 0.0, 0.0, 0.0, 0.0, 63.27279510922311, 0.0, 0.0, -1.5672010755005894, -7.037397616161584, -5.800166083729052, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 0.0, 20.0, -11.585297194009165, 0.0, 0.0, 0.0, 40.0, -0.03717626419754705, -9.946083234480728, 0.0, 0.0, -0.6417451831294341, -1.9444113530428497, -1.435037118757675, -22.26383301798223, -6.885855914628937, -6.615303033593514, 20.0, 39.63409477316115, -0.028319202058288973, -20.08886476232739, 0.0, 0.0, -0.06484269160558775, 0.0, -1.0770446650054422, 0.0, 0.0, 59.15658759285758, 0.0, -1.9149159296422869, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-50.0, 0.0, 0.0, -10.664467095607252, -0.031832228986976574, -2.6487102336030137, -10.0, -10.0, -10.0, 0.0, 0.0, 0.0, -20.0, 0.0, -3.9163773572003713, 0.0, -0.47223119977575556, -2.4460827255721416, -10.0, -23.78130204566973, -3.2852432482339746, -45.281347863994064, 0.0, -30.0, -30.0, 0.0, -23.831348092318898, 0.0, -50.0, 0.0, 0.0, 0.0, -0.10484477292214134, 0.0, 0.0, 0.0, 0.0, 0.0, -1.3836456887681936, -10.0, 0.0, 0.0, -40.0, -8.558718227097913, -10.646037953833373, -0.4835595757190525, -2.2005854321500844, -30.09256287107827, -1.0249658981705922, -10.0, 0.0, 0.0, 0.0, -20.0, 0.0, 0.0, -10.465426112580431, -1.4283012789699312, -20.0, -40.0, 0.0, 0.0, 0.0, 0.0, -6.731046834545802, 0.0, 0.0, -20.0, -21.332038718474294, -0.19526156595858768, -4.675418038161263, 0.0, 0.0, 0.0, -8.763165960270035, -1.3938101122166624, -0.6512881462415887, 0.0, -20.510808344904838, -10.0, -30.0, -30.0, 0.0, 0.0, 0.0, -12.510605979381303, -0.009263270416500768, -20.0, 0.0, -18.29842320814432, -0.542534416720073, -12.093007806924572, 0.0, -0.2336947056417582, 0.0, 0.0, -20.0, -0.4734004696374128, -10.329023091877414, 0.0, 0.0, 0.0, -0.07303553166905119, 0.0, -0.7941577814366063, 0.0, -2.9421206276610548, 0.0, 0.0, 0.0, 0.0, 0.0, -56.727204890776875, 0.0, 0.0, -1.5672010755005894, -7.037397616161584, -5.800166083729052, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -30.0, 0.0, -10.0, -11.585297194009165, 0.0, 0.0, 0.0, -20.0, -0.03717626419754705, -9.946083234480728, 0.0, 0.0, -0.6417451831294341, -1.9444113530428497, -1.435037118757675, -22.26383301798223, -6.885855914628937, -6.615303033593514, -10.0, -20.365905226838848, -0.028319202058288973, -20.08886476232739, 0.0, 0.0, -0.06484269160558775, 0.0, -1.0770446650054422, 0.0, 0.0, -30.84341240714241, 0.0, -1.9149159296422869, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6433692457155084, "mean_inference_ms": 1.1036325115358219, "mean_action_processing_ms": 0.23212117143626257, "mean_env_wait_ms": 0.4812971703500709, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00402265124850803, "StateBufferConnector_ms": 0.0032185772318898895, "ViewRequirementAgentConnector_ms": 0.08693300647500121}, "num_episodes": 162, "episode_return_max": 100.0, "episode_return_min": -22.26383301798223, "episode_return_mean": 8.566853633474409}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2752000, "num_agent_steps_trained": 2752000, "num_env_steps_sampled": 688000, "num_env_steps_trained": 688000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 369.3082694446544, "num_env_steps_trained_throughput_per_sec": 369.3082694446544, "timesteps_total": 688000, "num_env_steps_sampled_lifetime": 688000, "num_agent_steps_sampled_lifetime": 2752000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2752000, "timers": {"training_iteration_time_ms": 11070.715, "restore_workers_time_ms": 0.013, "training_step_time_ms": 11070.68, "sample_time_ms": 1105.408, "learn_time_ms": 9953.366, "learn_throughput": 401.874, "synch_weights_time_ms": 11.487}, "counters": {"num_env_steps_sampled": 688000, "num_env_steps_trained": 688000, "num_agent_steps_sampled": 2752000, "num_agent_steps_trained": 2752000}, "done": false, "training_iteration": 172, "trial_id": "86f16_00000", "date": "2024-08-08_16-50-14", "timestamp": 1723150214, "time_this_iter_s": 10.836562156677246, "time_total_s": 2228.309159517288, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x309c5b1f0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 2228.309159517288, "iterations_since_restore": 172, "perf": {"cpu_util_percent": 29.813333333333333, "ram_util_percent": 81.29333333333334}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.48318931408067967, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.735504061152749, "policy_loss": -0.017881772057681693, "vf_loss": 1.7526134012861454, "vf_explained_var": -2.683477198823969e-07, "kl": 0.007724311102934245, "entropy": 0.3788794885501794, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 486450.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.0397502803554137, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.364670949925979, "policy_loss": -0.03360809953058682, "vf_loss": 2.3964412902171413, "vf_explained_var": 0.05968594768395027, "kl": 0.009188718741250513, "entropy": 0.956264910598596, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 165600.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 692000, "num_env_steps_trained": 692000, "num_agent_steps_sampled": 2768000, "num_agent_steps_trained": 2768000}, "env_runners": {"episode_reward_max": 123.77200008221149, "episode_reward_min": -17.931998926363768, "episode_reward_mean": 15.14801762231651, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -86.2279999177885}, "policy_reward_max": {"adversary_policy": 70.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 8.209876543209877, "agent_policy": -9.48161200731312}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.0, 0.0, 20.0, 20.0, 79.9777019709494, 0.0, -14.73797129652253, -9.573252358881684, 38.7432373726001, 0.0, 0.0, -3.5259593503919064, 0.0, -7.968204910336278, 40.0, 0.0, 0.0, 0.0, 0.0, 38.89064604938139, 40.0, 20.0, 0.0, 20.0, 40.0, 0.0, 20.0, 20.0, 0.0, -0.20661236411245398, 20.0, 20.0, 0.0, 20.0, 0.0, -0.2094227080694211, 40.0, 20.0, -6.861754818108377, -1.933832719919818, 40.0, 0.0, 20.0, 0.0, -1.2189375715537476, 0.0, 0.0, 0.0, -3.0338413122865147, 0.0, 0.0, 80.0, 40.0, 0.0, 0.0, 59.682962609168754, 80.0, 60.0, 123.77200008221149, 15.197251560106858, 0.0, 0.0, 0.0, 0.0, 34.00929937053924, 0.0, 59.97172609049388, 0.0, 0.0, 79.67845707058879, 0.0, -0.6362419639913486, 39.196486859201045, -10.32281676523284, 0.0, 0.0, 0.0, -2.6398786170719415, -1.8437466057169438, 0.0, 60.0, 79.8175903780647, 0.0, 0.0, 0.0, 20.0, -3.9589896436375005, 0.0, 0.0, -5.253427555740103, 0.0, 0.0, 0.0, -0.8950968882514476, -0.94559378450909, 0.0, 40.0, 0.0, -0.151886478684492, 0.0, -2.0789433711760976, 40.0, 0.0, -1.7207953783559637, -0.551457840127475, 20.0, 0.0, -2.4637332254820796, 0.0, -4.683004037736522, 0.0, 77.56706166340874, 0.0, 0.0, 40.0, 120.0, 0.0, -14.676603571820447, 0.0, 9.974101496144394, -3.8682722303608967, 0.0, 20.0, 80.0, 0.0, 60.0, -0.5323431221126873, 20.0, 100.0, -3.966377646449174, 0.0, 0.0, 18.953365367120572, 0.0, -17.931998926363768, -0.6679743804259286, 0.0, -5.839429480518715, 0.0, -1.1175552240954778, 40.0, 0.0, 40.0, 13.578660866571703, 0.0, 0.0, 60.0, 100.0, 0.0, 39.73872638942629, -1.947401986009003, 0.0, 19.58668818073366, 0.0, -0.1982946551845799, -6.670577730690582, 40.0, 20.0, 40.0, 0.0, 90.47512195849148, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 70.0, 70.0, 70.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-20.0, 0.0, -10.0, -10.0, -40.0222980290506, 0.0, -14.73797129652253, -9.573252358881684, -21.2567626273999, 0.0, 0.0, -3.5259593503919064, 0.0, -7.968204910336278, -20.0, 0.0, 0.0, 0.0, 0.0, -21.109353950618612, -20.0, -10.0, 0.0, -10.0, -20.0, 0.0, -10.0, -10.0, 0.0, -0.20661236411245398, -10.0, -10.0, 0.0, -10.0, 0.0, -0.2094227080694211, -20.0, -10.0, -6.861754818108377, -1.933832719919818, -20.0, 0.0, -10.0, 0.0, -1.2189375715537476, 0.0, 0.0, 0.0, -3.0338413122865147, 0.0, 0.0, -40.0, -20.0, 0.0, 0.0, -30.31703739083125, -40.0, -30.0, -86.2279999177885, -14.802748439893138, 0.0, 0.0, 0.0, 0.0, -25.99070062946076, 0.0, -30.02827390950612, 0.0, 0.0, -40.3215429294112, 0.0, -0.6362419639913486, -20.803513140798955, -10.32281676523284, 0.0, 0.0, 0.0, -2.6398786170719415, -1.8437466057169438, 0.0, -30.0, -40.18240962193531, 0.0, 0.0, 0.0, -10.0, -3.9589896436375005, 0.0, 0.0, -5.253427555740103, 0.0, 0.0, 0.0, -0.8950968882514476, -0.94559378450909, 0.0, -20.0, 0.0, -0.151886478684492, 0.0, -2.0789433711760976, -20.0, 0.0, -1.7207953783559637, -0.551457840127475, -10.0, 0.0, -2.4637332254820796, 0.0, -4.683004037736522, 0.0, -42.43293833659126, 0.0, 0.0, -20.0, -60.0, 0.0, -14.676603571820447, 0.0, -20.025898503855604, -3.8682722303608967, 0.0, -10.0, -40.0, 0.0, -30.0, -0.5323431221126873, -10.0, -50.0, -3.966377646449174, 0.0, 0.0, -11.046634632879428, 0.0, -17.931998926363768, -0.6679743804259286, 0.0, -5.839429480518715, 0.0, -1.1175552240954778, -20.0, 0.0, -20.0, -16.421339133428297, 0.0, 0.0, -30.0, -50.0, 0.0, -20.261273610573706, -1.947401986009003, 0.0, -10.41331181926634, 0.0, -0.1982946551845799, -6.670577730690582, -20.0, -10.0, -20.0, 0.0, -59.52487804150851, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6431557271408329, "mean_inference_ms": 1.1032668180765985, "mean_action_processing_ms": 0.23202764855686991, "mean_env_wait_ms": 0.4811189776040947, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004154811670750748, "StateBufferConnector_ms": 0.0032260830019727165, "ViewRequirementAgentConnector_ms": 0.08793355506143452}, "num_episodes": 162, "episode_return_max": 123.77200008221149, "episode_return_min": -17.931998926363768, "episode_return_mean": 15.14801762231651}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2768000, "num_agent_steps_trained": 2768000, "num_env_steps_sampled": 692000, "num_env_steps_trained": 692000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 355.4201091257244, "num_env_steps_trained_throughput_per_sec": 355.4201091257244, "timesteps_total": 692000, "num_env_steps_sampled_lifetime": 692000, "num_agent_steps_sampled_lifetime": 2768000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2768000, "timers": {"training_iteration_time_ms": 11064.714, "restore_workers_time_ms": 0.013, "training_step_time_ms": 11064.679, "sample_time_ms": 1108.126, "learn_time_ms": 9944.66, "learn_throughput": 402.226, "synch_weights_time_ms": 11.54}, "counters": {"num_env_steps_sampled": 692000, "num_env_steps_trained": 692000, "num_agent_steps_sampled": 2768000, "num_agent_steps_trained": 2768000}, "done": false, "training_iteration": 173, "trial_id": "86f16_00000", "date": "2024-08-08_16-50-25", "timestamp": 1723150225, "time_this_iter_s": 11.259135007858276, "time_total_s": 2239.5682945251465, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x309c5b790>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 2239.5682945251465, "iterations_since_restore": 173, "perf": {"cpu_util_percent": 30.162499999999994, "ram_util_percent": 82.93125}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4784030740882488, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.4088862789226761, "policy_loss": -0.019681276896298065, "vf_loss": 1.4277666963161306, "vf_explained_var": -5.906778024443497e-07, "kl": 0.008008585058101678, "entropy": 0.38594721470107424, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 489270.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.1722209977606934, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.2692716559705635, "policy_loss": -0.03282908985565882, "vf_loss": 2.3004248935729263, "vf_explained_var": 0.13424923028796912, "kl": 0.008379249387979475, "entropy": 0.9405545998364687, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 166560.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 696000, "num_env_steps_trained": 696000, "num_agent_steps_sampled": 2784000, "num_agent_steps_trained": 2784000}, "env_runners": {"episode_reward_max": 100.0, "episode_reward_min": -26.214857809458465, "episode_reward_mean": 9.871696347166639, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -55.727431645315285}, "policy_reward_max": {"adversary_policy": 50.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 6.172839506172839, "agent_policy": -8.646822171351877}, "custom_metrics": {}, "hist_stats": {"episode_reward": [24.38589320668399, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.003907360548798, 16.846730715787388, 0.0, 12.140262741339718, -3.7455781076568355, 19.527111854796374, 0.0, 38.50225302947776, 60.0, 0.0, -16.112756326430212, -10.253455603395123, 0.0, 0.0, 0.0, 0.0, 100.0, -12.709126037700209, 28.87790882815201, -0.07948181079741823, 0.0, 59.260988277877644, -12.711116428659926, -12.964358056634255, 17.41091468087877, 0.0, -0.5760294984109615, 0.0, -1.2632593953955784, 0.0, -4.522057914047694, 0.0, 0.0, 0.0, 0.0, 0.0, -0.2544954595060478, -0.015971758374214717, -2.5498294307174256, 40.0, 0.0, -1.0931951311208365, 19.97142178016207, 0.0, 40.0, -13.57395546268648, 0.0, 0.0, 19.17040798860493, 0.0, 0.0, 94.27256835468472, -2.1954627504127213, -1.5168827465798849, -6.804240591309567, 0.0, 40.0, 0.0, -8.456369356449164, 58.53334289680947, 0.0, 0.0, 20.0, -16.41324358157677, -8.056315717929786, 75.59290080273978, 40.0, 59.38159644860521, 0.0, -0.8960535213731657, -26.214857809458465, -0.39027519188187365, -3.76165897610626, 20.0, 0.0, 39.971856404354725, 54.513761063993016, 0.0, 0.0, -2.1411240894598507, 0.0, 0.0, -2.2772843271548795, 0.0, -19.010441527265847, -0.20800889536564449, -0.6568581865500867, 40.0, 0.0, 0.0, -1.5915337722769174, 19.35600908796494, 39.62471979840936, 80.0, -8.573973699874449, 0.0, 19.629069891767493, 0.0, 0.0, 0.0, 40.0, 19.12854000981421, -2.260921134271695, 0.0, 37.1186867073783, 80.0, -12.759544361327059, 0.0, 0.0, 60.0, 80.0, -12.57740788477969, -1.1300680833338217, 0.0, 0.0, 100.0, 0.0, 0.0, -0.0609159123910985, 0.0, -16.132564922709097, 0.0, -0.2917869799934325, 0.0, 19.87064336160727, 20.0, 0.0, 0.0, 0.0, -13.954712764829111, 19.633572271184946, 36.408103145028306, 0.0, 0.0, 0.0, -0.0022839336014324196, 0.0, 0.0, -1.4019718426822114, 0.0, 20.0, 0.0, 0.0, 0.0, 19.55283208387903, -21.494368883022286, 45.405544723984605, -19.524939550495738, 39.35255300821586, -5.236010911117942, 38.813920868420325, -0.048032925092539314, -3.5706171788520225, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-35.61410679331601, -20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.003907360548798, -13.153269284212612, 0.0, -17.85973725866028, -3.7455781076568355, -10.472888145203628, 0.0, -21.497746970522243, -30.0, 0.0, -16.112756326430212, -10.253455603395123, 0.0, 0.0, 0.0, 0.0, -50.0, -12.709126037700209, -31.12209117184799, -0.07948181079741823, 0.0, -30.73901172212236, -12.711116428659926, -12.964358056634255, -12.58908531912123, 0.0, -0.5760294984109615, 0.0, -1.2632593953955784, 0.0, -4.522057914047694, 0.0, 0.0, 0.0, 0.0, 0.0, -0.2544954595060478, -0.015971758374214717, -2.5498294307174256, -20.0, 0.0, -1.0931951311208365, -10.028578219837929, 0.0, -20.0, -13.57395546268648, 0.0, 0.0, -10.829592011395071, 0.0, 0.0, -55.727431645315285, -2.1954627504127213, -1.5168827465798849, -6.804240591309567, 0.0, -20.0, 0.0, -8.456369356449164, -31.466657103190524, 0.0, 0.0, -10.0, -16.41324358157677, -8.056315717929786, -44.40709919726022, -20.0, -30.618403551394792, 0.0, -0.8960535213731657, -26.214857809458465, -0.39027519188187365, -3.76165897610626, -10.0, 0.0, -20.028143595645272, -35.486238936006984, 0.0, 0.0, -2.1411240894598507, 0.0, 0.0, -2.2772843271548795, 0.0, -19.010441527265847, -0.20800889536564449, -0.6568581865500867, -20.0, 0.0, 0.0, -1.5915337722769174, -10.643990912035061, -20.37528020159064, -40.0, -8.573973699874449, 0.0, -10.370930108232505, 0.0, 0.0, 0.0, -20.0, -10.87145999018579, -2.260921134271695, 0.0, -22.881313292621694, -40.0, -12.759544361327059, 0.0, 0.0, -30.0, -40.0, -12.57740788477969, -1.1300680833338217, 0.0, 0.0, -50.0, 0.0, 0.0, -0.0609159123910985, 0.0, -16.132564922709097, 0.0, -0.2917869799934325, 0.0, -10.129356638392728, -10.0, 0.0, 0.0, 0.0, -13.954712764829111, -10.366427728815053, -23.591896854971694, 0.0, 0.0, 0.0, -0.0022839336014324196, 0.0, 0.0, -1.4019718426822114, 0.0, -10.0, 0.0, 0.0, 0.0, -10.447167916120968, -21.494368883022286, -44.59445527601539, -19.524939550495738, -20.647446991784143, -5.236010911117942, -21.186079131579675, -0.048032925092539314, -3.5706171788520225, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6428542929264475, "mean_inference_ms": 1.1027762213329453, "mean_action_processing_ms": 0.2319024043580931, "mean_env_wait_ms": 0.4809800557808955, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0041152959988441, "StateBufferConnector_ms": 0.0030439576984923563, "ViewRequirementAgentConnector_ms": 0.08658001452316473}, "num_episodes": 162, "episode_return_max": 100.0, "episode_return_min": -26.214857809458465, "episode_return_mean": 9.871696347166639}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2784000, "num_agent_steps_trained": 2784000, "num_env_steps_sampled": 696000, "num_env_steps_trained": 696000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 359.6089017929457, "num_env_steps_trained_throughput_per_sec": 359.6089017929457, "timesteps_total": 696000, "num_env_steps_sampled_lifetime": 696000, "num_agent_steps_sampled_lifetime": 2784000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2784000, "timers": {"training_iteration_time_ms": 11060.288, "restore_workers_time_ms": 0.016, "training_step_time_ms": 11060.241, "sample_time_ms": 1118.025, "learn_time_ms": 9929.458, "learn_throughput": 402.842, "synch_weights_time_ms": 12.367}, "counters": {"num_env_steps_sampled": 696000, "num_env_steps_trained": 696000, "num_agent_steps_sampled": 2784000, "num_agent_steps_trained": 2784000}, "done": false, "training_iteration": 174, "trial_id": "86f16_00000", "date": "2024-08-08_16-50-37", "timestamp": 1723150237, "time_this_iter_s": 11.138071060180664, "time_total_s": 2250.706365585327, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x309caddc0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 2250.706365585327, "iterations_since_restore": 174, "perf": {"cpu_util_percent": 36.0, "ram_util_percent": 83.2625}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.48754467308944, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.4968122511890762, "policy_loss": -0.018999368518818803, "vf_loss": 1.5150801566687035, "vf_explained_var": 3.183141667792138e-08, "kl": 0.007314596969503817, "entropy": 0.40117224205470253, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 492090.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.242308924222986, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.4220605300118527, "policy_loss": -0.03315018503041453, "vf_loss": 2.4534307912612956, "vf_explained_var": 0.12679707792898018, "kl": 0.008899699968645584, "entropy": 0.931290979248782, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 167520.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 700000, "num_env_steps_trained": 700000, "num_agent_steps_sampled": 2800000, "num_agent_steps_trained": 2800000}, "env_runners": {"episode_reward_max": 140.0, "episode_reward_min": -33.89916430288228, "episode_reward_mean": 12.488010681540665, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -70.0}, "policy_reward_max": {"adversary_policy": 70.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 7.469135802469136, "agent_policy": -9.919396725866742}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.0, -1.2258119064238682, 0.0, 16.00175273271971, 0.0, 40.0, -28.54156977210635, 0.0, 0.0, 0.0, 20.0, -2.43365337392465, -0.6695663455605738, -1.170155998424821, 0.0, 40.0, 20.0, 80.0, 0.0, 20.0, 0.0, 140.0, 60.0, 20.0, -1.0671417431641095, 39.99045988620589, 0.0, 0.0, 0.0, 0.0, 40.0, 59.386900195610835, -6.260044749454865, 20.0, 15.746481282032196, 0.0, 0.0, 0.0, 20.0, -1.0881095349123782, -5.945075752620489, 0.0, -15.647828105608989, 0.0, -5.913795060668818, 20.0, 100.0, 19.76287311722544, 20.0, 0.0, 40.0, 55.48231321394194, -3.9301964954359074, 100.0, 38.875894915943746, 20.0, -26.62835445047544, -1.8790959508370377, 40.0, -0.8683335522988445, 0.0, 58.405504100648244, -2.5719740350567815, 0.0, 0.0, -3.7389821719543987, -1.010050625319452, -0.19874795455712357, -1.5942757333729474, 20.0, 0.0, -6.985625826919795, -9.105579986962946, 19.037276076480556, 0.0, -5.963502549589841, 0.0, -0.5989645261002452, -0.6278954601503572, 0.0, 20.0, 10.785585871689234, 0.0, 37.883135012502365, 99.17368073070305, 99.37444641160639, 0.0, 0.0, 20.0, -0.882953502567837, 38.40953661832647, 0.0, 0.0, 0.0, 0.0, -11.050037161837876, 20.0, -4.5786356758657965, 0.0, 0.0, 0.0, 19.497793449411514, 0.0, -2.410218834880763, 28.075286706140318, -0.8191937253056669, 66.57239251597285, -2.007071458542181, 0.0, -6.8319541014897744, -33.89916430288228, 0.0, 0.0, 19.183917597583992, 0.0, 60.0, 56.543210153658414, -13.110932450231248, 0.0, -6.976245486062975, 0.0, 0.0, 20.0, 11.806121920020402, 14.281424594828847, -13.27594633782251, -3.49031839026878, 19.849944698191322, 60.0, -0.5849557494129498, 0.0, 0.0, -0.49775953920794036, -3.849428383688423, 57.717167122936026, 19.809416130740075, 0.0, 0.0, -17.633990301274782, 20.0, -7.429588478413338, 0.0, 49.96537147257231, -13.925828598131572, 0.0, -0.15409767150777687, 20.0, 0.0, 80.0, 0.0, 0.0, 20.0, 0.0, 34.54561557997573, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 0.0, -4.033119886784528], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-20.0, -1.2258119064238682, 0.0, -13.998247267280291, 0.0, -20.0, -28.54156977210635, 0.0, 0.0, 0.0, -10.0, -2.43365337392465, -0.6695663455605738, -1.170155998424821, 0.0, -20.0, -10.0, -40.0, 0.0, -10.0, 0.0, -70.0, -30.0, -10.0, -1.0671417431641095, -20.009540113794106, 0.0, 0.0, 0.0, 0.0, -20.0, -30.613099804389172, -6.260044749454865, -10.0, -14.253518717967808, 0.0, 0.0, 0.0, -10.0, -1.0881095349123782, -5.945075752620489, 0.0, -15.647828105608989, 0.0, -5.913795060668818, -10.0, -50.0, -10.237126882774561, -10.0, 0.0, -20.0, -34.51768678605806, -3.9301964954359074, -50.0, -21.124105084056254, -10.0, -26.62835445047544, -1.8790959508370377, -20.0, -0.8683335522988445, 0.0, -31.59449589935175, -2.5719740350567815, 0.0, 0.0, -3.7389821719543987, -1.010050625319452, -0.19874795455712357, -1.5942757333729474, -10.0, 0.0, -6.985625826919795, -9.105579986962946, -10.962723923519443, 0.0, -5.963502549589841, 0.0, -0.5989645261002452, -0.6278954601503572, 0.0, -10.0, -19.214414128310764, 0.0, -22.11686498749764, -50.826319269296945, -50.62555358839362, 0.0, 0.0, -10.0, -0.882953502567837, -51.59046338167353, 0.0, 0.0, 0.0, 0.0, -11.050037161837876, -10.0, -4.5786356758657965, 0.0, 0.0, 0.0, -10.502206550588488, 0.0, -2.410218834880763, -31.924713293859682, -0.8191937253056669, -53.42760748402714, -2.007071458542181, 0.0, -6.8319541014897744, -33.89916430288228, 0.0, 0.0, -10.816082402416008, 0.0, -30.0, -33.456789846341586, -13.110932450231248, 0.0, -6.976245486062975, 0.0, 0.0, -10.0, -18.193878079979598, -15.718575405171151, -13.27594633782251, -3.49031839026878, -10.150055301808678, -30.0, -0.5849557494129498, 0.0, 0.0, -0.49775953920794036, -3.849428383688423, -32.28283287706397, -10.190583869259925, 0.0, 0.0, -17.633990301274782, -10.0, -7.429588478413338, 0.0, -40.03462852742769, -13.925828598131572, 0.0, -0.15409767150777687, -10.0, 0.0, -40.0, 0.0, 0.0, -10.0, 0.0, -25.454384420024276, 0.0, 0.0, 0.0, 0.0, 0.0, -20.0, 0.0, -4.033119886784528]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6424188872858067, "mean_inference_ms": 1.1020766472888848, "mean_action_processing_ms": 0.23175842429960608, "mean_env_wait_ms": 0.48078319665078245, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004014041688707139, "StateBufferConnector_ms": 0.002932622108930423, "ViewRequirementAgentConnector_ms": 0.08205131248191551}, "num_episodes": 162, "episode_return_max": 140.0, "episode_return_min": -33.89916430288228, "episode_return_mean": 12.488010681540665}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2800000, "num_agent_steps_trained": 2800000, "num_env_steps_sampled": 700000, "num_env_steps_trained": 700000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 341.97370609298713, "num_env_steps_trained_throughput_per_sec": 341.97370609298713, "timesteps_total": 700000, "num_env_steps_sampled_lifetime": 700000, "num_agent_steps_sampled_lifetime": 2800000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2800000, "timers": {"training_iteration_time_ms": 11104.026, "restore_workers_time_ms": 0.016, "training_step_time_ms": 11103.979, "sample_time_ms": 1111.052, "learn_time_ms": 9979.873, "learn_throughput": 400.807, "synch_weights_time_ms": 12.664}, "counters": {"num_env_steps_sampled": 700000, "num_env_steps_trained": 700000, "num_agent_steps_sampled": 2800000, "num_agent_steps_trained": 2800000}, "done": false, "training_iteration": 175, "trial_id": "86f16_00000", "date": "2024-08-08_16-50-49", "timestamp": 1723150249, "time_this_iter_s": 11.728886842727661, "time_total_s": 2262.435252428055, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x309c5bdc0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 2262.435252428055, "iterations_since_restore": 175, "perf": {"cpu_util_percent": 38.95882352941176, "ram_util_percent": 83.21176470588236}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.43461787695368975, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.8341425939865992, "policy_loss": -0.01667343759620298, "vf_loss": 0.8501588356198994, "vf_explained_var": -4.521287079398514e-07, "kl": 0.00657195135271277, "entropy": 0.39547733132932206, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 494910.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.402825717876355, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.9633563291902343, "policy_loss": -0.03521200979448622, "vf_loss": 1.996592546875278, "vf_explained_var": 0.17197629231959582, "kl": 0.009878954912521021, "entropy": 0.9442666864022613, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 168480.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 704000, "num_env_steps_trained": 704000, "num_agent_steps_sampled": 2816000, "num_agent_steps_trained": 2816000}, "env_runners": {"episode_reward_max": 60.0, "episode_reward_min": -30.550348656123315, "episode_reward_mean": 5.911574788215199, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 153, "episodes_timesteps_total": 3825, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -40.149241481759795}, "policy_reward_max": {"adversary_policy": 30.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 4.052287581699346, "agent_policy": -6.245287956882842}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-17.154521690392578, 20.0, 39.38440737854188, 0.0, 0.0, -0.30688872744591644, 13.632957871416432, 0.0, 0.0, 0.0, -15.87440368820228, 0.0, 20.0, 0.0, 0.0, -1.3586116823779704, 0.0, 40.0, -0.06733671891370197, 0.0, -0.14194647498920077, -3.5723646597481933, 0.0, 60.0, 0.0, 0.0, -9.238965756189588, 0.0, 40.0, -2.0894137325548745, -0.6354955293514752, -0.028057135871885075, 60.0, 0.0, 40.0, 20.0, 0.0, -4.268549767873555, -1.341774389214786, -1.4345840104004481, -5.193978123455139, -0.4456182315327295, 60.0, -1.7603642428175637, -3.51588511628094, -0.7537499301629158, 40.0, 0.0, -0.09093965544671234, -11.30625216116307, 8.689427148918346, -0.5078569274031708, 0.0, 0.0, -17.688959755273455, -7.014633708301902, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 0.0, 0.0, 0.0, 0.0, -5.367007028574367, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.42495408180706074, -11.841166942352384, 0.0, -0.19624324524520897, 60.0, 19.9129827662764, 0.0, 0.0, 0.0, 57.74852021664677, 0.0, -8.192150472579147, 40.0, -4.820338275662688, 49.8507585182402, 0.0, -3.0783422167918806, 59.90731532794079, -13.172254746224555, -0.5747301060871091, 0.0, -5.432356582608956, 0.0, 0.0, 0.0, 59.71898638395389, 0.0, 0.0, 0.0, 0.0, 0.0, -8.795963596411307, 57.57934708580594, -30.550348656123315, -9.566385987038906, 0.0, -0.44322934122962954, -3.2861836860918454, -0.75528293128162, 0.0, 0.0, -10.412244412140536, 60.0, -1.093852413426586, -1.4195142693643992, 19.398972336502748, -1.1368455035933867, 0.0, -1.1099171438552091, -13.43939196145495, 60.0, 20.0, 40.0, 0.0, 0.0, -24.057439084700672, -0.2987863154365089, 0.0, 0.0, -8.363135595587574, 0.0, 0.0, -1.6961256479105302, 0.0, 0.0, -11.666589563821699, 38.52266924164182, -0.06104940697235661, 0.0, 40.0, 19.74331547183579, -3.2414379254537176, 0.0, 0.0, 10.665701804396472], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0], "policy_agent_policy_reward": [-17.154521690392578, -10.0, -20.615592621458127, 0.0, 0.0, -0.30688872744591644, -16.36704212858357, 0.0, 0.0, 0.0, -15.87440368820228, 0.0, -10.0, 0.0, 0.0, -1.3586116823779704, 0.0, -20.0, -0.06733671891370197, 0.0, -0.14194647498920077, -3.5723646597481933, 0.0, -30.0, 0.0, 0.0, -9.238965756189588, 0.0, -20.0, -2.0894137325548745, -0.6354955293514752, -0.028057135871885075, -30.0, 0.0, -20.0, -10.0, 0.0, -4.268549767873555, -1.341774389214786, -1.4345840104004481, -5.193978123455139, -0.4456182315327295, -30.0, -1.7603642428175637, -3.51588511628094, -0.7537499301629158, -20.0, 0.0, -0.09093965544671234, -11.30625216116307, -21.310572851081652, -0.5078569274031708, 0.0, 0.0, -17.688959755273455, -7.014633708301902, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -10.0, 0.0, 0.0, 0.0, 0.0, -5.367007028574367, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.42495408180706074, -11.841166942352384, 0.0, -0.19624324524520897, -30.0, -10.087017233723598, 0.0, 0.0, 0.0, -32.25147978335323, 0.0, -8.192150472579147, -20.0, -4.820338275662688, -40.149241481759795, 0.0, -3.0783422167918806, -30.092684672059207, -13.172254746224555, -0.5747301060871091, 0.0, -5.432356582608956, 0.0, 0.0, 0.0, -30.281013616046113, 0.0, 0.0, 0.0, 0.0, 0.0, -8.795963596411307, -32.420652914194065, -30.550348656123315, -9.566385987038906, 0.0, -0.44322934122962954, -3.2861836860918454, -0.75528293128162, 0.0, 0.0, -10.412244412140536, -30.0, -1.093852413426586, -1.4195142693643992, -10.60102766349725, -1.1368455035933867, 0.0, -1.1099171438552091, -13.43939196145495, -30.0, -10.0, -20.0, 0.0, 0.0, -24.057439084700672, -0.2987863154365089, 0.0, 0.0, -8.363135595587574, 0.0, 0.0, -1.6961256479105302, 0.0, 0.0, -11.666589563821699, -21.477330758358175, -0.06104940697235661, 0.0, -20.0, -10.256684528164211, -3.2414379254537176, 0.0, 0.0, -19.334298195603527]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6420846895688179, "mean_inference_ms": 1.1017461132339224, "mean_action_processing_ms": 0.23165407161593995, "mean_env_wait_ms": 0.4806701655934006, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004383161956188725, "StateBufferConnector_ms": 0.0031318539887471917, "ViewRequirementAgentConnector_ms": 0.08553835301617392}, "num_episodes": 153, "episode_return_max": 60.0, "episode_return_min": -30.550348656123315, "episode_return_mean": 5.911574788215199}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2816000, "num_agent_steps_trained": 2816000, "num_env_steps_sampled": 704000, "num_env_steps_trained": 704000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 355.2912815221392, "num_env_steps_trained_throughput_per_sec": 355.2912815221392, "timesteps_total": 704000, "num_env_steps_sampled_lifetime": 704000, "num_agent_steps_sampled_lifetime": 2816000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2816000, "timers": {"training_iteration_time_ms": 11120.435, "restore_workers_time_ms": 0.016, "training_step_time_ms": 11120.387, "sample_time_ms": 1112.531, "learn_time_ms": 9994.866, "learn_throughput": 400.205, "synch_weights_time_ms": 12.589}, "counters": {"num_env_steps_sampled": 704000, "num_env_steps_trained": 704000, "num_agent_steps_sampled": 2816000, "num_agent_steps_trained": 2816000}, "done": false, "training_iteration": 176, "trial_id": "86f16_00000", "date": "2024-08-08_16-51-00", "timestamp": 1723150260, "time_this_iter_s": 11.263808965682983, "time_total_s": 2273.699061393738, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad5f7e50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 2273.699061393738, "iterations_since_restore": 176, "perf": {"cpu_util_percent": 30.041176470588237, "ram_util_percent": 82.95882352941176}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.47212146308722225, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.3430305868387222, "policy_loss": -0.017840771510510157, "vf_loss": 1.3600768320949366, "vf_explained_var": 1.6317299917234597e-08, "kl": 0.007945246484431385, "entropy": 0.3873792643454058, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 497730.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.4215691396966577, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.2144166085248194, "policy_loss": -0.03505888938040395, "vf_loss": 2.247507189027965, "vf_explained_var": 0.10092714298516511, "kl": 0.00984153342132951, "entropy": 0.921858643181622, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 169440.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 708000, "num_env_steps_trained": 708000, "num_agent_steps_sampled": 2832000, "num_agent_steps_trained": 2832000}, "env_runners": {"episode_reward_max": 100.0, "episode_reward_min": -21.92214501147515, "episode_reward_mean": 11.664740197002322, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -50.264358637687884}, "policy_reward_max": {"adversary_policy": 50.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 6.790123456790123, "agent_policy": -8.705630173368046}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, -4.423548278633726, -0.21222032542974056, -0.20419819165235942, 0.0, -1.491293325673072, 20.0, -0.11739962186167019, 0.0, 40.0, -10.758499810406091, 0.0, 0.0, 20.0, 40.0, 0.0, 0.0, 0.0, -0.6263609782743595, 60.0, 20.0, 0.0, 0.0, 100.0, -16.472404462359577, -0.44390200149856396, -0.6665670145064528, -0.4634807094635207, 0.0, 0.0, 80.0, 40.0, -14.741009899722794, 0.0, 0.0, 0.0, 40.0, 19.92741462599651, 0.0, -11.19164228198792, 0.0, 0.0, -0.3230030842502185, 0.0, -1.3814340955020576, -0.35109107014638985, -7.854011650485619, 40.0, 13.727714126666992, 60.0, 0.0, 0.0, -11.286415767670588, 0.0, 0.0, 40.0, 20.0, 40.0, 0.0, -1.0442887450346683, 0.0, 0.0, 58.50709068965901, -0.8700525348219901, 58.20763193163039, 0.0, 0.0, -0.05739927806010292, 60.0, -3.6007902450107707, -8.627621736708297, -3.0668954442563434, 0.0, 20.0, 0.0, 0.0, 60.0, -1.5784720905516958, 19.748828205220804, 58.04807324935953, 0.0, -8.63888605977105, 34.83788230554164, 20.0, -4.448568189129165, 20.0, 0.0, -2.1877599403525316, -11.605039716720427, 0.0, -4.545767012339436, 0.0, 40.0, 0.0, -2.5739460576580884, 77.025949410221, 0.0, -5.513704613490118, 20.0, 0.0, 40.0, 0.0, 40.0, 0.0, 0.0, 20.0, 0.0, -7.102025458227922, 60.0, -21.92214501147515, -5.089672838948758, 100.0, 0.0, -1.571890562884385, -12.024471234234177, 0.0, 0.0, 19.78243565799177, 18.712465851412585, 0.0, 20.0, 0.0, 13.905285272040684, 0.0, 0.0, -2.687941856046213, -9.758892945458447, 0.0, 56.618470720466185, 0.0, 40.0, 40.0, 0.0, 0.0, 60.0, 40.0, 40.0, 0.0, 0.0, -4.936742193160731, 0.0, 0.0, 20.0, 60.0, 0.0, -5.542111010632712, 60.0, 99.73564136231212, -6.066230431505622, 0.0, -11.479620586658507, -5.278930462166028, -18.511217671849135, 36.58194977471726, 0.0, -0.9923470327190764, -13.81237105681191, 39.93698092033456, -2.3625577778545406, 0.0, -5.109059825131952], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [0.0, 0.0, -4.423548278633726, -0.21222032542974056, -0.20419819165235942, 0.0, -1.491293325673072, -10.0, -0.11739962186167019, 0.0, -20.0, -10.758499810406091, 0.0, 0.0, -10.0, -20.0, 0.0, 0.0, 0.0, -0.6263609782743595, -30.0, -10.0, 0.0, 0.0, -50.0, -16.472404462359577, -0.44390200149856396, -0.6665670145064528, -0.4634807094635207, 0.0, 0.0, -40.0, -20.0, -14.741009899722794, 0.0, 0.0, 0.0, -20.0, -10.072585374003491, 0.0, -11.19164228198792, 0.0, 0.0, -0.3230030842502185, 0.0, -1.3814340955020576, -0.35109107014638985, -7.854011650485619, -20.0, -16.27228587333301, -30.0, 0.0, 0.0, -11.286415767670588, 0.0, 0.0, -20.0, -10.0, -20.0, 0.0, -1.0442887450346683, 0.0, 0.0, -31.49290931034099, -0.8700525348219901, -31.792368068369605, 0.0, 0.0, -0.05739927806010292, -30.0, -3.6007902450107707, -8.627621736708297, -3.0668954442563434, 0.0, -10.0, 0.0, 0.0, -30.0, -1.5784720905516958, -10.251171794779196, -31.951926750640467, 0.0, -8.63888605977105, -25.162117694458356, -10.0, -4.448568189129165, -10.0, 0.0, -2.1877599403525316, -11.605039716720427, 0.0, -4.545767012339436, 0.0, -20.0, 0.0, -2.5739460576580884, -42.974050589779, 0.0, -5.513704613490118, -10.0, 0.0, -20.0, 0.0, -20.0, 0.0, 0.0, -10.0, 0.0, -7.102025458227922, -30.0, -21.92214501147515, -5.089672838948758, -50.0, 0.0, -1.571890562884385, -12.024471234234177, 0.0, 0.0, -10.217564342008231, -11.287534148587417, 0.0, -10.0, 0.0, -16.094714727959317, 0.0, 0.0, -2.687941856046213, -9.758892945458447, 0.0, -33.381529279533815, 0.0, -20.0, -20.0, 0.0, 0.0, -30.0, -20.0, -20.0, 0.0, 0.0, -4.936742193160731, 0.0, 0.0, -10.0, -30.0, 0.0, -5.542111010632712, -30.0, -50.264358637687884, -6.066230431505622, 0.0, -11.479620586658507, -5.278930462166028, -18.511217671849135, -23.418050225282744, 0.0, -0.9923470327190764, -13.81237105681191, -20.06301907966544, -2.3625577778545406, 0.0, -5.109059825131952]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6417494318028751, "mean_inference_ms": 1.1010514723982923, "mean_action_processing_ms": 0.23150767269072547, "mean_env_wait_ms": 0.48045045252003177, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004207793577217761, "StateBufferConnector_ms": 0.0029170218809151357, "ViewRequirementAgentConnector_ms": 0.08323818077275782}, "num_episodes": 162, "episode_return_max": 100.0, "episode_return_min": -21.92214501147515, "episode_return_mean": 11.664740197002322}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2832000, "num_agent_steps_trained": 2832000, "num_env_steps_sampled": 708000, "num_env_steps_trained": 708000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 356.324812486402, "num_env_steps_trained_throughput_per_sec": 356.324812486402, "timesteps_total": 708000, "num_env_steps_sampled_lifetime": 708000, "num_agent_steps_sampled_lifetime": 2832000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2832000, "timers": {"training_iteration_time_ms": 11161.995, "restore_workers_time_ms": 0.017, "training_step_time_ms": 11161.946, "sample_time_ms": 1111.407, "learn_time_ms": 10036.711, "learn_throughput": 398.537, "synch_weights_time_ms": 13.307}, "counters": {"num_env_steps_sampled": 708000, "num_env_steps_trained": 708000, "num_agent_steps_sampled": 2832000, "num_agent_steps_trained": 2832000}, "done": false, "training_iteration": 177, "trial_id": "86f16_00000", "date": "2024-08-08_16-51-11", "timestamp": 1723150271, "time_this_iter_s": 11.2501699924469, "time_total_s": 2284.9492313861847, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad5b10d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 2284.9492313861847, "iterations_since_restore": 177, "perf": {"cpu_util_percent": 29.39375, "ram_util_percent": 82.69999999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.45489396852381686, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.2573691062893428, "policy_loss": -0.018774391714948335, "vf_loss": 1.275284426728039, "vf_explained_var": -3.6749856691833927e-07, "kl": 0.008590708465970372, "entropy": 0.39051888552329217, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 500550.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.142265267049273, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.006529074907303, "policy_loss": -0.033705309013991304, "vf_loss": 2.0382684657971066, "vf_explained_var": 0.12249094415456056, "kl": 0.009829564985660458, "entropy": 0.9603511015574138, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 170400.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 712000, "num_env_steps_trained": 712000, "num_agent_steps_sampled": 2848000, "num_agent_steps_trained": 2848000}, "env_runners": {"episode_reward_max": 100.0, "episode_reward_min": -33.19752744574547, "episode_reward_mean": 8.79854143079941, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -50.0}, "policy_reward_max": {"adversary_policy": 50.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 5.37037037037037, "agent_policy": -7.3125696803117}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 60.0, -0.5994672468011086, 0.0, 59.45881644630826, 20.0, 20.0, -5.183318890839201, 0.0, 51.04319437949971, 0.0, 20.0, 0.0, -23.75774605212012, -3.4382195987577635, 100.0, 40.0, 0.0, -13.023369272660867, -0.0010359052763553311, 0.0, -7.422376110156207, 0.0, -0.07639486331376566, 36.059313073499325, 0.0, 0.0, -1.6455413515946815, 0.0, 0.0, -2.8971667539017867, 0.0, -16.53281962783428, 40.0, 20.0, 0.0, 40.0, 40.0, 0.0, -17.20278591694002, -0.8285087970301286, 20.0, -0.06752184380421133, -13.59821191889232, 40.0, -0.19639830140398273, -1.6909487469537077, -10.472185979199493, 40.0, 40.0, -0.7071565011823278, 0.0, 60.0, -0.6123222154211128, 0.0, -0.3372951335579255, 18.66252514495507, 0.0, 0.0, -0.127777283103232, 0.0, 0.0, 0.0, 59.96671855468642, 60.0, 0.0, 0.0, 0.0, -1.8110637292507636, 40.0, 0.0, -1.7284589613106716, -1.1486894850028873, 20.0, -1.3774710872844642, 20.0, 0.0, 0.0, 0.0, 0.0, 20.0, 0.0, -4.654635509790605, -0.13770245756903776, 0.0, 0.0, 0.0, 20.0, 39.51811584311009, 0.0, 33.41324906934755, 20.0, 0.0, -5.273854262945308, 80.0, 40.0, 0.0, 0.0, 0.0, 0.0, -0.7580934821322116, 20.0, 40.0, 0.0, -6.363156349259702, 20.0, -0.22508745126661345, -7.5923627068496575, 0.0, 0.0, 0.0, -0.36397019643501727, 0.0, 0.0, -33.19752744574547, 40.0, 58.8326991707666, -3.464915051289826, -7.30853962741607, 19.86280540712804, 0.0, 38.797581577921534, 0.0, 0.0, -0.8180736762973251, 0.0, 0.0, 0.0, 0.0, -1.5197298695572647, 0.0, 0.0, 0.0, 0.0, 0.0, -1.9405660120942825, 0.0, 20.0, 20.0, 19.90125572852748, -13.231934868987025, 0.0, -7.064898582794878, 0.0, 0.0, 0.0, 20.0, 0.0, 0.0, 0.0, -1.4854781302296316, 19.769256223579184, -1.2614963952233815, 18.76426822988457, 0.0, -29.685155297126588, 58.208020844717154, 40.0, 0.0, 14.589346597415075, 0.0, -8.652025555238051], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0], "policy_agent_policy_reward": [0.0, -30.0, -0.5994672468011086, 0.0, -30.541183553691738, -10.0, -10.0, -5.183318890839201, 0.0, -38.95680562050029, 0.0, -10.0, 0.0, -23.75774605212012, -3.4382195987577635, -50.0, -20.0, 0.0, -13.023369272660867, -0.0010359052763553311, 0.0, -7.422376110156207, 0.0, -0.07639486331376566, -23.940686926500675, 0.0, 0.0, -1.6455413515946815, 0.0, 0.0, -2.8971667539017867, 0.0, -16.53281962783428, -20.0, -10.0, 0.0, -20.0, -20.0, 0.0, -17.20278591694002, -0.8285087970301286, -10.0, -0.06752184380421133, -13.59821191889232, -20.0, -0.19639830140398273, -1.6909487469537077, -10.472185979199493, -20.0, -20.0, -0.7071565011823278, 0.0, -30.0, -0.6123222154211128, 0.0, -0.3372951335579255, -11.337474855044933, 0.0, 0.0, -0.127777283103232, 0.0, 0.0, 0.0, -30.03328144531358, -30.0, 0.0, 0.0, 0.0, -1.8110637292507636, -20.0, 0.0, -1.7284589613106716, -1.1486894850028873, -10.0, -1.3774710872844642, -10.0, 0.0, 0.0, 0.0, 0.0, -10.0, 0.0, -4.654635509790605, -0.13770245756903776, 0.0, 0.0, 0.0, -10.0, -20.48188415688991, 0.0, -26.58675093065245, -10.0, 0.0, -5.273854262945308, -40.0, -20.0, 0.0, 0.0, 0.0, 0.0, -0.7580934821322116, -10.0, -20.0, 0.0, -6.363156349259702, -10.0, -0.22508745126661345, -7.5923627068496575, 0.0, 0.0, 0.0, -0.36397019643501727, 0.0, 0.0, -33.19752744574547, -20.0, -31.167300829233394, -3.464915051289826, -7.30853962741607, -10.137194592871959, 0.0, -21.20241842207847, 0.0, 0.0, -0.8180736762973251, 0.0, 0.0, 0.0, 0.0, -1.5197298695572647, 0.0, 0.0, 0.0, 0.0, 0.0, -1.9405660120942825, 0.0, -10.0, -10.0, -10.098744271472523, -13.231934868987025, 0.0, -7.064898582794878, 0.0, 0.0, 0.0, -10.0, 0.0, 0.0, 0.0, -1.4854781302296316, -10.230743776420818, -1.2614963952233815, -11.23573177011543, 0.0, -29.685155297126588, -31.79197915528285, -20.0, 0.0, -15.410653402584925, 0.0, -38.65202555523804]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6417187633066769, "mean_inference_ms": 1.1007897952363448, "mean_action_processing_ms": 0.23140240817292088, "mean_env_wait_ms": 0.4804062559254568, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004212503080014829, "StateBufferConnector_ms": 0.0032075393347092617, "ViewRequirementAgentConnector_ms": 0.09124168643244991}, "num_episodes": 162, "episode_return_max": 100.0, "episode_return_min": -33.19752744574547, "episode_return_mean": 8.79854143079941}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2848000, "num_agent_steps_trained": 2848000, "num_env_steps_sampled": 712000, "num_env_steps_trained": 712000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 353.81012132344415, "num_env_steps_trained_throughput_per_sec": 353.81012132344415, "timesteps_total": 712000, "num_env_steps_sampled_lifetime": 712000, "num_agent_steps_sampled_lifetime": 2848000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2848000, "timers": {"training_iteration_time_ms": 11188.56, "restore_workers_time_ms": 0.017, "training_step_time_ms": 11188.511, "sample_time_ms": 1119.909, "learn_time_ms": 10054.756, "learn_throughput": 397.822, "synch_weights_time_ms": 13.38}, "counters": {"num_env_steps_sampled": 712000, "num_env_steps_trained": 712000, "num_agent_steps_sampled": 2848000, "num_agent_steps_trained": 2848000}, "done": false, "training_iteration": 178, "trial_id": "86f16_00000", "date": "2024-08-08_16-51-23", "timestamp": 1723150283, "time_this_iter_s": 11.310392141342163, "time_total_s": 2296.259623527527, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad5b13a0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 2296.259623527527, "iterations_since_restore": 178, "perf": {"cpu_util_percent": 29.0875, "ram_util_percent": 82.42500000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4600233828345089, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.2025613353607503, "policy_loss": -0.01851315626739161, "vf_loss": 1.2203198876998103, "vf_explained_var": -5.255354211685505e-07, "kl": 0.007546044370427991, "entropy": 0.3872067997430233, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 503370.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.1666932086149853, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.169292652172347, "policy_loss": -0.03639486514827392, "vf_loss": 2.2036512948572637, "vf_explained_var": 0.0695979910592238, "kl": 0.010181064264221057, "entropy": 0.9682937048375606, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 171360.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 716000, "num_env_steps_trained": 716000, "num_agent_steps_sampled": 2864000, "num_agent_steps_trained": 2864000}, "env_runners": {"episode_reward_max": 117.17973311463365, "episode_reward_min": -23.110898880423708, "episode_reward_mean": 9.120663360566034, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -62.82026688536635}, "policy_reward_max": {"adversary_policy": 60.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 5.432098765432099, "agent_policy": -7.175632935730262}, "custom_metrics": {}, "hist_stats": {"episode_reward": [100.0, 0.0, 0.0, 0.0, -1.9781801692964307, -0.21843844440372462, 0.0, 20.0, -3.385045901382435, 20.0, 0.0, 20.0, -0.07049270419944409, 20.0, 40.0, 0.0, 20.0, 60.0, 0.0, 20.0, 20.0, 40.0, 0.0, 0.0, 0.0, -6.598003866576793, 0.0, 20.0, 0.0, -1.1925185412495665, 0.0, -1.0368081102747984, 0.0, 79.23861642582985, 20.0, 40.0, -1.322799124819285, 0.0, 0.0, 0.0, -0.5625220517899132, 0.0, -0.07840408690864886, 27.279676870949675, -6.906115486389324, -1.9242201123841662, 117.17973311463365, 58.91636921574084, -4.49286430359356, 0.0, -8.026384284523727, 0.0, -3.392492282289597, -9.985788844892419, 77.99781524929311, -1.4063489465976753, 0.0, 0.0, 59.91311632413001, 11.334196587328933, -1.0839196647112481, 0.0, -7.484595559937427, 0.0, 0.0, -0.6935270769842317, 0.0, 4.870697678673814, 58.538605141487054, -5.787305605469508, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 0.0, 40.0, 19.403387802007533, 40.0, -1.5197630890164882, 0.0, -9.643198537170786, 39.03518575426765, -9.44621363329586, 80.0, 0.0, -0.28929444247432934, 0.0, -14.030633499105491, 0.0, 40.0, 40.0, -0.11104108713854921, 0.0, -11.1922920006426, 0.0, 0.0, 0.0, 0.0, -3.503289502478411, -0.19730479465239315, -17.85878883125283, -0.8680340225888394, 0.0, 0.0, 0.0, 0.0, 53.26458404275833, -5.311260212628556, 0.0, 0.0, 0.0, 40.0, 40.0, 20.0, 60.0, 0.0, -23.110898880423708, -1.7660490783742577, -7.885454904469794, -5.523373834280454, -2.2642068648004994, 0.0, 0.0, -0.9365369159487535, 0.0, 0.0, 0.0, 0.0, 16.701116587296067, -0.17300459749365005, 0.0, -8.670955120353298, 0.0, 20.0, 0.0, 0.0, -0.07796173274812412, 0.0, -3.811944237536693, -5.8970527608719765, 0.0, -19.67732584546948, 0.0, 0.0, 0.0, 0.0, 20.0, 40.0, 0.0, 18.717113462993137, -0.13024137586061246, 0.0, -1.6469950144122547, -0.15010733806917864, -0.7181718817290883, 19.195419358268946, 20.0, 0.0, 20.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0], "policy_agent_policy_reward": [-50.0, 0.0, 0.0, 0.0, -1.9781801692964307, -0.21843844440372462, 0.0, -10.0, -3.385045901382435, -10.0, 0.0, -10.0, -0.07049270419944409, -10.0, -20.0, 0.0, -10.0, -30.0, 0.0, -10.0, -10.0, -20.0, 0.0, 0.0, 0.0, -6.598003866576793, 0.0, -10.0, 0.0, -1.1925185412495665, 0.0, -1.0368081102747984, 0.0, -40.761383574170154, -10.0, -20.0, -1.322799124819285, 0.0, 0.0, 0.0, -0.5625220517899132, 0.0, -0.07840408690864886, -32.72032312905033, -6.906115486389324, -1.9242201123841662, -62.82026688536635, -31.083630784259157, -4.49286430359356, 0.0, -8.026384284523727, 0.0, -3.392492282289597, -9.985788844892419, -42.002184750706895, -1.4063489465976753, 0.0, 0.0, -30.086883675869995, -18.665803412671064, -1.0839196647112481, 0.0, -7.484595559937427, 0.0, 0.0, -0.6935270769842317, 0.0, -25.12930232132619, -31.461394858512946, -5.787305605469508, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -30.0, 0.0, -20.0, -10.596612197992467, -20.0, -1.5197630890164882, 0.0, -9.643198537170786, -20.964814245732356, -9.44621363329586, -40.0, 0.0, -0.28929444247432934, 0.0, -14.030633499105491, 0.0, -20.0, -20.0, -0.11104108713854921, 0.0, -11.1922920006426, 0.0, 0.0, 0.0, 0.0, -3.503289502478411, -0.19730479465239315, -17.85878883125283, -0.8680340225888394, 0.0, 0.0, 0.0, 0.0, -36.73541595724167, -5.311260212628556, 0.0, 0.0, 0.0, -20.0, -20.0, -10.0, -30.0, 0.0, -23.110898880423708, -1.7660490783742577, -7.885454904469794, -5.523373834280454, -2.2642068648004994, 0.0, 0.0, -0.9365369159487535, 0.0, 0.0, 0.0, 0.0, -13.298883412703933, -0.17300459749365005, 0.0, -8.670955120353298, 0.0, -10.0, 0.0, 0.0, -0.07796173274812412, 0.0, -3.811944237536693, -5.8970527608719765, 0.0, -19.67732584546948, 0.0, 0.0, 0.0, 0.0, -10.0, -20.0, 0.0, -11.282886537006865, -0.13024137586061246, 0.0, -1.6469950144122547, -0.15010733806917864, -0.7181718817290883, -10.804580641731057, -10.0, 0.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6413431433386853, "mean_inference_ms": 1.1001134808622375, "mean_action_processing_ms": 0.23124137963985192, "mean_env_wait_ms": 0.4801781777394395, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0042311939192406925, "StateBufferConnector_ms": 0.0029474128911524643, "ViewRequirementAgentConnector_ms": 0.08196433385213216}, "num_episodes": 162, "episode_return_max": 117.17973311463365, "episode_return_min": -23.110898880423708, "episode_return_mean": 9.120663360566034}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2864000, "num_agent_steps_trained": 2864000, "num_env_steps_sampled": 716000, "num_env_steps_trained": 716000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 342.9679855149458, "num_env_steps_trained_throughput_per_sec": 342.9679855149458, "timesteps_total": 716000, "num_env_steps_sampled_lifetime": 716000, "num_agent_steps_sampled_lifetime": 2864000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2864000, "timers": {"training_iteration_time_ms": 11244.541, "restore_workers_time_ms": 0.016, "training_step_time_ms": 11244.491, "sample_time_ms": 1119.065, "learn_time_ms": 10111.268, "learn_throughput": 395.598, "synch_weights_time_ms": 13.646}, "counters": {"num_env_steps_sampled": 716000, "num_env_steps_trained": 716000, "num_agent_steps_sampled": 2864000, "num_agent_steps_trained": 2864000}, "done": false, "training_iteration": 179, "trial_id": "86f16_00000", "date": "2024-08-08_16-51-35", "timestamp": 1723150295, "time_this_iter_s": 11.669617176055908, "time_total_s": 2307.9292407035828, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad5b18b0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 2307.9292407035828, "iterations_since_restore": 179, "perf": {"cpu_util_percent": 30.847058823529416, "ram_util_percent": 82.6470588235294}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4273671863349617, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.1006986167625332, "policy_loss": -0.0178064730797782, "vf_loss": 1.1177692818514844, "vf_explained_var": 1.1552521523008956e-06, "kl": 0.00735807707271235, "entropy": 0.38100512326820524, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 506190.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.3814703279485303, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.8841817297351857, "policy_loss": -0.03783325486147078, "vf_loss": 1.9199078417072692, "vf_explained_var": 0.17414188776165246, "kl": 0.010535707943389391, "entropy": 0.9782217708726724, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 172320.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 720000, "num_env_steps_trained": 720000, "num_agent_steps_sampled": 2880000, "num_agent_steps_trained": 2880000}, "env_runners": {"episode_reward_max": 120.0, "episode_reward_min": -26.799843932477565, "episode_reward_mean": 7.233003906724444, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 157, "episodes_timesteps_total": 3925, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -60.0}, "policy_reward_max": {"adversary_policy": 60.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 4.713375796178344, "agent_policy": -6.907123481810587}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, -1.9562426649878772, -4.942544820486578, 0.0, 0.0, 0.0, 0.0, 0.0, -3.9916214016915816, 0.0, 0.0, 0.0, -3.4505737708195094, -6.521059385735538, -13.37810307217347, -0.211432810392298, 16.868862437998555, 0.0, 19.603777638575064, 0.0, -2.0387497992670776, 0.0, 20.0, -3.9015289198126455, -0.2854342199376114, -11.034842376966347, 0.0, 0.0, -7.819337010235904, 20.0, -1.0121880125953986, 0.0, 0.0, 20.0, -26.799843932477565, -12.588505680220756, 40.0, 35.794756338856025, 0.0, 0.0, 0.0, 0.0, -0.08290218980286368, 10.81118419729063, 37.14602737680352, 0.0, -0.10256273282215234, 37.08946936965529, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, -0.5425350471745138, 20.0, 120.0, -5.652432158644909, -0.38766391860969307, 0.0, -6.4103003692494624, -0.34797613663260063, 0.0, -5.322861927466192, 0.0, 5.251790351114386, 57.15003606460601, -3.4863468100084702, -6.611192170063496, 0.0, 60.0, 0.0, -5.074590907477035, 0.0, -3.4092524986170503, 80.0, 0.0, 20.0, -0.11291416992162295, -25.99238670576825, 40.0, -15.121623102220594, -20.15506087583757, 18.743233065777275, 0.0, 0.0, 20.0, -1.5899836843304849, -0.170306669560788, 0.0, 0.0, 20.0, 32.93851742677599, 40.0, 40.0, 40.0, 0.0, 0.0, -7.102926076689004, -2.873971223658226, 0.0, -1.7739976231779997, 0.0, 0.0, 0.0, 0.0, -0.241530698400384, 0.0, -6.094998567428622, 0.0, 0.0, 0.0, 0.0, 39.4297525178605, 0.0, -21.177722637553185, 0.0, -11.574739955075103, -6.1581907372567946, 0.0, 20.0, 44.4243783230076, 18.306335118583945, 0.0, 0.0, -1.7437862090942358, -3.608724745073423, 60.0, 0.0, 0.0, 0.0, 0.0, 19.68848663335946, 40.0, 0.0, 40.0, 20.0, 0.0, -0.6440561228393404, 18.563627991851025, 59.380756888299274, 40.0, -1.1313810338905628, 0.0, -1.1280797338292436, -5.956208298518185, 0.0, 0.0, 0.0, -3.8941647701845987, 40.0, 0.0, 0.0, 0.0, 60.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0], "policy_agent_policy_reward": [0.0, 0.0, 0.0, -1.9562426649878772, -4.942544820486578, 0.0, 0.0, 0.0, 0.0, 0.0, -3.9916214016915816, 0.0, 0.0, 0.0, -3.4505737708195094, -6.521059385735538, -13.37810307217347, -0.211432810392298, -13.131137562001443, 0.0, -10.396222361424929, 0.0, -2.0387497992670776, 0.0, -10.0, -3.9015289198126455, -0.2854342199376114, -11.034842376966347, 0.0, 0.0, -7.819337010235904, -10.0, -1.0121880125953986, 0.0, 0.0, -10.0, -26.799843932477565, -12.588505680220756, -20.0, -24.205243661143975, 0.0, 0.0, 0.0, 0.0, -0.08290218980286368, -19.18881580270937, -22.85397262319647, 0.0, -0.10256273282215234, -22.910530630344706, 0.0, 0.0, 0.0, 0.0, 0.0, -10.0, -0.5425350471745138, -10.0, -60.0, -5.652432158644909, -0.38766391860969307, 0.0, -6.4103003692494624, -0.34797613663260063, 0.0, -5.322861927466192, 0.0, -24.748209648885613, -32.84996393539399, -3.4863468100084702, -6.611192170063496, 0.0, -30.0, 0.0, -5.074590907477035, 0.0, -3.4092524986170503, -40.0, 0.0, -10.0, -0.11291416992162295, -25.99238670576825, -20.0, -15.121623102220594, -20.15506087583757, -11.256766934222725, 0.0, 0.0, -10.0, -1.5899836843304849, -0.170306669560788, 0.0, 0.0, -10.0, -27.06148257322401, -20.0, -20.0, -20.0, 0.0, 0.0, -7.102926076689004, -2.873971223658226, 0.0, -1.7739976231779997, 0.0, 0.0, 0.0, 0.0, -0.241530698400384, 0.0, -6.094998567428622, 0.0, 0.0, 0.0, 0.0, -20.5702474821395, 0.0, -21.177722637553185, 0.0, -11.574739955075103, -6.1581907372567946, 0.0, -10.0, -45.575621676992405, -11.693664881416057, 0.0, 0.0, -1.7437862090942358, -3.608724745073423, -30.0, 0.0, 0.0, 0.0, 0.0, -10.31151336664054, -20.0, 0.0, -20.0, -10.0, 0.0, -0.6440561228393404, -11.436372008148975, -30.619243111700726, -20.0, -1.1313810338905628, 0.0, -1.1280797338292436, -5.956208298518185, 0.0, 0.0, 0.0, -3.8941647701845987, -20.0, 0.0, 0.0, 0.0, -30.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6412532504747109, "mean_inference_ms": 1.0999408350590707, "mean_action_processing_ms": 0.23126917886333406, "mean_env_wait_ms": 0.48015874540789416, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0038670886094403114, "StateBufferConnector_ms": 0.002921159100380673, "ViewRequirementAgentConnector_ms": 0.08327748365462966}, "num_episodes": 157, "episode_return_max": 120.0, "episode_return_min": -26.799843932477565, "episode_return_mean": 7.233003906724444}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2880000, "num_agent_steps_trained": 2880000, "num_env_steps_sampled": 720000, "num_env_steps_trained": 720000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 363.0690415033622, "num_env_steps_trained_throughput_per_sec": 363.0690415033622, "timesteps_total": 720000, "num_env_steps_sampled_lifetime": 720000, "num_agent_steps_sampled_lifetime": 2880000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2880000, "timers": {"training_iteration_time_ms": 11229.681, "restore_workers_time_ms": 0.016, "training_step_time_ms": 11229.631, "sample_time_ms": 1116.265, "learn_time_ms": 10099.229, "learn_throughput": 396.07, "synch_weights_time_ms": 13.626}, "counters": {"num_env_steps_sampled": 720000, "num_env_steps_trained": 720000, "num_agent_steps_sampled": 2880000, "num_agent_steps_trained": 2880000}, "done": false, "training_iteration": 180, "trial_id": "86f16_00000", "date": "2024-08-08_16-51-46", "timestamp": 1723150306, "time_this_iter_s": 11.022754669189453, "time_total_s": 2318.951995372772, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad5b1d30>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 2318.951995372772, "iterations_since_restore": 180, "perf": {"cpu_util_percent": 28.84375, "ram_util_percent": 82.45625000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4540701321834791, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.7012582815073907, "policy_loss": -0.01930055190051133, "vf_loss": 1.719710401905344, "vf_explained_var": 6.62266785371388e-07, "kl": 0.008484312397717369, "entropy": 0.37022667477528254, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 509010.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.282940741504232, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.5395031705498696, "policy_loss": -0.037670995742761684, "vf_loss": 2.575229634468754, "vf_explained_var": 0.06486738361418247, "kl": 0.009722676509336224, "entropy": 0.9526020373528202, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 173280.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 724000, "num_env_steps_trained": 724000, "num_agent_steps_sampled": 2896000, "num_agent_steps_trained": 2896000}, "env_runners": {"episode_reward_max": 140.0, "episode_reward_min": -32.18901015549289, "episode_reward_mean": 12.10978932473157, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 158, "episodes_timesteps_total": 3950, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -77.77260914676475}, "policy_reward_max": {"adversary_policy": 70.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 7.215189873417722, "agent_policy": -9.535780295521594}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.19201209833457855, 18.87071511746755, -9.098015661398875, 0.0, 59.139447531940135, 20.0, -0.6941160089816523, -18.790283741389352, 17.245645758056632, -0.5731335681579064, 0.0, 0.0, 20.0, 40.0, -0.9669889709789892, 40.0, -1.1774311926964809, -9.344820935176553, 0.0, -0.5689805287385064, 0.0, -24.46682818585183, 0.0, 0.0, 39.10643257874032, -2.9558872211492213, 0.0, -0.169673331861665, 0.0, -0.10559669762893575, 0.0, 20.0, 100.0, 0.0, 60.0, 0.0, 40.0, -4.958558443764697, -1.5144161676476686, 20.0, 0.0, 20.0, 0.0, 0.0, 7.964642747705163, 0.0, 0.0, 40.0, 60.0, 60.0, -6.09306875264458, -1.0700544520195021, -10.720162450089825, 20.0, -4.640475321315121, 19.684943584808355, 0.0, -0.3061276648086664, -1.3976977109918531, 60.0, 0.0, 20.0, 40.0, 20.0, -0.9079334406965489, 40.0, 0.0, 0.0, -0.5562844743087658, -1.9779199900377076, 0.0, 80.0, 120.0, -0.3308607367223326, 0.0, 0.0, 40.0, -5.540152551299153, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 54.405853154359164, -1.986135150420379, 40.0, 0.0, -1.0178755718601173, 0.0, -1.2817341730341547, 0.0, 0.0, 40.0, 20.0, 40.0, -0.2875916055351635, -3.894448459241073, -32.18901015549289, -12.531687299386553, 0.0, 0.0, -1.4229093433752982, 80.0, 0.0, 0.0, 0.0, 38.80863678983684, 20.0, -30.44157129200585, 0.0, 0.0, -5.107152896219295, 38.495627316998025, -9.003199556251523, 20.0, 18.90007539063871, -1.4290413779018563, 0.0, 40.0, 59.500992392738226, -28.86961433521596, -7.043405527315169, 60.0, -4.944868396756432, 0.0, 79.36879863103128, 0.0, -1.4894099120698179, 40.0, 132.22739085323522, 0.0, 0.0, -1.736308312221635, 80.0, -2.44912592205696, 0.0, 0.0, 20.0, -17.716377612921427, 0.0, -11.767088253095416, 20.0, 140.0, -1.250793147058079, 0.0, 0.0, -1.5600437904684605, 0.0, -0.5578327733689181, -5.252572330180564, 0.0, 0.0, 0.0, -16.0252110478234, 0.0, 0.0, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-0.19201209833457855, -11.129284882532449, -9.098015661398875, 0.0, -30.860552468059872, -10.0, -0.6941160089816523, -18.790283741389352, -12.754354241943366, -0.5731335681579064, 0.0, 0.0, -10.0, -20.0, -0.9669889709789892, -20.0, -1.1774311926964809, -9.344820935176553, 0.0, -0.5689805287385064, 0.0, -24.46682818585183, 0.0, 0.0, -20.893567421259682, -2.9558872211492213, 0.0, -0.169673331861665, 0.0, -0.10559669762893575, 0.0, -10.0, -50.0, 0.0, -30.0, 0.0, -20.0, -4.958558443764697, -1.5144161676476686, -10.0, 0.0, -10.0, 0.0, 0.0, -52.03535725229484, 0.0, 0.0, -20.0, -30.0, -30.0, -6.09306875264458, -1.0700544520195021, -10.720162450089825, -10.0, -4.640475321315121, -10.315056415191645, 0.0, -0.3061276648086664, -1.3976977109918531, -30.0, 0.0, -10.0, -20.0, -10.0, -0.9079334406965489, -20.0, 0.0, 0.0, -0.5562844743087658, -1.9779199900377076, 0.0, -40.0, -60.0, -0.3308607367223326, 0.0, 0.0, -20.0, -5.540152551299153, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -35.594146845640836, -1.986135150420379, -20.0, 0.0, -1.0178755718601173, 0.0, -1.2817341730341547, 0.0, 0.0, -20.0, -10.0, -20.0, -0.2875916055351635, -3.894448459241073, -32.18901015549289, -12.531687299386553, 0.0, 0.0, -1.4229093433752982, -40.0, 0.0, 0.0, 0.0, -21.191363210163164, -10.0, -30.44157129200585, 0.0, 0.0, -5.107152896219295, -21.504372683001975, -9.003199556251523, -10.0, -11.099924609361292, -1.4290413779018563, 0.0, -20.0, -30.499007607261767, -28.86961433521596, -7.043405527315169, -30.0, -4.944868396756432, 0.0, -40.63120136896872, 0.0, -1.4894099120698179, -20.0, -77.77260914676475, 0.0, 0.0, -1.736308312221635, -40.0, -2.44912592205696, 0.0, 0.0, -10.0, -17.716377612921427, 0.0, -11.767088253095416, -10.0, -70.0, -1.250793147058079, 0.0, 0.0, -1.5600437904684605, 0.0, -0.5578327733689181, -5.252572330180564, 0.0, 0.0, 0.0, -16.0252110478234, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6404115153612147, "mean_inference_ms": 1.0982613655005475, "mean_action_processing_ms": 0.23077045604566399, "mean_env_wait_ms": 0.4795415552380809, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00424015371105339, "StateBufferConnector_ms": 0.0031158139434041858, "ViewRequirementAgentConnector_ms": 0.08770914017399654}, "num_episodes": 158, "episode_return_max": 140.0, "episode_return_min": -32.18901015549289, "episode_return_mean": 12.10978932473157}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2896000, "num_agent_steps_trained": 2896000, "num_env_steps_sampled": 724000, "num_env_steps_trained": 724000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 320.7602798312062, "num_env_steps_trained_throughput_per_sec": 320.7602798312062, "timesteps_total": 724000, "num_env_steps_sampled_lifetime": 724000, "num_agent_steps_sampled_lifetime": 2896000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2896000, "timers": {"training_iteration_time_ms": 11384.547, "restore_workers_time_ms": 0.017, "training_step_time_ms": 11384.496, "sample_time_ms": 1117.891, "learn_time_ms": 10251.917, "learn_throughput": 390.171, "synch_weights_time_ms": 14.037}, "counters": {"num_env_steps_sampled": 724000, "num_env_steps_trained": 724000, "num_agent_steps_sampled": 2896000, "num_agent_steps_trained": 2896000}, "done": false, "training_iteration": 181, "trial_id": "86f16_00000", "date": "2024-08-08_16-51-59", "timestamp": 1723150319, "time_this_iter_s": 12.505683898925781, "time_total_s": 2331.457679271698, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad5f7d30>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 2331.457679271698, "iterations_since_restore": 181, "perf": {"cpu_util_percent": 40.0529411764706, "ram_util_percent": 82.71176470588236}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.38821799328141177, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.0108161179837605, "policy_loss": -0.015102805735257286, "vf_loss": 1.0252290189477569, "vf_explained_var": -2.0748334573515764e-06, "kl": 0.006899056647985137, "entropy": 0.3913312325874964, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 511830.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.260259368022283, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.9064997526506582, "policy_loss": -0.03491285709606018, "vf_loss": 1.939466224052012, "vf_explained_var": 0.11884761992841959, "kl": 0.00973191706082078, "entropy": 0.9492535037919879, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 174240.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 728000, "num_env_steps_trained": 728000, "num_agent_steps_sampled": 2912000, "num_agent_steps_trained": 2912000}, "env_runners": {"episode_reward_max": 198.91005852460756, "episode_reward_min": -19.80173044858132, "episode_reward_mean": 8.25977852209782, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -101.08994147539244}, "policy_reward_max": {"adversary_policy": 100.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 5.061728395061729, "agent_policy": -6.925406663087366}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-9.557053486134054, 0.0, 0.0, 20.0, -0.02278694696482786, 15.481259949283645, -0.023649253824796768, -12.014284411644809, -0.4538771535387309, 0.0, 0.0, 0.0, 0.0, 0.0, 58.64076303909488, 0.0, 0.0, 18.528917223828245, 0.0, 0.0, 0.0, -14.868758199930355, -19.80173044858132, 0.0, 0.0, 0.0, 0.0, 20.0, -5.366675550315615, -11.989110726490654, 0.0, 0.0, 0.0, -0.13380143182300963, 0.0, 0.0, 0.0, 0.0, 100.0, 0.0, 60.0, 36.947641061228246, 0.0, -13.663552395628571, -2.9679355600083586, 0.0, 20.0, 20.0, 0.0, 39.69911627557969, 0.0, 60.0, 0.0, 0.0, 0.0, 20.0, 0.0, -2.875196178746713, 0.0, -8.653230958412037, 0.0, 40.0, 20.0, 0.0, 40.0, 0.0, 60.0, 20.0, -9.789523462751623, 40.0, 0.0, -0.35416133380184456, 0.0, -6.668850509415893, 0.0, 39.58929005812907, -14.164101270620964, -8.752998331627037, 0.0, 0.0, 0.0, 0.0, 198.91005852460756, 0.0, 0.0, -0.5229428585111762, 60.0, 38.07538567137355, -4.750861301534625, 0.0, -1.3509664549607259, 0.0, 0.0, -8.46848484665694, 20.0, 0.0, 0.0, 0.0, 60.0, 0.0, 0.0, 0.0, 20.0, 0.0, -0.024741936949005394, 0.0, -13.828404137717186, -4.856004684298314, -13.456199529398347, 19.943273217939115, 11.973672414942415, 0.0, -0.3563006288896797, -1.103487304298747, 20.0, 0.0, 0.0, -18.100551438517076, 60.0, 0.0, 0.0, 0.0, 40.0, 0.0, -0.22622459165541176, 0.0, 18.970020210349187, 0.0, 0.0, -10.733571342507483, -2.149626414079603, -1.5204263605148538, 0.0, 77.29088683476981, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, -5.079122981083121, 0.0, 36.32833605111953, -1.1735536754669762, 0.0, 0.0, 0.0, -15.57484585980842, 0.0, 0.0, 0.0, 0.0, 40.0, 0.0, 39.90898277184729, -9.041960767059878, -0.012894233125856358, 58.83747787656533, 0.0, 0.0, -4.5761695785464855, 7.987657935030198], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 100.0, 100.0, 100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0], "policy_agent_policy_reward": [-9.557053486134054, 0.0, 0.0, -10.0, -0.02278694696482786, -14.518740050716357, -0.023649253824796768, -12.014284411644809, -0.4538771535387309, 0.0, 0.0, 0.0, 0.0, 0.0, -31.359236960905115, 0.0, 0.0, -11.471082776171755, 0.0, 0.0, 0.0, -14.868758199930355, -19.80173044858132, 0.0, 0.0, 0.0, 0.0, -10.0, -5.366675550315615, -11.989110726490654, 0.0, 0.0, 0.0, -0.13380143182300963, 0.0, 0.0, 0.0, 0.0, -50.0, 0.0, -30.0, -23.052358938771757, 0.0, -13.663552395628571, -2.9679355600083586, 0.0, -10.0, -10.0, 0.0, -20.30088372442031, 0.0, -30.0, 0.0, 0.0, 0.0, -10.0, 0.0, -2.875196178746713, 0.0, -8.653230958412037, 0.0, -20.0, -10.0, 0.0, -20.0, 0.0, -30.0, -10.0, -9.789523462751623, -20.0, 0.0, -0.35416133380184456, 0.0, -6.668850509415893, 0.0, -20.41070994187093, -14.164101270620964, -8.752998331627037, 0.0, 0.0, 0.0, 0.0, -101.08994147539244, 0.0, 0.0, -0.5229428585111762, -30.0, -21.924614328626447, -4.750861301534625, 0.0, -1.3509664549607259, 0.0, 0.0, -8.46848484665694, -10.0, 0.0, 0.0, 0.0, -30.0, 0.0, 0.0, 0.0, -10.0, 0.0, -0.024741936949005394, 0.0, -13.828404137717186, -4.856004684298314, -13.456199529398347, -10.056726782060887, -18.026327585057587, 0.0, -0.3563006288896797, -1.103487304298747, -10.0, 0.0, 0.0, -18.100551438517076, -30.0, 0.0, 0.0, 0.0, -20.0, 0.0, -0.22622459165541176, 0.0, -11.029979789650813, 0.0, 0.0, -10.733571342507483, -2.149626414079603, -1.5204263605148538, 0.0, -42.70911316523019, -10.0, 0.0, 0.0, 0.0, 0.0, 0.0, -5.079122981083121, 0.0, -23.67166394888047, -1.1735536754669762, 0.0, 0.0, 0.0, -15.57484585980842, 0.0, 0.0, 0.0, 0.0, -20.0, 0.0, -20.091017228152708, -9.041960767059878, -0.012894233125856358, -31.162522123434673, 0.0, 0.0, -4.5761695785464855, -22.0123420649698]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6407312034905367, "mean_inference_ms": 1.0987149893322412, "mean_action_processing_ms": 0.23089223038967993, "mean_env_wait_ms": 0.4797452835442292, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006887059152862172, "StateBufferConnector_ms": 0.0032289528552396796, "ViewRequirementAgentConnector_ms": 0.09139400941354257}, "num_episodes": 162, "episode_return_max": 198.91005852460756, "episode_return_min": -19.80173044858132, "episode_return_mean": 8.25977852209782}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2912000, "num_agent_steps_trained": 2912000, "num_env_steps_sampled": 728000, "num_env_steps_trained": 728000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 358.2057940413019, "num_env_steps_trained_throughput_per_sec": 358.2057940413019, "timesteps_total": 728000, "num_env_steps_sampled_lifetime": 728000, "num_agent_steps_sampled_lifetime": 2912000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2912000, "timers": {"training_iteration_time_ms": 11418.118, "restore_workers_time_ms": 0.017, "training_step_time_ms": 11418.066, "sample_time_ms": 1126.594, "learn_time_ms": 10276.672, "learn_throughput": 389.231, "synch_weights_time_ms": 14.131}, "counters": {"num_env_steps_sampled": 728000, "num_env_steps_trained": 728000, "num_agent_steps_sampled": 2912000, "num_agent_steps_trained": 2912000}, "done": false, "training_iteration": 182, "trial_id": "86f16_00000", "date": "2024-08-08_16-52-10", "timestamp": 1723150330, "time_this_iter_s": 11.173679113388062, "time_total_s": 2342.631358385086, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad5aeca0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 2342.631358385086, "iterations_since_restore": 182, "perf": {"cpu_util_percent": 29.17058823529412, "ram_util_percent": 82.31176470588235}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4437426136793397, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.1150961776785817, "policy_loss": -0.018372550962929588, "vf_loss": 1.1326832150102508, "vf_explained_var": 3.2685327191724843e-07, "kl": 0.007855108160379277, "entropy": 0.38558360393165697, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 514650.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.556802141790589, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.0914842608074347, "policy_loss": -0.03410724624118302, "vf_loss": 2.1238844615717727, "vf_explained_var": 0.0771917026489973, "kl": 0.008535190557049535, "entropy": 0.9659218110144139, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 175200.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 732000, "num_env_steps_trained": 732000, "num_agent_steps_sampled": 2928000, "num_agent_steps_trained": 2928000}, "env_runners": {"episode_reward_max": 82.12467681038383, "episode_reward_min": -20.39471409382588, "episode_reward_mean": 8.664152711729434, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -67.87532318961617}, "policy_reward_max": {"adversary_policy": 50.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 5.308641975308642, "agent_policy": -7.2617732141964915}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-11.531189842016914, -20.39471409382588, 60.0, -16.304569164095422, 80.0, -1.1433355127418887, 0.0, -0.4732430363380902, -0.352614417174123, 20.0, 0.0, 60.0, -10.267429974787737, 0.0, -3.898811260239113, 0.0, 0.0, 0.0, -2.985016005130221, 20.0, 20.0, -5.32793774842577, 0.0, 0.0, 0.0, -1.5583480903995206, 0.0, -1.3463960847254974, -8.300686913905329, 0.0, 20.0, -0.28069057898389427, 18.939113332135207, -0.6628408094672333, -3.5806941812872797, -6.750888893801238, 82.12467681038383, -8.061666634600158, 0.0, 0.0, -10.334503450977639, 0.0, -3.8165828565283837, 20.0, 0.0, -0.9562946436121655, -3.7183048655115045, 0.0, 78.99503704101589, 0.0, -1.63218316913462, -6.55326314363063, 0.0, -4.343202573951812, 40.0, -5.262378953212314, 0.0, 0.0, 0.0, -5.857943360373097, -1.9749061078573205, -0.09199659683773231, 0.0, -1.0411927904629137, 0.0, 18.575469517149564, 0.0, -1.2757654165993337, -6.981161793288332, 59.69006281390904, 78.2193402170732, -4.396127185822048, 0.0, 20.0, 0.0, -11.608851697414417, 0.0, 0.0, 0.0, -0.5525446455997929, 0.0, 0.0, -6.784986793298236, 0.0, 0.0, -2.538394485454443, 0.0, -6.262062808177389, 0.0, 60.0, 0.0, 59.9606811449936, 0.0, 0.0, 0.0, 0.0, 60.0, 80.0, -7.6662578433079185, 0.0, 0.0, 59.11439964516664, -8.815824351578055, 0.0, -7.863975222395302, -0.3115304339716285, 40.0, 0.0, 37.020172593108455, 0.0, 60.0, 60.0, -1.81778243870518, -5.474539387315767, 0.0, -6.607044100515989, 0.0, 60.0, 0.0, 0.0, 0.0, 0.0, 12.319260221513396, 60.0, 0.0, 0.0, 20.0, 0.0, -6.2043817588411905, 0.0, 0.0, 0.0, -1.661905828346043, -1.097140425759714, 0.0, 0.0, 56.65504109168796, 0.0, 40.0, 80.0, 0.0, -0.5266252333074151, 0.0, 0.0, -3.251165079869856, 0.0, -5.594739077989626, 0.0, -0.1991672888538798, -11.224684691531948, 0.0, -0.332786921744993, 0.0, 0.0, -0.014299920587651505, 20.0, 39.86348346811566, -5.253644559599623, -10.969509321768877, 56.42782547310277, -0.22109960350668367, 20.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0], "policy_agent_policy_reward": [-11.531189842016914, -20.39471409382588, -30.0, -16.304569164095422, -40.0, -1.1433355127418887, 0.0, -0.4732430363380902, -0.352614417174123, -10.0, 0.0, -30.0, -10.267429974787737, 0.0, -3.898811260239113, 0.0, 0.0, 0.0, -2.985016005130221, -10.0, -10.0, -5.32793774842577, 0.0, 0.0, 0.0, -1.5583480903995206, 0.0, -1.3463960847254974, -8.300686913905329, 0.0, -10.0, -0.28069057898389427, -11.060886667864793, -0.6628408094672333, -3.5806941812872797, -6.750888893801238, -67.87532318961617, -8.061666634600158, 0.0, 0.0, -10.334503450977639, 0.0, -3.8165828565283837, -10.0, 0.0, -0.9562946436121655, -3.7183048655115045, 0.0, -41.00496295898411, 0.0, -1.63218316913462, -6.55326314363063, 0.0, -4.343202573951812, -20.0, -5.262378953212314, 0.0, 0.0, 0.0, -5.857943360373097, -1.9749061078573205, -0.09199659683773231, 0.0, -1.0411927904629137, 0.0, -11.424530482850438, 0.0, -1.2757654165993337, -6.981161793288332, -30.309937186090963, -41.780659782926804, -4.396127185822048, 0.0, -10.0, 0.0, -11.608851697414417, 0.0, 0.0, 0.0, -0.5525446455997929, 0.0, 0.0, -6.784986793298236, 0.0, 0.0, -2.538394485454443, 0.0, -6.262062808177389, 0.0, -30.0, 0.0, -30.039318855006396, 0.0, 0.0, 0.0, 0.0, -30.0, -40.0, -7.6662578433079185, 0.0, 0.0, -30.885600354833358, -8.815824351578055, 0.0, -7.863975222395302, -0.3115304339716285, -20.0, 0.0, -22.979827406891545, 0.0, -30.0, -30.0, -1.81778243870518, -5.474539387315767, 0.0, -6.607044100515989, 0.0, -30.0, 0.0, 0.0, 0.0, 0.0, -17.680739778486604, -30.0, 0.0, 0.0, -10.0, 0.0, -6.2043817588411905, 0.0, 0.0, 0.0, -1.661905828346043, -1.097140425759714, 0.0, 0.0, -33.344958908312044, 0.0, -20.0, -40.0, 0.0, -0.5266252333074151, 0.0, 0.0, -3.251165079869856, 0.0, -5.594739077989626, 0.0, -0.1991672888538798, -11.224684691531948, 0.0, -0.332786921744993, 0.0, 0.0, -0.014299920587651505, -10.0, -20.13651653188434, -5.253644559599623, -10.969509321768877, -33.57217452689723, -0.22109960350668367, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6403863364426128, "mean_inference_ms": 1.0981265960800488, "mean_action_processing_ms": 0.23076284870627858, "mean_env_wait_ms": 0.4795421460296724, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003898953214103793, "StateBufferConnector_ms": 0.0030304914639319902, "ViewRequirementAgentConnector_ms": 0.0820495464183666}, "num_episodes": 162, "episode_return_max": 82.12467681038383, "episode_return_min": -20.39471409382588, "episode_return_mean": 8.664152711729434}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2928000, "num_agent_steps_trained": 2928000, "num_env_steps_sampled": 732000, "num_env_steps_trained": 732000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 360.8808476781283, "num_env_steps_trained_throughput_per_sec": 360.8808476781283, "timesteps_total": 732000, "num_env_steps_sampled_lifetime": 732000, "num_agent_steps_sampled_lifetime": 2928000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2928000, "timers": {"training_iteration_time_ms": 11401.089, "restore_workers_time_ms": 0.017, "training_step_time_ms": 11401.037, "sample_time_ms": 1118.217, "learn_time_ms": 10268.111, "learn_throughput": 389.556, "synch_weights_time_ms": 14.003}, "counters": {"num_env_steps_sampled": 732000, "num_env_steps_trained": 732000, "num_agent_steps_sampled": 2928000, "num_agent_steps_trained": 2928000}, "done": false, "training_iteration": 183, "trial_id": "86f16_00000", "date": "2024-08-08_16-52-21", "timestamp": 1723150341, "time_this_iter_s": 11.088590860366821, "time_total_s": 2353.719949245453, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad5aeee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 2353.719949245453, "iterations_since_restore": 183, "perf": {"cpu_util_percent": 29.462500000000002, "ram_util_percent": 82.15625}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4850039578234473, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.4013384916258196, "policy_loss": -0.0197574145469405, "vf_loss": 1.420332816052944, "vf_explained_var": -1.6127072327525904e-07, "kl": 0.007630906451399089, "entropy": 0.37659742748695063, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 517470.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.3697749648243187, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.340724043175578, "policy_loss": -0.03204288305326675, "vf_loss": 2.371077020590504, "vf_explained_var": 0.17333962650348742, "kl": 0.008449505785782943, "entropy": 0.9595037216320634, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 176160.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 736000, "num_env_steps_trained": 736000, "num_agent_steps_sampled": 2944000, "num_agent_steps_trained": 2944000}, "env_runners": {"episode_reward_max": 79.62294587968361, "episode_reward_min": -33.93929237982021, "episode_reward_mean": 8.640625882860123, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 157, "episodes_timesteps_total": 3925, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -49.07808898123372}, "policy_reward_max": {"adversary_policy": 40.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 5.6687898089171975, "agent_policy": -8.365743543891469}, "custom_metrics": {}, "hist_stats": {"episode_reward": [20.0, 75.3018272636462, -9.001968277262867, 0.0, 38.053098409104756, 74.07176290008508, 40.0, 0.0, 19.5824964205412, 0.0, -3.2201481901166455, 37.93165526872272, 40.0, 16.76745381975348, 20.0, 40.0, -4.2011401567108955, 60.0, -16.43961917493019, -33.93929237982021, -0.7834762339766566, 19.976262686977655, 0.0, 12.342682363552214, -4.089066122158821, -0.8587455929024057, 0.0, 19.466029568280657, 0.0, 0.0, 0.0, 40.0, 20.0, 0.0, 40.0, 18.785612205241094, 28.641822695388257, 35.51242024639102, 34.82668803177948, 70.92191101876631, 17.802935461764587, 0.0, 18.30457663920004, 40.0, 20.0, 0.0, 0.0, -6.379747061403183, 0.0, 27.360768838801626, 0.0, -2.042474435364141, -12.080681321167939, 40.0, 60.0, 0.0, -13.005356541168165, 0.0, -11.555094703232658, 15.996138850968954, -3.5536397319380733, 20.0, 0.0, 0.0, 60.0, 20.0, 17.10612040084749, 0.0, -0.020987836120605063, -7.789194691268133, -5.41712984191689, 20.0, 0.0, 0.0, 0.0, -0.19887189019439533, 0.0, 0.0, -9.978091619929105, 0.0, 0.0, -0.03134747765448198, -5.969816471318867, 20.0, -2.790240742206035, 0.0, 0.0, 20.0, 0.0, 0.0, 0.0, 79.62294587968361, 0.0, 0.0, -5.093203400593978, 13.384164399141586, 20.0, -12.092776600369108, 19.27329465573898, -0.7800207710737916, 0.0, 40.0, -0.2840723608120099, 0.0, -1.5569454248857006, 40.0, -0.03840174468818014, -5.309950719837208, 0.0, -0.3245417211861634, 0.0, 0.0, 0.0, -3.735386471907062, -9.411417747743371, 0.0, 20.0, 20.0, 0.0, 0.0, 0.0, 71.58749793886825, -0.48092592561361225, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.035419732853648744, 0.0, 40.0, -12.10336553592959, 0.0, 29.115254845899212, 0.0, 0.0, 0.0, -12.324855938000361, 0.0, -11.471314733966656, -9.561897572307819, -0.12099175474597046, -1.1045412028978763, -3.03630631382884, 0.0, -1.8917067381368247, -6.320992571043102, 0.0, 0.0, 0.0, 0.0, 0.0, -24.731991724922796], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-10.0, -44.698172736353804, -9.001968277262867, 0.0, -21.946901590895234, -45.92823709991492, -20.0, 0.0, -40.4175035794588, 0.0, -3.2201481901166455, -22.068344731277275, -20.0, -13.232546180246523, -10.0, -20.0, -4.2011401567108955, -30.0, -16.43961917493019, -33.93929237982021, -0.7834762339766566, -10.023737313022345, 0.0, -17.657317636447786, -4.089066122158821, -0.8587455929024057, 0.0, -10.533970431719343, 0.0, 0.0, 0.0, -20.0, -10.0, 0.0, -20.0, -11.214387794758903, -31.358177304611743, -24.487579753608987, -25.173311968220524, -49.07808898123372, -12.197064538235415, 0.0, -11.69542336079996, -20.0, -10.0, 0.0, 0.0, -6.379747061403183, 0.0, -32.639231161198374, 0.0, -2.042474435364141, -12.080681321167939, -20.0, -30.0, 0.0, -13.005356541168165, 0.0, -11.555094703232658, -14.003861149031046, -3.5536397319380733, -10.0, 0.0, 0.0, -30.0, -10.0, -12.893879599152509, 0.0, -0.020987836120605063, -7.789194691268133, -5.41712984191689, -10.0, 0.0, 0.0, 0.0, -0.19887189019439533, 0.0, 0.0, -9.978091619929105, 0.0, 0.0, -0.03134747765448198, -5.969816471318867, -10.0, -2.790240742206035, 0.0, 0.0, -10.0, 0.0, 0.0, 0.0, -40.377054120316394, 0.0, 0.0, -5.093203400593978, -16.615835600858414, -10.0, -12.092776600369108, -10.726705344261019, -0.7800207710737916, 0.0, -20.0, -0.2840723608120099, 0.0, -1.5569454248857006, -20.0, -0.03840174468818014, -35.3099507198372, 0.0, -0.3245417211861634, 0.0, 0.0, 0.0, -3.735386471907062, -9.411417747743371, 0.0, -10.0, -10.0, 0.0, 0.0, 0.0, -48.41250206113175, -0.48092592561361225, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.035419732853648744, 0.0, -20.0, -12.10336553592959, 0.0, -30.884745154100788, 0.0, 0.0, 0.0, -12.324855938000361, 0.0, -11.471314733966656, -9.561897572307819, -0.12099175474597046, -1.1045412028978763, -3.03630631382884, 0.0, -1.8917067381368247, -6.320992571043102, 0.0, 0.0, 0.0, 0.0, 0.0, -24.731991724922796]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6403348097048659, "mean_inference_ms": 1.0981646226824637, "mean_action_processing_ms": 0.2308140355069024, "mean_env_wait_ms": 0.47956931569860667, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004119781931494451, "StateBufferConnector_ms": 0.0030813703111782194, "ViewRequirementAgentConnector_ms": 0.08563646085702689}, "num_episodes": 157, "episode_return_max": 79.62294587968361, "episode_return_min": -33.93929237982021, "episode_return_mean": 8.640625882860123}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2944000, "num_agent_steps_trained": 2944000, "num_env_steps_sampled": 736000, "num_env_steps_trained": 736000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 361.4155355064704, "num_env_steps_trained_throughput_per_sec": 361.4155355064704, "timesteps_total": 736000, "num_env_steps_sampled_lifetime": 736000, "num_agent_steps_sampled_lifetime": 2944000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2944000, "timers": {"training_iteration_time_ms": 11395.527, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11395.488, "sample_time_ms": 1109.135, "learn_time_ms": 10272.582, "learn_throughput": 389.386, "synch_weights_time_ms": 13.142}, "counters": {"num_env_steps_sampled": 736000, "num_env_steps_trained": 736000, "num_agent_steps_sampled": 2944000, "num_agent_steps_trained": 2944000}, "done": false, "training_iteration": 184, "trial_id": "86f16_00000", "date": "2024-08-08_16-52-33", "timestamp": 1723150353, "time_this_iter_s": 11.074227809906006, "time_total_s": 2364.794177055359, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad3ff160>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 2364.794177055359, "iterations_since_restore": 184, "perf": {"cpu_util_percent": 28.15625, "ram_util_percent": 81.98124999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.48861787779428434, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.4404155798203557, "policy_loss": -0.020476430174746017, "vf_loss": 1.4599863327881124, "vf_explained_var": -1.5057570545385915e-07, "kl": 0.009056757411821525, "entropy": 0.3893900507413749, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 520290.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.3766781112800044, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.240187622047961, "policy_loss": -0.040278718902845866, "vf_loss": 2.278104926397403, "vf_explained_var": 0.10704564911623796, "kl": 0.011807070022456423, "entropy": 0.9770859487354755, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 177120.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 740000, "num_env_steps_trained": 740000, "num_agent_steps_sampled": 2960000, "num_agent_steps_trained": 2960000}, "env_runners": {"episode_reward_max": 99.64022045957795, "episode_reward_min": -25.949649282849574, "episode_reward_mean": 9.678456083081059, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -50.35977954042205}, "policy_reward_max": {"adversary_policy": 50.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 5.864197530864198, "agent_policy": -7.9141365095115335}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, -1.0465599847168483, -0.7951163325551103, -2.3192323043798453, 0.0, 0.0, 0.0, -2.5081218617850256, -6.701567534176932, 0.0, 0.0, 33.73610946282286, 40.0, 52.54795546950037, 0.0, 80.0, -1.5380471649099658, 20.0, 0.0, 55.2696559328331, 0.0, 20.0, 0.0, 15.80831909799253, 40.0, 0.0, 0.0, 0.0, 0.0, -0.9807212262937548, -0.8839167596483111, 0.0, 20.0, 0.0, -7.648811110290691, 60.0, 0.0, 40.0, 0.0, -0.20789428790906506, -0.06096211067341151, -3.0225426099766386, -5.631462589714926, 59.90605877490151, -1.557406337613484, 80.0, 20.0, 20.0, 0.0, -4.937458913008587, 40.0, 0.0, 0.0, 20.0, -1.1579574036443219, 20.0, 0.0, 0.0, -7.909598679119931, 0.0, 0.0, 40.0, 0.0, 20.0, -16.004520798933537, 39.49905527212124, 0.0, 0.0, -7.384589949580095, 20.0, 0.0, 99.64022045957795, 40.0, 0.0, 0.0, 0.0, 0.0, 20.0, -3.2260889637801116, 0.0, 40.0, -25.949649282849574, 16.02319352417637, -3.103511024187622, 0.0, 16.71726854339231, 0.0, 18.05010804449754, 0.0, 80.0, 0.0, 0.0, -1.2733503683974212, -3.84071825697603, 60.0, 0.0, 0.0, -15.98971642510062, 0.0, 0.0, 0.0, -0.12616033320703268, 0.0, 0.0, 80.0, 0.0, 19.87998585173251, 0.0, -13.402814150098312, -7.976750505881875, -0.9446482142106383, 80.0, 0.0, 0.0, 0.0, -18.332047998607372, 0.0, 0.0, 20.0, 60.0, -9.434730602943958, 0.0, -0.03627338762841048, -4.479743689829517, -12.916761569830516, -2.716551721377641, 0.0, 0.0, 40.0, 0.0, -1.7175294376481465, -1.0083931482530517, 0.0, 0.0, 0.0, -8.151308238719704, 4.839107978796301, 0.0, 80.0, 0.0, 79.95470962805504, -2.4528430526786096, 0.0, -4.700662147621117, 0.0, 60.0, 6.638158810621057, 0.0, 0.0, 0.0, 0.0, 0.0, -1.8148248914713843, -19.378953612342784, 0.0, 40.0, -2.004006241597547, -2.1705061740753395, -10.943380646588889, 0.0, 0.0, -0.21160934705544698], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [0.0, -1.0465599847168483, -0.7951163325551103, -2.3192323043798453, 0.0, 0.0, 0.0, -2.5081218617850256, -6.701567534176932, 0.0, 0.0, -26.263890537177144, -20.0, -37.45204453049963, 0.0, -40.0, -1.5380471649099658, -10.0, 0.0, -34.7303440671669, 0.0, -10.0, 0.0, -14.191680902007471, -20.0, 0.0, 0.0, 0.0, 0.0, -0.9807212262937548, -0.8839167596483111, 0.0, -10.0, 0.0, -7.648811110290691, -30.0, 0.0, -20.0, 0.0, -0.20789428790906506, -0.06096211067341151, -3.0225426099766386, -5.631462589714926, -30.09394122509849, -1.557406337613484, -40.0, -10.0, -10.0, 0.0, -4.937458913008587, -20.0, 0.0, 0.0, -10.0, -1.1579574036443219, -10.0, 0.0, 0.0, -7.909598679119931, 0.0, 0.0, -20.0, 0.0, -10.0, -16.004520798933537, -20.500944727878757, 0.0, 0.0, -7.384589949580095, -10.0, 0.0, -50.35977954042205, -20.0, 0.0, 0.0, 0.0, 0.0, -10.0, -3.2260889637801116, 0.0, -20.0, -25.949649282849574, -13.976806475823631, -3.103511024187622, 0.0, -13.282731456607692, 0.0, -11.949891955502455, 0.0, -40.0, 0.0, 0.0, -1.2733503683974212, -3.84071825697603, -30.0, 0.0, 0.0, -15.98971642510062, 0.0, 0.0, 0.0, -0.12616033320703268, 0.0, 0.0, -40.0, 0.0, -10.120014148267488, 0.0, -13.402814150098312, -7.976750505881875, -0.9446482142106383, -40.0, 0.0, 0.0, 0.0, -18.332047998607372, 0.0, 0.0, -10.0, -30.0, -9.434730602943958, 0.0, -0.03627338762841048, -4.479743689829517, -12.916761569830516, -2.716551721377641, 0.0, 0.0, -20.0, 0.0, -1.7175294376481465, -1.0083931482530517, 0.0, 0.0, 0.0, -8.151308238719704, -25.1608920212037, 0.0, -40.0, 0.0, -40.04529037194496, -2.4528430526786096, 0.0, -4.700662147621117, 0.0, -30.0, -23.361841189378943, 0.0, 0.0, 0.0, 0.0, 0.0, -31.81482489147139, -19.378953612342784, 0.0, -20.0, -2.004006241597547, -2.1705061740753395, -10.943380646588889, 0.0, 0.0, -0.21160934705544698]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6396451111782028, "mean_inference_ms": 1.0969451084171773, "mean_action_processing_ms": 0.23048386531220907, "mean_env_wait_ms": 0.4791355905821923, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0039657692850371936, "StateBufferConnector_ms": 0.002977730315408589, "ViewRequirementAgentConnector_ms": 0.08018524558455856}, "num_episodes": 162, "episode_return_max": 99.64022045957795, "episode_return_min": -25.949649282849574, "episode_return_mean": 9.678456083081059}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2960000, "num_agent_steps_trained": 2960000, "num_env_steps_sampled": 740000, "num_env_steps_trained": 740000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 350.45971734974063, "num_env_steps_trained_throughput_per_sec": 350.45971734974063, "timesteps_total": 740000, "num_env_steps_sampled_lifetime": 740000, "num_agent_steps_sampled_lifetime": 2960000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2960000, "timers": {"training_iteration_time_ms": 11367.205, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11367.165, "sample_time_ms": 1114.556, "learn_time_ms": 10239.315, "learn_throughput": 390.651, "synch_weights_time_ms": 12.664}, "counters": {"num_env_steps_sampled": 740000, "num_env_steps_trained": 740000, "num_agent_steps_sampled": 2960000, "num_agent_steps_trained": 2960000}, "done": false, "training_iteration": 185, "trial_id": "86f16_00000", "date": "2024-08-08_16-52-44", "timestamp": 1723150364, "time_this_iter_s": 11.418550968170166, "time_total_s": 2376.212728023529, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad3ff550>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 2376.212728023529, "iterations_since_restore": 185, "perf": {"cpu_util_percent": 30.06875, "ram_util_percent": 81.875}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4038266456560463, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.0898411649444424, "policy_loss": -0.015835434215635404, "vf_loss": 1.1048962026675966, "vf_explained_var": 5.81039604565776e-08, "kl": 0.007803950805067688, "entropy": 0.38847402371201956, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 523110.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.1614685262863835, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.8949486445635557, "policy_loss": -0.033871073281867815, "vf_loss": 1.9268406001850962, "vf_explained_var": 0.07633267429967722, "kl": 0.009895620767563193, "entropy": 0.9749144069229563, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 178080.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 744000, "num_env_steps_trained": 744000, "num_agent_steps_sampled": 2976000, "num_agent_steps_trained": 2976000}, "env_runners": {"episode_reward_max": 140.0, "episode_reward_min": -27.42885302457378, "episode_reward_mean": 8.959784936416522, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 158, "episodes_timesteps_total": 3950, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -74.9626186544034}, "policy_reward_max": {"adversary_policy": 70.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 5.443037974683544, "agent_policy": -7.369328987634112}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 13.538023759927134, 40.0, -0.07538593348157097, 0.0, 0.0, 0.0, 0.0, 0.0, 39.034262423935516, 0.0, 0.0, 0.0, -1.9652585853278048, 0.0, 37.29825182631998, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.791393058249393, 0.0, -0.950012181798352, 0.0, 0.0, 0.0, 105.0373813455966, 0.0, -4.001391886332328, 20.0, 0.0, 39.105016355299696, 0.0, -2.972353387035947, 20.0, -2.2574155900405186, 0.0, 0.0, 90.88229922499747, -1.6685239537551366, 0.0, -16.347429463958452, 0.0, -12.710966560610197, 0.0, 0.0, 40.0, -0.2933695345719656, 0.0, 0.0, 13.247553397065424, 140.0, -1.4567981445817535, 0.0, 0.0, -1.580140102956732, 0.0, 0.0, -20.2265892876843, -0.06361686191383664, 0.0, 20.0, 20.0, -2.464077192741846, -2.0126175230008316, -3.030523723614076, 14.384334947528956, 20.0, -20.476502569497026, -0.6948630690263946, -21.228030528201636, 80.0, -0.3080226889018778, 20.0, -17.488458349080023, 0.0, -1.0016897238692202, 12.327695568560296, -0.31730446803995394, 0.0, 20.0, 40.0, 0.0, 0.0, 0.0, 20.0, 40.0, 0.0, 0.0, 0.0, 40.0, 77.74608994435346, 0.0, -0.31796939007177394, 0.0, -4.166625796503323, 0.0, 39.70690925890739, -1.7159402981065508, 16.83120774157774, 40.0, 0.0, 0.0, -4.207847343917663, -17.072022831921963, 40.0, 0.0, -4.5851245029398555, -6.474629901778347, 0.0, 0.0, 0.0, 100.0, 0.0, 20.0, 0.0, 37.943017299420305, 0.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, -0.1095279033793417, 0.0, 0.0, 0.0, 0.0, -3.7020908785428865, 59.61178041886255, -27.42885302457378, 38.47341049602642, 0.0, 0.0, -3.0083402067844496, 0.0, -0.2472491325915016, 63.045381794794174, 38.68409327713347, -1.6580512534997172, 20.0, 0.0, -7.349212082287728, 0.0, 0.0, 0.0, -1.7960769223746265, 59.97160671104845], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0], "policy_agent_policy_reward": [0.0, -16.461976240072868, -20.0, -0.07538593348157097, 0.0, 0.0, 0.0, 0.0, 0.0, -20.965737576064488, 0.0, 0.0, 0.0, -1.9652585853278048, 0.0, -22.701748173680027, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.791393058249393, 0.0, -0.950012181798352, 0.0, 0.0, 0.0, -74.9626186544034, 0.0, -4.001391886332328, -10.0, 0.0, -20.8949836447003, 0.0, -2.972353387035947, -10.0, -2.2574155900405186, 0.0, 0.0, -59.11770077500254, -1.6685239537551366, 0.0, -16.347429463958452, 0.0, -12.710966560610197, 0.0, 0.0, -20.0, -0.2933695345719656, 0.0, 0.0, -16.752446602934572, -70.0, -1.4567981445817535, 0.0, 0.0, -1.580140102956732, 0.0, 0.0, -20.2265892876843, -0.06361686191383664, 0.0, -10.0, -10.0, -2.464077192741846, -2.0126175230008316, -3.030523723614076, -15.615665052471044, -10.0, -20.476502569497026, -0.6948630690263946, -21.228030528201636, -40.0, -0.3080226889018778, -10.0, -17.488458349080023, 0.0, -1.0016897238692202, -17.6723044314397, -0.31730446803995394, 0.0, -10.0, -20.0, 0.0, 0.0, 0.0, -10.0, -20.0, 0.0, 0.0, 0.0, -20.0, -42.25391005564654, 0.0, -0.31796939007177394, 0.0, -4.166625796503323, 0.0, -20.293090741092612, -1.7159402981065508, -13.168792258422261, -20.0, 0.0, 0.0, -4.207847343917663, -17.072022831921963, -20.0, 0.0, -4.5851245029398555, -6.474629901778347, 0.0, 0.0, 0.0, -50.0, 0.0, -10.0, 0.0, -22.056982700579695, 0.0, -10.0, -10.0, 0.0, 0.0, 0.0, 0.0, -0.1095279033793417, 0.0, 0.0, 0.0, 0.0, -3.7020908785428865, -30.388219581137445, -27.42885302457378, -21.52658950397358, 0.0, 0.0, -3.0083402067844496, 0.0, -0.2472491325915016, -56.95461820520582, -21.315906722866533, -1.6580512534997172, -10.0, 0.0, -7.349212082287728, 0.0, 0.0, 0.0, -1.7960769223746265, -30.02839328895154]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6390435084753934, "mean_inference_ms": 1.0958388344773904, "mean_action_processing_ms": 0.2301775503354471, "mean_env_wait_ms": 0.47873157549785694, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003985060921198205, "StateBufferConnector_ms": 0.0030229363260389883, "ViewRequirementAgentConnector_ms": 0.08455877062640613}, "num_episodes": 158, "episode_return_max": 140.0, "episode_return_min": -27.42885302457378, "episode_return_mean": 8.959784936416522}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2976000, "num_agent_steps_trained": 2976000, "num_env_steps_sampled": 744000, "num_env_steps_trained": 744000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 361.0333153905722, "num_env_steps_trained_throughput_per_sec": 361.0333153905722, "timesteps_total": 744000, "num_env_steps_sampled_lifetime": 744000, "num_agent_steps_sampled_lifetime": 2976000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2976000, "timers": {"training_iteration_time_ms": 11349.299, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11349.26, "sample_time_ms": 1109.856, "learn_time_ms": 10225.841, "learn_throughput": 391.166, "synch_weights_time_ms": 12.972}, "counters": {"num_env_steps_sampled": 744000, "num_env_steps_trained": 744000, "num_agent_steps_sampled": 2976000, "num_agent_steps_trained": 2976000}, "done": false, "training_iteration": 186, "trial_id": "86f16_00000", "date": "2024-08-08_16-52-56", "timestamp": 1723150376, "time_this_iter_s": 11.085139989852905, "time_total_s": 2387.297868013382, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad3ff940>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 2387.297868013382, "iterations_since_restore": 186, "perf": {"cpu_util_percent": 28.54375, "ram_util_percent": 81.83125000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4977732832391634, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.7565325134823508, "policy_loss": -0.02161506930053344, "vf_loss": 1.7772606382555995, "vf_explained_var": -2.0493852331283245e-07, "kl": 0.008869404284414502, "entropy": 0.4319428338121015, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 525930.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.1887487817555664, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.246688775283595, "policy_loss": -0.03517234224321631, "vf_loss": 2.2801532968878746, "vf_explained_var": 0.04885760756830374, "kl": 0.008539064578690424, "entropy": 0.9810968248794476, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 179040.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 748000, "num_env_steps_trained": 748000, "num_agent_steps_sampled": 2992000, "num_agent_steps_trained": 2992000}, "env_runners": {"episode_reward_max": 140.0, "episode_reward_min": -28.571485828564697, "episode_reward_mean": 12.58047867333258, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -70.0}, "policy_reward_max": {"adversary_policy": 70.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 7.037037037037037, "agent_policy": -8.53063243777853}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-4.4396014680685765, 60.0, 20.0, 0.0, 0.0, 0.0, -1.4836851175951016, 0.0, 0.0, -1.435190725527592, 35.27878358146432, 40.0, -8.955422853389482, 0.0, 0.0, 79.9591829517915, -17.97106145424609, 0.0, 0.0, 0.0, -1.0236130679428213, 0.0, 20.0, 60.0, -0.9978507820613958, 16.41473933765043, 60.0, 12.82632318390582, 140.0, 0.0, 0.0, 0.0, 0.0, 80.0, 40.0, 0.0, 0.0, 12.694425678716222, 0.0, 0.0, -3.0539365931033178, 0.0, 0.0, 0.0, -1.801792939765755, 0.0, 40.0, 0.0, -1.6862802296773705, 26.873667909359853, 0.0, 17.097455417631668, 0.0, 60.0, -2.4511453707708055, 18.483337952428645, -4.35808191045588, 80.0, 0.0, 0.0, -3.790316872304567, 40.0, 0.0, -1.776760827384185, 140.0, 0.0, 20.0, 0.0, -8.000857437066408, 0.0, 0.0, 20.0, 0.0, 0.0, 0.0, 40.0, 0.0, 60.0, -4.318664054459087, 0.0, -0.46106458717950716, 0.0, 0.0, -0.43797715443187446, -1.5505102315393093, 100.0, 0.0, 100.0, 39.391871642942114, 0.0, 0.0, -0.5921922152503722, 0.0, 20.0, 13.169622186797845, 0.0, 0.0, 20.0, -28.571485828564697, -13.391866694413418, 0.0, -0.6956296017831787, 33.60587294190027, 40.0, -1.727896729611027, 0.0, -10.529478832690124, -0.22915735715528407, -7.051436733873612, 0.0, 0.0, 20.0, 40.0, 0.0, -2.1866182625964408, 0.0, 40.0, -5.429631012593476, 0.0, 0.0, 0.0, 0.0, 0.0, -0.6765149683091298, 0.0, 20.0, 20.0, -5.420640405086063, 0.0, -0.6177552063344016, 19.956366408836033, 0.0, 0.0, 0.0, 20.0, -4.028361660467224, 40.0, 0.0, 0.0, -0.1714356400812067, 60.0, 0.0, -2.48444218563043, 0.0, 99.82449877819174, 0.0, 18.68410606767419, 17.117181417034637, 20.0, 13.346469398381064, 0.0, 20.0, 0.0, -6.16553249053964, 59.26974920617495, -6.140378277797633, 0.0, 0.0, 0.0, 50.14815879874331, 20.0, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-4.4396014680685765, -30.0, -10.0, 0.0, 0.0, 0.0, -1.4836851175951016, 0.0, 0.0, -1.435190725527592, -24.721216418535683, -20.0, -8.955422853389482, 0.0, 0.0, -40.040817048208496, -17.97106145424609, 0.0, 0.0, 0.0, -1.0236130679428213, 0.0, -10.0, -30.0, -0.9978507820613958, -13.585260662349569, -30.0, -17.17367681609418, -70.0, 0.0, 0.0, 0.0, 0.0, -40.0, -20.0, 0.0, 0.0, -17.30557432128378, 0.0, 0.0, -3.0539365931033178, 0.0, 0.0, 0.0, -1.801792939765755, 0.0, -20.0, 0.0, -1.6862802296773705, -33.12633209064015, 0.0, -12.90254458236833, 0.0, -30.0, -2.4511453707708055, -11.516662047571355, -4.35808191045588, -40.0, 0.0, 0.0, -3.790316872304567, -20.0, 0.0, -1.776760827384185, -70.0, 0.0, -10.0, 0.0, -8.000857437066408, 0.0, 0.0, -10.0, 0.0, 0.0, 0.0, -20.0, 0.0, -30.0, -4.318664054459087, 0.0, -0.46106458717950716, 0.0, 0.0, -0.43797715443187446, -1.5505102315393093, -50.0, 0.0, -50.0, -20.608128357057886, 0.0, 0.0, -0.5921922152503722, 0.0, -10.0, -16.830377813202155, 0.0, 0.0, -10.0, -28.571485828564697, -13.391866694413418, 0.0, -0.6956296017831787, -26.394127058099727, -20.0, -1.727896729611027, 0.0, -10.529478832690124, -0.22915735715528407, -7.051436733873612, 0.0, 0.0, -10.0, -20.0, 0.0, -2.1866182625964408, 0.0, -20.0, -5.429631012593476, 0.0, 0.0, 0.0, 0.0, 0.0, -0.6765149683091298, 0.0, -10.0, -10.0, -5.420640405086063, 0.0, -0.6177552063344016, -10.04363359116397, 0.0, 0.0, 0.0, -10.0, -4.028361660467224, -20.0, 0.0, 0.0, -0.1714356400812067, -30.0, 0.0, -2.48444218563043, 0.0, -50.17550122180826, 0.0, -11.31589393232581, -12.882818582965355, -10.0, -16.653530601618936, 0.0, -10.0, 0.0, -6.16553249053964, -30.73025079382505, -6.140378277797633, 0.0, 0.0, 0.0, -39.85184120125669, -10.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6389850008372522, "mean_inference_ms": 1.0958162417811286, "mean_action_processing_ms": 0.23021889322387915, "mean_env_wait_ms": 0.4787551162401805, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004145171907212999, "StateBufferConnector_ms": 0.0029672811060775946, "ViewRequirementAgentConnector_ms": 0.08358852362927095}, "num_episodes": 162, "episode_return_max": 140.0, "episode_return_min": -28.571485828564697, "episode_return_mean": 12.58047867333258}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2992000, "num_agent_steps_trained": 2992000, "num_env_steps_sampled": 748000, "num_env_steps_trained": 748000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 359.4062882501578, "num_env_steps_trained_throughput_per_sec": 359.4062882501578, "timesteps_total": 748000, "num_env_steps_sampled_lifetime": 748000, "num_agent_steps_sampled_lifetime": 2992000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2992000, "timers": {"training_iteration_time_ms": 11339.674, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11339.636, "sample_time_ms": 1111.571, "learn_time_ms": 10215.369, "learn_throughput": 391.567, "synch_weights_time_ms": 12.222}, "counters": {"num_env_steps_sampled": 748000, "num_env_steps_trained": 748000, "num_agent_steps_sampled": 2992000, "num_agent_steps_trained": 2992000}, "done": false, "training_iteration": 187, "trial_id": "86f16_00000", "date": "2024-08-08_16-53-07", "timestamp": 1723150387, "time_this_iter_s": 11.136169910430908, "time_total_s": 2398.434037923813, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad3ffd30>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 2398.434037923813, "iterations_since_restore": 187, "perf": {"cpu_util_percent": 28.7375, "ram_util_percent": 81.8625}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.436950994235404, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.1478054122087804, "policy_loss": -0.017731756575864652, "vf_loss": 1.1647735666510062, "vf_explained_var": -3.206814434511442e-07, "kl": 0.007636038712618191, "entropy": 0.39365420748367375, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 528750.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.1466467527051765, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.882744639739394, "policy_loss": -0.03289703726719987, "vf_loss": 1.9139212315902114, "vf_explained_var": 0.0879344193264842, "kl": 0.008602220114790041, "entropy": 0.9984853735193611, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 180000.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 752000, "num_env_steps_trained": 752000, "num_agent_steps_sampled": 3008000, "num_agent_steps_trained": 3008000}, "env_runners": {"episode_reward_max": 140.0, "episode_reward_min": -27.707205518544495, "episode_reward_mean": 10.796552398660333, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 157, "episodes_timesteps_total": 3925, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -70.0}, "policy_reward_max": {"adversary_policy": 70.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 6.369426751592357, "agent_policy": -8.311727856116738}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, -0.6855449678194103, 0.0, 50.40343994086063, -3.693044280688641, 0.0, -0.27141315387575804, 60.0, 0.0, 0.0, -7.97617035556476, -0.4813192879796735, 0.0, -5.639376452008282, -1.3310967369615134, -11.061705438023186, 0.0, 0.0, 100.0, 0.0, -0.49563238909568597, 15.745850640029053, 0.0, 0.0, -0.7742332302073796, 20.0, 0.0, -3.0827386498694773, 40.0, 0.0, 0.0, -1.1345396192974877, 0.0, 20.0, 66.50364558315175, 40.0, 0.0, -0.6992264709957907, 20.0, 0.0, 40.0, -0.03969292595298213, 0.0, 60.0, 0.0, 40.0, -4.125571904791182, 20.0, 0.0, -0.9598516339489926, 40.0, 0.0, 0.0, 20.0, 95.2381511863127, 89.16168131197351, -2.0592186654787854, -4.653025275403905, 0.0, 0.0, 0.0, 40.0, 0.0, 0.0, -13.748252830073902, -0.6638484540730949, 0.0, 38.44278639605794, 19.409453312328246, 0.0, 0.0, 0.0, -1.096278511998956, 0.0, 57.14933069407606, 37.43850258395818, 20.0, 0.0, 80.0, -7.54570089696286, 80.0, 0.0, 0.0, 140.0, 20.0, 16.944647141949527, 0.0, 0.0, -3.611606623099224, 0.0, 40.0, 0.0, -8.009186990471534, 20.0, 60.0, 0.0, 0.0, 40.0, 0.0, 60.0, 0.0, 0.0, -4.02285285366181, 0.0, 0.0, 40.0, 0.0, 0.0, 40.0, 0.0, 0.0, 0.0, 0.0, -11.915317920594264, -13.463673841355948, 20.0, 0.0, 20.0, 12.85468929507999, 0.0, 0.0, -0.3138312548686828, 0.0, 20.0, 14.36846718758298, -0.0473997298388229, 0.0, 0.0, -1.8299412742579435, 40.0, 0.0, 15.957886635695541, 0.0, 0.0, 19.957537843642502, 13.751024328551203, -3.651223502102935, -27.707205518544495, -6.63899482861505, 0.0, 20.0, 0.0, -1.385857069377583, -16.980340278870912, 0.0, 0.0, 0.0, 0.0, 20.0, -18.1113455958023, 0.0, -7.052222158798643, -4.348492016973193, -1.212972862218723, -4.647743364503192, -1.1006776765506254, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [0.0, -0.6855449678194103, 0.0, -39.596560059139364, -3.693044280688641, 0.0, -0.27141315387575804, -30.0, 0.0, 0.0, -7.97617035556476, -0.4813192879796735, 0.0, -5.639376452008282, -1.3310967369615134, -11.061705438023186, 0.0, 0.0, -50.0, 0.0, -0.49563238909568597, -14.254149359970947, 0.0, 0.0, -0.7742332302073796, -10.0, 0.0, -3.0827386498694773, -20.0, 0.0, 0.0, -1.1345396192974877, 0.0, -10.0, -53.49635441684822, -20.0, 0.0, -0.6992264709957907, -10.0, 0.0, -20.0, -0.03969292595298213, 0.0, -30.0, 0.0, -20.0, -4.125571904791182, -10.0, 0.0, -0.9598516339489926, -20.0, 0.0, 0.0, -10.0, -54.761848813687294, -60.83831868802649, -2.0592186654787854, -4.653025275403905, 0.0, 0.0, 0.0, -20.0, 0.0, 0.0, -13.748252830073902, -0.6638484540730949, 0.0, -21.557213603942063, -10.590546687671754, 0.0, 0.0, 0.0, -1.096278511998956, 0.0, -32.85066930592394, -22.561497416041814, -10.0, 0.0, -40.0, -37.54570089696287, -40.0, 0.0, 0.0, -70.0, -10.0, -13.055352858050473, 0.0, 0.0, -3.611606623099224, 0.0, -20.0, 0.0, -8.009186990471534, -10.0, -30.0, 0.0, 0.0, -20.0, 0.0, -30.0, 0.0, 0.0, -4.02285285366181, 0.0, 0.0, -20.0, 0.0, 0.0, -20.0, 0.0, 0.0, 0.0, 0.0, -11.915317920594264, -13.463673841355948, -10.0, 0.0, -10.0, -17.145310704920014, 0.0, 0.0, -0.3138312548686828, 0.0, -10.0, -15.631532812417019, -0.0473997298388229, 0.0, 0.0, -1.8299412742579435, -20.0, 0.0, -14.04211336430446, 0.0, 0.0, -10.042462156357496, -16.248975671448804, -3.651223502102935, -27.707205518544495, -6.63899482861505, 0.0, -10.0, 0.0, -1.385857069377583, -16.980340278870912, 0.0, 0.0, 0.0, 0.0, -10.0, -18.1113455958023, 0.0, -7.052222158798643, -4.348492016973193, -1.212972862218723, -4.647743364503192, -1.1006776765506254, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6389710586552783, "mean_inference_ms": 1.0958732385386192, "mean_action_processing_ms": 0.23028078643738004, "mean_env_wait_ms": 0.4788193236824007, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004511122490949692, "StateBufferConnector_ms": 0.0032592730916989076, "ViewRequirementAgentConnector_ms": 0.08931159973144531}, "num_episodes": 157, "episode_return_max": 140.0, "episode_return_min": -27.707205518544495, "episode_return_mean": 10.796552398660333}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 3008000, "num_agent_steps_trained": 3008000, "num_env_steps_sampled": 752000, "num_env_steps_trained": 752000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 356.8248699627556, "num_env_steps_trained_throughput_per_sec": 356.8248699627556, "timesteps_total": 752000, "num_env_steps_sampled_lifetime": 752000, "num_agent_steps_sampled_lifetime": 3008000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 3008000, "timers": {"training_iteration_time_ms": 11330.122, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11330.084, "sample_time_ms": 1104.407, "learn_time_ms": 10213.049, "learn_throughput": 391.656, "synch_weights_time_ms": 12.152}, "counters": {"num_env_steps_sampled": 752000, "num_env_steps_trained": 752000, "num_agent_steps_sampled": 3008000, "num_agent_steps_trained": 3008000}, "done": false, "training_iteration": 188, "trial_id": "86f16_00000", "date": "2024-08-08_16-53-18", "timestamp": 1723150398, "time_this_iter_s": 11.215335130691528, "time_total_s": 2409.6493730545044, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x309c62ee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 2409.6493730545044, "iterations_since_restore": 188, "perf": {"cpu_util_percent": 28.162499999999998, "ram_util_percent": 81.74375}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4738119947466444, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.3986012319935128, "policy_loss": -0.019499148560872842, "vf_loss": 1.4172299792791934, "vf_explained_var": 3.22541446550518e-08, "kl": 0.008703996339082988, "entropy": 0.40139831423970823, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 531570.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.0939002020905417, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.110414158552885, "policy_loss": -0.03536754410306457, "vf_loss": 2.143916564558943, "vf_explained_var": 0.08495713857312998, "kl": 0.009325701579888108, "entropy": 1.019031736565133, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 180960.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 756000, "num_env_steps_trained": 756000, "num_agent_steps_sampled": 3024000, "num_agent_steps_trained": 3024000}, "env_runners": {"episode_reward_max": 100.0, "episode_reward_min": -24.896226349227668, "episode_reward_mean": 11.914524128982718, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -55.565221428237756}, "policy_reward_max": {"adversary_policy": 50.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 7.098765432098766, "agent_policy": -9.381772167313578}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, -10.85705945363583, 0.0, 98.77871392335122, 0.0, 0.0, -8.336137431190096, -0.970110927523884, -10.98391186890564, 0.0, -15.6103218655394, 0.0, 20.0, -0.46776033404894335, 80.0, -3.727208604788657, 80.0, 40.0, 60.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, -15.310288743025415, -1.477956024479088, -0.9954096677834823, 0.0, 20.0, 0.0, 0.0, 0.0, 0.0, -1.503401906064108, -0.9850663395065173, 0.0, 0.0, -7.146214005753029, 0.0, 0.0, 20.0, 0.0, -0.35442554815552807, 100.0, 59.70913428481461, 0.0, -2.707951614525821, -0.7557126709448796, -0.8343870866888126, 20.0, 0.0, 0.0, 0.0, 40.0, -3.20284115846156, 0.0, 0.0, 40.0, -0.5991408122387476, 60.0, -0.817058517756386, -5.256870468518823, 0.0, -11.739370056467507, 34.434778571762244, 40.0, 0.0, 80.0, -24.896226349227668, -5.636368460274737, 0.0, -10.217468599415945, 0.0, 20.0, 27.793963415554938, 0.0, 0.0, -1.529945580901273, 6.926375757901184, 60.0, 0.0, 40.0, 13.964775700681209, -0.894862780130169, 0.0, 0.0, 0.0, 0.0, -0.007176340770170819, 40.0, 34.611527782887826, 0.0, 18.946419912402263, 60.0, 15.830999628132563, -4.59939824426155, 0.0, -18.239638244989028, 0.0, -0.8056122334705718, 0.0, 20.0, 0.0, 0.0, 0.0, -1.0459198430878192, -11.61502918477181, -0.32946355644566494, 40.0, 0.0, -0.03732313661337194, -3.636995372359192, 0.0, 0.0, 80.0, 0.0, 7.762278122099815, -0.40018489519211276, 0.0, 0.0, 0.0, 40.0, 0.0, 59.73508854992455, 0.0, 0.0, -15.08277161077242, -0.3094358311519041, -1.752379647461727, 0.0, 0.0, 0.0, 19.87132916671713, 20.0, 60.0, -4.1325081369989505, 1.3950963911602903, 0.0, 20.0, 40.0, -1.1327794548652903, 40.0, 58.461095154685694, 0.0, -5.514548256853158, 95.85053802115178, 60.0, 60.0, -4.108044717028002, 60.0, -0.7040049669291082, 0.0, 0.0, 60.0, 0.0, 0.0, 0.0, 0.0, 49.2443577895655, 11.375464572725983, -3.2723373003445246], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [0.0, -10.85705945363583, 0.0, -51.221286076648774, 0.0, 0.0, -8.336137431190096, -0.970110927523884, -10.98391186890564, 0.0, -15.6103218655394, 0.0, -10.0, -0.46776033404894335, -40.0, -3.727208604788657, -40.0, -20.0, -30.0, -10.0, 0.0, 0.0, 0.0, 0.0, 0.0, -15.310288743025415, -1.477956024479088, -0.9954096677834823, 0.0, -10.0, 0.0, 0.0, 0.0, 0.0, -1.503401906064108, -0.9850663395065173, 0.0, 0.0, -7.146214005753029, 0.0, 0.0, -10.0, 0.0, -0.35442554815552807, -50.0, -30.290865715185383, 0.0, -2.707951614525821, -30.755712670944877, -0.8343870866888126, -10.0, 0.0, 0.0, 0.0, -20.0, -3.20284115846156, 0.0, 0.0, -20.0, -0.5991408122387476, -30.0, -0.817058517756386, -5.256870468518823, 0.0, -11.739370056467507, -55.565221428237756, -20.0, 0.0, -40.0, -24.896226349227668, -5.636368460274737, 0.0, -10.217468599415945, 0.0, -10.0, -32.20603658444507, 0.0, 0.0, -1.529945580901273, -23.073624242098816, -30.0, 0.0, -20.0, -16.03522429931879, -0.894862780130169, 0.0, 0.0, 0.0, 0.0, -0.007176340770170819, -20.0, -25.388472217112174, 0.0, -11.053580087597739, -30.0, -14.169000371867437, -4.59939824426155, 0.0, -18.239638244989028, 0.0, -0.8056122334705718, 0.0, -10.0, 0.0, 0.0, 0.0, -1.0459198430878192, -11.61502918477181, -0.32946355644566494, -20.0, 0.0, -0.03732313661337194, -3.636995372359192, 0.0, 0.0, -40.0, 0.0, -22.237721877900185, -0.40018489519211276, 0.0, 0.0, 0.0, -20.0, 0.0, -30.264911450075456, 0.0, 0.0, -15.08277161077242, -0.3094358311519041, -1.752379647461727, 0.0, 0.0, 0.0, -10.12867083328287, -10.0, -30.0, -4.1325081369989505, -28.604903608839706, 0.0, -10.0, -20.0, -1.1327794548652903, -20.0, -31.538904845314313, 0.0, -5.514548256853158, -54.14946197884824, -30.0, -30.0, -4.108044717028002, -30.0, -0.7040049669291082, 0.0, 0.0, -30.0, 0.0, 0.0, 0.0, 0.0, -40.7556422104345, -18.62453542727401, -3.2723373003445246]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6405528673322839, "mean_inference_ms": 1.0950311642537083, "mean_action_processing_ms": 0.23170457218306997, "mean_env_wait_ms": 0.4784653067409819, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004247382835105613, "StateBufferConnector_ms": 0.003287232952353395, "ViewRequirementAgentConnector_ms": 0.08543670913319529}, "num_episodes": 162, "episode_return_max": 100.0, "episode_return_min": -24.896226349227668, "episode_return_mean": 11.914524128982718}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 3024000, "num_agent_steps_trained": 3024000, "num_env_steps_sampled": 756000, "num_env_steps_trained": 756000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 348.04350908975795, "num_env_steps_trained_throughput_per_sec": 348.04350908975795, "timesteps_total": 756000, "num_env_steps_sampled_lifetime": 756000, "num_agent_steps_sampled_lifetime": 3024000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 3024000, "timers": {"training_iteration_time_ms": 11313.114, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11313.075, "sample_time_ms": 1144.227, "learn_time_ms": 10156.555, "learn_throughput": 393.834, "synch_weights_time_ms": 11.798}, "counters": {"num_env_steps_sampled": 756000, "num_env_steps_trained": 756000, "num_agent_steps_sampled": 3024000, "num_agent_steps_trained": 3024000}, "done": false, "training_iteration": 189, "trial_id": "86f16_00000", "date": "2024-08-08_16-53-30", "timestamp": 1723150410, "time_this_iter_s": 11.50298810005188, "time_total_s": 2421.1523611545563, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad413a60>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 2421.1523611545563, "iterations_since_restore": 189, "perf": {"cpu_util_percent": 30.441176470588236, "ram_util_percent": 81.36470588235295}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4509850336251952, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.3927846097777077, "policy_loss": -0.018174669887570844, "vf_loss": 1.4101931884356425, "vf_explained_var": 2.886386627846576e-07, "kl": 0.007660910288969172, "entropy": 0.407603180154841, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 534390.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.2091782193630936, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.1158442723448387, "policy_loss": -0.03321099547247286, "vf_loss": 2.147159374350061, "vf_explained_var": 0.08976914702604215, "kl": 0.00947947083798996, "entropy": 1.0203895167137185, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 181920.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 760000, "num_env_steps_trained": 760000, "num_agent_steps_sampled": 3040000, "num_agent_steps_trained": 3040000}, "env_runners": {"episode_reward_max": 120.0, "episode_reward_min": -24.995322543888776, "episode_reward_mean": 10.353219531373739, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -61.90275095958688}, "policy_reward_max": {"adversary_policy": 60.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 6.049382716049383, "agent_policy": -7.794928616774409}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, -0.23928196802941892, -0.6730101367813668, 0.0, 59.813208630622256, 0.0, -1.4447205054697054, -0.8853139115740982, 0.0, -0.06813095708080752, -1.7085646819494094, 0.0, 0.0, 78.7436629800415, 0.0, 20.0, 0.0, -0.026754681098201116, 0.0, 40.0, 20.0, -4.912626872667063, 0.0, 0.0, 0.0, -15.959178937159317, -2.1310237864125825, -0.32365102337860163, 53.75746104816978, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.62428412654316, 55.59778322320602, 0.0, 0.0, 40.0, 0.0, 0.0, 0.0, 100.0, 0.0, -10.87610566154029, 0.0, 60.0, 0.0, -2.3294116323792724, 0.0, 59.53445094954375, 0.0, 0.0, 0.0, 0.0, 5.025096095885804, 0.0, 38.13713867669066, 0.0, -1.1537271132269933, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.07791924539090611, 40.0, 0.0, -3.7711485556867297, 20.0, 0.0, 0.0, -11.318350923130154, 0.0, -12.36679527837343, 0.0, 0.0, 43.69972790246379, 59.90333933737992, 20.0, 0.0, -5.877077297298441, 0.0, 20.0, 0.0, -1.0026166247461532, 0.0, 20.0, 0.0, 0.0, 0.0, 0.0, 29.4866062817268, -1.8723977055529362, 0.0, -8.299695976962973, -0.09317720080152969, 19.64915440013394, 0.0, -1.0874945789790358, 40.0, 0.0, 0.0, 0.0, 100.0, -6.95478207307044, 118.09724904041312, -4.207861700986231, -6.979084511848202, 37.44717802680949, -17.79314930660682, -24.995322543888776, 120.0, 0.0, 0.0, 60.0, 97.47519803752472, 60.0, 0.0, 0.0, 40.0, -0.29023654996422454, -0.3928154159889652, 39.737564480084515, 0.0, -0.081269562571894, 20.0, -1.0810152208573331, -0.05418459796301622, -0.04866379502405205, 13.763644771179168, 40.0, -0.2910227780113994, 20.0, 20.0, 40.0, -20.025774214537265, 0.0, 0.0, -0.4263706642221643, 0.0, -1.157721327265755, -6.433117940218694, -2.0037608496913286, 0.0, 0.0, 0.0, 40.0, -2.556855617486801, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [0.0, -0.23928196802941892, -0.6730101367813668, 0.0, -30.186791369377747, 0.0, -1.4447205054697054, -0.8853139115740982, 0.0, -0.06813095708080752, -1.7085646819494094, 0.0, 0.0, -41.25633701995849, 0.0, -10.0, 0.0, -0.026754681098201116, 0.0, -20.0, -10.0, -4.912626872667063, 0.0, 0.0, 0.0, -15.959178937159317, -2.1310237864125825, -0.32365102337860163, -36.24253895183023, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -18.37571587345684, -34.40221677679398, 0.0, 0.0, -20.0, 0.0, 0.0, 0.0, -50.0, 0.0, -10.87610566154029, 0.0, -30.0, 0.0, -2.3294116323792724, 0.0, -30.465549050456254, 0.0, 0.0, 0.0, 0.0, -24.974903904114196, 0.0, -21.862861323309343, 0.0, -1.1537271132269933, 0.0, 0.0, 0.0, 0.0, 0.0, -20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.07791924539090611, -20.0, 0.0, -3.7711485556867297, -10.0, 0.0, 0.0, -11.318350923130154, 0.0, -12.36679527837343, 0.0, 0.0, -46.30027209753621, -30.09666066262008, -10.0, 0.0, -5.877077297298441, 0.0, -10.0, 0.0, -1.0026166247461532, 0.0, -10.0, 0.0, 0.0, 0.0, 0.0, -60.5133937182732, -1.8723977055529362, 0.0, -8.299695976962973, -0.09317720080152969, -10.350845599866057, 0.0, -1.0874945789790358, -20.0, 0.0, 0.0, 0.0, -50.0, -6.95478207307044, -61.90275095958688, -4.207861700986231, -6.979084511848202, -22.55282197319051, -17.79314930660682, -24.995322543888776, -60.0, 0.0, 0.0, -30.0, -52.52480196247527, -30.0, 0.0, 0.0, -20.0, -0.29023654996422454, -0.3928154159889652, -20.26243551991549, 0.0, -0.081269562571894, -10.0, -1.0810152208573331, -0.05418459796301622, -0.04866379502405205, -16.23635522882083, -20.0, -0.2910227780113994, -10.0, -10.0, -20.0, -20.025774214537265, 0.0, 0.0, -0.4263706642221643, 0.0, -1.157721327265755, -6.433117940218694, -2.0037608496913286, 0.0, 0.0, 0.0, -20.0, -2.556855617486801, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6403081209804201, "mean_inference_ms": 1.0946649368100538, "mean_action_processing_ms": 0.23159911487073864, "mean_env_wait_ms": 0.47834359865279846, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004651884973785023, "StateBufferConnector_ms": 0.0036366927770920742, "ViewRequirementAgentConnector_ms": 0.0863000198646828}, "num_episodes": 162, "episode_return_max": 120.0, "episode_return_min": -24.995322543888776, "episode_return_mean": 10.353219531373739}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 3040000, "num_agent_steps_trained": 3040000, "num_env_steps_sampled": 760000, "num_env_steps_trained": 760000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 355.95511369815694, "num_env_steps_trained_throughput_per_sec": 355.95511369815694, "timesteps_total": 760000, "num_env_steps_sampled_lifetime": 760000, "num_agent_steps_sampled_lifetime": 3040000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 3040000, "timers": {"training_iteration_time_ms": 11335.132, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11335.093, "sample_time_ms": 1154.128, "learn_time_ms": 10168.812, "learn_throughput": 393.36, "synch_weights_time_ms": 11.655}, "counters": {"num_env_steps_sampled": 760000, "num_env_steps_trained": 760000, "num_agent_steps_sampled": 3040000, "num_agent_steps_trained": 3040000}, "done": false, "training_iteration": 190, "trial_id": "86f16_00000", "date": "2024-08-08_16-53-42", "timestamp": 1723150422, "time_this_iter_s": 11.242406129837036, "time_total_s": 2432.3947672843933, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad413f70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 2432.3947672843933, "iterations_since_restore": 190, "perf": {"cpu_util_percent": 28.275, "ram_util_percent": 81.3125}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.46769546064819006, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.3973594524758928, "policy_loss": -0.020958261781517443, "vf_loss": 1.4174700799140525, "vf_explained_var": 5.268036050999419e-07, "kl": 0.008476329147905297, "entropy": 0.40807552394714763, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 537210.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.4535556914905707, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.4867695214226844, "policy_loss": -0.03698730891216352, "vf_loss": 2.5217994398127, "vf_explained_var": 0.10702168419957162, "kl": 0.009786979000521967, "entropy": 1.0058015113696457, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 182880.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 764000, "num_env_steps_trained": 764000, "num_agent_steps_sampled": 3056000, "num_agent_steps_trained": 3056000}, "env_runners": {"episode_reward_max": 80.0, "episode_reward_min": -22.868159215605996, "episode_reward_mean": 11.261830556809905, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 158, "episodes_timesteps_total": 3950, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -49.570965105779656}, "policy_reward_max": {"adversary_policy": 40.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 7.025316455696203, "agent_policy": -9.814118810278702}, "custom_metrics": {}, "hist_stats": {"episode_reward": [60.0, 0.0, -0.18009316148314025, 29.53075632784208, 18.15346450448409, 39.00133421612661, 0.0, 60.0, -0.3334304677038158, -13.990261592634706, -12.45494630124776, 0.0, 19.32695189218979, -20.489490300769507, 40.0, 39.41833619636918, 40.0, -22.868159215605996, -3.61235867009726, 60.0, 0.0, 0.0, 45.71745820451305, -1.398258852480414, 0.0, -12.854599309410812, 7.355657738409942, -5.985733202129396, 0.0, -2.5873013456582568, -15.097029673762187, 20.0, 59.33564159759702, 0.0, 0.0, 0.0, 0.0, 51.21440405641606, -14.701548302160273, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 0.0, 0.0, -16.76801104782171, 0.0, 0.0, 0.0, 0.0, -9.281607987198383, 0.0, 0.0, 60.0, 60.0, -1.3488275563178331, -12.768482692104286, -2.672335706021399, -15.656489968828554, 60.0, -0.028724618473349173, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, -4.6091303035330045, 20.0, -3.556632354884413, 38.7893658830565, -3.079480782402805, 40.0, 34.765214635896704, 20.0, -0.8744884525918206, 0.0, -0.05281147121434904, 0.0, 6.317751003012628, -0.2407863592263204, -1.249007262416355, 0.0, -4.294179202416361, 40.0, 0.0, 0.0, 59.88970583153838, -0.47211200812915743, 37.502121105484164, 0.0, 0.0, -4.329420583497179, 70.42903489422034, 40.0, 16.91206348027828, 79.11298579234162, -15.069962103016946, 60.0, -4.3306464127937545, 0.0, 40.0, 19.551461125277665, 0.0, -5.557335609181075, 36.39150407654824, -12.611932565404686, 0.0, 20.0, -0.26297095012993377, 20.0, 19.83427494541965, -2.2674141421544225, 0.0, -2.6924904459288594, 38.00776459704158, 20.0, 59.039387226421894, 0.0, 0.0, 0.0, 0.0, 27.419259180984348, -0.2205255385788052, -9.76593804002392, -15.767186951990471, 0.0, 19.66890855132149, 0.0, 0.0, 0.0, 0.0, 0.0, -20.815550958823923, -0.5066703265614958, -16.553032737885246, 0.0, 0.0, 0.0, -5.160954379393256, -7.901112322911516, 0.0, 40.0, 40.0, 40.0, 20.0, -5.38793088863727, 0.0, 0.0, 40.0, 0.0, 39.39181403881011, 0.0, 80.0, 60.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0], "policy_agent_policy_reward": [-30.0, 0.0, -0.18009316148314025, -30.46924367215792, -11.846535495515907, -20.9986657838734, 0.0, -30.0, -0.3334304677038158, -13.990261592634706, -12.45494630124776, 0.0, -10.673048107810212, -20.489490300769507, -20.0, -20.581663803630818, -20.0, -22.868159215605996, -3.61235867009726, -30.0, 0.0, 0.0, -44.28254179548695, -1.398258852480414, 0.0, -12.854599309410812, -22.644342261590054, -5.985733202129396, 0.0, -2.5873013456582568, -15.097029673762187, -10.0, -30.66435840240298, 0.0, 0.0, 0.0, 0.0, -38.78559594358394, -14.701548302160273, 0.0, 0.0, 0.0, 0.0, 0.0, -20.0, -20.0, 0.0, 0.0, -16.76801104782171, 0.0, 0.0, 0.0, 0.0, -9.281607987198383, 0.0, 0.0, -30.0, -30.0, -1.3488275563178331, -12.768482692104286, -2.672335706021399, -15.656489968828554, -30.0, -0.028724618473349173, -10.0, 0.0, 0.0, 0.0, 0.0, 0.0, -4.6091303035330045, -10.0, -3.556632354884413, -21.210634116943503, -3.079480782402805, -20.0, -25.234785364103296, -10.0, -0.8744884525918206, 0.0, -0.05281147121434904, 0.0, -23.68224899698737, -0.2407863592263204, -1.249007262416355, 0.0, -4.294179202416361, -20.0, 0.0, 0.0, -30.11029416846163, -0.47211200812915743, -22.497878894515832, 0.0, 0.0, -4.329420583497179, -49.570965105779656, -20.0, -13.087936519721719, -40.88701420765838, -15.069962103016946, -30.0, -4.3306464127937545, 0.0, -20.0, -10.448538874722338, 0.0, -5.557335609181075, -23.608495923451773, -12.611932565404686, 0.0, -10.0, -0.26297095012993377, -10.0, -10.16572505458035, -2.2674141421544225, 0.0, -2.6924904459288594, -21.99223540295842, -10.0, -30.960612773578106, 0.0, 0.0, 0.0, 0.0, -32.58074081901565, -0.2205255385788052, -9.76593804002392, -15.767186951990471, 0.0, -10.33109144867851, 0.0, 0.0, 0.0, 0.0, 0.0, -20.815550958823923, -0.5066703265614958, -16.553032737885246, 0.0, 0.0, 0.0, -5.160954379393256, -7.901112322911516, 0.0, -20.0, -20.0, -20.0, -10.0, -5.38793088863727, 0.0, 0.0, -20.0, 0.0, -20.60818596118989, 0.0, -40.0, -30.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6397312814536389, "mean_inference_ms": 1.09355816359033, "mean_action_processing_ms": 0.231220519136432, "mean_env_wait_ms": 0.4779185562940963, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00447917588149445, "StateBufferConnector_ms": 0.0030613398250145247, "ViewRequirementAgentConnector_ms": 0.08874973164329046}, "num_episodes": 158, "episode_return_max": 80.0, "episode_return_min": -22.868159215605996, "episode_return_mean": 11.261830556809905}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 3056000, "num_agent_steps_trained": 3056000, "num_env_steps_sampled": 764000, "num_env_steps_trained": 764000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 353.8281191475807, "num_env_steps_trained_throughput_per_sec": 353.8281191475807, "timesteps_total": 764000, "num_env_steps_sampled_lifetime": 764000, "num_agent_steps_sampled_lifetime": 3056000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 3056000, "timers": {"training_iteration_time_ms": 11218.587, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11218.55, "sample_time_ms": 1162.011, "learn_time_ms": 10044.658, "learn_throughput": 398.222, "synch_weights_time_ms": 11.519}, "counters": {"num_env_steps_sampled": 764000, "num_env_steps_trained": 764000, "num_agent_steps_sampled": 3056000, "num_agent_steps_trained": 3056000}, "done": false, "training_iteration": 191, "trial_id": "86f16_00000", "date": "2024-08-08_16-53-53", "timestamp": 1723150433, "time_this_iter_s": 11.310400009155273, "time_total_s": 2443.7051672935486, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad4061f0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 2443.7051672935486, "iterations_since_restore": 191, "perf": {"cpu_util_percent": 31.837500000000002, "ram_util_percent": 81.45625}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.43704818234587395, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.2671785178336692, "policy_loss": -0.018411832179024597, "vf_loss": 1.2848238031069437, "vf_explained_var": -2.4987450728179716e-07, "kl": 0.007665479751995391, "entropy": 0.384196474831155, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 540030.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.3628910670677823, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.0331564403294276, "policy_loss": -0.038085983733374934, "vf_loss": 2.0694132686903077, "vf_explained_var": 0.100651189374427, "kl": 0.009145765461307551, "entropy": 1.0070287166163325, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 183840.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 768000, "num_env_steps_trained": 768000, "num_agent_steps_sampled": 3072000, "num_agent_steps_trained": 3072000}, "env_runners": {"episode_reward_max": 120.0, "episode_reward_min": -29.745085085012228, "episode_reward_mean": 11.607025713037944, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 157, "episodes_timesteps_total": 3925, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -60.0}, "policy_reward_max": {"adversary_policy": 60.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 6.8152866242038215, "agent_policy": -8.838834159573523}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-3.6353055623271704, 20.0, 80.0, 35.06688616045631, 38.934868853661044, 0.0, 0.0, -12.241384828213754, 99.7758974142055, 0.0, -9.107528311084872, 40.0, 30.920893307488566, 0.0, 0.0, 0.0, 0.0, 54.485192955266285, 57.340454283422226, -0.022152240748252172, 40.0, -0.9914680887014671, -0.9350891146469409, 0.0, 0.0, 58.37395775698836, -0.7751055825252751, 0.0, 0.0, 0.0, 20.0, 0.0, 0.0, 20.0, 50.81143515947861, 0.0, -5.120615283757586, 0.0, 0.0, 0.0, 20.0, -6.581269828540703, 0.0, 0.0, 60.0, 14.850651669365007, 0.0, 0.0, 0.0, -10.148431076105728, -11.250696731723913, 60.0, 20.0, -1.9967531793268647, 0.0, -10.992831230768308, -1.0144980631307465, 36.11022992053415, 39.76069220842558, 0.0, 20.0, -0.17459500928321048, -1.2206427926533858, 40.0, 0.0, 60.0, 0.0, 120.0, -0.11422798107683207, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -13.728107203887001, 0.0, -5.857710550919677, 40.0, 78.51936321130815, -29.745085085012228, 20.0, -5.386790094521109, -9.859686729789773, 60.0, 20.0, -6.731624435933472, 18.460581102957264, -1.2487254852773955, 40.0, -1.6540756543597268, 0.0, -0.7255253984622922, 0.0, -7.238348653451748, -0.8347546669154648, 0.0, 16.117752006801567, 0.0, 0.0, 0.0, -4.457684418876521, 0.0, 0.0, 0.0, -3.5516318147762016, 11.002697051642013, 0.0, 0.0, 50.28321708935863, 0.0, 35.35890169095234, 20.0, 0.0, -0.44766371427022666, -0.2268214138902469, -1.2294322161629456, -0.7781951782043528, 0.0, 0.0, 40.0, 80.0, 0.0, -6.721880497197352, 0.0, 0.0, -1.6358863166178106, 14.764627969087286, 0.0, 0.0, 0.0, -0.9743954013678113, 20.0, 60.0, -1.027616272922145, 0.0, 0.0, 0.0, -0.06479141196298, 0.0, 40.0, 0.0, 20.0, -4.692469756653913, 0.0, 0.0, 56.54233154728723, 60.0, 20.0, -2.2644131325320194, 0.0, 0.0, -6.631288443517227, 0.0, 38.8596044403674, 20.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0], "policy_agent_policy_reward": [-3.6353055623271704, -10.0, -40.0, -24.933113839543687, -21.065131146338953, 0.0, 0.0, -12.241384828213754, -50.22410258579449, 0.0, -9.107528311084872, -20.0, -29.079106692511434, 0.0, 0.0, 0.0, 0.0, -35.514807044733715, -32.659545716577774, -0.022152240748252172, -20.0, -0.9914680887014671, -0.9350891146469409, 0.0, 0.0, -31.62604224301164, -0.7751055825252751, 0.0, 0.0, 0.0, -10.0, 0.0, 0.0, -10.0, -39.18856484052139, 0.0, -5.120615283757586, 0.0, 0.0, 0.0, -10.0, -6.581269828540703, 0.0, 0.0, -30.0, -45.14934833063499, 0.0, 0.0, 0.0, -10.148431076105728, -11.250696731723913, -30.0, -10.0, -31.99675317932686, 0.0, -10.992831230768308, -1.0144980631307465, -23.889770079465848, -20.239307791574422, 0.0, -10.0, -0.17459500928321048, -1.2206427926533858, -20.0, 0.0, -30.0, 0.0, -60.0, -0.11422798107683207, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -13.728107203887001, 0.0, -5.857710550919677, -20.0, -41.48063678869186, -29.745085085012228, -10.0, -5.386790094521109, -9.859686729789773, -30.0, -10.0, -6.731624435933472, -11.539418897042736, -1.2487254852773955, -20.0, -1.6540756543597268, 0.0, -0.7255253984622922, 0.0, -7.238348653451748, -0.8347546669154648, 0.0, -13.882247993198435, 0.0, 0.0, 0.0, -4.457684418876521, 0.0, 0.0, 0.0, -3.5516318147762016, -18.997302948357987, 0.0, 0.0, -39.71678291064137, 0.0, -24.641098309047663, -10.0, 0.0, -0.44766371427022666, -0.2268214138902469, -1.2294322161629456, -0.7781951782043528, 0.0, 0.0, -20.0, -40.0, 0.0, -6.721880497197352, 0.0, 0.0, -1.6358863166178106, -15.235372030912714, 0.0, 0.0, 0.0, -0.9743954013678113, -10.0, -30.0, -1.027616272922145, 0.0, 0.0, 0.0, -0.06479141196298, 0.0, -20.0, 0.0, -10.0, -4.692469756653913, 0.0, 0.0, -33.45766845271276, -30.0, -10.0, -2.2644131325320194, 0.0, 0.0, -6.631288443517227, 0.0, -21.140395559632594, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6398697074767438, "mean_inference_ms": 1.0942011139631087, "mean_action_processing_ms": 0.2315621986950875, "mean_env_wait_ms": 0.47822996177194566, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004040435620933582, "StateBufferConnector_ms": 0.002990103071662271, "ViewRequirementAgentConnector_ms": 0.08418544842179414}, "num_episodes": 157, "episode_return_max": 120.0, "episode_return_min": -29.745085085012228, "episode_return_mean": 11.607025713037944}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 3072000, "num_agent_steps_trained": 3072000, "num_env_steps_sampled": 768000, "num_env_steps_trained": 768000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 361.6950843841209, "num_env_steps_trained_throughput_per_sec": 361.6950843841209, "timesteps_total": 768000, "num_env_steps_sampled_lifetime": 768000, "num_agent_steps_sampled_lifetime": 3072000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 3072000, "timers": {"training_iteration_time_ms": 11207.814, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11207.778, "sample_time_ms": 1149.049, "learn_time_ms": 10046.721, "learn_throughput": 398.14, "synch_weights_time_ms": 11.693}, "counters": {"num_env_steps_sampled": 768000, "num_env_steps_trained": 768000, "num_agent_steps_sampled": 3072000, "num_agent_steps_trained": 3072000}, "done": false, "training_iteration": 192, "trial_id": "86f16_00000", "date": "2024-08-08_16-54-04", "timestamp": 1723150444, "time_this_iter_s": 11.06571102142334, "time_total_s": 2454.770878314972, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad4063a0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 2454.770878314972, "iterations_since_restore": 192, "perf": {"cpu_util_percent": 28.212500000000002, "ram_util_percent": 81.975}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5022159689178703, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.6728261525115222, "policy_loss": -0.02099103207538129, "vf_loss": 1.6929761375941283, "vf_explained_var": 2.820652427402794e-07, "kl": 0.0084104409996342, "entropy": 0.38551403847357907, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 542850.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.2285061654945215, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.3144632440060375, "policy_loss": -0.03689727576177878, "vf_loss": 2.349247225994865, "vf_explained_var": 0.07087292987853289, "kl": 0.010566480140835307, "entropy": 1.0183842304473123, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 184800.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 772000, "num_env_steps_trained": 772000, "num_agent_steps_sampled": 3088000, "num_agent_steps_trained": 3088000}, "env_runners": {"episode_reward_max": 137.28091495489505, "episode_reward_min": -20.15451808396163, "episode_reward_mean": 15.293865987305999, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -72.71908504510493}, "policy_reward_max": {"adversary_policy": 70.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 8.395061728395062, "agent_policy": -9.891319197879183}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-7.564668186214381, 0.0, 40.0, 60.0, 0.0, -6.133274233356058, 80.0, -2.124796501115328, 33.60154657444525, 0.0, 0.0, -2.110386816663039, 20.0, 0.0, 0.0, -0.9871199886988646, -0.0716095128784644, -3.298022331992562, 0.0, 0.0, 37.50431968429074, -11.510427862727273, 59.85307188026732, 0.0, -0.061965800231941204, 0.0, 0.0, 20.0, 0.0, 0.0, -1.9283540567793356, 80.0, 40.0, 0.0, -2.134523507787139, 60.0, 0.0, -0.10464962585551074, 0.0, -8.828889269313791, 90.67802231441759, 60.0, 20.0, 0.0, 60.0, -3.5257979911851356, 18.24847192939038, 0.0, 20.0, 38.61968345495873, 0.0, 20.0, -0.23816230191686105, 0.0, -3.6656146098197713, 60.0, 0.0, -3.7606501930128697, 0.0, 0.0, 0.0, 0.0, 0.0, -15.351301721312767, 40.0, -3.429398172848491, 0.0, 40.0, 0.0, 0.0, 120.0, 40.0, 0.0, -16.59109435091892, 20.0, 59.2369533053315, 60.0, 0.0, 0.0, 0.0, 80.0, 97.10528186273343, 59.72367637260507, 0.0, 0.0, 0.0, 137.28091495489505, 0.0, 80.0, -3.5114738513424637, 60.0, 19.759472575490026, 0.0, 56.62277448043795, 0.0, 20.0, 60.0, 0.0, 0.0, 0.0, 78.97836668019332, -1.2640524824786092, -10.639667439080483, 0.0, 60.0, 0.0, -2.4796364908833315, 0.0, 0.0, -0.388273013442727, -0.8292786186612877, 20.0, -1.1523741011254485, 20.0, 40.0, 0.0, 20.0, 0.0, 0.0, 40.0, 0.0, -1.2365593280286291, -4.604774091073922, 38.647914649498304, 53.643953598097156, -11.549684652361565, 0.0, 0.0, 0.0, 60.0, 0.0, -0.08761550635751347, 100.0, 32.66152300907754, 0.0, 60.0, 0.0, 0.0, 0.0, 0.0, -2.6575925797524267, 0.0, 0.0, 19.638030071461756, -0.11699961938561265, 0.0, 0.0, 0.0, -20.15451808396163, -4.4743354166819325, 0.0, 40.0, -2.683980256104136, 0.0, 0.0, -2.154071127062097, -2.9729028060538276, -0.19988383134493692, -2.52360042788487, -1.6537356718818308, 0.0, -3.4419710244410613], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-7.564668186214381, 0.0, -20.0, -30.0, 0.0, -6.133274233356058, -40.0, -2.124796501115328, -26.398453425554745, 0.0, 0.0, -2.110386816663039, -10.0, 0.0, 0.0, -0.9871199886988646, -0.0716095128784644, -3.298022331992562, 0.0, 0.0, -22.495680315709254, -11.510427862727273, -30.14692811973267, 0.0, -0.061965800231941204, 0.0, 0.0, -10.0, 0.0, 0.0, -1.9283540567793356, -40.0, -20.0, 0.0, -2.134523507787139, -30.0, 0.0, -0.10464962585551074, 0.0, -8.828889269313791, -59.32197768558241, -30.0, -10.0, 0.0, -30.0, -3.5257979911851356, -11.75152807060962, 0.0, -10.0, -21.380316545041268, 0.0, -10.0, -0.23816230191686105, 0.0, -3.6656146098197713, -30.0, 0.0, -3.7606501930128697, 0.0, 0.0, 0.0, 0.0, 0.0, -45.351301721312765, -20.0, -3.429398172848491, 0.0, -20.0, 0.0, 0.0, -60.0, -20.0, 0.0, -16.59109435091892, -10.0, -30.76304669466851, -30.0, 0.0, 0.0, 0.0, -40.0, -52.89471813726656, -30.27632362739493, 0.0, 0.0, 0.0, -72.71908504510493, 0.0, -40.0, -3.5114738513424637, -30.0, -10.240527424509974, 0.0, -33.37722551956205, 0.0, -10.0, -30.0, 0.0, 0.0, 0.0, -41.021633319806675, -1.2640524824786092, -10.639667439080483, 0.0, -30.0, 0.0, -2.4796364908833315, 0.0, 0.0, -0.388273013442727, -0.8292786186612877, -10.0, -1.1523741011254485, -10.0, -20.0, 0.0, -10.0, 0.0, 0.0, -20.0, 0.0, -1.2365593280286291, -4.604774091073922, -21.352085350501696, -36.35604640190285, -11.549684652361565, 0.0, 0.0, 0.0, -30.0, 0.0, -0.08761550635751347, -50.0, -27.33847699092246, 0.0, -30.0, 0.0, 0.0, 0.0, 0.0, -2.6575925797524267, 0.0, 0.0, -10.361969928538246, -0.11699961938561265, 0.0, 0.0, 0.0, -20.15451808396163, -4.4743354166819325, 0.0, -20.0, -2.683980256104136, 0.0, 0.0, -2.154071127062097, -2.9729028060538276, -0.19988383134493692, -2.52360042788487, -1.6537356718818308, 0.0, -3.4419710244410613]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6393259161532763, "mean_inference_ms": 1.093115970022395, "mean_action_processing_ms": 0.23119644006118076, "mean_env_wait_ms": 0.47783545298884816, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004052527156876929, "StateBufferConnector_ms": 0.00314580069647895, "ViewRequirementAgentConnector_ms": 0.08533435103334026}, "num_episodes": 162, "episode_return_max": 137.28091495489505, "episode_return_min": -20.15451808396163, "episode_return_mean": 15.293865987305999}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 3088000, "num_agent_steps_trained": 3088000, "num_env_steps_sampled": 772000, "num_env_steps_trained": 772000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 357.5346152216703, "num_env_steps_trained_throughput_per_sec": 357.5346152216703, "timesteps_total": 772000, "num_env_steps_sampled_lifetime": 772000, "num_agent_steps_sampled_lifetime": 3088000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 3088000, "timers": {"training_iteration_time_ms": 11218.188, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11218.151, "sample_time_ms": 1148.856, "learn_time_ms": 10056.968, "learn_throughput": 397.734, "synch_weights_time_ms": 12.002}, "counters": {"num_env_steps_sampled": 772000, "num_env_steps_trained": 772000, "num_agent_steps_sampled": 3088000, "num_agent_steps_trained": 3088000}, "done": false, "training_iteration": 193, "trial_id": "86f16_00000", "date": "2024-08-08_16-54-16", "timestamp": 1723150456, "time_this_iter_s": 11.192657947540283, "time_total_s": 2465.963536262512, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad406820>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 2465.963536262512, "iterations_since_restore": 193, "perf": {"cpu_util_percent": 29.38125, "ram_util_percent": 81.83125}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4285229962979648, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.091991733511289, "policy_loss": -0.016226404844510784, "vf_loss": 1.1074634308299274, "vf_explained_var": 5.8082824057721075e-08, "kl": 0.007547074060645971, "entropy": 0.40664224290678685, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 545670.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.4101158337046704, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.019526086250941, "policy_loss": -0.03745410421446043, "vf_loss": 2.05524323573336, "vf_explained_var": 0.10495728061844906, "kl": 0.008684797945492576, "entropy": 1.0212017244969804, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 185760.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 776000, "num_env_steps_trained": 776000, "num_agent_steps_sampled": 3104000, "num_agent_steps_trained": 3104000}, "env_runners": {"episode_reward_max": 120.0, "episode_reward_min": -34.09495383270555, "episode_reward_mean": 10.485680314966947, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -60.0}, "policy_reward_max": {"adversary_policy": 60.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 6.3580246913580245, "agent_policy": -8.588393759107127}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.76122707663657, -2.071016515014642, 0.0, 40.0, 0.0, 0.0, -0.8624024896412119, 0.0, -1.1112887765219515, -1.9007826775010717, 0.0, -0.8917613269770674, -16.496831988285248, 100.0, -0.04176590175919759, 40.0, -0.28423773911999684, 0.0, 0.0, -0.46755907746686254, 0.0, -8.929151165064049, -13.395317985287246, 0.0, 0.0, 0.0, 0.0, -18.67155223122423, 0.0, 0.0, -3.645781232213202, 60.0, 0.0, 0.0, 0.0, -34.09495383270555, 0.0, 40.0, 0.0, -4.903131184829472, -7.665203179954396, -8.099491642886962, -0.5847315370940609, 30.79980721255891, 40.0, 78.57315192800061, 0.0, 0.0, -8.537577287650949, -7.18996817551522, 0.0, 40.0, 59.96554214709131, 0.0, 0.0, 0.0, 0.0, 98.81361467131663, 0.0, 0.0, 29.73050778805715, 20.0, -0.5065152611865964, -0.5425245187805106, 60.0, 0.0, -0.3031191799557009, 54.538858485357316, 0.0, -11.776873878531566, 0.0, -0.37733617694616695, 0.0, 0.0, 0.0, 40.0, -4.0777041528806315, 100.0, 61.5637675913895, 0.0, -7.149239721507515, 40.0, 0.0, 0.0, 0.0, -0.06208532193042404, 0.0, -7.0189323695066985, 20.0, -20.95975560793707, 0.0, 0.0, 0.0, -0.012964729084598003, 0.0, -2.8742030150193654, 0.0, 99.09581364074714, 20.0, -1.7339414954295873, 19.352620469508295, 0.0, -1.0360966078331013, 40.0, 0.0, 0.0, 33.13558918353594, 20.0, 0.0, 20.0, 0.0, 0.0, -6.407054608137493, 0.0, 40.0, 120.0, 60.0, -7.2868079555444565, 0.0, 0.0, 10.654350919649064, 0.0, 36.594019768937095, -2.2372755076839956, 0.0, 0.0, 120.0, 0.0, -1.6222547790921116, 58.54450867012895, 0.0, 0.0, -3.8110523660976723, -12.262544990025132, 0.0, 20.0, 0.0, 0.0, -3.9957140973201497, 0.0, -1.7236358395655882, 0.0, -4.355485591995291, 0.0, -5.485685789639342, 100.0, -0.040726203007682704, 0.0, 20.0, -1.5255961827426412, 0.0, 0.0, -8.07016895102203, 0.0, 20.0, -15.163459034386156, -1.2942923524138217, 0.0, 0.0, 0.0, -15.789840986459431, 37.904224690105764], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 60.0, 60.0, 60.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0], "policy_agent_policy_reward": [-21.23877292336343, -2.071016515014642, 0.0, -20.0, 0.0, 0.0, -0.8624024896412119, 0.0, -1.1112887765219515, -1.9007826775010717, 0.0, -0.8917613269770674, -16.496831988285248, -50.0, -0.04176590175919759, -20.0, -0.28423773911999684, 0.0, 0.0, -0.46755907746686254, 0.0, -8.929151165064049, -13.395317985287246, 0.0, 0.0, 0.0, 0.0, -18.67155223122423, 0.0, 0.0, -3.645781232213202, -30.0, 0.0, 0.0, 0.0, -34.09495383270555, 0.0, -20.0, 0.0, -4.903131184829472, -7.665203179954396, -8.099491642886962, -0.5847315370940609, -29.20019278744109, -20.0, -41.42684807199939, 0.0, 0.0, -8.537577287650949, -7.18996817551522, 0.0, -20.0, -30.034457852908684, 0.0, 0.0, 0.0, 0.0, -51.18638532868337, 0.0, 0.0, -30.26949221194285, -10.0, -0.5065152611865964, -0.5425245187805106, -30.0, 0.0, -0.3031191799557009, -35.46114151464268, 0.0, -11.776873878531566, 0.0, -0.37733617694616695, 0.0, 0.0, 0.0, -20.0, -4.0777041528806315, -50.0, -58.43623240861049, 0.0, -7.149239721507515, -20.0, 0.0, 0.0, 0.0, -0.06208532193042404, 0.0, -7.0189323695066985, -10.0, -20.95975560793707, 0.0, 0.0, 0.0, -0.012964729084598003, 0.0, -2.8742030150193654, 0.0, -50.904186359252854, -10.0, -1.7339414954295873, -10.647379530491701, 0.0, -1.0360966078331013, -20.0, 0.0, 0.0, -26.86441081646406, -10.0, 0.0, -10.0, 0.0, 0.0, -6.407054608137493, 0.0, -20.0, -60.0, -30.0, -7.2868079555444565, 0.0, 0.0, -19.345649080350938, 0.0, -23.40598023106289, -2.2372755076839956, 0.0, 0.0, -60.0, 0.0, -1.6222547790921116, -31.455491329871062, 0.0, 0.0, -3.8110523660976723, -12.262544990025132, 0.0, -10.0, 0.0, 0.0, -3.9957140973201497, 0.0, -1.7236358395655882, 0.0, -4.355485591995291, 0.0, -5.485685789639342, -50.0, -0.040726203007682704, 0.0, -10.0, -1.5255961827426412, 0.0, 0.0, -8.07016895102203, 0.0, -10.0, -15.163459034386156, -1.2942923524138217, 0.0, 0.0, 0.0, -15.789840986459431, -22.095775309894233]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6390219340108109, "mean_inference_ms": 1.0926022001132378, "mean_action_processing_ms": 0.231061685435153, "mean_env_wait_ms": 0.47763334646096756, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004095869299806195, "StateBufferConnector_ms": 0.0030761147722785857, "ViewRequirementAgentConnector_ms": 0.0850676754374563}, "num_episodes": 162, "episode_return_max": 120.0, "episode_return_min": -34.09495383270555, "episode_return_mean": 10.485680314966947}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 3104000, "num_agent_steps_trained": 3104000, "num_env_steps_sampled": 776000, "num_env_steps_trained": 776000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 371.2226720780354, "num_env_steps_trained_throughput_per_sec": 371.2226720780354, "timesteps_total": 776000, "num_env_steps_sampled_lifetime": 776000, "num_agent_steps_sampled_lifetime": 3104000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 3104000, "timers": {"training_iteration_time_ms": 11188.949, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11188.912, "sample_time_ms": 1148.467, "learn_time_ms": 10028.154, "learn_throughput": 398.877, "synch_weights_time_ms": 11.906}, "counters": {"num_env_steps_sampled": 776000, "num_env_steps_trained": 776000, "num_agent_steps_sampled": 3104000, "num_agent_steps_trained": 3104000}, "done": false, "training_iteration": 194, "trial_id": "86f16_00000", "date": "2024-08-08_16-54-27", "timestamp": 1723150467, "time_this_iter_s": 10.780006170272827, "time_total_s": 2476.743542432785, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad406d30>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 2476.743542432785, "iterations_since_restore": 194, "perf": {"cpu_util_percent": 27.9125, "ram_util_percent": 81.775}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.40918448511907396, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.9187700179029018, "policy_loss": -0.01711219221143818, "vf_loss": 0.9350897606911389, "vf_explained_var": -1.036317635935249e-07, "kl": 0.007924500091695713, "entropy": 0.40523336078469635, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 548490.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.4396572853128116, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.0379013957455756, "policy_loss": -0.03691157111121963, "vf_loss": 2.073046762434145, "vf_explained_var": 0.12721440829336644, "kl": 0.00883102158816469, "entropy": 1.0136313704773783, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 186720.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 780000, "num_env_steps_trained": 780000, "num_agent_steps_sampled": 3120000, "num_agent_steps_trained": 3120000}, "env_runners": {"episode_reward_max": 99.27124556632928, "episode_reward_min": -36.152456708900694, "episode_reward_mean": 5.948872280498021, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -61.22122923347244}, "policy_reward_max": {"adversary_policy": 50.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 4.382716049382716, "agent_policy": -7.199275867650127}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, -1.736615757808463, -0.017648557809234466, 0.0, 0.0, 0.0, 0.0, -4.821671251472813, 56.205694209535324, 0.0, -1.4089076912048193, -0.247705329161384, 0.0, 17.41094967032589, 20.0, 39.81591735592226, 20.0, 0.0, 0.0, -22.07874520315871, 0.0, 0.0, 39.553537417207295, 27.90117848852108, 20.0, 0.0, -12.43157520521207, 60.0, -10.735797694118233, 0.0, 0.0, -0.58588358687087, 56.96616928797917, -3.0358890612546485, 18.764178883828453, -0.26200691080070726, 0.0, 20.0, -1.7932882538457262, -9.20738450126503, 78.73056319484807, -1.447117436826565, -4.174269495935393, 0.0, 60.0, -0.0552757919053215, 17.30665441047974, -1.2126734209008239, 0.0, 60.0, 0.0, 0.0, 0.0, -3.1441074645770817, -0.9604597105585255, -0.5565791294672695, -1.8910980089861662, 0.0, 0.0, 0.0, 0.0, -2.7713360902466544, 0.0, 20.0, 0.0, 0.0, 0.0, -1.3786403104250378, 80.0, 0.0, 60.0, 0.0, 0.0, 19.865668169238063, 0.0, -6.852629749667398, -1.7161083282558898, 0.0, -1.05244405677145, 0.0, 0.0, -33.109976568034234, 0.0, -12.42300588351752, -0.26128753296468465, -0.8273290257055499, -4.240905561149493, -2.949276053667951, -2.3328576621563455, -5.783057762775047, 0.0, 0.0, 0.0, 0.0, 57.2032980251919, -0.6742453977828633, 0.0, -14.252556401220014, -1.0417122855178929, 18.1917641583915, -14.224670676853297, -2.138180916260163, 0.0, 20.0, 0.0, -7.000619604151083, -36.152456708900694, 0.0, 28.778770766527572, -0.24597240925514074, -27.96587537720553, 20.0, -4.679146841656429, -13.55836392033985, 0.0, 0.0, -1.8681560531866304, 19.81899188864811, 20.0, 0.0, -4.166750247667215, 0.0, -2.784802053661827, 0.0, -1.5860684194479457, 40.0, -2.7796904300396106, -0.6853308538624037, 0.0, 20.0, -0.4212702313414818, 0.0, -0.0038159637526080648, 39.87250144095446, 99.27124556632928, -0.9369310464661627, -3.2709927672535377, 0.0, 25.014454022144086, 0.0, -9.886045140960489, 20.0, 0.0, -2.091994890050172, -13.949606339769133, 0.0, -0.8811314250136792, 0.0, 0.0, -4.542425186645778, -0.3190323870709977, -19.79571179592008, 0.0, -5.646130835743832, 0.0, -0.4771819296426838, 0.0, 0.0, 38.8359941820466, 59.85301964066174, -0.1128187529847513, 0.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 50.0, 50.0, 50.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [0.0, -1.736615757808463, -0.017648557809234466, 0.0, 0.0, 0.0, 0.0, -4.821671251472813, -33.79430579046468, 0.0, -1.4089076912048193, -0.247705329161384, 0.0, -12.589050329674107, -10.0, -20.18408264407774, -10.0, 0.0, 0.0, -22.07874520315871, 0.0, 0.0, -20.44646258279271, -32.09882151147893, -10.0, 0.0, -12.43157520521207, -30.0, -10.735797694118233, 0.0, 0.0, -0.58588358687087, -33.03383071202083, -3.0358890612546485, -11.23582111617155, -0.26200691080070726, 0.0, -10.0, -1.7932882538457262, -9.20738450126503, -41.269436805151926, -1.447117436826565, -4.174269495935393, 0.0, -30.0, -0.0552757919053215, -12.69334558952026, -1.2126734209008239, 0.0, -30.0, 0.0, 0.0, 0.0, -3.1441074645770817, -0.9604597105585255, -0.5565791294672695, -1.8910980089861662, 0.0, 0.0, 0.0, 0.0, -2.7713360902466544, 0.0, -10.0, 0.0, 0.0, 0.0, -1.3786403104250378, -40.0, 0.0, -30.0, 0.0, 0.0, -10.134331830761935, 0.0, -6.852629749667398, -1.7161083282558898, 0.0, -1.05244405677145, 0.0, 0.0, -33.109976568034234, 0.0, -12.42300588351752, -0.26128753296468465, -0.8273290257055499, -4.240905561149493, -2.949276053667951, -2.3328576621563455, -5.783057762775047, 0.0, 0.0, 0.0, 0.0, -32.796701974808094, -0.6742453977828633, 0.0, -14.252556401220014, -1.0417122855178929, -11.8082358416085, -14.224670676853297, -2.138180916260163, 0.0, -10.0, 0.0, -7.000619604151083, -36.152456708900694, 0.0, -61.22122923347244, -0.24597240925514074, -27.96587537720553, -10.0, -4.679146841656429, -13.55836392033985, 0.0, 0.0, -1.8681560531866304, -10.181008111351892, -10.0, 0.0, -4.166750247667215, 0.0, -2.784802053661827, 0.0, -1.5860684194479457, -20.0, -2.7796904300396106, -0.6853308538624037, 0.0, -10.0, -0.4212702313414818, 0.0, -0.0038159637526080648, -20.12749855904554, -50.728754433670716, -30.936931046466164, -3.2709927672535377, 0.0, -34.9855459778559, 0.0, -9.886045140960489, -10.0, 0.0, -2.091994890050172, -13.949606339769133, 0.0, -0.8811314250136792, 0.0, 0.0, -4.542425186645778, -0.3190323870709977, -19.79571179592008, 0.0, -5.646130835743832, 0.0, -0.4771819296426838, 0.0, 0.0, -21.164005817953402, -30.146980359338258, -0.1128187529847513, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6386525487764195, "mean_inference_ms": 1.0921628761700808, "mean_action_processing_ms": 0.23093474620381116, "mean_env_wait_ms": 0.47747729142588363, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004012202039177035, "StateBufferConnector_ms": 0.0031750143310170114, "ViewRequirementAgentConnector_ms": 0.08352325286394284}, "num_episodes": 162, "episode_return_max": 99.27124556632928, "episode_return_min": -36.152456708900694, "episode_return_mean": 5.948872280498021}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 3120000, "num_agent_steps_trained": 3120000, "num_env_steps_sampled": 780000, "num_env_steps_trained": 780000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 341.89779997905475, "num_env_steps_trained_throughput_per_sec": 341.89779997905475, "timesteps_total": 780000, "num_env_steps_sampled_lifetime": 780000, "num_agent_steps_sampled_lifetime": 3120000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 3120000, "timers": {"training_iteration_time_ms": 11217.531, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11217.495, "sample_time_ms": 1148.718, "learn_time_ms": 10056.508, "learn_throughput": 397.752, "synch_weights_time_ms": 11.889}, "counters": {"num_env_steps_sampled": 780000, "num_env_steps_trained": 780000, "num_agent_steps_sampled": 3120000, "num_agent_steps_trained": 3120000}, "done": false, "training_iteration": 195, "trial_id": "86f16_00000", "date": "2024-08-08_16-54-39", "timestamp": 1723150479, "time_this_iter_s": 11.704643964767456, "time_total_s": 2488.4481863975525, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad413a60>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 2488.4481863975525, "iterations_since_restore": 195, "perf": {"cpu_util_percent": 30.8125, "ram_util_percent": 81.76249999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4269677567777904, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.1675498862427176, "policy_loss": -0.01830371106348945, "vf_loss": 1.1850158835873537, "vf_explained_var": -5.765375516093369e-07, "kl": 0.008377137170723756, "entropy": 0.4120309435835121, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 551310.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.3145703228811425, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.074145552252109, "policy_loss": -0.03760536134116895, "vf_loss": 2.1097776414826512, "vf_explained_var": 0.12172784414142371, "kl": 0.009866335974096174, "entropy": 0.9820348295693596, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 187680.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 784000, "num_env_steps_trained": 784000, "num_agent_steps_sampled": 3136000, "num_agent_steps_trained": 3136000}, "env_runners": {"episode_reward_max": 140.0, "episode_reward_min": -28.51655094827413, "episode_reward_mean": 8.843773116452677, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 153, "episodes_timesteps_total": 3825, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -70.0}, "policy_reward_max": {"adversary_policy": 70.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 5.555555555555555, "agent_policy": -7.82289355021399}, "custom_metrics": {}, "hist_stats": {"episode_reward": [20.0, 0.0, 0.0, 0.0, 0.0, -12.489015840291193, 0.0, 40.0, -0.7208678800599078, 0.0, 0.0, 0.0, -8.040645536958412, -4.448924222591399, 0.0, 40.0, 0.0, 60.0, 0.0, 0.0, 0.0, 140.0, -0.5113060121542179, 0.0, -1.0228370916209228, 32.68958661652756, 0.0, 20.0, 0.0, 20.0, -5.819302917992153, 59.62034091113816, 0.0, 0.0, -17.610987690640137, 0.0, -8.788148321201493, -21.971649600905693, 0.0, 0.0, 60.0, 0.0, 0.0, 40.0, 0.0, 60.0, 0.0, 20.0, -7.977579515886417, 20.0, -0.1436262952513001, 0.0, 0.0, 0.0, 60.0, -3.378152649640459, -0.8509591453708787, -2.358899042230538, 75.65953919301843, 0.0, 0.0, 60.0, -1.2605654482138293, 0.0, 19.974614708675333, -5.628653092049349, 0.0, 0.0, 2.0306719039655854, 0.0, -1.5503222539196782, -9.372675348198749, 0.0, 0.0, 0.0, -2.5694067258850177, 20.0, 36.62461495034987, 20.0, 0.0, 0.0, -0.457305097291012, -11.998692476926779, -28.51655094827413, 20.0, 0.0, 0.0, -17.273440106779958, 38.66572902803226, 20.0, -3.3317463256120448, 20.0, -1.1948072173486024, 80.0, 0.0, -3.0352471688351095, -0.9229325835902258, -0.24696001726135397, -7.3274105340343345, 0.0, 20.0, 0.0, -0.9624552158079536, 0.0, 0.0, 16.428529458042895, 38.821844046651776, 0.0, 0.0, 40.0, -4.49980752233745, -6.108484943606376, -11.238172361278341, 0.0, -0.47556926014127643, 0.7150951769772229, -3.340429900152505, 0.0, 0.0, 0.0, -5.4712926299630436, 20.0, 40.0, 60.0, 0.0, 0.0, 0.0, -0.5522815418577132, -0.9813489998896319, -0.08138063830563036, 0.0, 17.846448388189366, 0.0, 100.0, -1.9171205301509664, -23.663339893906237, -0.3232380780527111, 0.0, -0.6346083951174775, 0.0, 0.0, 20.0, 0.0, -1.7504644489003374, 0.0, 0.0, 36.802299849108216, 0.0, 20.0, -0.02997068281170745, 10.5083861572316, -0.4408314213540343, 60.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0], "policy_agent_policy_reward": [-10.0, 0.0, 0.0, 0.0, 0.0, -12.489015840291193, 0.0, -20.0, -0.7208678800599078, 0.0, 0.0, 0.0, -8.040645536958412, -4.448924222591399, 0.0, -20.0, 0.0, -30.0, 0.0, 0.0, 0.0, -70.0, -0.5113060121542179, 0.0, -1.0228370916209228, -27.31041338347243, 0.0, -10.0, 0.0, -10.0, -5.819302917992153, -30.379659088861835, 0.0, 0.0, -17.610987690640137, 0.0, -8.788148321201493, -21.971649600905693, 0.0, 0.0, -30.0, 0.0, 0.0, -20.0, 0.0, -30.0, 0.0, -10.0, -7.977579515886417, -10.0, -0.1436262952513001, 0.0, 0.0, 0.0, -30.0, -3.378152649640459, -0.8509591453708787, -2.358899042230538, -44.34046080698157, 0.0, 0.0, -30.0, -1.2605654482138293, 0.0, -10.02538529132467, -5.628653092049349, 0.0, 0.0, -27.969328096034406, 0.0, -1.5503222539196782, -9.372675348198749, 0.0, 0.0, 0.0, -2.5694067258850177, -10.0, -23.375385049650124, -10.0, 0.0, 0.0, -0.457305097291012, -11.998692476926779, -28.51655094827413, -10.0, 0.0, 0.0, -17.273440106779958, -21.334270971967737, -10.0, -3.3317463256120448, -10.0, -1.1948072173486024, -40.0, 0.0, -3.0352471688351095, -0.9229325835902258, -0.24696001726135397, -7.3274105340343345, 0.0, -10.0, 0.0, -0.9624552158079536, 0.0, 0.0, -13.571470541957103, -21.17815595334822, 0.0, 0.0, -20.0, -4.49980752233745, -6.108484943606376, -11.238172361278341, 0.0, -0.47556926014127643, -29.284904823022778, -3.340429900152505, 0.0, 0.0, 0.0, -5.4712926299630436, -10.0, -20.0, -30.0, 0.0, 0.0, 0.0, -0.5522815418577132, -0.9813489998896319, -0.08138063830563036, 0.0, -42.153551611810634, 0.0, -50.0, -1.9171205301509664, -23.663339893906237, -0.3232380780527111, 0.0, -0.6346083951174775, 0.0, 0.0, -10.0, 0.0, -1.7504644489003374, 0.0, 0.0, -23.19770015089178, 0.0, -10.0, -0.02997068281170745, -19.4916138427684, -0.4408314213540343, -30.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.63832664889846, "mean_inference_ms": 1.0916575269669295, "mean_action_processing_ms": 0.23079401702755784, "mean_env_wait_ms": 0.47731677212040685, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0039622674580493, "StateBufferConnector_ms": 0.003336769303465201, "ViewRequirementAgentConnector_ms": 0.08157008613636291}, "num_episodes": 153, "episode_return_max": 140.0, "episode_return_min": -28.51655094827413, "episode_return_mean": 8.843773116452677}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 3136000, "num_agent_steps_trained": 3136000, "num_env_steps_sampled": 784000, "num_env_steps_trained": 784000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 356.0080848040785, "num_env_steps_trained_throughput_per_sec": 356.0080848040785, "timesteps_total": 784000, "num_env_steps_sampled_lifetime": 784000, "num_agent_steps_sampled_lifetime": 3136000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 3136000, "timers": {"training_iteration_time_ms": 11233.17, "restore_workers_time_ms": 0.013, "training_step_time_ms": 11233.134, "sample_time_ms": 1154.241, "learn_time_ms": 10066.661, "learn_throughput": 397.351, "synch_weights_time_ms": 11.825}, "counters": {"num_env_steps_sampled": 784000, "num_env_steps_trained": 784000, "num_agent_steps_sampled": 3136000, "num_agent_steps_trained": 3136000}, "done": false, "training_iteration": 196, "trial_id": "86f16_00000", "date": "2024-08-08_16-54-50", "timestamp": 1723150490, "time_this_iter_s": 11.241428852081299, "time_total_s": 2499.689615249634, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad3c8310>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 2499.689615249634, "iterations_since_restore": 196, "perf": {"cpu_util_percent": 27.794117647058822, "ram_util_percent": 81.60588235294117}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.49013629801941255, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.4066971304780203, "policy_loss": -0.021741123672687046, "vf_loss": 1.42748965718222, "vf_explained_var": -3.451996661247091e-07, "kl": 0.009485985028072316, "entropy": 0.4140202248984195, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 554130.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.3253276069959004, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.386039061658084, "policy_loss": -0.039004314454602236, "vf_loss": 2.4229616676767667, "vf_explained_var": 0.1509611101200183, "kl": 0.010408540676413535, "entropy": 1.0011582654590407, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 188640.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 788000, "num_env_steps_trained": 788000, "num_agent_steps_sampled": 3152000, "num_agent_steps_trained": 3152000}, "env_runners": {"episode_reward_max": 139.78726471514327, "episode_reward_min": -29.631914535260577, "episode_reward_mean": 8.423755474028672, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -70.21273528485675}, "policy_reward_max": {"adversary_policy": 70.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 5.617283950617284, "agent_policy": -8.428096377823179}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, -2.7424038034809106, -3.7550428227721513, -2.7080664396958953, -0.010499861281548784, -4.793868054432844, 20.0, 80.0, 0.0, 40.0, 139.78726471514327, -4.054924429470398, 0.0, 40.0, -0.20965980184007305, -1.2404990615761202, 0.0, 40.0, 19.90764604982365, 0.0, 0.0, 0.0, 40.0, -0.4461514451915538, 60.0, -0.026677204543461563, 0.0, -0.4485861307316741, -12.003262799267006, -2.2913326319480456, 0.0, -5.112297266220759, 0.0, -11.994856898121663, -0.9805248636001973, 40.0, 20.0, 10.613619644892815, 0.0, 14.654837984628982, 38.562596340292025, -5.4796318572345415, 0.0, -14.285168165872308, -1.5080774562116117, 60.0, -2.1082485689867765, 19.105603157024078, -15.240373616679383, 57.78006150736741, 19.840029145595196, 40.0, 34.84769745314503, 20.0, -12.517881910406016, 0.0, 40.0, 0.0, -9.019959745203087, 20.0, 11.754386946789806, 0.0, 0.0, -3.984067093876911, 0.0, 0.0, 0.0, 40.0, -3.080608127899379, -0.9809435989829063, 9.838943180537747, 0.0, -22.122217031343087, 0.0, 0.0, -12.62700591723828, 0.0, -1.6635882776972533, 40.0, -0.04899271686545692, 0.0, 0.0, 20.0, -2.4703202045315917, -6.8707737926593095, 0.0, -3.7653422923311743, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -29.631914535260577, -11.833522810273738, 48.1202403309715, 20.0, -0.4221051844557533, 0.0, -3.863431144251193, 0.0, 0.0, 0.0, -0.0015360198684555293, 57.64815412102736, 0.0, -0.16107523146035474, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 0.0, -27.266841508645406, -4.4164789977446794, 0.0, 5.146646144442057, 60.0, 20.0, 0.0, -19.75048003143165, -2.460505948862266, -2.4560010385813733, 19.710120646398185, 0.0, -1.5497345503037674, -22.25613708095076, -8.324398785940323, 0.0, 0.0, -20.485612786089938, -4.753365163617991, -6.171090315225513, 20.0, -1.012292061408423, 0.0, 0.0, 0.0, 0.0, -0.24579776505147866, -0.961306644120612, 0.0, 20.0, -1.6564534837315392, 0.0, 80.0, 0.0, 0.0, -21.28193064822398, 0.0, 60.0, 40.0, 60.0, -10.164547676380268, 20.0, 0.0, 19.73596178573043, 40.0, 0.0, 9.312990938908996, 80.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0], "policy_agent_policy_reward": [0.0, -2.7424038034809106, -3.7550428227721513, -2.7080664396958953, -0.010499861281548784, -4.793868054432844, -10.0, -40.0, 0.0, -20.0, -70.21273528485675, -4.054924429470398, 0.0, -20.0, -0.20965980184007305, -1.2404990615761202, 0.0, -20.0, -10.092353950176353, 0.0, 0.0, 0.0, -20.0, -0.4461514451915538, -30.0, -0.026677204543461563, 0.0, -0.4485861307316741, -12.003262799267006, -2.2913326319480456, 0.0, -5.112297266220759, 0.0, -11.994856898121663, -0.9805248636001973, -20.0, -10.0, -19.386380355107192, 0.0, -15.34516201537102, -21.437403659707975, -5.4796318572345415, 0.0, -14.285168165872308, -1.5080774562116117, -30.0, -2.1082485689867765, -10.894396842975922, -15.240373616679383, -32.2199384926326, -10.159970854404804, -20.0, -25.152302546854965, -10.0, -12.517881910406016, 0.0, -20.0, 0.0, -9.019959745203087, -10.0, -18.245613053210185, 0.0, 0.0, -3.984067093876911, 0.0, 0.0, 0.0, -20.0, -3.080608127899379, -0.9809435989829063, -20.161056819462253, 0.0, -22.122217031343087, 0.0, 0.0, -12.62700591723828, 0.0, -1.6635882776972533, -20.0, -0.04899271686545692, 0.0, 0.0, -10.0, -2.4703202045315917, -6.8707737926593095, 0.0, -3.7653422923311743, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -29.631914535260577, -11.833522810273738, -41.8797596690285, -10.0, -0.4221051844557533, 0.0, -3.863431144251193, 0.0, 0.0, 0.0, -0.0015360198684555293, -32.35184587897264, 0.0, -0.16107523146035474, 0.0, 0.0, 0.0, 0.0, 0.0, -10.0, 0.0, -27.266841508645406, -4.4164789977446794, 0.0, -24.853353855557945, -30.0, -10.0, 0.0, -19.75048003143165, -2.460505948862266, -2.4560010385813733, -10.289879353601815, 0.0, -1.5497345503037674, -22.25613708095076, -8.324398785940323, 0.0, 0.0, -20.485612786089938, -4.753365163617991, -6.171090315225513, -10.0, -1.012292061408423, 0.0, 0.0, 0.0, 0.0, -0.24579776505147866, -0.961306644120612, 0.0, -10.0, -1.6564534837315392, 0.0, -40.0, 0.0, 0.0, -21.28193064822398, 0.0, -30.0, -20.0, -30.0, -10.164547676380268, -10.0, 0.0, -10.26403821426957, -20.0, 0.0, -20.687009061091008, -40.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6380310781880018, "mean_inference_ms": 1.0911619580538978, "mean_action_processing_ms": 0.23067835428396535, "mean_env_wait_ms": 0.4771711849670371, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004298966607929748, "StateBufferConnector_ms": 0.0030480049274585865, "ViewRequirementAgentConnector_ms": 0.08497922508804887}, "num_episodes": 162, "episode_return_max": 139.78726471514327, "episode_return_min": -29.631914535260577, "episode_return_mean": 8.423755474028672}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 3152000, "num_agent_steps_trained": 3152000, "num_env_steps_sampled": 788000, "num_env_steps_trained": 788000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 275.25176878197533, "num_env_steps_trained_throughput_per_sec": 275.25176878197533, "timesteps_total": 788000, "num_env_steps_sampled_lifetime": 788000, "num_agent_steps_sampled_lifetime": 3152000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 3152000, "timers": {"training_iteration_time_ms": 11573.438, "restore_workers_time_ms": 0.013, "training_step_time_ms": 11573.402, "sample_time_ms": 1157.367, "learn_time_ms": 10400.675, "learn_throughput": 384.59, "synch_weights_time_ms": 14.809}, "counters": {"num_env_steps_sampled": 788000, "num_env_steps_trained": 788000, "num_agent_steps_sampled": 3152000, "num_agent_steps_trained": 3152000}, "done": false, "training_iteration": 197, "trial_id": "86f16_00000", "date": "2024-08-08_16-55-05", "timestamp": 1723150505, "time_this_iter_s": 14.559376955032349, "time_total_s": 2514.248992204666, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad5123a0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 2514.248992204666, "iterations_since_restore": 197, "perf": {"cpu_util_percent": 47.01904761904761, "ram_util_percent": 82.16190476190475}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.40045800324238784, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.1108571646272714, "policy_loss": -0.017460214257550323, "vf_loss": 1.1274933509581477, "vf_explained_var": -8.896310278709899e-08, "kl": 0.008240272328270187, "entropy": 0.4280707622779177, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 556950.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.7299380164593456, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.523364209011197, "policy_loss": -0.03748207523264379, "vf_loss": 2.559002822265029, "vf_explained_var": 0.16707175088425477, "kl": 0.009217293876263848, "entropy": 1.0230302177990476, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 189600.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 792000, "num_env_steps_trained": 792000, "num_agent_steps_sampled": 3168000, "num_agent_steps_trained": 3168000}, "env_runners": {"episode_reward_max": 160.0, "episode_reward_min": -81.38999484455807, "episode_reward_mean": 6.83777216797845, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -81.38999484455807}, "policy_reward_max": {"adversary_policy": 80.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 5.555555555555555, "agent_policy": -9.828894498688218}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.467689717244735, 39.58445435014675, -0.1306347008190778, -5.841892281329368, -0.45913164081440194, 0.0, 12.049141425095584, -8.326926486793553, 0.0, 0.0, 20.0, 0.0, 0.0, 14.386158660176838, 0.0, 32.90816196026268, 0.0, 0.0, 0.0, -9.667240944798333, -8.896751257779908, -2.232944474555892, 0.0, 0.0, -7.8294222509033435, 18.486796904562937, 0.0, -2.830777566165229, 0.0, 0.0, -8.861078695147867, 0.0, 34.671149289201885, -7.628019119930862, 0.0, 0.0, -0.9636891544792614, 19.85921670533132, 0.0, 0.0, 0.0, -29.51395656010597, 0.0, -23.24696421892985, 0.0, 0.0, 160.0, -0.9454390541485946, -0.8885924770050591, 0.0, 0.0, -81.38999484455807, 40.0, -0.3302057422036575, 0.0, -3.7482450849118245, -20.94091500456495, 40.0, -0.38193810538976636, 0.0, 0.0, -15.727313373307084, -0.530466294162043, -1.0571237467572536, 0.0, 0.0, -3.7318271966385637, 0.0, 40.0, 40.0, 20.0, -20.630118513807645, 39.81091581879771, 0.0, -26.28050443610573, 0.0, -5.270504753408877, -1.6204627489551682, -0.6938965225544658, 40.0, 60.0, 0.0, 107.2308982048024, -14.985695563973962, 60.0, 60.0, 40.0, -11.842629443072383, -18.277806177155917, 0.0, -4.026362546027378, 0.0, 0.0, 0.0, -1.0565571602125134, -0.2632095189583761, 0.0, -11.879568986418938, 0.0, 59.608969670595116, 40.0, 40.0, -9.921112024874132, 0.0, 20.0, 60.0, 0.0, -0.20107065237608635, 40.0, 0.0, 0.0, 0.0, -11.842405557202774, 0.0, -35.518407452622654, -0.8383835907370485, 34.53338932281466, -23.514626505170025, 20.0, 0.0, 0.0, -12.792091023437742, 0.0, -5.4254241876637765, -0.27729098073451586, 0.0, 0.0, 60.0, 40.0, -41.57473504949783, 40.0, -12.961431746718377, 17.532951050444687, 20.0, 60.0, -14.194455879468528, -3.7796545012517595, -15.633279975246253, 0.0, 0.0, 0.0, 39.360423472946955, 0.0, 0.0, 0.0, -4.378757655154909, -0.03160703300998269, 10.515369890326413, 0.0, 0.0, -3.0489225687972583, -4.3044476192627315, 0.0, 20.0, 0.0, 0.0, 0.0, -6.390413258550734, -0.33990867121274637, 120.0, -2.4539832159114594, 20.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 80.0, 80.0, 80.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0], "policy_agent_policy_reward": [-20.467689717244735, -20.41554564985325, -0.1306347008190778, -5.841892281329368, -0.45913164081440194, 0.0, -17.950858574904416, -8.326926486793553, 0.0, 0.0, -10.0, 0.0, 0.0, -45.613841339823175, 0.0, -27.091838039737333, 0.0, 0.0, 0.0, -9.667240944798333, -8.896751257779908, -2.232944474555892, 0.0, 0.0, -7.8294222509033435, -11.51320309543706, 0.0, -2.830777566165229, 0.0, 0.0, -8.861078695147867, 0.0, -25.328850710798122, -7.628019119930862, 0.0, 0.0, -0.9636891544792614, -10.14078329466868, 0.0, 0.0, 0.0, -29.51395656010597, 0.0, -23.24696421892985, 0.0, 0.0, -80.0, -0.9454390541485946, -0.8885924770050591, 0.0, 0.0, -81.38999484455807, -20.0, -0.3302057422036575, 0.0, -3.7482450849118245, -20.94091500456495, -20.0, -0.38193810538976636, 0.0, 0.0, -15.727313373307084, -0.530466294162043, -1.0571237467572536, 0.0, 0.0, -3.7318271966385637, 0.0, -20.0, -20.0, -10.0, -20.630118513807645, -20.189084181202286, 0.0, -26.28050443610573, 0.0, -5.270504753408877, -1.6204627489551682, -0.6938965225544658, -20.0, -30.0, 0.0, -72.7691017951976, -14.985695563973962, -30.0, -30.0, -20.0, -11.842629443072383, -18.277806177155917, 0.0, -4.026362546027378, 0.0, 0.0, 0.0, -1.0565571602125134, -0.2632095189583761, 0.0, -11.879568986418938, 0.0, -30.391030329404888, -20.0, -20.0, -9.921112024874132, 0.0, -10.0, -30.0, 0.0, -0.20107065237608635, -20.0, 0.0, 0.0, 0.0, -11.842405557202774, 0.0, -35.518407452622654, -0.8383835907370485, -25.466610677185344, -23.514626505170025, -10.0, 0.0, 0.0, -12.792091023437742, 0.0, -5.4254241876637765, -0.27729098073451586, 0.0, 0.0, -30.0, -20.0, -41.57473504949783, -20.0, -12.961431746718377, -12.467048949555316, -10.0, -30.0, -14.194455879468528, -3.7796545012517595, -15.633279975246253, 0.0, 0.0, 0.0, -20.639576527053045, 0.0, 0.0, 0.0, -4.378757655154909, -0.03160703300998269, -19.48463010967359, 0.0, 0.0, -3.0489225687972583, -34.30444761926273, 0.0, -10.0, 0.0, 0.0, 0.0, -6.390413258550734, -0.33990867121274637, -60.0, -2.4539832159114594, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6381733847776134, "mean_inference_ms": 1.091522143385701, "mean_action_processing_ms": 0.23069824572663714, "mean_env_wait_ms": 0.4773371070161031, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005249844657050239, "StateBufferConnector_ms": 0.0036662743415361567, "ViewRequirementAgentConnector_ms": 0.09312350072978455}, "num_episodes": 162, "episode_return_max": 160.0, "episode_return_min": -81.38999484455807, "episode_return_mean": 6.83777216797845}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 3168000, "num_agent_steps_trained": 3168000, "num_env_steps_sampled": 792000, "num_env_steps_trained": 792000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 216.71239630745018, "num_env_steps_trained_throughput_per_sec": 216.71239630745018, "timesteps_total": 792000, "num_env_steps_sampled_lifetime": 792000, "num_agent_steps_sampled_lifetime": 3168000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 3168000, "timers": {"training_iteration_time_ms": 12298.206, "restore_workers_time_ms": 0.014, "training_step_time_ms": 12298.167, "sample_time_ms": 1185.645, "learn_time_ms": 11096.764, "learn_throughput": 360.465, "synch_weights_time_ms": 15.038}, "counters": {"num_env_steps_sampled": 792000, "num_env_steps_trained": 792000, "num_agent_steps_sampled": 3168000, "num_agent_steps_trained": 3168000}, "done": false, "training_iteration": 198, "trial_id": "86f16_00000", "date": "2024-08-08_16-55-24", "timestamp": 1723150524, "time_this_iter_s": 18.477508068084717, "time_total_s": 2532.726500272751, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad512820>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 2532.726500272751, "iterations_since_restore": 198, "perf": {"cpu_util_percent": 63.71923076923076, "ram_util_percent": 82.17307692307692}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4415640793212339, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.1646534088655567, "policy_loss": -0.018713091103052918, "vf_loss": 1.182494828580542, "vf_explained_var": -6.634504237073533e-07, "kl": 0.008716691672500559, "entropy": 0.42485170335845746, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 559770.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.5164518522719543, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.3713939005509017, "policy_loss": -0.042379714156656215, "vf_loss": 2.4114675975094237, "vf_explained_var": 0.10126670971512794, "kl": 0.011530124439207432, "entropy": 0.9864935067171852, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 190560.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 796000, "num_env_steps_trained": 796000, "num_agent_steps_sampled": 3184000, "num_agent_steps_trained": 3184000}, "env_runners": {"episode_reward_max": 120.0, "episode_reward_min": -23.394741447359618, "episode_reward_mean": 10.651634577675232, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -60.0}, "policy_reward_max": {"adversary_policy": 60.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 6.54320987654321, "agent_policy": -8.977995051954398}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.0, 20.0, 0.0, 20.0, 0.0, 0.0, 0.0, 20.0, -7.702136238465696, 0.0, -1.8081506472858977, 51.412320711915655, 0.0, 0.0, 0.0, 0.0, -0.045068169091228016, 0.0, 0.0, 120.0, 0.0, 38.54071766172586, -23.2521374043178, 20.0, 0.0, 35.41500541285717, 0.0, 0.0, 0.0, -14.636784598875156, 54.44379285972545, 20.0, -6.444796990188536, 57.53979539365671, 0.0, 8.096325034560403, -12.894846494952255, -7.4825697044733035, -1.950438918945565, 40.0, 60.0, 60.0, 0.0, 0.0, 100.0, 56.841654548234814, 0.0, -5.482867870000787, 40.0, -5.839183833656354, 0.0, -11.414642216986593, -0.2318040687415701, 0.0, 0.0, -8.846188088992967, 0.0, -2.770193301255274, -14.156849898550286, -6.122238762005029, -1.2376357743183397, 59.28059087214058, 0.0, 0.0, 0.0, -0.4849943331444839, 0.0, 40.0, -0.782695024293607, 40.0, -1.7911012481933242, 19.99717149144731, 0.0, 80.0, 0.0, 0.0, -1.566385531065867, -14.656029793448475, 57.740149289980096, 0.0, 0.0, 0.0, -0.006700369872686407, 0.0, -3.3407345649834976, -2.111314902478262, 0.0, 0.0, 0.0, 0.0, 0.0, 1.9513262404592346, 80.0, 0.0, 0.0, -0.011289879856798413, 40.0, -23.394741447359618, -5.532890906682742, -9.493779745913905, -4.2252211844467285, 0.0, 20.0, 0.0, 0.0, -4.22176806067581, -1.3222859937193876, 0.0, 60.0, 0.0, 0.0, -0.04152894596604062, 0.0, 20.0, 60.0, 0.0, -8.218287609615214, 0.0, 20.0, 60.0, -6.136040010958519, 0.0, -1.0635122753033255, -1.0841527996884925, 0.0, -0.5710958966850799, -6.517267210988836, 40.0, 0.0, 0.0, -5.411589748630857, 56.89707273194858, 0.0, -13.967800609213715, 33.54915866535548, 0.0, 100.0, -7.935379380046408, 58.24640893784798, -2.309399171430555, 40.0, -0.23772313943651424, 0.0, -0.49456185065700486, -7.905409523159949, 0.0, 79.69129485007387, -3.721364769207409, -0.42978152275553017, -14.412809105150622, 0.0, 0.0, 19.518207019665045, 0.0, -21.229626645273868, 59.42784397079909, 0.0, -0.014152629342424339, 0.0, -13.817240698321156, -2.2448445999365685, 40.0], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 60.0, 60.0, 60.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0], "policy_agent_policy_reward": [-20.0, -10.0, 0.0, -10.0, 0.0, 0.0, 0.0, -10.0, -7.702136238465696, 0.0, -1.8081506472858977, -38.58767928808435, 0.0, 0.0, 0.0, 0.0, -0.045068169091228016, 0.0, 0.0, -60.0, 0.0, -21.459282338274143, -23.2521374043178, -10.0, 0.0, -24.584994587142834, 0.0, 0.0, 0.0, -14.636784598875156, -35.556207140274545, -10.0, -6.444796990188536, -32.46020460634329, 0.0, -21.903674965439595, -12.894846494952255, -7.4825697044733035, -1.950438918945565, -20.0, -30.0, -30.0, 0.0, 0.0, -50.0, -33.158345451765186, 0.0, -5.482867870000787, -20.0, -5.839183833656354, 0.0, -11.414642216986593, -0.2318040687415701, 0.0, 0.0, -8.846188088992967, 0.0, -2.770193301255274, -14.156849898550286, -6.122238762005029, -1.2376357743183397, -30.71940912785943, 0.0, 0.0, 0.0, -0.4849943331444839, 0.0, -20.0, -0.782695024293607, -20.0, -1.7911012481933242, -10.002828508552689, 0.0, -40.0, 0.0, 0.0, -1.566385531065867, -14.656029793448475, -32.259850710019904, 0.0, 0.0, 0.0, -0.006700369872686407, 0.0, -3.3407345649834976, -2.111314902478262, 0.0, 0.0, 0.0, 0.0, 0.0, -28.048673759540765, -40.0, 0.0, 0.0, -0.011289879856798413, -20.0, -23.394741447359618, -5.532890906682742, -9.493779745913905, -4.2252211844467285, 0.0, -10.0, 0.0, 0.0, -4.22176806067581, -1.3222859937193876, 0.0, -30.0, 0.0, 0.0, -0.04152894596604062, 0.0, -10.0, -30.0, 0.0, -8.218287609615214, 0.0, -10.0, -30.0, -6.136040010958519, 0.0, -1.0635122753033255, -1.0841527996884925, 0.0, -0.5710958966850799, -6.517267210988836, -20.0, 0.0, 0.0, -5.411589748630857, -33.10292726805141, 0.0, -13.967800609213715, -26.450841334644526, 0.0, -50.0, -7.935379380046408, -31.75359106215203, -2.309399171430555, -20.0, -0.23772313943651424, 0.0, -0.49456185065700486, -7.905409523159949, 0.0, -40.30870514992612, -3.721364769207409, -0.42978152275553017, -14.412809105150622, 0.0, 0.0, -10.481792980334955, 0.0, -21.229626645273868, -30.572156029200908, 0.0, -0.014152629342424339, 0.0, -13.817240698321156, -2.2448445999365685, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6383614696415364, "mean_inference_ms": 1.092011893270508, "mean_action_processing_ms": 0.23072582246463977, "mean_env_wait_ms": 0.4775432986515798, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0051747869562219695, "StateBufferConnector_ms": 0.0033711945569073714, "ViewRequirementAgentConnector_ms": 0.09801748358173135}, "num_episodes": 162, "episode_return_max": 120.0, "episode_return_min": -23.394741447359618, "episode_return_mean": 10.651634577675232}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 3184000, "num_agent_steps_trained": 3184000, "num_env_steps_sampled": 796000, "num_env_steps_trained": 796000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 213.8523038015776, "num_env_steps_trained_throughput_per_sec": 213.8523038015776, "timesteps_total": 796000, "num_env_steps_sampled_lifetime": 796000, "num_agent_steps_sampled_lifetime": 3184000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 3184000, "timers": {"training_iteration_time_ms": 13019.374, "restore_workers_time_ms": 0.014, "training_step_time_ms": 13019.334, "sample_time_ms": 1175.15, "learn_time_ms": 11827.664, "learn_throughput": 338.19, "synch_weights_time_ms": 15.802}, "counters": {"num_env_steps_sampled": 796000, "num_env_steps_trained": 796000, "num_agent_steps_sampled": 3184000, "num_agent_steps_trained": 3184000}, "done": false, "training_iteration": 199, "trial_id": "86f16_00000", "date": "2024-08-08_16-55-43", "timestamp": 1723150543, "time_this_iter_s": 18.715086936950684, "time_total_s": 2551.4415872097015, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad512d30>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 2551.4415872097015, "iterations_since_restore": 199, "perf": {"cpu_util_percent": 62.49629629629631, "ram_util_percent": 82.27777777777777}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"adversary_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.43120999135975296, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.2499756675345677, "policy_loss": -0.018130867276175595, "vf_loss": 1.2672964685352137, "vf_explained_var": -4.1979001768937347e-07, "kl": 0.00810064931461557, "entropy": 0.420511094961606, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 127.65957446808511, "num_grad_updates_lifetime": 562590.5, "diff_num_grad_updates_vs_sampler_policy": 1409.5}, "agent_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.53284307581683, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.518059622310102, "policy_loss": -0.03745995479063519, "vf_loss": 2.5534869944055876, "vf_explained_var": 0.13192375575502713, "kl": 0.010162874977245951, "entropy": 0.9974630232900381, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 191520.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 800000, "num_env_steps_trained": 800000, "num_agent_steps_sampled": 3200000, "num_agent_steps_trained": 3200000}, "env_runners": {"episode_reward_max": 140.0, "episode_reward_min": -29.785954308657274, "episode_reward_mean": 10.815121608521569, "episode_len_mean": 25.0, "episode_media": {}, "episodes_this_iter": 162, "episodes_timesteps_total": 4050, "policy_reward_min": {"adversary_policy": 0.0, "agent_policy": -70.0}, "policy_reward_max": {"adversary_policy": 70.0, "agent_policy": 0.0}, "policy_reward_mean": {"adversary_policy": 6.666666666666667, "agent_policy": -9.184878391478431}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-7.845107067458649, 0.0, 60.0, -7.043532046656849, -5.329697020028007, -0.4233667183895151, 37.08385978437974, -5.798308677393047, 20.0, 20.0, -7.074334925924812, 39.41639097118307, 39.84670145712804, -1.6074655131673377, 0.0, 0.0, -8.53718902960114, 0.0, 40.0, 0.0, 60.0, 40.0, 0.0, -9.047550657287967, 0.0, 0.0, 19.8410887467842, 0.0, 0.0, 0.0, -8.474745844397795, 20.0, -0.8940653235936757, -5.189031694121344, 80.0, 0.0, 0.0, -7.597950420678905, 0.0, 55.60060047742221, 0.0, 0.0, 0.0, 0.0, 0.0, -1.1271842795492026, 0.0, -2.929074963415629, 39.742013230152466, 40.0, 0.0, 20.0, 0.0, 40.0, 0.0, 0.0, -3.0827135459962314, 20.0, 0.0, -2.9231606206145377, 60.0, -29.785954308657274, -9.027265465016196, 20.0, -0.35894184801782747, 17.38010028839206, -0.37997681896933533, 0.0, 20.0, 40.0, -6.715838434709243, 17.455447766477334, 0.0, -1.2876107202318854, 0.0, 0.0, 53.29061406147724, -2.3346864510534613, 20.0, -2.1660786066291116, -2.418617084210813, 0.0, -0.012085523057022707, 40.0, -3.691171391615425, 0.0, -1.6361254840467732, -13.214971705020023, 0.0, 93.62522887279974, -0.10893930148953346, 0.0, -11.125296001824662, 0.0, 17.304920474305117, -14.325763215822777, 80.0, 0.0, -14.849835909254038, 14.944208167685439, 0.0, 39.456374522042445, -0.8829224400131785, 60.0, 0.0, 20.0, -0.23863970725880757, 27.08574430265008, 20.0, -3.9700817262288526, 20.0, 40.0, 0.0, 0.0, 0.0, -0.07435780478969645, 0.0, -18.22965401061705, -3.950374251676095, -8.865849699409013, -0.5394505910757241, 39.185717076867746, -0.7744438053701397, -8.817768902037047, 0.0, 0.0, -1.3918263546807186, 0.0, 39.31916691347638, 0.0, 0.0, 0.0, 0.0, 0.0, -5.0371670972768845, 44.31252416821662, 60.0, 20.0, 0.0, 43.708985490652445, -0.6334038530130304, 0.0, 20.0, 0.0, 140.0, -4.472238862246449, 0.0, -13.698392937919802, 20.0, 16.38182505384696, 40.0, 0.0, 0.0, -14.871421674712252, -7.136850492451914, -1.5510575257375503, 78.94261721990316, 0.0, 0.0, 79.76830105339484, -4.601240974051914, -3.54195019027709], "episode_lengths": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25], "policy_adversary_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 70.0, 70.0, 70.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "policy_agent_policy_reward": [-7.845107067458649, 0.0, -30.0, -7.043532046656849, -5.329697020028007, -0.4233667183895151, -22.916140215620263, -5.798308677393047, -10.0, -10.0, -7.074334925924812, -20.58360902881693, -20.15329854287196, -1.6074655131673377, 0.0, 0.0, -8.53718902960114, 0.0, -20.0, 0.0, -30.0, -20.0, 0.0, -9.047550657287967, 0.0, 0.0, -10.158911253215797, 0.0, 0.0, 0.0, -8.474745844397795, -10.0, -0.8940653235936757, -5.189031694121344, -40.0, 0.0, 0.0, -7.597950420678905, 0.0, -64.39939952257777, 0.0, 0.0, 0.0, 0.0, 0.0, -1.1271842795492026, 0.0, -2.929074963415629, -20.25798676984753, -20.0, 0.0, -10.0, 0.0, -20.0, 0.0, 0.0, -3.0827135459962314, -10.0, 0.0, -2.9231606206145377, -30.0, -29.785954308657274, -9.027265465016196, -10.0, -0.35894184801782747, -12.619899711607939, -0.37997681896933533, 0.0, -10.0, -20.0, -6.715838434709243, -12.544552233522664, 0.0, -1.2876107202318854, 0.0, 0.0, -36.709385938522765, -2.3346864510534613, -10.0, -2.1660786066291116, -2.418617084210813, 0.0, -0.012085523057022707, -20.0, -3.691171391615425, 0.0, -1.6361254840467732, -13.214971705020023, 0.0, -56.37477112720027, -0.10893930148953346, 0.0, -11.125296001824662, 0.0, -12.695079525694883, -14.325763215822777, -40.0, 0.0, -14.849835909254038, -15.055791832314558, 0.0, -20.543625477957555, -0.8829224400131785, -30.0, 0.0, -10.0, -0.23863970725880757, -32.91425569734992, -10.0, -3.9700817262288526, -10.0, -20.0, 0.0, 0.0, 0.0, -0.07435780478969645, 0.0, -18.22965401061705, -3.950374251676095, -8.865849699409013, -0.5394505910757241, -20.814282923132257, -0.7744438053701397, -8.817768902037047, 0.0, 0.0, -1.3918263546807186, 0.0, -20.68083308652362, 0.0, 0.0, 0.0, 0.0, 0.0, -5.0371670972768845, -45.68747583178338, -30.0, -10.0, 0.0, -46.291014509347555, -0.6334038530130304, 0.0, -10.0, 0.0, -70.0, -4.472238862246449, 0.0, -13.698392937919802, -10.0, -13.61817494615304, -20.0, 0.0, 0.0, -14.871421674712252, -7.136850492451914, -1.5510575257375503, -41.05738278009684, 0.0, 0.0, -40.231698946605164, -4.601240974051914, -3.54195019027709]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.639330479748948, "mean_inference_ms": 1.0932519977326134, "mean_action_processing_ms": 0.2308449267595315, "mean_env_wait_ms": 0.478000662231855, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00661788163361726, "StateBufferConnector_ms": 0.0041601098613974485, "ViewRequirementAgentConnector_ms": 0.109993381264769}, "num_episodes": 162, "episode_return_max": 140.0, "episode_return_min": -29.785954308657274, "episode_return_mean": 10.815121608521569}, "num_healthy_workers": 9, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 3200000, "num_agent_steps_trained": 3200000, "num_env_steps_sampled": 800000, "num_env_steps_trained": 800000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 290.75377634936257, "num_env_steps_trained_throughput_per_sec": 290.75377634936257, "timesteps_total": 800000, "num_env_steps_sampled_lifetime": 800000, "num_agent_steps_sampled_lifetime": 3200000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 3200000, "timers": {"training_iteration_time_ms": 13271.372, "restore_workers_time_ms": 0.014, "training_step_time_ms": 13271.331, "sample_time_ms": 1216.104, "learn_time_ms": 12038.062, "learn_throughput": 332.279, "synch_weights_time_ms": 16.266}, "counters": {"num_env_steps_sampled": 800000, "num_env_steps_trained": 800000, "num_agent_steps_sampled": 3200000, "num_agent_steps_trained": 3200000}, "done": true, "training_iteration": 200, "trial_id": "86f16_00000", "date": "2024-08-08_16-55-57", "timestamp": 1723150557, "time_this_iter_s": 13.794877052307129, "time_total_s": 2565.2364642620087, "pid": 24053, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "simple_tag_v3", "env_config": {}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_env_runner": 1, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad512f70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "always_attach_evaluation_results": true, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"adversary_policy": [null, "Box(-inf, inf, (16,), float32)", "Discrete(5)", {}], "agent_policy": [null, "Box(-inf, inf, (14,), float32)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 9, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "num_learner_workers": 0, "num_cpus_per_learner_worker": 1, "num_gpus_per_learner_worker": 0}, "time_since_restore": 2565.2364642620087, "iterations_since_restore": 200, "perf": {"cpu_util_percent": 44.93157894736842, "ram_util_percent": 82.34736842105264}}
