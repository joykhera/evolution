{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4734641798274226, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 6.13313038765438, "policy_loss": -0.017084104592650733, "vf_loss": 6.148457911405614, "vf_explained_var": 0.03395344205003567, "kl": 0.008782795674990488, "entropy": 1.6021194951244133, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 945.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3756336316545175, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 7.330466545195806, "policy_loss": -0.014324138010112893, "vf_loss": 7.343018871640402, "vf_explained_var": 0.02843405724202514, "kl": 0.008858974352380429, "entropy": 1.601989308488432, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 945.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 4000, "num_env_steps_trained": 4000, "num_agent_steps_sampled": 16000, "num_agent_steps_trained": 16000}, "env_runners": {"episode_reward_max": NaN, "episode_reward_min": NaN, "episode_reward_mean": NaN, "episode_len_mean": NaN, "episode_media": {}, "episodes_timesteps_total": 0, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [], "episode_lengths": []}, "sampler_perf": {}, "num_faulty_episodes": 0, "connector_metrics": {}, "num_episodes": 0, "episode_return_max": NaN, "episode_return_min": NaN, "episode_return_mean": NaN, "episodes_this_iter": 0}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 16000, "num_agent_steps_trained": 16000, "num_env_steps_sampled": 4000, "num_env_steps_trained": 4000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 76.85055783089429, "num_env_steps_trained_throughput_per_sec": 76.85055783089429, "timesteps_total": 4000, "num_env_steps_sampled_lifetime": 4000, "num_agent_steps_sampled_lifetime": 16000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 16000, "timers": {"training_iteration_time_ms": 52049.08, "restore_workers_time_ms": 0.019, "training_step_time_ms": 52049.017, "sample_time_ms": 3596.93, "learn_time_ms": 48433.101, "learn_throughput": 82.588, "synch_weights_time_ms": 14.163}, "counters": {"num_env_steps_sampled": 4000, "num_env_steps_trained": 4000, "num_agent_steps_sampled": 16000, "num_agent_steps_trained": 16000}, "done": false, "training_iteration": 1, "trial_id": "798d9_00000", "date": "2024-08-22_09-38-13", "timestamp": 1724299693, "time_this_iter_s": 52.11087203025818, "time_total_s": 52.11087203025818, "pid": 48427, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"prey_count": 2, "prey_speed": 1.0, "prey_view_size": 10, "prey_size": 1, "prey_color": [0, 255, 0], "prey_kill_reward": -10, "prey_alive_reward": 0.1, "prey_reward_sqr_reward": 1, "predator_count": 2, "predator_speed": 1.0, "predator_view_size": 10, "predator_size": 1, "predator_color": [255, 0, 0], "predator_kill_reward": 10, "map_size": 40, "max_steps": 400, "screen_size": 600, "render_mode": "None", "fps": 60}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 8, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": true, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 1, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "custom_cnn", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x300ba5af0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 52.11087203025818, "iterations_since_restore": 1, "perf": {"cpu_util_percent": 37.76133333333333, "ram_util_percent": 83.616}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.877704674163193, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 4.224525637349124, "policy_loss": -0.021546652018235475, "vf_loss": 4.244180307060322, "vf_explained_var": 0.10027545690536499, "kl": 0.009459940111572564, "entropy": 1.5924444688060295, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 2835.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.3881435370319104, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 6.70505492170021, "policy_loss": -0.021834170556055608, "vf_loss": 6.724923834725032, "vf_explained_var": 0.10531764714806169, "kl": 0.00982631894140184, "entropy": 1.5879779866763524, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 2835.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 8000, "num_env_steps_trained": 8000, "num_agent_steps_sampled": 32000, "num_agent_steps_trained": 32000}, "env_runners": {"episode_reward_max": NaN, "episode_reward_min": NaN, "episode_reward_mean": NaN, "episode_len_mean": NaN, "episode_media": {}, "episodes_timesteps_total": 0, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [], "episode_lengths": []}, "sampler_perf": {}, "num_faulty_episodes": 0, "connector_metrics": {}, "num_episodes": 0, "episode_return_max": NaN, "episode_return_min": NaN, "episode_return_mean": NaN, "episodes_this_iter": 0}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 32000, "num_agent_steps_trained": 32000, "num_env_steps_sampled": 8000, "num_env_steps_trained": 8000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 75.84805025912736, "num_env_steps_trained_throughput_per_sec": 75.84805025912736, "timesteps_total": 8000, "num_env_steps_sampled_lifetime": 8000, "num_agent_steps_sampled_lifetime": 32000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 32000, "timers": {"training_iteration_time_ms": 52393.058, "restore_workers_time_ms": 0.023, "training_step_time_ms": 52392.986, "sample_time_ms": 3677.251, "learn_time_ms": 48695.464, "learn_throughput": 82.143, "synch_weights_time_ms": 15.752}, "counters": {"num_env_steps_sampled": 8000, "num_env_steps_trained": 8000, "num_agent_steps_sampled": 32000, "num_agent_steps_trained": 32000}, "done": false, "training_iteration": 2, "trial_id": "798d9_00000", "date": "2024-08-22_09-39-08", "timestamp": 1724299748, "time_this_iter_s": 52.773138761520386, "time_total_s": 104.88401079177856, "pid": 48427, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"prey_count": 2, "prey_speed": 1.0, "prey_view_size": 10, "prey_size": 1, "prey_color": [0, 255, 0], "prey_kill_reward": -10, "prey_alive_reward": 0.1, "prey_reward_sqr_reward": 1, "predator_count": 2, "predator_speed": 1.0, "predator_view_size": 10, "predator_size": 1, "predator_color": [255, 0, 0], "predator_kill_reward": 10, "map_size": 40, "max_steps": 400, "screen_size": 600, "render_mode": "None", "fps": 60}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 8, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": true, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 1, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "custom_cnn", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a94fadc0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 104.88401079177856, "iterations_since_restore": 2, "perf": {"cpu_util_percent": 37.43291139240506, "ram_util_percent": 83.46582278481011}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.9726406622500647, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 3.149449306442624, "policy_loss": -0.019662064398767023, "vf_loss": 3.167247870485619, "vf_explained_var": 0.11861768169377847, "kl": 0.009317504409910056, "entropy": 1.5814641606870783, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 4725.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.239556384338903, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 5.8541438508916785, "policy_loss": -0.02268731363866695, "vf_loss": 5.874409443991524, "vf_explained_var": 0.176360330001387, "kl": 0.012108480207075084, "entropy": 1.5698997095779137, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 4725.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 12000, "num_env_steps_trained": 12000, "num_agent_steps_sampled": 48000, "num_agent_steps_trained": 48000}, "env_runners": {"episode_reward_max": NaN, "episode_reward_min": NaN, "episode_reward_mean": NaN, "episode_len_mean": NaN, "episode_media": {}, "episodes_timesteps_total": 0, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [], "episode_lengths": []}, "sampler_perf": {}, "num_faulty_episodes": 0, "connector_metrics": {}, "num_episodes": 0, "episode_return_max": NaN, "episode_return_min": NaN, "episode_return_mean": NaN, "episodes_this_iter": 0}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 48000, "num_agent_steps_trained": 48000, "num_env_steps_sampled": 12000, "num_env_steps_trained": 12000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 76.54239273238676, "num_env_steps_trained_throughput_per_sec": 76.54239273238676, "timesteps_total": 12000, "num_env_steps_sampled_lifetime": 12000, "num_agent_steps_sampled_lifetime": 48000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 48000, "timers": {"training_iteration_time_ms": 52348.248, "restore_workers_time_ms": 0.021, "training_step_time_ms": 52348.182, "sample_time_ms": 3296.459, "learn_time_ms": 49032.829, "learn_throughput": 81.578, "synch_weights_time_ms": 14.923}, "counters": {"num_env_steps_sampled": 12000, "num_env_steps_trained": 12000, "num_agent_steps_sampled": 48000, "num_agent_steps_trained": 48000}, "done": false, "training_iteration": 3, "trial_id": "798d9_00000", "date": "2024-08-22_09-40-01", "timestamp": 1724299801, "time_this_iter_s": 52.298826932907104, "time_total_s": 157.18283772468567, "pid": 48427, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"prey_count": 2, "prey_speed": 1.0, "prey_view_size": 10, "prey_size": 1, "prey_color": [0, 255, 0], "prey_kill_reward": -10, "prey_alive_reward": 0.1, "prey_reward_sqr_reward": 1, "predator_count": 2, "predator_speed": 1.0, "predator_view_size": 10, "predator_size": 1, "predator_color": [255, 0, 0], "predator_kill_reward": 10, "map_size": 40, "max_steps": 400, "screen_size": 600, "render_mode": "None", "fps": 60}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 8, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": true, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 1, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "custom_cnn", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x300bbeca0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 157.18283772468567, "iterations_since_restore": 3, "perf": {"cpu_util_percent": 37.624, "ram_util_percent": 82.88933333333334}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.5172943607839957, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 2.7481986136663528, "policy_loss": -0.02170921632004951, "vf_loss": 2.7681812246640525, "vf_explained_var": 0.17530686729168765, "kl": 0.008633039767420284, "entropy": 1.5692116778994363, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 6615.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.703461316495976, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 5.6241823789303895, "policy_loss": -0.020008343282998317, "vf_loss": 5.642146912327519, "vf_explained_var": 0.17902243641949206, "kl": 0.010219027076616252, "entropy": 1.5664556871015558, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 6615.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 16000, "num_env_steps_trained": 16000, "num_agent_steps_sampled": 64000, "num_agent_steps_trained": 64000}, "env_runners": {"episode_reward_max": NaN, "episode_reward_min": NaN, "episode_reward_mean": NaN, "episode_len_mean": NaN, "episode_media": {}, "episodes_timesteps_total": 0, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [], "episode_lengths": []}, "sampler_perf": {}, "num_faulty_episodes": 0, "connector_metrics": {}, "num_episodes": 0, "episode_return_max": NaN, "episode_return_min": NaN, "episode_return_mean": NaN, "episodes_this_iter": 0}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 64000, "num_agent_steps_trained": 64000, "num_env_steps_sampled": 16000, "num_env_steps_trained": 16000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 81.624132447644, "num_env_steps_trained_throughput_per_sec": 81.624132447644, "timesteps_total": 16000, "num_env_steps_sampled_lifetime": 16000, "num_agent_steps_sampled_lifetime": 64000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 64000, "timers": {"training_iteration_time_ms": 51512.467, "restore_workers_time_ms": 0.02, "training_step_time_ms": 51512.405, "sample_time_ms": 3049.786, "learn_time_ms": 48444.675, "learn_throughput": 82.568, "synch_weights_time_ms": 14.373}, "counters": {"num_env_steps_sampled": 16000, "num_env_steps_trained": 16000, "num_agent_steps_sampled": 64000, "num_agent_steps_trained": 64000}, "done": false, "training_iteration": 4, "trial_id": "798d9_00000", "date": "2024-08-22_09-40-50", "timestamp": 1724299850, "time_this_iter_s": 49.075852155685425, "time_total_s": 206.2586898803711, "pid": 48427, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"prey_count": 2, "prey_speed": 1.0, "prey_view_size": 10, "prey_size": 1, "prey_color": [0, 255, 0], "prey_kill_reward": -10, "prey_alive_reward": 0.1, "prey_reward_sqr_reward": 1, "predator_count": 2, "predator_speed": 1.0, "predator_view_size": 10, "predator_size": 1, "predator_color": [255, 0, 0], "predator_kill_reward": 10, "map_size": 40, "max_steps": 400, "screen_size": 600, "render_mode": "None", "fps": 60}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 8, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": true, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 1, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "custom_cnn", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x300bbe8b0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 206.2586898803711, "iterations_since_restore": 4, "perf": {"cpu_util_percent": 29.204347826086956, "ram_util_percent": 83.01884057971014}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.111159311053614, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 2.9888299330832466, "policy_loss": -0.023652155665562502, "vf_loss": 3.0103007436429383, "vf_explained_var": 0.17239252432944283, "kl": 0.010906724886544955, "entropy": 1.548081857123703, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 8505.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.817110021467562, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 5.899619074473305, "policy_loss": -0.026150839573151813, "vf_loss": 5.92295818152251, "vf_explained_var": 0.21870409042116196, "kl": 0.014058586988332017, "entropy": 1.5387056117335325, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 8505.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 20000, "num_env_steps_trained": 20000, "num_agent_steps_sampled": 80000, "num_agent_steps_trained": 80000}, "env_runners": {"episode_reward_max": NaN, "episode_reward_min": NaN, "episode_reward_mean": NaN, "episode_len_mean": NaN, "episode_media": {}, "episodes_timesteps_total": 0, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [], "episode_lengths": []}, "sampler_perf": {}, "num_faulty_episodes": 0, "connector_metrics": {}, "num_episodes": 0, "episode_return_max": NaN, "episode_return_min": NaN, "episode_return_mean": NaN, "episodes_this_iter": 0}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 80000, "num_agent_steps_trained": 80000, "num_env_steps_sampled": 20000, "num_env_steps_trained": 20000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 77.84495893797403, "num_env_steps_trained_throughput_per_sec": 77.84495893797403, "timesteps_total": 20000, "num_env_steps_sampled_lifetime": 20000, "num_agent_steps_sampled_lifetime": 80000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 80000, "timers": {"training_iteration_time_ms": 51486.813, "restore_workers_time_ms": 0.019, "training_step_time_ms": 51486.752, "sample_time_ms": 3406.283, "learn_time_ms": 48062.095, "learn_throughput": 83.226, "synch_weights_time_ms": 14.475}, "counters": {"num_env_steps_sampled": 20000, "num_env_steps_trained": 20000, "num_agent_steps_sampled": 80000, "num_agent_steps_trained": 80000}, "done": false, "training_iteration": 5, "trial_id": "798d9_00000", "date": "2024-08-22_09-41-41", "timestamp": 1724299901, "time_this_iter_s": 51.44613695144653, "time_total_s": 257.7048268318176, "pid": 48427, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"prey_count": 2, "prey_speed": 1.0, "prey_view_size": 10, "prey_size": 1, "prey_color": [0, 255, 0], "prey_kill_reward": -10, "prey_alive_reward": 0.1, "prey_reward_sqr_reward": 1, "predator_count": 2, "predator_speed": 1.0, "predator_view_size": 10, "predator_size": 1, "predator_color": [255, 0, 0], "predator_kill_reward": 10, "map_size": 40, "max_steps": 400, "screen_size": 600, "render_mode": "None", "fps": 60}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 8, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": true, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 1, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "custom_cnn", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x300bf5a60>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 257.7048268318176, "iterations_since_restore": 5, "perf": {"cpu_util_percent": 32.324657534246576, "ram_util_percent": 83.33835616438357}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.930572068155127, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 2.536854064906085, "policy_loss": -0.02139007940779997, "vf_loss": 2.5559133220601966, "vf_explained_var": 0.14473502951324302, "kl": 0.011654094372575403, "entropy": 1.5377151969879392, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 10395.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.13959185004865, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 5.818001900021992, "policy_loss": -0.02289135222022653, "vf_loss": 5.838058575625142, "vf_explained_var": 0.28275316616214774, "kl": 0.014173386442578501, "entropy": 1.5347417131933585, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 10395.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 24000, "num_env_steps_trained": 24000, "num_agent_steps_sampled": 96000, "num_agent_steps_trained": 96000}, "env_runners": {"episode_reward_max": NaN, "episode_reward_min": NaN, "episode_reward_mean": NaN, "episode_len_mean": NaN, "episode_media": {}, "episodes_timesteps_total": 0, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [], "episode_lengths": []}, "sampler_perf": {}, "num_faulty_episodes": 0, "connector_metrics": {}, "num_episodes": 0, "episode_return_max": NaN, "episode_return_min": NaN, "episode_return_mean": NaN, "episodes_this_iter": 0}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 96000, "num_agent_steps_trained": 96000, "num_env_steps_sampled": 24000, "num_env_steps_trained": 24000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 80.7316855645607, "num_env_steps_trained_throughput_per_sec": 80.7316855645607, "timesteps_total": 24000, "num_env_steps_sampled_lifetime": 24000, "num_agent_steps_sampled_lifetime": 96000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 96000, "timers": {"training_iteration_time_ms": 51163.485, "restore_workers_time_ms": 0.018, "training_step_time_ms": 51163.428, "sample_time_ms": 3267.627, "learn_time_ms": 47877.641, "learn_throughput": 83.546, "synch_weights_time_ms": 14.127}, "counters": {"num_env_steps_sampled": 24000, "num_env_steps_trained": 24000, "num_agent_steps_sampled": 96000, "num_agent_steps_trained": 96000}, "done": false, "training_iteration": 6, "trial_id": "798d9_00000", "date": "2024-08-22_09-42-31", "timestamp": 1724299951, "time_this_iter_s": 49.59078097343445, "time_total_s": 307.2956078052521, "pid": 48427, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"prey_count": 2, "prey_speed": 1.0, "prey_view_size": 10, "prey_size": 1, "prey_color": [0, 255, 0], "prey_kill_reward": -10, "prey_alive_reward": 0.1, "prey_reward_sqr_reward": 1, "predator_count": 2, "predator_speed": 1.0, "predator_view_size": 10, "predator_size": 1, "predator_color": [255, 0, 0], "predator_kill_reward": 10, "map_size": 40, "max_steps": 400, "screen_size": 600, "render_mode": "None", "fps": 60}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 8, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": true, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 1, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "custom_cnn", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x300bebee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 307.2956078052521, "iterations_since_restore": 6, "perf": {"cpu_util_percent": 31.083098591549298, "ram_util_percent": 83.35211267605634}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.159799304872593, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 2.9125207617169333, "policy_loss": -0.019355708117862896, "vf_loss": 2.9295638257233554, "vf_explained_var": 0.1547569337345305, "kl": 0.011563212238252163, "entropy": 1.5196676478814826, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 12285.5, "diff_num_grad_updates_vs_sampler_policy": 970.9599999999992}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 6.549966854487778, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 6.135185378190702, "policy_loss": -0.019264208859759113, "vf_loss": 6.151666790341574, "vf_explained_var": 0.3801407943957697, "kl": 0.013913960194599534, "entropy": 1.513386822188342, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 12285.5, "diff_num_grad_updates_vs_sampler_policy": 970.9599999999992}}, "num_env_steps_sampled": 28000, "num_env_steps_trained": 28000, "num_agent_steps_sampled": 112000, "num_agent_steps_trained": 112000}, "env_runners": {"episode_reward_max": 587.3999999999996, "episode_reward_min": 39.693152979228174, "episode_reward_mean": 264.82637561545073, "episode_len_mean": 400.0, "episode_media": {}, "episodes_timesteps_total": 18800, "policy_reward_min": {"prey_policy": -477.1636031426591, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 322.04191172763416, "predator_policy": 518.7387046770302}, "policy_reward_mean": {"prey_policy": -29.946432831932274, "predator_policy": 162.35962063965752}, "custom_metrics": {}, "hist_stats": {"episode_reward": [319.1000000000001, 395.91670796862, 125.96728212614214, 238.29999999999967, 212.7999999999985, 428.3274543974187, 306.3000000000013, 213.00015544486337, 424.24817610832963, 372.7000000000017, 351.89999999999907, 231.49999999999957, 174.43764546793366, 299.30000000000024, 440.11677977558287, 269.69999999999936, 538.9000000000005, 69.39756159241745, 587.3999999999996, 101.39999999999952, 119.29999999999697, 58.90000000000063, 63.712629493019854, 290.4925445973529, 241.13223304703237, 370.91663916018183, 358.9168236676343, 46.22202152717898, 211.1999999999996, 229.8999999999992, 368.2999999999993, 499.59999999999957, 305.39989239170626, 457.21081085698455, 138.59619829468053, 320.3231343679938, 253.4824225396431, 73.20000000000012, 39.693152979228174, 53.10000000000048, 372.01587367805865, 307.3999999999987, 52.08329168814634, 554.6136088493297, 73.4000000000001, 172.51661390670918, 314.5000000000002], "episode_lengths": [400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400], "policy_prey_policy_reward": [-33.48037747491744, 176.85623681481698, 26.430160761868635, -40.80481575322529, -173.39070401103916, -171.3907030189248, 184.2055053785144, -144.24432468529602, -7.148732506932676, -97.50055547741172, 11.668652477698977, 10.439842883486808, -152.30137464931465, -9.089360841830988, -135.36871088700246, -95.54433928398602, -161.21227492671034, 202.85323002231996, 33.13768373886731, 322.04191172763416, -37.88776262828977, 47.145506778500135, 79.98681403610979, -35.54340206319812, -188.1825260251033, 53.863974149791545, 246.20772292820098, -219.907991862822, 112.90225687216196, 126.08218511344265, -119.89548173449305, 79.90215770710263, 184.64258542943114, 190.44424775395328, -160.39244496516926, -132.12054811527494, 153.15452921752927, 319.01022357853276, -220.4603417719081, -44.60611747215477, 45.32770716481234, -147.87397598511114, -373.2080565725788, 18.453981624907964, -51.596342986116674, -432.2351876430542, -147.72077693286056, 30.750946971532784, -8.718594784215925, -77.57449877795553, 131.13359888055848, -76.41282741795835, -477.1636031426591, 152.41076216226548, -80.19598183366223, -124.64586702835348, 105.72869619249329, -1.9648889639130256, 55.48568529917049, -45.85455682559444, -62.40214191856839, 17.106722822609925, 87.69666749873406, 268.67402215929803, -50.38696514624137, -144.31431379636612, 65.05585552829419, 33.2460114701502, -13.098430599916068, -268.74883978781844, -11.294394465164757, 181.0634570921933, -16.92513187805305, 96.05843008442278, 14.478941326969109, -67.6590653950308, -118.55555651412521, -177.47588274825026, -189.77188382911984, -304.2946627024392, -254.73581174384054, 154.55987377587115, 82.78844862012033, 50.9480959558138, -451.7500226859305, 4.008634089920729, 103.88041434574149, 24.658147649416875, -162.9990322437011, -94.07113095617306, -170.69966320539146, -130.05132947249965, -153.03879348548688, 168.45588733626113], "policy_predator_policy_reward": [68.78037747491791, 106.94376318518296, 21.13203856478976, 389.1593243951866, 243.19070401103826, 227.55798514506557, 198.33881930678086, 0.0, 295.188372311621, 22.260915672723804, 195.88045965349966, 210.33849938273266, 210.6013746493134, 257.0893608418309, 171.94888861910482, 271.96431699674616, 379.348394331207, 3.2588266815118128, 17.520404533498784, 0.0, 261.28776262828944, 81.35449322150023, 23.35436496989366, 163.70222305719363, 257.4705363999939, 51.28566094325446, 161.37833142999125, 111.62193750462882, 152.49653707460456, 48.63580071537401, 153.195481734492, 156.49784229289745, 135.85741457056884, 27.955752246046575, 207.80547173975793, 154.10508293310434, 72.14547078247037, 43.089776421467214, 288.460341771907, 78.00611747215531, 39.072292835188115, 182.77397598510922, 393.5080565725784, 20.14601837509204, 122.12312720547139, 425.42103291672123, 301.2043479921501, 106.25802656652952, 27.284954916112756, 300.1403716930912, 175.8289647421534, 140.36690295542982, 518.7387046770302, 164.93095997099812, 94.06031235660068, 157.00355803259416, 68.77130380750701, 38.664888963913185, 19.01431470082947, 201.2545568255937, 177.30214191856723, 236.29327717738977, 72.07984358427261, 71.14946675769549, 293.5438991777642, 206.55727215654974, 53.51669053940074, 305.3922533191393, 133.96264308871412, 286.4808255937011, 116.00686985184572, 34.547201889119435, 113.36344017054255, 60.98568416273251, 23.621058673030827, 102.7590653950288, 120.34840462746682, 215.3761876141331, 218.97188382911824, 328.1946627024382, 319.2819639355882, 152.90984771044035, 81.77853761281452, 91.88491781125136, 495.9666294389831, 3.858050845174355, 152.21273182395146, 273.86231503021935, 192.6990322436994, 137.77113095617173, 437.37365659266703, 35.89394999193405, 28.794920199800845, 270.2879859494245]}, "sampler_perf": {"mean_raw_obs_processing_ms": 4.7865608021269335, "mean_inference_ms": 4.782135049805237, "mean_action_processing_ms": 2.8091103393335333, "mean_env_wait_ms": 10.15002463799624, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.013148531000664893, "StateBufferConnector_ms": 0.006137502954361287, "ViewRequirementAgentConnector_ms": 0.1372626487244951}, "num_episodes": 47, "episode_return_max": 587.3999999999996, "episode_return_min": 39.693152979228174, "episode_return_mean": 264.82637561545073, "episodes_this_iter": 47}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 112000, "num_agent_steps_trained": 112000, "num_env_steps_sampled": 28000, "num_env_steps_trained": 28000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 82.52608721936413, "num_env_steps_trained_throughput_per_sec": 82.52608721936413, "timesteps_total": 28000, "num_env_steps_sampled_lifetime": 28000, "num_agent_steps_sampled_lifetime": 112000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 112000, "timers": {"training_iteration_time_ms": 50778.635, "restore_workers_time_ms": 0.018, "training_step_time_ms": 50778.579, "sample_time_ms": 3124.874, "learn_time_ms": 47635.353, "learn_throughput": 83.971, "synch_weights_time_ms": 14.629}, "counters": {"num_env_steps_sampled": 28000, "num_env_steps_trained": 28000, "num_agent_steps_sampled": 112000, "num_agent_steps_trained": 112000}, "done": false, "training_iteration": 7, "trial_id": "798d9_00000", "date": "2024-08-22_09-43-20", "timestamp": 1724300000, "time_this_iter_s": 48.52613401412964, "time_total_s": 355.8217418193817, "pid": 48427, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"prey_count": 2, "prey_speed": 1.0, "prey_view_size": 10, "prey_size": 1, "prey_color": [0, 255, 0], "prey_kill_reward": -10, "prey_alive_reward": 0.1, "prey_reward_sqr_reward": 1, "predator_count": 2, "predator_speed": 1.0, "predator_view_size": 10, "predator_size": 1, "predator_color": [255, 0, 0], "predator_kill_reward": 10, "map_size": 40, "max_steps": 400, "screen_size": 600, "render_mode": "None", "fps": 60}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 8, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": true, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 1, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "custom_cnn", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x300bbee50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 355.8217418193817, "iterations_since_restore": 7, "perf": {"cpu_util_percent": 29.434782608695656, "ram_util_percent": 83.30579710144927}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.773113304408139, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 5.042748474317884, "policy_loss": -0.0296978083604247, "vf_loss": 5.068919947538427, "vf_explained_var": 0.21880643024015678, "kl": 0.0176316128122231, "entropy": 1.4261970899723195, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 14175.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 8.182960748987854, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 6.769075618723713, "policy_loss": -0.026770531735259784, "vf_loss": 6.792837812030126, "vf_explained_var": 0.33007629762881646, "kl": 0.015041704267440807, "entropy": 1.4499980219457516, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 14175.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 32000, "num_env_steps_trained": 32000, "num_agent_steps_sampled": 128000, "num_agent_steps_trained": 128000}, "env_runners": {"episode_reward_max": 702.0000000000007, "episode_reward_min": 37.506740396183545, "episode_reward_mean": 277.3883498707739, "episode_len_mean": 400.0, "episode_media": {}, "episodes_timesteps_total": 28800, "policy_reward_min": {"prey_policy": -477.1636031426591, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 362.875458830875, "predator_policy": 518.7387046770302}, "policy_reward_mean": {"prey_policy": -22.64809147276246, "predator_policy": 161.3422664081493}, "custom_metrics": {}, "hist_stats": {"episode_reward": [319.1000000000001, 395.91670796862, 125.96728212614214, 238.29999999999967, 212.7999999999985, 428.3274543974187, 306.3000000000013, 213.00015544486337, 424.24817610832963, 372.7000000000017, 351.89999999999907, 231.49999999999957, 174.43764546793366, 299.30000000000024, 440.11677977558287, 269.69999999999936, 538.9000000000005, 69.39756159241745, 587.3999999999996, 101.39999999999952, 119.29999999999697, 58.90000000000063, 63.712629493019854, 290.4925445973529, 241.13223304703237, 370.91663916018183, 358.9168236676343, 46.22202152717898, 211.1999999999996, 229.8999999999992, 368.2999999999993, 499.59999999999957, 305.39989239170626, 457.21081085698455, 138.59619829468053, 320.3231343679938, 253.4824225396431, 73.20000000000012, 39.693152979228174, 53.10000000000048, 372.01587367805865, 307.3999999999987, 52.08329168814634, 554.6136088493297, 73.4000000000001, 172.51661390670918, 314.5000000000002, 640.3999999999996, 358.4892629866069, 537.1000000000003, 240.62815016043697, 232.99951948252325, 438.4999999999999, 702.0000000000007, 504.6999999999995, 285.60000000000025, 266.70000000000033, 480.4999999999989, 64.7000163742361, 410.6028006084132, 345.90000000000043, 139.69999999999703, 70.90000000000029, 63.30000000000063, 279.64572693029027, 349.70000000000107, 235.9009733077793, 214.99999999999966, 276.68389954105544, 142.185420720523, 205.77902626148932, 37.506740396183545], "episode_lengths": [400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400], "policy_prey_policy_reward": [-33.48037747491744, 176.85623681481698, 26.430160761868635, -40.80481575322529, -173.39070401103916, -171.3907030189248, 184.2055053785144, -144.24432468529602, -7.148732506932676, -97.50055547741172, 11.668652477698977, 10.439842883486808, -152.30137464931465, -9.089360841830988, -135.36871088700246, -95.54433928398602, -161.21227492671034, 202.85323002231996, 33.13768373886731, 322.04191172763416, -37.88776262828977, 47.145506778500135, 79.98681403610979, -35.54340206319812, -188.1825260251033, 53.863974149791545, 246.20772292820098, -219.907991862822, 112.90225687216196, 126.08218511344265, -119.89548173449305, 79.90215770710263, 184.64258542943114, 190.44424775395328, -160.39244496516926, -132.12054811527494, 153.15452921752927, 319.01022357853276, -220.4603417719081, -44.60611747215477, 45.32770716481234, -147.87397598511114, -373.2080565725788, 18.453981624907964, -51.596342986116674, -432.2351876430542, -147.72077693286056, 30.750946971532784, -8.718594784215925, -77.57449877795553, 131.13359888055848, -76.41282741795835, -477.1636031426591, 152.41076216226548, -80.19598183366223, -124.64586702835348, 105.72869619249329, -1.9648889639130256, 55.48568529917049, -45.85455682559444, -62.40214191856839, 17.106722822609925, 87.69666749873406, 268.67402215929803, -50.38696514624137, -144.31431379636612, 65.05585552829419, 33.2460114701502, -13.098430599916068, -268.74883978781844, -11.294394465164757, 181.0634570921933, -16.92513187805305, 96.05843008442278, 14.478941326969109, -67.6590653950308, -118.55555651412521, -177.47588274825026, -189.77188382911984, -304.2946627024392, -254.73581174384054, 154.55987377587115, 82.78844862012033, 50.9480959558138, -451.7500226859305, 4.008634089920729, 103.88041434574149, 24.658147649416875, -162.9990322437011, -94.07113095617306, -170.69966320539146, -130.05132947249965, -153.03879348548688, 168.45588733626113, 235.4768797274106, 348.9665036205082, -110.06406504921048, 78.69916080689893, 95.29151321565989, 326.3721364186882, -19.169826879792645, -104.7844947775372, -158.90534356448262, -64.42264229576017, -353.2742296174582, 362.875458830875, 335.05710303969477, 257.29491828704704, 81.80681267278817, 142.86905860634414, -20.432894403191945, 20.71921057974368, 51.62033460976264, 34.248300659364475, 226.05840366195773, 67.43718812237373, -169.92054494847392, -117.24122907152062, -257.7315121765398, 361.7851532910748, 167.4070074237925, -72.15555908208464, 26.19324651093457, 33.6030165366545, -288.17736288755054, 23.443852062464494, -128.93884488795828, -142.80285529191028, -25.037662258665563, 119.9375724713436, 76.01645177360803, -83.11174434469032, 37.018753924373534, -154.76067785565894, -22.129318425672686, -78.38084396603054, -19.04034715917183, -421.33996044092163, -243.84991359235946, -75.3006140748056, 54.93146134287562, -312.95034565026685, -306.6654186305468, -260.9017327401376], "policy_predator_policy_reward": [68.78037747491791, 106.94376318518296, 21.13203856478976, 389.1593243951866, 243.19070401103826, 227.55798514506557, 198.33881930678086, 0.0, 295.188372311621, 22.260915672723804, 195.88045965349966, 210.33849938273266, 210.6013746493134, 257.0893608418309, 171.94888861910482, 271.96431699674616, 379.348394331207, 3.2588266815118128, 17.520404533498784, 0.0, 261.28776262828944, 81.35449322150023, 23.35436496989366, 163.70222305719363, 257.4705363999939, 51.28566094325446, 161.37833142999125, 111.62193750462882, 152.49653707460456, 48.63580071537401, 153.195481734492, 156.49784229289745, 135.85741457056884, 27.955752246046575, 207.80547173975793, 154.10508293310434, 72.14547078247037, 43.089776421467214, 288.460341771907, 78.00611747215531, 39.072292835188115, 182.77397598510922, 393.5080565725784, 20.14601837509204, 122.12312720547139, 425.42103291672123, 301.2043479921501, 106.25802656652952, 27.284954916112756, 300.1403716930912, 175.8289647421534, 140.36690295542982, 518.7387046770302, 164.93095997099812, 94.06031235660068, 157.00355803259416, 68.77130380750701, 38.664888963913185, 19.01431470082947, 201.2545568255937, 177.30214191856723, 236.29327717738977, 72.07984358427261, 71.14946675769549, 293.5438991777642, 206.55727215654974, 53.51669053940074, 305.3922533191393, 133.96264308871412, 286.4808255937011, 116.00686985184572, 34.547201889119435, 113.36344017054255, 60.98568416273251, 23.621058673030827, 102.7590653950288, 120.34840462746682, 215.3761876141331, 218.97188382911824, 328.1946627024382, 319.2819639355882, 152.90984771044035, 81.77853761281452, 91.88491781125136, 495.9666294389831, 3.858050845174355, 152.21273182395146, 273.86231503021935, 192.6990322436994, 137.77113095617173, 437.37365659266703, 35.89394999193405, 28.794920199800845, 270.2879859494245, 25.623120272589492, 30.333496379491763, 153.6158699346698, 236.2382972942456, 109.10848678433968, 6.327863581311885, 192.06724035824524, 172.51523145952336, 162.8261471603467, 293.5013581824182, 121.2804707762325, 307.61830001035077, 36.04289696030523, 73.605081712953, 93.29318732721097, 186.73094139365585, 264.83289440319186, 20.48078942025648, 0.0, 180.83136473087282, 41.6734821247086, 145.33092609096013, 102.56773114640504, 249.29405924782142, 211.31032296239817, 95.23883653147679, 11.392992576206154, 239.25555908208406, 48.31933511067729, 31.584401841733893, 320.37736288755036, 15.256147937535534, 161.53884488795643, 173.50285529190882, 100.89735298546444, 83.8484637321489, 240.98354822639197, 115.81174434468859, 186.02126421534868, 167.62163302371837, 39.54292005573028, 275.9672423359727, 368.0515318600075, 349.0126752811421, 276.34991359235966, 184.98603479532701, 159.1688218260833, 304.62908874280043, 505.2104852284398, 99.86340653843195]}, "sampler_perf": {"mean_raw_obs_processing_ms": 4.830064915122261, "mean_inference_ms": 4.676858178789684, "mean_action_processing_ms": 2.6437227413734963, "mean_env_wait_ms": 10.142940284028308, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.010469886991712783, "StateBufferConnector_ms": 0.005463593535953098, "ViewRequirementAgentConnector_ms": 0.17164631022347343}, "num_episodes": 25, "episode_return_max": 702.0000000000007, "episode_return_min": 37.506740396183545, "episode_return_mean": 277.3883498707739, "episodes_this_iter": 25}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 128000, "num_agent_steps_trained": 128000, "num_env_steps_sampled": 32000, "num_env_steps_trained": 32000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 81.73643505299034, "num_env_steps_trained_throughput_per_sec": 81.73643505299034, "timesteps_total": 32000, "num_env_steps_sampled_lifetime": 32000, "num_agent_steps_sampled_lifetime": 128000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 128000, "timers": {"training_iteration_time_ms": 50548.529, "restore_workers_time_ms": 0.018, "training_step_time_ms": 50548.474, "sample_time_ms": 3002.361, "learn_time_ms": 47527.452, "learn_throughput": 84.162, "synch_weights_time_ms": 15.047}, "counters": {"num_env_steps_sampled": 32000, "num_env_steps_trained": 32000, "num_agent_steps_sampled": 128000, "num_agent_steps_trained": 128000}, "done": false, "training_iteration": 8, "trial_id": "798d9_00000", "date": "2024-08-22_09-44-09", "timestamp": 1724300049, "time_this_iter_s": 48.99032402038574, "time_total_s": 404.81206583976746, "pid": 48427, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"prey_count": 2, "prey_speed": 1.0, "prey_view_size": 10, "prey_size": 1, "prey_color": [0, 255, 0], "prey_kill_reward": -10, "prey_alive_reward": 0.1, "prey_reward_sqr_reward": 1, "predator_count": 2, "predator_speed": 1.0, "predator_view_size": 10, "predator_size": 1, "predator_color": [255, 0, 0], "predator_kill_reward": 10, "map_size": 40, "max_steps": 400, "screen_size": 600, "render_mode": "None", "fps": 60}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 8, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": true, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 1, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "custom_cnn", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x16cfc4c10>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 404.81206583976746, "iterations_since_restore": 8, "perf": {"cpu_util_percent": 32.007246376811594, "ram_util_percent": 82.92608695652171}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.586210750082813, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 4.6134163778294965, "policy_loss": -0.021192515089679214, "vf_loss": 4.631501752863485, "vf_explained_var": 0.19856687352140115, "kl": 0.01553571095502881, "entropy": 1.418669226812938, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 16065.5, "diff_num_grad_updates_vs_sampler_policy": 970.4874999999993}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 7.166769141305691, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 6.522483018340257, "policy_loss": -0.026275696781483632, "vf_loss": 6.545677284967332, "vf_explained_var": 0.29584556048509303, "kl": 0.015407140420937033, "entropy": 1.4454540870807788, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 16065.5, "diff_num_grad_updates_vs_sampler_policy": 970.4874999999993}}, "num_env_steps_sampled": 36000, "num_env_steps_trained": 36000, "num_agent_steps_sampled": 144000, "num_agent_steps_trained": 144000}, "env_runners": {"episode_reward_max": 702.0000000000007, "episode_reward_min": 37.506740396183545, "episode_reward_mean": 277.3883498707739, "episode_len_mean": 400.0, "episode_media": {}, "episodes_timesteps_total": 28800, "policy_reward_min": {"prey_policy": -477.1636031426591, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 362.875458830875, "predator_policy": 518.7387046770302}, "policy_reward_mean": {"prey_policy": -22.64809147276246, "predator_policy": 161.3422664081493}, "custom_metrics": {}, "hist_stats": {"episode_reward": [319.1000000000001, 395.91670796862, 125.96728212614214, 238.29999999999967, 212.7999999999985, 428.3274543974187, 306.3000000000013, 213.00015544486337, 424.24817610832963, 372.7000000000017, 351.89999999999907, 231.49999999999957, 174.43764546793366, 299.30000000000024, 440.11677977558287, 269.69999999999936, 538.9000000000005, 69.39756159241745, 587.3999999999996, 101.39999999999952, 119.29999999999697, 58.90000000000063, 63.712629493019854, 290.4925445973529, 241.13223304703237, 370.91663916018183, 358.9168236676343, 46.22202152717898, 211.1999999999996, 229.8999999999992, 368.2999999999993, 499.59999999999957, 305.39989239170626, 457.21081085698455, 138.59619829468053, 320.3231343679938, 253.4824225396431, 73.20000000000012, 39.693152979228174, 53.10000000000048, 372.01587367805865, 307.3999999999987, 52.08329168814634, 554.6136088493297, 73.4000000000001, 172.51661390670918, 314.5000000000002, 640.3999999999996, 358.4892629866069, 537.1000000000003, 240.62815016043697, 232.99951948252325, 438.4999999999999, 702.0000000000007, 504.6999999999995, 285.60000000000025, 266.70000000000033, 480.4999999999989, 64.7000163742361, 410.6028006084132, 345.90000000000043, 139.69999999999703, 70.90000000000029, 63.30000000000063, 279.64572693029027, 349.70000000000107, 235.9009733077793, 214.99999999999966, 276.68389954105544, 142.185420720523, 205.77902626148932, 37.506740396183545], "episode_lengths": [400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400], "policy_prey_policy_reward": [-33.48037747491744, 176.85623681481698, 26.430160761868635, -40.80481575322529, -173.39070401103916, -171.3907030189248, 184.2055053785144, -144.24432468529602, -7.148732506932676, -97.50055547741172, 11.668652477698977, 10.439842883486808, -152.30137464931465, -9.089360841830988, -135.36871088700246, -95.54433928398602, -161.21227492671034, 202.85323002231996, 33.13768373886731, 322.04191172763416, -37.88776262828977, 47.145506778500135, 79.98681403610979, -35.54340206319812, -188.1825260251033, 53.863974149791545, 246.20772292820098, -219.907991862822, 112.90225687216196, 126.08218511344265, -119.89548173449305, 79.90215770710263, 184.64258542943114, 190.44424775395328, -160.39244496516926, -132.12054811527494, 153.15452921752927, 319.01022357853276, -220.4603417719081, -44.60611747215477, 45.32770716481234, -147.87397598511114, -373.2080565725788, 18.453981624907964, -51.596342986116674, -432.2351876430542, -147.72077693286056, 30.750946971532784, -8.718594784215925, -77.57449877795553, 131.13359888055848, -76.41282741795835, -477.1636031426591, 152.41076216226548, -80.19598183366223, -124.64586702835348, 105.72869619249329, -1.9648889639130256, 55.48568529917049, -45.85455682559444, -62.40214191856839, 17.106722822609925, 87.69666749873406, 268.67402215929803, -50.38696514624137, -144.31431379636612, 65.05585552829419, 33.2460114701502, -13.098430599916068, -268.74883978781844, -11.294394465164757, 181.0634570921933, -16.92513187805305, 96.05843008442278, 14.478941326969109, -67.6590653950308, -118.55555651412521, -177.47588274825026, -189.77188382911984, -304.2946627024392, -254.73581174384054, 154.55987377587115, 82.78844862012033, 50.9480959558138, -451.7500226859305, 4.008634089920729, 103.88041434574149, 24.658147649416875, -162.9990322437011, -94.07113095617306, -170.69966320539146, -130.05132947249965, -153.03879348548688, 168.45588733626113, 235.4768797274106, 348.9665036205082, -110.06406504921048, 78.69916080689893, 95.29151321565989, 326.3721364186882, -19.169826879792645, -104.7844947775372, -158.90534356448262, -64.42264229576017, -353.2742296174582, 362.875458830875, 335.05710303969477, 257.29491828704704, 81.80681267278817, 142.86905860634414, -20.432894403191945, 20.71921057974368, 51.62033460976264, 34.248300659364475, 226.05840366195773, 67.43718812237373, -169.92054494847392, -117.24122907152062, -257.7315121765398, 361.7851532910748, 167.4070074237925, -72.15555908208464, 26.19324651093457, 33.6030165366545, -288.17736288755054, 23.443852062464494, -128.93884488795828, -142.80285529191028, -25.037662258665563, 119.9375724713436, 76.01645177360803, -83.11174434469032, 37.018753924373534, -154.76067785565894, -22.129318425672686, -78.38084396603054, -19.04034715917183, -421.33996044092163, -243.84991359235946, -75.3006140748056, 54.93146134287562, -312.95034565026685, -306.6654186305468, -260.9017327401376], "policy_predator_policy_reward": [68.78037747491791, 106.94376318518296, 21.13203856478976, 389.1593243951866, 243.19070401103826, 227.55798514506557, 198.33881930678086, 0.0, 295.188372311621, 22.260915672723804, 195.88045965349966, 210.33849938273266, 210.6013746493134, 257.0893608418309, 171.94888861910482, 271.96431699674616, 379.348394331207, 3.2588266815118128, 17.520404533498784, 0.0, 261.28776262828944, 81.35449322150023, 23.35436496989366, 163.70222305719363, 257.4705363999939, 51.28566094325446, 161.37833142999125, 111.62193750462882, 152.49653707460456, 48.63580071537401, 153.195481734492, 156.49784229289745, 135.85741457056884, 27.955752246046575, 207.80547173975793, 154.10508293310434, 72.14547078247037, 43.089776421467214, 288.460341771907, 78.00611747215531, 39.072292835188115, 182.77397598510922, 393.5080565725784, 20.14601837509204, 122.12312720547139, 425.42103291672123, 301.2043479921501, 106.25802656652952, 27.284954916112756, 300.1403716930912, 175.8289647421534, 140.36690295542982, 518.7387046770302, 164.93095997099812, 94.06031235660068, 157.00355803259416, 68.77130380750701, 38.664888963913185, 19.01431470082947, 201.2545568255937, 177.30214191856723, 236.29327717738977, 72.07984358427261, 71.14946675769549, 293.5438991777642, 206.55727215654974, 53.51669053940074, 305.3922533191393, 133.96264308871412, 286.4808255937011, 116.00686985184572, 34.547201889119435, 113.36344017054255, 60.98568416273251, 23.621058673030827, 102.7590653950288, 120.34840462746682, 215.3761876141331, 218.97188382911824, 328.1946627024382, 319.2819639355882, 152.90984771044035, 81.77853761281452, 91.88491781125136, 495.9666294389831, 3.858050845174355, 152.21273182395146, 273.86231503021935, 192.6990322436994, 137.77113095617173, 437.37365659266703, 35.89394999193405, 28.794920199800845, 270.2879859494245, 25.623120272589492, 30.333496379491763, 153.6158699346698, 236.2382972942456, 109.10848678433968, 6.327863581311885, 192.06724035824524, 172.51523145952336, 162.8261471603467, 293.5013581824182, 121.2804707762325, 307.61830001035077, 36.04289696030523, 73.605081712953, 93.29318732721097, 186.73094139365585, 264.83289440319186, 20.48078942025648, 0.0, 180.83136473087282, 41.6734821247086, 145.33092609096013, 102.56773114640504, 249.29405924782142, 211.31032296239817, 95.23883653147679, 11.392992576206154, 239.25555908208406, 48.31933511067729, 31.584401841733893, 320.37736288755036, 15.256147937535534, 161.53884488795643, 173.50285529190882, 100.89735298546444, 83.8484637321489, 240.98354822639197, 115.81174434468859, 186.02126421534868, 167.62163302371837, 39.54292005573028, 275.9672423359727, 368.0515318600075, 349.0126752811421, 276.34991359235966, 184.98603479532701, 159.1688218260833, 304.62908874280043, 505.2104852284398, 99.86340653843195]}, "sampler_perf": {"mean_raw_obs_processing_ms": 4.830064915122261, "mean_inference_ms": 4.676858178789684, "mean_action_processing_ms": 2.6437227413734963, "mean_env_wait_ms": 10.142940284028308, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.010469886991712783, "StateBufferConnector_ms": 0.005463593535953098, "ViewRequirementAgentConnector_ms": 0.17164631022347343}, "num_episodes": 0, "episode_return_max": 702.0000000000007, "episode_return_min": 37.506740396183545, "episode_return_mean": 277.3883498707739, "episodes_this_iter": 0}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 144000, "num_agent_steps_trained": 144000, "num_env_steps_sampled": 36000, "num_env_steps_trained": 36000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 77.4590475935974, "num_env_steps_trained_throughput_per_sec": 77.4590475935974, "timesteps_total": 36000, "num_env_steps_sampled_lifetime": 36000, "num_agent_steps_sampled_lifetime": 144000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 144000, "timers": {"training_iteration_time_ms": 50669.826, "restore_workers_time_ms": 0.018, "training_step_time_ms": 50669.772, "sample_time_ms": 2924.324, "learn_time_ms": 47727.009, "learn_throughput": 83.81, "synch_weights_time_ms": 14.771}, "counters": {"num_env_steps_sampled": 36000, "num_env_steps_trained": 36000, "num_agent_steps_sampled": 144000, "num_agent_steps_trained": 144000}, "done": false, "training_iteration": 9, "trial_id": "798d9_00000", "date": "2024-08-22_09-45-00", "timestamp": 1724300100, "time_this_iter_s": 51.68843865394592, "time_total_s": 456.5005044937134, "pid": 48427, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"prey_count": 2, "prey_speed": 1.0, "prey_view_size": 10, "prey_size": 1, "prey_color": [0, 255, 0], "prey_kill_reward": -10, "prey_alive_reward": 0.1, "prey_reward_sqr_reward": 1, "predator_count": 2, "predator_speed": 1.0, "predator_view_size": 10, "predator_size": 1, "predator_color": [255, 0, 0], "predator_kill_reward": 10, "map_size": 40, "max_steps": 400, "screen_size": 600, "render_mode": "None", "fps": 60}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 8, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": true, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 1, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "custom_cnn", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a94fadc0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 456.5005044937134, "iterations_since_restore": 9, "perf": {"cpu_util_percent": 41.821621621621624, "ram_util_percent": 83.31486486486487}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.1061436367413355, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 3.2764898242143095, "policy_loss": -0.024169480521724653, "vf_loss": 3.2976708880177252, "vf_explained_var": 0.15951730596325384, "kl": 0.014942054390394813, "entropy": 1.444685076090394, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 17955.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 8.457552119474562, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 6.102811803514995, "policy_loss": -0.021954963475012433, "vf_loss": 6.122314777323808, "vf_explained_var": 0.3442105188886955, "kl": 0.01225988138713455, "entropy": 1.4604344809496845, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 17955.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 40000, "num_env_steps_trained": 40000, "num_agent_steps_sampled": 160000, "num_agent_steps_trained": 160000}, "env_runners": {"episode_reward_max": 702.0000000000007, "episode_reward_min": 37.506740396183545, "episode_reward_mean": 277.3883498707739, "episode_len_mean": 400.0, "episode_media": {}, "episodes_timesteps_total": 28800, "policy_reward_min": {"prey_policy": -477.1636031426591, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 362.875458830875, "predator_policy": 518.7387046770302}, "policy_reward_mean": {"prey_policy": -22.64809147276246, "predator_policy": 161.3422664081493}, "custom_metrics": {}, "hist_stats": {"episode_reward": [319.1000000000001, 395.91670796862, 125.96728212614214, 238.29999999999967, 212.7999999999985, 428.3274543974187, 306.3000000000013, 213.00015544486337, 424.24817610832963, 372.7000000000017, 351.89999999999907, 231.49999999999957, 174.43764546793366, 299.30000000000024, 440.11677977558287, 269.69999999999936, 538.9000000000005, 69.39756159241745, 587.3999999999996, 101.39999999999952, 119.29999999999697, 58.90000000000063, 63.712629493019854, 290.4925445973529, 241.13223304703237, 370.91663916018183, 358.9168236676343, 46.22202152717898, 211.1999999999996, 229.8999999999992, 368.2999999999993, 499.59999999999957, 305.39989239170626, 457.21081085698455, 138.59619829468053, 320.3231343679938, 253.4824225396431, 73.20000000000012, 39.693152979228174, 53.10000000000048, 372.01587367805865, 307.3999999999987, 52.08329168814634, 554.6136088493297, 73.4000000000001, 172.51661390670918, 314.5000000000002, 640.3999999999996, 358.4892629866069, 537.1000000000003, 240.62815016043697, 232.99951948252325, 438.4999999999999, 702.0000000000007, 504.6999999999995, 285.60000000000025, 266.70000000000033, 480.4999999999989, 64.7000163742361, 410.6028006084132, 345.90000000000043, 139.69999999999703, 70.90000000000029, 63.30000000000063, 279.64572693029027, 349.70000000000107, 235.9009733077793, 214.99999999999966, 276.68389954105544, 142.185420720523, 205.77902626148932, 37.506740396183545], "episode_lengths": [400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400], "policy_prey_policy_reward": [-33.48037747491744, 176.85623681481698, 26.430160761868635, -40.80481575322529, -173.39070401103916, -171.3907030189248, 184.2055053785144, -144.24432468529602, -7.148732506932676, -97.50055547741172, 11.668652477698977, 10.439842883486808, -152.30137464931465, -9.089360841830988, -135.36871088700246, -95.54433928398602, -161.21227492671034, 202.85323002231996, 33.13768373886731, 322.04191172763416, -37.88776262828977, 47.145506778500135, 79.98681403610979, -35.54340206319812, -188.1825260251033, 53.863974149791545, 246.20772292820098, -219.907991862822, 112.90225687216196, 126.08218511344265, -119.89548173449305, 79.90215770710263, 184.64258542943114, 190.44424775395328, -160.39244496516926, -132.12054811527494, 153.15452921752927, 319.01022357853276, -220.4603417719081, -44.60611747215477, 45.32770716481234, -147.87397598511114, -373.2080565725788, 18.453981624907964, -51.596342986116674, -432.2351876430542, -147.72077693286056, 30.750946971532784, -8.718594784215925, -77.57449877795553, 131.13359888055848, -76.41282741795835, -477.1636031426591, 152.41076216226548, -80.19598183366223, -124.64586702835348, 105.72869619249329, -1.9648889639130256, 55.48568529917049, -45.85455682559444, -62.40214191856839, 17.106722822609925, 87.69666749873406, 268.67402215929803, -50.38696514624137, -144.31431379636612, 65.05585552829419, 33.2460114701502, -13.098430599916068, -268.74883978781844, -11.294394465164757, 181.0634570921933, -16.92513187805305, 96.05843008442278, 14.478941326969109, -67.6590653950308, -118.55555651412521, -177.47588274825026, -189.77188382911984, -304.2946627024392, -254.73581174384054, 154.55987377587115, 82.78844862012033, 50.9480959558138, -451.7500226859305, 4.008634089920729, 103.88041434574149, 24.658147649416875, -162.9990322437011, -94.07113095617306, -170.69966320539146, -130.05132947249965, -153.03879348548688, 168.45588733626113, 235.4768797274106, 348.9665036205082, -110.06406504921048, 78.69916080689893, 95.29151321565989, 326.3721364186882, -19.169826879792645, -104.7844947775372, -158.90534356448262, -64.42264229576017, -353.2742296174582, 362.875458830875, 335.05710303969477, 257.29491828704704, 81.80681267278817, 142.86905860634414, -20.432894403191945, 20.71921057974368, 51.62033460976264, 34.248300659364475, 226.05840366195773, 67.43718812237373, -169.92054494847392, -117.24122907152062, -257.7315121765398, 361.7851532910748, 167.4070074237925, -72.15555908208464, 26.19324651093457, 33.6030165366545, -288.17736288755054, 23.443852062464494, -128.93884488795828, -142.80285529191028, -25.037662258665563, 119.9375724713436, 76.01645177360803, -83.11174434469032, 37.018753924373534, -154.76067785565894, -22.129318425672686, -78.38084396603054, -19.04034715917183, -421.33996044092163, -243.84991359235946, -75.3006140748056, 54.93146134287562, -312.95034565026685, -306.6654186305468, -260.9017327401376], "policy_predator_policy_reward": [68.78037747491791, 106.94376318518296, 21.13203856478976, 389.1593243951866, 243.19070401103826, 227.55798514506557, 198.33881930678086, 0.0, 295.188372311621, 22.260915672723804, 195.88045965349966, 210.33849938273266, 210.6013746493134, 257.0893608418309, 171.94888861910482, 271.96431699674616, 379.348394331207, 3.2588266815118128, 17.520404533498784, 0.0, 261.28776262828944, 81.35449322150023, 23.35436496989366, 163.70222305719363, 257.4705363999939, 51.28566094325446, 161.37833142999125, 111.62193750462882, 152.49653707460456, 48.63580071537401, 153.195481734492, 156.49784229289745, 135.85741457056884, 27.955752246046575, 207.80547173975793, 154.10508293310434, 72.14547078247037, 43.089776421467214, 288.460341771907, 78.00611747215531, 39.072292835188115, 182.77397598510922, 393.5080565725784, 20.14601837509204, 122.12312720547139, 425.42103291672123, 301.2043479921501, 106.25802656652952, 27.284954916112756, 300.1403716930912, 175.8289647421534, 140.36690295542982, 518.7387046770302, 164.93095997099812, 94.06031235660068, 157.00355803259416, 68.77130380750701, 38.664888963913185, 19.01431470082947, 201.2545568255937, 177.30214191856723, 236.29327717738977, 72.07984358427261, 71.14946675769549, 293.5438991777642, 206.55727215654974, 53.51669053940074, 305.3922533191393, 133.96264308871412, 286.4808255937011, 116.00686985184572, 34.547201889119435, 113.36344017054255, 60.98568416273251, 23.621058673030827, 102.7590653950288, 120.34840462746682, 215.3761876141331, 218.97188382911824, 328.1946627024382, 319.2819639355882, 152.90984771044035, 81.77853761281452, 91.88491781125136, 495.9666294389831, 3.858050845174355, 152.21273182395146, 273.86231503021935, 192.6990322436994, 137.77113095617173, 437.37365659266703, 35.89394999193405, 28.794920199800845, 270.2879859494245, 25.623120272589492, 30.333496379491763, 153.6158699346698, 236.2382972942456, 109.10848678433968, 6.327863581311885, 192.06724035824524, 172.51523145952336, 162.8261471603467, 293.5013581824182, 121.2804707762325, 307.61830001035077, 36.04289696030523, 73.605081712953, 93.29318732721097, 186.73094139365585, 264.83289440319186, 20.48078942025648, 0.0, 180.83136473087282, 41.6734821247086, 145.33092609096013, 102.56773114640504, 249.29405924782142, 211.31032296239817, 95.23883653147679, 11.392992576206154, 239.25555908208406, 48.31933511067729, 31.584401841733893, 320.37736288755036, 15.256147937535534, 161.53884488795643, 173.50285529190882, 100.89735298546444, 83.8484637321489, 240.98354822639197, 115.81174434468859, 186.02126421534868, 167.62163302371837, 39.54292005573028, 275.9672423359727, 368.0515318600075, 349.0126752811421, 276.34991359235966, 184.98603479532701, 159.1688218260833, 304.62908874280043, 505.2104852284398, 99.86340653843195]}, "sampler_perf": {"mean_raw_obs_processing_ms": 4.830064915122261, "mean_inference_ms": 4.676858178789684, "mean_action_processing_ms": 2.6437227413734963, "mean_env_wait_ms": 10.142940284028308, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.010469886991712783, "StateBufferConnector_ms": 0.005463593535953098, "ViewRequirementAgentConnector_ms": 0.17164631022347343}, "num_episodes": 0, "episode_return_max": 702.0000000000007, "episode_return_min": 37.506740396183545, "episode_return_mean": 277.3883498707739, "episodes_this_iter": 0}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 160000, "num_agent_steps_trained": 160000, "num_env_steps_sampled": 40000, "num_env_steps_trained": 40000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 80.95361737838948, "num_env_steps_trained_throughput_per_sec": 80.95361737838948, "timesteps_total": 40000, "num_env_steps_sampled_lifetime": 40000, "num_agent_steps_sampled_lifetime": 160000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 160000, "timers": {"training_iteration_time_ms": 50543.945, "restore_workers_time_ms": 0.017, "training_step_time_ms": 50543.892, "sample_time_ms": 2860.817, "learn_time_ms": 47664.63, "learn_throughput": 83.92, "synch_weights_time_ms": 14.752}, "counters": {"num_env_steps_sampled": 40000, "num_env_steps_trained": 40000, "num_agent_steps_sampled": 160000, "num_agent_steps_trained": 160000}, "done": false, "training_iteration": 10, "trial_id": "798d9_00000", "date": "2024-08-22_09-45-50", "timestamp": 1724300150, "time_this_iter_s": 49.46399998664856, "time_total_s": 505.96450448036194, "pid": 48427, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"prey_count": 2, "prey_speed": 1.0, "prey_view_size": 10, "prey_size": 1, "prey_color": [0, 255, 0], "prey_kill_reward": -10, "prey_alive_reward": 0.1, "prey_reward_sqr_reward": 1, "predator_count": 2, "predator_speed": 1.0, "predator_view_size": 10, "predator_size": 1, "predator_color": [255, 0, 0], "predator_kill_reward": 10, "map_size": 40, "max_steps": 400, "screen_size": 600, "render_mode": "None", "fps": 60}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 8, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": true, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 1, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "custom_cnn", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x300bbeca0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 505.96450448036194, "iterations_since_restore": 10, "perf": {"cpu_util_percent": 31.489999999999995, "ram_util_percent": 82.59857142857142}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.039845796709969, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 2.432671245506832, "policy_loss": -0.020130300432660436, "vf_loss": 2.449619338878248, "vf_explained_var": 0.21482147359974169, "kl": 0.01591102981708313, "entropy": 1.4364755150502322, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 19845.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 9.152249584942268, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 5.510260704837779, "policy_loss": -0.020504678479825744, "vf_loss": 5.528064419731261, "vf_explained_var": 0.4874977156598732, "kl": 0.013504835775752783, "entropy": 1.4530160960696992, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 19845.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 44000, "num_env_steps_trained": 44000, "num_agent_steps_sampled": 176000, "num_agent_steps_trained": 176000}, "env_runners": {"episode_reward_max": 702.0000000000007, "episode_reward_min": 37.506740396183545, "episode_reward_mean": 277.3883498707739, "episode_len_mean": 400.0, "episode_media": {}, "episodes_timesteps_total": 28800, "policy_reward_min": {"prey_policy": -477.1636031426591, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 362.875458830875, "predator_policy": 518.7387046770302}, "policy_reward_mean": {"prey_policy": -22.64809147276246, "predator_policy": 161.3422664081493}, "custom_metrics": {}, "hist_stats": {"episode_reward": [319.1000000000001, 395.91670796862, 125.96728212614214, 238.29999999999967, 212.7999999999985, 428.3274543974187, 306.3000000000013, 213.00015544486337, 424.24817610832963, 372.7000000000017, 351.89999999999907, 231.49999999999957, 174.43764546793366, 299.30000000000024, 440.11677977558287, 269.69999999999936, 538.9000000000005, 69.39756159241745, 587.3999999999996, 101.39999999999952, 119.29999999999697, 58.90000000000063, 63.712629493019854, 290.4925445973529, 241.13223304703237, 370.91663916018183, 358.9168236676343, 46.22202152717898, 211.1999999999996, 229.8999999999992, 368.2999999999993, 499.59999999999957, 305.39989239170626, 457.21081085698455, 138.59619829468053, 320.3231343679938, 253.4824225396431, 73.20000000000012, 39.693152979228174, 53.10000000000048, 372.01587367805865, 307.3999999999987, 52.08329168814634, 554.6136088493297, 73.4000000000001, 172.51661390670918, 314.5000000000002, 640.3999999999996, 358.4892629866069, 537.1000000000003, 240.62815016043697, 232.99951948252325, 438.4999999999999, 702.0000000000007, 504.6999999999995, 285.60000000000025, 266.70000000000033, 480.4999999999989, 64.7000163742361, 410.6028006084132, 345.90000000000043, 139.69999999999703, 70.90000000000029, 63.30000000000063, 279.64572693029027, 349.70000000000107, 235.9009733077793, 214.99999999999966, 276.68389954105544, 142.185420720523, 205.77902626148932, 37.506740396183545], "episode_lengths": [400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400], "policy_prey_policy_reward": [-33.48037747491744, 176.85623681481698, 26.430160761868635, -40.80481575322529, -173.39070401103916, -171.3907030189248, 184.2055053785144, -144.24432468529602, -7.148732506932676, -97.50055547741172, 11.668652477698977, 10.439842883486808, -152.30137464931465, -9.089360841830988, -135.36871088700246, -95.54433928398602, -161.21227492671034, 202.85323002231996, 33.13768373886731, 322.04191172763416, -37.88776262828977, 47.145506778500135, 79.98681403610979, -35.54340206319812, -188.1825260251033, 53.863974149791545, 246.20772292820098, -219.907991862822, 112.90225687216196, 126.08218511344265, -119.89548173449305, 79.90215770710263, 184.64258542943114, 190.44424775395328, -160.39244496516926, -132.12054811527494, 153.15452921752927, 319.01022357853276, -220.4603417719081, -44.60611747215477, 45.32770716481234, -147.87397598511114, -373.2080565725788, 18.453981624907964, -51.596342986116674, -432.2351876430542, -147.72077693286056, 30.750946971532784, -8.718594784215925, -77.57449877795553, 131.13359888055848, -76.41282741795835, -477.1636031426591, 152.41076216226548, -80.19598183366223, -124.64586702835348, 105.72869619249329, -1.9648889639130256, 55.48568529917049, -45.85455682559444, -62.40214191856839, 17.106722822609925, 87.69666749873406, 268.67402215929803, -50.38696514624137, -144.31431379636612, 65.05585552829419, 33.2460114701502, -13.098430599916068, -268.74883978781844, -11.294394465164757, 181.0634570921933, -16.92513187805305, 96.05843008442278, 14.478941326969109, -67.6590653950308, -118.55555651412521, -177.47588274825026, -189.77188382911984, -304.2946627024392, -254.73581174384054, 154.55987377587115, 82.78844862012033, 50.9480959558138, -451.7500226859305, 4.008634089920729, 103.88041434574149, 24.658147649416875, -162.9990322437011, -94.07113095617306, -170.69966320539146, -130.05132947249965, -153.03879348548688, 168.45588733626113, 235.4768797274106, 348.9665036205082, -110.06406504921048, 78.69916080689893, 95.29151321565989, 326.3721364186882, -19.169826879792645, -104.7844947775372, -158.90534356448262, -64.42264229576017, -353.2742296174582, 362.875458830875, 335.05710303969477, 257.29491828704704, 81.80681267278817, 142.86905860634414, -20.432894403191945, 20.71921057974368, 51.62033460976264, 34.248300659364475, 226.05840366195773, 67.43718812237373, -169.92054494847392, -117.24122907152062, -257.7315121765398, 361.7851532910748, 167.4070074237925, -72.15555908208464, 26.19324651093457, 33.6030165366545, -288.17736288755054, 23.443852062464494, -128.93884488795828, -142.80285529191028, -25.037662258665563, 119.9375724713436, 76.01645177360803, -83.11174434469032, 37.018753924373534, -154.76067785565894, -22.129318425672686, -78.38084396603054, -19.04034715917183, -421.33996044092163, -243.84991359235946, -75.3006140748056, 54.93146134287562, -312.95034565026685, -306.6654186305468, -260.9017327401376], "policy_predator_policy_reward": [68.78037747491791, 106.94376318518296, 21.13203856478976, 389.1593243951866, 243.19070401103826, 227.55798514506557, 198.33881930678086, 0.0, 295.188372311621, 22.260915672723804, 195.88045965349966, 210.33849938273266, 210.6013746493134, 257.0893608418309, 171.94888861910482, 271.96431699674616, 379.348394331207, 3.2588266815118128, 17.520404533498784, 0.0, 261.28776262828944, 81.35449322150023, 23.35436496989366, 163.70222305719363, 257.4705363999939, 51.28566094325446, 161.37833142999125, 111.62193750462882, 152.49653707460456, 48.63580071537401, 153.195481734492, 156.49784229289745, 135.85741457056884, 27.955752246046575, 207.80547173975793, 154.10508293310434, 72.14547078247037, 43.089776421467214, 288.460341771907, 78.00611747215531, 39.072292835188115, 182.77397598510922, 393.5080565725784, 20.14601837509204, 122.12312720547139, 425.42103291672123, 301.2043479921501, 106.25802656652952, 27.284954916112756, 300.1403716930912, 175.8289647421534, 140.36690295542982, 518.7387046770302, 164.93095997099812, 94.06031235660068, 157.00355803259416, 68.77130380750701, 38.664888963913185, 19.01431470082947, 201.2545568255937, 177.30214191856723, 236.29327717738977, 72.07984358427261, 71.14946675769549, 293.5438991777642, 206.55727215654974, 53.51669053940074, 305.3922533191393, 133.96264308871412, 286.4808255937011, 116.00686985184572, 34.547201889119435, 113.36344017054255, 60.98568416273251, 23.621058673030827, 102.7590653950288, 120.34840462746682, 215.3761876141331, 218.97188382911824, 328.1946627024382, 319.2819639355882, 152.90984771044035, 81.77853761281452, 91.88491781125136, 495.9666294389831, 3.858050845174355, 152.21273182395146, 273.86231503021935, 192.6990322436994, 137.77113095617173, 437.37365659266703, 35.89394999193405, 28.794920199800845, 270.2879859494245, 25.623120272589492, 30.333496379491763, 153.6158699346698, 236.2382972942456, 109.10848678433968, 6.327863581311885, 192.06724035824524, 172.51523145952336, 162.8261471603467, 293.5013581824182, 121.2804707762325, 307.61830001035077, 36.04289696030523, 73.605081712953, 93.29318732721097, 186.73094139365585, 264.83289440319186, 20.48078942025648, 0.0, 180.83136473087282, 41.6734821247086, 145.33092609096013, 102.56773114640504, 249.29405924782142, 211.31032296239817, 95.23883653147679, 11.392992576206154, 239.25555908208406, 48.31933511067729, 31.584401841733893, 320.37736288755036, 15.256147937535534, 161.53884488795643, 173.50285529190882, 100.89735298546444, 83.8484637321489, 240.98354822639197, 115.81174434468859, 186.02126421534868, 167.62163302371837, 39.54292005573028, 275.9672423359727, 368.0515318600075, 349.0126752811421, 276.34991359235966, 184.98603479532701, 159.1688218260833, 304.62908874280043, 505.2104852284398, 99.86340653843195]}, "sampler_perf": {"mean_raw_obs_processing_ms": 4.830064915122261, "mean_inference_ms": 4.676858178789684, "mean_action_processing_ms": 2.6437227413734963, "mean_env_wait_ms": 10.142940284028308, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.010469886991712783, "StateBufferConnector_ms": 0.005463593535953098, "ViewRequirementAgentConnector_ms": 0.17164631022347343}, "num_episodes": 0, "episode_return_max": 702.0000000000007, "episode_return_min": 37.506740396183545, "episode_return_mean": 277.3883498707739, "episodes_this_iter": 0}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 176000, "num_agent_steps_trained": 176000, "num_env_steps_sampled": 44000, "num_env_steps_trained": 44000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 81.95546694863374, "num_env_steps_trained_throughput_per_sec": 81.95546694863374, "timesteps_total": 44000, "num_env_steps_sampled_lifetime": 44000, "num_agent_steps_sampled_lifetime": 176000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 176000, "timers": {"training_iteration_time_ms": 50219.737, "restore_workers_time_ms": 0.017, "training_step_time_ms": 50219.686, "sample_time_ms": 2708.741, "learn_time_ms": 47492.683, "learn_throughput": 84.224, "synch_weights_time_ms": 14.693}, "counters": {"num_env_steps_sampled": 44000, "num_env_steps_trained": 44000, "num_agent_steps_sampled": 176000, "num_agent_steps_trained": 176000}, "done": false, "training_iteration": 11, "trial_id": "798d9_00000", "date": "2024-08-22_09-46-39", "timestamp": 1724300199, "time_this_iter_s": 48.85747671127319, "time_total_s": 554.8219811916351, "pid": 48427, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"prey_count": 2, "prey_speed": 1.0, "prey_view_size": 10, "prey_size": 1, "prey_color": [0, 255, 0], "prey_kill_reward": -10, "prey_alive_reward": 0.1, "prey_reward_sqr_reward": 1, "predator_count": 2, "predator_speed": 1.0, "predator_view_size": 10, "predator_size": 1, "predator_color": [255, 0, 0], "predator_kill_reward": 10, "map_size": 40, "max_steps": 400, "screen_size": 600, "render_mode": "None", "fps": 60}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 8, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": true, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 1, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "custom_cnn", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x300bfda60>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 554.8219811916351, "iterations_since_restore": 11, "perf": {"cpu_util_percent": 30.059420289855073, "ram_util_percent": 82.4550724637681}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.9185728058613165, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 2.283285191134801, "policy_loss": -0.01736647287339327, "vf_loss": 2.297875409403806, "vf_explained_var": 0.22001729396285202, "kl": 0.013881257493985156, "entropy": 1.4231429872058687, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 21735.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 10.346387847201534, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 4.805385755609583, "policy_loss": -0.026064653769406494, "vf_loss": 4.828708410641504, "vf_explained_var": 0.4056485367830468, "kl": 0.013709902017076732, "entropy": 1.447060939370009, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 21735.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 48000, "num_env_steps_trained": 48000, "num_agent_steps_sampled": 192000, "num_agent_steps_trained": 192000}, "env_runners": {"episode_reward_max": 702.0000000000007, "episode_reward_min": 37.506740396183545, "episode_reward_mean": 277.3883498707739, "episode_len_mean": 400.0, "episode_media": {}, "episodes_timesteps_total": 28800, "policy_reward_min": {"prey_policy": -477.1636031426591, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 362.875458830875, "predator_policy": 518.7387046770302}, "policy_reward_mean": {"prey_policy": -22.64809147276246, "predator_policy": 161.3422664081493}, "custom_metrics": {}, "hist_stats": {"episode_reward": [319.1000000000001, 395.91670796862, 125.96728212614214, 238.29999999999967, 212.7999999999985, 428.3274543974187, 306.3000000000013, 213.00015544486337, 424.24817610832963, 372.7000000000017, 351.89999999999907, 231.49999999999957, 174.43764546793366, 299.30000000000024, 440.11677977558287, 269.69999999999936, 538.9000000000005, 69.39756159241745, 587.3999999999996, 101.39999999999952, 119.29999999999697, 58.90000000000063, 63.712629493019854, 290.4925445973529, 241.13223304703237, 370.91663916018183, 358.9168236676343, 46.22202152717898, 211.1999999999996, 229.8999999999992, 368.2999999999993, 499.59999999999957, 305.39989239170626, 457.21081085698455, 138.59619829468053, 320.3231343679938, 253.4824225396431, 73.20000000000012, 39.693152979228174, 53.10000000000048, 372.01587367805865, 307.3999999999987, 52.08329168814634, 554.6136088493297, 73.4000000000001, 172.51661390670918, 314.5000000000002, 640.3999999999996, 358.4892629866069, 537.1000000000003, 240.62815016043697, 232.99951948252325, 438.4999999999999, 702.0000000000007, 504.6999999999995, 285.60000000000025, 266.70000000000033, 480.4999999999989, 64.7000163742361, 410.6028006084132, 345.90000000000043, 139.69999999999703, 70.90000000000029, 63.30000000000063, 279.64572693029027, 349.70000000000107, 235.9009733077793, 214.99999999999966, 276.68389954105544, 142.185420720523, 205.77902626148932, 37.506740396183545], "episode_lengths": [400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400], "policy_prey_policy_reward": [-33.48037747491744, 176.85623681481698, 26.430160761868635, -40.80481575322529, -173.39070401103916, -171.3907030189248, 184.2055053785144, -144.24432468529602, -7.148732506932676, -97.50055547741172, 11.668652477698977, 10.439842883486808, -152.30137464931465, -9.089360841830988, -135.36871088700246, -95.54433928398602, -161.21227492671034, 202.85323002231996, 33.13768373886731, 322.04191172763416, -37.88776262828977, 47.145506778500135, 79.98681403610979, -35.54340206319812, -188.1825260251033, 53.863974149791545, 246.20772292820098, -219.907991862822, 112.90225687216196, 126.08218511344265, -119.89548173449305, 79.90215770710263, 184.64258542943114, 190.44424775395328, -160.39244496516926, -132.12054811527494, 153.15452921752927, 319.01022357853276, -220.4603417719081, -44.60611747215477, 45.32770716481234, -147.87397598511114, -373.2080565725788, 18.453981624907964, -51.596342986116674, -432.2351876430542, -147.72077693286056, 30.750946971532784, -8.718594784215925, -77.57449877795553, 131.13359888055848, -76.41282741795835, -477.1636031426591, 152.41076216226548, -80.19598183366223, -124.64586702835348, 105.72869619249329, -1.9648889639130256, 55.48568529917049, -45.85455682559444, -62.40214191856839, 17.106722822609925, 87.69666749873406, 268.67402215929803, -50.38696514624137, -144.31431379636612, 65.05585552829419, 33.2460114701502, -13.098430599916068, -268.74883978781844, -11.294394465164757, 181.0634570921933, -16.92513187805305, 96.05843008442278, 14.478941326969109, -67.6590653950308, -118.55555651412521, -177.47588274825026, -189.77188382911984, -304.2946627024392, -254.73581174384054, 154.55987377587115, 82.78844862012033, 50.9480959558138, -451.7500226859305, 4.008634089920729, 103.88041434574149, 24.658147649416875, -162.9990322437011, -94.07113095617306, -170.69966320539146, -130.05132947249965, -153.03879348548688, 168.45588733626113, 235.4768797274106, 348.9665036205082, -110.06406504921048, 78.69916080689893, 95.29151321565989, 326.3721364186882, -19.169826879792645, -104.7844947775372, -158.90534356448262, -64.42264229576017, -353.2742296174582, 362.875458830875, 335.05710303969477, 257.29491828704704, 81.80681267278817, 142.86905860634414, -20.432894403191945, 20.71921057974368, 51.62033460976264, 34.248300659364475, 226.05840366195773, 67.43718812237373, -169.92054494847392, -117.24122907152062, -257.7315121765398, 361.7851532910748, 167.4070074237925, -72.15555908208464, 26.19324651093457, 33.6030165366545, -288.17736288755054, 23.443852062464494, -128.93884488795828, -142.80285529191028, -25.037662258665563, 119.9375724713436, 76.01645177360803, -83.11174434469032, 37.018753924373534, -154.76067785565894, -22.129318425672686, -78.38084396603054, -19.04034715917183, -421.33996044092163, -243.84991359235946, -75.3006140748056, 54.93146134287562, -312.95034565026685, -306.6654186305468, -260.9017327401376], "policy_predator_policy_reward": [68.78037747491791, 106.94376318518296, 21.13203856478976, 389.1593243951866, 243.19070401103826, 227.55798514506557, 198.33881930678086, 0.0, 295.188372311621, 22.260915672723804, 195.88045965349966, 210.33849938273266, 210.6013746493134, 257.0893608418309, 171.94888861910482, 271.96431699674616, 379.348394331207, 3.2588266815118128, 17.520404533498784, 0.0, 261.28776262828944, 81.35449322150023, 23.35436496989366, 163.70222305719363, 257.4705363999939, 51.28566094325446, 161.37833142999125, 111.62193750462882, 152.49653707460456, 48.63580071537401, 153.195481734492, 156.49784229289745, 135.85741457056884, 27.955752246046575, 207.80547173975793, 154.10508293310434, 72.14547078247037, 43.089776421467214, 288.460341771907, 78.00611747215531, 39.072292835188115, 182.77397598510922, 393.5080565725784, 20.14601837509204, 122.12312720547139, 425.42103291672123, 301.2043479921501, 106.25802656652952, 27.284954916112756, 300.1403716930912, 175.8289647421534, 140.36690295542982, 518.7387046770302, 164.93095997099812, 94.06031235660068, 157.00355803259416, 68.77130380750701, 38.664888963913185, 19.01431470082947, 201.2545568255937, 177.30214191856723, 236.29327717738977, 72.07984358427261, 71.14946675769549, 293.5438991777642, 206.55727215654974, 53.51669053940074, 305.3922533191393, 133.96264308871412, 286.4808255937011, 116.00686985184572, 34.547201889119435, 113.36344017054255, 60.98568416273251, 23.621058673030827, 102.7590653950288, 120.34840462746682, 215.3761876141331, 218.97188382911824, 328.1946627024382, 319.2819639355882, 152.90984771044035, 81.77853761281452, 91.88491781125136, 495.9666294389831, 3.858050845174355, 152.21273182395146, 273.86231503021935, 192.6990322436994, 137.77113095617173, 437.37365659266703, 35.89394999193405, 28.794920199800845, 270.2879859494245, 25.623120272589492, 30.333496379491763, 153.6158699346698, 236.2382972942456, 109.10848678433968, 6.327863581311885, 192.06724035824524, 172.51523145952336, 162.8261471603467, 293.5013581824182, 121.2804707762325, 307.61830001035077, 36.04289696030523, 73.605081712953, 93.29318732721097, 186.73094139365585, 264.83289440319186, 20.48078942025648, 0.0, 180.83136473087282, 41.6734821247086, 145.33092609096013, 102.56773114640504, 249.29405924782142, 211.31032296239817, 95.23883653147679, 11.392992576206154, 239.25555908208406, 48.31933511067729, 31.584401841733893, 320.37736288755036, 15.256147937535534, 161.53884488795643, 173.50285529190882, 100.89735298546444, 83.8484637321489, 240.98354822639197, 115.81174434468859, 186.02126421534868, 167.62163302371837, 39.54292005573028, 275.9672423359727, 368.0515318600075, 349.0126752811421, 276.34991359235966, 184.98603479532701, 159.1688218260833, 304.62908874280043, 505.2104852284398, 99.86340653843195]}, "sampler_perf": {"mean_raw_obs_processing_ms": 4.830064915122261, "mean_inference_ms": 4.676858178789684, "mean_action_processing_ms": 2.6437227413734963, "mean_env_wait_ms": 10.142940284028308, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.010469886991712783, "StateBufferConnector_ms": 0.005463593535953098, "ViewRequirementAgentConnector_ms": 0.17164631022347343}, "num_episodes": 0, "episode_return_max": 702.0000000000007, "episode_return_min": 37.506740396183545, "episode_return_mean": 277.3883498707739, "episodes_this_iter": 0}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 192000, "num_agent_steps_trained": 192000, "num_env_steps_sampled": 48000, "num_env_steps_trained": 48000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 82.46614452478374, "num_env_steps_trained_throughput_per_sec": 82.46614452478374, "timesteps_total": 48000, "num_env_steps_sampled_lifetime": 48000, "num_agent_steps_sampled_lifetime": 192000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 192000, "timers": {"training_iteration_time_ms": 49796.511, "restore_workers_time_ms": 0.017, "training_step_time_ms": 49796.46, "sample_time_ms": 2544.133, "learn_time_ms": 47233.743, "learn_throughput": 84.685, "synch_weights_time_ms": 14.473}, "counters": {"num_env_steps_sampled": 48000, "num_env_steps_trained": 48000, "num_agent_steps_sampled": 192000, "num_agent_steps_trained": 192000}, "done": false, "training_iteration": 12, "trial_id": "798d9_00000", "date": "2024-08-22_09-47-27", "timestamp": 1724300247, "time_this_iter_s": 48.56045174598694, "time_total_s": 603.3824329376221, "pid": 48427, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"prey_count": 2, "prey_speed": 1.0, "prey_view_size": 10, "prey_size": 1, "prey_color": [0, 255, 0], "prey_kill_reward": -10, "prey_alive_reward": 0.1, "prey_reward_sqr_reward": 1, "predator_count": 2, "predator_speed": 1.0, "predator_view_size": 10, "predator_size": 1, "predator_color": [255, 0, 0], "predator_kill_reward": 10, "map_size": 40, "max_steps": 400, "screen_size": 600, "render_mode": "None", "fps": 60}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 8, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": true, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 1, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "custom_cnn", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x300bf7ee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 603.3824329376221, "iterations_since_restore": 12, "perf": {"cpu_util_percent": 28.656521739130433, "ram_util_percent": 82.0768115942029}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.501239286434083, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 2.2764822584611397, "policy_loss": -0.01795668292312671, "vf_loss": 2.291560942029196, "vf_explained_var": 0.19070159013939914, "kl": 0.014390001811885407, "entropy": 1.4044198640439876, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 23625.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 9.102820870422182, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 4.371186011682743, "policy_loss": -0.02602800352242652, "vf_loss": 4.394574811849645, "vf_explained_var": 0.35884089201846453, "kl": 0.013196038473496046, "entropy": 1.4372572587911414, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 23625.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 52000, "num_env_steps_trained": 52000, "num_agent_steps_sampled": 208000, "num_agent_steps_trained": 208000}, "env_runners": {"episode_reward_max": 702.0000000000007, "episode_reward_min": 37.506740396183545, "episode_reward_mean": 269.8152693152248, "episode_len_mean": 400.0, "episode_media": {}, "episodes_timesteps_total": 33200, "policy_reward_min": {"prey_policy": -477.1636031426591, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 362.875458830875, "predator_policy": 518.7387046770302}, "policy_reward_mean": {"prey_policy": -20.242386763835434, "predator_policy": 155.15002142144778}, "custom_metrics": {}, "hist_stats": {"episode_reward": [319.1000000000001, 395.91670796862, 125.96728212614214, 238.29999999999967, 212.7999999999985, 428.3274543974187, 306.3000000000013, 213.00015544486337, 424.24817610832963, 372.7000000000017, 351.89999999999907, 231.49999999999957, 174.43764546793366, 299.30000000000024, 440.11677977558287, 269.69999999999936, 538.9000000000005, 69.39756159241745, 587.3999999999996, 101.39999999999952, 119.29999999999697, 58.90000000000063, 63.712629493019854, 290.4925445973529, 241.13223304703237, 370.91663916018183, 358.9168236676343, 46.22202152717898, 211.1999999999996, 229.8999999999992, 368.2999999999993, 499.59999999999957, 305.39989239170626, 457.21081085698455, 138.59619829468053, 320.3231343679938, 253.4824225396431, 73.20000000000012, 39.693152979228174, 53.10000000000048, 372.01587367805865, 307.3999999999987, 52.08329168814634, 554.6136088493297, 73.4000000000001, 172.51661390670918, 314.5000000000002, 640.3999999999996, 358.4892629866069, 537.1000000000003, 240.62815016043697, 232.99951948252325, 438.4999999999999, 702.0000000000007, 504.6999999999995, 285.60000000000025, 266.70000000000033, 480.4999999999989, 64.7000163742361, 410.6028006084132, 345.90000000000043, 139.69999999999703, 70.90000000000029, 63.30000000000063, 279.64572693029027, 349.70000000000107, 235.9009733077793, 214.99999999999966, 276.68389954105544, 142.185420720523, 205.77902626148932, 37.506740396183545, 77.49999999999987, 271.8425160205221, 351.20000000000005, 76.09999999999995, 72.80000000000014, 355.7000000000013, 359.22088371689665, 155.7375321156466, 336.1052306148806, 112.6999999999975, 253.79999999999728], "episode_lengths": [400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400], "policy_prey_policy_reward": [-33.48037747491744, 176.85623681481698, 26.430160761868635, -40.80481575322529, -173.39070401103916, -171.3907030189248, 184.2055053785144, -144.24432468529602, -7.148732506932676, -97.50055547741172, 11.668652477698977, 10.439842883486808, -152.30137464931465, -9.089360841830988, -135.36871088700246, -95.54433928398602, -161.21227492671034, 202.85323002231996, 33.13768373886731, 322.04191172763416, -37.88776262828977, 47.145506778500135, 79.98681403610979, -35.54340206319812, -188.1825260251033, 53.863974149791545, 246.20772292820098, -219.907991862822, 112.90225687216196, 126.08218511344265, -119.89548173449305, 79.90215770710263, 184.64258542943114, 190.44424775395328, -160.39244496516926, -132.12054811527494, 153.15452921752927, 319.01022357853276, -220.4603417719081, -44.60611747215477, 45.32770716481234, -147.87397598511114, -373.2080565725788, 18.453981624907964, -51.596342986116674, -432.2351876430542, -147.72077693286056, 30.750946971532784, -8.718594784215925, -77.57449877795553, 131.13359888055848, -76.41282741795835, -477.1636031426591, 152.41076216226548, -80.19598183366223, -124.64586702835348, 105.72869619249329, -1.9648889639130256, 55.48568529917049, -45.85455682559444, -62.40214191856839, 17.106722822609925, 87.69666749873406, 268.67402215929803, -50.38696514624137, -144.31431379636612, 65.05585552829419, 33.2460114701502, -13.098430599916068, -268.74883978781844, -11.294394465164757, 181.0634570921933, -16.92513187805305, 96.05843008442278, 14.478941326969109, -67.6590653950308, -118.55555651412521, -177.47588274825026, -189.77188382911984, -304.2946627024392, -254.73581174384054, 154.55987377587115, 82.78844862012033, 50.9480959558138, -451.7500226859305, 4.008634089920729, 103.88041434574149, 24.658147649416875, -162.9990322437011, -94.07113095617306, -170.69966320539146, -130.05132947249965, -153.03879348548688, 168.45588733626113, 235.4768797274106, 348.9665036205082, -110.06406504921048, 78.69916080689893, 95.29151321565989, 326.3721364186882, -19.169826879792645, -104.7844947775372, -158.90534356448262, -64.42264229576017, -353.2742296174582, 362.875458830875, 335.05710303969477, 257.29491828704704, 81.80681267278817, 142.86905860634414, -20.432894403191945, 20.71921057974368, 51.62033460976264, 34.248300659364475, 226.05840366195773, 67.43718812237373, -169.92054494847392, -117.24122907152062, -257.7315121765398, 361.7851532910748, 167.4070074237925, -72.15555908208464, 26.19324651093457, 33.6030165366545, -288.17736288755054, 23.443852062464494, -128.93884488795828, -142.80285529191028, -25.037662258665563, 119.9375724713436, 76.01645177360803, -83.11174434469032, 37.018753924373534, -154.76067785565894, -22.129318425672686, -78.38084396603054, -19.04034715917183, -421.33996044092163, -243.84991359235946, -75.3006140748056, 54.93146134287562, -312.95034565026685, -306.6654186305468, -260.9017327401376, 31.996687674699466, 10.34654449282513, 34.38302170292425, -76.00888895123396, -71.92676674605877, 134.63575370769615, -34.22777170509586, 20.782347460913304, -14.544705892595905, -31.805622761643214, -69.92707120921031, 278.84899009248386, 230.7530938951969, -397.9559854840322, -42.78852140229542, 2.883250559362983, -135.89478858578298, -165.35902046121583, -41.16909061479087, 35.7415997430519, 180.95020980183662, 21.37570396407685], "policy_predator_policy_reward": [68.78037747491791, 106.94376318518296, 21.13203856478976, 389.1593243951866, 243.19070401103826, 227.55798514506557, 198.33881930678086, 0.0, 295.188372311621, 22.260915672723804, 195.88045965349966, 210.33849938273266, 210.6013746493134, 257.0893608418309, 171.94888861910482, 271.96431699674616, 379.348394331207, 3.2588266815118128, 17.520404533498784, 0.0, 261.28776262828944, 81.35449322150023, 23.35436496989366, 163.70222305719363, 257.4705363999939, 51.28566094325446, 161.37833142999125, 111.62193750462882, 152.49653707460456, 48.63580071537401, 153.195481734492, 156.49784229289745, 135.85741457056884, 27.955752246046575, 207.80547173975793, 154.10508293310434, 72.14547078247037, 43.089776421467214, 288.460341771907, 78.00611747215531, 39.072292835188115, 182.77397598510922, 393.5080565725784, 20.14601837509204, 122.12312720547139, 425.42103291672123, 301.2043479921501, 106.25802656652952, 27.284954916112756, 300.1403716930912, 175.8289647421534, 140.36690295542982, 518.7387046770302, 164.93095997099812, 94.06031235660068, 157.00355803259416, 68.77130380750701, 38.664888963913185, 19.01431470082947, 201.2545568255937, 177.30214191856723, 236.29327717738977, 72.07984358427261, 71.14946675769549, 293.5438991777642, 206.55727215654974, 53.51669053940074, 305.3922533191393, 133.96264308871412, 286.4808255937011, 116.00686985184572, 34.547201889119435, 113.36344017054255, 60.98568416273251, 23.621058673030827, 102.7590653950288, 120.34840462746682, 215.3761876141331, 218.97188382911824, 328.1946627024382, 319.2819639355882, 152.90984771044035, 81.77853761281452, 91.88491781125136, 495.9666294389831, 3.858050845174355, 152.21273182395146, 273.86231503021935, 192.6990322436994, 137.77113095617173, 437.37365659266703, 35.89394999193405, 28.794920199800845, 270.2879859494245, 25.623120272589492, 30.333496379491763, 153.6158699346698, 236.2382972942456, 109.10848678433968, 6.327863581311885, 192.06724035824524, 172.51523145952336, 162.8261471603467, 293.5013581824182, 121.2804707762325, 307.61830001035077, 36.04289696030523, 73.605081712953, 93.29318732721097, 186.73094139365585, 264.83289440319186, 20.48078942025648, 0.0, 180.83136473087282, 41.6734821247086, 145.33092609096013, 102.56773114640504, 249.29405924782142, 211.31032296239817, 95.23883653147679, 11.392992576206154, 239.25555908208406, 48.31933511067729, 31.584401841733893, 320.37736288755036, 15.256147937535534, 161.53884488795643, 173.50285529190882, 100.89735298546444, 83.8484637321489, 240.98354822639197, 115.81174434468859, 186.02126421534868, 167.62163302371837, 39.54292005573028, 275.9672423359727, 368.0515318600075, 349.0126752811421, 276.34991359235966, 184.98603479532701, 159.1688218260833, 304.62908874280043, 505.2104852284398, 99.86340653843195, 7.303312325300711, 27.853455507174978, 74.18320943417223, 239.28517383465712, 124.65178849150561, 163.83922454685717, 70.22777170509606, 19.317652539086684, 51.544705892596404, 67.60562276164372, 103.42707120920916, 43.351009907516115, 452.7364425343829, 73.68733277134959, 59.08737096883469, 136.5554319897471, 326.5144604485311, 310.8445792133451, 114.26909061479087, 3.85840025694834, 8.832114021663266, 42.64197221242239]}, "sampler_perf": {"mean_raw_obs_processing_ms": 4.768306197169487, "mean_inference_ms": 4.599059949407463, "mean_action_processing_ms": 2.548481489384639, "mean_env_wait_ms": 10.120804889273915, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.009656957833163709, "StateBufferConnector_ms": 0.00524089997073254, "ViewRequirementAgentConnector_ms": 0.1774836735553052}, "num_episodes": 11, "episode_return_max": 702.0000000000007, "episode_return_min": 37.506740396183545, "episode_return_mean": 269.8152693152248, "episodes_this_iter": 11}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 208000, "num_agent_steps_trained": 208000, "num_env_steps_sampled": 52000, "num_env_steps_trained": 52000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 82.50879168126158, "num_env_steps_trained_throughput_per_sec": 82.50879168126158, "timesteps_total": 52000, "num_env_steps_sampled_lifetime": 52000, "num_agent_steps_sampled_lifetime": 208000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 208000, "timers": {"training_iteration_time_ms": 49418.617, "restore_workers_time_ms": 0.016, "training_step_time_ms": 49418.567, "sample_time_ms": 2504.603, "learn_time_ms": 46895.113, "learn_throughput": 85.297, "synch_weights_time_ms": 14.669}, "counters": {"num_env_steps_sampled": 52000, "num_env_steps_trained": 52000, "num_agent_steps_sampled": 208000, "num_agent_steps_trained": 208000}, "done": false, "training_iteration": 13, "trial_id": "798d9_00000", "date": "2024-08-22_09-48-16", "timestamp": 1724300296, "time_this_iter_s": 48.5427942276001, "time_total_s": 651.9252271652222, "pid": 48427, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"prey_count": 2, "prey_speed": 1.0, "prey_view_size": 10, "prey_size": 1, "prey_color": [0, 255, 0], "prey_kill_reward": -10, "prey_alive_reward": 0.1, "prey_reward_sqr_reward": 1, "predator_count": 2, "predator_speed": 1.0, "predator_view_size": 10, "predator_size": 1, "predator_color": [255, 0, 0], "predator_kill_reward": 10, "map_size": 40, "max_steps": 400, "screen_size": 600, "render_mode": "None", "fps": 60}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 8, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": true, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 1, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "custom_cnn", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x300bfd550>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 651.9252271652222, "iterations_since_restore": 13, "perf": {"cpu_util_percent": 28.96956521739131, "ram_util_percent": 82.62463768115944}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.756059039648248, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 3.299593170736202, "policy_loss": -0.019519217540978125, "vf_loss": 3.3158289298809396, "vf_explained_var": 0.22127406565600602, "kl": 0.016417323585806623, "entropy": 1.3122502196402777, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 25515.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 9.550334609784777, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 4.808806545898397, "policy_loss": -0.024155524016786663, "vf_loss": 4.830309560311535, "vf_explained_var": 0.34468860777597576, "kl": 0.013262538361072383, "entropy": 1.395182333799897, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 25515.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 56000, "num_env_steps_trained": 56000, "num_agent_steps_sampled": 224000, "num_agent_steps_trained": 224000}, "env_runners": {"episode_reward_max": 723.1480054049603, "episode_reward_min": 37.506740396183545, "episode_reward_mean": 290.3496694479087, "episode_len_mean": 400.0, "episode_media": {}, "episodes_timesteps_total": 40000, "policy_reward_min": {"prey_policy": -477.1636031426591, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 376.812382620373, "predator_policy": 518.7387046770302}, "policy_reward_mean": {"prey_policy": -4.956779750134191, "predator_policy": 150.1316144740884}, "custom_metrics": {}, "hist_stats": {"episode_reward": [212.7999999999985, 428.3274543974187, 306.3000000000013, 213.00015544486337, 424.24817610832963, 372.7000000000017, 351.89999999999907, 231.49999999999957, 174.43764546793366, 299.30000000000024, 440.11677977558287, 269.69999999999936, 538.9000000000005, 69.39756159241745, 587.3999999999996, 101.39999999999952, 119.29999999999697, 58.90000000000063, 63.712629493019854, 290.4925445973529, 241.13223304703237, 370.91663916018183, 358.9168236676343, 46.22202152717898, 211.1999999999996, 229.8999999999992, 368.2999999999993, 499.59999999999957, 305.39989239170626, 457.21081085698455, 138.59619829468053, 320.3231343679938, 253.4824225396431, 73.20000000000012, 39.693152979228174, 53.10000000000048, 372.01587367805865, 307.3999999999987, 52.08329168814634, 554.6136088493297, 73.4000000000001, 172.51661390670918, 314.5000000000002, 640.3999999999996, 358.4892629866069, 537.1000000000003, 240.62815016043697, 232.99951948252325, 438.4999999999999, 702.0000000000007, 504.6999999999995, 285.60000000000025, 266.70000000000033, 480.4999999999989, 64.7000163742361, 410.6028006084132, 345.90000000000043, 139.69999999999703, 70.90000000000029, 63.30000000000063, 279.64572693029027, 349.70000000000107, 235.9009733077793, 214.99999999999966, 276.68389954105544, 142.185420720523, 205.77902626148932, 37.506740396183545, 77.49999999999987, 271.8425160205221, 351.20000000000005, 76.09999999999995, 72.80000000000014, 355.7000000000013, 359.22088371689665, 155.7375321156466, 336.1052306148806, 112.6999999999975, 253.79999999999728, 721.4984895986631, 339.2000000000014, 75.30897762584883, 722.5725727731624, 173.58894962874808, 414.3321651231242, 258.49999999999886, 384.0000000000024, 240.96741587580104, 703.8146078439153, 423.4788817070565, 335.0000000000022, 74.60000000000005, 723.1480054049603, 193.5544715538415, 488.6302082538318, 69.9129267472765, 340.7263431202153, 392.4665577952974, 545.9830086702245, 98.2999999999984], "episode_lengths": [400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400], "policy_prey_policy_reward": [-7.148732506932676, -97.50055547741172, 11.668652477698977, 10.439842883486808, -152.30137464931465, -9.089360841830988, -135.36871088700246, -95.54433928398602, -161.21227492671034, 202.85323002231996, 33.13768373886731, 322.04191172763416, -37.88776262828977, 47.145506778500135, 79.98681403610979, -35.54340206319812, -188.1825260251033, 53.863974149791545, 246.20772292820098, -219.907991862822, 112.90225687216196, 126.08218511344265, -119.89548173449305, 79.90215770710263, 184.64258542943114, 190.44424775395328, -160.39244496516926, -132.12054811527494, 153.15452921752927, 319.01022357853276, -220.4603417719081, -44.60611747215477, 45.32770716481234, -147.87397598511114, -373.2080565725788, 18.453981624907964, -51.596342986116674, -432.2351876430542, -147.72077693286056, 30.750946971532784, -8.718594784215925, -77.57449877795553, 131.13359888055848, -76.41282741795835, -477.1636031426591, 152.41076216226548, -80.19598183366223, -124.64586702835348, 105.72869619249329, -1.9648889639130256, 55.48568529917049, -45.85455682559444, -62.40214191856839, 17.106722822609925, 87.69666749873406, 268.67402215929803, -50.38696514624137, -144.31431379636612, 65.05585552829419, 33.2460114701502, -13.098430599916068, -268.74883978781844, -11.294394465164757, 181.0634570921933, -16.92513187805305, 96.05843008442278, 14.478941326969109, -67.6590653950308, -118.55555651412521, -177.47588274825026, -189.77188382911984, -304.2946627024392, -254.73581174384054, 154.55987377587115, 82.78844862012033, 50.9480959558138, -451.7500226859305, 4.008634089920729, 103.88041434574149, 24.658147649416875, -162.9990322437011, -94.07113095617306, -170.69966320539146, -130.05132947249965, -153.03879348548688, 168.45588733626113, 235.4768797274106, 348.9665036205082, -110.06406504921048, 78.69916080689893, 95.29151321565989, 326.3721364186882, -19.169826879792645, -104.7844947775372, -158.90534356448262, -64.42264229576017, -353.2742296174582, 362.875458830875, 335.05710303969477, 257.29491828704704, 81.80681267278817, 142.86905860634414, -20.432894403191945, 20.71921057974368, 51.62033460976264, 34.248300659364475, 226.05840366195773, 67.43718812237373, -169.92054494847392, -117.24122907152062, -257.7315121765398, 361.7851532910748, 167.4070074237925, -72.15555908208464, 26.19324651093457, 33.6030165366545, -288.17736288755054, 23.443852062464494, -128.93884488795828, -142.80285529191028, -25.037662258665563, 119.9375724713436, 76.01645177360803, -83.11174434469032, 37.018753924373534, -154.76067785565894, -22.129318425672686, -78.38084396603054, -19.04034715917183, -421.33996044092163, -243.84991359235946, -75.3006140748056, 54.93146134287562, -312.95034565026685, -306.6654186305468, -260.9017327401376, 31.996687674699466, 10.34654449282513, 34.38302170292425, -76.00888895123396, -71.92676674605877, 134.63575370769615, -34.22777170509586, 20.782347460913304, -14.544705892595905, -31.805622761643214, -69.92707120921031, 278.84899009248386, 230.7530938951969, -397.9559854840322, -42.78852140229542, 2.883250559362983, -135.89478858578298, -165.35902046121583, -41.16909061479087, 35.7415997430519, 180.95020980183662, 21.37570396407685, 376.812382620373, 238.67536051365965, -4.43180510827797, 166.23865487288418, -27.67991996354027, -164.21709143395827, 178.22699779725613, 376.50488660967693, -20.16341730583126, -245.22234222187024, 160.01817667167325, 123.21176222927895, -20.215857706416543, 121.35425197813554, -51.57749341911413, 306.5751911969785, -192.40888599054787, -77.841632635107, 188.87290687109663, 371.48585235607493, 335.9683026473879, -9.896362053920004, 116.41860709750614, 34.904361931576304, -110.79399720694488, -21.801659883465526, 238.165410034407, 219.8827998355583, 15.59405184196084, -168.98851628184283, 72.46951393471171, 162.77193975145033, -58.30292523317673, -172.50928584692716, 81.88041325852578, -341.07474037518733, -297.50826128377986, 162.03038682314977, 46.34328116392672, 131.33413444684265, -85.28254186766168, 37.238340115120536], "policy_predator_policy_reward": [295.188372311621, 22.260915672723804, 195.88045965349966, 210.33849938273266, 210.6013746493134, 257.0893608418309, 171.94888861910482, 271.96431699674616, 379.348394331207, 3.2588266815118128, 17.520404533498784, 0.0, 261.28776262828944, 81.35449322150023, 23.35436496989366, 163.70222305719363, 257.4705363999939, 51.28566094325446, 161.37833142999125, 111.62193750462882, 152.49653707460456, 48.63580071537401, 153.195481734492, 156.49784229289745, 135.85741457056884, 27.955752246046575, 207.80547173975793, 154.10508293310434, 72.14547078247037, 43.089776421467214, 288.460341771907, 78.00611747215531, 39.072292835188115, 182.77397598510922, 393.5080565725784, 20.14601837509204, 122.12312720547139, 425.42103291672123, 301.2043479921501, 106.25802656652952, 27.284954916112756, 300.1403716930912, 175.8289647421534, 140.36690295542982, 518.7387046770302, 164.93095997099812, 94.06031235660068, 157.00355803259416, 68.77130380750701, 38.664888963913185, 19.01431470082947, 201.2545568255937, 177.30214191856723, 236.29327717738977, 72.07984358427261, 71.14946675769549, 293.5438991777642, 206.55727215654974, 53.51669053940074, 305.3922533191393, 133.96264308871412, 286.4808255937011, 116.00686985184572, 34.547201889119435, 113.36344017054255, 60.98568416273251, 23.621058673030827, 102.7590653950288, 120.34840462746682, 215.3761876141331, 218.97188382911824, 328.1946627024382, 319.2819639355882, 152.90984771044035, 81.77853761281452, 91.88491781125136, 495.9666294389831, 3.858050845174355, 152.21273182395146, 273.86231503021935, 192.6990322436994, 137.77113095617173, 437.37365659266703, 35.89394999193405, 28.794920199800845, 270.2879859494245, 25.623120272589492, 30.333496379491763, 153.6158699346698, 236.2382972942456, 109.10848678433968, 6.327863581311885, 192.06724035824524, 172.51523145952336, 162.8261471603467, 293.5013581824182, 121.2804707762325, 307.61830001035077, 36.04289696030523, 73.605081712953, 93.29318732721097, 186.73094139365585, 264.83289440319186, 20.48078942025648, 0.0, 180.83136473087282, 41.6734821247086, 145.33092609096013, 102.56773114640504, 249.29405924782142, 211.31032296239817, 95.23883653147679, 11.392992576206154, 239.25555908208406, 48.31933511067729, 31.584401841733893, 320.37736288755036, 15.256147937535534, 161.53884488795643, 173.50285529190882, 100.89735298546444, 83.8484637321489, 240.98354822639197, 115.81174434468859, 186.02126421534868, 167.62163302371837, 39.54292005573028, 275.9672423359727, 368.0515318600075, 349.0126752811421, 276.34991359235966, 184.98603479532701, 159.1688218260833, 304.62908874280043, 505.2104852284398, 99.86340653843195, 7.303312325300711, 27.853455507174978, 74.18320943417223, 239.28517383465712, 124.65178849150561, 163.83922454685717, 70.22777170509606, 19.317652539086684, 51.544705892596404, 67.60562276164372, 103.42707120920916, 43.351009907516115, 452.7364425343829, 73.68733277134959, 59.08737096883469, 136.5554319897471, 326.5144604485311, 310.8445792133451, 114.26909061479087, 3.85840025694834, 8.832114021663266, 42.64197221242239, 48.94219097032222, 57.068555494308264, 47.997631840897064, 129.39551839449697, 92.16123838429971, 175.04475063904655, 47.99618264074478, 119.8445057254844, 247.55790001950245, 191.41680913694933, 35.490956156910784, 95.6112700652532, 112.52790766200972, 44.8336980662715, 95.52136695461668, 33.480935267517815, 255.50298303454406, 255.71495146691126, 98.0831479592286, 45.37270065751511, 50.17855548698743, 47.22838562659909, 71.87426679582525, 111.80276417509246, 148.19399720694318, 59.001659883466054, 144.4351585296887, 120.6646370053063, 268.35152675598937, 78.59740923773558, 3.9032024145927275, 249.4855521530756, 98.2290317846702, 202.49610604270714, 155.5281616442165, 444.3925085926601, 345.33050151087895, 182.61393074504878, 352.9001988343047, 15.405394225149582, 143.78254186766017, 2.5616598848797247]}, "sampler_perf": {"mean_raw_obs_processing_ms": 4.680801584264803, "mean_inference_ms": 4.496871900335682, "mean_action_processing_ms": 2.376586961786646, "mean_env_wait_ms": 10.083663688635902, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.013302445411682129, "StateBufferConnector_ms": 0.00510251522064209, "ViewRequirementAgentConnector_ms": 0.171563982963562}, "num_episodes": 21, "episode_return_max": 723.1480054049603, "episode_return_min": 37.506740396183545, "episode_return_mean": 290.3496694479087, "episodes_this_iter": 21}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 224000, "num_agent_steps_trained": 224000, "num_env_steps_sampled": 56000, "num_env_steps_trained": 56000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 80.50358231530706, "num_env_steps_trained_throughput_per_sec": 80.50358231530706, "timesteps_total": 56000, "num_env_steps_sampled_lifetime": 56000, "num_agent_steps_sampled_lifetime": 224000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 224000, "timers": {"training_iteration_time_ms": 49486.828, "restore_workers_time_ms": 0.017, "training_step_time_ms": 49486.778, "sample_time_ms": 2497.657, "learn_time_ms": 46970.003, "learn_throughput": 85.161, "synch_weights_time_ms": 14.845}, "counters": {"num_env_steps_sampled": 56000, "num_env_steps_trained": 56000, "num_agent_steps_sampled": 224000, "num_agent_steps_trained": 224000}, "done": false, "training_iteration": 14, "trial_id": "798d9_00000", "date": "2024-08-22_09-49-06", "timestamp": 1724300346, "time_this_iter_s": 49.760759115219116, "time_total_s": 701.6859862804413, "pid": 48427, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"prey_count": 2, "prey_speed": 1.0, "prey_view_size": 10, "prey_size": 1, "prey_color": [0, 255, 0], "prey_kill_reward": -10, "prey_alive_reward": 0.1, "prey_reward_sqr_reward": 1, "predator_count": 2, "predator_speed": 1.0, "predator_view_size": 10, "predator_size": 1, "predator_color": [255, 0, 0], "predator_kill_reward": 10, "map_size": 40, "max_steps": 400, "screen_size": 600, "render_mode": "None", "fps": 60}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 8, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": true, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 1, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "custom_cnn", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x16cfc4f70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 701.6859862804413, "iterations_since_restore": 14, "perf": {"cpu_util_percent": 32.612676056338024, "ram_util_percent": 83.2183098591549}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.968013496373696, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 5.699089044742483, "policy_loss": -0.017463446962129738, "vf_loss": 5.712985740893732, "vf_explained_var": 0.22424434057619205, "kl": 0.01783386112126724, "entropy": 1.1519755989155442, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 27405.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 7.733860282292442, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 6.028975345217993, "policy_loss": -0.02476187289554488, "vf_loss": 6.0506564892158305, "vf_explained_var": 0.08997181868427014, "kl": 0.015403702445623894, "entropy": 1.3331436347078394, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 27405.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 60000, "num_env_steps_trained": 60000, "num_agent_steps_sampled": 240000, "num_agent_steps_trained": 240000}, "env_runners": {"episode_reward_max": 723.1480054049603, "episode_reward_min": 37.506740396183545, "episode_reward_mean": 289.4042679449699, "episode_len_mean": 400.0, "episode_media": {}, "episodes_timesteps_total": 40000, "policy_reward_min": {"prey_policy": -717.2097699875618, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 376.812382620373, "predator_policy": 759.4665335850866}, "policy_reward_mean": {"prey_policy": -17.381333179507784, "predator_policy": 162.0834671519926}, "custom_metrics": {}, "hist_stats": {"episode_reward": [253.4824225396431, 73.20000000000012, 39.693152979228174, 53.10000000000048, 372.01587367805865, 307.3999999999987, 52.08329168814634, 554.6136088493297, 73.4000000000001, 172.51661390670918, 314.5000000000002, 640.3999999999996, 358.4892629866069, 537.1000000000003, 240.62815016043697, 232.99951948252325, 438.4999999999999, 702.0000000000007, 504.6999999999995, 285.60000000000025, 266.70000000000033, 480.4999999999989, 64.7000163742361, 410.6028006084132, 345.90000000000043, 139.69999999999703, 70.90000000000029, 63.30000000000063, 279.64572693029027, 349.70000000000107, 235.9009733077793, 214.99999999999966, 276.68389954105544, 142.185420720523, 205.77902626148932, 37.506740396183545, 77.49999999999987, 271.8425160205221, 351.20000000000005, 76.09999999999995, 72.80000000000014, 355.7000000000013, 359.22088371689665, 155.7375321156466, 336.1052306148806, 112.6999999999975, 253.79999999999728, 721.4984895986631, 339.2000000000014, 75.30897762584883, 722.5725727731624, 173.58894962874808, 414.3321651231242, 258.49999999999886, 384.0000000000024, 240.96741587580104, 703.8146078439153, 423.4788817070565, 335.0000000000022, 74.60000000000005, 723.1480054049603, 193.5544715538415, 488.6302082538318, 69.9129267472765, 340.7263431202153, 392.4665577952974, 545.9830086702245, 98.2999999999984, 316.7000000000009, 227.6999999999974, 193.37327863109786, 154.45429480276803, 491.65151733745085, 320.32080431783436, 322.24259643122446, 418.40000000000236, 157.81851315233754, 229.22599306291164, 324.75804483222174, 94.09999999999852, 364.2453454854257, 347.4000000000017, 201.39999999999847, 241.89999999999782, 110.0813413518992, 66.5000000000005, 208.39875498733264, 200.43662297567656, 565.9816752716484, 390.813077006542, 163.06813170125574, 70.80000000000027, 271.47241157243354, 485.6470795074924, 641.472844360221, 289.40387365809295, 292.6693794986311, 139.59999999999746, 479.87496995193294, 225.099999999998], "episode_lengths": [400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400], "policy_prey_policy_reward": [-16.92513187805305, 96.05843008442278, 14.478941326969109, -67.6590653950308, -118.55555651412521, -177.47588274825026, -189.77188382911984, -304.2946627024392, -254.73581174384054, 154.55987377587115, 82.78844862012033, 50.9480959558138, -451.7500226859305, 4.008634089920729, 103.88041434574149, 24.658147649416875, -162.9990322437011, -94.07113095617306, -170.69966320539146, -130.05132947249965, -153.03879348548688, 168.45588733626113, 235.4768797274106, 348.9665036205082, -110.06406504921048, 78.69916080689893, 95.29151321565989, 326.3721364186882, -19.169826879792645, -104.7844947775372, -158.90534356448262, -64.42264229576017, -353.2742296174582, 362.875458830875, 335.05710303969477, 257.29491828704704, 81.80681267278817, 142.86905860634414, -20.432894403191945, 20.71921057974368, 51.62033460976264, 34.248300659364475, 226.05840366195773, 67.43718812237373, -169.92054494847392, -117.24122907152062, -257.7315121765398, 361.7851532910748, 167.4070074237925, -72.15555908208464, 26.19324651093457, 33.6030165366545, -288.17736288755054, 23.443852062464494, -128.93884488795828, -142.80285529191028, -25.037662258665563, 119.9375724713436, 76.01645177360803, -83.11174434469032, 37.018753924373534, -154.76067785565894, -22.129318425672686, -78.38084396603054, -19.04034715917183, -421.33996044092163, -243.84991359235946, -75.3006140748056, 54.93146134287562, -312.95034565026685, -306.6654186305468, -260.9017327401376, 31.996687674699466, 10.34654449282513, 34.38302170292425, -76.00888895123396, -71.92676674605877, 134.63575370769615, -34.22777170509586, 20.782347460913304, -14.544705892595905, -31.805622761643214, -69.92707120921031, 278.84899009248386, 230.7530938951969, -397.9559854840322, -42.78852140229542, 2.883250559362983, -135.89478858578298, -165.35902046121583, -41.16909061479087, 35.7415997430519, 180.95020980183662, 21.37570396407685, 376.812382620373, 238.67536051365965, -4.43180510827797, 166.23865487288418, -27.67991996354027, -164.21709143395827, 178.22699779725613, 376.50488660967693, -20.16341730583126, -245.22234222187024, 160.01817667167325, 123.21176222927895, -20.215857706416543, 121.35425197813554, -51.57749341911413, 306.5751911969785, -192.40888599054787, -77.841632635107, 188.87290687109663, 371.48585235607493, 335.9683026473879, -9.896362053920004, 116.41860709750614, 34.904361931576304, -110.79399720694488, -21.801659883465526, 238.165410034407, 219.8827998355583, 15.59405184196084, -168.98851628184283, 72.46951393471171, 162.77193975145033, -58.30292523317673, -172.50928584692716, 81.88041325852578, -341.07474037518733, -297.50826128377986, 162.03038682314977, 46.34328116392672, 131.33413444684265, -85.28254186766168, 37.238340115120536, 15.85916393149381, 85.66739952993525, 22.684045979464056, 98.53515575320644, -87.13196176951354, -94.37986289616912, -149.76831165587336, -75.51364954145205, -36.71783950835651, 254.969615421524, -110.25832207875189, -287.6128259541711, -65.65915374974611, 102.55344483659391, 32.72318239507697, 354.4670965799534, -166.77066475120913, -27.417026496085683, -12.586726203201136, -227.1978859956428, 140.5945339114458, -382.3472846149405, -267.01312868873384, -68.56653485713092, -717.2097699875618, 63.588297442470555, 167.8923696688501, 9.28816264377539, -280.227785948628, 21.18204378720486, 25.88774058410634, -117.00891312813721, -82.28048431438276, -88.88794122105355, 22.303183204337465, -197.6956768698257, -554.0154183602142, 77.35304482442349, -247.36430799600797, -196.6907244586775, -106.37918720231912, 281.6170912392196, 59.20077720047444, -295.77302853798363, 4.021379005777842, 34.916329868153014, -32.42448643294864, -60.520441200790195, 128.30208745411701, -8.632199429560416, -13.598161324406597, 165.327598003983, 236.89376340262797, 240.12460891032336, -154.1987553812961, -3.38499640213143, -52.21930582784222, -676.1833750043567, -146.60816132987821, 36.49736207429844, 208.80140202984538, -129.58778107555176, -24.417826634627417, -178.86622926616926], "policy_predator_policy_reward": [113.36344017054255, 60.98568416273251, 23.621058673030827, 102.7590653950288, 120.34840462746682, 215.3761876141331, 218.97188382911824, 328.1946627024382, 319.2819639355882, 152.90984771044035, 81.77853761281452, 91.88491781125136, 495.9666294389831, 3.858050845174355, 152.21273182395146, 273.86231503021935, 192.6990322436994, 137.77113095617173, 437.37365659266703, 35.89394999193405, 28.794920199800845, 270.2879859494245, 25.623120272589492, 30.333496379491763, 153.6158699346698, 236.2382972942456, 109.10848678433968, 6.327863581311885, 192.06724035824524, 172.51523145952336, 162.8261471603467, 293.5013581824182, 121.2804707762325, 307.61830001035077, 36.04289696030523, 73.605081712953, 93.29318732721097, 186.73094139365585, 264.83289440319186, 20.48078942025648, 0.0, 180.83136473087282, 41.6734821247086, 145.33092609096013, 102.56773114640504, 249.29405924782142, 211.31032296239817, 95.23883653147679, 11.392992576206154, 239.25555908208406, 48.31933511067729, 31.584401841733893, 320.37736288755036, 15.256147937535534, 161.53884488795643, 173.50285529190882, 100.89735298546444, 83.8484637321489, 240.98354822639197, 115.81174434468859, 186.02126421534868, 167.62163302371837, 39.54292005573028, 275.9672423359727, 368.0515318600075, 349.0126752811421, 276.34991359235966, 184.98603479532701, 159.1688218260833, 304.62908874280043, 505.2104852284398, 99.86340653843195, 7.303312325300711, 27.853455507174978, 74.18320943417223, 239.28517383465712, 124.65178849150561, 163.83922454685717, 70.22777170509606, 19.317652539086684, 51.544705892596404, 67.60562276164372, 103.42707120920916, 43.351009907516115, 452.7364425343829, 73.68733277134959, 59.08737096883469, 136.5554319897471, 326.5144604485311, 310.8445792133451, 114.26909061479087, 3.85840025694834, 8.832114021663266, 42.64197221242239, 48.94219097032222, 57.068555494308264, 47.997631840897064, 129.39551839449697, 92.16123838429971, 175.04475063904655, 47.99618264074478, 119.8445057254844, 247.55790001950245, 191.41680913694933, 35.490956156910784, 95.6112700652532, 112.52790766200972, 44.8336980662715, 95.52136695461668, 33.480935267517815, 255.50298303454406, 255.71495146691126, 98.0831479592286, 45.37270065751511, 50.17855548698743, 47.22838562659909, 71.87426679582525, 111.80276417509246, 148.19399720694318, 59.001659883466054, 144.4351585296887, 120.6646370053063, 268.35152675598937, 78.59740923773558, 3.9032024145927275, 249.4855521530756, 98.2290317846702, 202.49610604270714, 155.5281616442165, 444.3925085926601, 345.33050151087895, 182.61393074504878, 352.9001988343047, 15.405394225149582, 143.78254186766017, 2.5616598848797247, 22.340836068506178, 192.83260047006453, 16.01595402053598, 90.46484424679274, 35.59821790301873, 339.28688539376185, 306.9695322051485, 72.76672379494487, 217.91569059613775, 55.48405082814195, 435.95660559066124, 282.2353467600994, 146.1898458007251, 139.15845954364437, 6.676817604923221, 24.532903420046566, 187.30150813882418, 164.70469626081004, 82.83604087979359, 386.1745643819638, 368.4777954542359, 198.03300008148415, 302.40890144869473, 127.27076209717296, 311.5444041395558, 706.3224138909611, 28.748303230751507, 141.4711644566232, 309.02778594863446, 151.4179562127952, 12.812259415893742, 320.208913128137, 136.73623637017465, 144.51353051715768, 16.096816795662544, 225.79567686982415, 67.18142319031695, 617.8797053328075, 344.06051655132137, 300.43113887904093, 353.2698161330049, 37.473955101743016, 445.68147119629776, 181.70385714775293, 76.97185206056606, 47.15857076676161, 68.32448643294913, 95.42044120078874, 122.1710150926939, 29.63150845518346, 37.895128270290236, 296.0225145576254, 107.99259423247598, 56.46187781479349, 112.26595953431027, 334.7216659072099, 759.4665335850866, 261.60552674574205, 246.50816132987754, 3.202637925701816, 274.7865713661366, 125.87477763150062, 214.2230592747555, 214.16099662604157]}, "sampler_perf": {"mean_raw_obs_processing_ms": 4.541994630119945, "mean_inference_ms": 4.345235889753215, "mean_action_processing_ms": 1.9452312721264096, "mean_env_wait_ms": 9.985038978437627, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00913381576538086, "StateBufferConnector_ms": 0.004638075828552246, "ViewRequirementAgentConnector_ms": 0.1879587173461914}, "num_episodes": 32, "episode_return_max": 723.1480054049603, "episode_return_min": 37.506740396183545, "episode_return_mean": 289.4042679449699, "episodes_this_iter": 32}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 240000, "num_agent_steps_trained": 240000, "num_env_steps_sampled": 60000, "num_env_steps_trained": 60000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 78.449592656775, "num_env_steps_trained_throughput_per_sec": 78.449592656775, "timesteps_total": 60000, "num_env_steps_sampled_lifetime": 60000, "num_agent_steps_sampled_lifetime": 240000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 240000, "timers": {"training_iteration_time_ms": 49447.225, "restore_workers_time_ms": 0.017, "training_step_time_ms": 49447.176, "sample_time_ms": 2255.712, "learn_time_ms": 47172.685, "learn_throughput": 84.795, "synch_weights_time_ms": 14.789}, "counters": {"num_env_steps_sampled": 60000, "num_env_steps_trained": 60000, "num_agent_steps_sampled": 240000, "num_agent_steps_trained": 240000}, "done": false, "training_iteration": 15, "trial_id": "798d9_00000", "date": "2024-08-22_09-49-57", "timestamp": 1724300397, "time_this_iter_s": 51.042017221450806, "time_total_s": 752.7280035018921, "pid": 48427, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"prey_count": 2, "prey_speed": 1.0, "prey_view_size": 10, "prey_size": 1, "prey_color": [0, 255, 0], "prey_kill_reward": -10, "prey_alive_reward": 0.1, "prey_reward_sqr_reward": 1, "predator_count": 2, "predator_speed": 1.0, "predator_view_size": 10, "predator_size": 1, "predator_color": [255, 0, 0], "predator_kill_reward": 10, "map_size": 40, "max_steps": 400, "screen_size": 600, "render_mode": "None", "fps": 60}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 8, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": true, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 1, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "custom_cnn", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x300bfdaf0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 752.7280035018921, "iterations_since_restore": 15, "perf": {"cpu_util_percent": 36.013698630136986, "ram_util_percent": 83.04109589041094}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.54144502178071, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 6.7575078618589535, "policy_loss": -0.020251523623755447, "vf_loss": 6.774699784586669, "vf_explained_var": 0.22313577857597794, "kl": 0.01529795118267574, "entropy": 1.024552607946295, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 29295.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 7.478758779026213, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 7.111076549752049, "policy_loss": -0.023975380795648094, "vf_loss": 7.131329177674793, "vf_explained_var": 0.07285132559518966, "kl": 0.018613786408037104, "entropy": 1.2824376828456052, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 29295.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 64000, "num_env_steps_trained": 64000, "num_agent_steps_sampled": 256000, "num_agent_steps_trained": 256000}, "env_runners": {"episode_reward_max": 723.1480054049603, "episode_reward_min": 37.506740396183545, "episode_reward_mean": 296.4267880179258, "episode_len_mean": 400.0, "episode_media": {}, "episodes_timesteps_total": 40000, "policy_reward_min": {"prey_policy": -717.2097699875618, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 376.812382620373, "predator_policy": 759.4665335850866}, "policy_reward_mean": {"prey_policy": -19.949845325038144, "predator_policy": 168.1632393340009}, "custom_metrics": {}, "hist_stats": {"episode_reward": [73.4000000000001, 172.51661390670918, 314.5000000000002, 640.3999999999996, 358.4892629866069, 537.1000000000003, 240.62815016043697, 232.99951948252325, 438.4999999999999, 702.0000000000007, 504.6999999999995, 285.60000000000025, 266.70000000000033, 480.4999999999989, 64.7000163742361, 410.6028006084132, 345.90000000000043, 139.69999999999703, 70.90000000000029, 63.30000000000063, 279.64572693029027, 349.70000000000107, 235.9009733077793, 214.99999999999966, 276.68389954105544, 142.185420720523, 205.77902626148932, 37.506740396183545, 77.49999999999987, 271.8425160205221, 351.20000000000005, 76.09999999999995, 72.80000000000014, 355.7000000000013, 359.22088371689665, 155.7375321156466, 336.1052306148806, 112.6999999999975, 253.79999999999728, 721.4984895986631, 339.2000000000014, 75.30897762584883, 722.5725727731624, 173.58894962874808, 414.3321651231242, 258.49999999999886, 384.0000000000024, 240.96741587580104, 703.8146078439153, 423.4788817070565, 335.0000000000022, 74.60000000000005, 723.1480054049603, 193.5544715538415, 488.6302082538318, 69.9129267472765, 340.7263431202153, 392.4665577952974, 545.9830086702245, 98.2999999999984, 316.7000000000009, 227.6999999999974, 193.37327863109786, 154.45429480276803, 491.65151733745085, 320.32080431783436, 322.24259643122446, 418.40000000000236, 157.81851315233754, 229.22599306291164, 324.75804483222174, 94.09999999999852, 364.2453454854257, 347.4000000000017, 201.39999999999847, 241.89999999999782, 110.0813413518992, 66.5000000000005, 208.39875498733264, 200.43662297567656, 565.9816752716484, 390.813077006542, 163.06813170125574, 70.80000000000027, 271.47241157243354, 485.6470795074924, 641.472844360221, 289.40387365809295, 292.6693794986311, 139.59999999999746, 479.87496995193294, 225.099999999998, 319.6180339887521, 400.2077972399478, 423.8599160870824, 157.50703763845527, 171.28200822029507, 402.12665410562306, 393.34271319556916, 139.89619655427137], "episode_lengths": [400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400], "policy_prey_policy_reward": [-162.9990322437011, -94.07113095617306, -170.69966320539146, -130.05132947249965, -153.03879348548688, 168.45588733626113, 235.4768797274106, 348.9665036205082, -110.06406504921048, 78.69916080689893, 95.29151321565989, 326.3721364186882, -19.169826879792645, -104.7844947775372, -158.90534356448262, -64.42264229576017, -353.2742296174582, 362.875458830875, 335.05710303969477, 257.29491828704704, 81.80681267278817, 142.86905860634414, -20.432894403191945, 20.71921057974368, 51.62033460976264, 34.248300659364475, 226.05840366195773, 67.43718812237373, -169.92054494847392, -117.24122907152062, -257.7315121765398, 361.7851532910748, 167.4070074237925, -72.15555908208464, 26.19324651093457, 33.6030165366545, -288.17736288755054, 23.443852062464494, -128.93884488795828, -142.80285529191028, -25.037662258665563, 119.9375724713436, 76.01645177360803, -83.11174434469032, 37.018753924373534, -154.76067785565894, -22.129318425672686, -78.38084396603054, -19.04034715917183, -421.33996044092163, -243.84991359235946, -75.3006140748056, 54.93146134287562, -312.95034565026685, -306.6654186305468, -260.9017327401376, 31.996687674699466, 10.34654449282513, 34.38302170292425, -76.00888895123396, -71.92676674605877, 134.63575370769615, -34.22777170509586, 20.782347460913304, -14.544705892595905, -31.805622761643214, -69.92707120921031, 278.84899009248386, 230.7530938951969, -397.9559854840322, -42.78852140229542, 2.883250559362983, -135.89478858578298, -165.35902046121583, -41.16909061479087, 35.7415997430519, 180.95020980183662, 21.37570396407685, 376.812382620373, 238.67536051365965, -4.43180510827797, 166.23865487288418, -27.67991996354027, -164.21709143395827, 178.22699779725613, 376.50488660967693, -20.16341730583126, -245.22234222187024, 160.01817667167325, 123.21176222927895, -20.215857706416543, 121.35425197813554, -51.57749341911413, 306.5751911969785, -192.40888599054787, -77.841632635107, 188.87290687109663, 371.48585235607493, 335.9683026473879, -9.896362053920004, 116.41860709750614, 34.904361931576304, -110.79399720694488, -21.801659883465526, 238.165410034407, 219.8827998355583, 15.59405184196084, -168.98851628184283, 72.46951393471171, 162.77193975145033, -58.30292523317673, -172.50928584692716, 81.88041325852578, -341.07474037518733, -297.50826128377986, 162.03038682314977, 46.34328116392672, 131.33413444684265, -85.28254186766168, 37.238340115120536, 15.85916393149381, 85.66739952993525, 22.684045979464056, 98.53515575320644, -87.13196176951354, -94.37986289616912, -149.76831165587336, -75.51364954145205, -36.71783950835651, 254.969615421524, -110.25832207875189, -287.6128259541711, -65.65915374974611, 102.55344483659391, 32.72318239507697, 354.4670965799534, -166.77066475120913, -27.417026496085683, -12.586726203201136, -227.1978859956428, 140.5945339114458, -382.3472846149405, -267.01312868873384, -68.56653485713092, -717.2097699875618, 63.588297442470555, 167.8923696688501, 9.28816264377539, -280.227785948628, 21.18204378720486, 25.88774058410634, -117.00891312813721, -82.28048431438276, -88.88794122105355, 22.303183204337465, -197.6956768698257, -554.0154183602142, 77.35304482442349, -247.36430799600797, -196.6907244586775, -106.37918720231912, 281.6170912392196, 59.20077720047444, -295.77302853798363, 4.021379005777842, 34.916329868153014, -32.42448643294864, -60.520441200790195, 128.30208745411701, -8.632199429560416, -13.598161324406597, 165.327598003983, 236.89376340262797, 240.12460891032336, -154.1987553812961, -3.38499640213143, -52.21930582784222, -676.1833750043567, -146.60816132987821, 36.49736207429844, 208.80140202984538, -129.58778107555176, -24.417826634627417, -178.86622926616926, -294.1032647258467, -187.78180212306458, 97.59652167047804, -82.07851964067258, -413.7394307005578, 229.49023038929224, -571.2046392019516, -41.99070273087026, -88.45912867082248, 12.194603986279349, 5.278838588669828, 14.153301304206064, 78.91535343658234, -253.2965906461101, -97.32119278939447, 28.8569610991972], "policy_predator_policy_reward": [192.6990322436994, 137.77113095617173, 437.37365659266703, 35.89394999193405, 28.794920199800845, 270.2879859494245, 25.623120272589492, 30.333496379491763, 153.6158699346698, 236.2382972942456, 109.10848678433968, 6.327863581311885, 192.06724035824524, 172.51523145952336, 162.8261471603467, 293.5013581824182, 121.2804707762325, 307.61830001035077, 36.04289696030523, 73.605081712953, 93.29318732721097, 186.73094139365585, 264.83289440319186, 20.48078942025648, 0.0, 180.83136473087282, 41.6734821247086, 145.33092609096013, 102.56773114640504, 249.29405924782142, 211.31032296239817, 95.23883653147679, 11.392992576206154, 239.25555908208406, 48.31933511067729, 31.584401841733893, 320.37736288755036, 15.256147937535534, 161.53884488795643, 173.50285529190882, 100.89735298546444, 83.8484637321489, 240.98354822639197, 115.81174434468859, 186.02126421534868, 167.62163302371837, 39.54292005573028, 275.9672423359727, 368.0515318600075, 349.0126752811421, 276.34991359235966, 184.98603479532701, 159.1688218260833, 304.62908874280043, 505.2104852284398, 99.86340653843195, 7.303312325300711, 27.853455507174978, 74.18320943417223, 239.28517383465712, 124.65178849150561, 163.83922454685717, 70.22777170509606, 19.317652539086684, 51.544705892596404, 67.60562276164372, 103.42707120920916, 43.351009907516115, 452.7364425343829, 73.68733277134959, 59.08737096883469, 136.5554319897471, 326.5144604485311, 310.8445792133451, 114.26909061479087, 3.85840025694834, 8.832114021663266, 42.64197221242239, 48.94219097032222, 57.068555494308264, 47.997631840897064, 129.39551839449697, 92.16123838429971, 175.04475063904655, 47.99618264074478, 119.8445057254844, 247.55790001950245, 191.41680913694933, 35.490956156910784, 95.6112700652532, 112.52790766200972, 44.8336980662715, 95.52136695461668, 33.480935267517815, 255.50298303454406, 255.71495146691126, 98.0831479592286, 45.37270065751511, 50.17855548698743, 47.22838562659909, 71.87426679582525, 111.80276417509246, 148.19399720694318, 59.001659883466054, 144.4351585296887, 120.6646370053063, 268.35152675598937, 78.59740923773558, 3.9032024145927275, 249.4855521530756, 98.2290317846702, 202.49610604270714, 155.5281616442165, 444.3925085926601, 345.33050151087895, 182.61393074504878, 352.9001988343047, 15.405394225149582, 143.78254186766017, 2.5616598848797247, 22.340836068506178, 192.83260047006453, 16.01595402053598, 90.46484424679274, 35.59821790301873, 339.28688539376185, 306.9695322051485, 72.76672379494487, 217.91569059613775, 55.48405082814195, 435.95660559066124, 282.2353467600994, 146.1898458007251, 139.15845954364437, 6.676817604923221, 24.532903420046566, 187.30150813882418, 164.70469626081004, 82.83604087979359, 386.1745643819638, 368.4777954542359, 198.03300008148415, 302.40890144869473, 127.27076209717296, 311.5444041395558, 706.3224138909611, 28.748303230751507, 141.4711644566232, 309.02778594863446, 151.4179562127952, 12.812259415893742, 320.208913128137, 136.73623637017465, 144.51353051715768, 16.096816795662544, 225.79567686982415, 67.18142319031695, 617.8797053328075, 344.06051655132137, 300.43113887904093, 353.2698161330049, 37.473955101743016, 445.68147119629776, 181.70385714775293, 76.97185206056606, 47.15857076676161, 68.32448643294913, 95.42044120078874, 122.1710150926939, 29.63150845518346, 37.895128270290236, 296.0225145576254, 107.99259423247598, 56.46187781479349, 112.26595953431027, 334.7216659072099, 759.4665335850866, 261.60552674574205, 246.50816132987754, 3.202637925701816, 274.7865713661366, 125.87477763150062, 214.2230592747555, 214.16099662604157, 464.4032647258461, 337.0998361118139, 127.15778874413638, 257.53200646600254, 142.49138545873936, 465.6177309396087, 165.38092327482514, 605.3214562964532, 27.409688054564715, 220.1368448502749, 202.881024662453, 179.81348955029034, 283.96642254864327, 283.7575278564508, 185.75724828082608, 22.603179963644248]}, "sampler_perf": {"mean_raw_obs_processing_ms": 4.436288836499808, "mean_inference_ms": 4.250461023949442, "mean_action_processing_ms": 1.9725599516232233, "mean_env_wait_ms": 9.975721494916215, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.009700775146484375, "StateBufferConnector_ms": 0.004861712455749512, "ViewRequirementAgentConnector_ms": 0.18415462970733643}, "num_episodes": 8, "episode_return_max": 723.1480054049603, "episode_return_min": 37.506740396183545, "episode_return_mean": 296.4267880179258, "episodes_this_iter": 8}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 256000, "num_agent_steps_trained": 256000, "num_env_steps_sampled": 64000, "num_env_steps_trained": 64000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 82.28314186135303, "num_env_steps_trained_throughput_per_sec": 82.28314186135303, "timesteps_total": 64000, "num_env_steps_sampled_lifetime": 64000, "num_agent_steps_sampled_lifetime": 256000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 256000, "timers": {"training_iteration_time_ms": 49353.804, "restore_workers_time_ms": 0.017, "training_step_time_ms": 49353.754, "sample_time_ms": 2198.875, "learn_time_ms": 47136.221, "learn_throughput": 84.86, "synch_weights_time_ms": 14.837}, "counters": {"num_env_steps_sampled": 64000, "num_env_steps_trained": 64000, "num_agent_steps_sampled": 256000, "num_agent_steps_trained": 256000}, "done": false, "training_iteration": 16, "trial_id": "798d9_00000", "date": "2024-08-22_09-50-45", "timestamp": 1724300445, "time_this_iter_s": 48.66698598861694, "time_total_s": 801.394989490509, "pid": 48427, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"prey_count": 2, "prey_speed": 1.0, "prey_view_size": 10, "prey_size": 1, "prey_color": [0, 255, 0], "prey_kill_reward": -10, "prey_alive_reward": 0.1, "prey_reward_sqr_reward": 1, "predator_count": 2, "predator_speed": 1.0, "predator_view_size": 10, "predator_size": 1, "predator_color": [255, 0, 0], "predator_kill_reward": 10, "map_size": 40, "max_steps": 400, "screen_size": 600, "render_mode": "None", "fps": 60}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 8, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": true, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 1, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "custom_cnn", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x300c04040>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 801.394989490509, "iterations_since_restore": 16, "perf": {"cpu_util_percent": 29.21594202898551, "ram_util_percent": 82.39999999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 6.008169090243244, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 6.313777253489015, "policy_loss": -0.01720606316147106, "vf_loss": 6.328327807925996, "vf_explained_var": 0.23544630430362842, "kl": 0.013277500267411587, "entropy": 1.0456204445273787, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 31185.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 7.515093405189968, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 6.67138197838314, "policy_loss": -0.026282635789054137, "vf_loss": 6.693979246654208, "vf_explained_var": -0.009769923504067477, "kl": 0.0184267984826374, "entropy": 1.290253807312597, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 31185.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 68000, "num_env_steps_trained": 68000, "num_agent_steps_sampled": 272000, "num_agent_steps_trained": 272000}, "env_runners": {"episode_reward_max": 723.1480054049603, "episode_reward_min": 37.506740396183545, "episode_reward_mean": 296.4267880179258, "episode_len_mean": 400.0, "episode_media": {}, "episodes_timesteps_total": 40000, "policy_reward_min": {"prey_policy": -717.2097699875618, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 376.812382620373, "predator_policy": 759.4665335850866}, "policy_reward_mean": {"prey_policy": -19.949845325038144, "predator_policy": 168.1632393340009}, "custom_metrics": {}, "hist_stats": {"episode_reward": [73.4000000000001, 172.51661390670918, 314.5000000000002, 640.3999999999996, 358.4892629866069, 537.1000000000003, 240.62815016043697, 232.99951948252325, 438.4999999999999, 702.0000000000007, 504.6999999999995, 285.60000000000025, 266.70000000000033, 480.4999999999989, 64.7000163742361, 410.6028006084132, 345.90000000000043, 139.69999999999703, 70.90000000000029, 63.30000000000063, 279.64572693029027, 349.70000000000107, 235.9009733077793, 214.99999999999966, 276.68389954105544, 142.185420720523, 205.77902626148932, 37.506740396183545, 77.49999999999987, 271.8425160205221, 351.20000000000005, 76.09999999999995, 72.80000000000014, 355.7000000000013, 359.22088371689665, 155.7375321156466, 336.1052306148806, 112.6999999999975, 253.79999999999728, 721.4984895986631, 339.2000000000014, 75.30897762584883, 722.5725727731624, 173.58894962874808, 414.3321651231242, 258.49999999999886, 384.0000000000024, 240.96741587580104, 703.8146078439153, 423.4788817070565, 335.0000000000022, 74.60000000000005, 723.1480054049603, 193.5544715538415, 488.6302082538318, 69.9129267472765, 340.7263431202153, 392.4665577952974, 545.9830086702245, 98.2999999999984, 316.7000000000009, 227.6999999999974, 193.37327863109786, 154.45429480276803, 491.65151733745085, 320.32080431783436, 322.24259643122446, 418.40000000000236, 157.81851315233754, 229.22599306291164, 324.75804483222174, 94.09999999999852, 364.2453454854257, 347.4000000000017, 201.39999999999847, 241.89999999999782, 110.0813413518992, 66.5000000000005, 208.39875498733264, 200.43662297567656, 565.9816752716484, 390.813077006542, 163.06813170125574, 70.80000000000027, 271.47241157243354, 485.6470795074924, 641.472844360221, 289.40387365809295, 292.6693794986311, 139.59999999999746, 479.87496995193294, 225.099999999998, 319.6180339887521, 400.2077972399478, 423.8599160870824, 157.50703763845527, 171.28200822029507, 402.12665410562306, 393.34271319556916, 139.89619655427137], "episode_lengths": [400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400], "policy_prey_policy_reward": [-162.9990322437011, -94.07113095617306, -170.69966320539146, -130.05132947249965, -153.03879348548688, 168.45588733626113, 235.4768797274106, 348.9665036205082, -110.06406504921048, 78.69916080689893, 95.29151321565989, 326.3721364186882, -19.169826879792645, -104.7844947775372, -158.90534356448262, -64.42264229576017, -353.2742296174582, 362.875458830875, 335.05710303969477, 257.29491828704704, 81.80681267278817, 142.86905860634414, -20.432894403191945, 20.71921057974368, 51.62033460976264, 34.248300659364475, 226.05840366195773, 67.43718812237373, -169.92054494847392, -117.24122907152062, -257.7315121765398, 361.7851532910748, 167.4070074237925, -72.15555908208464, 26.19324651093457, 33.6030165366545, -288.17736288755054, 23.443852062464494, -128.93884488795828, -142.80285529191028, -25.037662258665563, 119.9375724713436, 76.01645177360803, -83.11174434469032, 37.018753924373534, -154.76067785565894, -22.129318425672686, -78.38084396603054, -19.04034715917183, -421.33996044092163, -243.84991359235946, -75.3006140748056, 54.93146134287562, -312.95034565026685, -306.6654186305468, -260.9017327401376, 31.996687674699466, 10.34654449282513, 34.38302170292425, -76.00888895123396, -71.92676674605877, 134.63575370769615, -34.22777170509586, 20.782347460913304, -14.544705892595905, -31.805622761643214, -69.92707120921031, 278.84899009248386, 230.7530938951969, -397.9559854840322, -42.78852140229542, 2.883250559362983, -135.89478858578298, -165.35902046121583, -41.16909061479087, 35.7415997430519, 180.95020980183662, 21.37570396407685, 376.812382620373, 238.67536051365965, -4.43180510827797, 166.23865487288418, -27.67991996354027, -164.21709143395827, 178.22699779725613, 376.50488660967693, -20.16341730583126, -245.22234222187024, 160.01817667167325, 123.21176222927895, -20.215857706416543, 121.35425197813554, -51.57749341911413, 306.5751911969785, -192.40888599054787, -77.841632635107, 188.87290687109663, 371.48585235607493, 335.9683026473879, -9.896362053920004, 116.41860709750614, 34.904361931576304, -110.79399720694488, -21.801659883465526, 238.165410034407, 219.8827998355583, 15.59405184196084, -168.98851628184283, 72.46951393471171, 162.77193975145033, -58.30292523317673, -172.50928584692716, 81.88041325852578, -341.07474037518733, -297.50826128377986, 162.03038682314977, 46.34328116392672, 131.33413444684265, -85.28254186766168, 37.238340115120536, 15.85916393149381, 85.66739952993525, 22.684045979464056, 98.53515575320644, -87.13196176951354, -94.37986289616912, -149.76831165587336, -75.51364954145205, -36.71783950835651, 254.969615421524, -110.25832207875189, -287.6128259541711, -65.65915374974611, 102.55344483659391, 32.72318239507697, 354.4670965799534, -166.77066475120913, -27.417026496085683, -12.586726203201136, -227.1978859956428, 140.5945339114458, -382.3472846149405, -267.01312868873384, -68.56653485713092, -717.2097699875618, 63.588297442470555, 167.8923696688501, 9.28816264377539, -280.227785948628, 21.18204378720486, 25.88774058410634, -117.00891312813721, -82.28048431438276, -88.88794122105355, 22.303183204337465, -197.6956768698257, -554.0154183602142, 77.35304482442349, -247.36430799600797, -196.6907244586775, -106.37918720231912, 281.6170912392196, 59.20077720047444, -295.77302853798363, 4.021379005777842, 34.916329868153014, -32.42448643294864, -60.520441200790195, 128.30208745411701, -8.632199429560416, -13.598161324406597, 165.327598003983, 236.89376340262797, 240.12460891032336, -154.1987553812961, -3.38499640213143, -52.21930582784222, -676.1833750043567, -146.60816132987821, 36.49736207429844, 208.80140202984538, -129.58778107555176, -24.417826634627417, -178.86622926616926, -294.1032647258467, -187.78180212306458, 97.59652167047804, -82.07851964067258, -413.7394307005578, 229.49023038929224, -571.2046392019516, -41.99070273087026, -88.45912867082248, 12.194603986279349, 5.278838588669828, 14.153301304206064, 78.91535343658234, -253.2965906461101, -97.32119278939447, 28.8569610991972], "policy_predator_policy_reward": [192.6990322436994, 137.77113095617173, 437.37365659266703, 35.89394999193405, 28.794920199800845, 270.2879859494245, 25.623120272589492, 30.333496379491763, 153.6158699346698, 236.2382972942456, 109.10848678433968, 6.327863581311885, 192.06724035824524, 172.51523145952336, 162.8261471603467, 293.5013581824182, 121.2804707762325, 307.61830001035077, 36.04289696030523, 73.605081712953, 93.29318732721097, 186.73094139365585, 264.83289440319186, 20.48078942025648, 0.0, 180.83136473087282, 41.6734821247086, 145.33092609096013, 102.56773114640504, 249.29405924782142, 211.31032296239817, 95.23883653147679, 11.392992576206154, 239.25555908208406, 48.31933511067729, 31.584401841733893, 320.37736288755036, 15.256147937535534, 161.53884488795643, 173.50285529190882, 100.89735298546444, 83.8484637321489, 240.98354822639197, 115.81174434468859, 186.02126421534868, 167.62163302371837, 39.54292005573028, 275.9672423359727, 368.0515318600075, 349.0126752811421, 276.34991359235966, 184.98603479532701, 159.1688218260833, 304.62908874280043, 505.2104852284398, 99.86340653843195, 7.303312325300711, 27.853455507174978, 74.18320943417223, 239.28517383465712, 124.65178849150561, 163.83922454685717, 70.22777170509606, 19.317652539086684, 51.544705892596404, 67.60562276164372, 103.42707120920916, 43.351009907516115, 452.7364425343829, 73.68733277134959, 59.08737096883469, 136.5554319897471, 326.5144604485311, 310.8445792133451, 114.26909061479087, 3.85840025694834, 8.832114021663266, 42.64197221242239, 48.94219097032222, 57.068555494308264, 47.997631840897064, 129.39551839449697, 92.16123838429971, 175.04475063904655, 47.99618264074478, 119.8445057254844, 247.55790001950245, 191.41680913694933, 35.490956156910784, 95.6112700652532, 112.52790766200972, 44.8336980662715, 95.52136695461668, 33.480935267517815, 255.50298303454406, 255.71495146691126, 98.0831479592286, 45.37270065751511, 50.17855548698743, 47.22838562659909, 71.87426679582525, 111.80276417509246, 148.19399720694318, 59.001659883466054, 144.4351585296887, 120.6646370053063, 268.35152675598937, 78.59740923773558, 3.9032024145927275, 249.4855521530756, 98.2290317846702, 202.49610604270714, 155.5281616442165, 444.3925085926601, 345.33050151087895, 182.61393074504878, 352.9001988343047, 15.405394225149582, 143.78254186766017, 2.5616598848797247, 22.340836068506178, 192.83260047006453, 16.01595402053598, 90.46484424679274, 35.59821790301873, 339.28688539376185, 306.9695322051485, 72.76672379494487, 217.91569059613775, 55.48405082814195, 435.95660559066124, 282.2353467600994, 146.1898458007251, 139.15845954364437, 6.676817604923221, 24.532903420046566, 187.30150813882418, 164.70469626081004, 82.83604087979359, 386.1745643819638, 368.4777954542359, 198.03300008148415, 302.40890144869473, 127.27076209717296, 311.5444041395558, 706.3224138909611, 28.748303230751507, 141.4711644566232, 309.02778594863446, 151.4179562127952, 12.812259415893742, 320.208913128137, 136.73623637017465, 144.51353051715768, 16.096816795662544, 225.79567686982415, 67.18142319031695, 617.8797053328075, 344.06051655132137, 300.43113887904093, 353.2698161330049, 37.473955101743016, 445.68147119629776, 181.70385714775293, 76.97185206056606, 47.15857076676161, 68.32448643294913, 95.42044120078874, 122.1710150926939, 29.63150845518346, 37.895128270290236, 296.0225145576254, 107.99259423247598, 56.46187781479349, 112.26595953431027, 334.7216659072099, 759.4665335850866, 261.60552674574205, 246.50816132987754, 3.202637925701816, 274.7865713661366, 125.87477763150062, 214.2230592747555, 214.16099662604157, 464.4032647258461, 337.0998361118139, 127.15778874413638, 257.53200646600254, 142.49138545873936, 465.6177309396087, 165.38092327482514, 605.3214562964532, 27.409688054564715, 220.1368448502749, 202.881024662453, 179.81348955029034, 283.96642254864327, 283.7575278564508, 185.75724828082608, 22.603179963644248]}, "sampler_perf": {"mean_raw_obs_processing_ms": 4.436288836499808, "mean_inference_ms": 4.250461023949442, "mean_action_processing_ms": 1.9725599516232233, "mean_env_wait_ms": 9.975721494916215, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.009700775146484375, "StateBufferConnector_ms": 0.004861712455749512, "ViewRequirementAgentConnector_ms": 0.18415462970733643}, "num_episodes": 0, "episode_return_max": 723.1480054049603, "episode_return_min": 37.506740396183545, "episode_return_mean": 296.4267880179258, "episodes_this_iter": 0}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 272000, "num_agent_steps_trained": 272000, "num_env_steps_sampled": 68000, "num_env_steps_trained": 68000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 81.62306024883596, "num_env_steps_trained_throughput_per_sec": 81.62306024883596, "timesteps_total": 68000, "num_env_steps_sampled_lifetime": 68000, "num_agent_steps_sampled_lifetime": 272000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 272000, "timers": {"training_iteration_time_ms": 49407.428, "restore_workers_time_ms": 0.017, "training_step_time_ms": 49407.357, "sample_time_ms": 2168.232, "learn_time_ms": 47220.103, "learn_throughput": 84.71, "synch_weights_time_ms": 14.728}, "counters": {"num_env_steps_sampled": 68000, "num_env_steps_trained": 68000, "num_agent_steps_sampled": 272000, "num_agent_steps_trained": 272000}, "done": false, "training_iteration": 17, "trial_id": "798d9_00000", "date": "2024-08-22_09-51-34", "timestamp": 1724300494, "time_this_iter_s": 49.060030937194824, "time_total_s": 850.4550204277039, "pid": 48427, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"prey_count": 2, "prey_speed": 1.0, "prey_view_size": 10, "prey_size": 1, "prey_color": [0, 255, 0], "prey_kill_reward": -10, "prey_alive_reward": 0.1, "prey_reward_sqr_reward": 1, "predator_count": 2, "predator_speed": 1.0, "predator_view_size": 10, "predator_size": 1, "predator_color": [255, 0, 0], "predator_kill_reward": 10, "map_size": 40, "max_steps": 400, "screen_size": 600, "render_mode": "None", "fps": 60}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 8, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": true, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 1, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "custom_cnn", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x16cfcbee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 850.4550204277039, "iterations_since_restore": 17, "perf": {"cpu_util_percent": 29.87536231884058, "ram_util_percent": 82.61884057971015}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 6.730045031681263, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 5.801806962553155, "policy_loss": -0.018281969230217986, "vf_loss": 5.8175334892575705, "vf_explained_var": 0.2827877705690091, "kl": 0.012777160244584872, "entropy": 1.0427155799335903, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 33075.5, "diff_num_grad_updates_vs_sampler_policy": 970.9599999999992}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 6.961689321893863, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 5.775117655153628, "policy_loss": -0.02360947001232672, "vf_loss": 5.795301941967515, "vf_explained_var": -0.09778857745190776, "kl": 0.017125907195879825, "entropy": 1.2846677537948366, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 33075.5, "diff_num_grad_updates_vs_sampler_policy": 970.9599999999992}}, "num_env_steps_sampled": 72000, "num_env_steps_trained": 72000, "num_agent_steps_sampled": 288000, "num_agent_steps_trained": 288000}, "env_runners": {"episode_reward_max": 723.1480054049603, "episode_reward_min": 37.506740396183545, "episode_reward_mean": 296.4267880179258, "episode_len_mean": 400.0, "episode_media": {}, "episodes_timesteps_total": 40000, "policy_reward_min": {"prey_policy": -717.2097699875618, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 376.812382620373, "predator_policy": 759.4665335850866}, "policy_reward_mean": {"prey_policy": -19.949845325038144, "predator_policy": 168.1632393340009}, "custom_metrics": {}, "hist_stats": {"episode_reward": [73.4000000000001, 172.51661390670918, 314.5000000000002, 640.3999999999996, 358.4892629866069, 537.1000000000003, 240.62815016043697, 232.99951948252325, 438.4999999999999, 702.0000000000007, 504.6999999999995, 285.60000000000025, 266.70000000000033, 480.4999999999989, 64.7000163742361, 410.6028006084132, 345.90000000000043, 139.69999999999703, 70.90000000000029, 63.30000000000063, 279.64572693029027, 349.70000000000107, 235.9009733077793, 214.99999999999966, 276.68389954105544, 142.185420720523, 205.77902626148932, 37.506740396183545, 77.49999999999987, 271.8425160205221, 351.20000000000005, 76.09999999999995, 72.80000000000014, 355.7000000000013, 359.22088371689665, 155.7375321156466, 336.1052306148806, 112.6999999999975, 253.79999999999728, 721.4984895986631, 339.2000000000014, 75.30897762584883, 722.5725727731624, 173.58894962874808, 414.3321651231242, 258.49999999999886, 384.0000000000024, 240.96741587580104, 703.8146078439153, 423.4788817070565, 335.0000000000022, 74.60000000000005, 723.1480054049603, 193.5544715538415, 488.6302082538318, 69.9129267472765, 340.7263431202153, 392.4665577952974, 545.9830086702245, 98.2999999999984, 316.7000000000009, 227.6999999999974, 193.37327863109786, 154.45429480276803, 491.65151733745085, 320.32080431783436, 322.24259643122446, 418.40000000000236, 157.81851315233754, 229.22599306291164, 324.75804483222174, 94.09999999999852, 364.2453454854257, 347.4000000000017, 201.39999999999847, 241.89999999999782, 110.0813413518992, 66.5000000000005, 208.39875498733264, 200.43662297567656, 565.9816752716484, 390.813077006542, 163.06813170125574, 70.80000000000027, 271.47241157243354, 485.6470795074924, 641.472844360221, 289.40387365809295, 292.6693794986311, 139.59999999999746, 479.87496995193294, 225.099999999998, 319.6180339887521, 400.2077972399478, 423.8599160870824, 157.50703763845527, 171.28200822029507, 402.12665410562306, 393.34271319556916, 139.89619655427137], "episode_lengths": [400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400], "policy_prey_policy_reward": [-162.9990322437011, -94.07113095617306, -170.69966320539146, -130.05132947249965, -153.03879348548688, 168.45588733626113, 235.4768797274106, 348.9665036205082, -110.06406504921048, 78.69916080689893, 95.29151321565989, 326.3721364186882, -19.169826879792645, -104.7844947775372, -158.90534356448262, -64.42264229576017, -353.2742296174582, 362.875458830875, 335.05710303969477, 257.29491828704704, 81.80681267278817, 142.86905860634414, -20.432894403191945, 20.71921057974368, 51.62033460976264, 34.248300659364475, 226.05840366195773, 67.43718812237373, -169.92054494847392, -117.24122907152062, -257.7315121765398, 361.7851532910748, 167.4070074237925, -72.15555908208464, 26.19324651093457, 33.6030165366545, -288.17736288755054, 23.443852062464494, -128.93884488795828, -142.80285529191028, -25.037662258665563, 119.9375724713436, 76.01645177360803, -83.11174434469032, 37.018753924373534, -154.76067785565894, -22.129318425672686, -78.38084396603054, -19.04034715917183, -421.33996044092163, -243.84991359235946, -75.3006140748056, 54.93146134287562, -312.95034565026685, -306.6654186305468, -260.9017327401376, 31.996687674699466, 10.34654449282513, 34.38302170292425, -76.00888895123396, -71.92676674605877, 134.63575370769615, -34.22777170509586, 20.782347460913304, -14.544705892595905, -31.805622761643214, -69.92707120921031, 278.84899009248386, 230.7530938951969, -397.9559854840322, -42.78852140229542, 2.883250559362983, -135.89478858578298, -165.35902046121583, -41.16909061479087, 35.7415997430519, 180.95020980183662, 21.37570396407685, 376.812382620373, 238.67536051365965, -4.43180510827797, 166.23865487288418, -27.67991996354027, -164.21709143395827, 178.22699779725613, 376.50488660967693, -20.16341730583126, -245.22234222187024, 160.01817667167325, 123.21176222927895, -20.215857706416543, 121.35425197813554, -51.57749341911413, 306.5751911969785, -192.40888599054787, -77.841632635107, 188.87290687109663, 371.48585235607493, 335.9683026473879, -9.896362053920004, 116.41860709750614, 34.904361931576304, -110.79399720694488, -21.801659883465526, 238.165410034407, 219.8827998355583, 15.59405184196084, -168.98851628184283, 72.46951393471171, 162.77193975145033, -58.30292523317673, -172.50928584692716, 81.88041325852578, -341.07474037518733, -297.50826128377986, 162.03038682314977, 46.34328116392672, 131.33413444684265, -85.28254186766168, 37.238340115120536, 15.85916393149381, 85.66739952993525, 22.684045979464056, 98.53515575320644, -87.13196176951354, -94.37986289616912, -149.76831165587336, -75.51364954145205, -36.71783950835651, 254.969615421524, -110.25832207875189, -287.6128259541711, -65.65915374974611, 102.55344483659391, 32.72318239507697, 354.4670965799534, -166.77066475120913, -27.417026496085683, -12.586726203201136, -227.1978859956428, 140.5945339114458, -382.3472846149405, -267.01312868873384, -68.56653485713092, -717.2097699875618, 63.588297442470555, 167.8923696688501, 9.28816264377539, -280.227785948628, 21.18204378720486, 25.88774058410634, -117.00891312813721, -82.28048431438276, -88.88794122105355, 22.303183204337465, -197.6956768698257, -554.0154183602142, 77.35304482442349, -247.36430799600797, -196.6907244586775, -106.37918720231912, 281.6170912392196, 59.20077720047444, -295.77302853798363, 4.021379005777842, 34.916329868153014, -32.42448643294864, -60.520441200790195, 128.30208745411701, -8.632199429560416, -13.598161324406597, 165.327598003983, 236.89376340262797, 240.12460891032336, -154.1987553812961, -3.38499640213143, -52.21930582784222, -676.1833750043567, -146.60816132987821, 36.49736207429844, 208.80140202984538, -129.58778107555176, -24.417826634627417, -178.86622926616926, -294.1032647258467, -187.78180212306458, 97.59652167047804, -82.07851964067258, -413.7394307005578, 229.49023038929224, -571.2046392019516, -41.99070273087026, -88.45912867082248, 12.194603986279349, 5.278838588669828, 14.153301304206064, 78.91535343658234, -253.2965906461101, -97.32119278939447, 28.8569610991972], "policy_predator_policy_reward": [192.6990322436994, 137.77113095617173, 437.37365659266703, 35.89394999193405, 28.794920199800845, 270.2879859494245, 25.623120272589492, 30.333496379491763, 153.6158699346698, 236.2382972942456, 109.10848678433968, 6.327863581311885, 192.06724035824524, 172.51523145952336, 162.8261471603467, 293.5013581824182, 121.2804707762325, 307.61830001035077, 36.04289696030523, 73.605081712953, 93.29318732721097, 186.73094139365585, 264.83289440319186, 20.48078942025648, 0.0, 180.83136473087282, 41.6734821247086, 145.33092609096013, 102.56773114640504, 249.29405924782142, 211.31032296239817, 95.23883653147679, 11.392992576206154, 239.25555908208406, 48.31933511067729, 31.584401841733893, 320.37736288755036, 15.256147937535534, 161.53884488795643, 173.50285529190882, 100.89735298546444, 83.8484637321489, 240.98354822639197, 115.81174434468859, 186.02126421534868, 167.62163302371837, 39.54292005573028, 275.9672423359727, 368.0515318600075, 349.0126752811421, 276.34991359235966, 184.98603479532701, 159.1688218260833, 304.62908874280043, 505.2104852284398, 99.86340653843195, 7.303312325300711, 27.853455507174978, 74.18320943417223, 239.28517383465712, 124.65178849150561, 163.83922454685717, 70.22777170509606, 19.317652539086684, 51.544705892596404, 67.60562276164372, 103.42707120920916, 43.351009907516115, 452.7364425343829, 73.68733277134959, 59.08737096883469, 136.5554319897471, 326.5144604485311, 310.8445792133451, 114.26909061479087, 3.85840025694834, 8.832114021663266, 42.64197221242239, 48.94219097032222, 57.068555494308264, 47.997631840897064, 129.39551839449697, 92.16123838429971, 175.04475063904655, 47.99618264074478, 119.8445057254844, 247.55790001950245, 191.41680913694933, 35.490956156910784, 95.6112700652532, 112.52790766200972, 44.8336980662715, 95.52136695461668, 33.480935267517815, 255.50298303454406, 255.71495146691126, 98.0831479592286, 45.37270065751511, 50.17855548698743, 47.22838562659909, 71.87426679582525, 111.80276417509246, 148.19399720694318, 59.001659883466054, 144.4351585296887, 120.6646370053063, 268.35152675598937, 78.59740923773558, 3.9032024145927275, 249.4855521530756, 98.2290317846702, 202.49610604270714, 155.5281616442165, 444.3925085926601, 345.33050151087895, 182.61393074504878, 352.9001988343047, 15.405394225149582, 143.78254186766017, 2.5616598848797247, 22.340836068506178, 192.83260047006453, 16.01595402053598, 90.46484424679274, 35.59821790301873, 339.28688539376185, 306.9695322051485, 72.76672379494487, 217.91569059613775, 55.48405082814195, 435.95660559066124, 282.2353467600994, 146.1898458007251, 139.15845954364437, 6.676817604923221, 24.532903420046566, 187.30150813882418, 164.70469626081004, 82.83604087979359, 386.1745643819638, 368.4777954542359, 198.03300008148415, 302.40890144869473, 127.27076209717296, 311.5444041395558, 706.3224138909611, 28.748303230751507, 141.4711644566232, 309.02778594863446, 151.4179562127952, 12.812259415893742, 320.208913128137, 136.73623637017465, 144.51353051715768, 16.096816795662544, 225.79567686982415, 67.18142319031695, 617.8797053328075, 344.06051655132137, 300.43113887904093, 353.2698161330049, 37.473955101743016, 445.68147119629776, 181.70385714775293, 76.97185206056606, 47.15857076676161, 68.32448643294913, 95.42044120078874, 122.1710150926939, 29.63150845518346, 37.895128270290236, 296.0225145576254, 107.99259423247598, 56.46187781479349, 112.26595953431027, 334.7216659072099, 759.4665335850866, 261.60552674574205, 246.50816132987754, 3.202637925701816, 274.7865713661366, 125.87477763150062, 214.2230592747555, 214.16099662604157, 464.4032647258461, 337.0998361118139, 127.15778874413638, 257.53200646600254, 142.49138545873936, 465.6177309396087, 165.38092327482514, 605.3214562964532, 27.409688054564715, 220.1368448502749, 202.881024662453, 179.81348955029034, 283.96642254864327, 283.7575278564508, 185.75724828082608, 22.603179963644248]}, "sampler_perf": {"mean_raw_obs_processing_ms": 4.436288836499808, "mean_inference_ms": 4.250461023949442, "mean_action_processing_ms": 1.9725599516232233, "mean_env_wait_ms": 9.975721494916215, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.009700775146484375, "StateBufferConnector_ms": 0.004861712455749512, "ViewRequirementAgentConnector_ms": 0.18415462970733643}, "num_episodes": 0, "episode_return_max": 723.1480054049603, "episode_return_min": 37.506740396183545, "episode_return_mean": 296.4267880179258, "episodes_this_iter": 0}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 288000, "num_agent_steps_trained": 288000, "num_env_steps_sampled": 72000, "num_env_steps_trained": 72000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 82.8699317967558, "num_env_steps_trained_throughput_per_sec": 82.8699317967558, "timesteps_total": 72000, "num_env_steps_sampled_lifetime": 72000, "num_agent_steps_sampled_lifetime": 288000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 288000, "timers": {"training_iteration_time_ms": 49340.491, "restore_workers_time_ms": 0.016, "training_step_time_ms": 49340.419, "sample_time_ms": 2178.163, "learn_time_ms": 47143.754, "learn_throughput": 84.847, "synch_weights_time_ms": 14.337}, "counters": {"num_env_steps_sampled": 72000, "num_env_steps_trained": 72000, "num_agent_steps_sampled": 288000, "num_agent_steps_trained": 288000}, "done": false, "training_iteration": 18, "trial_id": "798d9_00000", "date": "2024-08-22_09-52-23", "timestamp": 1724300543, "time_this_iter_s": 48.3163321018219, "time_total_s": 898.7713525295258, "pid": 48427, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"prey_count": 2, "prey_speed": 1.0, "prey_view_size": 10, "prey_size": 1, "prey_color": [0, 255, 0], "prey_kill_reward": -10, "prey_alive_reward": 0.1, "prey_reward_sqr_reward": 1, "predator_count": 2, "predator_speed": 1.0, "predator_view_size": 10, "predator_size": 1, "predator_color": [255, 0, 0], "predator_kill_reward": 10, "map_size": 40, "max_steps": 400, "screen_size": 600, "render_mode": "None", "fps": 60}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 8, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": true, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 1, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "custom_cnn", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x300c04160>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 898.7713525295258, "iterations_since_restore": 18, "perf": {"cpu_util_percent": 30.066666666666674, "ram_util_percent": 82.66231884057972}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 6.269099875291189, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 5.3769293701837935, "policy_loss": -0.017815025240582014, "vf_loss": 5.391774753540282, "vf_explained_var": 0.3072653248511925, "kl": 0.014848289420463578, "entropy": 1.0406768968811742, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 34965.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 6.885962282065992, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 5.3114606298466835, "policy_loss": -0.025457735699675386, "vf_loss": 5.333942710533344, "vf_explained_var": 0.055235647776770216, "kl": 0.01487825588697676, "entropy": 1.2755645259347543, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 34965.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 76000, "num_env_steps_trained": 76000, "num_agent_steps_sampled": 304000, "num_agent_steps_trained": 304000}, "env_runners": {"episode_reward_max": 723.1480054049603, "episode_reward_min": 37.506740396183545, "episode_reward_mean": 296.43079343517525, "episode_len_mean": 400.0, "episode_media": {}, "episodes_timesteps_total": 40000, "policy_reward_min": {"prey_policy": -717.2097699875618, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 376.812382620373, "predator_policy": 759.4665335850866}, "policy_reward_mean": {"prey_policy": -23.142083921079212, "predator_policy": 171.35748063866674}, "custom_metrics": {}, "hist_stats": {"episode_reward": [314.5000000000002, 640.3999999999996, 358.4892629866069, 537.1000000000003, 240.62815016043697, 232.99951948252325, 438.4999999999999, 702.0000000000007, 504.6999999999995, 285.60000000000025, 266.70000000000033, 480.4999999999989, 64.7000163742361, 410.6028006084132, 345.90000000000043, 139.69999999999703, 70.90000000000029, 63.30000000000063, 279.64572693029027, 349.70000000000107, 235.9009733077793, 214.99999999999966, 276.68389954105544, 142.185420720523, 205.77902626148932, 37.506740396183545, 77.49999999999987, 271.8425160205221, 351.20000000000005, 76.09999999999995, 72.80000000000014, 355.7000000000013, 359.22088371689665, 155.7375321156466, 336.1052306148806, 112.6999999999975, 253.79999999999728, 721.4984895986631, 339.2000000000014, 75.30897762584883, 722.5725727731624, 173.58894962874808, 414.3321651231242, 258.49999999999886, 384.0000000000024, 240.96741587580104, 703.8146078439153, 423.4788817070565, 335.0000000000022, 74.60000000000005, 723.1480054049603, 193.5544715538415, 488.6302082538318, 69.9129267472765, 340.7263431202153, 392.4665577952974, 545.9830086702245, 98.2999999999984, 316.7000000000009, 227.6999999999974, 193.37327863109786, 154.45429480276803, 491.65151733745085, 320.32080431783436, 322.24259643122446, 418.40000000000236, 157.81851315233754, 229.22599306291164, 324.75804483222174, 94.09999999999852, 364.2453454854257, 347.4000000000017, 201.39999999999847, 241.89999999999782, 110.0813413518992, 66.5000000000005, 208.39875498733264, 200.43662297567656, 565.9816752716484, 390.813077006542, 163.06813170125574, 70.80000000000027, 271.47241157243354, 485.6470795074924, 641.472844360221, 289.40387365809295, 292.6693794986311, 139.59999999999746, 479.87496995193294, 225.099999999998, 319.6180339887521, 400.2077972399478, 423.8599160870824, 157.50703763845527, 171.28200822029507, 402.12665410562306, 393.34271319556916, 139.89619655427137, 122.33149929910607, 123.98565633254854], "episode_lengths": [400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400], "policy_prey_policy_reward": [-153.03879348548688, 168.45588733626113, 235.4768797274106, 348.9665036205082, -110.06406504921048, 78.69916080689893, 95.29151321565989, 326.3721364186882, -19.169826879792645, -104.7844947775372, -158.90534356448262, -64.42264229576017, -353.2742296174582, 362.875458830875, 335.05710303969477, 257.29491828704704, 81.80681267278817, 142.86905860634414, -20.432894403191945, 20.71921057974368, 51.62033460976264, 34.248300659364475, 226.05840366195773, 67.43718812237373, -169.92054494847392, -117.24122907152062, -257.7315121765398, 361.7851532910748, 167.4070074237925, -72.15555908208464, 26.19324651093457, 33.6030165366545, -288.17736288755054, 23.443852062464494, -128.93884488795828, -142.80285529191028, -25.037662258665563, 119.9375724713436, 76.01645177360803, -83.11174434469032, 37.018753924373534, -154.76067785565894, -22.129318425672686, -78.38084396603054, -19.04034715917183, -421.33996044092163, -243.84991359235946, -75.3006140748056, 54.93146134287562, -312.95034565026685, -306.6654186305468, -260.9017327401376, 31.996687674699466, 10.34654449282513, 34.38302170292425, -76.00888895123396, -71.92676674605877, 134.63575370769615, -34.22777170509586, 20.782347460913304, -14.544705892595905, -31.805622761643214, -69.92707120921031, 278.84899009248386, 230.7530938951969, -397.9559854840322, -42.78852140229542, 2.883250559362983, -135.89478858578298, -165.35902046121583, -41.16909061479087, 35.7415997430519, 180.95020980183662, 21.37570396407685, 376.812382620373, 238.67536051365965, -4.43180510827797, 166.23865487288418, -27.67991996354027, -164.21709143395827, 178.22699779725613, 376.50488660967693, -20.16341730583126, -245.22234222187024, 160.01817667167325, 123.21176222927895, -20.215857706416543, 121.35425197813554, -51.57749341911413, 306.5751911969785, -192.40888599054787, -77.841632635107, 188.87290687109663, 371.48585235607493, 335.9683026473879, -9.896362053920004, 116.41860709750614, 34.904361931576304, -110.79399720694488, -21.801659883465526, 238.165410034407, 219.8827998355583, 15.59405184196084, -168.98851628184283, 72.46951393471171, 162.77193975145033, -58.30292523317673, -172.50928584692716, 81.88041325852578, -341.07474037518733, -297.50826128377986, 162.03038682314977, 46.34328116392672, 131.33413444684265, -85.28254186766168, 37.238340115120536, 15.85916393149381, 85.66739952993525, 22.684045979464056, 98.53515575320644, -87.13196176951354, -94.37986289616912, -149.76831165587336, -75.51364954145205, -36.71783950835651, 254.969615421524, -110.25832207875189, -287.6128259541711, -65.65915374974611, 102.55344483659391, 32.72318239507697, 354.4670965799534, -166.77066475120913, -27.417026496085683, -12.586726203201136, -227.1978859956428, 140.5945339114458, -382.3472846149405, -267.01312868873384, -68.56653485713092, -717.2097699875618, 63.588297442470555, 167.8923696688501, 9.28816264377539, -280.227785948628, 21.18204378720486, 25.88774058410634, -117.00891312813721, -82.28048431438276, -88.88794122105355, 22.303183204337465, -197.6956768698257, -554.0154183602142, 77.35304482442349, -247.36430799600797, -196.6907244586775, -106.37918720231912, 281.6170912392196, 59.20077720047444, -295.77302853798363, 4.021379005777842, 34.916329868153014, -32.42448643294864, -60.520441200790195, 128.30208745411701, -8.632199429560416, -13.598161324406597, 165.327598003983, 236.89376340262797, 240.12460891032336, -154.1987553812961, -3.38499640213143, -52.21930582784222, -676.1833750043567, -146.60816132987821, 36.49736207429844, 208.80140202984538, -129.58778107555176, -24.417826634627417, -178.86622926616926, -294.1032647258467, -187.78180212306458, 97.59652167047804, -82.07851964067258, -413.7394307005578, 229.49023038929224, -571.2046392019516, -41.99070273087026, -88.45912867082248, 12.194603986279349, 5.278838588669828, 14.153301304206064, 78.91535343658234, -253.2965906461101, -97.32119278939447, 28.8569610991972, -613.1746087344347, -82.62505967109945, -48.09265033306259, -452.3765563473814], "policy_predator_policy_reward": [28.794920199800845, 270.2879859494245, 25.623120272589492, 30.333496379491763, 153.6158699346698, 236.2382972942456, 109.10848678433968, 6.327863581311885, 192.06724035824524, 172.51523145952336, 162.8261471603467, 293.5013581824182, 121.2804707762325, 307.61830001035077, 36.04289696030523, 73.605081712953, 93.29318732721097, 186.73094139365585, 264.83289440319186, 20.48078942025648, 0.0, 180.83136473087282, 41.6734821247086, 145.33092609096013, 102.56773114640504, 249.29405924782142, 211.31032296239817, 95.23883653147679, 11.392992576206154, 239.25555908208406, 48.31933511067729, 31.584401841733893, 320.37736288755036, 15.256147937535534, 161.53884488795643, 173.50285529190882, 100.89735298546444, 83.8484637321489, 240.98354822639197, 115.81174434468859, 186.02126421534868, 167.62163302371837, 39.54292005573028, 275.9672423359727, 368.0515318600075, 349.0126752811421, 276.34991359235966, 184.98603479532701, 159.1688218260833, 304.62908874280043, 505.2104852284398, 99.86340653843195, 7.303312325300711, 27.853455507174978, 74.18320943417223, 239.28517383465712, 124.65178849150561, 163.83922454685717, 70.22777170509606, 19.317652539086684, 51.544705892596404, 67.60562276164372, 103.42707120920916, 43.351009907516115, 452.7364425343829, 73.68733277134959, 59.08737096883469, 136.5554319897471, 326.5144604485311, 310.8445792133451, 114.26909061479087, 3.85840025694834, 8.832114021663266, 42.64197221242239, 48.94219097032222, 57.068555494308264, 47.997631840897064, 129.39551839449697, 92.16123838429971, 175.04475063904655, 47.99618264074478, 119.8445057254844, 247.55790001950245, 191.41680913694933, 35.490956156910784, 95.6112700652532, 112.52790766200972, 44.8336980662715, 95.52136695461668, 33.480935267517815, 255.50298303454406, 255.71495146691126, 98.0831479592286, 45.37270065751511, 50.17855548698743, 47.22838562659909, 71.87426679582525, 111.80276417509246, 148.19399720694318, 59.001659883466054, 144.4351585296887, 120.6646370053063, 268.35152675598937, 78.59740923773558, 3.9032024145927275, 249.4855521530756, 98.2290317846702, 202.49610604270714, 155.5281616442165, 444.3925085926601, 345.33050151087895, 182.61393074504878, 352.9001988343047, 15.405394225149582, 143.78254186766017, 2.5616598848797247, 22.340836068506178, 192.83260047006453, 16.01595402053598, 90.46484424679274, 35.59821790301873, 339.28688539376185, 306.9695322051485, 72.76672379494487, 217.91569059613775, 55.48405082814195, 435.95660559066124, 282.2353467600994, 146.1898458007251, 139.15845954364437, 6.676817604923221, 24.532903420046566, 187.30150813882418, 164.70469626081004, 82.83604087979359, 386.1745643819638, 368.4777954542359, 198.03300008148415, 302.40890144869473, 127.27076209717296, 311.5444041395558, 706.3224138909611, 28.748303230751507, 141.4711644566232, 309.02778594863446, 151.4179562127952, 12.812259415893742, 320.208913128137, 136.73623637017465, 144.51353051715768, 16.096816795662544, 225.79567686982415, 67.18142319031695, 617.8797053328075, 344.06051655132137, 300.43113887904093, 353.2698161330049, 37.473955101743016, 445.68147119629776, 181.70385714775293, 76.97185206056606, 47.15857076676161, 68.32448643294913, 95.42044120078874, 122.1710150926939, 29.63150845518346, 37.895128270290236, 296.0225145576254, 107.99259423247598, 56.46187781479349, 112.26595953431027, 334.7216659072099, 759.4665335850866, 261.60552674574205, 246.50816132987754, 3.202637925701816, 274.7865713661366, 125.87477763150062, 214.2230592747555, 214.16099662604157, 464.4032647258461, 337.0998361118139, 127.15778874413638, 257.53200646600254, 142.49138545873936, 465.6177309396087, 165.38092327482514, 605.3214562964532, 27.409688054564715, 220.1368448502749, 202.881024662453, 179.81348955029034, 283.96642254864327, 283.7575278564508, 185.75724828082608, 22.603179963644248, 61.44533903815531, 756.6858286664868, 517.159223736543, 107.29563927645538]}, "sampler_perf": {"mean_raw_obs_processing_ms": 4.427111678845687, "mean_inference_ms": 4.191291354223288, "mean_action_processing_ms": 1.9816225091172788, "mean_env_wait_ms": 9.990080472684705, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.009742140769958496, "StateBufferConnector_ms": 0.004868268966674805, "ViewRequirementAgentConnector_ms": 0.18418622016906738}, "num_episodes": 2, "episode_return_max": 723.1480054049603, "episode_return_min": 37.506740396183545, "episode_return_mean": 296.43079343517525, "episodes_this_iter": 2}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 304000, "num_agent_steps_trained": 304000, "num_env_steps_sampled": 76000, "num_env_steps_trained": 76000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 65.15947141291514, "num_env_steps_trained_throughput_per_sec": 65.15947141291514, "timesteps_total": 76000, "num_env_steps_sampled_lifetime": 76000, "num_agent_steps_sampled_lifetime": 304000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 304000, "timers": {"training_iteration_time_ms": 50315.257, "restore_workers_time_ms": 0.016, "training_step_time_ms": 50315.186, "sample_time_ms": 2176.928, "learn_time_ms": 48119.037, "learn_throughput": 83.127, "synch_weights_time_ms": 14.569}, "counters": {"num_env_steps_sampled": 76000, "num_env_steps_trained": 76000, "num_agent_steps_sampled": 304000, "num_agent_steps_trained": 304000}, "done": false, "training_iteration": 19, "trial_id": "798d9_00000", "date": "2024-08-22_09-53-24", "timestamp": 1724300604, "time_this_iter_s": 61.45350217819214, "time_total_s": 960.2248547077179, "pid": 48427, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"prey_count": 2, "prey_speed": 1.0, "prey_view_size": 10, "prey_size": 1, "prey_color": [0, 255, 0], "prey_kill_reward": -10, "prey_alive_reward": 0.1, "prey_reward_sqr_reward": 1, "predator_count": 2, "predator_speed": 1.0, "predator_view_size": 10, "predator_size": 1, "predator_color": [255, 0, 0], "predator_kill_reward": 10, "map_size": 40, "max_steps": 400, "screen_size": 600, "render_mode": "None", "fps": 60}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 8, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": true, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 1, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "custom_cnn", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x300bfd700>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 960.2248547077179, "iterations_since_restore": 19, "perf": {"cpu_util_percent": 46.19871794871795, "ram_util_percent": 82.74230769230768}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 6.6567656665882735, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 5.230687708451003, "policy_loss": -0.019559127432860868, "vf_loss": 5.2472964124074055, "vf_explained_var": 0.3362804587871309, "kl": 0.014752176971908993, "entropy": 1.0230659983145496, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 36855.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.863622477729485, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 4.855107261642577, "policy_loss": -0.02536446263720454, "vf_loss": 4.87723755975249, "vf_explained_var": 0.09246658651286332, "kl": 0.016170815910981406, "entropy": 1.2306154649724406, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 36855.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 80000, "num_env_steps_trained": 80000, "num_agent_steps_sampled": 320000, "num_agent_steps_trained": 320000}, "env_runners": {"episode_reward_max": 723.1480054049603, "episode_reward_min": 27.0, "episode_reward_mean": 264.04200128258015, "episode_len_mean": 400.0, "episode_media": {}, "episodes_timesteps_total": 40000, "policy_reward_min": {"prey_policy": -1077.8550878369078, "predator_policy": 2.5616598848797247}, "policy_reward_max": {"prey_policy": 376.812382620373, "predator_policy": 1044.0266464297151}, "policy_reward_mean": {"prey_policy": -104.98811339570291, "predator_policy": 237.00911403699308}, "custom_metrics": {}, "hist_stats": {"episode_reward": [410.6028006084132, 345.90000000000043, 139.69999999999703, 70.90000000000029, 63.30000000000063, 279.64572693029027, 349.70000000000107, 235.9009733077793, 214.99999999999966, 276.68389954105544, 142.185420720523, 205.77902626148932, 37.506740396183545, 77.49999999999987, 271.8425160205221, 351.20000000000005, 76.09999999999995, 72.80000000000014, 355.7000000000013, 359.22088371689665, 155.7375321156466, 336.1052306148806, 112.6999999999975, 253.79999999999728, 721.4984895986631, 339.2000000000014, 75.30897762584883, 722.5725727731624, 173.58894962874808, 414.3321651231242, 258.49999999999886, 384.0000000000024, 240.96741587580104, 703.8146078439153, 423.4788817070565, 335.0000000000022, 74.60000000000005, 723.1480054049603, 193.5544715538415, 488.6302082538318, 69.9129267472765, 340.7263431202153, 392.4665577952974, 545.9830086702245, 98.2999999999984, 316.7000000000009, 227.6999999999974, 193.37327863109786, 154.45429480276803, 491.65151733745085, 320.32080431783436, 322.24259643122446, 418.40000000000236, 157.81851315233754, 229.22599306291164, 324.75804483222174, 94.09999999999852, 364.2453454854257, 347.4000000000017, 201.39999999999847, 241.89999999999782, 110.0813413518992, 66.5000000000005, 208.39875498733264, 200.43662297567656, 565.9816752716484, 390.813077006542, 163.06813170125574, 70.80000000000027, 271.47241157243354, 485.6470795074924, 641.472844360221, 289.40387365809295, 292.6693794986311, 139.59999999999746, 479.87496995193294, 225.099999999998, 319.6180339887521, 400.2077972399478, 423.8599160870824, 157.50703763845527, 171.28200822029507, 402.12665410562306, 393.34271319556916, 139.89619655427137, 122.33149929910607, 123.98565633254854, 27.0, 175.97065355536495, 227.07126985988214, 248.91763795632795, 236.78450181134696, 49.51379297998552, 141.20860719018108, 120.43199823381104, 80.99999999999943, 44.100000000000314, 129.2668994152722, 265.49112076673555, 81.1812519753878], "episode_lengths": [400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400], "policy_prey_policy_reward": [-257.7315121765398, 361.7851532910748, 167.4070074237925, -72.15555908208464, 26.19324651093457, 33.6030165366545, -288.17736288755054, 23.443852062464494, -128.93884488795828, -142.80285529191028, -25.037662258665563, 119.9375724713436, 76.01645177360803, -83.11174434469032, 37.018753924373534, -154.76067785565894, -22.129318425672686, -78.38084396603054, -19.04034715917183, -421.33996044092163, -243.84991359235946, -75.3006140748056, 54.93146134287562, -312.95034565026685, -306.6654186305468, -260.9017327401376, 31.996687674699466, 10.34654449282513, 34.38302170292425, -76.00888895123396, -71.92676674605877, 134.63575370769615, -34.22777170509586, 20.782347460913304, -14.544705892595905, -31.805622761643214, -69.92707120921031, 278.84899009248386, 230.7530938951969, -397.9559854840322, -42.78852140229542, 2.883250559362983, -135.89478858578298, -165.35902046121583, -41.16909061479087, 35.7415997430519, 180.95020980183662, 21.37570396407685, 376.812382620373, 238.67536051365965, -4.43180510827797, 166.23865487288418, -27.67991996354027, -164.21709143395827, 178.22699779725613, 376.50488660967693, -20.16341730583126, -245.22234222187024, 160.01817667167325, 123.21176222927895, -20.215857706416543, 121.35425197813554, -51.57749341911413, 306.5751911969785, -192.40888599054787, -77.841632635107, 188.87290687109663, 371.48585235607493, 335.9683026473879, -9.896362053920004, 116.41860709750614, 34.904361931576304, -110.79399720694488, -21.801659883465526, 238.165410034407, 219.8827998355583, 15.59405184196084, -168.98851628184283, 72.46951393471171, 162.77193975145033, -58.30292523317673, -172.50928584692716, 81.88041325852578, -341.07474037518733, -297.50826128377986, 162.03038682314977, 46.34328116392672, 131.33413444684265, -85.28254186766168, 37.238340115120536, 15.85916393149381, 85.66739952993525, 22.684045979464056, 98.53515575320644, -87.13196176951354, -94.37986289616912, -149.76831165587336, -75.51364954145205, -36.71783950835651, 254.969615421524, -110.25832207875189, -287.6128259541711, -65.65915374974611, 102.55344483659391, 32.72318239507697, 354.4670965799534, -166.77066475120913, -27.417026496085683, -12.586726203201136, -227.1978859956428, 140.5945339114458, -382.3472846149405, -267.01312868873384, -68.56653485713092, -717.2097699875618, 63.588297442470555, 167.8923696688501, 9.28816264377539, -280.227785948628, 21.18204378720486, 25.88774058410634, -117.00891312813721, -82.28048431438276, -88.88794122105355, 22.303183204337465, -197.6956768698257, -554.0154183602142, 77.35304482442349, -247.36430799600797, -196.6907244586775, -106.37918720231912, 281.6170912392196, 59.20077720047444, -295.77302853798363, 4.021379005777842, 34.916329868153014, -32.42448643294864, -60.520441200790195, 128.30208745411701, -8.632199429560416, -13.598161324406597, 165.327598003983, 236.89376340262797, 240.12460891032336, -154.1987553812961, -3.38499640213143, -52.21930582784222, -676.1833750043567, -146.60816132987821, 36.49736207429844, 208.80140202984538, -129.58778107555176, -24.417826634627417, -178.86622926616926, -294.1032647258467, -187.78180212306458, 97.59652167047804, -82.07851964067258, -413.7394307005578, 229.49023038929224, -571.2046392019516, -41.99070273087026, -88.45912867082248, 12.194603986279349, 5.278838588669828, 14.153301304206064, 78.91535343658234, -253.2965906461101, -97.32119278939447, 28.8569610991972, -613.1746087344347, -82.62505967109945, -48.09265033306259, -452.3765563473814, -958.0081108092561, -584.5014562901385, -89.71148711155239, -590.3298151816005, -228.16216699996465, -139.1731195309735, -771.2724829168144, -337.9952915950716, -19.418052103837567, -940.6094645987503, -832.2733573856433, -837.6648589154923, -1077.8550878369078, -293.34900159180876, -764.2336104764197, -254.48665155037477, -1026.2266464297154, 1.9462415198095113, -641.4914763075627, -745.4117615564805, -567.5474173541759, -593.1973599579004, -37.564797046436816, -740.4405304806073, -950.9116387202935, -787.3216875943064], "policy_predator_policy_reward": [211.31032296239817, 95.23883653147679, 11.392992576206154, 239.25555908208406, 48.31933511067729, 31.584401841733893, 320.37736288755036, 15.256147937535534, 161.53884488795643, 173.50285529190882, 100.89735298546444, 83.8484637321489, 240.98354822639197, 115.81174434468859, 186.02126421534868, 167.62163302371837, 39.54292005573028, 275.9672423359727, 368.0515318600075, 349.0126752811421, 276.34991359235966, 184.98603479532701, 159.1688218260833, 304.62908874280043, 505.2104852284398, 99.86340653843195, 7.303312325300711, 27.853455507174978, 74.18320943417223, 239.28517383465712, 124.65178849150561, 163.83922454685717, 70.22777170509606, 19.317652539086684, 51.544705892596404, 67.60562276164372, 103.42707120920916, 43.351009907516115, 452.7364425343829, 73.68733277134959, 59.08737096883469, 136.5554319897471, 326.5144604485311, 310.8445792133451, 114.26909061479087, 3.85840025694834, 8.832114021663266, 42.64197221242239, 48.94219097032222, 57.068555494308264, 47.997631840897064, 129.39551839449697, 92.16123838429971, 175.04475063904655, 47.99618264074478, 119.8445057254844, 247.55790001950245, 191.41680913694933, 35.490956156910784, 95.6112700652532, 112.52790766200972, 44.8336980662715, 95.52136695461668, 33.480935267517815, 255.50298303454406, 255.71495146691126, 98.0831479592286, 45.37270065751511, 50.17855548698743, 47.22838562659909, 71.87426679582525, 111.80276417509246, 148.19399720694318, 59.001659883466054, 144.4351585296887, 120.6646370053063, 268.35152675598937, 78.59740923773558, 3.9032024145927275, 249.4855521530756, 98.2290317846702, 202.49610604270714, 155.5281616442165, 444.3925085926601, 345.33050151087895, 182.61393074504878, 352.9001988343047, 15.405394225149582, 143.78254186766017, 2.5616598848797247, 22.340836068506178, 192.83260047006453, 16.01595402053598, 90.46484424679274, 35.59821790301873, 339.28688539376185, 306.9695322051485, 72.76672379494487, 217.91569059613775, 55.48405082814195, 435.95660559066124, 282.2353467600994, 146.1898458007251, 139.15845954364437, 6.676817604923221, 24.532903420046566, 187.30150813882418, 164.70469626081004, 82.83604087979359, 386.1745643819638, 368.4777954542359, 198.03300008148415, 302.40890144869473, 127.27076209717296, 311.5444041395558, 706.3224138909611, 28.748303230751507, 141.4711644566232, 309.02778594863446, 151.4179562127952, 12.812259415893742, 320.208913128137, 136.73623637017465, 144.51353051715768, 16.096816795662544, 225.79567686982415, 67.18142319031695, 617.8797053328075, 344.06051655132137, 300.43113887904093, 353.2698161330049, 37.473955101743016, 445.68147119629776, 181.70385714775293, 76.97185206056606, 47.15857076676161, 68.32448643294913, 95.42044120078874, 122.1710150926939, 29.63150845518346, 37.895128270290236, 296.0225145576254, 107.99259423247598, 56.46187781479349, 112.26595953431027, 334.7216659072099, 759.4665335850866, 261.60552674574205, 246.50816132987754, 3.202637925701816, 274.7865713661366, 125.87477763150062, 214.2230592747555, 214.16099662604157, 464.4032647258461, 337.0998361118139, 127.15778874413638, 257.53200646600254, 142.49138545873936, 465.6177309396087, 165.38092327482514, 605.3214562964532, 27.409688054564715, 220.1368448502749, 202.881024662453, 179.81348955029034, 283.96642254864327, 283.7575278564508, 185.75724828082608, 22.603179963644248, 61.44533903815531, 756.6858286664868, 517.159223736543, 107.29563927645538, 973.7081108092566, 595.8014562901382, 140.0639500983123, 715.9480057502072, 341.1927095214421, 253.21384686937833, 951.5480176315726, 406.63739483664716, 318.5973910893518, 878.2146274245848, 839.5733573856439, 879.8786518954794, 1040.446976294844, 471.9657203240586, 762.117137608719, 377.035122651886, 1044.0266464297151, 61.25375848019064, 669.1914763075652, 761.8117615564835, 524.5828347910635, 765.4288419362913, 336.02599128500935, 707.4704570087705, 864.2248498098111, 955.1897284801764]}, "sampler_perf": {"mean_raw_obs_processing_ms": 4.360329579404776, "mean_inference_ms": 4.138271494400973, "mean_action_processing_ms": 1.8627095559576548, "mean_env_wait_ms": 10.011731036923706, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.009449124336242676, "StateBufferConnector_ms": 0.004790902137756348, "ViewRequirementAgentConnector_ms": 0.16970860958099365}, "num_episodes": 13, "episode_return_max": 723.1480054049603, "episode_return_min": 27.0, "episode_return_mean": 264.04200128258015, "episodes_this_iter": 13}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 320000, "num_agent_steps_trained": 320000, "num_env_steps_sampled": 80000, "num_env_steps_trained": 80000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 74.62586167418593, "num_env_steps_trained_throughput_per_sec": 74.62586167418593, "timesteps_total": 80000, "num_env_steps_sampled_lifetime": 80000, "num_agent_steps_sampled_lifetime": 320000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 320000, "timers": {"training_iteration_time_ms": 50734.228, "restore_workers_time_ms": 0.019, "training_step_time_ms": 50734.152, "sample_time_ms": 2392.828, "learn_time_ms": 48321.373, "learn_throughput": 82.779, "synch_weights_time_ms": 14.49}, "counters": {"num_env_steps_sampled": 80000, "num_env_steps_trained": 80000, "num_agent_steps_sampled": 320000, "num_agent_steps_trained": 320000}, "done": false, "training_iteration": 20, "trial_id": "798d9_00000", "date": "2024-08-22_09-54-18", "timestamp": 1724300658, "time_this_iter_s": 53.645946979522705, "time_total_s": 1013.8708016872406, "pid": 48427, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"prey_count": 2, "prey_speed": 1.0, "prey_view_size": 10, "prey_size": 1, "prey_color": [0, 255, 0], "prey_kill_reward": -10, "prey_alive_reward": 0.1, "prey_reward_sqr_reward": 1, "predator_count": 2, "predator_speed": 1.0, "predator_view_size": 10, "predator_size": 1, "predator_color": [255, 0, 0], "predator_kill_reward": 10, "map_size": 40, "max_steps": 400, "screen_size": 600, "render_mode": "None", "fps": 60}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 8, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": true, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 1, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "custom_cnn", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x300c10550>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1013.8708016872406, "iterations_since_restore": 20, "perf": {"cpu_util_percent": 51.90526315789474, "ram_util_percent": 82.54342105263157}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 6.992675416557877, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 5.402356986646299, "policy_loss": -0.01855949422014414, "vf_loss": 5.417844686306343, "vf_explained_var": 0.3195535427363461, "kl": 0.015359032389377712, "entropy": 0.9752436480194172, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 38745.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.674070801053729, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 5.30840620792732, "policy_loss": -0.02758884780508067, "vf_loss": 5.332580212184361, "vf_explained_var": 0.014641854340437228, "kl": 0.017074210809484597, "entropy": 1.2180224285554633, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 38745.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 84000, "num_env_steps_trained": 84000, "num_agent_steps_sampled": 336000, "num_agent_steps_trained": 336000}, "env_runners": {"episode_reward_max": 723.1480054049603, "episode_reward_min": 18.87856513393217, "episode_reward_mean": 245.20214241087928, "episode_len_mean": 400.0, "episode_media": {}, "episodes_timesteps_total": 40000, "policy_reward_min": {"prey_policy": -1135.3817687190829, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 376.812382620373, "predator_policy": 1044.0266464297151}, "policy_reward_mean": {"prey_policy": -155.98483498578, "predator_policy": 278.5859061912198}, "custom_metrics": {}, "hist_stats": {"episode_reward": [76.09999999999995, 72.80000000000014, 355.7000000000013, 359.22088371689665, 155.7375321156466, 336.1052306148806, 112.6999999999975, 253.79999999999728, 721.4984895986631, 339.2000000000014, 75.30897762584883, 722.5725727731624, 173.58894962874808, 414.3321651231242, 258.49999999999886, 384.0000000000024, 240.96741587580104, 703.8146078439153, 423.4788817070565, 335.0000000000022, 74.60000000000005, 723.1480054049603, 193.5544715538415, 488.6302082538318, 69.9129267472765, 340.7263431202153, 392.4665577952974, 545.9830086702245, 98.2999999999984, 316.7000000000009, 227.6999999999974, 193.37327863109786, 154.45429480276803, 491.65151733745085, 320.32080431783436, 322.24259643122446, 418.40000000000236, 157.81851315233754, 229.22599306291164, 324.75804483222174, 94.09999999999852, 364.2453454854257, 347.4000000000017, 201.39999999999847, 241.89999999999782, 110.0813413518992, 66.5000000000005, 208.39875498733264, 200.43662297567656, 565.9816752716484, 390.813077006542, 163.06813170125574, 70.80000000000027, 271.47241157243354, 485.6470795074924, 641.472844360221, 289.40387365809295, 292.6693794986311, 139.59999999999746, 479.87496995193294, 225.099999999998, 319.6180339887521, 400.2077972399478, 423.8599160870824, 157.50703763845527, 171.28200822029507, 402.12665410562306, 393.34271319556916, 139.89619655427137, 122.33149929910607, 123.98565633254854, 27.0, 175.97065355536495, 227.07126985988214, 248.91763795632795, 236.78450181134696, 49.51379297998552, 141.20860719018108, 120.43199823381104, 80.99999999999943, 44.100000000000314, 129.2668994152722, 265.49112076673555, 81.1812519753878, 169.92263091401327, 44.80000000000028, 29.33896820447685, 116.9738215638955, 78.99999999999979, 73.93846624547294, 102.1422361651755, 93.89999999999885, 18.87856513393217, 327.0853317484657, 70.57285761003118, 44.17409475235046, 113.00596079975779, 80.64440000211064, 64.6000000000006, 160.38388347648228], "episode_lengths": [400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400], "policy_prey_policy_reward": [-34.22777170509586, 20.782347460913304, -14.544705892595905, -31.805622761643214, -69.92707120921031, 278.84899009248386, 230.7530938951969, -397.9559854840322, -42.78852140229542, 2.883250559362983, -135.89478858578298, -165.35902046121583, -41.16909061479087, 35.7415997430519, 180.95020980183662, 21.37570396407685, 376.812382620373, 238.67536051365965, -4.43180510827797, 166.23865487288418, -27.67991996354027, -164.21709143395827, 178.22699779725613, 376.50488660967693, -20.16341730583126, -245.22234222187024, 160.01817667167325, 123.21176222927895, -20.215857706416543, 121.35425197813554, -51.57749341911413, 306.5751911969785, -192.40888599054787, -77.841632635107, 188.87290687109663, 371.48585235607493, 335.9683026473879, -9.896362053920004, 116.41860709750614, 34.904361931576304, -110.79399720694488, -21.801659883465526, 238.165410034407, 219.8827998355583, 15.59405184196084, -168.98851628184283, 72.46951393471171, 162.77193975145033, -58.30292523317673, -172.50928584692716, 81.88041325852578, -341.07474037518733, -297.50826128377986, 162.03038682314977, 46.34328116392672, 131.33413444684265, -85.28254186766168, 37.238340115120536, 15.85916393149381, 85.66739952993525, 22.684045979464056, 98.53515575320644, -87.13196176951354, -94.37986289616912, -149.76831165587336, -75.51364954145205, -36.71783950835651, 254.969615421524, -110.25832207875189, -287.6128259541711, -65.65915374974611, 102.55344483659391, 32.72318239507697, 354.4670965799534, -166.77066475120913, -27.417026496085683, -12.586726203201136, -227.1978859956428, 140.5945339114458, -382.3472846149405, -267.01312868873384, -68.56653485713092, -717.2097699875618, 63.588297442470555, 167.8923696688501, 9.28816264377539, -280.227785948628, 21.18204378720486, 25.88774058410634, -117.00891312813721, -82.28048431438276, -88.88794122105355, 22.303183204337465, -197.6956768698257, -554.0154183602142, 77.35304482442349, -247.36430799600797, -196.6907244586775, -106.37918720231912, 281.6170912392196, 59.20077720047444, -295.77302853798363, 4.021379005777842, 34.916329868153014, -32.42448643294864, -60.520441200790195, 128.30208745411701, -8.632199429560416, -13.598161324406597, 165.327598003983, 236.89376340262797, 240.12460891032336, -154.1987553812961, -3.38499640213143, -52.21930582784222, -676.1833750043567, -146.60816132987821, 36.49736207429844, 208.80140202984538, -129.58778107555176, -24.417826634627417, -178.86622926616926, -294.1032647258467, -187.78180212306458, 97.59652167047804, -82.07851964067258, -413.7394307005578, 229.49023038929224, -571.2046392019516, -41.99070273087026, -88.45912867082248, 12.194603986279349, 5.278838588669828, 14.153301304206064, 78.91535343658234, -253.2965906461101, -97.32119278939447, 28.8569610991972, -613.1746087344347, -82.62505967109945, -48.09265033306259, -452.3765563473814, -958.0081108092561, -584.5014562901385, -89.71148711155239, -590.3298151816005, -228.16216699996465, -139.1731195309735, -771.2724829168144, -337.9952915950716, -19.418052103837567, -940.6094645987503, -832.2733573856433, -837.6648589154923, -1077.8550878369078, -293.34900159180876, -764.2336104764197, -254.48665155037477, -1026.2266464297154, 1.9462415198095113, -641.4914763075627, -745.4117615564805, -567.5474173541759, -593.1973599579004, -37.564797046436816, -740.4405304806073, -950.9116387202935, -787.3216875943064, -277.3243983079356, -239.9655693195871, -93.14389247382144, -941.0264789653185, -1135.3817687190829, -460.26282532488045, -513.7929578285921, -268.4558631177458, 40.0000000000003, 15.559064460474586, 34.51183062219323, -147.20067973066858, -784.5876647490282, -119.16502810195513, -64.56894269410893, 40.0000000000003, -961.6962409717364, -931.382869187502, -857.1385677763353, 78.48427432847419, -503.6339933418699, 23.428511991704504, -1004.9962576226209, 34.74038812078656, -658.9421825197294, -154.31769216624147, -688.2530833662153, -364.7205196573287, -124.06451883218813, -38.22196955611365, -168.7364803175798, -894.5997891378624], "policy_predator_policy_reward": [70.22777170509606, 19.317652539086684, 51.544705892596404, 67.60562276164372, 103.42707120920916, 43.351009907516115, 452.7364425343829, 73.68733277134959, 59.08737096883469, 136.5554319897471, 326.5144604485311, 310.8445792133451, 114.26909061479087, 3.85840025694834, 8.832114021663266, 42.64197221242239, 48.94219097032222, 57.068555494308264, 47.997631840897064, 129.39551839449697, 92.16123838429971, 175.04475063904655, 47.99618264074478, 119.8445057254844, 247.55790001950245, 191.41680913694933, 35.490956156910784, 95.6112700652532, 112.52790766200972, 44.8336980662715, 95.52136695461668, 33.480935267517815, 255.50298303454406, 255.71495146691126, 98.0831479592286, 45.37270065751511, 50.17855548698743, 47.22838562659909, 71.87426679582525, 111.80276417509246, 148.19399720694318, 59.001659883466054, 144.4351585296887, 120.6646370053063, 268.35152675598937, 78.59740923773558, 3.9032024145927275, 249.4855521530756, 98.2290317846702, 202.49610604270714, 155.5281616442165, 444.3925085926601, 345.33050151087895, 182.61393074504878, 352.9001988343047, 15.405394225149582, 143.78254186766017, 2.5616598848797247, 22.340836068506178, 192.83260047006453, 16.01595402053598, 90.46484424679274, 35.59821790301873, 339.28688539376185, 306.9695322051485, 72.76672379494487, 217.91569059613775, 55.48405082814195, 435.95660559066124, 282.2353467600994, 146.1898458007251, 139.15845954364437, 6.676817604923221, 24.532903420046566, 187.30150813882418, 164.70469626081004, 82.83604087979359, 386.1745643819638, 368.4777954542359, 198.03300008148415, 302.40890144869473, 127.27076209717296, 311.5444041395558, 706.3224138909611, 28.748303230751507, 141.4711644566232, 309.02778594863446, 151.4179562127952, 12.812259415893742, 320.208913128137, 136.73623637017465, 144.51353051715768, 16.096816795662544, 225.79567686982415, 67.18142319031695, 617.8797053328075, 344.06051655132137, 300.43113887904093, 353.2698161330049, 37.473955101743016, 445.68147119629776, 181.70385714775293, 76.97185206056606, 47.15857076676161, 68.32448643294913, 95.42044120078874, 122.1710150926939, 29.63150845518346, 37.895128270290236, 296.0225145576254, 107.99259423247598, 56.46187781479349, 112.26595953431027, 334.7216659072099, 759.4665335850866, 261.60552674574205, 246.50816132987754, 3.202637925701816, 274.7865713661366, 125.87477763150062, 214.2230592747555, 214.16099662604157, 464.4032647258461, 337.0998361118139, 127.15778874413638, 257.53200646600254, 142.49138545873936, 465.6177309396087, 165.38092327482514, 605.3214562964532, 27.409688054564715, 220.1368448502749, 202.881024662453, 179.81348955029034, 283.96642254864327, 283.7575278564508, 185.75724828082608, 22.603179963644248, 61.44533903815531, 756.6858286664868, 517.159223736543, 107.29563927645538, 973.7081108092566, 595.8014562901382, 140.0639500983123, 715.9480057502072, 341.1927095214421, 253.21384686937833, 951.5480176315726, 406.63739483664716, 318.5973910893518, 878.2146274245848, 839.5733573856439, 879.8786518954794, 1040.446976294844, 471.9657203240586, 762.117137608719, 377.035122651886, 1044.0266464297151, 61.25375848019064, 669.1914763075652, 761.8117615564835, 524.5828347910635, 765.4288419362913, 336.02599128500935, 707.4704570087705, 864.2248498098111, 955.1897284801764, 418.89555080493045, 268.3170477366086, 137.2438924738196, 941.7264789653186, 837.9300621127719, 787.0535001356714, 249.8054417895971, 649.4172007206437, 0.0, 23.440935539525427, 9.923524430199894, 176.70379092374665, 768.0447480086945, 237.8501810074673, 118.46894269410713, 0.0, 988.5494252741128, 923.408250019058, 370.8982376404749, 734.8413875558513, 530.5339933418732, 20.244345618326637, 1012.896257622622, 1.5337066315638035, 1.1832765355174397, 925.0825589502115, 737.3307511248817, 396.2872519007783, 154.06451883218642, 72.82196955611367, 323.7203637940623, 899.999789137863]}, "sampler_perf": {"mean_raw_obs_processing_ms": 4.276263478211906, "mean_inference_ms": 4.080049426605547, "mean_action_processing_ms": 1.8342528872429507, "mean_env_wait_ms": 10.003448062596176, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00924384593963623, "StateBufferConnector_ms": 0.004884123802185059, "ViewRequirementAgentConnector_ms": 0.15980303287506104}, "num_episodes": 16, "episode_return_max": 723.1480054049603, "episode_return_min": 18.87856513393217, "episode_return_mean": 245.20214241087928, "episodes_this_iter": 16}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 336000, "num_agent_steps_trained": 336000, "num_env_steps_sampled": 84000, "num_env_steps_trained": 84000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 75.11958028463306, "num_env_steps_trained_throughput_per_sec": 75.11958028463306, "timesteps_total": 84000, "num_env_steps_sampled_lifetime": 84000, "num_agent_steps_sampled_lifetime": 336000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 336000, "timers": {"training_iteration_time_ms": 51178.372, "restore_workers_time_ms": 0.019, "training_step_time_ms": 51178.297, "sample_time_ms": 2554.801, "learn_time_ms": 48603.278, "learn_throughput": 82.299, "synch_weights_time_ms": 14.693}, "counters": {"num_env_steps_sampled": 84000, "num_env_steps_trained": 84000, "num_agent_steps_sampled": 336000, "num_agent_steps_trained": 336000}, "done": false, "training_iteration": 21, "trial_id": "798d9_00000", "date": "2024-08-22_09-55-11", "timestamp": 1724300711, "time_this_iter_s": 53.293875217437744, "time_total_s": 1067.1646769046783, "pid": 48427, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"prey_count": 2, "prey_speed": 1.0, "prey_view_size": 10, "prey_size": 1, "prey_color": [0, 255, 0], "prey_kill_reward": -10, "prey_alive_reward": 0.1, "prey_reward_sqr_reward": 1, "predator_count": 2, "predator_speed": 1.0, "predator_view_size": 10, "predator_size": 1, "predator_color": [255, 0, 0], "predator_kill_reward": 10, "map_size": 40, "max_steps": 400, "screen_size": 600, "render_mode": "None", "fps": 60}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 8, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": true, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 1, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "custom_cnn", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x300bf78b0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1067.1646769046783, "iterations_since_restore": 21, "perf": {"cpu_util_percent": 99.20131578947368, "ram_util_percent": 83.4263157894737}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 6.064292168617248, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 5.758266602622138, "policy_loss": -0.016571656145431376, "vf_loss": 5.77203322289482, "vf_explained_var": 0.3479354011949408, "kl": 0.014025201625560247, "entropy": 0.922880876789648, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 40635.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 6.1855474138701405, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 5.794566789253679, "policy_loss": -0.026875281925732023, "vf_loss": 5.8180722630213175, "vf_explained_var": 0.09635598643746957, "kl": 0.01684902938447459, "entropy": 1.1912803972839678, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 40635.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 88000, "num_env_steps_trained": 88000, "num_agent_steps_sampled": 352000, "num_agent_steps_trained": 352000}, "env_runners": {"episode_reward_max": 723.1480054049603, "episode_reward_min": 18.87856513393217, "episode_reward_mean": 208.59087608321633, "episode_len_mean": 400.0, "episode_media": {}, "episodes_timesteps_total": 40000, "policy_reward_min": {"prey_policy": -1211.7692242864675, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 354.4670965799534, "predator_policy": 1192.2648094749234}, "policy_reward_mean": {"prey_policy": -245.6591299343193, "predator_policy": 349.95456797592794}, "custom_metrics": {}, "hist_stats": {"episode_reward": [335.0000000000022, 74.60000000000005, 723.1480054049603, 193.5544715538415, 488.6302082538318, 69.9129267472765, 340.7263431202153, 392.4665577952974, 545.9830086702245, 98.2999999999984, 316.7000000000009, 227.6999999999974, 193.37327863109786, 154.45429480276803, 491.65151733745085, 320.32080431783436, 322.24259643122446, 418.40000000000236, 157.81851315233754, 229.22599306291164, 324.75804483222174, 94.09999999999852, 364.2453454854257, 347.4000000000017, 201.39999999999847, 241.89999999999782, 110.0813413518992, 66.5000000000005, 208.39875498733264, 200.43662297567656, 565.9816752716484, 390.813077006542, 163.06813170125574, 70.80000000000027, 271.47241157243354, 485.6470795074924, 641.472844360221, 289.40387365809295, 292.6693794986311, 139.59999999999746, 479.87496995193294, 225.099999999998, 319.6180339887521, 400.2077972399478, 423.8599160870824, 157.50703763845527, 171.28200822029507, 402.12665410562306, 393.34271319556916, 139.89619655427137, 122.33149929910607, 123.98565633254854, 27.0, 175.97065355536495, 227.07126985988214, 248.91763795632795, 236.78450181134696, 49.51379297998552, 141.20860719018108, 120.43199823381104, 80.99999999999943, 44.100000000000314, 129.2668994152722, 265.49112076673555, 81.1812519753878, 169.92263091401327, 44.80000000000028, 29.33896820447685, 116.9738215638955, 78.99999999999979, 73.93846624547294, 102.1422361651755, 93.89999999999885, 18.87856513393217, 327.0853317484657, 70.57285761003118, 44.17409475235046, 113.00596079975779, 80.64440000211064, 64.6000000000006, 160.38388347648228, 30.077119002153168, 86.01538034006023, 76.41107477117838, 108.33303090610076, 131.9590479458621, 422.5034472823143, 288.88002515527637, 178.89980714946458, 130.09999999999994, 101.1607744554352, 152.29999999999714, 75.39999999999999, 149.24819220567184, 62.45813470604908, 76.34054096210176, 112.32679465716517, 61.30000000000059, 104.93959286879112, 169.6461114498268], "episode_lengths": [400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400], "policy_prey_policy_reward": [116.41860709750614, 34.904361931576304, -110.79399720694488, -21.801659883465526, 238.165410034407, 219.8827998355583, 15.59405184196084, -168.98851628184283, 72.46951393471171, 162.77193975145033, -58.30292523317673, -172.50928584692716, 81.88041325852578, -341.07474037518733, -297.50826128377986, 162.03038682314977, 46.34328116392672, 131.33413444684265, -85.28254186766168, 37.238340115120536, 15.85916393149381, 85.66739952993525, 22.684045979464056, 98.53515575320644, -87.13196176951354, -94.37986289616912, -149.76831165587336, -75.51364954145205, -36.71783950835651, 254.969615421524, -110.25832207875189, -287.6128259541711, -65.65915374974611, 102.55344483659391, 32.72318239507697, 354.4670965799534, -166.77066475120913, -27.417026496085683, -12.586726203201136, -227.1978859956428, 140.5945339114458, -382.3472846149405, -267.01312868873384, -68.56653485713092, -717.2097699875618, 63.588297442470555, 167.8923696688501, 9.28816264377539, -280.227785948628, 21.18204378720486, 25.88774058410634, -117.00891312813721, -82.28048431438276, -88.88794122105355, 22.303183204337465, -197.6956768698257, -554.0154183602142, 77.35304482442349, -247.36430799600797, -196.6907244586775, -106.37918720231912, 281.6170912392196, 59.20077720047444, -295.77302853798363, 4.021379005777842, 34.916329868153014, -32.42448643294864, -60.520441200790195, 128.30208745411701, -8.632199429560416, -13.598161324406597, 165.327598003983, 236.89376340262797, 240.12460891032336, -154.1987553812961, -3.38499640213143, -52.21930582784222, -676.1833750043567, -146.60816132987821, 36.49736207429844, 208.80140202984538, -129.58778107555176, -24.417826634627417, -178.86622926616926, -294.1032647258467, -187.78180212306458, 97.59652167047804, -82.07851964067258, -413.7394307005578, 229.49023038929224, -571.2046392019516, -41.99070273087026, -88.45912867082248, 12.194603986279349, 5.278838588669828, 14.153301304206064, 78.91535343658234, -253.2965906461101, -97.32119278939447, 28.8569610991972, -613.1746087344347, -82.62505967109945, -48.09265033306259, -452.3765563473814, -958.0081108092561, -584.5014562901385, -89.71148711155239, -590.3298151816005, -228.16216699996465, -139.1731195309735, -771.2724829168144, -337.9952915950716, -19.418052103837567, -940.6094645987503, -832.2733573856433, -837.6648589154923, -1077.8550878369078, -293.34900159180876, -764.2336104764197, -254.48665155037477, -1026.2266464297154, 1.9462415198095113, -641.4914763075627, -745.4117615564805, -567.5474173541759, -593.1973599579004, -37.564797046436816, -740.4405304806073, -950.9116387202935, -787.3216875943064, -277.3243983079356, -239.9655693195871, -93.14389247382144, -941.0264789653185, -1135.3817687190829, -460.26282532488045, -513.7929578285921, -268.4558631177458, 40.0000000000003, 15.559064460474586, 34.51183062219323, -147.20067973066858, -784.5876647490282, -119.16502810195513, -64.56894269410893, 40.0000000000003, -961.6962409717364, -931.382869187502, -857.1385677763353, 78.48427432847419, -503.6339933418699, 23.428511991704504, -1004.9962576226209, 34.74038812078656, -658.9421825197294, -154.31769216624147, -688.2530833662153, -364.7205196573287, -124.06451883218813, -38.22196955611365, -168.7364803175798, -894.5997891378624, -902.5913308904594, -541.101654141373, -5.147180791724269, -1211.7692242864675, -530.3999173964023, -39.6470908432685, -674.8706925847459, -216.25453284076636, -619.6419515807949, -231.08240936854747, -526.2937877983853, -616.8348418332259, -384.47007584853276, -962.5182779501183, -610.5421839531836, -170.84129851662408, -84.69448511473064, 34.50180705498734, -626.9538676243252, -110.93779792263746, -24.25448288313516, -105.04595171477095, -20.237714150015712, 24.69504858687679, -317.27147207938185, -793.1198126732669, -596.5756532409371, -400.3769941825762, -842.6872388835557, 11.072411046644715, -875.1745938517199, -295.51947842627635, -472.8377370893173, 40.0000000000003, -64.04474155357948, -1150.5360122661841, -228.02567513991562, -824.8755610492829], "policy_predator_policy_reward": [71.87426679582525, 111.80276417509246, 148.19399720694318, 59.001659883466054, 144.4351585296887, 120.6646370053063, 268.35152675598937, 78.59740923773558, 3.9032024145927275, 249.4855521530756, 98.2290317846702, 202.49610604270714, 155.5281616442165, 444.3925085926601, 345.33050151087895, 182.61393074504878, 352.9001988343047, 15.405394225149582, 143.78254186766017, 2.5616598848797247, 22.340836068506178, 192.83260047006453, 16.01595402053598, 90.46484424679274, 35.59821790301873, 339.28688539376185, 306.9695322051485, 72.76672379494487, 217.91569059613775, 55.48405082814195, 435.95660559066124, 282.2353467600994, 146.1898458007251, 139.15845954364437, 6.676817604923221, 24.532903420046566, 187.30150813882418, 164.70469626081004, 82.83604087979359, 386.1745643819638, 368.4777954542359, 198.03300008148415, 302.40890144869473, 127.27076209717296, 311.5444041395558, 706.3224138909611, 28.748303230751507, 141.4711644566232, 309.02778594863446, 151.4179562127952, 12.812259415893742, 320.208913128137, 136.73623637017465, 144.51353051715768, 16.096816795662544, 225.79567686982415, 67.18142319031695, 617.8797053328075, 344.06051655132137, 300.43113887904093, 353.2698161330049, 37.473955101743016, 445.68147119629776, 181.70385714775293, 76.97185206056606, 47.15857076676161, 68.32448643294913, 95.42044120078874, 122.1710150926939, 29.63150845518346, 37.895128270290236, 296.0225145576254, 107.99259423247598, 56.46187781479349, 112.26595953431027, 334.7216659072099, 759.4665335850866, 261.60552674574205, 246.50816132987754, 3.202637925701816, 274.7865713661366, 125.87477763150062, 214.2230592747555, 214.16099662604157, 464.4032647258461, 337.0998361118139, 127.15778874413638, 257.53200646600254, 142.49138545873936, 465.6177309396087, 165.38092327482514, 605.3214562964532, 27.409688054564715, 220.1368448502749, 202.881024662453, 179.81348955029034, 283.96642254864327, 283.7575278564508, 185.75724828082608, 22.603179963644248, 61.44533903815531, 756.6858286664868, 517.159223736543, 107.29563927645538, 973.7081108092566, 595.8014562901382, 140.0639500983123, 715.9480057502072, 341.1927095214421, 253.21384686937833, 951.5480176315726, 406.63739483664716, 318.5973910893518, 878.2146274245848, 839.5733573856439, 879.8786518954794, 1040.446976294844, 471.9657203240586, 762.117137608719, 377.035122651886, 1044.0266464297151, 61.25375848019064, 669.1914763075652, 761.8117615564835, 524.5828347910635, 765.4288419362913, 336.02599128500935, 707.4704570087705, 864.2248498098111, 955.1897284801764, 418.89555080493045, 268.3170477366086, 137.2438924738196, 941.7264789653186, 837.9300621127719, 787.0535001356714, 249.8054417895971, 649.4172007206437, 0.0, 23.440935539525427, 9.923524430199894, 176.70379092374665, 768.0447480086945, 237.8501810074673, 118.46894269410713, 0.0, 988.5494252741128, 923.408250019058, 370.8982376404749, 734.8413875558513, 530.5339933418732, 20.244345618326637, 1012.896257622622, 1.5337066315638035, 1.1832765355174397, 925.0825589502115, 737.3307511248817, 396.2872519007783, 154.06451883218642, 72.82196955611367, 323.7203637940623, 899.999789137863, 906.0349867596565, 567.7351172743328, 1192.2648094749234, 110.6669759433296, 67.36469425144463, 579.0933887594076, 763.5113579943423, 235.9468983372709, 95.2330436691542, 887.4503652260491, 842.1051946289151, 723.5268822850117, 1020.7564086183648, 615.1119703355611, 644.1884351152901, 316.0948545039841, 175.2944851147307, 4.998192945012882, 701.8495591985411, 137.20288080385652, 142.85448288313546, 138.74595171476903, 56.337714150016225, 14.604951413123256, 548.7857154733578, 710.8537614849703, 616.7698140003711, 442.640968129199, 856.7872388835575, 51.16812991545756, 939.4241745278763, 343.5966924072928, 494.1377370893221, 0.0, 162.97910663010813, 1156.5412400584466, 830.2314131178107, 392.3159345212152]}, "sampler_perf": {"mean_raw_obs_processing_ms": 4.317984224290589, "mean_inference_ms": 4.105817213880013, "mean_action_processing_ms": 1.7769863232657244, "mean_env_wait_ms": 10.038152618257977, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0045740604400634766, "StateBufferConnector_ms": 0.004891514778137207, "ViewRequirementAgentConnector_ms": 0.38131558895111084}, "num_episodes": 19, "episode_return_max": 723.1480054049603, "episode_return_min": 18.87856513393217, "episode_return_mean": 208.59087608321633, "episodes_this_iter": 19}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 352000, "num_agent_steps_trained": 352000, "num_env_steps_sampled": 88000, "num_env_steps_trained": 88000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 75.37229772036395, "num_env_steps_trained_throughput_per_sec": 75.37229772036395, "timesteps_total": 88000, "num_env_steps_sampled_lifetime": 88000, "num_agent_steps_sampled_lifetime": 352000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 352000, "timers": {"training_iteration_time_ms": 51634.886, "restore_workers_time_ms": 0.018, "training_step_time_ms": 51634.813, "sample_time_ms": 2634.665, "learn_time_ms": 48980.797, "learn_throughput": 81.665, "synch_weights_time_ms": 14.492}, "counters": {"num_env_steps_sampled": 88000, "num_env_steps_trained": 88000, "num_agent_steps_sampled": 352000, "num_agent_steps_trained": 352000}, "done": false, "training_iteration": 22, "trial_id": "798d9_00000", "date": "2024-08-22_09-56-05", "timestamp": 1724300765, "time_this_iter_s": 53.10523819923401, "time_total_s": 1120.2699151039124, "pid": 48427, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"prey_count": 2, "prey_speed": 1.0, "prey_view_size": 10, "prey_size": 1, "prey_color": [0, 255, 0], "prey_kill_reward": -10, "prey_alive_reward": 0.1, "prey_reward_sqr_reward": 1, "predator_count": 2, "predator_speed": 1.0, "predator_view_size": 10, "predator_size": 1, "predator_color": [255, 0, 0], "predator_kill_reward": 10, "map_size": 40, "max_steps": 400, "screen_size": 600, "render_mode": "None", "fps": 60}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 8, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": true, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 1, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "custom_cnn", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x16cfcb1f0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1120.2699151039124, "iterations_since_restore": 22, "perf": {"cpu_util_percent": 49.14, "ram_util_percent": 82.46133333333333}}
