{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.4130744865095175, "cur_kl_coeff": 0.2, "cur_lr": 0.0014144343523880775, "total_loss": 7.888908544419304, "policy_loss": 0.0006843504606790485, "vf_loss": 7.885825661250523, "vf_explained_var": 0.025288849627530134, "kl": 0.01199273438020448, "entropy": 1.597693837382806, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 945.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8265619947540539, "cur_kl_coeff": 0.2, "cur_lr": 0.0014144343523880775, "total_loss": 3.8313661886901453, "policy_loss": -0.007562236959563085, "vf_loss": 3.8368973937614883, "vf_explained_var": 0.003952866540384041, "kl": 0.010155209742796337, "entropy": 1.5992436076598193, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 945.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 4000, "num_env_steps_trained": 4000, "num_agent_steps_sampled": 16000, "num_agent_steps_trained": 16000}, "env_runners": {"episode_reward_max": 301.8000000000003, "episode_reward_min": -119.20000000000073, "episode_reward_mean": 68.71666666666647, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 3600, "policy_reward_min": {"prey_policy": -313.9000000000001, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 162.0}, "policy_reward_mean": {"prey_policy": 5.302777777777759, "predator_policy": 29.055555555555557}, "custom_metrics": {}, "hist_stats": {"episode_reward": [32.30000000000018, 301.8000000000003, -16.79999999999997, 177.6999999999995, 54.80000000000032, 38.9000000000003, 107.89999999999898, -55.49999999999991, 124.80000000000004, 119.39999999999907, 57.499999999999375, -37.999999999999936, -61.79999999999982, 9.900000000000157, 231.7999999999995, -119.20000000000073, 79.60000000000002, 191.7999999999994], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [5.299999999999978, 20.000000000000014, 200.0, 75.79999999999993, 130.1, -313.9000000000001, 168.5, -17.79999999999974, -3.7000000000000157, 42.500000000000156, 17.899999999999977, 20.000000000000014, 4.700000000000029, 75.1999999999997, 12.200000000000237, -171.70000000000059, 47.89999999999997, 35.900000000000006, 64.3999999999998, 20.000000000000014, -33.699999999999946, 24.199999999999946, 20.000000000000014, -133.00000000000017, -175.60000000000053, -35.19999999999988, -123.10000000000002, 29.000000000000064, 88.99999999999999, 129.79999999999956, -309.2999999999993, 28.1, 57.79999999999999, 21.80000000000004, -26.199999999999775, 194.0], "policy_predator_policy_reward": [0.0, 7.0, 24.0, 2.0, 8.0, 159.0, 27.0, 0.0, 16.0, 0.0, 0.0, 1.0, 0.0, 28.0, 104.0, 0.0, 40.0, 1.0, 15.0, 20.0, 0.0, 67.0, 71.0, 4.0, 86.0, 63.0, 72.0, 32.0, 8.0, 5.0, 162.0, 0.0, 0.0, 0.0, 24.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6348646293817777, "mean_inference_ms": 1.7020403405506745, "mean_action_processing_ms": 0.288117836013997, "mean_env_wait_ms": 0.24829300029886595, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005902184380425347, "StateBufferConnector_ms": 0.003240505854288737, "ViewRequirementAgentConnector_ms": 0.09414288732740614}, "num_episodes": 18, "episode_return_max": 301.8000000000003, "episode_return_min": -119.20000000000073, "episode_return_mean": 68.71666666666647, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 16000, "num_agent_steps_trained": 16000, "num_env_steps_sampled": 4000, "num_env_steps_trained": 4000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 360.29525662594244, "num_env_steps_trained_throughput_per_sec": 360.29525662594244, "timesteps_total": 4000, "num_env_steps_sampled_lifetime": 4000, "num_agent_steps_sampled_lifetime": 16000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 16000, "timers": {"training_iteration_time_ms": 11102.014, "restore_workers_time_ms": 0.02, "training_step_time_ms": 11101.955, "sample_time_ms": 1349.305, "learn_time_ms": 9731.403, "learn_throughput": 411.04, "synch_weights_time_ms": 17.429}, "counters": {"num_env_steps_sampled": 4000, "num_env_steps_trained": 4000, "num_agent_steps_sampled": 16000, "num_agent_steps_trained": 16000}, "done": false, "training_iteration": 1, "trial_id": "7f9b9_00000", "date": "2024-08-13_10-30-11", "timestamp": 1723559411, "time_this_iter_s": 11.176142930984497, "time_total_s": 11.176142930984497, "pid": 45656, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001414434352388078, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x31fceb700>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 11.176142930984497, "iterations_since_restore": 1, "perf": {"cpu_util_percent": 43.5625, "ram_util_percent": 83.70625}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.882413651120095, "cur_kl_coeff": 0.2, "cur_lr": 0.0014144343523880775, "total_loss": 6.352503544439084, "policy_loss": 0.0014440605010364264, "vf_loss": 6.348404081788643, "vf_explained_var": 0.03636770166417278, "kl": 0.01327707248075955, "entropy": 1.5917197803971628, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 2835.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.617787825588196, "cur_kl_coeff": 0.2, "cur_lr": 0.0014144343523880775, "total_loss": 3.6626502356201254, "policy_loss": -0.005721906622842191, "vf_loss": 3.6664097209456106, "vf_explained_var": -0.0029463112985015547, "kl": 0.009812150121636934, "entropy": 1.5949966922638907, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 2835.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 8000, "num_env_steps_trained": 8000, "num_agent_steps_sampled": 32000, "num_agent_steps_trained": 32000}, "env_runners": {"episode_reward_max": 301.8000000000003, "episode_reward_min": -119.20000000000073, "episode_reward_mean": 56.67777777777766, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 7200, "policy_reward_min": {"prey_policy": -313.9000000000001, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 162.0}, "policy_reward_mean": {"prey_policy": 1.5472222222222014, "predator_policy": 26.791666666666668}, "custom_metrics": {}, "hist_stats": {"episode_reward": [32.30000000000018, 301.8000000000003, -16.79999999999997, 177.6999999999995, 54.80000000000032, 38.9000000000003, 107.89999999999898, -55.49999999999991, 124.80000000000004, 119.39999999999907, 57.499999999999375, -37.999999999999936, -61.79999999999982, 9.900000000000157, 231.7999999999995, -119.20000000000073, 79.60000000000002, 191.7999999999994, -50.099999999999945, 160.59999999999906, 169.69999999999982, -0.39999999999987323, 71.99999999999964, -90.30000000000021, 43.50000000000021, 63.400000000000375, -51.2999999999997, 14.80000000000038, 63.00000000000017, 30.60000000000014, 28.400000000000254, 151.89999999999924, 44.50000000000038, 100.09999999999906, 75.40000000000003, -22.299999999999827], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [5.299999999999978, 20.000000000000014, 200.0, 75.79999999999993, 130.1, -313.9000000000001, 168.5, -17.79999999999974, -3.7000000000000157, 42.500000000000156, 17.899999999999977, 20.000000000000014, 4.700000000000029, 75.1999999999997, 12.200000000000237, -171.70000000000059, 47.89999999999997, 35.900000000000006, 64.3999999999998, 20.000000000000014, -33.699999999999946, 24.199999999999946, 20.000000000000014, -133.00000000000017, -175.60000000000053, -35.19999999999988, -123.10000000000002, 29.000000000000064, 88.99999999999999, 129.79999999999956, -309.2999999999993, 28.1, 57.79999999999999, 21.80000000000004, -26.199999999999775, 194.0, -198.40000000000015, 44.300000000000075, 140.5999999999997, 20.000000000000014, 140.0, -19.30000000000003, -45.099999999999795, -37.29999999999993, 31.1000000000001, 20.900000000000013, -37.5999999999999, -183.70000000000047, 57.2000000000001, -69.70000000000064, 43.40000000000018, 20.000000000000014, -122.80000000000055, -11.500000000000039, -45.69999999999995, 24.500000000000096, 36.20000000000007, -11.199999999999962, -98.50000000000026, 55.10000000000012, -11.500000000000016, 17.900000000000013, 144.1999999999997, -22.300000000000026, 24.500000000000092, 20.000000000000014, 26.300000000000114, 45.80000000000011, 34.39999999999998, 20.000000000000014, -38.19999999999985, -93.1], "policy_predator_policy_reward": [0.0, 7.0, 24.0, 2.0, 8.0, 159.0, 27.0, 0.0, 16.0, 0.0, 0.0, 1.0, 0.0, 28.0, 104.0, 0.0, 40.0, 1.0, 15.0, 20.0, 0.0, 67.0, 71.0, 4.0, 86.0, 63.0, 72.0, 32.0, 8.0, 5.0, 162.0, 0.0, 0.0, 0.0, 24.0, 0.0, 0.0, 104.0, 0.0, 0.0, 43.0, 6.0, 2.0, 80.0, 0.0, 20.0, 31.0, 100.0, 56.0, 0.0, 0.0, 0.0, 83.0, 0.0, 20.0, 16.0, 0.0, 38.0, 74.0, 0.0, 22.0, 0.0, 27.0, 3.0, 0.0, 0.0, 0.0, 28.0, 0.0, 21.0, 71.0, 38.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6102406728264849, "mean_inference_ms": 1.6154625840613928, "mean_action_processing_ms": 0.2703323480939721, "mean_env_wait_ms": 0.23299513332312494, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005746881167093913, "StateBufferConnector_ms": 0.0030746062596639, "ViewRequirementAgentConnector_ms": 0.09027885066138373}, "num_episodes": 18, "episode_return_max": 301.8000000000003, "episode_return_min": -119.20000000000073, "episode_return_mean": 56.67777777777766, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 32000, "num_agent_steps_trained": 32000, "num_env_steps_sampled": 8000, "num_env_steps_trained": 8000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 423.7888457898041, "num_env_steps_trained_throughput_per_sec": 423.7888457898041, "timesteps_total": 8000, "num_env_steps_sampled_lifetime": 8000, "num_agent_steps_sampled_lifetime": 32000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 32000, "timers": {"training_iteration_time_ms": 10270.342, "restore_workers_time_ms": 0.033, "training_step_time_ms": 10270.275, "sample_time_ms": 1242.673, "learn_time_ms": 9010.474, "learn_throughput": 443.928, "synch_weights_time_ms": 14.688}, "counters": {"num_env_steps_sampled": 8000, "num_env_steps_trained": 8000, "num_agent_steps_sampled": 32000, "num_agent_steps_trained": 32000}, "done": false, "training_iteration": 2, "trial_id": "7f9b9_00000", "date": "2024-08-13_10-30-23", "timestamp": 1723559423, "time_this_iter_s": 9.446018934249878, "time_total_s": 20.622161865234375, "pid": 45656, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001414434352388078, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x31fe9ee50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 20.622161865234375, "iterations_since_restore": 2, "perf": {"cpu_util_percent": 30.605555555555554, "ram_util_percent": 83.63888888888889}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.3439649438258834, "cur_kl_coeff": 0.2, "cur_lr": 0.0014144343523880775, "total_loss": 7.015483766888815, "policy_loss": -0.00301114777940764, "vf_loss": 7.015722427923213, "vf_explained_var": 0.03342191346738704, "kl": 0.013862355695084563, "entropy": 1.5882529953800182, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 4725.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5445746760086092, "cur_kl_coeff": 0.2, "cur_lr": 0.0014144343523880775, "total_loss": 4.426725571622294, "policy_loss": -0.008878329903054883, "vf_loss": 4.432985167023997, "vf_explained_var": 0.0006241096075249728, "kl": 0.013093705243924274, "entropy": 1.5710751771296143, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 4725.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 12000, "num_env_steps_trained": 12000, "num_agent_steps_sampled": 48000, "num_agent_steps_trained": 48000}, "env_runners": {"episode_reward_max": 301.8000000000003, "episode_reward_min": -122.30000000000013, "episode_reward_mean": 55.69629629629616, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 10800, "policy_reward_min": {"prey_policy": -313.9000000000001, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 162.0}, "policy_reward_mean": {"prey_policy": -0.9018518518518788, "predator_policy": 28.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [32.30000000000018, 301.8000000000003, -16.79999999999997, 177.6999999999995, 54.80000000000032, 38.9000000000003, 107.89999999999898, -55.49999999999991, 124.80000000000004, 119.39999999999907, 57.499999999999375, -37.999999999999936, -61.79999999999982, 9.900000000000157, 231.7999999999995, -119.20000000000073, 79.60000000000002, 191.7999999999994, -50.099999999999945, 160.59999999999906, 169.69999999999982, -0.39999999999987323, 71.99999999999964, -90.30000000000021, 43.50000000000021, 63.400000000000375, -51.2999999999997, 14.80000000000038, 63.00000000000017, 30.60000000000014, 28.400000000000254, 151.89999999999924, 44.50000000000038, 100.09999999999906, 75.40000000000003, -22.299999999999827, -28.699999999999733, 2.699999999999938, 201.2999999999992, -63.39999999999992, 26.000000000000284, 52.80000000000047, 167.3999999999993, 144.1000000000001, -58.699999999999655, 55.300000000000246, 74.29999999999994, 151.19999999999905, 83.79999999999893, 131.7999999999994, 105.69999999999996, -5.300000000000169, 49.2, -122.30000000000013], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [5.299999999999978, 20.000000000000014, 200.0, 75.79999999999993, 130.1, -313.9000000000001, 168.5, -17.79999999999974, -3.7000000000000157, 42.500000000000156, 17.899999999999977, 20.000000000000014, 4.700000000000029, 75.1999999999997, 12.200000000000237, -171.70000000000059, 47.89999999999997, 35.900000000000006, 64.3999999999998, 20.000000000000014, -33.699999999999946, 24.199999999999946, 20.000000000000014, -133.00000000000017, -175.60000000000053, -35.19999999999988, -123.10000000000002, 29.000000000000064, 88.99999999999999, 129.79999999999956, -309.2999999999993, 28.1, 57.79999999999999, 21.80000000000004, -26.199999999999775, 194.0, -198.40000000000015, 44.300000000000075, 140.5999999999997, 20.000000000000014, 140.0, -19.30000000000003, -45.099999999999795, -37.29999999999993, 31.1000000000001, 20.900000000000013, -37.5999999999999, -183.70000000000047, 57.2000000000001, -69.70000000000064, 43.40000000000018, 20.000000000000014, -122.80000000000055, -11.500000000000039, -45.69999999999995, 24.500000000000096, 36.20000000000007, -11.199999999999962, -98.50000000000026, 55.10000000000012, -11.500000000000016, 17.900000000000013, 144.1999999999997, -22.300000000000026, 24.500000000000092, 20.000000000000014, 26.300000000000114, 45.80000000000011, 34.39999999999998, 20.000000000000014, -38.19999999999985, -93.1, -97.60000000000011, -27.099999999999945, 11.899999999999975, -47.19999999999997, 175.69999999999993, -9.399999999999835, -177.40000000000003, 20.000000000000014, 50.299999999999976, -85.30000000000004, 24.800000000000097, 20.000000000000014, 160.99999999999977, -76.6000000000005, 66.79999999999998, 26.300000000000004, -82.9, -86.80000000000064, -0.6999999999999393, 20.000000000000014, 10.700000000000001, -30.399999999999878, 132.49999999999972, -19.299999999999834, 8.299999999999962, 60.499999999999936, 86.6, 27.200000000000138, 23.60000000000008, 82.09999999999998, 15.800000000000008, -108.09999999999995, 61.69999999999994, -191.5, -179.50000000000028, -74.80000000000004], "policy_predator_policy_reward": [0.0, 7.0, 24.0, 2.0, 8.0, 159.0, 27.0, 0.0, 16.0, 0.0, 0.0, 1.0, 0.0, 28.0, 104.0, 0.0, 40.0, 1.0, 15.0, 20.0, 0.0, 67.0, 71.0, 4.0, 86.0, 63.0, 72.0, 32.0, 8.0, 5.0, 162.0, 0.0, 0.0, 0.0, 24.0, 0.0, 0.0, 104.0, 0.0, 0.0, 43.0, 6.0, 2.0, 80.0, 0.0, 20.0, 31.0, 100.0, 56.0, 0.0, 0.0, 0.0, 83.0, 0.0, 20.0, 16.0, 0.0, 38.0, 74.0, 0.0, 22.0, 0.0, 27.0, 3.0, 0.0, 0.0, 0.0, 28.0, 0.0, 21.0, 71.0, 38.0, 22.0, 74.0, 32.0, 6.0, 35.0, 0.0, 0.0, 94.0, 4.0, 57.0, 8.0, 0.0, 43.0, 40.0, 1.0, 50.0, 34.0, 77.0, 36.0, 0.0, 42.0, 52.0, 0.0, 38.0, 9.0, 6.0, 18.0, 0.0, 0.0, 0.0, 85.0, 2.0, 114.0, 65.0, 0.0, 132.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5925746760714827, "mean_inference_ms": 1.5572457987596318, "mean_action_processing_ms": 0.2594160334885774, "mean_env_wait_ms": 0.22336722928641942, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005965983426129377, "StateBufferConnector_ms": 0.003011800624706127, "ViewRequirementAgentConnector_ms": 0.08938047620985243}, "num_episodes": 18, "episode_return_max": 301.8000000000003, "episode_return_min": -122.30000000000013, "episode_return_mean": 55.69629629629616, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 48000, "num_agent_steps_trained": 48000, "num_env_steps_sampled": 12000, "num_env_steps_trained": 12000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 424.32340042734785, "num_env_steps_trained_throughput_per_sec": 424.32340042734785, "timesteps_total": 12000, "num_env_steps_sampled_lifetime": 12000, "num_agent_steps_sampled_lifetime": 48000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 48000, "timers": {"training_iteration_time_ms": 9989.156, "restore_workers_time_ms": 0.026, "training_step_time_ms": 9989.097, "sample_time_ms": 1174.224, "learn_time_ms": 8799.499, "learn_throughput": 454.571, "synch_weights_time_ms": 13.436}, "counters": {"num_env_steps_sampled": 12000, "num_env_steps_trained": 12000, "num_agent_steps_sampled": 48000, "num_agent_steps_trained": 48000}, "done": false, "training_iteration": 3, "trial_id": "7f9b9_00000", "date": "2024-08-13_10-30-32", "timestamp": 1723559432, "time_this_iter_s": 9.430917739868164, "time_total_s": 30.05307960510254, "pid": 45656, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001414434352388078, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x31fe9e5e0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 30.05307960510254, "iterations_since_restore": 3, "perf": {"cpu_util_percent": 28.700000000000003, "ram_util_percent": 83.52307692307694}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.3869912519026055, "cur_kl_coeff": 0.2, "cur_lr": 0.0014144343523880775, "total_loss": 7.233671865261421, "policy_loss": -0.0007705540832368627, "vf_loss": 7.231736167524227, "vf_explained_var": 0.04348203073102961, "kl": 0.013531275008345922, "entropy": 1.5711056848051688, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 6615.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7036086462043896, "cur_kl_coeff": 0.2, "cur_lr": 0.0014144343523880775, "total_loss": 4.0980042746458105, "policy_loss": -0.007834039991672235, "vf_loss": 4.103777285353847, "vf_explained_var": 0.014701845563908734, "kl": 0.010305107083707025, "entropy": 1.5752253927251019, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 6615.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 16000, "num_env_steps_trained": 16000, "num_agent_steps_sampled": 64000, "num_agent_steps_trained": 64000}, "env_runners": {"episode_reward_max": 301.8000000000003, "episode_reward_min": -262.59999999999866, "episode_reward_mean": 45.4708333333332, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 14400, "policy_reward_min": {"prey_policy": -381.5999999999998, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 207.0}, "policy_reward_mean": {"prey_policy": -10.834027777777813, "predator_policy": 33.56944444444444}, "custom_metrics": {}, "hist_stats": {"episode_reward": [32.30000000000018, 301.8000000000003, -16.79999999999997, 177.6999999999995, 54.80000000000032, 38.9000000000003, 107.89999999999898, -55.49999999999991, 124.80000000000004, 119.39999999999907, 57.499999999999375, -37.999999999999936, -61.79999999999982, 9.900000000000157, 231.7999999999995, -119.20000000000073, 79.60000000000002, 191.7999999999994, -50.099999999999945, 160.59999999999906, 169.69999999999982, -0.39999999999987323, 71.99999999999964, -90.30000000000021, 43.50000000000021, 63.400000000000375, -51.2999999999997, 14.80000000000038, 63.00000000000017, 30.60000000000014, 28.400000000000254, 151.89999999999924, 44.50000000000038, 100.09999999999906, 75.40000000000003, -22.299999999999827, -28.699999999999733, 2.699999999999938, 201.2999999999992, -63.39999999999992, 26.000000000000284, 52.80000000000047, 167.3999999999993, 144.1000000000001, -58.699999999999655, 55.300000000000246, 74.29999999999994, 151.19999999999905, 83.79999999999893, 131.7999999999994, 105.69999999999996, -5.300000000000169, 49.2, -122.30000000000013, 72.19999999999978, 21.900000000000023, -131.00000000000023, 15.599999999999966, 91.29999999999939, 74.79999999999993, 8.899999999999956, 109.99999999999983, 184.7999999999991, 54.700000000000266, -262.59999999999866, 81.9999999999992, -183.20000000000027, -22.9, 182.7999999999994, 3.0000000000002007, -110.10000000000034, 74.09999999999997], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [5.299999999999978, 20.000000000000014, 200.0, 75.79999999999993, 130.1, -313.9000000000001, 168.5, -17.79999999999974, -3.7000000000000157, 42.500000000000156, 17.899999999999977, 20.000000000000014, 4.700000000000029, 75.1999999999997, 12.200000000000237, -171.70000000000059, 47.89999999999997, 35.900000000000006, 64.3999999999998, 20.000000000000014, -33.699999999999946, 24.199999999999946, 20.000000000000014, -133.00000000000017, -175.60000000000053, -35.19999999999988, -123.10000000000002, 29.000000000000064, 88.99999999999999, 129.79999999999956, -309.2999999999993, 28.1, 57.79999999999999, 21.80000000000004, -26.199999999999775, 194.0, -198.40000000000015, 44.300000000000075, 140.5999999999997, 20.000000000000014, 140.0, -19.30000000000003, -45.099999999999795, -37.29999999999993, 31.1000000000001, 20.900000000000013, -37.5999999999999, -183.70000000000047, 57.2000000000001, -69.70000000000064, 43.40000000000018, 20.000000000000014, -122.80000000000055, -11.500000000000039, -45.69999999999995, 24.500000000000096, 36.20000000000007, -11.199999999999962, -98.50000000000026, 55.10000000000012, -11.500000000000016, 17.900000000000013, 144.1999999999997, -22.300000000000026, 24.500000000000092, 20.000000000000014, 26.300000000000114, 45.80000000000011, 34.39999999999998, 20.000000000000014, -38.19999999999985, -93.1, -97.60000000000011, -27.099999999999945, 11.899999999999975, -47.19999999999997, 175.69999999999993, -9.399999999999835, -177.40000000000003, 20.000000000000014, 50.299999999999976, -85.30000000000004, 24.800000000000097, 20.000000000000014, 160.99999999999977, -76.6000000000005, 66.79999999999998, 26.300000000000004, -82.9, -86.80000000000064, -0.6999999999999393, 20.000000000000014, 10.700000000000001, -30.399999999999878, 132.49999999999972, -19.299999999999834, 8.299999999999962, 60.499999999999936, 86.6, 27.200000000000138, 23.60000000000008, 82.09999999999998, 15.800000000000008, -108.09999999999995, 61.69999999999994, -191.5, -179.50000000000028, -74.80000000000004, 21.800000000000047, 22.40000000000008, 36.50000000000004, -136.60000000000025, -78.10000000000005, -205.90000000000018, 34.39999999999999, -104.79999999999995, -53.50000000000004, 72.80000000000001, 41.600000000000236, -35.80000000000002, -172.90000000000046, 75.79999999999934, -99.70000000000022, 151.7, 1.399999999999969, 160.3999999999999, 22.700000000000053, -6.999999999999936, -175.30000000000032, -217.30000000000035, -11.799999999999867, 60.80000000000014, -127.30000000000018, -223.90000000000012, -120.70000000000007, -2.199999999999996, 46.10000000000005, 112.69999999999993, -103.90000000000025, 38.90000000000021, -381.5999999999998, 9.500000000000048, 112.1, -226.0000000000001], "policy_predator_policy_reward": [0.0, 7.0, 24.0, 2.0, 8.0, 159.0, 27.0, 0.0, 16.0, 0.0, 0.0, 1.0, 0.0, 28.0, 104.0, 0.0, 40.0, 1.0, 15.0, 20.0, 0.0, 67.0, 71.0, 4.0, 86.0, 63.0, 72.0, 32.0, 8.0, 5.0, 162.0, 0.0, 0.0, 0.0, 24.0, 0.0, 0.0, 104.0, 0.0, 0.0, 43.0, 6.0, 2.0, 80.0, 0.0, 20.0, 31.0, 100.0, 56.0, 0.0, 0.0, 0.0, 83.0, 0.0, 20.0, 16.0, 0.0, 38.0, 74.0, 0.0, 22.0, 0.0, 27.0, 3.0, 0.0, 0.0, 0.0, 28.0, 0.0, 21.0, 71.0, 38.0, 22.0, 74.0, 32.0, 6.0, 35.0, 0.0, 0.0, 94.0, 4.0, 57.0, 8.0, 0.0, 43.0, 40.0, 1.0, 50.0, 34.0, 77.0, 36.0, 0.0, 42.0, 52.0, 0.0, 38.0, 9.0, 6.0, 18.0, 0.0, 0.0, 0.0, 85.0, 2.0, 114.0, 65.0, 0.0, 132.0, 0.0, 28.0, 8.0, 114.0, 126.0, 27.0, 3.0, 83.0, 35.0, 37.0, 69.0, 0.0, 16.0, 90.0, 53.0, 5.0, 23.0, 0.0, 3.0, 36.0, 0.0, 130.0, 0.0, 33.0, 98.0, 70.0, 0.0, 100.0, 0.0, 24.0, 68.0, 0.0, 55.0, 207.0, 54.0, 134.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5822238448314967, "mean_inference_ms": 1.5192651368473067, "mean_action_processing_ms": 0.2531201303406639, "mean_env_wait_ms": 0.2163468953327207, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005977352460225423, "StateBufferConnector_ms": 0.0029956301053365073, "ViewRequirementAgentConnector_ms": 0.09248107671737671}, "num_episodes": 18, "episode_return_max": 301.8000000000003, "episode_return_min": -262.59999999999866, "episode_return_mean": 45.4708333333332, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 64000, "num_agent_steps_trained": 64000, "num_env_steps_sampled": 16000, "num_env_steps_trained": 16000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 407.2817158814859, "num_env_steps_trained_throughput_per_sec": 407.2817158814859, "timesteps_total": 16000, "num_env_steps_sampled_lifetime": 16000, "num_agent_steps_sampled_lifetime": 64000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 64000, "timers": {"training_iteration_time_ms": 9947.172, "restore_workers_time_ms": 0.023, "training_step_time_ms": 9947.118, "sample_time_ms": 1151.034, "learn_time_ms": 8780.097, "learn_throughput": 455.576, "synch_weights_time_ms": 13.545}, "counters": {"num_env_steps_sampled": 16000, "num_env_steps_trained": 16000, "num_agent_steps_sampled": 64000, "num_agent_steps_trained": 64000}, "done": false, "training_iteration": 4, "trial_id": "7f9b9_00000", "date": "2024-08-13_10-30-42", "timestamp": 1723559442, "time_this_iter_s": 9.862181901931763, "time_total_s": 39.9152615070343, "pid": 45656, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001414434352388078, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x31fec88b0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 39.9152615070343, "iterations_since_restore": 4, "perf": {"cpu_util_percent": 30.707142857142856, "ram_util_percent": 83.14285714285714}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.417513684368638, "cur_kl_coeff": 0.2, "cur_lr": 0.0014144343523880775, "total_loss": 6.269809836180753, "policy_loss": -0.004337431576223699, "vf_loss": 6.2709785388260295, "vf_explained_var": 0.038559643490604624, "kl": 0.015843692700282352, "entropy": 1.5648800782425694, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 8505.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5725987137783142, "cur_kl_coeff": 0.2, "cur_lr": 0.0014144343523880775, "total_loss": 1.8762123501490033, "policy_loss": -0.006718393151953856, "vf_loss": 1.8804983273385063, "vf_explained_var": 0.017190269597623715, "kl": 0.012162085378761104, "entropy": 1.53885201095904, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 8505.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 20000, "num_env_steps_trained": 20000, "num_agent_steps_sampled": 80000, "num_agent_steps_trained": 80000}, "env_runners": {"episode_reward_max": 373.9, "episode_reward_min": -262.59999999999866, "episode_reward_mean": 56.83434343434329, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 19800, "policy_reward_min": {"prey_policy": -381.5999999999998, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 207.0}, "policy_reward_mean": {"prey_policy": -2.835353535353568, "predator_policy": 31.252525252525253}, "custom_metrics": {}, "hist_stats": {"episode_reward": [32.30000000000018, 301.8000000000003, -16.79999999999997, 177.6999999999995, 54.80000000000032, 38.9000000000003, 107.89999999999898, -55.49999999999991, 124.80000000000004, 119.39999999999907, 57.499999999999375, -37.999999999999936, -61.79999999999982, 9.900000000000157, 231.7999999999995, -119.20000000000073, 79.60000000000002, 191.7999999999994, -50.099999999999945, 160.59999999999906, 169.69999999999982, -0.39999999999987323, 71.99999999999964, -90.30000000000021, 43.50000000000021, 63.400000000000375, -51.2999999999997, 14.80000000000038, 63.00000000000017, 30.60000000000014, 28.400000000000254, 151.89999999999924, 44.50000000000038, 100.09999999999906, 75.40000000000003, -22.299999999999827, -28.699999999999733, 2.699999999999938, 201.2999999999992, -63.39999999999992, 26.000000000000284, 52.80000000000047, 167.3999999999993, 144.1000000000001, -58.699999999999655, 55.300000000000246, 74.29999999999994, 151.19999999999905, 83.79999999999893, 131.7999999999994, 105.69999999999996, -5.300000000000169, 49.2, -122.30000000000013, 72.19999999999978, 21.900000000000023, -131.00000000000023, 15.599999999999966, 91.29999999999939, 74.79999999999993, 8.899999999999956, 109.99999999999983, 184.7999999999991, 54.700000000000266, -262.59999999999866, 81.9999999999992, -183.20000000000027, -22.9, 182.7999999999994, 3.0000000000002007, -110.10000000000034, 74.09999999999997, -28.30000000000006, -89.30000000000044, 48.50000000000034, 42.700000000000294, 146.29999999999964, 36.900000000000176, 276.70000000000016, 60.70000000000014, -128.80000000000007, 68.70000000000007, 82.39999999999986, 59.800000000000345, 239.5999999999994, 242.4999999999994, -15.300000000000008, 44.10000000000002, 130.8999999999998, 94.19999999999915, -0.2999999999998928, 94.89999999999839, 36.700000000000294, 128.29999999999998, 225.99999999999952, 97.50000000000007, -6.1999999999996565, 89.5999999999994, 373.9], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [5.299999999999978, 20.000000000000014, 200.0, 75.79999999999993, 130.1, -313.9000000000001, 168.5, -17.79999999999974, -3.7000000000000157, 42.500000000000156, 17.899999999999977, 20.000000000000014, 4.700000000000029, 75.1999999999997, 12.200000000000237, -171.70000000000059, 47.89999999999997, 35.900000000000006, 64.3999999999998, 20.000000000000014, -33.699999999999946, 24.199999999999946, 20.000000000000014, -133.00000000000017, -175.60000000000053, -35.19999999999988, -123.10000000000002, 29.000000000000064, 88.99999999999999, 129.79999999999956, -309.2999999999993, 28.1, 57.79999999999999, 21.80000000000004, -26.199999999999775, 194.0, -198.40000000000015, 44.300000000000075, 140.5999999999997, 20.000000000000014, 140.0, -19.30000000000003, -45.099999999999795, -37.29999999999993, 31.1000000000001, 20.900000000000013, -37.5999999999999, -183.70000000000047, 57.2000000000001, -69.70000000000064, 43.40000000000018, 20.000000000000014, -122.80000000000055, -11.500000000000039, -45.69999999999995, 24.500000000000096, 36.20000000000007, -11.199999999999962, -98.50000000000026, 55.10000000000012, -11.500000000000016, 17.900000000000013, 144.1999999999997, -22.300000000000026, 24.500000000000092, 20.000000000000014, 26.300000000000114, 45.80000000000011, 34.39999999999998, 20.000000000000014, -38.19999999999985, -93.1, -97.60000000000011, -27.099999999999945, 11.899999999999975, -47.19999999999997, 175.69999999999993, -9.399999999999835, -177.40000000000003, 20.000000000000014, 50.299999999999976, -85.30000000000004, 24.800000000000097, 20.000000000000014, 160.99999999999977, -76.6000000000005, 66.79999999999998, 26.300000000000004, -82.9, -86.80000000000064, -0.6999999999999393, 20.000000000000014, 10.700000000000001, -30.399999999999878, 132.49999999999972, -19.299999999999834, 8.299999999999962, 60.499999999999936, 86.6, 27.200000000000138, 23.60000000000008, 82.09999999999998, 15.800000000000008, -108.09999999999995, 61.69999999999994, -191.5, -179.50000000000028, -74.80000000000004, 21.800000000000047, 22.40000000000008, 36.50000000000004, -136.60000000000025, -78.10000000000005, -205.90000000000018, 34.39999999999999, -104.79999999999995, -53.50000000000004, 72.80000000000001, 41.600000000000236, -35.80000000000002, -172.90000000000046, 75.79999999999934, -99.70000000000022, 151.7, 1.399999999999969, 160.3999999999999, 22.700000000000053, -6.999999999999936, -175.30000000000032, -217.30000000000035, -11.799999999999867, 60.80000000000014, -127.30000000000018, -223.90000000000012, -120.70000000000007, -2.199999999999996, 46.10000000000005, 112.69999999999993, -103.90000000000025, 38.90000000000021, -381.5999999999998, 9.500000000000048, 112.1, -226.0000000000001, -46.60000000000004, -66.70000000000002, -71.19999999999999, -153.10000000000025, -19.899999999999856, 25.400000000000105, 22.70000000000001, 20.000000000000014, 69.19999999999982, -4.9000000000000785, 24.50000000000009, -61.60000000000022, 78.4999999999995, 198.2, 20.000000000000014, 4.699999999999992, -154.30000000000004, -128.50000000000009, -43.89999999999977, 62.600000000000044, 25.100000000000076, 44.300000000000246, 39.80000000000016, 20.000000000000014, 162.79999999999978, 75.79999999999997, 159.49999999999974, 82.99999999999984, -5.2000000000000295, -192.10000000000022, 22.1000000000001, -42.99999999999999, 25.400000000000006, 105.49999999999997, 45.50000000000015, 4.699999999999999, -204.70000000000047, 97.39999999999955, 42.50000000000021, 52.400000000000226, 13.699999999999946, 20.000000000000014, -128.8000000000001, 142.1, 59.60000000000011, 151.39999999999995, 43.100000000000136, -4.599999999999975, -63.100000000000094, -30.099999999999774, 20.000000000000014, 65.6, 182.0, 191.9], "policy_predator_policy_reward": [0.0, 7.0, 24.0, 2.0, 8.0, 159.0, 27.0, 0.0, 16.0, 0.0, 0.0, 1.0, 0.0, 28.0, 104.0, 0.0, 40.0, 1.0, 15.0, 20.0, 0.0, 67.0, 71.0, 4.0, 86.0, 63.0, 72.0, 32.0, 8.0, 5.0, 162.0, 0.0, 0.0, 0.0, 24.0, 0.0, 0.0, 104.0, 0.0, 0.0, 43.0, 6.0, 2.0, 80.0, 0.0, 20.0, 31.0, 100.0, 56.0, 0.0, 0.0, 0.0, 83.0, 0.0, 20.0, 16.0, 0.0, 38.0, 74.0, 0.0, 22.0, 0.0, 27.0, 3.0, 0.0, 0.0, 0.0, 28.0, 0.0, 21.0, 71.0, 38.0, 22.0, 74.0, 32.0, 6.0, 35.0, 0.0, 0.0, 94.0, 4.0, 57.0, 8.0, 0.0, 43.0, 40.0, 1.0, 50.0, 34.0, 77.0, 36.0, 0.0, 42.0, 52.0, 0.0, 38.0, 9.0, 6.0, 18.0, 0.0, 0.0, 0.0, 85.0, 2.0, 114.0, 65.0, 0.0, 132.0, 0.0, 28.0, 8.0, 114.0, 126.0, 27.0, 3.0, 83.0, 35.0, 37.0, 69.0, 0.0, 16.0, 90.0, 53.0, 5.0, 23.0, 0.0, 3.0, 36.0, 0.0, 130.0, 0.0, 33.0, 98.0, 70.0, 0.0, 100.0, 0.0, 24.0, 68.0, 0.0, 55.0, 207.0, 54.0, 134.0, 4.0, 81.0, 135.0, 0.0, 0.0, 43.0, 0.0, 0.0, 51.0, 31.0, 9.0, 65.0, 0.0, 0.0, 36.0, 0.0, 154.0, 0.0, 36.0, 14.0, 13.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 99.0, 83.0, 35.0, 30.0, 0.0, 0.0, 30.0, 14.0, 0.0, 107.0, 0.0, 0.0, 0.0, 3.0, 24.0, 91.0, 0.0, 15.0, 45.0, 14.0, 58.0, 29.0, 0.0, 4.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5750991934370844, "mean_inference_ms": 1.4850649424178692, "mean_action_processing_ms": 0.24714435623853837, "mean_env_wait_ms": 0.21018922535091217, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006065224156235204, "StateBufferConnector_ms": 0.0030435696996823705, "ViewRequirementAgentConnector_ms": 0.09224077667852845}, "num_episodes": 27, "episode_return_max": 373.9, "episode_return_min": -262.59999999999866, "episode_return_mean": 56.83434343434329, "episodes_this_iter": 27}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 80000, "num_agent_steps_trained": 80000, "num_env_steps_sampled": 20000, "num_env_steps_trained": 20000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 423.64184476085995, "num_env_steps_trained_throughput_per_sec": 423.64184476085995, "timesteps_total": 20000, "num_env_steps_sampled_lifetime": 20000, "num_agent_steps_sampled_lifetime": 80000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 80000, "timers": {"training_iteration_time_ms": 9846.127, "restore_workers_time_ms": 0.021, "training_step_time_ms": 9846.076, "sample_time_ms": 1145.883, "learn_time_ms": 8685.007, "learn_throughput": 460.564, "synch_weights_time_ms": 13.073}, "counters": {"num_env_steps_sampled": 20000, "num_env_steps_trained": 20000, "num_agent_steps_sampled": 80000, "num_agent_steps_trained": 80000}, "done": false, "training_iteration": 5, "trial_id": "7f9b9_00000", "date": "2024-08-13_10-30-52", "timestamp": 1723559452, "time_this_iter_s": 9.4468994140625, "time_total_s": 49.3621609210968, "pid": 45656, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001414434352388078, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x31fe9ea60>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 49.3621609210968, "iterations_since_restore": 5, "perf": {"cpu_util_percent": 28.8, "ram_util_percent": 83.22857142857141}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.0747802511251794, "cur_kl_coeff": 0.2, "cur_lr": 0.0014144343523880775, "total_loss": 8.872732038851138, "policy_loss": -0.003402613981986645, "vf_loss": 8.872804606402362, "vf_explained_var": 0.025391279042713225, "kl": 0.016650167822289015, "entropy": 1.5487334783115083, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 10395.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.61728988190492, "cur_kl_coeff": 0.2, "cur_lr": 0.0014144343523880775, "total_loss": 4.779303161303202, "policy_loss": -0.011465324129584053, "vf_loss": 4.787950963948769, "vf_explained_var": 0.0065947390107250715, "kl": 0.014087658689499625, "entropy": 1.5336250816072736, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 10395.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 24000, "num_env_steps_trained": 24000, "num_agent_steps_sampled": 96000, "num_agent_steps_trained": 96000}, "env_runners": {"episode_reward_max": 373.9, "episode_reward_min": -262.59999999999866, "episode_reward_mean": 52.75499999999988, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -381.5999999999998, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 198.2, "predator_policy": 207.0}, "policy_reward_mean": {"prey_policy": -8.547500000000035, "predator_policy": 34.925}, "custom_metrics": {}, "hist_stats": {"episode_reward": [191.7999999999994, -50.099999999999945, 160.59999999999906, 169.69999999999982, -0.39999999999987323, 71.99999999999964, -90.30000000000021, 43.50000000000021, 63.400000000000375, -51.2999999999997, 14.80000000000038, 63.00000000000017, 30.60000000000014, 28.400000000000254, 151.89999999999924, 44.50000000000038, 100.09999999999906, 75.40000000000003, -22.299999999999827, -28.699999999999733, 2.699999999999938, 201.2999999999992, -63.39999999999992, 26.000000000000284, 52.80000000000047, 167.3999999999993, 144.1000000000001, -58.699999999999655, 55.300000000000246, 74.29999999999994, 151.19999999999905, 83.79999999999893, 131.7999999999994, 105.69999999999996, -5.300000000000169, 49.2, -122.30000000000013, 72.19999999999978, 21.900000000000023, -131.00000000000023, 15.599999999999966, 91.29999999999939, 74.79999999999993, 8.899999999999956, 109.99999999999983, 184.7999999999991, 54.700000000000266, -262.59999999999866, 81.9999999999992, -183.20000000000027, -22.9, 182.7999999999994, 3.0000000000002007, -110.10000000000034, 74.09999999999997, -28.30000000000006, -89.30000000000044, 48.50000000000034, 42.700000000000294, 146.29999999999964, 36.900000000000176, 276.70000000000016, 60.70000000000014, -128.80000000000007, 68.70000000000007, 82.39999999999986, 59.800000000000345, 239.5999999999994, 242.4999999999994, -15.300000000000008, 44.10000000000002, 130.8999999999998, 94.19999999999915, -0.2999999999998928, 94.89999999999839, 36.700000000000294, 128.29999999999998, 225.99999999999952, 97.50000000000007, -6.1999999999996565, 89.5999999999994, 373.9, 95.70000000000002, 44.10000000000027, 88.39999999999995, -212.5999999999999, 108.49999999999947, -174.20000000000064, 334.9999999999999, 10.899999999999892, 44.50000000000004, 77.49999999999994, 201.39999999999952, 242.29999999999967, 172.29999999999995, -4.099999999999914, 21.90000000000028, -245.10000000000014, 53.900000000000034, -166.40000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-26.199999999999775, 194.0, -198.40000000000015, 44.300000000000075, 140.5999999999997, 20.000000000000014, 140.0, -19.30000000000003, -45.099999999999795, -37.29999999999993, 31.1000000000001, 20.900000000000013, -37.5999999999999, -183.70000000000047, 57.2000000000001, -69.70000000000064, 43.40000000000018, 20.000000000000014, -122.80000000000055, -11.500000000000039, -45.69999999999995, 24.500000000000096, 36.20000000000007, -11.199999999999962, -98.50000000000026, 55.10000000000012, -11.500000000000016, 17.900000000000013, 144.1999999999997, -22.300000000000026, 24.500000000000092, 20.000000000000014, 26.300000000000114, 45.80000000000011, 34.39999999999998, 20.000000000000014, -38.19999999999985, -93.1, -97.60000000000011, -27.099999999999945, 11.899999999999975, -47.19999999999997, 175.69999999999993, -9.399999999999835, -177.40000000000003, 20.000000000000014, 50.299999999999976, -85.30000000000004, 24.800000000000097, 20.000000000000014, 160.99999999999977, -76.6000000000005, 66.79999999999998, 26.300000000000004, -82.9, -86.80000000000064, -0.6999999999999393, 20.000000000000014, 10.700000000000001, -30.399999999999878, 132.49999999999972, -19.299999999999834, 8.299999999999962, 60.499999999999936, 86.6, 27.200000000000138, 23.60000000000008, 82.09999999999998, 15.800000000000008, -108.09999999999995, 61.69999999999994, -191.5, -179.50000000000028, -74.80000000000004, 21.800000000000047, 22.40000000000008, 36.50000000000004, -136.60000000000025, -78.10000000000005, -205.90000000000018, 34.39999999999999, -104.79999999999995, -53.50000000000004, 72.80000000000001, 41.600000000000236, -35.80000000000002, -172.90000000000046, 75.79999999999934, -99.70000000000022, 151.7, 1.399999999999969, 160.3999999999999, 22.700000000000053, -6.999999999999936, -175.30000000000032, -217.30000000000035, -11.799999999999867, 60.80000000000014, -127.30000000000018, -223.90000000000012, -120.70000000000007, -2.199999999999996, 46.10000000000005, 112.69999999999993, -103.90000000000025, 38.90000000000021, -381.5999999999998, 9.500000000000048, 112.1, -226.0000000000001, -46.60000000000004, -66.70000000000002, -71.19999999999999, -153.10000000000025, -19.899999999999856, 25.400000000000105, 22.70000000000001, 20.000000000000014, 69.19999999999982, -4.9000000000000785, 24.50000000000009, -61.60000000000022, 78.4999999999995, 198.2, 20.000000000000014, 4.699999999999992, -154.30000000000004, -128.50000000000009, -43.89999999999977, 62.600000000000044, 25.100000000000076, 44.300000000000246, 39.80000000000016, 20.000000000000014, 162.79999999999978, 75.79999999999997, 159.49999999999974, 82.99999999999984, -5.2000000000000295, -192.10000000000022, 22.1000000000001, -42.99999999999999, 25.400000000000006, 105.49999999999997, 45.50000000000015, 4.699999999999999, -204.70000000000047, 97.39999999999955, 42.50000000000021, 52.400000000000226, 13.699999999999946, 20.000000000000014, -128.8000000000001, 142.1, 59.60000000000011, 151.39999999999995, 43.100000000000136, -4.599999999999975, -63.100000000000094, -30.099999999999774, 20.000000000000014, 65.6, 182.0, 191.9, 45.5, -38.80000000000007, -77.50000000000037, -30.400000000000034, -1.8999999999999995, -60.700000000000074, -142.60000000000002, -223.0, -61.89999999999999, 103.39999999999996, -237.10000000000008, -102.09999999999981, 184.7, 149.29999999999995, -21.69999999999999, -96.39999999999999, -84.09999999999998, 50.59999999999997, 42.19999999999999, -54.700000000000024, -27.399999999999892, 183.79999999999998, 125.0, 80.29999999999997, 40.10000000000002, 78.19999999999999, -2.499999999999991, -94.60000000000076, -32.799999999999976, 13.7, -240.70000000000016, -195.4000000000001, 128.89999999999998, -199.0000000000001, -199.00000000000006, -126.4], "policy_predator_policy_reward": [24.0, 0.0, 0.0, 104.0, 0.0, 0.0, 43.0, 6.0, 2.0, 80.0, 0.0, 20.0, 31.0, 100.0, 56.0, 0.0, 0.0, 0.0, 83.0, 0.0, 20.0, 16.0, 0.0, 38.0, 74.0, 0.0, 22.0, 0.0, 27.0, 3.0, 0.0, 0.0, 0.0, 28.0, 0.0, 21.0, 71.0, 38.0, 22.0, 74.0, 32.0, 6.0, 35.0, 0.0, 0.0, 94.0, 4.0, 57.0, 8.0, 0.0, 43.0, 40.0, 1.0, 50.0, 34.0, 77.0, 36.0, 0.0, 42.0, 52.0, 0.0, 38.0, 9.0, 6.0, 18.0, 0.0, 0.0, 0.0, 85.0, 2.0, 114.0, 65.0, 0.0, 132.0, 0.0, 28.0, 8.0, 114.0, 126.0, 27.0, 3.0, 83.0, 35.0, 37.0, 69.0, 0.0, 16.0, 90.0, 53.0, 5.0, 23.0, 0.0, 3.0, 36.0, 0.0, 130.0, 0.0, 33.0, 98.0, 70.0, 0.0, 100.0, 0.0, 24.0, 68.0, 0.0, 55.0, 207.0, 54.0, 134.0, 4.0, 81.0, 135.0, 0.0, 0.0, 43.0, 0.0, 0.0, 51.0, 31.0, 9.0, 65.0, 0.0, 0.0, 36.0, 0.0, 154.0, 0.0, 36.0, 14.0, 13.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 99.0, 83.0, 35.0, 30.0, 0.0, 0.0, 30.0, 14.0, 0.0, 107.0, 0.0, 0.0, 0.0, 3.0, 24.0, 91.0, 0.0, 15.0, 45.0, 14.0, 58.0, 29.0, 0.0, 4.0, 0.0, 0.0, 5.0, 84.0, 79.0, 73.0, 67.0, 84.0, 153.0, 0.0, 34.0, 33.0, 122.0, 43.0, 0.0, 1.0, 0.0, 129.0, 78.0, 0.0, 90.0, 0.0, 3.0, 42.0, 13.0, 24.0, 0.0, 54.0, 65.0, 28.0, 0.0, 41.0, 33.0, 158.0, 98.0, 26.0, 159.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5594751441790677, "mean_inference_ms": 1.4257727471615873, "mean_action_processing_ms": 0.2359844033898099, "mean_env_wait_ms": 0.20023681971762555, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005615711212158203, "StateBufferConnector_ms": 0.0029871463775634766, "ViewRequirementAgentConnector_ms": 0.09096765518188477}, "num_episodes": 18, "episode_return_max": 373.9, "episode_return_min": -262.59999999999866, "episode_return_mean": 52.75499999999988, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 96000, "num_agent_steps_trained": 96000, "num_env_steps_sampled": 24000, "num_env_steps_trained": 24000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 416.2402824453039, "num_env_steps_trained_throughput_per_sec": 416.2402824453039, "timesteps_total": 24000, "num_env_steps_sampled_lifetime": 24000, "num_agent_steps_sampled_lifetime": 96000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 96000, "timers": {"training_iteration_time_ms": 9806.746, "restore_workers_time_ms": 0.019, "training_step_time_ms": 9806.698, "sample_time_ms": 1118.79, "learn_time_ms": 8672.227, "learn_throughput": 461.243, "synch_weights_time_ms": 13.049}, "counters": {"num_env_steps_sampled": 24000, "num_env_steps_trained": 24000, "num_agent_steps_sampled": 96000, "num_agent_steps_trained": 96000}, "done": false, "training_iteration": 6, "trial_id": "7f9b9_00000", "date": "2024-08-13_10-31-01", "timestamp": 1723559461, "time_this_iter_s": 9.647548198699951, "time_total_s": 59.00970911979675, "pid": 45656, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001414434352388078, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x31fe89f70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 59.00970911979675, "iterations_since_restore": 6, "perf": {"cpu_util_percent": 29.923076923076923, "ram_util_percent": 83.72307692307692}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.175202637800464, "cur_kl_coeff": 0.2, "cur_lr": 0.0014144343523880775, "total_loss": 7.675750556067815, "policy_loss": -0.0020127757496777037, "vf_loss": 7.674785632178897, "vf_explained_var": 0.04661803444226583, "kl": 0.014888510276174613, "entropy": 1.540772467630881, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 12285.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6894463834781496, "cur_kl_coeff": 0.2, "cur_lr": 0.0014144343523880775, "total_loss": 3.4601377410232708, "policy_loss": -0.009352149510209167, "vf_loss": 3.4666257647610217, "vf_explained_var": 0.042683681987580796, "kl": 0.01432060109326156, "entropy": 1.538373702796048, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 12285.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 28000, "num_env_steps_trained": 28000, "num_agent_steps_sampled": 112000, "num_agent_steps_trained": 112000}, "env_runners": {"episode_reward_max": 373.9, "episode_reward_min": -262.59999999999866, "episode_reward_mean": 62.514999999999866, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -381.5999999999998, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 198.2, "predator_policy": 207.0}, "policy_reward_mean": {"prey_policy": -5.307500000000044, "predator_policy": 36.565}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-22.299999999999827, -28.699999999999733, 2.699999999999938, 201.2999999999992, -63.39999999999992, 26.000000000000284, 52.80000000000047, 167.3999999999993, 144.1000000000001, -58.699999999999655, 55.300000000000246, 74.29999999999994, 151.19999999999905, 83.79999999999893, 131.7999999999994, 105.69999999999996, -5.300000000000169, 49.2, -122.30000000000013, 72.19999999999978, 21.900000000000023, -131.00000000000023, 15.599999999999966, 91.29999999999939, 74.79999999999993, 8.899999999999956, 109.99999999999983, 184.7999999999991, 54.700000000000266, -262.59999999999866, 81.9999999999992, -183.20000000000027, -22.9, 182.7999999999994, 3.0000000000002007, -110.10000000000034, 74.09999999999997, -28.30000000000006, -89.30000000000044, 48.50000000000034, 42.700000000000294, 146.29999999999964, 36.900000000000176, 276.70000000000016, 60.70000000000014, -128.80000000000007, 68.70000000000007, 82.39999999999986, 59.800000000000345, 239.5999999999994, 242.4999999999994, -15.300000000000008, 44.10000000000002, 130.8999999999998, 94.19999999999915, -0.2999999999998928, 94.89999999999839, 36.700000000000294, 128.29999999999998, 225.99999999999952, 97.50000000000007, -6.1999999999996565, 89.5999999999994, 373.9, 95.70000000000002, 44.10000000000027, 88.39999999999995, -212.5999999999999, 108.49999999999947, -174.20000000000064, 334.9999999999999, 10.899999999999892, 44.50000000000004, 77.49999999999994, 201.39999999999952, 242.29999999999967, 172.29999999999995, -4.099999999999914, 21.90000000000028, -245.10000000000014, 53.900000000000034, -166.40000000000003, 270.9, 180.89999999999904, 241.9999999999991, 143.3999999999994, 318.10000000000116, 165.09999999999994, 126.89999999999978, 135.99999999999963, 81.90000000000002, -25.0, 134.9, 71.80000000000005, 203.8999999999994, -102.49999999999982, 348.4000000000001, -156.30000000000132, -195.90000000000012, 49.100000000000044], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-38.19999999999985, -93.1, -97.60000000000011, -27.099999999999945, 11.899999999999975, -47.19999999999997, 175.69999999999993, -9.399999999999835, -177.40000000000003, 20.000000000000014, 50.299999999999976, -85.30000000000004, 24.800000000000097, 20.000000000000014, 160.99999999999977, -76.6000000000005, 66.79999999999998, 26.300000000000004, -82.9, -86.80000000000064, -0.6999999999999393, 20.000000000000014, 10.700000000000001, -30.399999999999878, 132.49999999999972, -19.299999999999834, 8.299999999999962, 60.499999999999936, 86.6, 27.200000000000138, 23.60000000000008, 82.09999999999998, 15.800000000000008, -108.09999999999995, 61.69999999999994, -191.5, -179.50000000000028, -74.80000000000004, 21.800000000000047, 22.40000000000008, 36.50000000000004, -136.60000000000025, -78.10000000000005, -205.90000000000018, 34.39999999999999, -104.79999999999995, -53.50000000000004, 72.80000000000001, 41.600000000000236, -35.80000000000002, -172.90000000000046, 75.79999999999934, -99.70000000000022, 151.7, 1.399999999999969, 160.3999999999999, 22.700000000000053, -6.999999999999936, -175.30000000000032, -217.30000000000035, -11.799999999999867, 60.80000000000014, -127.30000000000018, -223.90000000000012, -120.70000000000007, -2.199999999999996, 46.10000000000005, 112.69999999999993, -103.90000000000025, 38.90000000000021, -381.5999999999998, 9.500000000000048, 112.1, -226.0000000000001, -46.60000000000004, -66.70000000000002, -71.19999999999999, -153.10000000000025, -19.899999999999856, 25.400000000000105, 22.70000000000001, 20.000000000000014, 69.19999999999982, -4.9000000000000785, 24.50000000000009, -61.60000000000022, 78.4999999999995, 198.2, 20.000000000000014, 4.699999999999992, -154.30000000000004, -128.50000000000009, -43.89999999999977, 62.600000000000044, 25.100000000000076, 44.300000000000246, 39.80000000000016, 20.000000000000014, 162.79999999999978, 75.79999999999997, 159.49999999999974, 82.99999999999984, -5.2000000000000295, -192.10000000000022, 22.1000000000001, -42.99999999999999, 25.400000000000006, 105.49999999999997, 45.50000000000015, 4.699999999999999, -204.70000000000047, 97.39999999999955, 42.50000000000021, 52.400000000000226, 13.699999999999946, 20.000000000000014, -128.8000000000001, 142.1, 59.60000000000011, 151.39999999999995, 43.100000000000136, -4.599999999999975, -63.100000000000094, -30.099999999999774, 20.000000000000014, 65.6, 182.0, 191.9, 45.5, -38.80000000000007, -77.50000000000037, -30.400000000000034, -1.8999999999999995, -60.700000000000074, -142.60000000000002, -223.0, -61.89999999999999, 103.39999999999996, -237.10000000000008, -102.09999999999981, 184.7, 149.29999999999995, -21.69999999999999, -96.39999999999999, -84.09999999999998, 50.59999999999997, 42.19999999999999, -54.700000000000024, -27.399999999999892, 183.79999999999998, 125.0, 80.29999999999997, 40.10000000000002, 78.19999999999999, -2.499999999999991, -94.60000000000076, -32.799999999999976, 13.7, -240.70000000000016, -195.4000000000001, 128.89999999999998, -199.0000000000001, -199.00000000000006, -126.4, 140.0, 119.89999999999998, 24.500000000000057, 154.39999999999975, 169.39999999999992, 65.6000000000001, 138.49999999999997, -54.1, 139.69999999999968, 178.39999999999998, 31.100000000000016, 79.99999999999994, 96.20000000000002, -25.299999999999784, -83.80000000000007, 132.7999999999997, -26.79999999999999, 22.699999999999978, -64.9, -63.099999999999994, -19.30000000000001, 69.20000000000002, -10.899999999999842, 25.699999999999996, 43.70000000000002, 105.19999999999942, -160.29999999999995, -53.20000000000003, 155.89999999999998, 186.5, -94.60000000000058, -153.70000000000056, -190.00000000000003, -166.90000000000006, -19.899999999999757, -25.0], "policy_predator_policy_reward": [71.0, 38.0, 22.0, 74.0, 32.0, 6.0, 35.0, 0.0, 0.0, 94.0, 4.0, 57.0, 8.0, 0.0, 43.0, 40.0, 1.0, 50.0, 34.0, 77.0, 36.0, 0.0, 42.0, 52.0, 0.0, 38.0, 9.0, 6.0, 18.0, 0.0, 0.0, 0.0, 85.0, 2.0, 114.0, 65.0, 0.0, 132.0, 0.0, 28.0, 8.0, 114.0, 126.0, 27.0, 3.0, 83.0, 35.0, 37.0, 69.0, 0.0, 16.0, 90.0, 53.0, 5.0, 23.0, 0.0, 3.0, 36.0, 0.0, 130.0, 0.0, 33.0, 98.0, 70.0, 0.0, 100.0, 0.0, 24.0, 68.0, 0.0, 55.0, 207.0, 54.0, 134.0, 4.0, 81.0, 135.0, 0.0, 0.0, 43.0, 0.0, 0.0, 51.0, 31.0, 9.0, 65.0, 0.0, 0.0, 36.0, 0.0, 154.0, 0.0, 36.0, 14.0, 13.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 99.0, 83.0, 35.0, 30.0, 0.0, 0.0, 30.0, 14.0, 0.0, 107.0, 0.0, 0.0, 0.0, 3.0, 24.0, 91.0, 0.0, 15.0, 45.0, 14.0, 58.0, 29.0, 0.0, 4.0, 0.0, 0.0, 5.0, 84.0, 79.0, 73.0, 67.0, 84.0, 153.0, 0.0, 34.0, 33.0, 122.0, 43.0, 0.0, 1.0, 0.0, 129.0, 78.0, 0.0, 90.0, 0.0, 3.0, 42.0, 13.0, 24.0, 0.0, 54.0, 65.0, 28.0, 0.0, 41.0, 33.0, 158.0, 98.0, 26.0, 159.0, 0.0, 0.0, 11.0, 2.0, 0.0, 6.0, 1.0, 18.0, 41.0, 0.0, 0.0, 0.0, 54.0, 28.0, 28.0, 0.0, 87.0, 8.0, 78.0, 99.0, 4.0, 67.0, 18.0, 57.0, 0.0, 42.0, 13.0, 111.0, 0.0, 6.0, 0.0, 0.0, 92.0, 101.0, 60.0, 19.0, 75.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5513883366382849, "mean_inference_ms": 1.3943635992447698, "mean_action_processing_ms": 0.23098765622865636, "mean_env_wait_ms": 0.1946972562254388, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005254387855529785, "StateBufferConnector_ms": 0.0029714107513427734, "ViewRequirementAgentConnector_ms": 0.09199702739715576}, "num_episodes": 18, "episode_return_max": 373.9, "episode_return_min": -262.59999999999866, "episode_return_mean": 62.514999999999866, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 112000, "num_agent_steps_trained": 112000, "num_env_steps_sampled": 28000, "num_env_steps_trained": 28000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 410.0418060308975, "num_env_steps_trained_throughput_per_sec": 410.0418060308975, "timesteps_total": 28000, "num_env_steps_sampled_lifetime": 28000, "num_agent_steps_sampled_lifetime": 112000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 112000, "timers": {"training_iteration_time_ms": 9799.37, "restore_workers_time_ms": 0.019, "training_step_time_ms": 9799.322, "sample_time_ms": 1112.398, "learn_time_ms": 8671.353, "learn_throughput": 461.289, "synch_weights_time_ms": 13.143}, "counters": {"num_env_steps_sampled": 28000, "num_env_steps_trained": 28000, "num_agent_steps_sampled": 112000, "num_agent_steps_trained": 112000}, "done": false, "training_iteration": 7, "trial_id": "7f9b9_00000", "date": "2024-08-13_10-31-11", "timestamp": 1723559471, "time_this_iter_s": 9.802536010742188, "time_total_s": 68.81224513053894, "pid": 45656, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001414434352388078, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x31feefaf0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 68.81224513053894, "iterations_since_restore": 7, "perf": {"cpu_util_percent": 31.12857142857143, "ram_util_percent": 83.48571428571428}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.645338069635724, "cur_kl_coeff": 0.2, "cur_lr": 0.0014144343523880775, "total_loss": 6.188791227340698, "policy_loss": -0.0012607694519732994, "vf_loss": 6.187179538938734, "vf_explained_var": -0.025408619673794538, "kl": 0.014362289551157342, "entropy": 1.5495292203136222, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 14175.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9370981101636533, "cur_kl_coeff": 0.2, "cur_lr": 0.0014144343523880775, "total_loss": 4.927753092119933, "policy_loss": -0.007534409451382186, "vf_loss": 4.932250121535447, "vf_explained_var": 0.01929474813597543, "kl": 0.01518685316300237, "entropy": 1.5200949762233351, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 14175.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 32000, "num_env_steps_trained": 32000, "num_agent_steps_sampled": 128000, "num_agent_steps_trained": 128000}, "env_runners": {"episode_reward_max": 373.9, "episode_reward_min": -262.59999999999866, "episode_reward_mean": 61.09799999999986, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -381.5999999999998, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 198.2, "predator_policy": 207.0}, "policy_reward_mean": {"prey_policy": -8.24600000000004, "predator_policy": 38.795}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-122.30000000000013, 72.19999999999978, 21.900000000000023, -131.00000000000023, 15.599999999999966, 91.29999999999939, 74.79999999999993, 8.899999999999956, 109.99999999999983, 184.7999999999991, 54.700000000000266, -262.59999999999866, 81.9999999999992, -183.20000000000027, -22.9, 182.7999999999994, 3.0000000000002007, -110.10000000000034, 74.09999999999997, -28.30000000000006, -89.30000000000044, 48.50000000000034, 42.700000000000294, 146.29999999999964, 36.900000000000176, 276.70000000000016, 60.70000000000014, -128.80000000000007, 68.70000000000007, 82.39999999999986, 59.800000000000345, 239.5999999999994, 242.4999999999994, -15.300000000000008, 44.10000000000002, 130.8999999999998, 94.19999999999915, -0.2999999999998928, 94.89999999999839, 36.700000000000294, 128.29999999999998, 225.99999999999952, 97.50000000000007, -6.1999999999996565, 89.5999999999994, 373.9, 95.70000000000002, 44.10000000000027, 88.39999999999995, -212.5999999999999, 108.49999999999947, -174.20000000000064, 334.9999999999999, 10.899999999999892, 44.50000000000004, 77.49999999999994, 201.39999999999952, 242.29999999999967, 172.29999999999995, -4.099999999999914, 21.90000000000028, -245.10000000000014, 53.900000000000034, -166.40000000000003, 270.9, 180.89999999999904, 241.9999999999991, 143.3999999999994, 318.10000000000116, 165.09999999999994, 126.89999999999978, 135.99999999999963, 81.90000000000002, -25.0, 134.9, 71.80000000000005, 203.8999999999994, -102.49999999999982, 348.4000000000001, -156.30000000000132, -195.90000000000012, 49.100000000000044, 116.59999999999926, -56.199999999999775, 203.7999999999991, 17.999999999999975, -134.1000000000005, -32.40000000000014, 83.5999999999998, 33.20000000000026, 27.100000000000257, 18.600000000000115, 114.1999999999995, 24.200000000000045, 158.39999999999958, -14.699999999999948, 104.49999999999959, 33.3999999999999, 123.09999999999995, 104.19999999999975], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-179.50000000000028, -74.80000000000004, 21.800000000000047, 22.40000000000008, 36.50000000000004, -136.60000000000025, -78.10000000000005, -205.90000000000018, 34.39999999999999, -104.79999999999995, -53.50000000000004, 72.80000000000001, 41.600000000000236, -35.80000000000002, -172.90000000000046, 75.79999999999934, -99.70000000000022, 151.7, 1.399999999999969, 160.3999999999999, 22.700000000000053, -6.999999999999936, -175.30000000000032, -217.30000000000035, -11.799999999999867, 60.80000000000014, -127.30000000000018, -223.90000000000012, -120.70000000000007, -2.199999999999996, 46.10000000000005, 112.69999999999993, -103.90000000000025, 38.90000000000021, -381.5999999999998, 9.500000000000048, 112.1, -226.0000000000001, -46.60000000000004, -66.70000000000002, -71.19999999999999, -153.10000000000025, -19.899999999999856, 25.400000000000105, 22.70000000000001, 20.000000000000014, 69.19999999999982, -4.9000000000000785, 24.50000000000009, -61.60000000000022, 78.4999999999995, 198.2, 20.000000000000014, 4.699999999999992, -154.30000000000004, -128.50000000000009, -43.89999999999977, 62.600000000000044, 25.100000000000076, 44.300000000000246, 39.80000000000016, 20.000000000000014, 162.79999999999978, 75.79999999999997, 159.49999999999974, 82.99999999999984, -5.2000000000000295, -192.10000000000022, 22.1000000000001, -42.99999999999999, 25.400000000000006, 105.49999999999997, 45.50000000000015, 4.699999999999999, -204.70000000000047, 97.39999999999955, 42.50000000000021, 52.400000000000226, 13.699999999999946, 20.000000000000014, -128.8000000000001, 142.1, 59.60000000000011, 151.39999999999995, 43.100000000000136, -4.599999999999975, -63.100000000000094, -30.099999999999774, 20.000000000000014, 65.6, 182.0, 191.9, 45.5, -38.80000000000007, -77.50000000000037, -30.400000000000034, -1.8999999999999995, -60.700000000000074, -142.60000000000002, -223.0, -61.89999999999999, 103.39999999999996, -237.10000000000008, -102.09999999999981, 184.7, 149.29999999999995, -21.69999999999999, -96.39999999999999, -84.09999999999998, 50.59999999999997, 42.19999999999999, -54.700000000000024, -27.399999999999892, 183.79999999999998, 125.0, 80.29999999999997, 40.10000000000002, 78.19999999999999, -2.499999999999991, -94.60000000000076, -32.799999999999976, 13.7, -240.70000000000016, -195.4000000000001, 128.89999999999998, -199.0000000000001, -199.00000000000006, -126.4, 140.0, 119.89999999999998, 24.500000000000057, 154.39999999999975, 169.39999999999992, 65.6000000000001, 138.49999999999997, -54.1, 139.69999999999968, 178.39999999999998, 31.100000000000016, 79.99999999999994, 96.20000000000002, -25.299999999999784, -83.80000000000007, 132.7999999999997, -26.79999999999999, 22.699999999999978, -64.9, -63.099999999999994, -19.30000000000001, 69.20000000000002, -10.899999999999842, 25.699999999999996, 43.70000000000002, 105.19999999999942, -160.29999999999995, -53.20000000000003, 155.89999999999998, 186.5, -94.60000000000058, -153.70000000000056, -190.00000000000003, -166.90000000000006, -19.899999999999757, -25.0, 46.70000000000008, 23.900000000000084, -226.60000000000005, -34.59999999999975, 168.49999999999983, 35.300000000000146, 20.000000000000014, -21.999999999999744, -194.80000000000047, -148.30000000000004, -187.0, 23.60000000000015, -75.69999999999996, -6.699999999999967, 20.900000000000027, 5.299999999999996, 20.000000000000014, -13.900000000000041, 20.000000000000014, -129.4000000000002, 72.80000000000001, 7.399999999999994, 20.000000000000014, -83.79999999999997, 33.200000000000045, 69.19999999999993, 20.000000000000014, -180.70000000000005, 69.50000000000003, 20.000000000000014, -10.299999999999978, -49.29999999999998, -15.999999999999993, -4.899999999999999, 113.59999999999978, -99.39999999999995], "policy_predator_policy_reward": [0.0, 132.0, 0.0, 28.0, 8.0, 114.0, 126.0, 27.0, 3.0, 83.0, 35.0, 37.0, 69.0, 0.0, 16.0, 90.0, 53.0, 5.0, 23.0, 0.0, 3.0, 36.0, 0.0, 130.0, 0.0, 33.0, 98.0, 70.0, 0.0, 100.0, 0.0, 24.0, 68.0, 0.0, 55.0, 207.0, 54.0, 134.0, 4.0, 81.0, 135.0, 0.0, 0.0, 43.0, 0.0, 0.0, 51.0, 31.0, 9.0, 65.0, 0.0, 0.0, 36.0, 0.0, 154.0, 0.0, 36.0, 14.0, 13.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 99.0, 83.0, 35.0, 30.0, 0.0, 0.0, 30.0, 14.0, 0.0, 107.0, 0.0, 0.0, 0.0, 3.0, 24.0, 91.0, 0.0, 15.0, 45.0, 14.0, 58.0, 29.0, 0.0, 4.0, 0.0, 0.0, 5.0, 84.0, 79.0, 73.0, 67.0, 84.0, 153.0, 0.0, 34.0, 33.0, 122.0, 43.0, 0.0, 1.0, 0.0, 129.0, 78.0, 0.0, 90.0, 0.0, 3.0, 42.0, 13.0, 24.0, 0.0, 54.0, 65.0, 28.0, 0.0, 41.0, 33.0, 158.0, 98.0, 26.0, 159.0, 0.0, 0.0, 11.0, 2.0, 0.0, 6.0, 1.0, 18.0, 41.0, 0.0, 0.0, 0.0, 54.0, 28.0, 28.0, 0.0, 87.0, 8.0, 78.0, 99.0, 4.0, 67.0, 18.0, 57.0, 0.0, 42.0, 13.0, 111.0, 0.0, 6.0, 0.0, 0.0, 92.0, 101.0, 60.0, 19.0, 75.0, 27.0, 19.0, 110.0, 95.0, 0.0, 0.0, 20.0, 0.0, 125.0, 84.0, 131.0, 0.0, 106.0, 60.0, 0.0, 7.0, 14.0, 7.0, 63.0, 65.0, 1.0, 33.0, 88.0, 0.0, 0.0, 56.0, 38.0, 108.0, 15.0, 0.0, 28.0, 65.0, 46.0, 98.0, 0.0, 90.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5495151465600354, "mean_inference_ms": 1.3818916781108501, "mean_action_processing_ms": 0.22927160387941434, "mean_env_wait_ms": 0.19228486951332266, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004869818687438965, "StateBufferConnector_ms": 0.0029718875885009766, "ViewRequirementAgentConnector_ms": 0.0911567211151123}, "num_episodes": 18, "episode_return_max": 373.9, "episode_return_min": -262.59999999999866, "episode_return_mean": 61.09799999999986, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 128000, "num_agent_steps_trained": 128000, "num_env_steps_sampled": 32000, "num_env_steps_trained": 32000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 408.61303392306695, "num_env_steps_trained_throughput_per_sec": 408.61303392306695, "timesteps_total": 32000, "num_env_steps_sampled_lifetime": 32000, "num_agent_steps_sampled_lifetime": 128000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 128000, "timers": {"training_iteration_time_ms": 9798.102, "restore_workers_time_ms": 0.018, "training_step_time_ms": 9798.052, "sample_time_ms": 1120.369, "learn_time_ms": 8657.784, "learn_throughput": 462.012, "synch_weights_time_ms": 16.93}, "counters": {"num_env_steps_sampled": 32000, "num_env_steps_trained": 32000, "num_agent_steps_sampled": 128000, "num_agent_steps_trained": 128000}, "done": false, "training_iteration": 8, "trial_id": "7f9b9_00000", "date": "2024-08-13_10-31-21", "timestamp": 1723559481, "time_this_iter_s": 9.979365110397339, "time_total_s": 78.79161024093628, "pid": 45656, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001414434352388078, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x31fe8d700>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 78.79161024093628, "iterations_since_restore": 8, "perf": {"cpu_util_percent": 30.578571428571433, "ram_util_percent": 83.46428571428571}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.978007967793752, "cur_kl_coeff": 0.2, "cur_lr": 0.0014144343523880775, "total_loss": 6.035359714144752, "policy_loss": -0.006292690889954212, "vf_loss": 6.038298675496742, "vf_explained_var": -0.06001134606265517, "kl": 0.016768646754414605, "entropy": 1.5350593213051085, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 16065.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8378290947704088, "cur_kl_coeff": 0.2, "cur_lr": 0.0014144343523880775, "total_loss": 5.922757092733232, "policy_loss": -0.005840699790567948, "vf_loss": 5.925918433779762, "vf_explained_var": 0.01835214404202012, "kl": 0.013396849142278639, "entropy": 1.4919711834539182, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 16065.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 36000, "num_env_steps_trained": 36000, "num_agent_steps_sampled": 144000, "num_agent_steps_trained": 144000}, "env_runners": {"episode_reward_max": 373.9, "episode_reward_min": -388.0999999999991, "episode_reward_mean": 64.20299999999985, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -330.4, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 198.2, "predator_policy": 194.0}, "policy_reward_mean": {"prey_policy": -6.488500000000037, "predator_policy": 38.59}, "custom_metrics": {}, "hist_stats": {"episode_reward": [42.700000000000294, 146.29999999999964, 36.900000000000176, 276.70000000000016, 60.70000000000014, -128.80000000000007, 68.70000000000007, 82.39999999999986, 59.800000000000345, 239.5999999999994, 242.4999999999994, -15.300000000000008, 44.10000000000002, 130.8999999999998, 94.19999999999915, -0.2999999999998928, 94.89999999999839, 36.700000000000294, 128.29999999999998, 225.99999999999952, 97.50000000000007, -6.1999999999996565, 89.5999999999994, 373.9, 95.70000000000002, 44.10000000000027, 88.39999999999995, -212.5999999999999, 108.49999999999947, -174.20000000000064, 334.9999999999999, 10.899999999999892, 44.50000000000004, 77.49999999999994, 201.39999999999952, 242.29999999999967, 172.29999999999995, -4.099999999999914, 21.90000000000028, -245.10000000000014, 53.900000000000034, -166.40000000000003, 270.9, 180.89999999999904, 241.9999999999991, 143.3999999999994, 318.10000000000116, 165.09999999999994, 126.89999999999978, 135.99999999999963, 81.90000000000002, -25.0, 134.9, 71.80000000000005, 203.8999999999994, -102.49999999999982, 348.4000000000001, -156.30000000000132, -195.90000000000012, 49.100000000000044, 116.59999999999926, -56.199999999999775, 203.7999999999991, 17.999999999999975, -134.1000000000005, -32.40000000000014, 83.5999999999998, 33.20000000000026, 27.100000000000257, 18.600000000000115, 114.1999999999995, 24.200000000000045, 158.39999999999958, -14.699999999999948, 104.49999999999959, 33.3999999999999, 123.09999999999995, 104.19999999999975, -71.90000000000094, 207.99999999999957, -21.399999999999878, -31.299999999999883, 121.89999999999961, 49.99999999999956, -45.19999999999973, 66.9, 44.50000000000038, 39.80000000000019, -11.499999999999783, 47.20000000000029, 163.79999999999998, 7.4999999999996, 129.59999999999874, -100.40000000000009, 57.69999999999929, -66.0, -76.40000000000077, -8.599999999999921, 269.29999999999995, -388.0999999999991], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [22.70000000000001, 20.000000000000014, 69.19999999999982, -4.9000000000000785, 24.50000000000009, -61.60000000000022, 78.4999999999995, 198.2, 20.000000000000014, 4.699999999999992, -154.30000000000004, -128.50000000000009, -43.89999999999977, 62.600000000000044, 25.100000000000076, 44.300000000000246, 39.80000000000016, 20.000000000000014, 162.79999999999978, 75.79999999999997, 159.49999999999974, 82.99999999999984, -5.2000000000000295, -192.10000000000022, 22.1000000000001, -42.99999999999999, 25.400000000000006, 105.49999999999997, 45.50000000000015, 4.699999999999999, -204.70000000000047, 97.39999999999955, 42.50000000000021, 52.400000000000226, 13.699999999999946, 20.000000000000014, -128.8000000000001, 142.1, 59.60000000000011, 151.39999999999995, 43.100000000000136, -4.599999999999975, -63.100000000000094, -30.099999999999774, 20.000000000000014, 65.6, 182.0, 191.9, 45.5, -38.80000000000007, -77.50000000000037, -30.400000000000034, -1.8999999999999995, -60.700000000000074, -142.60000000000002, -223.0, -61.89999999999999, 103.39999999999996, -237.10000000000008, -102.09999999999981, 184.7, 149.29999999999995, -21.69999999999999, -96.39999999999999, -84.09999999999998, 50.59999999999997, 42.19999999999999, -54.700000000000024, -27.399999999999892, 183.79999999999998, 125.0, 80.29999999999997, 40.10000000000002, 78.19999999999999, -2.499999999999991, -94.60000000000076, -32.799999999999976, 13.7, -240.70000000000016, -195.4000000000001, 128.89999999999998, -199.0000000000001, -199.00000000000006, -126.4, 140.0, 119.89999999999998, 24.500000000000057, 154.39999999999975, 169.39999999999992, 65.6000000000001, 138.49999999999997, -54.1, 139.69999999999968, 178.39999999999998, 31.100000000000016, 79.99999999999994, 96.20000000000002, -25.299999999999784, -83.80000000000007, 132.7999999999997, -26.79999999999999, 22.699999999999978, -64.9, -63.099999999999994, -19.30000000000001, 69.20000000000002, -10.899999999999842, 25.699999999999996, 43.70000000000002, 105.19999999999942, -160.29999999999995, -53.20000000000003, 155.89999999999998, 186.5, -94.60000000000058, -153.70000000000056, -190.00000000000003, -166.90000000000006, -19.899999999999757, -25.0, 46.70000000000008, 23.900000000000084, -226.60000000000005, -34.59999999999975, 168.49999999999983, 35.300000000000146, 20.000000000000014, -21.999999999999744, -194.80000000000047, -148.30000000000004, -187.0, 23.60000000000015, -75.69999999999996, -6.699999999999967, 20.900000000000027, 5.299999999999996, 20.000000000000014, -13.900000000000041, 20.000000000000014, -129.4000000000002, 72.80000000000001, 7.399999999999994, 20.000000000000014, -83.79999999999997, 33.200000000000045, 69.19999999999993, 20.000000000000014, -180.70000000000005, 69.50000000000003, 20.000000000000014, -10.299999999999978, -49.29999999999998, -15.999999999999993, -4.899999999999999, 113.59999999999978, -99.39999999999995, -66.40000000000089, -113.50000000000006, 107.29999999999984, 7.700000000000003, -255.4, 20.000000000000014, 17.899999999999988, -140.20000000000016, 101.89999999999992, 20.000000000000014, 20.000000000000014, -45.999999999999986, -230.20000000000016, 20.000000000000014, -92.50000000000003, 1.4000000000000057, 20.000000000000014, 24.500000000000085, -86.19999999999995, 20.000000000000014, -17.799999999999834, -15.69999999999985, 27.200000000000145, 20.000000000000014, 11.599999999999701, 93.2, 74.89999999999942, -171.39999999999998, 107.59999999999951, 20.000000000000014, 20.000000000000014, -330.4, 26.300000000000118, -49.60000000000001, -254.5, 30.5, -178.90000000000035, -32.499999999999886, -15.699999999999882, -64.90000000000036, 162.19999999999996, 91.09999999999967, -308.8, -292.29999999999916], "policy_predator_policy_reward": [0.0, 0.0, 51.0, 31.0, 9.0, 65.0, 0.0, 0.0, 36.0, 0.0, 154.0, 0.0, 36.0, 14.0, 13.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 99.0, 83.0, 35.0, 30.0, 0.0, 0.0, 30.0, 14.0, 0.0, 107.0, 0.0, 0.0, 0.0, 3.0, 24.0, 91.0, 0.0, 15.0, 45.0, 14.0, 58.0, 29.0, 0.0, 4.0, 0.0, 0.0, 5.0, 84.0, 79.0, 73.0, 67.0, 84.0, 153.0, 0.0, 34.0, 33.0, 122.0, 43.0, 0.0, 1.0, 0.0, 129.0, 78.0, 0.0, 90.0, 0.0, 3.0, 42.0, 13.0, 24.0, 0.0, 54.0, 65.0, 28.0, 0.0, 41.0, 33.0, 158.0, 98.0, 26.0, 159.0, 0.0, 0.0, 11.0, 2.0, 0.0, 6.0, 1.0, 18.0, 41.0, 0.0, 0.0, 0.0, 54.0, 28.0, 28.0, 0.0, 87.0, 8.0, 78.0, 99.0, 4.0, 67.0, 18.0, 57.0, 0.0, 42.0, 13.0, 111.0, 0.0, 6.0, 0.0, 0.0, 92.0, 101.0, 60.0, 19.0, 75.0, 27.0, 19.0, 110.0, 95.0, 0.0, 0.0, 20.0, 0.0, 125.0, 84.0, 131.0, 0.0, 106.0, 60.0, 0.0, 7.0, 14.0, 7.0, 63.0, 65.0, 1.0, 33.0, 88.0, 0.0, 0.0, 56.0, 38.0, 108.0, 15.0, 0.0, 28.0, 65.0, 46.0, 98.0, 0.0, 90.0, 101.0, 7.0, 55.0, 38.0, 119.0, 95.0, 41.0, 50.0, 0.0, 0.0, 0.0, 76.0, 132.0, 33.0, 123.0, 35.0, 0.0, 0.0, 76.0, 30.0, 0.0, 22.0, 0.0, 0.0, 0.0, 59.0, 72.0, 32.0, 2.0, 0.0, 165.0, 45.0, 44.0, 37.0, 158.0, 0.0, 97.0, 38.0, 55.0, 17.0, 9.0, 7.0, 19.0, 194.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5656405554091848, "mean_inference_ms": 1.414249159011011, "mean_action_processing_ms": 0.23209734007432348, "mean_env_wait_ms": 0.19683196859073362, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0048323869705200195, "StateBufferConnector_ms": 0.0032198429107666016, "ViewRequirementAgentConnector_ms": 0.10368525981903076}, "num_episodes": 22, "episode_return_max": 373.9, "episode_return_min": -388.0999999999991, "episode_return_mean": 64.20299999999985, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 144000, "num_agent_steps_trained": 144000, "num_env_steps_sampled": 36000, "num_env_steps_trained": 36000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 310.5100209031241, "num_env_steps_trained_throughput_per_sec": 310.5100209031241, "timesteps_total": 36000, "num_env_steps_sampled_lifetime": 36000, "num_agent_steps_sampled_lifetime": 144000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 144000, "timers": {"training_iteration_time_ms": 10140.762, "restore_workers_time_ms": 0.018, "training_step_time_ms": 10140.712, "sample_time_ms": 1249.252, "learn_time_ms": 8871.777, "learn_throughput": 450.868, "synch_weights_time_ms": 16.736}, "counters": {"num_env_steps_sampled": 36000, "num_env_steps_trained": 36000, "num_agent_steps_sampled": 144000, "num_agent_steps_trained": 144000}, "done": false, "training_iteration": 9, "trial_id": "7f9b9_00000", "date": "2024-08-13_10-31-34", "timestamp": 1723559494, "time_this_iter_s": 12.93954086303711, "time_total_s": 91.73115110397339, "pid": 45656, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001414434352388078, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x31ffb6700>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 91.73115110397339, "iterations_since_restore": 9, "perf": {"cpu_util_percent": 52.67894736842105, "ram_util_percent": 83.64210526315792}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.1718865104137905, "cur_kl_coeff": 0.2, "cur_lr": 0.0014144343523880775, "total_loss": 4.606054533347882, "policy_loss": -0.0016169697865498838, "vf_loss": 4.604596546718052, "vf_explained_var": -0.13497259383479124, "kl": 0.015374835980297315, "entropy": 1.5025699590879773, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 17955.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5835389129541538, "cur_kl_coeff": 0.2, "cur_lr": 0.0014144343523880775, "total_loss": 5.115075378569346, "policy_loss": -0.00559590963237776, "vf_loss": 5.118120318493515, "vf_explained_var": 0.0025062239043927067, "kl": 0.012754880959510844, "entropy": 1.463519681635357, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 17955.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 40000, "num_env_steps_trained": 40000, "num_agent_steps_sampled": 160000, "num_agent_steps_trained": 160000}, "env_runners": {"episode_reward_max": 373.9, "episode_reward_min": -422.5999999999997, "episode_reward_mean": 36.17999999999985, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -395.8, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 191.9, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -29.830000000000037, "predator_policy": 47.92}, "custom_metrics": {}, "hist_stats": {"episode_reward": [373.9, 95.70000000000002, 44.10000000000027, 88.39999999999995, -212.5999999999999, 108.49999999999947, -174.20000000000064, 334.9999999999999, 10.899999999999892, 44.50000000000004, 77.49999999999994, 201.39999999999952, 242.29999999999967, 172.29999999999995, -4.099999999999914, 21.90000000000028, -245.10000000000014, 53.900000000000034, -166.40000000000003, 270.9, 180.89999999999904, 241.9999999999991, 143.3999999999994, 318.10000000000116, 165.09999999999994, 126.89999999999978, 135.99999999999963, 81.90000000000002, -25.0, 134.9, 71.80000000000005, 203.8999999999994, -102.49999999999982, 348.4000000000001, -156.30000000000132, -195.90000000000012, 49.100000000000044, 116.59999999999926, -56.199999999999775, 203.7999999999991, 17.999999999999975, -134.1000000000005, -32.40000000000014, 83.5999999999998, 33.20000000000026, 27.100000000000257, 18.600000000000115, 114.1999999999995, 24.200000000000045, 158.39999999999958, -14.699999999999948, 104.49999999999959, 33.3999999999999, 123.09999999999995, 104.19999999999975, -71.90000000000094, 207.99999999999957, -21.399999999999878, -31.299999999999883, 121.89999999999961, 49.99999999999956, -45.19999999999973, 66.9, 44.50000000000038, 39.80000000000019, -11.499999999999783, 47.20000000000029, 163.79999999999998, 7.4999999999996, 129.59999999999874, -100.40000000000009, 57.69999999999929, -66.0, -76.40000000000077, -8.599999999999921, 269.29999999999995, -388.0999999999991, 3.0000000000001483, -43.59999999999992, 73.79999999999978, 23.00000000000003, -65.39999999999986, -89.8000000000005, -176.9, 13.500000000000117, -124.50000000000003, -42.399999999999714, 33.70000000000022, -18.000000000000462, -96.30000000000115, -43.29999999999996, -422.5999999999997, -21.59999999999978, 45.20000000000019, 61.0999999999997, -93.10000000000093, 34.40000000000026, 113.49999999999919, 80.4999999999993, 1.4000000000000692], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [182.0, 191.9, 45.5, -38.80000000000007, -77.50000000000037, -30.400000000000034, -1.8999999999999995, -60.700000000000074, -142.60000000000002, -223.0, -61.89999999999999, 103.39999999999996, -237.10000000000008, -102.09999999999981, 184.7, 149.29999999999995, -21.69999999999999, -96.39999999999999, -84.09999999999998, 50.59999999999997, 42.19999999999999, -54.700000000000024, -27.399999999999892, 183.79999999999998, 125.0, 80.29999999999997, 40.10000000000002, 78.19999999999999, -2.499999999999991, -94.60000000000076, -32.799999999999976, 13.7, -240.70000000000016, -195.4000000000001, 128.89999999999998, -199.0000000000001, -199.00000000000006, -126.4, 140.0, 119.89999999999998, 24.500000000000057, 154.39999999999975, 169.39999999999992, 65.6000000000001, 138.49999999999997, -54.1, 139.69999999999968, 178.39999999999998, 31.100000000000016, 79.99999999999994, 96.20000000000002, -25.299999999999784, -83.80000000000007, 132.7999999999997, -26.79999999999999, 22.699999999999978, -64.9, -63.099999999999994, -19.30000000000001, 69.20000000000002, -10.899999999999842, 25.699999999999996, 43.70000000000002, 105.19999999999942, -160.29999999999995, -53.20000000000003, 155.89999999999998, 186.5, -94.60000000000058, -153.70000000000056, -190.00000000000003, -166.90000000000006, -19.899999999999757, -25.0, 46.70000000000008, 23.900000000000084, -226.60000000000005, -34.59999999999975, 168.49999999999983, 35.300000000000146, 20.000000000000014, -21.999999999999744, -194.80000000000047, -148.30000000000004, -187.0, 23.60000000000015, -75.69999999999996, -6.699999999999967, 20.900000000000027, 5.299999999999996, 20.000000000000014, -13.900000000000041, 20.000000000000014, -129.4000000000002, 72.80000000000001, 7.399999999999994, 20.000000000000014, -83.79999999999997, 33.200000000000045, 69.19999999999993, 20.000000000000014, -180.70000000000005, 69.50000000000003, 20.000000000000014, -10.299999999999978, -49.29999999999998, -15.999999999999993, -4.899999999999999, 113.59999999999978, -99.39999999999995, -66.40000000000089, -113.50000000000006, 107.29999999999984, 7.700000000000003, -255.4, 20.000000000000014, 17.899999999999988, -140.20000000000016, 101.89999999999992, 20.000000000000014, 20.000000000000014, -45.999999999999986, -230.20000000000016, 20.000000000000014, -92.50000000000003, 1.4000000000000057, 20.000000000000014, 24.500000000000085, -86.19999999999995, 20.000000000000014, -17.799999999999834, -15.69999999999985, 27.200000000000145, 20.000000000000014, 11.599999999999701, 93.2, 74.89999999999942, -171.39999999999998, 107.59999999999951, 20.000000000000014, 20.000000000000014, -330.4, 26.300000000000118, -49.60000000000001, -254.5, 30.5, -178.90000000000035, -32.499999999999886, -15.699999999999882, -64.90000000000036, 162.19999999999996, 91.09999999999967, -308.8, -292.29999999999916, -9.39999999999989, -13.599999999999804, -51.40000000000005, -128.20000000000002, 53.900000000000226, 17.899999999999977, 20.000000000000014, -21.999999999999744, -222.4, 20.000000000000014, 20.000000000000014, -395.8, -217.2999999999999, -235.60000000000005, -149.20000000000022, 22.700000000000063, -158.50000000000003, -211.0, -9.099999999999898, -166.30000000000038, 2.299999999999973, -49.599999999999916, -136.6000000000001, -63.400000000000844, -169.60000000000053, -24.69999999999984, -87.10000000000073, -26.19999999999976, -390.69999999999993, -355.90000000000003, -241.60000000000002, -1.0000000000000204, -137.20000000000033, 25.400000000000098, 32.60000000000023, -50.499999999999986, -36.69999999999989, -135.40000000000057, -13.599999999999854, 20.000000000000014, 7.399999999999974, 37.09999999999985, 20.000000000000014, 60.50000000000022, -147.4, -14.19999999999981], "policy_predator_policy_reward": [0.0, 0.0, 5.0, 84.0, 79.0, 73.0, 67.0, 84.0, 153.0, 0.0, 34.0, 33.0, 122.0, 43.0, 0.0, 1.0, 0.0, 129.0, 78.0, 0.0, 90.0, 0.0, 3.0, 42.0, 13.0, 24.0, 0.0, 54.0, 65.0, 28.0, 0.0, 41.0, 33.0, 158.0, 98.0, 26.0, 159.0, 0.0, 0.0, 11.0, 2.0, 0.0, 6.0, 1.0, 18.0, 41.0, 0.0, 0.0, 0.0, 54.0, 28.0, 28.0, 0.0, 87.0, 8.0, 78.0, 99.0, 4.0, 67.0, 18.0, 57.0, 0.0, 42.0, 13.0, 111.0, 0.0, 6.0, 0.0, 0.0, 92.0, 101.0, 60.0, 19.0, 75.0, 27.0, 19.0, 110.0, 95.0, 0.0, 0.0, 20.0, 0.0, 125.0, 84.0, 131.0, 0.0, 106.0, 60.0, 0.0, 7.0, 14.0, 7.0, 63.0, 65.0, 1.0, 33.0, 88.0, 0.0, 0.0, 56.0, 38.0, 108.0, 15.0, 0.0, 28.0, 65.0, 46.0, 98.0, 0.0, 90.0, 101.0, 7.0, 55.0, 38.0, 119.0, 95.0, 41.0, 50.0, 0.0, 0.0, 0.0, 76.0, 132.0, 33.0, 123.0, 35.0, 0.0, 0.0, 76.0, 30.0, 0.0, 22.0, 0.0, 0.0, 0.0, 59.0, 72.0, 32.0, 2.0, 0.0, 165.0, 45.0, 44.0, 37.0, 158.0, 0.0, 97.0, 38.0, 55.0, 17.0, 9.0, 7.0, 19.0, 194.0, 26.0, 0.0, 57.0, 79.0, 0.0, 2.0, 5.0, 20.0, 10.0, 127.0, 150.0, 136.0, 138.0, 138.0, 93.0, 47.0, 98.0, 147.0, 96.0, 37.0, 0.0, 81.0, 80.0, 102.0, 95.0, 3.0, 55.0, 15.0, 200.0, 124.0, 108.0, 113.0, 60.0, 97.0, 0.0, 79.0, 78.0, 1.0, 28.0, 0.0, 35.0, 34.0, 0.0, 0.0, 64.0, 99.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5790752297654244, "mean_inference_ms": 1.4443228715952585, "mean_action_processing_ms": 0.23474112321962537, "mean_env_wait_ms": 0.20153185960294454, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004436612129211426, "StateBufferConnector_ms": 0.003477931022644043, "ViewRequirementAgentConnector_ms": 0.11503076553344727}, "num_episodes": 23, "episode_return_max": 373.9, "episode_return_min": -422.5999999999997, "episode_return_mean": 36.17999999999985, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 160000, "num_agent_steps_trained": 160000, "num_env_steps_sampled": 40000, "num_env_steps_trained": 40000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 363.23512081812737, "num_env_steps_trained_throughput_per_sec": 363.23512081812737, "timesteps_total": 40000, "num_env_steps_sampled_lifetime": 40000, "num_agent_steps_sampled_lifetime": 160000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 160000, "timers": {"training_iteration_time_ms": 10227.902, "restore_workers_time_ms": 0.018, "training_step_time_ms": 10227.851, "sample_time_ms": 1232.68, "learn_time_ms": 8976.045, "learn_throughput": 445.631, "synch_weights_time_ms": 16.285}, "counters": {"num_env_steps_sampled": 40000, "num_env_steps_trained": 40000, "num_agent_steps_sampled": 160000, "num_agent_steps_trained": 160000}, "done": false, "training_iteration": 10, "trial_id": "7f9b9_00000", "date": "2024-08-13_10-31-45", "timestamp": 1723559505, "time_this_iter_s": 11.040771961212158, "time_total_s": 102.77192306518555, "pid": 45656, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001414434352388078, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x31feefb80>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 102.77192306518555, "iterations_since_restore": 10, "perf": {"cpu_util_percent": 40.95, "ram_util_percent": 83.4125}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.4313546244114166, "cur_kl_coeff": 0.2, "cur_lr": 0.0014144343523880775, "total_loss": 5.173976501964387, "policy_loss": -0.005783734811105268, "vf_loss": 5.175997270478143, "vf_explained_var": -0.11781759892821943, "kl": 0.01881482142850559, "entropy": 1.4975873243241082, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 19845.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6630428210925804, "cur_kl_coeff": 0.2, "cur_lr": 0.0014144343523880775, "total_loss": 6.165409293250432, "policy_loss": -0.0055482151568251314, "vf_loss": 6.168556288058165, "vf_explained_var": -0.003204685922652956, "kl": 0.012006090157696808, "entropy": 1.4494547204365806, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 19845.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 44000, "num_env_steps_trained": 44000, "num_agent_steps_sampled": 176000, "num_agent_steps_trained": 176000}, "env_runners": {"episode_reward_max": 348.4000000000001, "episode_reward_min": -422.5999999999997, "episode_reward_mean": 20.835999999999853, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -395.8, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 186.5, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -39.952000000000034, "predator_policy": 50.37}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-166.40000000000003, 270.9, 180.89999999999904, 241.9999999999991, 143.3999999999994, 318.10000000000116, 165.09999999999994, 126.89999999999978, 135.99999999999963, 81.90000000000002, -25.0, 134.9, 71.80000000000005, 203.8999999999994, -102.49999999999982, 348.4000000000001, -156.30000000000132, -195.90000000000012, 49.100000000000044, 116.59999999999926, -56.199999999999775, 203.7999999999991, 17.999999999999975, -134.1000000000005, -32.40000000000014, 83.5999999999998, 33.20000000000026, 27.100000000000257, 18.600000000000115, 114.1999999999995, 24.200000000000045, 158.39999999999958, -14.699999999999948, 104.49999999999959, 33.3999999999999, 123.09999999999995, 104.19999999999975, -71.90000000000094, 207.99999999999957, -21.399999999999878, -31.299999999999883, 121.89999999999961, 49.99999999999956, -45.19999999999973, 66.9, 44.50000000000038, 39.80000000000019, -11.499999999999783, 47.20000000000029, 163.79999999999998, 7.4999999999996, 129.59999999999874, -100.40000000000009, 57.69999999999929, -66.0, -76.40000000000077, -8.599999999999921, 269.29999999999995, -388.0999999999991, 3.0000000000001483, -43.59999999999992, 73.79999999999978, 23.00000000000003, -65.39999999999986, -89.8000000000005, -176.9, 13.500000000000117, -124.50000000000003, -42.399999999999714, 33.70000000000022, -18.000000000000462, -96.30000000000115, -43.29999999999996, -422.5999999999997, -21.59999999999978, 45.20000000000019, 61.0999999999997, -93.10000000000093, 34.40000000000026, 113.49999999999919, 80.4999999999993, 1.4000000000000692, -146.20000000000041, -257.3000000000001, 15.599999999999921, -125.50000000000082, -2.999999999999941, -23.099999999999653, -93.70000000000039, 21.400000000000006, 94.99999999999949, 31.20000000000016, 30.300000000000317, 36.2000000000003, 46.000000000000384, -127.5000000000002, 40.0000000000003, 43.9000000000002, 93.49999999999878, 23.100000000000158], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-199.00000000000006, -126.4, 140.0, 119.89999999999998, 24.500000000000057, 154.39999999999975, 169.39999999999992, 65.6000000000001, 138.49999999999997, -54.1, 139.69999999999968, 178.39999999999998, 31.100000000000016, 79.99999999999994, 96.20000000000002, -25.299999999999784, -83.80000000000007, 132.7999999999997, -26.79999999999999, 22.699999999999978, -64.9, -63.099999999999994, -19.30000000000001, 69.20000000000002, -10.899999999999842, 25.699999999999996, 43.70000000000002, 105.19999999999942, -160.29999999999995, -53.20000000000003, 155.89999999999998, 186.5, -94.60000000000058, -153.70000000000056, -190.00000000000003, -166.90000000000006, -19.899999999999757, -25.0, 46.70000000000008, 23.900000000000084, -226.60000000000005, -34.59999999999975, 168.49999999999983, 35.300000000000146, 20.000000000000014, -21.999999999999744, -194.80000000000047, -148.30000000000004, -187.0, 23.60000000000015, -75.69999999999996, -6.699999999999967, 20.900000000000027, 5.299999999999996, 20.000000000000014, -13.900000000000041, 20.000000000000014, -129.4000000000002, 72.80000000000001, 7.399999999999994, 20.000000000000014, -83.79999999999997, 33.200000000000045, 69.19999999999993, 20.000000000000014, -180.70000000000005, 69.50000000000003, 20.000000000000014, -10.299999999999978, -49.29999999999998, -15.999999999999993, -4.899999999999999, 113.59999999999978, -99.39999999999995, -66.40000000000089, -113.50000000000006, 107.29999999999984, 7.700000000000003, -255.4, 20.000000000000014, 17.899999999999988, -140.20000000000016, 101.89999999999992, 20.000000000000014, 20.000000000000014, -45.999999999999986, -230.20000000000016, 20.000000000000014, -92.50000000000003, 1.4000000000000057, 20.000000000000014, 24.500000000000085, -86.19999999999995, 20.000000000000014, -17.799999999999834, -15.69999999999985, 27.200000000000145, 20.000000000000014, 11.599999999999701, 93.2, 74.89999999999942, -171.39999999999998, 107.59999999999951, 20.000000000000014, 20.000000000000014, -330.4, 26.300000000000118, -49.60000000000001, -254.5, 30.5, -178.90000000000035, -32.499999999999886, -15.699999999999882, -64.90000000000036, 162.19999999999996, 91.09999999999967, -308.8, -292.29999999999916, -9.39999999999989, -13.599999999999804, -51.40000000000005, -128.20000000000002, 53.900000000000226, 17.899999999999977, 20.000000000000014, -21.999999999999744, -222.4, 20.000000000000014, 20.000000000000014, -395.8, -217.2999999999999, -235.60000000000005, -149.20000000000022, 22.700000000000063, -158.50000000000003, -211.0, -9.099999999999898, -166.30000000000038, 2.299999999999973, -49.599999999999916, -136.6000000000001, -63.400000000000844, -169.60000000000053, -24.69999999999984, -87.10000000000073, -26.19999999999976, -390.69999999999993, -355.90000000000003, -241.60000000000002, -1.0000000000000204, -137.20000000000033, 25.400000000000098, 32.60000000000023, -50.499999999999986, -36.69999999999989, -135.40000000000057, -13.599999999999854, 20.000000000000014, 7.399999999999974, 37.09999999999985, 20.000000000000014, 60.50000000000022, -147.4, -14.19999999999981, -263.4999999999986, -135.70000000000005, -226.90000000000006, -252.4, -30.099999999999774, 13.699999999999964, -377.4999999999999, -1.0000000000000275, -91.60000000000082, -33.39999999999997, -207.10000000000045, 20.000000000000014, -206.80000000000015, -136.90000000000035, 20.000000000000014, -19.599999999999753, 20.000000000000014, 38.000000000000036, 3.1999999999999775, 20.000000000000014, 32.300000000000225, -97.00000000000074, -110.80000000000001, 20.000000000000014, 38.900000000000254, -142.90000000000052, -201.40000000000043, -162.09999999999994, 20.000000000000014, 20.000000000000014, -15.100000000000014, 20.000000000000014, 20.000000000000014, 57.49999999999952, 20.000000000000014, -121.9], "policy_predator_policy_reward": [159.0, 0.0, 0.0, 11.0, 2.0, 0.0, 6.0, 1.0, 18.0, 41.0, 0.0, 0.0, 0.0, 54.0, 28.0, 28.0, 0.0, 87.0, 8.0, 78.0, 99.0, 4.0, 67.0, 18.0, 57.0, 0.0, 42.0, 13.0, 111.0, 0.0, 6.0, 0.0, 0.0, 92.0, 101.0, 60.0, 19.0, 75.0, 27.0, 19.0, 110.0, 95.0, 0.0, 0.0, 20.0, 0.0, 125.0, 84.0, 131.0, 0.0, 106.0, 60.0, 0.0, 7.0, 14.0, 7.0, 63.0, 65.0, 1.0, 33.0, 88.0, 0.0, 0.0, 56.0, 38.0, 108.0, 15.0, 0.0, 28.0, 65.0, 46.0, 98.0, 0.0, 90.0, 101.0, 7.0, 55.0, 38.0, 119.0, 95.0, 41.0, 50.0, 0.0, 0.0, 0.0, 76.0, 132.0, 33.0, 123.0, 35.0, 0.0, 0.0, 76.0, 30.0, 0.0, 22.0, 0.0, 0.0, 0.0, 59.0, 72.0, 32.0, 2.0, 0.0, 165.0, 45.0, 44.0, 37.0, 158.0, 0.0, 97.0, 38.0, 55.0, 17.0, 9.0, 7.0, 19.0, 194.0, 26.0, 0.0, 57.0, 79.0, 0.0, 2.0, 5.0, 20.0, 10.0, 127.0, 150.0, 136.0, 138.0, 138.0, 93.0, 47.0, 98.0, 147.0, 96.0, 37.0, 0.0, 81.0, 80.0, 102.0, 95.0, 3.0, 55.0, 15.0, 200.0, 124.0, 108.0, 113.0, 60.0, 97.0, 0.0, 79.0, 78.0, 1.0, 28.0, 0.0, 35.0, 34.0, 0.0, 0.0, 64.0, 99.0, 83.0, 170.0, 37.0, 185.0, 0.0, 32.0, 106.0, 147.0, 40.0, 82.0, 66.0, 98.0, 101.0, 149.0, 0.0, 21.0, 18.0, 19.0, 0.0, 8.0, 46.0, 49.0, 77.0, 50.0, 64.0, 86.0, 157.0, 79.0, 0.0, 0.0, 7.0, 32.0, 8.0, 8.0, 54.0, 71.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5920543597746232, "mean_inference_ms": 1.4762924730417069, "mean_action_processing_ms": 0.23808671434705325, "mean_env_wait_ms": 0.20622948019509071, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004530668258666992, "StateBufferConnector_ms": 0.0035619735717773438, "ViewRequirementAgentConnector_ms": 0.11773145198822021}, "num_episodes": 18, "episode_return_max": 348.4000000000001, "episode_return_min": -422.5999999999997, "episode_return_mean": 20.835999999999853, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 176000, "num_agent_steps_trained": 176000, "num_env_steps_sampled": 44000, "num_env_steps_trained": 44000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 357.15494421827617, "num_env_steps_trained_throughput_per_sec": 357.15494421827617, "timesteps_total": 44000, "num_env_steps_sampled_lifetime": 44000, "num_agent_steps_sampled_lifetime": 176000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 176000, "timers": {"training_iteration_time_ms": 10237.664, "restore_workers_time_ms": 0.017, "training_step_time_ms": 10237.614, "sample_time_ms": 1232.866, "learn_time_ms": 8984.36, "learn_throughput": 445.218, "synch_weights_time_ms": 17.627}, "counters": {"num_env_steps_sampled": 44000, "num_env_steps_trained": 44000, "num_agent_steps_sampled": 176000, "num_agent_steps_trained": 176000}, "done": false, "training_iteration": 11, "trial_id": "7f9b9_00000", "date": "2024-08-13_10-31-57", "timestamp": 1723559517, "time_this_iter_s": 11.235789060592651, "time_total_s": 114.0077121257782, "pid": 45656, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001414434352388078, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x31feef280>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 114.0077121257782, "iterations_since_restore": 11, "perf": {"cpu_util_percent": 41.53125, "ram_util_percent": 83.175}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.506332619070376, "cur_kl_coeff": 0.2, "cur_lr": 0.0014144343523880775, "total_loss": 4.323015963463556, "policy_loss": -0.0066696902273823975, "vf_loss": 4.326180396635066, "vf_explained_var": -0.0836249741612288, "kl": 0.01752630596220633, "entropy": 1.4738743991448136, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 21735.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5813979398084697, "cur_kl_coeff": 0.2, "cur_lr": 0.0014144343523880775, "total_loss": 4.578789194551095, "policy_loss": -0.006932367652866536, "vf_loss": 4.583412075295019, "vf_explained_var": 0.0020342708895446132, "kl": 0.011547434260018197, "entropy": 1.4384778064394754, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 21735.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 48000, "num_env_steps_trained": 48000, "num_agent_steps_sampled": 192000, "num_agent_steps_trained": 192000}, "env_runners": {"episode_reward_max": 269.29999999999995, "episode_reward_min": -422.5999999999997, "episode_reward_mean": 5.055999999999863, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -395.8, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 168.49999999999983, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -49.267000000000024, "predator_policy": 51.795}, "custom_metrics": {}, "hist_stats": {"episode_reward": [49.100000000000044, 116.59999999999926, -56.199999999999775, 203.7999999999991, 17.999999999999975, -134.1000000000005, -32.40000000000014, 83.5999999999998, 33.20000000000026, 27.100000000000257, 18.600000000000115, 114.1999999999995, 24.200000000000045, 158.39999999999958, -14.699999999999948, 104.49999999999959, 33.3999999999999, 123.09999999999995, 104.19999999999975, -71.90000000000094, 207.99999999999957, -21.399999999999878, -31.299999999999883, 121.89999999999961, 49.99999999999956, -45.19999999999973, 66.9, 44.50000000000038, 39.80000000000019, -11.499999999999783, 47.20000000000029, 163.79999999999998, 7.4999999999996, 129.59999999999874, -100.40000000000009, 57.69999999999929, -66.0, -76.40000000000077, -8.599999999999921, 269.29999999999995, -388.0999999999991, 3.0000000000001483, -43.59999999999992, 73.79999999999978, 23.00000000000003, -65.39999999999986, -89.8000000000005, -176.9, 13.500000000000117, -124.50000000000003, -42.399999999999714, 33.70000000000022, -18.000000000000462, -96.30000000000115, -43.29999999999996, -422.5999999999997, -21.59999999999978, 45.20000000000019, 61.0999999999997, -93.10000000000093, 34.40000000000026, 113.49999999999919, 80.4999999999993, 1.4000000000000692, -146.20000000000041, -257.3000000000001, 15.599999999999921, -125.50000000000082, -2.999999999999941, -23.099999999999653, -93.70000000000039, 21.400000000000006, 94.99999999999949, 31.20000000000016, 30.300000000000317, 36.2000000000003, 46.000000000000384, -127.5000000000002, 40.0000000000003, 43.9000000000002, 93.49999999999878, 23.100000000000158, 94.29999999999941, 4.599999999999961, -116.90000000000023, -102.4000000000012, 94.6999999999995, 117.69999999999989, 40.0000000000003, -38.99999999999967, 6.9000000000001, 40.0000000000003, 72.99999999999996, 10.300000000000066, -108.30000000000118, -18.89999999999955, 58.39999999999976, -5.900000000000011, -54.999999999999766, 106.59999999999944], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-19.899999999999757, -25.0, 46.70000000000008, 23.900000000000084, -226.60000000000005, -34.59999999999975, 168.49999999999983, 35.300000000000146, 20.000000000000014, -21.999999999999744, -194.80000000000047, -148.30000000000004, -187.0, 23.60000000000015, -75.69999999999996, -6.699999999999967, 20.900000000000027, 5.299999999999996, 20.000000000000014, -13.900000000000041, 20.000000000000014, -129.4000000000002, 72.80000000000001, 7.399999999999994, 20.000000000000014, -83.79999999999997, 33.200000000000045, 69.19999999999993, 20.000000000000014, -180.70000000000005, 69.50000000000003, 20.000000000000014, -10.299999999999978, -49.29999999999998, -15.999999999999993, -4.899999999999999, 113.59999999999978, -99.39999999999995, -66.40000000000089, -113.50000000000006, 107.29999999999984, 7.700000000000003, -255.4, 20.000000000000014, 17.899999999999988, -140.20000000000016, 101.89999999999992, 20.000000000000014, 20.000000000000014, -45.999999999999986, -230.20000000000016, 20.000000000000014, -92.50000000000003, 1.4000000000000057, 20.000000000000014, 24.500000000000085, -86.19999999999995, 20.000000000000014, -17.799999999999834, -15.69999999999985, 27.200000000000145, 20.000000000000014, 11.599999999999701, 93.2, 74.89999999999942, -171.39999999999998, 107.59999999999951, 20.000000000000014, 20.000000000000014, -330.4, 26.300000000000118, -49.60000000000001, -254.5, 30.5, -178.90000000000035, -32.499999999999886, -15.699999999999882, -64.90000000000036, 162.19999999999996, 91.09999999999967, -308.8, -292.29999999999916, -9.39999999999989, -13.599999999999804, -51.40000000000005, -128.20000000000002, 53.900000000000226, 17.899999999999977, 20.000000000000014, -21.999999999999744, -222.4, 20.000000000000014, 20.000000000000014, -395.8, -217.2999999999999, -235.60000000000005, -149.20000000000022, 22.700000000000063, -158.50000000000003, -211.0, -9.099999999999898, -166.30000000000038, 2.299999999999973, -49.599999999999916, -136.6000000000001, -63.400000000000844, -169.60000000000053, -24.69999999999984, -87.10000000000073, -26.19999999999976, -390.69999999999993, -355.90000000000003, -241.60000000000002, -1.0000000000000204, -137.20000000000033, 25.400000000000098, 32.60000000000023, -50.499999999999986, -36.69999999999989, -135.40000000000057, -13.599999999999854, 20.000000000000014, 7.399999999999974, 37.09999999999985, 20.000000000000014, 60.50000000000022, -147.4, -14.19999999999981, -263.4999999999986, -135.70000000000005, -226.90000000000006, -252.4, -30.099999999999774, 13.699999999999964, -377.4999999999999, -1.0000000000000275, -91.60000000000082, -33.39999999999997, -207.10000000000045, 20.000000000000014, -206.80000000000015, -136.90000000000035, 20.000000000000014, -19.599999999999753, 20.000000000000014, 38.000000000000036, 3.1999999999999775, 20.000000000000014, 32.300000000000225, -97.00000000000074, -110.80000000000001, 20.000000000000014, 38.900000000000254, -142.90000000000052, -201.40000000000043, -162.09999999999994, 20.000000000000014, 20.000000000000014, -15.100000000000014, 20.000000000000014, 20.000000000000014, 57.49999999999952, 20.000000000000014, -121.9, 25.70000000000011, -24.39999999999995, -203.20000000000033, 18.799999999999997, -84.99999999999997, -229.90000000000018, -145.30000000000055, -99.10000000000065, 77.59999999999991, -28.899999999999906, 72.5, 27.20000000000013, 20.000000000000014, 20.000000000000014, -261.69999999999925, 31.700000000000227, 20.000000000000014, -48.099999999999774, 20.000000000000014, 20.000000000000014, 9.499999999999973, 30.500000000000085, 20.000000000000014, -36.699999999999754, -187.90000000000046, -30.399999999999785, -46.59999999999981, -28.29999999999975, -7.599999999999962, 20.000000000000014, 20.000000000000014, -88.90000000000032, -195.70000000000022, -43.299999999999784, 41.600000000000065, 20.000000000000014], "policy_predator_policy_reward": [19.0, 75.0, 27.0, 19.0, 110.0, 95.0, 0.0, 0.0, 20.0, 0.0, 125.0, 84.0, 131.0, 0.0, 106.0, 60.0, 0.0, 7.0, 14.0, 7.0, 63.0, 65.0, 1.0, 33.0, 88.0, 0.0, 0.0, 56.0, 38.0, 108.0, 15.0, 0.0, 28.0, 65.0, 46.0, 98.0, 0.0, 90.0, 101.0, 7.0, 55.0, 38.0, 119.0, 95.0, 41.0, 50.0, 0.0, 0.0, 0.0, 76.0, 132.0, 33.0, 123.0, 35.0, 0.0, 0.0, 76.0, 30.0, 0.0, 22.0, 0.0, 0.0, 0.0, 59.0, 72.0, 32.0, 2.0, 0.0, 165.0, 45.0, 44.0, 37.0, 158.0, 0.0, 97.0, 38.0, 55.0, 17.0, 9.0, 7.0, 19.0, 194.0, 26.0, 0.0, 57.0, 79.0, 0.0, 2.0, 5.0, 20.0, 10.0, 127.0, 150.0, 136.0, 138.0, 138.0, 93.0, 47.0, 98.0, 147.0, 96.0, 37.0, 0.0, 81.0, 80.0, 102.0, 95.0, 3.0, 55.0, 15.0, 200.0, 124.0, 108.0, 113.0, 60.0, 97.0, 0.0, 79.0, 78.0, 1.0, 28.0, 0.0, 35.0, 34.0, 0.0, 0.0, 64.0, 99.0, 83.0, 170.0, 37.0, 185.0, 0.0, 32.0, 106.0, 147.0, 40.0, 82.0, 66.0, 98.0, 101.0, 149.0, 0.0, 21.0, 18.0, 19.0, 0.0, 8.0, 46.0, 49.0, 77.0, 50.0, 64.0, 86.0, 157.0, 79.0, 0.0, 0.0, 7.0, 32.0, 8.0, 8.0, 54.0, 71.0, 35.0, 58.0, 121.0, 68.0, 95.0, 103.0, 70.0, 72.0, 0.0, 46.0, 4.0, 14.0, 0.0, 0.0, 57.0, 134.0, 35.0, 0.0, 0.0, 0.0, 17.0, 16.0, 0.0, 27.0, 105.0, 5.0, 35.0, 21.0, 28.0, 18.0, 63.0, 0.0, 50.0, 134.0, 19.0, 26.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6056467323459583, "mean_inference_ms": 1.5095186162348566, "mean_action_processing_ms": 0.24171857101971042, "mean_env_wait_ms": 0.21101792289903762, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0046852827072143555, "StateBufferConnector_ms": 0.0036579370498657227, "ViewRequirementAgentConnector_ms": 0.12278366088867188}, "num_episodes": 18, "episode_return_max": 269.29999999999995, "episode_return_min": -422.5999999999997, "episode_return_mean": 5.055999999999863, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 192000, "num_agent_steps_trained": 192000, "num_env_steps_sampled": 48000, "num_env_steps_trained": 48000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 402.80082822678156, "num_env_steps_trained_throughput_per_sec": 402.80082822678156, "timesteps_total": 48000, "num_env_steps_sampled_lifetime": 48000, "num_agent_steps_sampled_lifetime": 192000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 192000, "timers": {"training_iteration_time_ms": 10286.845, "restore_workers_time_ms": 0.014, "training_step_time_ms": 10286.796, "sample_time_ms": 1244.735, "learn_time_ms": 9021.552, "learn_throughput": 443.383, "synch_weights_time_ms": 17.571}, "counters": {"num_env_steps_sampled": 48000, "num_env_steps_trained": 48000, "num_agent_steps_sampled": 192000, "num_agent_steps_trained": 192000}, "done": false, "training_iteration": 12, "trial_id": "7f9b9_00000", "date": "2024-08-13_10-32-07", "timestamp": 1723559527, "time_this_iter_s": 9.985880851745605, "time_total_s": 123.9935929775238, "pid": 45656, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001414434352388078, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x31fe89dc0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 123.9935929775238, "iterations_since_restore": 12, "perf": {"cpu_util_percent": 31.349999999999998, "ram_util_percent": 83.1}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8742974591318262, "cur_kl_coeff": 0.2, "cur_lr": 0.0014144343523880775, "total_loss": 3.891937670884309, "policy_loss": -0.0011332596841923616, "vf_loss": 3.8894317251033885, "vf_explained_var": 0.011295939847905799, "kl": 0.018196053988312193, "entropy": 1.4518129384076153, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 23625.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7121065343971605, "cur_kl_coeff": 0.2, "cur_lr": 0.0014144343523880775, "total_loss": 3.5936864817584, "policy_loss": -0.005016681188766761, "vf_loss": 3.5964459507553665, "vf_explained_var": 0.00645295469849198, "kl": 0.011286088100907228, "entropy": 1.4427298099275618, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 23625.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 52000, "num_env_steps_trained": 52000, "num_agent_steps_sampled": 208000, "num_agent_steps_trained": 208000}, "env_runners": {"episode_reward_max": 269.29999999999995, "episode_reward_min": -422.5999999999997, "episode_reward_mean": -2.657000000000121, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -395.8, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 162.19999999999996, "predator_policy": 278.0}, "policy_reward_mean": {"prey_policy": -52.69350000000004, "predator_policy": 51.365}, "custom_metrics": {}, "hist_stats": {"episode_reward": [104.19999999999975, -71.90000000000094, 207.99999999999957, -21.399999999999878, -31.299999999999883, 121.89999999999961, 49.99999999999956, -45.19999999999973, 66.9, 44.50000000000038, 39.80000000000019, -11.499999999999783, 47.20000000000029, 163.79999999999998, 7.4999999999996, 129.59999999999874, -100.40000000000009, 57.69999999999929, -66.0, -76.40000000000077, -8.599999999999921, 269.29999999999995, -388.0999999999991, 3.0000000000001483, -43.59999999999992, 73.79999999999978, 23.00000000000003, -65.39999999999986, -89.8000000000005, -176.9, 13.500000000000117, -124.50000000000003, -42.399999999999714, 33.70000000000022, -18.000000000000462, -96.30000000000115, -43.29999999999996, -422.5999999999997, -21.59999999999978, 45.20000000000019, 61.0999999999997, -93.10000000000093, 34.40000000000026, 113.49999999999919, 80.4999999999993, 1.4000000000000692, -146.20000000000041, -257.3000000000001, 15.599999999999921, -125.50000000000082, -2.999999999999941, -23.099999999999653, -93.70000000000039, 21.400000000000006, 94.99999999999949, 31.20000000000016, 30.300000000000317, 36.2000000000003, 46.000000000000384, -127.5000000000002, 40.0000000000003, 43.9000000000002, 93.49999999999878, 23.100000000000158, 94.29999999999941, 4.599999999999961, -116.90000000000023, -102.4000000000012, 94.6999999999995, 117.69999999999989, 40.0000000000003, -38.99999999999967, 6.9000000000001, 40.0000000000003, 72.99999999999996, 10.300000000000066, -108.30000000000118, -18.89999999999955, 58.39999999999976, -5.900000000000011, -54.999999999999766, 106.59999999999944, -8.800000000000026, 46.60000000000009, -13.599999999999811, -305.5, 40.0000000000003, 81.29999999999909, 33.400000000000084, 56.800000000000196, 78.40000000000006, 15.000000000000025, 9.799999999999894, 105.09999999999917, -151.60000000000045, 72.29999999999983, -41.000000000000355, 10.799999999999994, 33.400000000000205, 36.70000000000025], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [113.59999999999978, -99.39999999999995, -66.40000000000089, -113.50000000000006, 107.29999999999984, 7.700000000000003, -255.4, 20.000000000000014, 17.899999999999988, -140.20000000000016, 101.89999999999992, 20.000000000000014, 20.000000000000014, -45.999999999999986, -230.20000000000016, 20.000000000000014, -92.50000000000003, 1.4000000000000057, 20.000000000000014, 24.500000000000085, -86.19999999999995, 20.000000000000014, -17.799999999999834, -15.69999999999985, 27.200000000000145, 20.000000000000014, 11.599999999999701, 93.2, 74.89999999999942, -171.39999999999998, 107.59999999999951, 20.000000000000014, 20.000000000000014, -330.4, 26.300000000000118, -49.60000000000001, -254.5, 30.5, -178.90000000000035, -32.499999999999886, -15.699999999999882, -64.90000000000036, 162.19999999999996, 91.09999999999967, -308.8, -292.29999999999916, -9.39999999999989, -13.599999999999804, -51.40000000000005, -128.20000000000002, 53.900000000000226, 17.899999999999977, 20.000000000000014, -21.999999999999744, -222.4, 20.000000000000014, 20.000000000000014, -395.8, -217.2999999999999, -235.60000000000005, -149.20000000000022, 22.700000000000063, -158.50000000000003, -211.0, -9.099999999999898, -166.30000000000038, 2.299999999999973, -49.599999999999916, -136.6000000000001, -63.400000000000844, -169.60000000000053, -24.69999999999984, -87.10000000000073, -26.19999999999976, -390.69999999999993, -355.90000000000003, -241.60000000000002, -1.0000000000000204, -137.20000000000033, 25.400000000000098, 32.60000000000023, -50.499999999999986, -36.69999999999989, -135.40000000000057, -13.599999999999854, 20.000000000000014, 7.399999999999974, 37.09999999999985, 20.000000000000014, 60.50000000000022, -147.4, -14.19999999999981, -263.4999999999986, -135.70000000000005, -226.90000000000006, -252.4, -30.099999999999774, 13.699999999999964, -377.4999999999999, -1.0000000000000275, -91.60000000000082, -33.39999999999997, -207.10000000000045, 20.000000000000014, -206.80000000000015, -136.90000000000035, 20.000000000000014, -19.599999999999753, 20.000000000000014, 38.000000000000036, 3.1999999999999775, 20.000000000000014, 32.300000000000225, -97.00000000000074, -110.80000000000001, 20.000000000000014, 38.900000000000254, -142.90000000000052, -201.40000000000043, -162.09999999999994, 20.000000000000014, 20.000000000000014, -15.100000000000014, 20.000000000000014, 20.000000000000014, 57.49999999999952, 20.000000000000014, -121.9, 25.70000000000011, -24.39999999999995, -203.20000000000033, 18.799999999999997, -84.99999999999997, -229.90000000000018, -145.30000000000055, -99.10000000000065, 77.59999999999991, -28.899999999999906, 72.5, 27.20000000000013, 20.000000000000014, 20.000000000000014, -261.69999999999925, 31.700000000000227, 20.000000000000014, -48.099999999999774, 20.000000000000014, 20.000000000000014, 9.499999999999973, 30.500000000000085, 20.000000000000014, -36.699999999999754, -187.90000000000046, -30.399999999999785, -46.59999999999981, -28.29999999999975, -7.599999999999962, 20.000000000000014, 20.000000000000014, -88.90000000000032, -195.70000000000022, -43.299999999999784, 41.600000000000065, 20.000000000000014, -19.89999999999982, -220.9, 20.000000000000014, -42.39999999999992, 29.90000000000018, -113.50000000000017, -209.39999999999998, -374.1, 20.000000000000014, 20.000000000000014, 52.70000000000014, 23.600000000000065, 15.799999999999963, -153.40000000000023, 20.000000000000014, -26.19999999999998, 91.69999999999989, -55.30000000000026, -83.80000000000025, -2.200000000000018, -148.59999999999997, 28.400000000000162, 91.99999999999983, 1.0999999999999865, -152.80000000000058, -122.80000000000032, 20.000000000000014, 32.300000000000175, -133.60000000000036, -60.40000000000043, -40.89999999999976, 13.699999999999966, 7.399999999999967, 20.000000000000014, 13.699999999999964, 20.000000000000014], "policy_predator_policy_reward": [0.0, 90.0, 101.0, 7.0, 55.0, 38.0, 119.0, 95.0, 41.0, 50.0, 0.0, 0.0, 0.0, 76.0, 132.0, 33.0, 123.0, 35.0, 0.0, 0.0, 76.0, 30.0, 0.0, 22.0, 0.0, 0.0, 0.0, 59.0, 72.0, 32.0, 2.0, 0.0, 165.0, 45.0, 44.0, 37.0, 158.0, 0.0, 97.0, 38.0, 55.0, 17.0, 9.0, 7.0, 19.0, 194.0, 26.0, 0.0, 57.0, 79.0, 0.0, 2.0, 5.0, 20.0, 10.0, 127.0, 150.0, 136.0, 138.0, 138.0, 93.0, 47.0, 98.0, 147.0, 96.0, 37.0, 0.0, 81.0, 80.0, 102.0, 95.0, 3.0, 55.0, 15.0, 200.0, 124.0, 108.0, 113.0, 60.0, 97.0, 0.0, 79.0, 78.0, 1.0, 28.0, 0.0, 35.0, 34.0, 0.0, 0.0, 64.0, 99.0, 83.0, 170.0, 37.0, 185.0, 0.0, 32.0, 106.0, 147.0, 40.0, 82.0, 66.0, 98.0, 101.0, 149.0, 0.0, 21.0, 18.0, 19.0, 0.0, 8.0, 46.0, 49.0, 77.0, 50.0, 64.0, 86.0, 157.0, 79.0, 0.0, 0.0, 7.0, 32.0, 8.0, 8.0, 54.0, 71.0, 35.0, 58.0, 121.0, 68.0, 95.0, 103.0, 70.0, 72.0, 0.0, 46.0, 4.0, 14.0, 0.0, 0.0, 57.0, 134.0, 35.0, 0.0, 0.0, 0.0, 17.0, 16.0, 0.0, 27.0, 105.0, 5.0, 35.0, 21.0, 28.0, 18.0, 63.0, 0.0, 50.0, 134.0, 19.0, 26.0, 125.0, 107.0, 36.0, 33.0, 14.0, 56.0, 0.0, 278.0, 0.0, 0.0, 5.0, 0.0, 95.0, 76.0, 55.0, 8.0, 0.0, 42.0, 34.0, 67.0, 106.0, 24.0, 11.0, 1.0, 42.0, 82.0, 11.0, 9.0, 56.0, 97.0, 10.0, 28.0, 6.0, 0.0, 3.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6168500513698496, "mean_inference_ms": 1.5376162876838044, "mean_action_processing_ms": 0.24445436783113522, "mean_env_wait_ms": 0.21495573206928392, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0045081377029418945, "StateBufferConnector_ms": 0.0036363601684570312, "ViewRequirementAgentConnector_ms": 0.12232720851898193}, "num_episodes": 18, "episode_return_max": 269.29999999999995, "episode_return_min": -422.5999999999997, "episode_return_mean": -2.657000000000121, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 208000, "num_agent_steps_trained": 208000, "num_env_steps_sampled": 52000, "num_env_steps_trained": 52000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 383.4265772925761, "num_env_steps_trained_throughput_per_sec": 383.4265772925761, "timesteps_total": 52000, "num_env_steps_sampled_lifetime": 52000, "num_agent_steps_sampled_lifetime": 208000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 208000, "timers": {"training_iteration_time_ms": 10387.392, "restore_workers_time_ms": 0.014, "training_step_time_ms": 10387.343, "sample_time_ms": 1248.35, "learn_time_ms": 9117.99, "learn_throughput": 438.693, "synch_weights_time_ms": 17.842}, "counters": {"num_env_steps_sampled": 52000, "num_env_steps_trained": 52000, "num_agent_steps_sampled": 208000, "num_agent_steps_trained": 208000}, "done": false, "training_iteration": 13, "trial_id": "7f9b9_00000", "date": "2024-08-13_10-32-17", "timestamp": 1723559537, "time_this_iter_s": 10.484172821044922, "time_total_s": 134.47776579856873, "pid": 45656, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001414434352388078, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x31fe9e3a0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 134.47776579856873, "iterations_since_restore": 13, "perf": {"cpu_util_percent": 34.88666666666666, "ram_util_percent": 83.15333333333335}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6363947306675886, "cur_kl_coeff": 0.2, "cur_lr": 0.0014144343523880775, "total_loss": 4.543165320315689, "policy_loss": -0.0004937335476772022, "vf_loss": 4.540226702336912, "vf_explained_var": 0.01695612079252011, "kl": 0.017161708543318565, "entropy": 1.399335251346467, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 25515.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5535690772470343, "cur_kl_coeff": 0.2, "cur_lr": 0.0014144343523880775, "total_loss": 3.298691158950644, "policy_loss": -0.008363069587254099, "vf_loss": 3.3044944121724082, "vf_explained_var": 0.0077163653714316235, "kl": 0.012799097677462196, "entropy": 1.4686915287895808, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 25515.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 56000, "num_env_steps_trained": 56000, "num_agent_steps_sampled": 224000, "num_agent_steps_trained": 224000}, "env_runners": {"episode_reward_max": 178.19999999999945, "episode_reward_min": -592.6999999999999, "episode_reward_mean": -14.66300000000005, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -596.6999999999999, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 138.79999999999978, "predator_policy": 523.0}, "policy_reward_mean": {"prey_policy": -57.46650000000003, "predator_policy": 50.135}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-65.39999999999986, -89.8000000000005, -176.9, 13.500000000000117, -124.50000000000003, -42.399999999999714, 33.70000000000022, -18.000000000000462, -96.30000000000115, -43.29999999999996, -422.5999999999997, -21.59999999999978, 45.20000000000019, 61.0999999999997, -93.10000000000093, 34.40000000000026, 113.49999999999919, 80.4999999999993, 1.4000000000000692, -146.20000000000041, -257.3000000000001, 15.599999999999921, -125.50000000000082, -2.999999999999941, -23.099999999999653, -93.70000000000039, 21.400000000000006, 94.99999999999949, 31.20000000000016, 30.300000000000317, 36.2000000000003, 46.000000000000384, -127.5000000000002, 40.0000000000003, 43.9000000000002, 93.49999999999878, 23.100000000000158, 94.29999999999941, 4.599999999999961, -116.90000000000023, -102.4000000000012, 94.6999999999995, 117.69999999999989, 40.0000000000003, -38.99999999999967, 6.9000000000001, 40.0000000000003, 72.99999999999996, 10.300000000000066, -108.30000000000118, -18.89999999999955, 58.39999999999976, -5.900000000000011, -54.999999999999766, 106.59999999999944, -8.800000000000026, 46.60000000000009, -13.599999999999811, -305.5, 40.0000000000003, 81.29999999999909, 33.400000000000084, 56.800000000000196, 78.40000000000006, 15.000000000000025, 9.799999999999894, 105.09999999999917, -151.60000000000045, 72.29999999999983, -41.000000000000355, 10.799999999999994, 33.400000000000205, 36.70000000000025, 8.099999999999993, 63.90000000000027, -113.6999999999999, 130.8999999999991, -269.0999999999998, 24.600000000000083, -310.19999999999914, -592.6999999999999, 40.0000000000003, -47.19999999999984, 35.10000000000023, 143.39999999999927, 51.70000000000049, -2.8999999999997446, 178.19999999999945, 37.80000000000027, -4.899999999999858, -29.599999999999948, 43.60000000000035, 30.70000000000016, -219.59999999999974, 49.50000000000046, 40.0000000000003, 40.0000000000003, 23.500000000000156, -40.49999999999965, 34.60000000000044], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-222.4, 20.000000000000014, 20.000000000000014, -395.8, -217.2999999999999, -235.60000000000005, -149.20000000000022, 22.700000000000063, -158.50000000000003, -211.0, -9.099999999999898, -166.30000000000038, 2.299999999999973, -49.599999999999916, -136.6000000000001, -63.400000000000844, -169.60000000000053, -24.69999999999984, -87.10000000000073, -26.19999999999976, -390.69999999999993, -355.90000000000003, -241.60000000000002, -1.0000000000000204, -137.20000000000033, 25.400000000000098, 32.60000000000023, -50.499999999999986, -36.69999999999989, -135.40000000000057, -13.599999999999854, 20.000000000000014, 7.399999999999974, 37.09999999999985, 20.000000000000014, 60.50000000000022, -147.4, -14.19999999999981, -263.4999999999986, -135.70000000000005, -226.90000000000006, -252.4, -30.099999999999774, 13.699999999999964, -377.4999999999999, -1.0000000000000275, -91.60000000000082, -33.39999999999997, -207.10000000000045, 20.000000000000014, -206.80000000000015, -136.90000000000035, 20.000000000000014, -19.599999999999753, 20.000000000000014, 38.000000000000036, 3.1999999999999775, 20.000000000000014, 32.300000000000225, -97.00000000000074, -110.80000000000001, 20.000000000000014, 38.900000000000254, -142.90000000000052, -201.40000000000043, -162.09999999999994, 20.000000000000014, 20.000000000000014, -15.100000000000014, 20.000000000000014, 20.000000000000014, 57.49999999999952, 20.000000000000014, -121.9, 25.70000000000011, -24.39999999999995, -203.20000000000033, 18.799999999999997, -84.99999999999997, -229.90000000000018, -145.30000000000055, -99.10000000000065, 77.59999999999991, -28.899999999999906, 72.5, 27.20000000000013, 20.000000000000014, 20.000000000000014, -261.69999999999925, 31.700000000000227, 20.000000000000014, -48.099999999999774, 20.000000000000014, 20.000000000000014, 9.499999999999973, 30.500000000000085, 20.000000000000014, -36.699999999999754, -187.90000000000046, -30.399999999999785, -46.59999999999981, -28.29999999999975, -7.599999999999962, 20.000000000000014, 20.000000000000014, -88.90000000000032, -195.70000000000022, -43.299999999999784, 41.600000000000065, 20.000000000000014, -19.89999999999982, -220.9, 20.000000000000014, -42.39999999999992, 29.90000000000018, -113.50000000000017, -209.39999999999998, -374.1, 20.000000000000014, 20.000000000000014, 52.70000000000014, 23.600000000000065, 15.799999999999963, -153.40000000000023, 20.000000000000014, -26.19999999999998, 91.69999999999989, -55.30000000000026, -83.80000000000025, -2.200000000000018, -148.59999999999997, 28.400000000000162, 91.99999999999983, 1.0999999999999865, -152.80000000000058, -122.80000000000032, 20.000000000000014, 32.300000000000175, -133.60000000000036, -60.40000000000043, -40.89999999999976, 13.699999999999966, 7.399999999999967, 20.000000000000014, 13.699999999999964, 20.000000000000014, -91.90000000000057, 20.000000000000014, 20.000000000000014, -3.09999999999993, -131.19999999999996, -74.50000000000004, 20.000000000000014, 110.89999999999984, -215.20000000000005, -166.90000000000003, -178.00000000000048, 56.60000000000014, -248.00000000000014, -239.2000000000002, -526.0, -596.6999999999999, 20.000000000000014, 20.000000000000014, -68.20000000000033, -42.999999999999886, 20.000000000000014, -40.89999999999976, -9.399999999999855, 138.79999999999978, 31.700000000000212, 20.000000000000014, 13.699999999999964, -55.60000000000031, 67.9999999999998, 99.2, 15.799999999999962, 20.000000000000014, -214.90000000000015, 20.000000000000014, -105.39999999999998, -80.20000000000084, 23.600000000000065, 20.000000000000014, 23.00000000000006, -7.299999999999891, -212.79999999999995, -200.79999999999995, 20.000000000000014, 27.50000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -53.499999999999865, 20.000000000000014, -155.50000000000054, 20.000000000000014, 41.60000000000022, -43.00000000000003], "policy_predator_policy_reward": [10.0, 127.0, 150.0, 136.0, 138.0, 138.0, 93.0, 47.0, 98.0, 147.0, 96.0, 37.0, 0.0, 81.0, 80.0, 102.0, 95.0, 3.0, 55.0, 15.0, 200.0, 124.0, 108.0, 113.0, 60.0, 97.0, 0.0, 79.0, 78.0, 1.0, 28.0, 0.0, 35.0, 34.0, 0.0, 0.0, 64.0, 99.0, 83.0, 170.0, 37.0, 185.0, 0.0, 32.0, 106.0, 147.0, 40.0, 82.0, 66.0, 98.0, 101.0, 149.0, 0.0, 21.0, 18.0, 19.0, 0.0, 8.0, 46.0, 49.0, 77.0, 50.0, 64.0, 86.0, 157.0, 79.0, 0.0, 0.0, 7.0, 32.0, 8.0, 8.0, 54.0, 71.0, 35.0, 58.0, 121.0, 68.0, 95.0, 103.0, 70.0, 72.0, 0.0, 46.0, 4.0, 14.0, 0.0, 0.0, 57.0, 134.0, 35.0, 0.0, 0.0, 0.0, 17.0, 16.0, 0.0, 27.0, 105.0, 5.0, 35.0, 21.0, 28.0, 18.0, 63.0, 0.0, 50.0, 134.0, 19.0, 26.0, 125.0, 107.0, 36.0, 33.0, 14.0, 56.0, 0.0, 278.0, 0.0, 0.0, 5.0, 0.0, 95.0, 76.0, 55.0, 8.0, 0.0, 42.0, 34.0, 67.0, 106.0, 24.0, 11.0, 1.0, 42.0, 82.0, 11.0, 9.0, 56.0, 97.0, 10.0, 28.0, 6.0, 0.0, 3.0, 0.0, 59.0, 21.0, 47.0, 0.0, 3.0, 89.0, 0.0, 0.0, 113.0, 0.0, 71.0, 75.0, 6.0, 171.0, 7.0, 523.0, 0.0, 0.0, 64.0, 0.0, 27.0, 29.0, 14.0, 0.0, 0.0, 0.0, 36.0, 3.0, 9.0, 2.0, 0.0, 2.0, 89.0, 101.0, 65.0, 91.0, 0.0, 0.0, 2.0, 13.0, 194.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 46.0, 11.0, 5.0, 90.0, 30.0, 6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.61591360971312, "mean_inference_ms": 1.544969278937431, "mean_action_processing_ms": 0.2458058556352436, "mean_env_wait_ms": 0.2159255570804813, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004113554954528809, "StateBufferConnector_ms": 0.0036339759826660156, "ViewRequirementAgentConnector_ms": 0.11011767387390137}, "num_episodes": 27, "episode_return_max": 178.19999999999945, "episode_return_min": -592.6999999999999, "episode_return_mean": -14.66300000000005, "episodes_this_iter": 27}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 224000, "num_agent_steps_trained": 224000, "num_env_steps_sampled": 56000, "num_env_steps_trained": 56000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 378.6296392394546, "num_env_steps_trained_throughput_per_sec": 378.6296392394546, "timesteps_total": 56000, "num_env_steps_sampled_lifetime": 56000, "num_agent_steps_sampled_lifetime": 224000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 224000, "timers": {"training_iteration_time_ms": 10461.712, "restore_workers_time_ms": 0.013, "training_step_time_ms": 10461.663, "sample_time_ms": 1290.581, "learn_time_ms": 9150.43, "learn_throughput": 437.138, "synch_weights_time_ms": 17.721}, "counters": {"num_env_steps_sampled": 56000, "num_env_steps_trained": 56000, "num_agent_steps_sampled": 224000, "num_agent_steps_trained": 224000}, "done": false, "training_iteration": 14, "trial_id": "7f9b9_00000", "date": "2024-08-13_10-32-28", "timestamp": 1723559548, "time_this_iter_s": 10.618464946746826, "time_total_s": 145.09623074531555, "pid": 45656, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001414434352388078, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x31ffa69d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 145.09623074531555, "iterations_since_restore": 14, "perf": {"cpu_util_percent": 37.78666666666666, "ram_util_percent": 83.42000000000002}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7048477752814217, "cur_kl_coeff": 0.2, "cur_lr": 0.0014144343523880775, "total_loss": 5.656642441144065, "policy_loss": 0.0005822665329096178, "vf_loss": 5.652730624385612, "vf_explained_var": 0.02720950990126877, "kl": 0.016647788347559086, "entropy": 1.4405751128676076, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 27405.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6230984666360119, "cur_kl_coeff": 0.2, "cur_lr": 0.0014144343523880775, "total_loss": 4.695059445421531, "policy_loss": -0.011250071569528213, "vf_loss": 4.702765185744674, "vf_explained_var": 0.007524358469342429, "kl": 0.017721651388764376, "entropy": 1.4780028382937114, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 27405.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 60000, "num_env_steps_trained": 60000, "num_agent_steps_sampled": 240000, "num_agent_steps_trained": 240000}, "env_runners": {"episode_reward_max": 178.19999999999945, "episode_reward_min": -592.6999999999999, "episode_reward_mean": -23.91400000000001, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -630.8, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 138.79999999999978, "predator_policy": 690.0}, "policy_reward_mean": {"prey_policy": -68.73200000000003, "predator_policy": 56.775}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.4000000000000692, -146.20000000000041, -257.3000000000001, 15.599999999999921, -125.50000000000082, -2.999999999999941, -23.099999999999653, -93.70000000000039, 21.400000000000006, 94.99999999999949, 31.20000000000016, 30.300000000000317, 36.2000000000003, 46.000000000000384, -127.5000000000002, 40.0000000000003, 43.9000000000002, 93.49999999999878, 23.100000000000158, 94.29999999999941, 4.599999999999961, -116.90000000000023, -102.4000000000012, 94.6999999999995, 117.69999999999989, 40.0000000000003, -38.99999999999967, 6.9000000000001, 40.0000000000003, 72.99999999999996, 10.300000000000066, -108.30000000000118, -18.89999999999955, 58.39999999999976, -5.900000000000011, -54.999999999999766, 106.59999999999944, -8.800000000000026, 46.60000000000009, -13.599999999999811, -305.5, 40.0000000000003, 81.29999999999909, 33.400000000000084, 56.800000000000196, 78.40000000000006, 15.000000000000025, 9.799999999999894, 105.09999999999917, -151.60000000000045, 72.29999999999983, -41.000000000000355, 10.799999999999994, 33.400000000000205, 36.70000000000025, 8.099999999999993, 63.90000000000027, -113.6999999999999, 130.8999999999991, -269.0999999999998, 24.600000000000083, -310.19999999999914, -592.6999999999999, 40.0000000000003, -47.19999999999984, 35.10000000000023, 143.39999999999927, 51.70000000000049, -2.8999999999997446, 178.19999999999945, 37.80000000000027, -4.899999999999858, -29.599999999999948, 43.60000000000035, 30.70000000000016, -219.59999999999974, 49.50000000000046, 40.0000000000003, 40.0000000000003, 23.500000000000156, -40.49999999999965, 34.60000000000044, 38.10000000000034, -243.40000000000023, 113.39999999999931, 0.4000000000001219, 16.000000000000213, -54.49999999999973, -259.20000000000005, -414.5, 40.00000000000031, -273.40000000000003, -21.599999999999554, 40.0000000000003, 145.49999999999977, 22.300000000000033, -267.59999999999985, 72.7999999999998, -296.79999999999995, -394.5999999999999], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-147.4, -14.19999999999981, -263.4999999999986, -135.70000000000005, -226.90000000000006, -252.4, -30.099999999999774, 13.699999999999964, -377.4999999999999, -1.0000000000000275, -91.60000000000082, -33.39999999999997, -207.10000000000045, 20.000000000000014, -206.80000000000015, -136.90000000000035, 20.000000000000014, -19.599999999999753, 20.000000000000014, 38.000000000000036, 3.1999999999999775, 20.000000000000014, 32.300000000000225, -97.00000000000074, -110.80000000000001, 20.000000000000014, 38.900000000000254, -142.90000000000052, -201.40000000000043, -162.09999999999994, 20.000000000000014, 20.000000000000014, -15.100000000000014, 20.000000000000014, 20.000000000000014, 57.49999999999952, 20.000000000000014, -121.9, 25.70000000000011, -24.39999999999995, -203.20000000000033, 18.799999999999997, -84.99999999999997, -229.90000000000018, -145.30000000000055, -99.10000000000065, 77.59999999999991, -28.899999999999906, 72.5, 27.20000000000013, 20.000000000000014, 20.000000000000014, -261.69999999999925, 31.700000000000227, 20.000000000000014, -48.099999999999774, 20.000000000000014, 20.000000000000014, 9.499999999999973, 30.500000000000085, 20.000000000000014, -36.699999999999754, -187.90000000000046, -30.399999999999785, -46.59999999999981, -28.29999999999975, -7.599999999999962, 20.000000000000014, 20.000000000000014, -88.90000000000032, -195.70000000000022, -43.299999999999784, 41.600000000000065, 20.000000000000014, -19.89999999999982, -220.9, 20.000000000000014, -42.39999999999992, 29.90000000000018, -113.50000000000017, -209.39999999999998, -374.1, 20.000000000000014, 20.000000000000014, 52.70000000000014, 23.600000000000065, 15.799999999999963, -153.40000000000023, 20.000000000000014, -26.19999999999998, 91.69999999999989, -55.30000000000026, -83.80000000000025, -2.200000000000018, -148.59999999999997, 28.400000000000162, 91.99999999999983, 1.0999999999999865, -152.80000000000058, -122.80000000000032, 20.000000000000014, 32.300000000000175, -133.60000000000036, -60.40000000000043, -40.89999999999976, 13.699999999999966, 7.399999999999967, 20.000000000000014, 13.699999999999964, 20.000000000000014, -91.90000000000057, 20.000000000000014, 20.000000000000014, -3.09999999999993, -131.19999999999996, -74.50000000000004, 20.000000000000014, 110.89999999999984, -215.20000000000005, -166.90000000000003, -178.00000000000048, 56.60000000000014, -248.00000000000014, -239.2000000000002, -526.0, -596.6999999999999, 20.000000000000014, 20.000000000000014, -68.20000000000033, -42.999999999999886, 20.000000000000014, -40.89999999999976, -9.399999999999855, 138.79999999999978, 31.700000000000212, 20.000000000000014, 13.699999999999964, -55.60000000000031, 67.9999999999998, 99.2, 15.799999999999962, 20.000000000000014, -214.90000000000015, 20.000000000000014, -105.39999999999998, -80.20000000000084, 23.600000000000065, 20.000000000000014, 23.00000000000006, -7.299999999999891, -212.79999999999995, -200.79999999999995, 20.000000000000014, 27.50000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -53.499999999999865, 20.000000000000014, -155.50000000000054, 20.000000000000014, 41.60000000000022, -43.00000000000003, -19.899999999999828, 20.000000000000014, -157.00000000000026, -321.4, -5.1999999999999265, 83.59999999999982, -166.60000000000022, 20.000000000000014, 43.70000000000003, -294.7, -263.4999999999989, 20.000000000000014, -337.3, -214.90000000000003, -485.7, -630.8, -36.699999999999754, 49.70000000000023, -249.80000000000004, -229.60000000000005, 20.000000000000014, -97.6000000000008, 20.000000000000014, 20.000000000000014, 46.400000000000084, 82.10000000000005, -66.70000000000081, 20.000000000000014, -456.79999999999995, -316.8, 20.900000000000027, 26.900000000000144, -556.7, -297.1, -511.79999999999995, -446.8], "policy_predator_policy_reward": [64.0, 99.0, 83.0, 170.0, 37.0, 185.0, 0.0, 32.0, 106.0, 147.0, 40.0, 82.0, 66.0, 98.0, 101.0, 149.0, 0.0, 21.0, 18.0, 19.0, 0.0, 8.0, 46.0, 49.0, 77.0, 50.0, 64.0, 86.0, 157.0, 79.0, 0.0, 0.0, 7.0, 32.0, 8.0, 8.0, 54.0, 71.0, 35.0, 58.0, 121.0, 68.0, 95.0, 103.0, 70.0, 72.0, 0.0, 46.0, 4.0, 14.0, 0.0, 0.0, 57.0, 134.0, 35.0, 0.0, 0.0, 0.0, 17.0, 16.0, 0.0, 27.0, 105.0, 5.0, 35.0, 21.0, 28.0, 18.0, 63.0, 0.0, 50.0, 134.0, 19.0, 26.0, 125.0, 107.0, 36.0, 33.0, 14.0, 56.0, 0.0, 278.0, 0.0, 0.0, 5.0, 0.0, 95.0, 76.0, 55.0, 8.0, 0.0, 42.0, 34.0, 67.0, 106.0, 24.0, 11.0, 1.0, 42.0, 82.0, 11.0, 9.0, 56.0, 97.0, 10.0, 28.0, 6.0, 0.0, 3.0, 0.0, 59.0, 21.0, 47.0, 0.0, 3.0, 89.0, 0.0, 0.0, 113.0, 0.0, 71.0, 75.0, 6.0, 171.0, 7.0, 523.0, 0.0, 0.0, 64.0, 0.0, 27.0, 29.0, 14.0, 0.0, 0.0, 0.0, 36.0, 3.0, 9.0, 2.0, 0.0, 2.0, 89.0, 101.0, 65.0, 91.0, 0.0, 0.0, 2.0, 13.0, 194.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 46.0, 11.0, 5.0, 90.0, 30.0, 6.0, 4.0, 34.0, 140.0, 95.0, 20.0, 15.0, 51.0, 96.0, 229.0, 38.0, 97.0, 92.0, 0.0, 293.0, 12.0, 690.0, 0.0, 27.0, 206.0, 0.0, 56.0, 0.0, 0.0, 0.0, 5.0, 12.0, 23.0, 46.0, 0.0, 506.0, 13.0, 12.0, 387.0, 170.0, 558.0, 6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6193358044482151, "mean_inference_ms": 1.5594599533952078, "mean_action_processing_ms": 0.24679649687334623, "mean_env_wait_ms": 0.21786126833801567, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004100441932678223, "StateBufferConnector_ms": 0.004694819450378418, "ViewRequirementAgentConnector_ms": 0.1049032211303711}, "num_episodes": 18, "episode_return_max": 178.19999999999945, "episode_return_min": -592.6999999999999, "episode_return_mean": -23.91400000000001, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 240000, "num_agent_steps_trained": 240000, "num_env_steps_sampled": 60000, "num_env_steps_trained": 60000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 342.35237353536155, "num_env_steps_trained_throughput_per_sec": 342.35237353536155, "timesteps_total": 60000, "num_env_steps_sampled_lifetime": 60000, "num_agent_steps_sampled_lifetime": 240000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 240000, "timers": {"training_iteration_time_ms": 10685.905, "restore_workers_time_ms": 0.014, "training_step_time_ms": 10685.855, "sample_time_ms": 1353.087, "learn_time_ms": 9311.647, "learn_throughput": 429.57, "synch_weights_time_ms": 17.974}, "counters": {"num_env_steps_sampled": 60000, "num_env_steps_trained": 60000, "num_agent_steps_sampled": 240000, "num_agent_steps_trained": 240000}, "done": false, "training_iteration": 15, "trial_id": "7f9b9_00000", "date": "2024-08-13_10-32-40", "timestamp": 1723559560, "time_this_iter_s": 11.811191082000732, "time_total_s": 156.90742182731628, "pid": 45656, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001414434352388078, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x31fe9e700>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 156.90742182731628, "iterations_since_restore": 15, "perf": {"cpu_util_percent": 43.11176470588235, "ram_util_percent": 83.21176470588236}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8376179182655596, "cur_kl_coeff": 0.2, "cur_lr": 0.0014144343523880775, "total_loss": 6.319224420426384, "policy_loss": 0.0010949269614660394, "vf_loss": 6.314652012264918, "vf_explained_var": 0.09867702356721988, "kl": 0.01738739514293187, "entropy": 1.4536880440812894, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 29295.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6357774122918725, "cur_kl_coeff": 0.2, "cur_lr": 0.0014144343523880775, "total_loss": 4.4720223238859225, "policy_loss": -0.007467665624553485, "vf_loss": 4.4764092658562635, "vf_explained_var": 0.015215176596212639, "kl": 0.01540365403616099, "entropy": 1.4735856461146521, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 29295.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 64000, "num_env_steps_trained": 64000, "num_agent_steps_sampled": 256000, "num_agent_steps_trained": 256000}, "env_runners": {"episode_reward_max": 301.4000000000005, "episode_reward_min": -592.6999999999999, "episode_reward_mean": -22.174999999999986, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -748.2, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 138.79999999999978, "predator_policy": 690.0}, "policy_reward_mean": {"prey_policy": -80.40750000000001, "predator_policy": 69.32}, "custom_metrics": {}, "hist_stats": {"episode_reward": [23.100000000000158, 94.29999999999941, 4.599999999999961, -116.90000000000023, -102.4000000000012, 94.6999999999995, 117.69999999999989, 40.0000000000003, -38.99999999999967, 6.9000000000001, 40.0000000000003, 72.99999999999996, 10.300000000000066, -108.30000000000118, -18.89999999999955, 58.39999999999976, -5.900000000000011, -54.999999999999766, 106.59999999999944, -8.800000000000026, 46.60000000000009, -13.599999999999811, -305.5, 40.0000000000003, 81.29999999999909, 33.400000000000084, 56.800000000000196, 78.40000000000006, 15.000000000000025, 9.799999999999894, 105.09999999999917, -151.60000000000045, 72.29999999999983, -41.000000000000355, 10.799999999999994, 33.400000000000205, 36.70000000000025, 8.099999999999993, 63.90000000000027, -113.6999999999999, 130.8999999999991, -269.0999999999998, 24.600000000000083, -310.19999999999914, -592.6999999999999, 40.0000000000003, -47.19999999999984, 35.10000000000023, 143.39999999999927, 51.70000000000049, -2.8999999999997446, 178.19999999999945, 37.80000000000027, -4.899999999999858, -29.599999999999948, 43.60000000000035, 30.70000000000016, -219.59999999999974, 49.50000000000046, 40.0000000000003, 40.0000000000003, 23.500000000000156, -40.49999999999965, 34.60000000000044, 38.10000000000034, -243.40000000000023, 113.39999999999931, 0.4000000000001219, 16.000000000000213, -54.49999999999973, -259.20000000000005, -414.5, 40.00000000000031, -273.40000000000003, -21.599999999999554, 40.0000000000003, 145.49999999999977, 22.300000000000033, -267.59999999999985, 72.7999999999998, -296.79999999999995, -394.5999999999999, -18.599999999999746, 56.40000000000001, -195.2, -16.599999999999905, -16.99999999999956, -221.49999999999972, 23.500000000000277, 301.4000000000005, 127.39999999999938, 69.3000000000001, 77.99999999999923, -499.4999999999999, 116.19999999999955, -189.80000000000018, 42.10000000000036, 129.99999999999972, 40.0000000000003, 26.00000000000022], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, -121.9, 25.70000000000011, -24.39999999999995, -203.20000000000033, 18.799999999999997, -84.99999999999997, -229.90000000000018, -145.30000000000055, -99.10000000000065, 77.59999999999991, -28.899999999999906, 72.5, 27.20000000000013, 20.000000000000014, 20.000000000000014, -261.69999999999925, 31.700000000000227, 20.000000000000014, -48.099999999999774, 20.000000000000014, 20.000000000000014, 9.499999999999973, 30.500000000000085, 20.000000000000014, -36.699999999999754, -187.90000000000046, -30.399999999999785, -46.59999999999981, -28.29999999999975, -7.599999999999962, 20.000000000000014, 20.000000000000014, -88.90000000000032, -195.70000000000022, -43.299999999999784, 41.600000000000065, 20.000000000000014, -19.89999999999982, -220.9, 20.000000000000014, -42.39999999999992, 29.90000000000018, -113.50000000000017, -209.39999999999998, -374.1, 20.000000000000014, 20.000000000000014, 52.70000000000014, 23.600000000000065, 15.799999999999963, -153.40000000000023, 20.000000000000014, -26.19999999999998, 91.69999999999989, -55.30000000000026, -83.80000000000025, -2.200000000000018, -148.59999999999997, 28.400000000000162, 91.99999999999983, 1.0999999999999865, -152.80000000000058, -122.80000000000032, 20.000000000000014, 32.300000000000175, -133.60000000000036, -60.40000000000043, -40.89999999999976, 13.699999999999966, 7.399999999999967, 20.000000000000014, 13.699999999999964, 20.000000000000014, -91.90000000000057, 20.000000000000014, 20.000000000000014, -3.09999999999993, -131.19999999999996, -74.50000000000004, 20.000000000000014, 110.89999999999984, -215.20000000000005, -166.90000000000003, -178.00000000000048, 56.60000000000014, -248.00000000000014, -239.2000000000002, -526.0, -596.6999999999999, 20.000000000000014, 20.000000000000014, -68.20000000000033, -42.999999999999886, 20.000000000000014, -40.89999999999976, -9.399999999999855, 138.79999999999978, 31.700000000000212, 20.000000000000014, 13.699999999999964, -55.60000000000031, 67.9999999999998, 99.2, 15.799999999999962, 20.000000000000014, -214.90000000000015, 20.000000000000014, -105.39999999999998, -80.20000000000084, 23.600000000000065, 20.000000000000014, 23.00000000000006, -7.299999999999891, -212.79999999999995, -200.79999999999995, 20.000000000000014, 27.50000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -53.499999999999865, 20.000000000000014, -155.50000000000054, 20.000000000000014, 41.60000000000022, -43.00000000000003, -19.899999999999828, 20.000000000000014, -157.00000000000026, -321.4, -5.1999999999999265, 83.59999999999982, -166.60000000000022, 20.000000000000014, 43.70000000000003, -294.7, -263.4999999999989, 20.000000000000014, -337.3, -214.90000000000003, -485.7, -630.8, -36.699999999999754, 49.70000000000023, -249.80000000000004, -229.60000000000005, 20.000000000000014, -97.6000000000008, 20.000000000000014, 20.000000000000014, 46.400000000000084, 82.10000000000005, -66.70000000000081, 20.000000000000014, -456.79999999999995, -316.8, 20.900000000000027, 26.900000000000144, -556.7, -297.1, -511.79999999999995, -446.8, -154.60000000000022, 20.000000000000014, 91.09999999999994, -272.70000000000005, -456.7, -110.49999999999997, -529.0999999999999, 84.49999999999969, 20.90000000000003, -115.90000000000074, -217.8999999999999, -263.59999999999985, -11.500000000000007, 20.000000000000014, 117.19999999999965, -730.8, 108.19999999999979, -2.800000000000045, -64.00000000000045, 23.300000000000022, -128.00000000000006, 67.99999999999974, -617.6999999999999, -567.8, 90.1999999999999, 20.000000000000014, -748.2, -600.6000000000001, 31.400000000000176, -55.30000000000005, 20.000000000000014, 92.00000000000003, 20.000000000000014, 20.000000000000014, 31.700000000000212, -75.70000000000022], "policy_predator_policy_reward": [54.0, 71.0, 35.0, 58.0, 121.0, 68.0, 95.0, 103.0, 70.0, 72.0, 0.0, 46.0, 4.0, 14.0, 0.0, 0.0, 57.0, 134.0, 35.0, 0.0, 0.0, 0.0, 17.0, 16.0, 0.0, 27.0, 105.0, 5.0, 35.0, 21.0, 28.0, 18.0, 63.0, 0.0, 50.0, 134.0, 19.0, 26.0, 125.0, 107.0, 36.0, 33.0, 14.0, 56.0, 0.0, 278.0, 0.0, 0.0, 5.0, 0.0, 95.0, 76.0, 55.0, 8.0, 0.0, 42.0, 34.0, 67.0, 106.0, 24.0, 11.0, 1.0, 42.0, 82.0, 11.0, 9.0, 56.0, 97.0, 10.0, 28.0, 6.0, 0.0, 3.0, 0.0, 59.0, 21.0, 47.0, 0.0, 3.0, 89.0, 0.0, 0.0, 113.0, 0.0, 71.0, 75.0, 6.0, 171.0, 7.0, 523.0, 0.0, 0.0, 64.0, 0.0, 27.0, 29.0, 14.0, 0.0, 0.0, 0.0, 36.0, 3.0, 9.0, 2.0, 0.0, 2.0, 89.0, 101.0, 65.0, 91.0, 0.0, 0.0, 2.0, 13.0, 194.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 46.0, 11.0, 5.0, 90.0, 30.0, 6.0, 4.0, 34.0, 140.0, 95.0, 20.0, 15.0, 51.0, 96.0, 229.0, 38.0, 97.0, 92.0, 0.0, 293.0, 12.0, 690.0, 0.0, 27.0, 206.0, 0.0, 56.0, 0.0, 0.0, 0.0, 5.0, 12.0, 23.0, 46.0, 0.0, 506.0, 13.0, 12.0, 387.0, 170.0, 558.0, 6.0, 30.0, 86.0, 0.0, 238.0, 36.0, 336.0, 421.0, 7.0, 12.0, 66.0, 260.0, 0.0, 0.0, 15.0, 470.0, 445.0, 12.0, 10.0, 45.0, 65.0, 112.0, 26.0, 0.0, 686.0, 6.0, 0.0, 631.0, 528.0, 20.0, 46.0, 4.0, 14.0, 0.0, 0.0, 70.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6251109722406757, "mean_inference_ms": 1.5793243946035245, "mean_action_processing_ms": 0.2488720127620287, "mean_env_wait_ms": 0.22044630464278903, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004153013229370117, "StateBufferConnector_ms": 0.004740476608276367, "ViewRequirementAgentConnector_ms": 0.10770297050476074}, "num_episodes": 18, "episode_return_max": 301.4000000000005, "episode_return_min": -592.6999999999999, "episode_return_mean": -22.174999999999986, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 256000, "num_agent_steps_trained": 256000, "num_env_steps_sampled": 64000, "num_env_steps_trained": 64000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 342.1631443949649, "num_env_steps_trained_throughput_per_sec": 342.1631443949649, "timesteps_total": 64000, "num_env_steps_sampled_lifetime": 64000, "num_agent_steps_sampled_lifetime": 256000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 256000, "timers": {"training_iteration_time_ms": 10893.956, "restore_workers_time_ms": 0.014, "training_step_time_ms": 10893.903, "sample_time_ms": 1440.064, "learn_time_ms": 9432.93, "learn_throughput": 424.046, "synch_weights_time_ms": 18.132}, "counters": {"num_env_steps_sampled": 64000, "num_env_steps_trained": 64000, "num_agent_steps_sampled": 256000, "num_agent_steps_trained": 256000}, "done": false, "training_iteration": 16, "trial_id": "7f9b9_00000", "date": "2024-08-13_10-32-52", "timestamp": 1723559572, "time_this_iter_s": 11.724781036376953, "time_total_s": 168.63220286369324, "pid": 45656, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001414434352388078, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x31fe89dc0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 168.63220286369324, "iterations_since_restore": 16, "perf": {"cpu_util_percent": 45.40625, "ram_util_percent": 83.5375}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7690560286322599, "cur_kl_coeff": 0.2, "cur_lr": 0.0014144343523880775, "total_loss": 8.12517686117263, "policy_loss": 0.0011999240849738715, "vf_loss": 8.1203354943997, "vf_explained_var": 0.13231075484916646, "kl": 0.0182072547715772, "entropy": 1.4389586536341874, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 31185.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6611569924960061, "cur_kl_coeff": 0.2, "cur_lr": 0.0014144343523880775, "total_loss": 5.936138510577893, "policy_loss": -0.007374791920470892, "vf_loss": 5.940430959570345, "vf_explained_var": 0.010870034890200095, "kl": 0.01541167629604975, "entropy": 1.4524566285193912, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 31185.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 68000, "num_env_steps_trained": 68000, "num_agent_steps_sampled": 272000, "num_agent_steps_trained": 272000}, "env_runners": {"episode_reward_max": 301.4000000000005, "episode_reward_min": -592.6999999999999, "episode_reward_mean": -33.686999999999955, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -794.5, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 138.79999999999978, "predator_policy": 861.0}, "policy_reward_mean": {"prey_policy": -101.35850000000003, "predator_policy": 84.515}, "custom_metrics": {}, "hist_stats": {"episode_reward": [106.59999999999944, -8.800000000000026, 46.60000000000009, -13.599999999999811, -305.5, 40.0000000000003, 81.29999999999909, 33.400000000000084, 56.800000000000196, 78.40000000000006, 15.000000000000025, 9.799999999999894, 105.09999999999917, -151.60000000000045, 72.29999999999983, -41.000000000000355, 10.799999999999994, 33.400000000000205, 36.70000000000025, 8.099999999999993, 63.90000000000027, -113.6999999999999, 130.8999999999991, -269.0999999999998, 24.600000000000083, -310.19999999999914, -592.6999999999999, 40.0000000000003, -47.19999999999984, 35.10000000000023, 143.39999999999927, 51.70000000000049, -2.8999999999997446, 178.19999999999945, 37.80000000000027, -4.899999999999858, -29.599999999999948, 43.60000000000035, 30.70000000000016, -219.59999999999974, 49.50000000000046, 40.0000000000003, 40.0000000000003, 23.500000000000156, -40.49999999999965, 34.60000000000044, 38.10000000000034, -243.40000000000023, 113.39999999999931, 0.4000000000001219, 16.000000000000213, -54.49999999999973, -259.20000000000005, -414.5, 40.00000000000031, -273.40000000000003, -21.599999999999554, 40.0000000000003, 145.49999999999977, 22.300000000000033, -267.59999999999985, 72.7999999999998, -296.79999999999995, -394.5999999999999, -18.599999999999746, 56.40000000000001, -195.2, -16.599999999999905, -16.99999999999956, -221.49999999999972, 23.500000000000277, 301.4000000000005, 127.39999999999938, 69.3000000000001, 77.99999999999923, -499.4999999999999, 116.19999999999955, -189.80000000000018, 42.10000000000036, 129.99999999999972, 40.0000000000003, 26.00000000000022, 29.900000000000244, 59.50000000000003, -48.69999999999981, -470.69999999999993, -49.7999999999999, 5.799999999999786, 48.100000000000435, -90.7, -197.6000000000003, -514.6999999999996, -222.99999999999986, 102.49999999999989, -144.2, -4.400000000000058, 47.900000000000425, 170.0999999999992, 214.59999999999982, 30.800000000000004], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [41.600000000000065, 20.000000000000014, -19.89999999999982, -220.9, 20.000000000000014, -42.39999999999992, 29.90000000000018, -113.50000000000017, -209.39999999999998, -374.1, 20.000000000000014, 20.000000000000014, 52.70000000000014, 23.600000000000065, 15.799999999999963, -153.40000000000023, 20.000000000000014, -26.19999999999998, 91.69999999999989, -55.30000000000026, -83.80000000000025, -2.200000000000018, -148.59999999999997, 28.400000000000162, 91.99999999999983, 1.0999999999999865, -152.80000000000058, -122.80000000000032, 20.000000000000014, 32.300000000000175, -133.60000000000036, -60.40000000000043, -40.89999999999976, 13.699999999999966, 7.399999999999967, 20.000000000000014, 13.699999999999964, 20.000000000000014, -91.90000000000057, 20.000000000000014, 20.000000000000014, -3.09999999999993, -131.19999999999996, -74.50000000000004, 20.000000000000014, 110.89999999999984, -215.20000000000005, -166.90000000000003, -178.00000000000048, 56.60000000000014, -248.00000000000014, -239.2000000000002, -526.0, -596.6999999999999, 20.000000000000014, 20.000000000000014, -68.20000000000033, -42.999999999999886, 20.000000000000014, -40.89999999999976, -9.399999999999855, 138.79999999999978, 31.700000000000212, 20.000000000000014, 13.699999999999964, -55.60000000000031, 67.9999999999998, 99.2, 15.799999999999962, 20.000000000000014, -214.90000000000015, 20.000000000000014, -105.39999999999998, -80.20000000000084, 23.600000000000065, 20.000000000000014, 23.00000000000006, -7.299999999999891, -212.79999999999995, -200.79999999999995, 20.000000000000014, 27.50000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -53.499999999999865, 20.000000000000014, -155.50000000000054, 20.000000000000014, 41.60000000000022, -43.00000000000003, -19.899999999999828, 20.000000000000014, -157.00000000000026, -321.4, -5.1999999999999265, 83.59999999999982, -166.60000000000022, 20.000000000000014, 43.70000000000003, -294.7, -263.4999999999989, 20.000000000000014, -337.3, -214.90000000000003, -485.7, -630.8, -36.699999999999754, 49.70000000000023, -249.80000000000004, -229.60000000000005, 20.000000000000014, -97.6000000000008, 20.000000000000014, 20.000000000000014, 46.400000000000084, 82.10000000000005, -66.70000000000081, 20.000000000000014, -456.79999999999995, -316.8, 20.900000000000027, 26.900000000000144, -556.7, -297.1, -511.79999999999995, -446.8, -154.60000000000022, 20.000000000000014, 91.09999999999994, -272.70000000000005, -456.7, -110.49999999999997, -529.0999999999999, 84.49999999999969, 20.90000000000003, -115.90000000000074, -217.8999999999999, -263.59999999999985, -11.500000000000007, 20.000000000000014, 117.19999999999965, -730.8, 108.19999999999979, -2.800000000000045, -64.00000000000045, 23.300000000000022, -128.00000000000006, 67.99999999999974, -617.6999999999999, -567.8, 90.1999999999999, 20.000000000000014, -748.2, -600.6000000000001, 31.400000000000176, -55.30000000000005, 20.000000000000014, 92.00000000000003, 20.000000000000014, 20.000000000000014, 31.700000000000212, -75.70000000000022, 20.000000000000014, -30.099999999999774, 76.69999999999997, -119.20000000000016, 3.200000000000003, -424.9, -627.8, -463.9, -625.8, 92.00000000000009, -565.9, 19.700000000000074, 20.000000000000014, 28.100000000000147, -409.2, -74.49999999999994, -167.50000000000003, -192.1000000000002, -581.1999999999995, -794.5, -329.10000000000025, -171.89999999999998, 81.80000000000008, 13.699999999999964, -36.700000000000024, -540.5, -4.899999999999984, -194.50000000000006, 26.900000000000126, 20.000000000000014, 113.89999999999995, 45.20000000000017, 71.29999999999993, 134.29999999999998, -59.800000000000466, 17.599999999999984], "policy_predator_policy_reward": [19.0, 26.0, 125.0, 107.0, 36.0, 33.0, 14.0, 56.0, 0.0, 278.0, 0.0, 0.0, 5.0, 0.0, 95.0, 76.0, 55.0, 8.0, 0.0, 42.0, 34.0, 67.0, 106.0, 24.0, 11.0, 1.0, 42.0, 82.0, 11.0, 9.0, 56.0, 97.0, 10.0, 28.0, 6.0, 0.0, 3.0, 0.0, 59.0, 21.0, 47.0, 0.0, 3.0, 89.0, 0.0, 0.0, 113.0, 0.0, 71.0, 75.0, 6.0, 171.0, 7.0, 523.0, 0.0, 0.0, 64.0, 0.0, 27.0, 29.0, 14.0, 0.0, 0.0, 0.0, 36.0, 3.0, 9.0, 2.0, 0.0, 2.0, 89.0, 101.0, 65.0, 91.0, 0.0, 0.0, 2.0, 13.0, 194.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 46.0, 11.0, 5.0, 90.0, 30.0, 6.0, 4.0, 34.0, 140.0, 95.0, 20.0, 15.0, 51.0, 96.0, 229.0, 38.0, 97.0, 92.0, 0.0, 293.0, 12.0, 690.0, 0.0, 27.0, 206.0, 0.0, 56.0, 0.0, 0.0, 0.0, 5.0, 12.0, 23.0, 46.0, 0.0, 506.0, 13.0, 12.0, 387.0, 170.0, 558.0, 6.0, 30.0, 86.0, 0.0, 238.0, 36.0, 336.0, 421.0, 7.0, 12.0, 66.0, 260.0, 0.0, 0.0, 15.0, 470.0, 445.0, 12.0, 10.0, 45.0, 65.0, 112.0, 26.0, 0.0, 686.0, 6.0, 0.0, 631.0, 528.0, 20.0, 46.0, 4.0, 14.0, 0.0, 0.0, 70.0, 0.0, 21.0, 19.0, 102.0, 0.0, 0.0, 373.0, 0.0, 621.0, 484.0, 0.0, 518.0, 34.0, 0.0, 0.0, 318.0, 75.0, 100.0, 62.0, 0.0, 861.0, 278.0, 0.0, 3.0, 4.0, 433.0, 0.0, 100.0, 95.0, 1.0, 0.0, 0.0, 11.0, 0.0, 9.0, 34.0, 39.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6309361868991952, "mean_inference_ms": 1.60022199426064, "mean_action_processing_ms": 0.2510964761913448, "mean_env_wait_ms": 0.22297400102288104, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00411534309387207, "StateBufferConnector_ms": 0.008221268653869629, "ViewRequirementAgentConnector_ms": 0.10802185535430908}, "num_episodes": 18, "episode_return_max": 301.4000000000005, "episode_return_min": -592.6999999999999, "episode_return_mean": -33.686999999999955, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 272000, "num_agent_steps_trained": 272000, "num_env_steps_sampled": 68000, "num_env_steps_trained": 68000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 324.7578642577997, "num_env_steps_trained_throughput_per_sec": 324.7578642577997, "timesteps_total": 68000, "num_env_steps_sampled_lifetime": 68000, "num_agent_steps_sampled_lifetime": 272000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 272000, "timers": {"training_iteration_time_ms": 11150.132, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11150.079, "sample_time_ms": 1475.188, "learn_time_ms": 9653.318, "learn_throughput": 414.365, "synch_weights_time_ms": 18.717}, "counters": {"num_env_steps_sampled": 68000, "num_env_steps_trained": 68000, "num_agent_steps_sampled": 272000, "num_agent_steps_trained": 272000}, "done": false, "training_iteration": 17, "trial_id": "7f9b9_00000", "date": "2024-08-13_10-33-04", "timestamp": 1723559584, "time_this_iter_s": 12.381746292114258, "time_total_s": 181.0139491558075, "pid": 45656, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001414434352388078, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x31ffb65e0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 181.0139491558075, "iterations_since_restore": 17, "perf": {"cpu_util_percent": 47.13333333333333, "ram_util_percent": 83.59444444444445}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9166633294372963, "cur_kl_coeff": 0.2, "cur_lr": 0.0014144343523880775, "total_loss": 8.17701677065047, "policy_loss": -0.0025077228907436607, "vf_loss": 8.175712242580595, "vf_explained_var": 0.1432990722555332, "kl": 0.01906120926681896, "entropy": 1.4651148612537082, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 33075.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6206147008787387, "cur_kl_coeff": 0.2, "cur_lr": 0.0014144343523880775, "total_loss": 6.7435578368958975, "policy_loss": -0.008237685675353363, "vf_loss": 6.74873349300768, "vf_explained_var": 0.005635785772686913, "kl": 0.015310072815023482, "entropy": 1.4367471694315552, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 33075.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 72000, "num_env_steps_trained": 72000, "num_agent_steps_sampled": 288000, "num_agent_steps_trained": 288000}, "env_runners": {"episode_reward_max": 387.4999999999998, "episode_reward_min": -592.6999999999999, "episode_reward_mean": -32.221, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -837.9999999999997, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 168.4999999999998, "predator_policy": 861.0}, "policy_reward_mean": {"prey_policy": -144.36050000000003, "predator_policy": 128.25}, "custom_metrics": {}, "hist_stats": {"episode_reward": [130.8999999999991, -269.0999999999998, 24.600000000000083, -310.19999999999914, -592.6999999999999, 40.0000000000003, -47.19999999999984, 35.10000000000023, 143.39999999999927, 51.70000000000049, -2.8999999999997446, 178.19999999999945, 37.80000000000027, -4.899999999999858, -29.599999999999948, 43.60000000000035, 30.70000000000016, -219.59999999999974, 49.50000000000046, 40.0000000000003, 40.0000000000003, 23.500000000000156, -40.49999999999965, 34.60000000000044, 38.10000000000034, -243.40000000000023, 113.39999999999931, 0.4000000000001219, 16.000000000000213, -54.49999999999973, -259.20000000000005, -414.5, 40.00000000000031, -273.40000000000003, -21.599999999999554, 40.0000000000003, 145.49999999999977, 22.300000000000033, -267.59999999999985, 72.7999999999998, -296.79999999999995, -394.5999999999999, -18.599999999999746, 56.40000000000001, -195.2, -16.599999999999905, -16.99999999999956, -221.49999999999972, 23.500000000000277, 301.4000000000005, 127.39999999999938, 69.3000000000001, 77.99999999999923, -499.4999999999999, 116.19999999999955, -189.80000000000018, 42.10000000000036, 129.99999999999972, 40.0000000000003, 26.00000000000022, 29.900000000000244, 59.50000000000003, -48.69999999999981, -470.69999999999993, -49.7999999999999, 5.799999999999786, 48.100000000000435, -90.7, -197.6000000000003, -514.6999999999996, -222.99999999999986, 102.49999999999989, -144.2, -4.400000000000058, 47.900000000000425, 170.0999999999992, 214.59999999999982, 30.800000000000004, 223.59999999999945, -105.80000000000035, 23.40000000000012, 272.2999999999996, 77.10000000000016, -386.4, -13.199999999999996, 147.1999999999992, 113.79999999999941, 80.59999999999977, -72.8999999999997, 230.2999999999998, -342.80000000000007, -39.19999999999997, -88.89999999999989, 54.000000000000256, -219.8000000000004, 387.4999999999998, 326.9000000000002, -136.80000000000044, -88.4000000000005, -131.90000000000094], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 110.89999999999984, -215.20000000000005, -166.90000000000003, -178.00000000000048, 56.60000000000014, -248.00000000000014, -239.2000000000002, -526.0, -596.6999999999999, 20.000000000000014, 20.000000000000014, -68.20000000000033, -42.999999999999886, 20.000000000000014, -40.89999999999976, -9.399999999999855, 138.79999999999978, 31.700000000000212, 20.000000000000014, 13.699999999999964, -55.60000000000031, 67.9999999999998, 99.2, 15.799999999999962, 20.000000000000014, -214.90000000000015, 20.000000000000014, -105.39999999999998, -80.20000000000084, 23.600000000000065, 20.000000000000014, 23.00000000000006, -7.299999999999891, -212.79999999999995, -200.79999999999995, 20.000000000000014, 27.50000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -53.499999999999865, 20.000000000000014, -155.50000000000054, 20.000000000000014, 41.60000000000022, -43.00000000000003, -19.899999999999828, 20.000000000000014, -157.00000000000026, -321.4, -5.1999999999999265, 83.59999999999982, -166.60000000000022, 20.000000000000014, 43.70000000000003, -294.7, -263.4999999999989, 20.000000000000014, -337.3, -214.90000000000003, -485.7, -630.8, -36.699999999999754, 49.70000000000023, -249.80000000000004, -229.60000000000005, 20.000000000000014, -97.6000000000008, 20.000000000000014, 20.000000000000014, 46.400000000000084, 82.10000000000005, -66.70000000000081, 20.000000000000014, -456.79999999999995, -316.8, 20.900000000000027, 26.900000000000144, -556.7, -297.1, -511.79999999999995, -446.8, -154.60000000000022, 20.000000000000014, 91.09999999999994, -272.70000000000005, -456.7, -110.49999999999997, -529.0999999999999, 84.49999999999969, 20.90000000000003, -115.90000000000074, -217.8999999999999, -263.59999999999985, -11.500000000000007, 20.000000000000014, 117.19999999999965, -730.8, 108.19999999999979, -2.800000000000045, -64.00000000000045, 23.300000000000022, -128.00000000000006, 67.99999999999974, -617.6999999999999, -567.8, 90.1999999999999, 20.000000000000014, -748.2, -600.6000000000001, 31.400000000000176, -55.30000000000005, 20.000000000000014, 92.00000000000003, 20.000000000000014, 20.000000000000014, 31.700000000000212, -75.70000000000022, 20.000000000000014, -30.099999999999774, 76.69999999999997, -119.20000000000016, 3.200000000000003, -424.9, -627.8, -463.9, -625.8, 92.00000000000009, -565.9, 19.700000000000074, 20.000000000000014, 28.100000000000147, -409.2, -74.49999999999994, -167.50000000000003, -192.1000000000002, -581.1999999999995, -794.5, -329.10000000000025, -171.89999999999998, 81.80000000000008, 13.699999999999964, -36.700000000000024, -540.5, -4.899999999999984, -194.50000000000006, 26.900000000000126, 20.000000000000014, 113.89999999999995, 45.20000000000017, 71.29999999999993, 134.29999999999998, -59.800000000000466, 17.599999999999984, 139.69999999999996, 65.89999999999966, -45.69999999999977, -814.1, 65.60000000000007, -309.20000000000005, 168.4999999999998, -373.19999999999993, 20.000000000000014, 22.09999999999999, -579.3, -417.1, -793.0, -713.1999999999998, 7.1000000000001044, 109.0999999999996, -76.9000000000003, 127.69999999999978, 34.700000000000045, -30.099999999999905, -196.0, -98.89999999999984, 152.2999999999999, -837.9999999999997, -693.1, -380.70000000000005, -535.4000000000001, 54.19999999999999, -147.4000000000002, -265.5, -75.70000000000002, 22.700000000000053, -176.8000000000004, -824.0, -470.4, 164.8999999999999, -207.70000000000005, 131.5999999999998, -91.90000000000035, -779.9000000000001, -784.4, -85.00000000000051, -48.0999999999998, -652.7999999999994], "policy_predator_policy_reward": [0.0, 0.0, 113.0, 0.0, 71.0, 75.0, 6.0, 171.0, 7.0, 523.0, 0.0, 0.0, 64.0, 0.0, 27.0, 29.0, 14.0, 0.0, 0.0, 0.0, 36.0, 3.0, 9.0, 2.0, 0.0, 2.0, 89.0, 101.0, 65.0, 91.0, 0.0, 0.0, 2.0, 13.0, 194.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 46.0, 11.0, 5.0, 90.0, 30.0, 6.0, 4.0, 34.0, 140.0, 95.0, 20.0, 15.0, 51.0, 96.0, 229.0, 38.0, 97.0, 92.0, 0.0, 293.0, 12.0, 690.0, 0.0, 27.0, 206.0, 0.0, 56.0, 0.0, 0.0, 0.0, 5.0, 12.0, 23.0, 46.0, 0.0, 506.0, 13.0, 12.0, 387.0, 170.0, 558.0, 6.0, 30.0, 86.0, 0.0, 238.0, 36.0, 336.0, 421.0, 7.0, 12.0, 66.0, 260.0, 0.0, 0.0, 15.0, 470.0, 445.0, 12.0, 10.0, 45.0, 65.0, 112.0, 26.0, 0.0, 686.0, 6.0, 0.0, 631.0, 528.0, 20.0, 46.0, 4.0, 14.0, 0.0, 0.0, 70.0, 0.0, 21.0, 19.0, 102.0, 0.0, 0.0, 373.0, 0.0, 621.0, 484.0, 0.0, 518.0, 34.0, 0.0, 0.0, 318.0, 75.0, 100.0, 62.0, 0.0, 861.0, 278.0, 0.0, 3.0, 4.0, 433.0, 0.0, 100.0, 95.0, 1.0, 0.0, 0.0, 11.0, 0.0, 9.0, 34.0, 39.0, 6.0, 12.0, 16.0, 738.0, 22.0, 245.0, 251.0, 226.0, 0.0, 35.0, 610.0, 0.0, 728.0, 765.0, 31.0, 0.0, 0.0, 63.0, 28.0, 48.0, 0.0, 222.0, 223.0, 693.0, 0.0, 731.0, 415.0, 27.0, 219.0, 105.0, 78.0, 29.0, 104.0, 677.0, 360.0, 333.0, 188.0, 215.0, 79.0, 656.0, 713.0, 68.0, 528.0, 41.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6396759493484798, "mean_inference_ms": 1.6305080275049477, "mean_action_processing_ms": 0.2544619189024214, "mean_env_wait_ms": 0.2269106397376026, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004269838333129883, "StateBufferConnector_ms": 0.008314847946166992, "ViewRequirementAgentConnector_ms": 0.11129164695739746}, "num_episodes": 22, "episode_return_max": 387.4999999999998, "episode_return_min": -592.6999999999999, "episode_return_mean": -32.221, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 288000, "num_agent_steps_trained": 288000, "num_env_steps_sampled": 72000, "num_env_steps_trained": 72000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 347.24295602299196, "num_env_steps_trained_throughput_per_sec": 347.24295602299196, "timesteps_total": 72000, "num_env_steps_sampled_lifetime": 72000, "num_agent_steps_sampled_lifetime": 288000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 288000, "timers": {"training_iteration_time_ms": 11323.142, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11323.09, "sample_time_ms": 1498.692, "learn_time_ms": 9806.139, "learn_throughput": 407.908, "synch_weights_time_ms": 15.824}, "counters": {"num_env_steps_sampled": 72000, "num_env_steps_trained": 72000, "num_agent_steps_sampled": 288000, "num_agent_steps_trained": 288000}, "done": false, "training_iteration": 18, "trial_id": "7f9b9_00000", "date": "2024-08-13_10-33-16", "timestamp": 1723559596, "time_this_iter_s": 11.586124897003174, "time_total_s": 192.60007405281067, "pid": 45656, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001414434352388078, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x31ffb6790>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 192.60007405281067, "iterations_since_restore": 18, "perf": {"cpu_util_percent": 43.07058823529412, "ram_util_percent": 83.4235294117647}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7916027870916185, "cur_kl_coeff": 0.2, "cur_lr": 0.0014144343523880775, "total_loss": 5.733972599897435, "policy_loss": -0.0009114878690707936, "vf_loss": 5.731179883997276, "vf_explained_var": 0.12945473566257135, "kl": 0.018520992378329906, "entropy": 1.4418359792421735, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 34965.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.912338426519954, "cur_kl_coeff": 0.2, "cur_lr": 0.0014144343523880775, "total_loss": 4.523541572737315, "policy_loss": -0.004158588792640893, "vf_loss": 4.525261195626839, "vf_explained_var": 0.005990713172488742, "kl": 0.012194830978318286, "entropy": 1.3833266346542923, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 34965.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 76000, "num_env_steps_trained": 76000, "num_agent_steps_sampled": 304000, "num_agent_steps_trained": 304000}, "env_runners": {"episode_reward_max": 387.4999999999998, "episode_reward_min": -514.6999999999996, "episode_reward_mean": -17.22000000000006, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -837.9999999999997, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 181.0999999999999, "predator_policy": 861.0}, "policy_reward_mean": {"prey_policy": -153.305, "predator_policy": 144.695}, "custom_metrics": {}, "hist_stats": {"episode_reward": [34.60000000000044, 38.10000000000034, -243.40000000000023, 113.39999999999931, 0.4000000000001219, 16.000000000000213, -54.49999999999973, -259.20000000000005, -414.5, 40.00000000000031, -273.40000000000003, -21.599999999999554, 40.0000000000003, 145.49999999999977, 22.300000000000033, -267.59999999999985, 72.7999999999998, -296.79999999999995, -394.5999999999999, -18.599999999999746, 56.40000000000001, -195.2, -16.599999999999905, -16.99999999999956, -221.49999999999972, 23.500000000000277, 301.4000000000005, 127.39999999999938, 69.3000000000001, 77.99999999999923, -499.4999999999999, 116.19999999999955, -189.80000000000018, 42.10000000000036, 129.99999999999972, 40.0000000000003, 26.00000000000022, 29.900000000000244, 59.50000000000003, -48.69999999999981, -470.69999999999993, -49.7999999999999, 5.799999999999786, 48.100000000000435, -90.7, -197.6000000000003, -514.6999999999996, -222.99999999999986, 102.49999999999989, -144.2, -4.400000000000058, 47.900000000000425, 170.0999999999992, 214.59999999999982, 30.800000000000004, 223.59999999999945, -105.80000000000035, 23.40000000000012, 272.2999999999996, 77.10000000000016, -386.4, -13.199999999999996, 147.1999999999992, 113.79999999999941, 80.59999999999977, -72.8999999999997, 230.2999999999998, -342.80000000000007, -39.19999999999997, -88.89999999999989, 54.000000000000256, -219.8000000000004, 387.4999999999998, 326.9000000000002, -136.80000000000044, -88.4000000000005, -131.90000000000094, 163.79999999999973, 322.60000000000025, 55.30000000000016, -104.6000000000002, 133.6999999999997, 56.10000000000032, -27.49999999999978, -105.50000000000031, -343.3999999999999, -67.20000000000107, 97.89999999999964, 228.49999999999974, -132.7000000000008, 36.600000000000314, -9.799999999999986, -118.10000000000038, 40.0000000000003, 113.5999999999994, 62.400000000000276, 214.19999999999908, 53.80000000000007, 153.69999999999953, 29.000000000000128], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [41.60000000000022, -43.00000000000003, -19.899999999999828, 20.000000000000014, -157.00000000000026, -321.4, -5.1999999999999265, 83.59999999999982, -166.60000000000022, 20.000000000000014, 43.70000000000003, -294.7, -263.4999999999989, 20.000000000000014, -337.3, -214.90000000000003, -485.7, -630.8, -36.699999999999754, 49.70000000000023, -249.80000000000004, -229.60000000000005, 20.000000000000014, -97.6000000000008, 20.000000000000014, 20.000000000000014, 46.400000000000084, 82.10000000000005, -66.70000000000081, 20.000000000000014, -456.79999999999995, -316.8, 20.900000000000027, 26.900000000000144, -556.7, -297.1, -511.79999999999995, -446.8, -154.60000000000022, 20.000000000000014, 91.09999999999994, -272.70000000000005, -456.7, -110.49999999999997, -529.0999999999999, 84.49999999999969, 20.90000000000003, -115.90000000000074, -217.8999999999999, -263.59999999999985, -11.500000000000007, 20.000000000000014, 117.19999999999965, -730.8, 108.19999999999979, -2.800000000000045, -64.00000000000045, 23.300000000000022, -128.00000000000006, 67.99999999999974, -617.6999999999999, -567.8, 90.1999999999999, 20.000000000000014, -748.2, -600.6000000000001, 31.400000000000176, -55.30000000000005, 20.000000000000014, 92.00000000000003, 20.000000000000014, 20.000000000000014, 31.700000000000212, -75.70000000000022, 20.000000000000014, -30.099999999999774, 76.69999999999997, -119.20000000000016, 3.200000000000003, -424.9, -627.8, -463.9, -625.8, 92.00000000000009, -565.9, 19.700000000000074, 20.000000000000014, 28.100000000000147, -409.2, -74.49999999999994, -167.50000000000003, -192.1000000000002, -581.1999999999995, -794.5, -329.10000000000025, -171.89999999999998, 81.80000000000008, 13.699999999999964, -36.700000000000024, -540.5, -4.899999999999984, -194.50000000000006, 26.900000000000126, 20.000000000000014, 113.89999999999995, 45.20000000000017, 71.29999999999993, 134.29999999999998, -59.800000000000466, 17.599999999999984, 139.69999999999996, 65.89999999999966, -45.69999999999977, -814.1, 65.60000000000007, -309.20000000000005, 168.4999999999998, -373.19999999999993, 20.000000000000014, 22.09999999999999, -579.3, -417.1, -793.0, -713.1999999999998, 7.1000000000001044, 109.0999999999996, -76.9000000000003, 127.69999999999978, 34.700000000000045, -30.099999999999905, -196.0, -98.89999999999984, 152.2999999999999, -837.9999999999997, -693.1, -380.70000000000005, -535.4000000000001, 54.19999999999999, -147.4000000000002, -265.5, -75.70000000000002, 22.700000000000053, -176.8000000000004, -824.0, -470.4, 164.8999999999999, -207.70000000000005, 131.5999999999998, -91.90000000000035, -779.9000000000001, -784.4, -85.00000000000051, -48.0999999999998, -652.7999999999994, -695.2, 20.000000000000014, 147.79999999999993, 174.79999999999995, -40.29999999999976, 32.6000000000001, 52.40000000000023, -417.0, 172.10000000000002, -240.40000000000043, -75.40000000000023, 33.50000000000024, -27.39999999999997, -42.09999999999976, 20.000000000000014, -396.4999999999999, -336.20000000000005, -518.2000000000003, -159.40000000000023, -38.799999999999756, 38.90000000000008, 20.000000000000014, 52.40000000000019, -480.9, -317.99999999999915, -341.6999999999973, -1.3000000000000131, 17.899999999999988, -33.70000000000011, -228.1000000000001, -540.9, -50.199999999999875, 20.000000000000014, 20.000000000000014, 31.999999999999915, 8.600000000000023, 20.000000000000014, -517.6, 181.0999999999999, 13.100000000000104, 20.000000000000014, -29.200000000000024, 176.59999999999994, -61.90000000000061, -0.9999999999999846, 20.000000000000014], "policy_predator_policy_reward": [30.0, 6.0, 4.0, 34.0, 140.0, 95.0, 20.0, 15.0, 51.0, 96.0, 229.0, 38.0, 97.0, 92.0, 0.0, 293.0, 12.0, 690.0, 0.0, 27.0, 206.0, 0.0, 56.0, 0.0, 0.0, 0.0, 5.0, 12.0, 23.0, 46.0, 0.0, 506.0, 13.0, 12.0, 387.0, 170.0, 558.0, 6.0, 30.0, 86.0, 0.0, 238.0, 36.0, 336.0, 421.0, 7.0, 12.0, 66.0, 260.0, 0.0, 0.0, 15.0, 470.0, 445.0, 12.0, 10.0, 45.0, 65.0, 112.0, 26.0, 0.0, 686.0, 6.0, 0.0, 631.0, 528.0, 20.0, 46.0, 4.0, 14.0, 0.0, 0.0, 70.0, 0.0, 21.0, 19.0, 102.0, 0.0, 0.0, 373.0, 0.0, 621.0, 484.0, 0.0, 518.0, 34.0, 0.0, 0.0, 318.0, 75.0, 100.0, 62.0, 0.0, 861.0, 278.0, 0.0, 3.0, 4.0, 433.0, 0.0, 100.0, 95.0, 1.0, 0.0, 0.0, 11.0, 0.0, 9.0, 34.0, 39.0, 6.0, 12.0, 16.0, 738.0, 22.0, 245.0, 251.0, 226.0, 0.0, 35.0, 610.0, 0.0, 728.0, 765.0, 31.0, 0.0, 0.0, 63.0, 28.0, 48.0, 0.0, 222.0, 223.0, 693.0, 0.0, 731.0, 415.0, 27.0, 219.0, 105.0, 78.0, 29.0, 104.0, 677.0, 360.0, 333.0, 188.0, 215.0, 79.0, 656.0, 713.0, 68.0, 528.0, 41.0, 363.0, 476.0, 0.0, 0.0, 63.0, 0.0, 0.0, 260.0, 79.0, 123.0, 49.0, 49.0, 41.0, 1.0, 271.0, 0.0, 501.0, 10.0, 28.0, 103.0, 26.0, 13.0, 361.0, 296.0, 527.0, 0.0, 6.0, 14.0, 142.0, 110.0, 50.0, 423.0, 0.0, 0.0, 73.0, 0.0, 209.0, 351.0, 6.0, 14.0, 14.0, 49.0, 8.0, 31.0, 10.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6484063353485605, "mean_inference_ms": 1.6582245900609336, "mean_action_processing_ms": 0.25768786227232354, "mean_env_wait_ms": 0.23020835316906474, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005395650863647461, "StateBufferConnector_ms": 0.009199380874633789, "ViewRequirementAgentConnector_ms": 0.13280093669891357}, "num_episodes": 23, "episode_return_max": 387.4999999999998, "episode_return_min": -514.6999999999996, "episode_return_mean": -17.22000000000006, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 304000, "num_agent_steps_trained": 304000, "num_env_steps_sampled": 76000, "num_env_steps_trained": 76000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 343.93980817192266, "num_env_steps_trained_throughput_per_sec": 343.93980817192266, "timesteps_total": 76000, "num_env_steps_sampled_lifetime": 76000, "num_agent_steps_sampled_lifetime": 304000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 304000, "timers": {"training_iteration_time_ms": 11197.934, "restore_workers_time_ms": 0.013, "training_step_time_ms": 11197.882, "sample_time_ms": 1420.648, "learn_time_ms": 9759.247, "learn_throughput": 409.868, "synch_weights_time_ms": 15.579}, "counters": {"num_env_steps_sampled": 76000, "num_env_steps_trained": 76000, "num_agent_steps_sampled": 304000, "num_agent_steps_trained": 304000}, "done": false, "training_iteration": 19, "trial_id": "7f9b9_00000", "date": "2024-08-13_10-33-27", "timestamp": 1723559607, "time_this_iter_s": 11.697273969650269, "time_total_s": 204.29734802246094, "pid": 45656, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001414434352388078, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x31fe5bb80>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 204.29734802246094, "iterations_since_restore": 19, "perf": {"cpu_util_percent": 45.4875, "ram_util_percent": 83.55}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9141449850387675, "cur_kl_coeff": 0.2, "cur_lr": 0.0014144343523880775, "total_loss": 3.7361574725499227, "policy_loss": -0.004101045869990553, "vf_loss": 3.7354983879775596, "vf_explained_var": 0.15688042372622818, "kl": 0.02380067250009479, "entropy": 1.4355014392938563, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 36855.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7540420887646851, "cur_kl_coeff": 0.2, "cur_lr": 0.0014144343523880775, "total_loss": 2.8895091725404933, "policy_loss": -0.007713392908468094, "vf_loss": 2.8946517488943835, "vf_explained_var": 0.002648745611231163, "kl": 0.012854108784896272, "entropy": 1.3907177057846514, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 36855.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 80000, "num_env_steps_trained": 80000, "num_agent_steps_sampled": 320000, "num_agent_steps_trained": 320000}, "env_runners": {"episode_reward_max": 387.4999999999998, "episode_reward_min": -514.6999999999996, "episode_reward_mean": 1.362999999999916, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -837.9999999999997, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 181.0999999999999, "predator_policy": 861.0}, "policy_reward_mean": {"prey_policy": -133.36350000000002, "predator_policy": 134.045}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-394.5999999999999, -18.599999999999746, 56.40000000000001, -195.2, -16.599999999999905, -16.99999999999956, -221.49999999999972, 23.500000000000277, 301.4000000000005, 127.39999999999938, 69.3000000000001, 77.99999999999923, -499.4999999999999, 116.19999999999955, -189.80000000000018, 42.10000000000036, 129.99999999999972, 40.0000000000003, 26.00000000000022, 29.900000000000244, 59.50000000000003, -48.69999999999981, -470.69999999999993, -49.7999999999999, 5.799999999999786, 48.100000000000435, -90.7, -197.6000000000003, -514.6999999999996, -222.99999999999986, 102.49999999999989, -144.2, -4.400000000000058, 47.900000000000425, 170.0999999999992, 214.59999999999982, 30.800000000000004, 223.59999999999945, -105.80000000000035, 23.40000000000012, 272.2999999999996, 77.10000000000016, -386.4, -13.199999999999996, 147.1999999999992, 113.79999999999941, 80.59999999999977, -72.8999999999997, 230.2999999999998, -342.80000000000007, -39.19999999999997, -88.89999999999989, 54.000000000000256, -219.8000000000004, 387.4999999999998, 326.9000000000002, -136.80000000000044, -88.4000000000005, -131.90000000000094, 163.79999999999973, 322.60000000000025, 55.30000000000016, -104.6000000000002, 133.6999999999997, 56.10000000000032, -27.49999999999978, -105.50000000000031, -343.3999999999999, -67.20000000000107, 97.89999999999964, 228.49999999999974, -132.7000000000008, 36.600000000000314, -9.799999999999986, -118.10000000000038, 40.0000000000003, 113.5999999999994, 62.400000000000276, 214.19999999999908, 53.80000000000007, 153.69999999999953, 29.000000000000128, -53.19999999999993, 16.000000000000124, -50.700000000000635, 178.9999999999994, -73.50000000000016, 46.2000000000004, 161.49999999999935, 24.400000000000045, 35.600000000000236, 34.50000000000022, -35.69999999999979, -9.199999999999958, 67.20000000000019, -71.0000000000012, 90.5999999999998, -43.19999999999969, -22.39999999999955, 254.29999999999976], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-511.79999999999995, -446.8, -154.60000000000022, 20.000000000000014, 91.09999999999994, -272.70000000000005, -456.7, -110.49999999999997, -529.0999999999999, 84.49999999999969, 20.90000000000003, -115.90000000000074, -217.8999999999999, -263.59999999999985, -11.500000000000007, 20.000000000000014, 117.19999999999965, -730.8, 108.19999999999979, -2.800000000000045, -64.00000000000045, 23.300000000000022, -128.00000000000006, 67.99999999999974, -617.6999999999999, -567.8, 90.1999999999999, 20.000000000000014, -748.2, -600.6000000000001, 31.400000000000176, -55.30000000000005, 20.000000000000014, 92.00000000000003, 20.000000000000014, 20.000000000000014, 31.700000000000212, -75.70000000000022, 20.000000000000014, -30.099999999999774, 76.69999999999997, -119.20000000000016, 3.200000000000003, -424.9, -627.8, -463.9, -625.8, 92.00000000000009, -565.9, 19.700000000000074, 20.000000000000014, 28.100000000000147, -409.2, -74.49999999999994, -167.50000000000003, -192.1000000000002, -581.1999999999995, -794.5, -329.10000000000025, -171.89999999999998, 81.80000000000008, 13.699999999999964, -36.700000000000024, -540.5, -4.899999999999984, -194.50000000000006, 26.900000000000126, 20.000000000000014, 113.89999999999995, 45.20000000000017, 71.29999999999993, 134.29999999999998, -59.800000000000466, 17.599999999999984, 139.69999999999996, 65.89999999999966, -45.69999999999977, -814.1, 65.60000000000007, -309.20000000000005, 168.4999999999998, -373.19999999999993, 20.000000000000014, 22.09999999999999, -579.3, -417.1, -793.0, -713.1999999999998, 7.1000000000001044, 109.0999999999996, -76.9000000000003, 127.69999999999978, 34.700000000000045, -30.099999999999905, -196.0, -98.89999999999984, 152.2999999999999, -837.9999999999997, -693.1, -380.70000000000005, -535.4000000000001, 54.19999999999999, -147.4000000000002, -265.5, -75.70000000000002, 22.700000000000053, -176.8000000000004, -824.0, -470.4, 164.8999999999999, -207.70000000000005, 131.5999999999998, -91.90000000000035, -779.9000000000001, -784.4, -85.00000000000051, -48.0999999999998, -652.7999999999994, -695.2, 20.000000000000014, 147.79999999999993, 174.79999999999995, -40.29999999999976, 32.6000000000001, 52.40000000000023, -417.0, 172.10000000000002, -240.40000000000043, -75.40000000000023, 33.50000000000024, -27.39999999999997, -42.09999999999976, 20.000000000000014, -396.4999999999999, -336.20000000000005, -518.2000000000003, -159.40000000000023, -38.799999999999756, 38.90000000000008, 20.000000000000014, 52.40000000000019, -480.9, -317.99999999999915, -341.6999999999973, -1.3000000000000131, 17.899999999999988, -33.70000000000011, -228.1000000000001, -540.9, -50.199999999999875, 20.000000000000014, 20.000000000000014, 31.999999999999915, 8.600000000000023, 20.000000000000014, -517.6, 181.0999999999999, 13.100000000000104, 20.000000000000014, -29.200000000000024, 176.59999999999994, -61.90000000000061, -0.9999999999999846, 20.000000000000014, -237.6000000000005, 25.400000000000098, -97.00000000000003, 20.000000000000014, -33.9999999999998, -57.70000000000035, 7.399999999999965, 155.59999999999997, -36.099999999999966, -251.39999999999984, 21.20000000000003, 20.000000000000014, 141.4999999999999, 20.000000000000014, -11.499999999999819, 17.899999999999988, 11.599999999999966, 20.000000000000014, 9.499999999999964, 20.000000000000014, -249.70000000000007, 20.000000000000014, -134.8000000000002, -6.399999999999951, 75.79999999999934, -34.59999999999975, -111.10000000000059, -82.9000000000006, 14.600000000000016, 20.000000000000014, -9.399999999999926, -122.80000000000075, -106.0000000000008, 23.600000000000065, 129.7999999999999, 84.5], "policy_predator_policy_reward": [558.0, 6.0, 30.0, 86.0, 0.0, 238.0, 36.0, 336.0, 421.0, 7.0, 12.0, 66.0, 260.0, 0.0, 0.0, 15.0, 470.0, 445.0, 12.0, 10.0, 45.0, 65.0, 112.0, 26.0, 0.0, 686.0, 6.0, 0.0, 631.0, 528.0, 20.0, 46.0, 4.0, 14.0, 0.0, 0.0, 70.0, 0.0, 21.0, 19.0, 102.0, 0.0, 0.0, 373.0, 0.0, 621.0, 484.0, 0.0, 518.0, 34.0, 0.0, 0.0, 318.0, 75.0, 100.0, 62.0, 0.0, 861.0, 278.0, 0.0, 3.0, 4.0, 433.0, 0.0, 100.0, 95.0, 1.0, 0.0, 0.0, 11.0, 0.0, 9.0, 34.0, 39.0, 6.0, 12.0, 16.0, 738.0, 22.0, 245.0, 251.0, 226.0, 0.0, 35.0, 610.0, 0.0, 728.0, 765.0, 31.0, 0.0, 0.0, 63.0, 28.0, 48.0, 0.0, 222.0, 223.0, 693.0, 0.0, 731.0, 415.0, 27.0, 219.0, 105.0, 78.0, 29.0, 104.0, 677.0, 360.0, 333.0, 188.0, 215.0, 79.0, 656.0, 713.0, 68.0, 528.0, 41.0, 363.0, 476.0, 0.0, 0.0, 63.0, 0.0, 0.0, 260.0, 79.0, 123.0, 49.0, 49.0, 41.0, 1.0, 271.0, 0.0, 501.0, 10.0, 28.0, 103.0, 26.0, 13.0, 361.0, 296.0, 527.0, 0.0, 6.0, 14.0, 142.0, 110.0, 50.0, 423.0, 0.0, 0.0, 73.0, 0.0, 209.0, 351.0, 6.0, 14.0, 14.0, 49.0, 8.0, 31.0, 10.0, 0.0, 159.0, 0.0, 0.0, 93.0, 2.0, 39.0, 10.0, 6.0, 64.0, 150.0, 0.0, 5.0, 0.0, 0.0, 3.0, 15.0, 4.0, 0.0, 5.0, 0.0, 76.0, 118.0, 6.0, 126.0, 1.0, 25.0, 40.0, 83.0, 40.0, 16.0, 52.0, 37.0, 0.0, 60.0, 0.0, 40.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6533960435017414, "mean_inference_ms": 1.6729526235280558, "mean_action_processing_ms": 0.2596773617241751, "mean_env_wait_ms": 0.23193615438313422, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005129814147949219, "StateBufferConnector_ms": 0.008710741996765137, "ViewRequirementAgentConnector_ms": 0.12505948543548584}, "num_episodes": 18, "episode_return_max": 387.4999999999998, "episode_return_min": -514.6999999999996, "episode_return_mean": 1.362999999999916, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 320000, "num_agent_steps_trained": 320000, "num_env_steps_sampled": 80000, "num_env_steps_trained": 80000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 305.8285612454414, "num_env_steps_trained_throughput_per_sec": 305.8285612454414, "timesteps_total": 80000, "num_env_steps_sampled_lifetime": 80000, "num_agent_steps_sampled_lifetime": 320000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 320000, "timers": {"training_iteration_time_ms": 11404.641, "restore_workers_time_ms": 0.013, "training_step_time_ms": 11404.591, "sample_time_ms": 1457.281, "learn_time_ms": 9928.53, "learn_throughput": 402.879, "synch_weights_time_ms": 16.159}, "counters": {"num_env_steps_sampled": 80000, "num_env_steps_trained": 80000, "num_agent_steps_sampled": 320000, "num_agent_steps_trained": 320000}, "done": false, "training_iteration": 20, "trial_id": "7f9b9_00000", "date": "2024-08-13_10-33-41", "timestamp": 1723559621, "time_this_iter_s": 13.16118597984314, "time_total_s": 217.45853400230408, "pid": 45656, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001414434352388078, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x31feefa60>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 217.45853400230408, "iterations_since_restore": 20, "perf": {"cpu_util_percent": 55.43157894736842, "ram_util_percent": 83.3157894736842}}
