{"num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1600000, "num_agent_steps_trained": 1600000, "num_env_steps_sampled": 400000, "num_env_steps_trained": 400000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 147.32166221022254, "num_env_steps_trained_throughput_per_sec": 147.32166221022254, "timesteps_total": 400000, "num_env_steps_sampled_lifetime": 400000, "num_agent_steps_sampled_lifetime": 1600000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1600000, "training_iteration": 100, "timestamp": 1724393649, "time_this_iter_s": 27.17846393585205, "time_total_s": 2659.1143910884857, "time_since_restore": 2659.1143910884857, "iterations_since_restore": 100, "info/num_env_steps_sampled": 400000, "info/num_env_steps_trained": 400000, "info/num_agent_steps_sampled": 1600000, "info/num_agent_steps_trained": 1600000, "env_runners/episode_reward_max": 721.914131394269, "env_runners/episode_reward_min": -86.49900554914603, "env_runners/episode_reward_mean": 172.6019864727314, "env_runners/episode_len_mean": 400.0, "env_runners/episodes_timesteps_total": 40000, "env_runners/num_faulty_episodes": 0, "env_runners/num_episodes": 11, "env_runners/episode_return_max": 721.914131394269, "env_runners/episode_return_min": -86.49900554914603, "env_runners/episode_return_mean": 172.6019864727314, "env_runners/episodes_this_iter": 11, "timers/training_iteration_time_ms": 25595.691, "timers/restore_workers_time_ms": 0.026, "timers/training_step_time_ms": 25595.508, "timers/sample_time_ms": 2203.349, "timers/learn_time_ms": 23362.171, "timers/learn_throughput": 171.217, "timers/synch_weights_time_ms": 26.72, "counters/num_env_steps_sampled": 400000, "counters/num_env_steps_trained": 400000, "counters/num_agent_steps_sampled": 1600000, "counters/num_agent_steps_trained": 1600000, "perf/cpu_util_percent": 43.142105263157895, "perf/ram_util_percent": 83.10789473684213, "info/learner/predator_policy/num_agent_steps_trained": 126.98412698412699, "info/learner/predator_policy/num_grad_updates_lifetime": 94028.0, "info/learner/predator_policy/diff_num_grad_updates_vs_sampler_policy": 472.0, "info/learner/prey_policy/num_agent_steps_trained": 126.98412698412699, "info/learner/prey_policy/num_grad_updates_lifetime": 94028.0, "info/learner/prey_policy/diff_num_grad_updates_vs_sampler_policy": 472.0, "info/learner/predator_policy/learner_stats/allreduce_latency": 0.0, "info/learner/predator_policy/learner_stats/grad_gnorm": 19.543156125810413, "info/learner/predator_policy/learner_stats/cur_kl_coeff": 0.1, "info/learner/predator_policy/learner_stats/cur_lr": 0.00010000000000000003, "info/learner/predator_policy/learner_stats/total_loss": 5.86344508973379, "info/learner/predator_policy/learner_stats/policy_loss": -0.008797786981064492, "info/learner/predator_policy/learner_stats/vf_loss": 5.871425161916743, "info/learner/predator_policy/learner_stats/vf_explained_var": 0.20215381024375795, "info/learner/predator_policy/learner_stats/kl": 0.008177213444221745, "info/learner/predator_policy/learner_stats/entropy": 0.382791475707261, "info/learner/predator_policy/learner_stats/entropy_coeff": 0.0, "info/learner/prey_policy/learner_stats/allreduce_latency": 0.0, "info/learner/prey_policy/learner_stats/grad_gnorm": 13.865035650717518, "info/learner/prey_policy/learner_stats/cur_kl_coeff": 0.2, "info/learner/prey_policy/learner_stats/cur_lr": 0.00010000000000000003, "info/learner/prey_policy/learner_stats/total_loss": 5.607423277254457, "info/learner/prey_policy/learner_stats/policy_loss": -0.014521978013513107, "info/learner/prey_policy/learner_stats/vf_loss": 5.619905807858422, "info/learner/prey_policy/learner_stats/vf_explained_var": 0.415580608605077, "info/learner/prey_policy/learner_stats/kl": 0.010197246680282568, "info/learner/prey_policy/learner_stats/entropy": 0.6693808976935332, "info/learner/prey_policy/learner_stats/entropy_coeff": 0.0, "_timestamp": 1724393649.880221, "_runtime": 2653.8370168209076, "_step": 99, "env_runners/policy_reward_min/prey_policy": -1191.122797606987, "env_runners/policy_reward_min/predator_policy": 0.0, "env_runners/policy_reward_max/prey_policy": 400.0, "env_runners/policy_reward_max/predator_policy": 904.043775933585, "env_runners/policy_reward_mean/prey_policy": -367.28540736677513, "env_runners/policy_reward_mean/predator_policy": 453.5864006031414, "env_runners/sampler_perf/mean_raw_obs_processing_ms": 3.7981642615007583, "env_runners/sampler_perf/mean_inference_ms": 3.5247292040572584, "env_runners/sampler_perf/mean_action_processing_ms": 1.14567070656393, "env_runners/sampler_perf/mean_env_wait_ms": 10.3079836190876, "env_runners/sampler_perf/mean_env_render_ms": 0.0, "env_runners/connector_metrics/ObsPreprocessorConnector_ms": 0.008200645446777344, "env_runners/connector_metrics/StateBufferConnector_ms": 0.004508018493652344, "env_runners/connector_metrics/ViewRequirementAgentConnector_ms": 0.15738403797149658}