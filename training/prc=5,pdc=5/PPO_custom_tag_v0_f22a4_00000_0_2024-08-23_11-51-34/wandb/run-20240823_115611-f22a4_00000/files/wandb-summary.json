{"num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 4000000, "num_agent_steps_trained": 4000000, "num_env_steps_sampled": 400000, "num_env_steps_trained": 400000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 66.6632036842435, "num_env_steps_trained_throughput_per_sec": 66.6632036842435, "timesteps_total": 400000, "num_env_steps_sampled_lifetime": 400000, "num_agent_steps_sampled_lifetime": 4000000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 4000000, "training_iteration": 100, "timestamp": 1724400898, "time_this_iter_s": 60.04609775543213, "time_total_s": 6529.98730802536, "time_since_restore": 6529.98730802536, "iterations_since_restore": 100, "info/num_env_steps_sampled": 400000, "info/num_env_steps_trained": 400000, "info/num_agent_steps_sampled": 4000000, "info/num_agent_steps_trained": 4000000, "env_runners/episode_reward_max": 2311.729631100007, "env_runners/episode_reward_min": 222.06449407885992, "env_runners/episode_reward_mean": 1097.3762082741391, "env_runners/episode_len_mean": 400.0, "env_runners/episodes_timesteps_total": 40000, "env_runners/num_faulty_episodes": 0, "env_runners/num_episodes": 14, "env_runners/episode_return_max": 2311.729631100007, "env_runners/episode_return_min": 222.06449407885992, "env_runners/episode_return_mean": 1097.3762082741391, "env_runners/episodes_this_iter": 14, "timers/training_iteration_time_ms": 60906.193, "timers/restore_workers_time_ms": 0.014, "timers/training_step_time_ms": 60906.1, "timers/sample_time_ms": 3260.015, "timers/learn_time_ms": 57622.111, "timers/learn_throughput": 69.418, "timers/synch_weights_time_ms": 14.599, "counters/num_env_steps_sampled": 400000, "counters/num_env_steps_trained": 400000, "counters/num_agent_steps_sampled": 4000000, "counters/num_agent_steps_trained": 4000000, "perf/cpu_util_percent": 29.564705882352943, "perf/ram_util_percent": 82.30470588235295, "info/learner/prey_policy/num_agent_steps_trained": 127.38853503184713, "info/learner/prey_policy/num_grad_updates_lifetime": 234323.0, "info/learner/prey_policy/diff_num_grad_updates_vs_sampler_policy": 1177.0, "info/learner/predator_policy/num_agent_steps_trained": 127.38853503184713, "info/learner/predator_policy/num_grad_updates_lifetime": 234323.0, "info/learner/predator_policy/diff_num_grad_updates_vs_sampler_policy": 1177.0, "info/learner/prey_policy/learner_stats/allreduce_latency": 0.0, "info/learner/prey_policy/learner_stats/grad_gnorm": 41.84590273966455, "info/learner/prey_policy/learner_stats/cur_kl_coeff": 0.30000000000000004, "info/learner/prey_policy/learner_stats/cur_lr": 0.00010000000000000003, "info/learner/prey_policy/learner_stats/total_loss": 7.14297164625423, "info/learner/prey_policy/learner_stats/policy_loss": -0.009961378691033826, "info/learner/prey_policy/learner_stats/vf_loss": 7.150756220402485, "info/learner/prey_policy/learner_stats/vf_explained_var": 0.5238014837738815, "info/learner/prey_policy/learner_stats/kl": 0.007256027951049609, "info/learner/prey_policy/learner_stats/entropy": 0.5994291995741, "info/learner/prey_policy/learner_stats/entropy_coeff": 0.0, "info/learner/predator_policy/learner_stats/allreduce_latency": 0.0, "info/learner/predator_policy/learner_stats/grad_gnorm": 18.274894694613803, "info/learner/predator_policy/learner_stats/cur_kl_coeff": 0.2, "info/learner/predator_policy/learner_stats/cur_lr": 0.00010000000000000003, "info/learner/predator_policy/learner_stats/total_loss": 8.318156777724086, "info/learner/predator_policy/learner_stats/policy_loss": -0.012596419714233045, "info/learner/predator_policy/learner_stats/vf_loss": 8.32943463538103, "info/learner/predator_policy/learner_stats/vf_explained_var": -0.3373926781798118, "info/learner/predator_policy/learner_stats/kl": 0.006592852047608963, "info/learner/predator_policy/learner_stats/entropy": 0.22244857508538887, "info/learner/predator_policy/learner_stats/entropy_coeff": 0.0, "_timestamp": 1724400898.128473, "_runtime": 6526.537187099457, "_step": 99, "env_runners/policy_reward_min/prey_policy": -1171.640654799692, "env_runners/policy_reward_min/predator_policy": 106.22233578728112, "env_runners/policy_reward_max/prey_policy": 389.2, "env_runners/policy_reward_max/predator_policy": 999.5229013956659, "env_runners/policy_reward_mean/prey_policy": -433.4906804388262, "env_runners/policy_reward_mean/predator_policy": 652.9659220936543, "env_runners/sampler_perf/mean_raw_obs_processing_ms": 12.457296005927944, "env_runners/sampler_perf/mean_inference_ms": 8.46031272187605, "env_runners/sampler_perf/mean_action_processing_ms": 4.522360097748555, "env_runners/sampler_perf/mean_env_wait_ms": 13.137613712733293, "env_runners/sampler_perf/mean_env_render_ms": 0.0, "env_runners/connector_metrics/ObsPreprocessorConnector_ms": 0.009724020957946777, "env_runners/connector_metrics/StateBufferConnector_ms": 0.00829625129699707, "env_runners/connector_metrics/ViewRequirementAgentConnector_ms": 0.32307398319244385}