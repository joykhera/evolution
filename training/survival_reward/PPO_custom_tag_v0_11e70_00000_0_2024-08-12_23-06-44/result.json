{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6814542869726817, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.920146265673259, "policy_loss": 0.0010854221043970298, "vf_loss": 2.9149202129828238, "vf_explained_var": 0.003947857069590735, "kl": 0.02070311488849776, "entropy": 1.6025439478102184, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 945.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.1824771218198946, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.536903250658954, "policy_loss": -0.005113448849854567, "vf_loss": 7.5372467293310415, "vf_explained_var": -0.013383193463875504, "kl": 0.02384979013530981, "entropy": 1.6026754217173056, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 945.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 4000, "num_env_steps_trained": 4000, "num_agent_steps_sampled": 16000, "num_agent_steps_trained": 16000}, "env_runners": {"episode_reward_max": 205.2999999999997, "episode_reward_min": -123.10000000000036, "episode_reward_mean": 44.26666666666664, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 3600, "policy_reward_min": {"prey_policy": -269.8, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 120.7999999999995, "predator_policy": 138.0}, "policy_reward_mean": {"prey_policy": 2.0499999999999776, "predator_policy": 20.083333333333332}, "custom_metrics": {}, "hist_stats": {"episode_reward": [205.2999999999997, 26.10000000000045, 85.00000000000006, 166.09999999999897, 0.20000000000001794, -123.10000000000036, 35.20000000000038, 43.600000000000364, -14.399999999999972, 59.30000000000049, 33.400000000000205, 29.59999999999996, 62.80000000000026, 24.700000000000287, -42.400000000000176, 68.59999999999997, 140.79999999999876, -3.9999999999997313], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [117.49999999999974, 69.80000000000004, 47.90000000000024, -59.79999999999996, 14.599999999999959, 43.4, 101.60000000000001, 51.50000000000022, 30.80000000000002, -76.59999999999995, -269.8, -7.300000000000029, -3.9999999999998934, -17.79999999999974, 20.000000000000014, 23.60000000000008, 37.100000000000094, -116.50000000000011, 20.000000000000014, 32.30000000000023, 20.000000000000014, 7.399999999999965, 42.2, -55.600000000000016, -23.49999999999993, 20.30000000000007, -21.999999999999744, -16.299999999999997, -9.399999999999855, -85.00000000000085, 9.499999999999972, 31.09999999999998, 20.000000000000014, 120.7999999999995, 20.000000000000014, -64.00000000000091], "policy_predator_policy_reward": [0.0, 18.0, 0.0, 38.0, 27.0, 0.0, 13.0, 0.0, 0.0, 46.0, 16.0, 138.0, 8.0, 49.0, 0.0, 0.0, 65.0, 0.0, 0.0, 7.0, 6.0, 0.0, 43.0, 0.0, 29.0, 37.0, 0.0, 63.0, 50.0, 2.0, 0.0, 28.0, 0.0, 0.0, 0.0, 40.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7953175688321418, "mean_inference_ms": 1.8497698087723171, "mean_action_processing_ms": 0.3149636378818728, "mean_env_wait_ms": 0.24297500837538147, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0064392884572347, "StateBufferConnector_ms": 0.003247128592597114, "ViewRequirementAgentConnector_ms": 0.10932419035169813}, "num_episodes": 18, "episode_return_max": 205.2999999999997, "episode_return_min": -123.10000000000036, "episode_return_mean": 44.26666666666664, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 16000, "num_agent_steps_trained": 16000, "num_env_steps_sampled": 4000, "num_env_steps_trained": 4000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 70.23585853816977, "num_env_steps_trained_throughput_per_sec": 70.23585853816977, "timesteps_total": 4000, "num_env_steps_sampled_lifetime": 4000, "num_agent_steps_sampled_lifetime": 16000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 16000, "timers": {"training_iteration_time_ms": 56950.974, "restore_workers_time_ms": 0.018, "training_step_time_ms": 56950.924, "sample_time_ms": 1557.568, "learn_time_ms": 55375.966, "learn_throughput": 72.234, "synch_weights_time_ms": 11.343}, "counters": {"num_env_steps_sampled": 4000, "num_env_steps_trained": 4000, "num_agent_steps_sampled": 16000, "num_agent_steps_trained": 16000}, "done": false, "training_iteration": 1, "trial_id": "11e70_00000", "date": "2024-08-12_23-07-53", "timestamp": 1723518473, "time_this_iter_s": 57.01151514053345, "time_total_s": 57.01151514053345, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2ad7e50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 57.01151514053345, "iterations_since_restore": 1, "perf": {"cpu_util_percent": 49.611111111111114, "ram_util_percent": 83.48271604938272}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6557076118610523, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.0913939872116005, "policy_loss": -0.010414980000707877, "vf_loss": 4.100190023518113, "vf_explained_var": 0.0014689797446841286, "kl": 0.005396486977459787, "entropy": 1.5950437980354149, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 2835.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.592025606121336, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.265093356339389, "policy_loss": -0.008191729390811392, "vf_loss": 7.272091883200186, "vf_explained_var": -0.008012627861487171, "kl": 0.003977357404226305, "entropy": 1.5957450415722276, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 2835.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 8000, "num_env_steps_trained": 8000, "num_agent_steps_sampled": 32000, "num_agent_steps_trained": 32000}, "env_runners": {"episode_reward_max": 318.5000000000001, "episode_reward_min": -123.10000000000036, "episode_reward_mean": 52.54999999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 7200, "policy_reward_min": {"prey_policy": -269.8, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 186.49999999999997, "predator_policy": 138.0}, "policy_reward_mean": {"prey_policy": -2.475000000000052, "predator_policy": 28.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [205.2999999999997, 26.10000000000045, 85.00000000000006, 166.09999999999897, 0.20000000000001794, -123.10000000000036, 35.20000000000038, 43.600000000000364, -14.399999999999972, 59.30000000000049, 33.400000000000205, 29.59999999999996, 62.80000000000026, 24.700000000000287, -42.400000000000176, 68.59999999999997, 140.79999999999876, -3.9999999999997313, 109.59999999999982, 83.40000000000006, 318.5000000000001, 25.600000000000193, -52.59999999999982, 18.600000000000044, 88.49999999999997, 42.39999999999997, -7.299999999999805, 213.9999999999992, -81.00000000000009, -44.299999999999876, 34.9000000000001, 178.09999999999997, 81.89999999999962, 72.60000000000001, 32.400000000000226, -20.300000000000054], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [117.49999999999974, 69.80000000000004, 47.90000000000024, -59.79999999999996, 14.599999999999959, 43.4, 101.60000000000001, 51.50000000000022, 30.80000000000002, -76.59999999999995, -269.8, -7.300000000000029, -3.9999999999998934, -17.79999999999974, 20.000000000000014, 23.60000000000008, 37.100000000000094, -116.50000000000011, 20.000000000000014, 32.30000000000023, 20.000000000000014, 7.399999999999965, 42.2, -55.600000000000016, -23.49999999999993, 20.30000000000007, -21.999999999999744, -16.299999999999997, -9.399999999999855, -85.00000000000085, 9.499999999999972, 31.09999999999998, 20.000000000000014, 120.7999999999995, 20.000000000000014, -64.00000000000091, -129.1000000000006, 166.70000000000002, 141.2, -164.8000000000001, 172.6999999999999, 138.79999999999998, -115.60000000000068, 60.20000000000008, -54.9999999999999, -184.6, 4.999999999999979, -39.39999999999996, 0.4999999999999716, 26.000000000000128, -190.90000000000018, 125.29999999999978, -70.30000000000067, 20.000000000000014, 24.50000000000009, 186.49999999999997, -211.00000000000017, 20.000000000000014, 1.0999999999999794, -168.40000000000023, 20.000000000000014, -21.099999999999802, -33.10000000000004, 126.19999999999999, 59.90000000000021, 20.000000000000014, 97.40000000000003, -152.8000000000002, 95.59999999999998, -152.20000000000056, -36.70000000000003, -34.599999999999866], "policy_predator_policy_reward": [0.0, 18.0, 0.0, 38.0, 27.0, 0.0, 13.0, 0.0, 0.0, 46.0, 16.0, 138.0, 8.0, 49.0, 0.0, 0.0, 65.0, 0.0, 0.0, 7.0, 6.0, 0.0, 43.0, 0.0, 29.0, 37.0, 0.0, 63.0, 50.0, 2.0, 0.0, 28.0, 0.0, 0.0, 0.0, 40.0, 71.0, 1.0, 97.0, 10.0, 3.0, 4.0, 13.0, 68.0, 52.0, 135.0, 8.0, 45.0, 54.0, 8.0, 106.0, 2.0, 0.0, 43.0, 3.0, 0.0, 0.0, 110.0, 75.0, 48.0, 30.0, 6.0, 3.0, 82.0, 1.0, 1.0, 5.0, 123.0, 82.0, 7.0, 0.0, 51.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8029784024033437, "mean_inference_ms": 1.872199748160512, "mean_action_processing_ms": 0.32255816552031924, "mean_env_wait_ms": 0.24815825568124625, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007304549217224121, "StateBufferConnector_ms": 0.0036428372065226236, "ViewRequirementAgentConnector_ms": 0.23034479882982042}, "num_episodes": 18, "episode_return_max": 318.5000000000001, "episode_return_min": -123.10000000000036, "episode_return_mean": 52.54999999999998, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 32000, "num_agent_steps_trained": 32000, "num_env_steps_sampled": 8000, "num_env_steps_trained": 8000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 73.76579600185563, "num_env_steps_trained_throughput_per_sec": 73.76579600185563, "timesteps_total": 8000, "num_env_steps_sampled_lifetime": 8000, "num_agent_steps_sampled_lifetime": 32000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 32000, "timers": {"training_iteration_time_ms": 55588.338, "restore_workers_time_ms": 0.035, "training_step_time_ms": 55588.248, "sample_time_ms": 1577.038, "learn_time_ms": 53994.015, "learn_throughput": 74.082, "synch_weights_time_ms": 11.241}, "counters": {"num_env_steps_sampled": 8000, "num_env_steps_trained": 8000, "num_agent_steps_sampled": 32000, "num_agent_steps_trained": 32000}, "done": false, "training_iteration": 2, "trial_id": "11e70_00000", "date": "2024-08-12_23-08-50", "timestamp": 1723518530, "time_this_iter_s": 54.24736189842224, "time_total_s": 111.25887703895569, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2b59700>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 111.25887703895569, "iterations_since_restore": 2, "perf": {"cpu_util_percent": 43.13333333333333, "ram_util_percent": 80.59753086419754}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7892567942066797, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.457775247286237, "policy_loss": -0.010485536178140334, "vf_loss": 4.466621523307114, "vf_explained_var": 0.010459462233952114, "kl": 0.005464200843043067, "entropy": 1.5840066469535625, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 4725.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.238677484900863, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.980084675077408, "policy_loss": -0.014821235798225398, "vf_loss": 7.99270704763907, "vf_explained_var": 0.0090733373291278, "kl": 0.014659046555231054, "entropy": 1.5731455399245813, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 4725.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 12000, "num_env_steps_trained": 12000, "num_agent_steps_sampled": 48000, "num_agent_steps_trained": 48000}, "env_runners": {"episode_reward_max": 318.5000000000001, "episode_reward_min": -128.40000000000043, "episode_reward_mean": 55.59444444444438, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 10800, "policy_reward_min": {"prey_policy": -314.7999999999998, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 194.59999999999997, "predator_policy": 166.0}, "policy_reward_mean": {"prey_policy": -7.3138888888889575, "predator_policy": 35.111111111111114}, "custom_metrics": {}, "hist_stats": {"episode_reward": [205.2999999999997, 26.10000000000045, 85.00000000000006, 166.09999999999897, 0.20000000000001794, -123.10000000000036, 35.20000000000038, 43.600000000000364, -14.399999999999972, 59.30000000000049, 33.400000000000205, 29.59999999999996, 62.80000000000026, 24.700000000000287, -42.400000000000176, 68.59999999999997, 140.79999999999876, -3.9999999999997313, 109.59999999999982, 83.40000000000006, 318.5000000000001, 25.600000000000193, -52.59999999999982, 18.600000000000044, 88.49999999999997, 42.39999999999997, -7.299999999999805, 213.9999999999992, -81.00000000000009, -44.299999999999876, 34.9000000000001, 178.09999999999997, 81.89999999999962, 72.60000000000001, 32.400000000000226, -20.300000000000054, 47.80000000000027, 254.4999999999999, -103.80000000000103, 42.10000000000008, 124.59999999999874, 34.0000000000002, -1.3999999999999861, -24.4999999999999, -128.40000000000043, 219.69999999999908, 142.79999999999984, 137.79999999999987, 77.09999999999997, 279.79999999999995, 107.49999999999991, -8.299999999999953, -62.30000000000004, -28.699999999999847], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [117.49999999999974, 69.80000000000004, 47.90000000000024, -59.79999999999996, 14.599999999999959, 43.4, 101.60000000000001, 51.50000000000022, 30.80000000000002, -76.59999999999995, -269.8, -7.300000000000029, -3.9999999999998934, -17.79999999999974, 20.000000000000014, 23.60000000000008, 37.100000000000094, -116.50000000000011, 20.000000000000014, 32.30000000000023, 20.000000000000014, 7.399999999999965, 42.2, -55.600000000000016, -23.49999999999993, 20.30000000000007, -21.999999999999744, -16.299999999999997, -9.399999999999855, -85.00000000000085, 9.499999999999972, 31.09999999999998, 20.000000000000014, 120.7999999999995, 20.000000000000014, -64.00000000000091, -129.1000000000006, 166.70000000000002, 141.2, -164.8000000000001, 172.6999999999999, 138.79999999999998, -115.60000000000068, 60.20000000000008, -54.9999999999999, -184.6, 4.999999999999979, -39.39999999999996, 0.4999999999999716, 26.000000000000128, -190.90000000000018, 125.29999999999978, -70.30000000000067, 20.000000000000014, 24.50000000000009, 186.49999999999997, -211.00000000000017, 20.000000000000014, 1.0999999999999794, -168.40000000000023, 20.000000000000014, -21.099999999999802, -33.10000000000004, 126.19999999999999, 59.90000000000021, 20.000000000000014, 97.40000000000003, -152.8000000000002, 95.59999999999998, -152.20000000000056, -36.70000000000003, -34.599999999999866, 20.000000000000014, 21.800000000000004, 67.4, 145.09999999999988, -127.90000000000006, -88.90000000000069, -94.89999999999998, 70.99999999999999, 20.000000000000014, 104.59999999999944, -68.50000000000003, 9.499999999999947, -126.10000000000008, 10.699999999999974, 71.30000000000013, -314.7999999999998, -221.20000000000024, -215.20000000000013, 104.59999999999948, 109.09999999999965, -5.50000000000027, 74.2999999999999, 27.499999999999993, 41.300000000000075, -166.90000000000015, 119.0, 42.199999999999875, 194.59999999999997, 87.49999999999997, 20.000000000000014, -261.40000000000003, 70.09999999999988, -253.0, 22.700000000000063, 9.79999999999999, -131.5000000000004], "policy_predator_policy_reward": [0.0, 18.0, 0.0, 38.0, 27.0, 0.0, 13.0, 0.0, 0.0, 46.0, 16.0, 138.0, 8.0, 49.0, 0.0, 0.0, 65.0, 0.0, 0.0, 7.0, 6.0, 0.0, 43.0, 0.0, 29.0, 37.0, 0.0, 63.0, 50.0, 2.0, 0.0, 28.0, 0.0, 0.0, 0.0, 40.0, 71.0, 1.0, 97.0, 10.0, 3.0, 4.0, 13.0, 68.0, 52.0, 135.0, 8.0, 45.0, 54.0, 8.0, 106.0, 2.0, 0.0, 43.0, 3.0, 0.0, 0.0, 110.0, 75.0, 48.0, 30.0, 6.0, 3.0, 82.0, 1.0, 1.0, 5.0, 123.0, 82.0, 7.0, 0.0, 51.0, 6.0, 0.0, 0.0, 42.0, 62.0, 51.0, 10.0, 56.0, 0.0, 0.0, 93.0, 0.0, 114.0, 0.0, 154.0, 65.0, 165.0, 143.0, 0.0, 6.0, 22.0, 52.0, 34.0, 35.0, 0.0, 125.0, 43.0, 0.0, 0.0, 0.0, 166.0, 17.0, 38.0, 130.0, 49.0, 44.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7849396189524588, "mean_inference_ms": 1.836833524763357, "mean_action_processing_ms": 0.31606629150442317, "mean_env_wait_ms": 0.2430231638536353, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007048138865718135, "StateBufferConnector_ms": 0.0034453692259611905, "ViewRequirementAgentConnector_ms": 0.18711090087890625}, "num_episodes": 18, "episode_return_max": 318.5000000000001, "episode_return_min": -128.40000000000043, "episode_return_mean": 55.59444444444438, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 48000, "num_agent_steps_trained": 48000, "num_env_steps_sampled": 12000, "num_env_steps_trained": 12000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 77.71198805397259, "num_env_steps_trained_throughput_per_sec": 77.71198805397259, "timesteps_total": 12000, "num_env_steps_sampled_lifetime": 12000, "num_agent_steps_sampled_lifetime": 48000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 48000, "timers": {"training_iteration_time_ms": 54216.264, "restore_workers_time_ms": 0.028, "training_step_time_ms": 54216.19, "sample_time_ms": 1455.33, "learn_time_ms": 52745.17, "learn_throughput": 75.836, "synch_weights_time_ms": 11.207}, "counters": {"num_env_steps_sampled": 12000, "num_env_steps_trained": 12000, "num_agent_steps_sampled": 48000, "num_agent_steps_trained": 48000}, "done": false, "training_iteration": 3, "trial_id": "11e70_00000", "date": "2024-08-12_23-09-41", "timestamp": 1723518581, "time_this_iter_s": 51.48535919189453, "time_total_s": 162.74423623085022, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2af5d30>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 162.74423623085022, "iterations_since_restore": 3, "perf": {"cpu_util_percent": 38.22027027027027, "ram_util_percent": 81.36351351351352}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5378904705798184, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.476772289175205, "policy_loss": -0.012201770534615708, "vf_loss": 3.4870147529733244, "vf_explained_var": 0.00912992761879371, "kl": 0.006531006887197697, "entropy": 1.5816458823188904, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 6615.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.9664585196467304, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.474794582841257, "policy_loss": -0.0120695919424256, "vf_loss": 6.485553711684292, "vf_explained_var": 0.029866930826631173, "kl": 0.008736503005187761, "entropy": 1.5607386124827873, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 6615.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 16000, "num_env_steps_trained": 16000, "num_agent_steps_sampled": 64000, "num_agent_steps_trained": 64000}, "env_runners": {"episode_reward_max": 318.5000000000001, "episode_reward_min": -293.20000000000016, "episode_reward_mean": 59.12222222222211, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 14400, "policy_reward_min": {"prey_policy": -322.8, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 194.59999999999997, "predator_policy": 186.0}, "policy_reward_mean": {"prey_policy": -5.855555555555609, "predator_policy": 35.416666666666664}, "custom_metrics": {}, "hist_stats": {"episode_reward": [205.2999999999997, 26.10000000000045, 85.00000000000006, 166.09999999999897, 0.20000000000001794, -123.10000000000036, 35.20000000000038, 43.600000000000364, -14.399999999999972, 59.30000000000049, 33.400000000000205, 29.59999999999996, 62.80000000000026, 24.700000000000287, -42.400000000000176, 68.59999999999997, 140.79999999999876, -3.9999999999997313, 109.59999999999982, 83.40000000000006, 318.5000000000001, 25.600000000000193, -52.59999999999982, 18.600000000000044, 88.49999999999997, 42.39999999999997, -7.299999999999805, 213.9999999999992, -81.00000000000009, -44.299999999999876, 34.9000000000001, 178.09999999999997, 81.89999999999962, 72.60000000000001, 32.400000000000226, -20.300000000000054, 47.80000000000027, 254.4999999999999, -103.80000000000103, 42.10000000000008, 124.59999999999874, 34.0000000000002, -1.3999999999999861, -24.4999999999999, -128.40000000000043, 219.69999999999908, 142.79999999999984, 137.79999999999987, 77.09999999999997, 279.79999999999995, 107.49999999999991, -8.299999999999953, -62.30000000000004, -28.699999999999847, -2.2000000000000064, -21.999999999999854, -84.19999999999987, 152.29999999999944, -293.20000000000016, 148.29999999999964, -30.099999999999888, -8.599999999999842, 163.4999999999995, 98.19999999999993, 247.4999999999996, 208.59999999999943, 87.00000000000006, 27.300000000000253, 18.90000000000007, 105.9999999999996, 230.89999999999938, 206.49999999999918], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [117.49999999999974, 69.80000000000004, 47.90000000000024, -59.79999999999996, 14.599999999999959, 43.4, 101.60000000000001, 51.50000000000022, 30.80000000000002, -76.59999999999995, -269.8, -7.300000000000029, -3.9999999999998934, -17.79999999999974, 20.000000000000014, 23.60000000000008, 37.100000000000094, -116.50000000000011, 20.000000000000014, 32.30000000000023, 20.000000000000014, 7.399999999999965, 42.2, -55.600000000000016, -23.49999999999993, 20.30000000000007, -21.999999999999744, -16.299999999999997, -9.399999999999855, -85.00000000000085, 9.499999999999972, 31.09999999999998, 20.000000000000014, 120.7999999999995, 20.000000000000014, -64.00000000000091, -129.1000000000006, 166.70000000000002, 141.2, -164.8000000000001, 172.6999999999999, 138.79999999999998, -115.60000000000068, 60.20000000000008, -54.9999999999999, -184.6, 4.999999999999979, -39.39999999999996, 0.4999999999999716, 26.000000000000128, -190.90000000000018, 125.29999999999978, -70.30000000000067, 20.000000000000014, 24.50000000000009, 186.49999999999997, -211.00000000000017, 20.000000000000014, 1.0999999999999794, -168.40000000000023, 20.000000000000014, -21.099999999999802, -33.10000000000004, 126.19999999999999, 59.90000000000021, 20.000000000000014, 97.40000000000003, -152.8000000000002, 95.59999999999998, -152.20000000000056, -36.70000000000003, -34.599999999999866, 20.000000000000014, 21.800000000000004, 67.4, 145.09999999999988, -127.90000000000006, -88.90000000000069, -94.89999999999998, 70.99999999999999, 20.000000000000014, 104.59999999999944, -68.50000000000003, 9.499999999999947, -126.10000000000008, 10.699999999999974, 71.30000000000013, -314.7999999999998, -221.20000000000024, -215.20000000000013, 104.59999999999948, 109.09999999999965, -5.50000000000027, 74.2999999999999, 27.499999999999993, 41.300000000000075, -166.90000000000015, 119.0, 42.199999999999875, 194.59999999999997, 87.49999999999997, 20.000000000000014, -261.40000000000003, 70.09999999999988, -253.0, 22.700000000000063, 9.79999999999999, -131.5000000000004, -230.79999999999998, 38.60000000000001, -181.0, 20.000000000000014, 29.000000000000163, -257.2000000000003, -76.90000000000055, 162.19999999999993, -322.8, -156.4, 98.30000000000001, 20.000000000000014, -97.6, -50.50000000000003, 20.000000000000014, -118.60000000000036, 83.60000000000002, 35.9000000000002, -50.8, 59.000000000000036, 90.20000000000007, 155.29999999999995, 181.1, 24.500000000000068, 58.99999999999997, 20.000000000000014, 20.000000000000014, -33.70000000000003, -47.8, -28.29999999999975, 94.1, -45.09999999999976, 143.29999999999978, 83.59999999999997, 186.49999999999991, 20.000000000000014], "policy_predator_policy_reward": [0.0, 18.0, 0.0, 38.0, 27.0, 0.0, 13.0, 0.0, 0.0, 46.0, 16.0, 138.0, 8.0, 49.0, 0.0, 0.0, 65.0, 0.0, 0.0, 7.0, 6.0, 0.0, 43.0, 0.0, 29.0, 37.0, 0.0, 63.0, 50.0, 2.0, 0.0, 28.0, 0.0, 0.0, 0.0, 40.0, 71.0, 1.0, 97.0, 10.0, 3.0, 4.0, 13.0, 68.0, 52.0, 135.0, 8.0, 45.0, 54.0, 8.0, 106.0, 2.0, 0.0, 43.0, 3.0, 0.0, 0.0, 110.0, 75.0, 48.0, 30.0, 6.0, 3.0, 82.0, 1.0, 1.0, 5.0, 123.0, 82.0, 7.0, 0.0, 51.0, 6.0, 0.0, 0.0, 42.0, 62.0, 51.0, 10.0, 56.0, 0.0, 0.0, 93.0, 0.0, 114.0, 0.0, 154.0, 65.0, 165.0, 143.0, 0.0, 6.0, 22.0, 52.0, 34.0, 35.0, 0.0, 125.0, 43.0, 0.0, 0.0, 0.0, 166.0, 17.0, 38.0, 130.0, 49.0, 44.0, 131.0, 59.0, 34.0, 105.0, 73.0, 71.0, 5.0, 62.0, 0.0, 186.0, 0.0, 30.0, 0.0, 118.0, 3.0, 87.0, 13.0, 31.0, 26.0, 64.0, 0.0, 2.0, 3.0, 0.0, 8.0, 0.0, 41.0, 0.0, 46.0, 49.0, 57.0, 0.0, 0.0, 4.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7679545795033051, "mean_inference_ms": 1.798425905074305, "mean_action_processing_ms": 0.30952824591256023, "mean_env_wait_ms": 0.23752901864619258, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006920927100711399, "StateBufferConnector_ms": 0.0033918354246351454, "ViewRequirementAgentConnector_ms": 0.16552060842514038}, "num_episodes": 18, "episode_return_max": 318.5000000000001, "episode_return_min": -293.20000000000016, "episode_return_mean": 59.12222222222211, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 64000, "num_agent_steps_trained": 64000, "num_env_steps_sampled": 16000, "num_env_steps_trained": 16000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 76.20525136221777, "num_env_steps_trained_throughput_per_sec": 76.20525136221777, "timesteps_total": 16000, "num_env_steps_sampled_lifetime": 16000, "num_agent_steps_sampled_lifetime": 64000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 64000, "timers": {"training_iteration_time_ms": 53784.655, "restore_workers_time_ms": 0.024, "training_step_time_ms": 53784.589, "sample_time_ms": 1387.909, "learn_time_ms": 52381.651, "learn_throughput": 76.363, "synch_weights_time_ms": 11.162}, "counters": {"num_env_steps_sampled": 16000, "num_env_steps_trained": 16000, "num_agent_steps_sampled": 64000, "num_agent_steps_trained": 64000}, "done": false, "training_iteration": 4, "trial_id": "11e70_00000", "date": "2024-08-12_23-10-34", "timestamp": 1723518634, "time_this_iter_s": 52.53674006462097, "time_total_s": 215.2809762954712, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2b624c0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 215.2809762954712, "iterations_since_restore": 4, "perf": {"cpu_util_percent": 41.21621621621621, "ram_util_percent": 82.60000000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5196869665668125, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.7282437190807687, "policy_loss": -0.011309246233388505, "vf_loss": 2.7370657400479392, "vf_explained_var": 0.01582812089768667, "kl": 0.008290768203768934, "entropy": 1.5778723713582155, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 8505.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.281099994409652, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.749038871886238, "policy_loss": -0.010468807142282092, "vf_loss": 6.75806615718458, "vf_explained_var": 0.059277668548008755, "kl": 0.009610212243947256, "entropy": 1.55540513147122, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 8505.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 20000, "num_env_steps_trained": 20000, "num_agent_steps_sampled": 80000, "num_agent_steps_trained": 80000}, "env_runners": {"episode_reward_max": 337.0, "episode_reward_min": -293.20000000000016, "episode_reward_mean": 73.4222222222221, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 19800, "policy_reward_min": {"prey_policy": -322.8, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 199.0}, "policy_reward_mean": {"prey_policy": 3.6555555555555186, "predator_policy": 33.05555555555556}, "custom_metrics": {}, "hist_stats": {"episode_reward": [205.2999999999997, 26.10000000000045, 85.00000000000006, 166.09999999999897, 0.20000000000001794, -123.10000000000036, 35.20000000000038, 43.600000000000364, -14.399999999999972, 59.30000000000049, 33.400000000000205, 29.59999999999996, 62.80000000000026, 24.700000000000287, -42.400000000000176, 68.59999999999997, 140.79999999999876, -3.9999999999997313, 109.59999999999982, 83.40000000000006, 318.5000000000001, 25.600000000000193, -52.59999999999982, 18.600000000000044, 88.49999999999997, 42.39999999999997, -7.299999999999805, 213.9999999999992, -81.00000000000009, -44.299999999999876, 34.9000000000001, 178.09999999999997, 81.89999999999962, 72.60000000000001, 32.400000000000226, -20.300000000000054, 47.80000000000027, 254.4999999999999, -103.80000000000103, 42.10000000000008, 124.59999999999874, 34.0000000000002, -1.3999999999999861, -24.4999999999999, -128.40000000000043, 219.69999999999908, 142.79999999999984, 137.79999999999987, 77.09999999999997, 279.79999999999995, 107.49999999999991, -8.299999999999953, -62.30000000000004, -28.699999999999847, -2.2000000000000064, -21.999999999999854, -84.19999999999987, 152.29999999999944, -293.20000000000016, 148.29999999999964, -30.099999999999888, -8.599999999999842, 163.4999999999995, 98.19999999999993, 247.4999999999996, 208.59999999999943, 87.00000000000006, 27.300000000000253, 18.90000000000007, 105.9999999999996, 230.89999999999938, 206.49999999999918, 60.4000000000002, 74.20000000000019, 190.5, 119.49999999999974, 47.20000000000017, 157.1, 67.39999999999984, 325.69999999999993, 80.00000000000006, 42.000000000000014, 128.39999999999972, 56.20000000000046, 42.700000000000294, 35.600000000000236, 86.20000000000007, 157.99999999999926, 185.6999999999994, -41.49999999999997, 126.59999999999978, 258.7999999999997, 192.19999999999928, 332.0, -237.9000000000012, -33.599999999999866, 51.700000000000095, 337.0, 169.8999999999989], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [117.49999999999974, 69.80000000000004, 47.90000000000024, -59.79999999999996, 14.599999999999959, 43.4, 101.60000000000001, 51.50000000000022, 30.80000000000002, -76.59999999999995, -269.8, -7.300000000000029, -3.9999999999998934, -17.79999999999974, 20.000000000000014, 23.60000000000008, 37.100000000000094, -116.50000000000011, 20.000000000000014, 32.30000000000023, 20.000000000000014, 7.399999999999965, 42.2, -55.600000000000016, -23.49999999999993, 20.30000000000007, -21.999999999999744, -16.299999999999997, -9.399999999999855, -85.00000000000085, 9.499999999999972, 31.09999999999998, 20.000000000000014, 120.7999999999995, 20.000000000000014, -64.00000000000091, -129.1000000000006, 166.70000000000002, 141.2, -164.8000000000001, 172.6999999999999, 138.79999999999998, -115.60000000000068, 60.20000000000008, -54.9999999999999, -184.6, 4.999999999999979, -39.39999999999996, 0.4999999999999716, 26.000000000000128, -190.90000000000018, 125.29999999999978, -70.30000000000067, 20.000000000000014, 24.50000000000009, 186.49999999999997, -211.00000000000017, 20.000000000000014, 1.0999999999999794, -168.40000000000023, 20.000000000000014, -21.099999999999802, -33.10000000000004, 126.19999999999999, 59.90000000000021, 20.000000000000014, 97.40000000000003, -152.8000000000002, 95.59999999999998, -152.20000000000056, -36.70000000000003, -34.599999999999866, 20.000000000000014, 21.800000000000004, 67.4, 145.09999999999988, -127.90000000000006, -88.90000000000069, -94.89999999999998, 70.99999999999999, 20.000000000000014, 104.59999999999944, -68.50000000000003, 9.499999999999947, -126.10000000000008, 10.699999999999974, 71.30000000000013, -314.7999999999998, -221.20000000000024, -215.20000000000013, 104.59999999999948, 109.09999999999965, -5.50000000000027, 74.2999999999999, 27.499999999999993, 41.300000000000075, -166.90000000000015, 119.0, 42.199999999999875, 194.59999999999997, 87.49999999999997, 20.000000000000014, -261.40000000000003, 70.09999999999988, -253.0, 22.700000000000063, 9.79999999999999, -131.5000000000004, -230.79999999999998, 38.60000000000001, -181.0, 20.000000000000014, 29.000000000000163, -257.2000000000003, -76.90000000000055, 162.19999999999993, -322.8, -156.4, 98.30000000000001, 20.000000000000014, -97.6, -50.50000000000003, 20.000000000000014, -118.60000000000036, 83.60000000000002, 35.9000000000002, -50.8, 59.000000000000036, 90.20000000000007, 155.29999999999995, 181.1, 24.500000000000068, 58.99999999999997, 20.000000000000014, 20.000000000000014, -33.70000000000003, -47.8, -28.29999999999975, 94.1, -45.09999999999976, 143.29999999999978, 83.59999999999997, 186.49999999999991, 20.000000000000014, -37.599999999999994, 20.000000000000014, 20.000000000000014, 54.199999999999974, 186.5, -97.0, 120.49999999999999, -21.999999999999808, 49.70000000000006, -74.50000000000045, 109.1, -28.0, -50.79999999999998, 24.20000000000011, 118.1, 182.6, 7.999999999999972, -7.0, 13.99999999999999, -85.0, 108.8, -30.399999999999757, 20.000000000000014, 36.20000000000022, 22.700000000000063, 20.000000000000014, 11.599999999999964, 20.000000000000014, 25.39999999999999, -5.19999999999993, 44.0, 65.00000000000014, 30.799999999999997, 140.89999999999998, -146.8, -36.69999999999977, 110.90000000000003, -28.299999999999777, 157.4, 88.39999999999966, 165.5, 13.699999999999946, 170.9, 160.1, -251.09999999999957, -185.80000000000052, -68.20000000000006, -60.39999999999998, 134.0, -175.30000000000038, 137.0, 200.0, 111.80000000000013, 55.10000000000021], "policy_predator_policy_reward": [0.0, 18.0, 0.0, 38.0, 27.0, 0.0, 13.0, 0.0, 0.0, 46.0, 16.0, 138.0, 8.0, 49.0, 0.0, 0.0, 65.0, 0.0, 0.0, 7.0, 6.0, 0.0, 43.0, 0.0, 29.0, 37.0, 0.0, 63.0, 50.0, 2.0, 0.0, 28.0, 0.0, 0.0, 0.0, 40.0, 71.0, 1.0, 97.0, 10.0, 3.0, 4.0, 13.0, 68.0, 52.0, 135.0, 8.0, 45.0, 54.0, 8.0, 106.0, 2.0, 0.0, 43.0, 3.0, 0.0, 0.0, 110.0, 75.0, 48.0, 30.0, 6.0, 3.0, 82.0, 1.0, 1.0, 5.0, 123.0, 82.0, 7.0, 0.0, 51.0, 6.0, 0.0, 0.0, 42.0, 62.0, 51.0, 10.0, 56.0, 0.0, 0.0, 93.0, 0.0, 114.0, 0.0, 154.0, 65.0, 165.0, 143.0, 0.0, 6.0, 22.0, 52.0, 34.0, 35.0, 0.0, 125.0, 43.0, 0.0, 0.0, 0.0, 166.0, 17.0, 38.0, 130.0, 49.0, 44.0, 131.0, 59.0, 34.0, 105.0, 73.0, 71.0, 5.0, 62.0, 0.0, 186.0, 0.0, 30.0, 0.0, 118.0, 3.0, 87.0, 13.0, 31.0, 26.0, 64.0, 0.0, 2.0, 3.0, 0.0, 8.0, 0.0, 41.0, 0.0, 46.0, 49.0, 57.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 78.0, 0.0, 0.0, 98.0, 3.0, 0.0, 21.0, 72.0, 0.0, 0.0, 76.0, 21.0, 73.0, 25.0, 0.0, 79.0, 0.0, 89.0, 24.0, 0.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 12.0, 54.0, 49.0, 0.0, 14.0, 0.0, 97.0, 45.0, 12.0, 32.0, 0.0, 13.0, 3.0, 10.0, 1.0, 0.0, 0.0, 199.0, 59.0, 36.0, 93.0, 0.0, 0.0, 0.0, 3.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7612660845441268, "mean_inference_ms": 1.786010938316093, "mean_action_processing_ms": 0.30673965185444185, "mean_env_wait_ms": 0.23565575810169828, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007270442114935981, "StateBufferConnector_ms": 0.003792541195647885, "ViewRequirementAgentConnector_ms": 0.16087125046084624}, "num_episodes": 27, "episode_return_max": 337.0, "episode_return_min": -293.20000000000016, "episode_return_mean": 73.4222222222221, "episodes_this_iter": 27}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 80000, "num_agent_steps_trained": 80000, "num_env_steps_sampled": 20000, "num_env_steps_trained": 20000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 74.47658003401862, "num_env_steps_trained_throughput_per_sec": 74.47658003401862, "timesteps_total": 20000, "num_env_steps_sampled_lifetime": 20000, "num_agent_steps_sampled_lifetime": 80000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 80000, "timers": {"training_iteration_time_ms": 53769.357, "restore_workers_time_ms": 0.022, "training_step_time_ms": 53769.297, "sample_time_ms": 1442.731, "learn_time_ms": 52312.313, "learn_throughput": 76.464, "synch_weights_time_ms": 10.905}, "counters": {"num_env_steps_sampled": 20000, "num_env_steps_trained": 20000, "num_agent_steps_sampled": 80000, "num_agent_steps_trained": 80000}, "done": false, "training_iteration": 5, "trial_id": "11e70_00000", "date": "2024-08-12_23-11-28", "timestamp": 1723518688, "time_this_iter_s": 53.721609354019165, "time_total_s": 269.00258564949036, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2b61700>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 269.00258564949036, "iterations_since_restore": 5, "perf": {"cpu_util_percent": 43.38181818181818, "ram_util_percent": 82.63766233766232}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.848484000989369, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.543545341743994, "policy_loss": -0.010705803956087463, "vf_loss": 4.55188996577389, "vf_explained_var": 0.02173439008849008, "kl": 0.007870589324116143, "entropy": 1.5810490974042781, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 10395.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.7223818762907905, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.850488162671448, "policy_loss": -0.0112663999297188, "vf_loss": 8.859814155921734, "vf_explained_var": 0.08336956595617627, "kl": 0.012936210028642776, "entropy": 1.535103233844515, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 10395.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 24000, "num_env_steps_trained": 24000, "num_agent_steps_sampled": 96000, "num_agent_steps_trained": 96000}, "env_runners": {"episode_reward_max": 343.5, "episode_reward_min": -293.20000000000016, "episode_reward_mean": 89.01199999999989, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -322.8, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 199.0}, "policy_reward_mean": {"prey_policy": 7.5959999999999575, "predator_policy": 36.91}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-3.9999999999997313, 109.59999999999982, 83.40000000000006, 318.5000000000001, 25.600000000000193, -52.59999999999982, 18.600000000000044, 88.49999999999997, 42.39999999999997, -7.299999999999805, 213.9999999999992, -81.00000000000009, -44.299999999999876, 34.9000000000001, 178.09999999999997, 81.89999999999962, 72.60000000000001, 32.400000000000226, -20.300000000000054, 47.80000000000027, 254.4999999999999, -103.80000000000103, 42.10000000000008, 124.59999999999874, 34.0000000000002, -1.3999999999999861, -24.4999999999999, -128.40000000000043, 219.69999999999908, 142.79999999999984, 137.79999999999987, 77.09999999999997, 279.79999999999995, 107.49999999999991, -8.299999999999953, -62.30000000000004, -28.699999999999847, -2.2000000000000064, -21.999999999999854, -84.19999999999987, 152.29999999999944, -293.20000000000016, 148.29999999999964, -30.099999999999888, -8.599999999999842, 163.4999999999995, 98.19999999999993, 247.4999999999996, 208.59999999999943, 87.00000000000006, 27.300000000000253, 18.90000000000007, 105.9999999999996, 230.89999999999938, 206.49999999999918, 60.4000000000002, 74.20000000000019, 190.5, 119.49999999999974, 47.20000000000017, 157.1, 67.39999999999984, 325.69999999999993, 80.00000000000006, 42.000000000000014, 128.39999999999972, 56.20000000000046, 42.700000000000294, 35.600000000000236, 86.20000000000007, 157.99999999999926, 185.6999999999994, -41.49999999999997, 126.59999999999978, 258.7999999999997, 192.19999999999928, 332.0, -237.9000000000012, -33.599999999999866, 51.700000000000095, 337.0, 169.8999999999989, 97.40000000000003, 202.9, 269.20000000000005, 316.6, -137.7000000000002, 100.69999999999987, 141.99999999999963, 120.00000000000003, -69.0, 343.5, 303.19999999999993, 83.20000000000019, 137.3, 52.30000000000018, -192.3000000000005, 303.5999999999999, 211.8999999999993, 148.4], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, -64.00000000000091, -129.1000000000006, 166.70000000000002, 141.2, -164.8000000000001, 172.6999999999999, 138.79999999999998, -115.60000000000068, 60.20000000000008, -54.9999999999999, -184.6, 4.999999999999979, -39.39999999999996, 0.4999999999999716, 26.000000000000128, -190.90000000000018, 125.29999999999978, -70.30000000000067, 20.000000000000014, 24.50000000000009, 186.49999999999997, -211.00000000000017, 20.000000000000014, 1.0999999999999794, -168.40000000000023, 20.000000000000014, -21.099999999999802, -33.10000000000004, 126.19999999999999, 59.90000000000021, 20.000000000000014, 97.40000000000003, -152.8000000000002, 95.59999999999998, -152.20000000000056, -36.70000000000003, -34.599999999999866, 20.000000000000014, 21.800000000000004, 67.4, 145.09999999999988, -127.90000000000006, -88.90000000000069, -94.89999999999998, 70.99999999999999, 20.000000000000014, 104.59999999999944, -68.50000000000003, 9.499999999999947, -126.10000000000008, 10.699999999999974, 71.30000000000013, -314.7999999999998, -221.20000000000024, -215.20000000000013, 104.59999999999948, 109.09999999999965, -5.50000000000027, 74.2999999999999, 27.499999999999993, 41.300000000000075, -166.90000000000015, 119.0, 42.199999999999875, 194.59999999999997, 87.49999999999997, 20.000000000000014, -261.40000000000003, 70.09999999999988, -253.0, 22.700000000000063, 9.79999999999999, -131.5000000000004, -230.79999999999998, 38.60000000000001, -181.0, 20.000000000000014, 29.000000000000163, -257.2000000000003, -76.90000000000055, 162.19999999999993, -322.8, -156.4, 98.30000000000001, 20.000000000000014, -97.6, -50.50000000000003, 20.000000000000014, -118.60000000000036, 83.60000000000002, 35.9000000000002, -50.8, 59.000000000000036, 90.20000000000007, 155.29999999999995, 181.1, 24.500000000000068, 58.99999999999997, 20.000000000000014, 20.000000000000014, -33.70000000000003, -47.8, -28.29999999999975, 94.1, -45.09999999999976, 143.29999999999978, 83.59999999999997, 186.49999999999991, 20.000000000000014, -37.599999999999994, 20.000000000000014, 20.000000000000014, 54.199999999999974, 186.5, -97.0, 120.49999999999999, -21.999999999999808, 49.70000000000006, -74.50000000000045, 109.1, -28.0, -50.79999999999998, 24.20000000000011, 118.1, 182.6, 7.999999999999972, -7.0, 13.99999999999999, -85.0, 108.8, -30.399999999999757, 20.000000000000014, 36.20000000000022, 22.700000000000063, 20.000000000000014, 11.599999999999964, 20.000000000000014, 25.39999999999999, -5.19999999999993, 44.0, 65.00000000000014, 30.799999999999997, 140.89999999999998, -146.8, -36.69999999999977, 110.90000000000003, -28.299999999999777, 157.4, 88.39999999999966, 165.5, 13.699999999999946, 170.9, 160.1, -251.09999999999957, -185.80000000000052, -68.20000000000006, -60.39999999999998, 134.0, -175.30000000000038, 137.0, 200.0, 111.80000000000013, 55.10000000000021, 29.0, -55.60000000000008, 71.6, 62.3, 158.6, 77.60000000000002, 158.0, 134.6, -204.70000000000016, -157.0, -183.70000000000053, 187.39999999999995, 38.900000000000254, 73.1, -45.10000000000018, 70.10000000000002, -277.0, -31.0, 167.0, 159.5, 123.2, 154.99999999999994, 7.700000000000109, -5.5, -90.70000000000002, 116.0, 7.39999999999996, -21.099999999999994, -80.79999999999978, -284.50000000000034, 196.4, 84.20000000000005, 191.9, 20.000000000000014, 89.0, -28.599999999999994], "policy_predator_policy_reward": [0.0, 40.0, 71.0, 1.0, 97.0, 10.0, 3.0, 4.0, 13.0, 68.0, 52.0, 135.0, 8.0, 45.0, 54.0, 8.0, 106.0, 2.0, 0.0, 43.0, 3.0, 0.0, 0.0, 110.0, 75.0, 48.0, 30.0, 6.0, 3.0, 82.0, 1.0, 1.0, 5.0, 123.0, 82.0, 7.0, 0.0, 51.0, 6.0, 0.0, 0.0, 42.0, 62.0, 51.0, 10.0, 56.0, 0.0, 0.0, 93.0, 0.0, 114.0, 0.0, 154.0, 65.0, 165.0, 143.0, 0.0, 6.0, 22.0, 52.0, 34.0, 35.0, 0.0, 125.0, 43.0, 0.0, 0.0, 0.0, 166.0, 17.0, 38.0, 130.0, 49.0, 44.0, 131.0, 59.0, 34.0, 105.0, 73.0, 71.0, 5.0, 62.0, 0.0, 186.0, 0.0, 30.0, 0.0, 118.0, 3.0, 87.0, 13.0, 31.0, 26.0, 64.0, 0.0, 2.0, 3.0, 0.0, 8.0, 0.0, 41.0, 0.0, 46.0, 49.0, 57.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 78.0, 0.0, 0.0, 98.0, 3.0, 0.0, 21.0, 72.0, 0.0, 0.0, 76.0, 21.0, 73.0, 25.0, 0.0, 79.0, 0.0, 89.0, 24.0, 0.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 12.0, 54.0, 49.0, 0.0, 14.0, 0.0, 97.0, 45.0, 12.0, 32.0, 0.0, 13.0, 3.0, 10.0, 1.0, 0.0, 0.0, 199.0, 59.0, 36.0, 93.0, 0.0, 0.0, 0.0, 3.0, 0.0, 107.0, 17.0, 51.0, 18.0, 33.0, 0.0, 24.0, 0.0, 120.0, 104.0, 0.0, 97.0, 0.0, 30.0, 27.0, 68.0, 78.0, 161.0, 3.0, 14.0, 23.0, 2.0, 30.0, 51.0, 32.0, 80.0, 12.0, 54.0, 133.0, 40.0, 0.0, 23.0, 0.0, 0.0, 8.0, 80.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7483047643512932, "mean_inference_ms": 1.760985089414413, "mean_action_processing_ms": 0.3032172759833582, "mean_env_wait_ms": 0.23260142833920347, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006705760955810547, "StateBufferConnector_ms": 0.003782510757446289, "ViewRequirementAgentConnector_ms": 0.15968823432922363}, "num_episodes": 18, "episode_return_max": 343.5, "episode_return_min": -293.20000000000016, "episode_return_mean": 89.01199999999989, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 96000, "num_agent_steps_trained": 96000, "num_env_steps_sampled": 24000, "num_env_steps_trained": 24000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 76.44711553737112, "num_env_steps_trained_throughput_per_sec": 76.44711553737112, "timesteps_total": 24000, "num_env_steps_sampled_lifetime": 24000, "num_agent_steps_sampled_lifetime": 96000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 96000, "timers": {"training_iteration_time_ms": 53528.425, "restore_workers_time_ms": 0.02, "training_step_time_ms": 53528.368, "sample_time_ms": 1400.615, "learn_time_ms": 52113.942, "learn_throughput": 76.755, "synch_weights_time_ms": 10.788}, "counters": {"num_env_steps_sampled": 24000, "num_env_steps_trained": 24000, "num_agent_steps_sampled": 96000, "num_agent_steps_trained": 96000}, "done": false, "training_iteration": 6, "trial_id": "11e70_00000", "date": "2024-08-12_23-12-20", "timestamp": 1723518740, "time_this_iter_s": 52.37441110610962, "time_total_s": 321.3769967556, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2b619d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 321.3769967556, "iterations_since_restore": 6, "perf": {"cpu_util_percent": 44.85945945945946, "ram_util_percent": 82.4108108108108}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.9381276550747097, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.1316053191190045, "policy_loss": -0.01406508788901317, "vf_loss": 6.142548459673685, "vf_explained_var": 0.024082523205923655, "kl": 0.01040647447655603, "entropy": 1.5570437653985605, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 12285.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.62289956770246, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.231916338552242, "policy_loss": -0.013467126501423538, "vf_loss": 8.243339987911245, "vf_explained_var": 0.03490723891863747, "kl": 0.013623056649393455, "entropy": 1.528271795328332, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 12285.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 28000, "num_env_steps_trained": 28000, "num_agent_steps_sampled": 112000, "num_agent_steps_trained": 112000}, "env_runners": {"episode_reward_max": 357.7000000000001, "episode_reward_min": -293.20000000000016, "episode_reward_mean": 85.73199999999989, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -368.30000000000007, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 242.0}, "policy_reward_mean": {"prey_policy": 1.6959999999999786, "predator_policy": 41.17}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.300000000000054, 47.80000000000027, 254.4999999999999, -103.80000000000103, 42.10000000000008, 124.59999999999874, 34.0000000000002, -1.3999999999999861, -24.4999999999999, -128.40000000000043, 219.69999999999908, 142.79999999999984, 137.79999999999987, 77.09999999999997, 279.79999999999995, 107.49999999999991, -8.299999999999953, -62.30000000000004, -28.699999999999847, -2.2000000000000064, -21.999999999999854, -84.19999999999987, 152.29999999999944, -293.20000000000016, 148.29999999999964, -30.099999999999888, -8.599999999999842, 163.4999999999995, 98.19999999999993, 247.4999999999996, 208.59999999999943, 87.00000000000006, 27.300000000000253, 18.90000000000007, 105.9999999999996, 230.89999999999938, 206.49999999999918, 60.4000000000002, 74.20000000000019, 190.5, 119.49999999999974, 47.20000000000017, 157.1, 67.39999999999984, 325.69999999999993, 80.00000000000006, 42.000000000000014, 128.39999999999972, 56.20000000000046, 42.700000000000294, 35.600000000000236, 86.20000000000007, 157.99999999999926, 185.6999999999994, -41.49999999999997, 126.59999999999978, 258.7999999999997, 192.19999999999928, 332.0, -237.9000000000012, -33.599999999999866, 51.700000000000095, 337.0, 169.8999999999989, 97.40000000000003, 202.9, 269.20000000000005, 316.6, -137.7000000000002, 100.69999999999987, 141.99999999999963, 120.00000000000003, -69.0, 343.5, 303.19999999999993, 83.20000000000019, 137.3, 52.30000000000018, -192.3000000000005, 303.5999999999999, 211.8999999999993, 148.4, -6.199999999999996, 10.299999999999946, 63.89999999999998, 142.7, 24.700000000000045, -155.1, -171.00000000000009, -30.299999999999876, 2.500000000000046, -142.60000000000008, 129.4, 135.10000000000008, 357.7000000000001, 251.8, -85.89999999999998, 157.4, 84.1999999999993, 14.70000000000017], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-36.70000000000003, -34.599999999999866, 20.000000000000014, 21.800000000000004, 67.4, 145.09999999999988, -127.90000000000006, -88.90000000000069, -94.89999999999998, 70.99999999999999, 20.000000000000014, 104.59999999999944, -68.50000000000003, 9.499999999999947, -126.10000000000008, 10.699999999999974, 71.30000000000013, -314.7999999999998, -221.20000000000024, -215.20000000000013, 104.59999999999948, 109.09999999999965, -5.50000000000027, 74.2999999999999, 27.499999999999993, 41.300000000000075, -166.90000000000015, 119.0, 42.199999999999875, 194.59999999999997, 87.49999999999997, 20.000000000000014, -261.40000000000003, 70.09999999999988, -253.0, 22.700000000000063, 9.79999999999999, -131.5000000000004, -230.79999999999998, 38.60000000000001, -181.0, 20.000000000000014, 29.000000000000163, -257.2000000000003, -76.90000000000055, 162.19999999999993, -322.8, -156.4, 98.30000000000001, 20.000000000000014, -97.6, -50.50000000000003, 20.000000000000014, -118.60000000000036, 83.60000000000002, 35.9000000000002, -50.8, 59.000000000000036, 90.20000000000007, 155.29999999999995, 181.1, 24.500000000000068, 58.99999999999997, 20.000000000000014, 20.000000000000014, -33.70000000000003, -47.8, -28.29999999999975, 94.1, -45.09999999999976, 143.29999999999978, 83.59999999999997, 186.49999999999991, 20.000000000000014, -37.599999999999994, 20.000000000000014, 20.000000000000014, 54.199999999999974, 186.5, -97.0, 120.49999999999999, -21.999999999999808, 49.70000000000006, -74.50000000000045, 109.1, -28.0, -50.79999999999998, 24.20000000000011, 118.1, 182.6, 7.999999999999972, -7.0, 13.99999999999999, -85.0, 108.8, -30.399999999999757, 20.000000000000014, 36.20000000000022, 22.700000000000063, 20.000000000000014, 11.599999999999964, 20.000000000000014, 25.39999999999999, -5.19999999999993, 44.0, 65.00000000000014, 30.799999999999997, 140.89999999999998, -146.8, -36.69999999999977, 110.90000000000003, -28.299999999999777, 157.4, 88.39999999999966, 165.5, 13.699999999999946, 170.9, 160.1, -251.09999999999957, -185.80000000000052, -68.20000000000006, -60.39999999999998, 134.0, -175.30000000000038, 137.0, 200.0, 111.80000000000013, 55.10000000000021, 29.0, -55.60000000000008, 71.6, 62.3, 158.6, 77.60000000000002, 158.0, 134.6, -204.70000000000016, -157.0, -183.70000000000053, 187.39999999999995, 38.900000000000254, 73.1, -45.10000000000018, 70.10000000000002, -277.0, -31.0, 167.0, 159.5, 123.2, 154.99999999999994, 7.700000000000109, -5.5, -90.70000000000002, 116.0, 7.39999999999996, -21.099999999999994, -80.79999999999978, -284.50000000000034, 196.4, 84.20000000000005, 191.9, 20.000000000000014, 89.0, -28.599999999999994, -85.6, -148.6, 20.000000000000014, -36.699999999999754, -18.400000000000006, -24.7, 37.099999999999994, 20.599999999999994, -55.89999999999997, -27.40000000000005, -290.8, -142.3, -368.30000000000007, -147.7, -126.69999999999999, -34.599999999999994, -72.10000000000005, -15.400000000000006, -157.60000000000008, -133.0, 8.0, 52.4, 47.3, 18.79999999999997, 198.2, 141.49999999999997, 27.20000000000001, 182.6, -239.50000000000003, -111.39999999999999, -25.599999999999994, 92.0, 0.20000000000000284, 20.000000000000014, -28.300000000000033, 20.000000000000014], "policy_predator_policy_reward": [0.0, 51.0, 6.0, 0.0, 0.0, 42.0, 62.0, 51.0, 10.0, 56.0, 0.0, 0.0, 93.0, 0.0, 114.0, 0.0, 154.0, 65.0, 165.0, 143.0, 0.0, 6.0, 22.0, 52.0, 34.0, 35.0, 0.0, 125.0, 43.0, 0.0, 0.0, 0.0, 166.0, 17.0, 38.0, 130.0, 49.0, 44.0, 131.0, 59.0, 34.0, 105.0, 73.0, 71.0, 5.0, 62.0, 0.0, 186.0, 0.0, 30.0, 0.0, 118.0, 3.0, 87.0, 13.0, 31.0, 26.0, 64.0, 0.0, 2.0, 3.0, 0.0, 8.0, 0.0, 41.0, 0.0, 46.0, 49.0, 57.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 78.0, 0.0, 0.0, 98.0, 3.0, 0.0, 21.0, 72.0, 0.0, 0.0, 76.0, 21.0, 73.0, 25.0, 0.0, 79.0, 0.0, 89.0, 24.0, 0.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 12.0, 54.0, 49.0, 0.0, 14.0, 0.0, 97.0, 45.0, 12.0, 32.0, 0.0, 13.0, 3.0, 10.0, 1.0, 0.0, 0.0, 199.0, 59.0, 36.0, 93.0, 0.0, 0.0, 0.0, 3.0, 0.0, 107.0, 17.0, 51.0, 18.0, 33.0, 0.0, 24.0, 0.0, 120.0, 104.0, 0.0, 97.0, 0.0, 30.0, 27.0, 68.0, 78.0, 161.0, 3.0, 14.0, 23.0, 2.0, 30.0, 51.0, 32.0, 80.0, 12.0, 54.0, 133.0, 40.0, 0.0, 23.0, 0.0, 0.0, 8.0, 80.0, 89.0, 139.0, 27.0, 0.0, 91.0, 16.0, 7.0, 78.0, 9.0, 99.0, 175.0, 103.0, 242.0, 103.0, 58.0, 73.0, 25.0, 65.0, 27.0, 121.0, 34.0, 35.0, 0.0, 69.0, 0.0, 18.0, 17.0, 25.0, 138.0, 127.0, 73.0, 18.0, 41.0, 23.0, 12.0, 11.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7341914744736425, "mean_inference_ms": 1.721192946958997, "mean_action_processing_ms": 0.2963483790318077, "mean_env_wait_ms": 0.22815037244327221, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006753444671630859, "StateBufferConnector_ms": 0.00510561466217041, "ViewRequirementAgentConnector_ms": 0.15724647045135498}, "num_episodes": 18, "episode_return_max": 357.7000000000001, "episode_return_min": -293.20000000000016, "episode_return_mean": 85.73199999999989, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 112000, "num_agent_steps_trained": 112000, "num_env_steps_sampled": 28000, "num_env_steps_trained": 28000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 78.23937492352266, "num_env_steps_trained_throughput_per_sec": 78.23937492352266, "timesteps_total": 28000, "num_env_steps_sampled_lifetime": 28000, "num_agent_steps_sampled_lifetime": 112000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 112000, "timers": {"training_iteration_time_ms": 53185.101, "restore_workers_time_ms": 0.02, "training_step_time_ms": 53185.048, "sample_time_ms": 1397.857, "learn_time_ms": 51773.567, "learn_throughput": 77.26, "synch_weights_time_ms": 10.835}, "counters": {"num_env_steps_sampled": 28000, "num_env_steps_trained": 28000, "num_agent_steps_sampled": 112000, "num_agent_steps_trained": 112000}, "done": false, "training_iteration": 7, "trial_id": "11e70_00000", "date": "2024-08-12_23-13-11", "timestamp": 1723518791, "time_this_iter_s": 51.15910506248474, "time_total_s": 372.5361018180847, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2ad7280>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 372.5361018180847, "iterations_since_restore": 7, "perf": {"cpu_util_percent": 37.24109589041096, "ram_util_percent": 83.35068493150685}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.558110775644817, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.672740006068397, "policy_loss": -0.015220923131706301, "vf_loss": 6.684874479858964, "vf_explained_var": 0.04528013269106547, "kl": 0.010288141892846922, "entropy": 1.5522357087917429, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 14175.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.231568965142366, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.900073229320466, "policy_loss": -0.011422610729218277, "vf_loss": 8.909750633391123, "vf_explained_var": 0.027259028084063656, "kl": 0.011634602690815685, "entropy": 1.5264101664855998, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 14175.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 32000, "num_env_steps_trained": 32000, "num_agent_steps_sampled": 128000, "num_agent_steps_trained": 128000}, "env_runners": {"episode_reward_max": 357.7000000000001, "episode_reward_min": -293.20000000000016, "episode_reward_mean": 87.3919999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -368.30000000000007, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 242.0}, "policy_reward_mean": {"prey_policy": 0.39099999999999, "predator_policy": 43.305}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-28.699999999999847, -2.2000000000000064, -21.999999999999854, -84.19999999999987, 152.29999999999944, -293.20000000000016, 148.29999999999964, -30.099999999999888, -8.599999999999842, 163.4999999999995, 98.19999999999993, 247.4999999999996, 208.59999999999943, 87.00000000000006, 27.300000000000253, 18.90000000000007, 105.9999999999996, 230.89999999999938, 206.49999999999918, 60.4000000000002, 74.20000000000019, 190.5, 119.49999999999974, 47.20000000000017, 157.1, 67.39999999999984, 325.69999999999993, 80.00000000000006, 42.000000000000014, 128.39999999999972, 56.20000000000046, 42.700000000000294, 35.600000000000236, 86.20000000000007, 157.99999999999926, 185.6999999999994, -41.49999999999997, 126.59999999999978, 258.7999999999997, 192.19999999999928, 332.0, -237.9000000000012, -33.599999999999866, 51.700000000000095, 337.0, 169.8999999999989, 97.40000000000003, 202.9, 269.20000000000005, 316.6, -137.7000000000002, 100.69999999999987, 141.99999999999963, 120.00000000000003, -69.0, 343.5, 303.19999999999993, 83.20000000000019, 137.3, 52.30000000000018, -192.3000000000005, 303.5999999999999, 211.8999999999993, 148.4, -6.199999999999996, 10.299999999999946, 63.89999999999998, 142.7, 24.700000000000045, -155.1, -171.00000000000009, -30.299999999999876, 2.500000000000046, -142.60000000000008, 129.4, 135.10000000000008, 357.7000000000001, 251.8, -85.89999999999998, 157.4, 84.1999999999993, 14.70000000000017, 72.90000000000006, 47.8000000000001, 206.69999999999996, 92.49999999999986, 250.79999999999995, 2.700000000000003, -29.6, 160.60000000000008, -6.499999999999989, 42.39999999999999, 89.99999999999997, -149.7, 135.89999999999998, -51.8, 41.30000000000002, 298.4000000000001, 48.30000000000003, 31.999999999999588], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [9.79999999999999, -131.5000000000004, -230.79999999999998, 38.60000000000001, -181.0, 20.000000000000014, 29.000000000000163, -257.2000000000003, -76.90000000000055, 162.19999999999993, -322.8, -156.4, 98.30000000000001, 20.000000000000014, -97.6, -50.50000000000003, 20.000000000000014, -118.60000000000036, 83.60000000000002, 35.9000000000002, -50.8, 59.000000000000036, 90.20000000000007, 155.29999999999995, 181.1, 24.500000000000068, 58.99999999999997, 20.000000000000014, 20.000000000000014, -33.70000000000003, -47.8, -28.29999999999975, 94.1, -45.09999999999976, 143.29999999999978, 83.59999999999997, 186.49999999999991, 20.000000000000014, -37.599999999999994, 20.000000000000014, 20.000000000000014, 54.199999999999974, 186.5, -97.0, 120.49999999999999, -21.999999999999808, 49.70000000000006, -74.50000000000045, 109.1, -28.0, -50.79999999999998, 24.20000000000011, 118.1, 182.6, 7.999999999999972, -7.0, 13.99999999999999, -85.0, 108.8, -30.399999999999757, 20.000000000000014, 36.20000000000022, 22.700000000000063, 20.000000000000014, 11.599999999999964, 20.000000000000014, 25.39999999999999, -5.19999999999993, 44.0, 65.00000000000014, 30.799999999999997, 140.89999999999998, -146.8, -36.69999999999977, 110.90000000000003, -28.299999999999777, 157.4, 88.39999999999966, 165.5, 13.699999999999946, 170.9, 160.1, -251.09999999999957, -185.80000000000052, -68.20000000000006, -60.39999999999998, 134.0, -175.30000000000038, 137.0, 200.0, 111.80000000000013, 55.10000000000021, 29.0, -55.60000000000008, 71.6, 62.3, 158.6, 77.60000000000002, 158.0, 134.6, -204.70000000000016, -157.0, -183.70000000000053, 187.39999999999995, 38.900000000000254, 73.1, -45.10000000000018, 70.10000000000002, -277.0, -31.0, 167.0, 159.5, 123.2, 154.99999999999994, 7.700000000000109, -5.5, -90.70000000000002, 116.0, 7.39999999999996, -21.099999999999994, -80.79999999999978, -284.50000000000034, 196.4, 84.20000000000005, 191.9, 20.000000000000014, 89.0, -28.599999999999994, -85.6, -148.6, 20.000000000000014, -36.699999999999754, -18.400000000000006, -24.7, 37.099999999999994, 20.599999999999994, -55.89999999999997, -27.40000000000005, -290.8, -142.3, -368.30000000000007, -147.7, -126.69999999999999, -34.599999999999994, -72.10000000000005, -15.400000000000006, -157.60000000000008, -133.0, 8.0, 52.4, 47.3, 18.79999999999997, 198.2, 141.49999999999997, 27.20000000000001, 182.6, -239.50000000000003, -111.39999999999999, -25.599999999999994, 92.0, 0.20000000000000284, 20.000000000000014, -28.300000000000033, 20.000000000000014, -14.200000000000017, 4.100000000000016, -118.60000000000045, 52.4, -72.40000000000003, 190.1, 78.19999999999999, -15.699999999999775, 137.29999999999998, 54.5, -106.00000000000003, -97.3, -8.5, -195.1, 53.59999999999998, 20.0, -39.39999999999999, -135.10000000000005, -95.50000000000001, -3.10000000000003, -40.29999999999999, 20.299999999999997, -184.9, -179.8, 20.300000000000004, 38.6, -91.0, -185.8, 21.79999999999997, -89.5, 125.0, 148.39999999999998, -24.70000000000001, 20.000000000000014, -130.0, 20.000000000000014], "policy_predator_policy_reward": [49.0, 44.0, 131.0, 59.0, 34.0, 105.0, 73.0, 71.0, 5.0, 62.0, 0.0, 186.0, 0.0, 30.0, 0.0, 118.0, 3.0, 87.0, 13.0, 31.0, 26.0, 64.0, 0.0, 2.0, 3.0, 0.0, 8.0, 0.0, 41.0, 0.0, 46.0, 49.0, 57.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 78.0, 0.0, 0.0, 98.0, 3.0, 0.0, 21.0, 72.0, 0.0, 0.0, 76.0, 21.0, 73.0, 25.0, 0.0, 79.0, 0.0, 89.0, 24.0, 0.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 12.0, 54.0, 49.0, 0.0, 14.0, 0.0, 97.0, 45.0, 12.0, 32.0, 0.0, 13.0, 3.0, 10.0, 1.0, 0.0, 0.0, 199.0, 59.0, 36.0, 93.0, 0.0, 0.0, 0.0, 3.0, 0.0, 107.0, 17.0, 51.0, 18.0, 33.0, 0.0, 24.0, 0.0, 120.0, 104.0, 0.0, 97.0, 0.0, 30.0, 27.0, 68.0, 78.0, 161.0, 3.0, 14.0, 23.0, 2.0, 30.0, 51.0, 32.0, 80.0, 12.0, 54.0, 133.0, 40.0, 0.0, 23.0, 0.0, 0.0, 8.0, 80.0, 89.0, 139.0, 27.0, 0.0, 91.0, 16.0, 7.0, 78.0, 9.0, 99.0, 175.0, 103.0, 242.0, 103.0, 58.0, 73.0, 25.0, 65.0, 27.0, 121.0, 34.0, 35.0, 0.0, 69.0, 0.0, 18.0, 17.0, 25.0, 138.0, 127.0, 73.0, 18.0, 41.0, 23.0, 12.0, 11.0, 20.0, 63.0, 59.0, 55.0, 0.0, 89.0, 30.0, 0.0, 0.0, 59.0, 124.0, 82.0, 105.0, 69.0, 24.0, 63.0, 76.0, 92.0, 52.0, 89.0, 6.0, 104.0, 64.0, 151.0, 58.0, 19.0, 112.0, 113.0, 94.0, 15.0, 25.0, 0.0, 0.0, 53.0, 99.0, 43.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7265410594718921, "mean_inference_ms": 1.6994820235161117, "mean_action_processing_ms": 0.293169319450483, "mean_env_wait_ms": 0.225513246506968, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0062334537506103516, "StateBufferConnector_ms": 0.005131959915161133, "ViewRequirementAgentConnector_ms": 0.12093198299407959}, "num_episodes": 18, "episode_return_max": 357.7000000000001, "episode_return_min": -293.20000000000016, "episode_return_mean": 87.3919999999999, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 128000, "num_agent_steps_trained": 128000, "num_env_steps_sampled": 32000, "num_env_steps_trained": 32000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 78.74546981764709, "num_env_steps_trained_throughput_per_sec": 78.74546981764709, "timesteps_total": 32000, "num_env_steps_sampled_lifetime": 32000, "num_agent_steps_sampled_lifetime": 128000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 128000, "timers": {"training_iteration_time_ms": 52886.537, "restore_workers_time_ms": 0.019, "training_step_time_ms": 52886.483, "sample_time_ms": 1365.171, "learn_time_ms": 51507.485, "learn_throughput": 77.659, "synch_weights_time_ms": 11.0}, "counters": {"num_env_steps_sampled": 32000, "num_env_steps_trained": 32000, "num_agent_steps_sampled": 128000, "num_agent_steps_trained": 128000}, "done": false, "training_iteration": 8, "trial_id": "11e70_00000", "date": "2024-08-12_23-14-02", "timestamp": 1723518842, "time_this_iter_s": 50.81870126724243, "time_total_s": 423.35480308532715, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2b62430>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 423.35480308532715, "iterations_since_restore": 8, "perf": {"cpu_util_percent": 38.60555555555556, "ram_util_percent": 83.00833333333333}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.258746185819939, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.492197943742944, "policy_loss": -0.010989883615113006, "vf_loss": 7.500796067273176, "vf_explained_var": 0.027353288067711725, "kl": 0.007972522794371136, "entropy": 1.5420917509724854, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 16065.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.6851724421536485, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.833105351432922, "policy_loss": -0.018334942952749473, "vf_loss": 7.848892009573639, "vf_explained_var": -0.04524695311904584, "kl": 0.01698879470871746, "entropy": 1.4991391411534063, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 16065.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 36000, "num_env_steps_trained": 36000, "num_agent_steps_sampled": 144000, "num_agent_steps_trained": 144000}, "env_runners": {"episode_reward_max": 357.7000000000001, "episode_reward_min": -237.9000000000012, "episode_reward_mean": 84.12799999999994, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -368.30000000000007, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 242.0}, "policy_reward_mean": {"prey_policy": -7.696000000000007, "predator_policy": 49.76}, "custom_metrics": {}, "hist_stats": {"episode_reward": [119.49999999999974, 47.20000000000017, 157.1, 67.39999999999984, 325.69999999999993, 80.00000000000006, 42.000000000000014, 128.39999999999972, 56.20000000000046, 42.700000000000294, 35.600000000000236, 86.20000000000007, 157.99999999999926, 185.6999999999994, -41.49999999999997, 126.59999999999978, 258.7999999999997, 192.19999999999928, 332.0, -237.9000000000012, -33.599999999999866, 51.700000000000095, 337.0, 169.8999999999989, 97.40000000000003, 202.9, 269.20000000000005, 316.6, -137.7000000000002, 100.69999999999987, 141.99999999999963, 120.00000000000003, -69.0, 343.5, 303.19999999999993, 83.20000000000019, 137.3, 52.30000000000018, -192.3000000000005, 303.5999999999999, 211.8999999999993, 148.4, -6.199999999999996, 10.299999999999946, 63.89999999999998, 142.7, 24.700000000000045, -155.1, -171.00000000000009, -30.299999999999876, 2.500000000000046, -142.60000000000008, 129.4, 135.10000000000008, 357.7000000000001, 251.8, -85.89999999999998, 157.4, 84.1999999999993, 14.70000000000017, 72.90000000000006, 47.8000000000001, 206.69999999999996, 92.49999999999986, 250.79999999999995, 2.700000000000003, -29.6, 160.60000000000008, -6.499999999999989, 42.39999999999999, 89.99999999999997, -149.7, 135.89999999999998, -51.8, 41.30000000000002, 298.4000000000001, 48.30000000000003, 31.999999999999588, 130.6, -131.79999999999998, 104.99999999999972, -176.2, 146.99999999999994, 51.99999999999994, 296.79999999999984, 13.400000000000048, 40.0000000000003, 15.300000000000011, 51.10000000000011, 1.2999999999999972, 84.09999999999991, -10.59999999999988, -50.69999999999992, 96.59999999999953, 40.6, 57.599999999999994, 308.1999999999998, 14.800000000000018, -20.39999999999999, 159.99999999999997], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [120.49999999999999, -21.999999999999808, 49.70000000000006, -74.50000000000045, 109.1, -28.0, -50.79999999999998, 24.20000000000011, 118.1, 182.6, 7.999999999999972, -7.0, 13.99999999999999, -85.0, 108.8, -30.399999999999757, 20.000000000000014, 36.20000000000022, 22.700000000000063, 20.000000000000014, 11.599999999999964, 20.000000000000014, 25.39999999999999, -5.19999999999993, 44.0, 65.00000000000014, 30.799999999999997, 140.89999999999998, -146.8, -36.69999999999977, 110.90000000000003, -28.299999999999777, 157.4, 88.39999999999966, 165.5, 13.699999999999946, 170.9, 160.1, -251.09999999999957, -185.80000000000052, -68.20000000000006, -60.39999999999998, 134.0, -175.30000000000038, 137.0, 200.0, 111.80000000000013, 55.10000000000021, 29.0, -55.60000000000008, 71.6, 62.3, 158.6, 77.60000000000002, 158.0, 134.6, -204.70000000000016, -157.0, -183.70000000000053, 187.39999999999995, 38.900000000000254, 73.1, -45.10000000000018, 70.10000000000002, -277.0, -31.0, 167.0, 159.5, 123.2, 154.99999999999994, 7.700000000000109, -5.5, -90.70000000000002, 116.0, 7.39999999999996, -21.099999999999994, -80.79999999999978, -284.50000000000034, 196.4, 84.20000000000005, 191.9, 20.000000000000014, 89.0, -28.599999999999994, -85.6, -148.6, 20.000000000000014, -36.699999999999754, -18.400000000000006, -24.7, 37.099999999999994, 20.599999999999994, -55.89999999999997, -27.40000000000005, -290.8, -142.3, -368.30000000000007, -147.7, -126.69999999999999, -34.599999999999994, -72.10000000000005, -15.400000000000006, -157.60000000000008, -133.0, 8.0, 52.4, 47.3, 18.79999999999997, 198.2, 141.49999999999997, 27.20000000000001, 182.6, -239.50000000000003, -111.39999999999999, -25.599999999999994, 92.0, 0.20000000000000284, 20.000000000000014, -28.300000000000033, 20.000000000000014, -14.200000000000017, 4.100000000000016, -118.60000000000045, 52.4, -72.40000000000003, 190.1, 78.19999999999999, -15.699999999999775, 137.29999999999998, 54.5, -106.00000000000003, -97.3, -8.5, -195.1, 53.59999999999998, 20.0, -39.39999999999999, -135.10000000000005, -95.50000000000001, -3.10000000000003, -40.29999999999999, 20.299999999999997, -184.9, -179.8, 20.300000000000004, 38.6, -91.0, -185.8, 21.79999999999997, -89.5, 125.0, 148.39999999999998, -24.70000000000001, 20.000000000000014, -130.0, 20.000000000000014, 11.0, 41.6, -225.7, -165.10000000000002, 156.19999999999982, -143.20000000000002, -255.70000000000005, -128.5, -37.30000000000001, 77.30000000000001, -52.3, -27.69999999999999, 191.9, 101.9, -92.8, -35.800000000000026, 20.000000000000014, 20.000000000000014, -4.0, -150.70000000000007, -199.9, 20.000000000000014, -172.3, 38.6, -94.30000000000001, 109.4, -217.60000000000002, 20.000000000000014, -100.9, -56.80000000000001, 20.000000000000014, 26.599999999999994, -91.0, -6.3999999999999915, 28.099999999999998, -158.5, 109.99999999999997, 198.2, -91.90000000000009, -145.3, -205.0, -6.399999999999995, -74.80000000000007, 102.8], "policy_predator_policy_reward": [0.0, 21.0, 72.0, 0.0, 0.0, 76.0, 21.0, 73.0, 25.0, 0.0, 79.0, 0.0, 89.0, 24.0, 0.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 12.0, 54.0, 49.0, 0.0, 14.0, 0.0, 97.0, 45.0, 12.0, 32.0, 0.0, 13.0, 3.0, 10.0, 1.0, 0.0, 0.0, 199.0, 59.0, 36.0, 93.0, 0.0, 0.0, 0.0, 3.0, 0.0, 107.0, 17.0, 51.0, 18.0, 33.0, 0.0, 24.0, 0.0, 120.0, 104.0, 0.0, 97.0, 0.0, 30.0, 27.0, 68.0, 78.0, 161.0, 3.0, 14.0, 23.0, 2.0, 30.0, 51.0, 32.0, 80.0, 12.0, 54.0, 133.0, 40.0, 0.0, 23.0, 0.0, 0.0, 8.0, 80.0, 89.0, 139.0, 27.0, 0.0, 91.0, 16.0, 7.0, 78.0, 9.0, 99.0, 175.0, 103.0, 242.0, 103.0, 58.0, 73.0, 25.0, 65.0, 27.0, 121.0, 34.0, 35.0, 0.0, 69.0, 0.0, 18.0, 17.0, 25.0, 138.0, 127.0, 73.0, 18.0, 41.0, 23.0, 12.0, 11.0, 20.0, 63.0, 59.0, 55.0, 0.0, 89.0, 30.0, 0.0, 0.0, 59.0, 124.0, 82.0, 105.0, 69.0, 24.0, 63.0, 76.0, 92.0, 52.0, 89.0, 6.0, 104.0, 64.0, 151.0, 58.0, 19.0, 112.0, 113.0, 94.0, 15.0, 25.0, 0.0, 0.0, 53.0, 99.0, 43.0, 59.0, 19.0, 137.0, 122.0, 3.0, 89.0, 145.0, 63.0, 51.0, 56.0, 77.0, 55.0, 0.0, 3.0, 48.0, 94.0, 0.0, 0.0, 29.0, 141.0, 115.0, 116.0, 134.0, 1.0, 61.0, 8.0, 82.0, 105.0, 53.0, 54.0, 18.0, 32.0, 63.0, 75.0, 56.0, 132.0, 0.0, 0.0, 137.0, 115.0, 83.0, 108.0, 83.0, 49.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7223051744458115, "mean_inference_ms": 1.6833765757524934, "mean_action_processing_ms": 0.29208813805672296, "mean_env_wait_ms": 0.22326185110066432, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005429983139038086, "StateBufferConnector_ms": 0.0050934553146362305, "ViewRequirementAgentConnector_ms": 0.1285700798034668}, "num_episodes": 22, "episode_return_max": 357.7000000000001, "episode_return_min": -237.9000000000012, "episode_return_mean": 84.12799999999994, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 144000, "num_agent_steps_trained": 144000, "num_env_steps_sampled": 36000, "num_env_steps_trained": 36000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 77.95356321837585, "num_env_steps_trained_throughput_per_sec": 77.95356321837585, "timesteps_total": 36000, "num_env_steps_sampled_lifetime": 36000, "num_agent_steps_sampled_lifetime": 144000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 144000, "timers": {"training_iteration_time_ms": 52711.656, "restore_workers_time_ms": 0.019, "training_step_time_ms": 52711.604, "sample_time_ms": 1345.357, "learn_time_ms": 51352.597, "learn_throughput": 77.893, "synch_weights_time_ms": 10.887}, "counters": {"num_env_steps_sampled": 36000, "num_env_steps_trained": 36000, "num_agent_steps_sampled": 144000, "num_agent_steps_trained": 144000}, "done": false, "training_iteration": 9, "trial_id": "11e70_00000", "date": "2024-08-12_23-14-53", "timestamp": 1723518893, "time_this_iter_s": 51.36851477622986, "time_total_s": 474.723317861557, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2a91f70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 474.723317861557, "iterations_since_restore": 9, "perf": {"cpu_util_percent": 38.25342465753425, "ram_util_percent": 82.95342465753426}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.466499249140422, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.586441404352743, "policy_loss": -0.009794059040754166, "vf_loss": 5.594187673185237, "vf_explained_var": 0.015075775460591393, "kl": 0.006825994477605404, "entropy": 1.5295302799139072, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 17955.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.06554748646166, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.513021145926581, "policy_loss": -0.014099792168825549, "vf_loss": 7.525175847452154, "vf_explained_var": 0.15834324258975882, "kl": 0.012967239830473586, "entropy": 1.4866756529404372, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 17955.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 40000, "num_env_steps_trained": 40000, "num_agent_steps_sampled": 160000, "num_agent_steps_trained": 160000}, "env_runners": {"episode_reward_max": 364.5, "episode_reward_min": -192.3000000000005, "episode_reward_mean": 78.14599999999994, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -368.30000000000007, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 199.1, "predator_policy": 242.0}, "policy_reward_mean": {"prey_policy": -15.337000000000023, "predator_policy": 54.41}, "custom_metrics": {}, "hist_stats": {"episode_reward": [169.8999999999989, 97.40000000000003, 202.9, 269.20000000000005, 316.6, -137.7000000000002, 100.69999999999987, 141.99999999999963, 120.00000000000003, -69.0, 343.5, 303.19999999999993, 83.20000000000019, 137.3, 52.30000000000018, -192.3000000000005, 303.5999999999999, 211.8999999999993, 148.4, -6.199999999999996, 10.299999999999946, 63.89999999999998, 142.7, 24.700000000000045, -155.1, -171.00000000000009, -30.299999999999876, 2.500000000000046, -142.60000000000008, 129.4, 135.10000000000008, 357.7000000000001, 251.8, -85.89999999999998, 157.4, 84.1999999999993, 14.70000000000017, 72.90000000000006, 47.8000000000001, 206.69999999999996, 92.49999999999986, 250.79999999999995, 2.700000000000003, -29.6, 160.60000000000008, -6.499999999999989, 42.39999999999999, 89.99999999999997, -149.7, 135.89999999999998, -51.8, 41.30000000000002, 298.4000000000001, 48.30000000000003, 31.999999999999588, 130.6, -131.79999999999998, 104.99999999999972, -176.2, 146.99999999999994, 51.99999999999994, 296.79999999999984, 13.400000000000048, 40.0000000000003, 15.300000000000011, 51.10000000000011, 1.2999999999999972, 84.09999999999991, -10.59999999999988, -50.69999999999992, 96.59999999999953, 40.6, 57.599999999999994, 308.1999999999998, 14.800000000000018, -20.39999999999999, 159.99999999999997, 164.09999999999994, 144.89999999999964, 168.49999999999997, 364.5, -19.999999999999886, 52.60000000000012, 155.7999999999993, 87.19999999999936, -97.50000000000091, 44.9, 133.0, 40.10000000000027, 78.59999999999991, 31.20000000000018, 25.999999999999993, 90.79999999999997, 102.89999999999988, -12.099999999999874, -35.89999999999967, 175.79999999999998, 48.69999999999985, 27.19999999999999, 147.5], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [111.80000000000013, 55.10000000000021, 29.0, -55.60000000000008, 71.6, 62.3, 158.6, 77.60000000000002, 158.0, 134.6, -204.70000000000016, -157.0, -183.70000000000053, 187.39999999999995, 38.900000000000254, 73.1, -45.10000000000018, 70.10000000000002, -277.0, -31.0, 167.0, 159.5, 123.2, 154.99999999999994, 7.700000000000109, -5.5, -90.70000000000002, 116.0, 7.39999999999996, -21.099999999999994, -80.79999999999978, -284.50000000000034, 196.4, 84.20000000000005, 191.9, 20.000000000000014, 89.0, -28.599999999999994, -85.6, -148.6, 20.000000000000014, -36.699999999999754, -18.400000000000006, -24.7, 37.099999999999994, 20.599999999999994, -55.89999999999997, -27.40000000000005, -290.8, -142.3, -368.30000000000007, -147.7, -126.69999999999999, -34.599999999999994, -72.10000000000005, -15.400000000000006, -157.60000000000008, -133.0, 8.0, 52.4, 47.3, 18.79999999999997, 198.2, 141.49999999999997, 27.20000000000001, 182.6, -239.50000000000003, -111.39999999999999, -25.599999999999994, 92.0, 0.20000000000000284, 20.000000000000014, -28.300000000000033, 20.000000000000014, -14.200000000000017, 4.100000000000016, -118.60000000000045, 52.4, -72.40000000000003, 190.1, 78.19999999999999, -15.699999999999775, 137.29999999999998, 54.5, -106.00000000000003, -97.3, -8.5, -195.1, 53.59999999999998, 20.0, -39.39999999999999, -135.10000000000005, -95.50000000000001, -3.10000000000003, -40.29999999999999, 20.299999999999997, -184.9, -179.8, 20.300000000000004, 38.6, -91.0, -185.8, 21.79999999999997, -89.5, 125.0, 148.39999999999998, -24.70000000000001, 20.000000000000014, -130.0, 20.000000000000014, 11.0, 41.6, -225.7, -165.10000000000002, 156.19999999999982, -143.20000000000002, -255.70000000000005, -128.5, -37.30000000000001, 77.30000000000001, -52.3, -27.69999999999999, 191.9, 101.9, -92.8, -35.800000000000026, 20.000000000000014, 20.000000000000014, -4.0, -150.70000000000007, -199.9, 20.000000000000014, -172.3, 38.6, -94.30000000000001, 109.4, -217.60000000000002, 20.000000000000014, -100.9, -56.80000000000001, 20.000000000000014, 26.599999999999994, -91.0, -6.3999999999999915, 28.099999999999998, -158.5, 109.99999999999997, 198.2, -91.90000000000009, -145.3, -205.0, -6.399999999999995, -74.80000000000007, 102.8, 70.1, 28.999999999999964, 20.000000000000014, 74.9, 106.4, -22.900000000000006, 154.4, 199.1, -29.199999999999925, -164.80000000000024, -17.20000000000003, -62.20000000000002, -17.79999999999974, 149.59999999999988, -127.00000000000051, 144.19999999999968, -9.700000000000038, -235.80000000000047, -86.8000000000003, -25.299999999999997, 26.30000000000001, 25.699999999999996, -115.90000000000018, 20.000000000000014, -82.0, -6.400000000000022, 20.000000000000014, 3.1999999999999704, -3.1000000000000365, -4.900000000000038, 11.900000000000002, -21.099999999999998, -71.2000000000001, 52.10000000000003, -17.500000000000036, -202.60000000000002, 20.000000000000014, -124.90000000000055, -55.900000000000034, 136.6999999999999, -6.699999999999967, -37.600000000000136, -62.80000000000004, 20.000000000000014, 16.70000000000001, 36.80000000000001], "policy_predator_policy_reward": [3.0, 0.0, 107.0, 17.0, 51.0, 18.0, 33.0, 0.0, 24.0, 0.0, 120.0, 104.0, 0.0, 97.0, 0.0, 30.0, 27.0, 68.0, 78.0, 161.0, 3.0, 14.0, 23.0, 2.0, 30.0, 51.0, 32.0, 80.0, 12.0, 54.0, 133.0, 40.0, 0.0, 23.0, 0.0, 0.0, 8.0, 80.0, 89.0, 139.0, 27.0, 0.0, 91.0, 16.0, 7.0, 78.0, 9.0, 99.0, 175.0, 103.0, 242.0, 103.0, 58.0, 73.0, 25.0, 65.0, 27.0, 121.0, 34.0, 35.0, 0.0, 69.0, 0.0, 18.0, 17.0, 25.0, 138.0, 127.0, 73.0, 18.0, 41.0, 23.0, 12.0, 11.0, 20.0, 63.0, 59.0, 55.0, 0.0, 89.0, 30.0, 0.0, 0.0, 59.0, 124.0, 82.0, 105.0, 69.0, 24.0, 63.0, 76.0, 92.0, 52.0, 89.0, 6.0, 104.0, 64.0, 151.0, 58.0, 19.0, 112.0, 113.0, 94.0, 15.0, 25.0, 0.0, 0.0, 53.0, 99.0, 43.0, 59.0, 19.0, 137.0, 122.0, 3.0, 89.0, 145.0, 63.0, 51.0, 56.0, 77.0, 55.0, 0.0, 3.0, 48.0, 94.0, 0.0, 0.0, 29.0, 141.0, 115.0, 116.0, 134.0, 1.0, 61.0, 8.0, 82.0, 105.0, 53.0, 54.0, 18.0, 32.0, 63.0, 75.0, 56.0, 132.0, 0.0, 0.0, 137.0, 115.0, 83.0, 108.0, 83.0, 49.0, 65.0, 0.0, 12.0, 38.0, 29.0, 56.0, 0.0, 11.0, 74.0, 100.0, 48.0, 84.0, 23.0, 1.0, 70.0, 0.0, 21.0, 127.0, 72.0, 85.0, 16.0, 65.0, 76.0, 60.0, 95.0, 72.0, 0.0, 8.0, 34.0, 0.0, 53.0, 47.0, 40.0, 82.0, 91.0, 117.0, 69.0, 0.0, 4.0, 91.0, 0.0, 93.0, 27.0, 43.0, 52.0, 42.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7110804320375671, "mean_inference_ms": 1.6479246987159013, "mean_action_processing_ms": 0.28642161810583183, "mean_env_wait_ms": 0.21953624345480077, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004627346992492676, "StateBufferConnector_ms": 0.004849791526794434, "ViewRequirementAgentConnector_ms": 0.1217566728591919}, "num_episodes": 23, "episode_return_max": 364.5, "episode_return_min": -192.3000000000005, "episode_return_mean": 78.14599999999994, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 160000, "num_agent_steps_trained": 160000, "num_env_steps_sampled": 40000, "num_env_steps_trained": 40000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 78.88355956179598, "num_env_steps_trained_throughput_per_sec": 78.88355956179598, "timesteps_total": 40000, "num_env_steps_sampled_lifetime": 40000, "num_agent_steps_sampled_lifetime": 160000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 160000, "timers": {"training_iteration_time_ms": 52511.256, "restore_workers_time_ms": 0.018, "training_step_time_ms": 52511.206, "sample_time_ms": 1329.678, "learn_time_ms": 51167.949, "learn_throughput": 78.174, "synch_weights_time_ms": 10.896}, "counters": {"num_env_steps_sampled": 40000, "num_env_steps_trained": 40000, "num_agent_steps_sampled": 160000, "num_agent_steps_trained": 160000}, "done": false, "training_iteration": 10, "trial_id": "11e70_00000", "date": "2024-08-12_23-15-44", "timestamp": 1723518944, "time_this_iter_s": 50.77944087982178, "time_total_s": 525.5027587413788, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2ad7940>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 525.5027587413788, "iterations_since_restore": 10, "perf": {"cpu_util_percent": 40.201388888888886, "ram_util_percent": 83.08611111111112}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.5443858331473415, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.529795863893297, "policy_loss": -0.01462377679605707, "vf_loss": 5.54115721157619, "vf_explained_var": 0.03628436822109121, "kl": 0.01087477204501406, "entropy": 1.525347004744111, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 19845.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.658853183347712, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.174304462614513, "policy_loss": -0.013769747228632686, "vf_loss": 8.185934770422637, "vf_explained_var": 0.0904506091402952, "kl": 0.014262973707734411, "entropy": 1.4579705240865233, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 19845.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 44000, "num_env_steps_trained": 44000, "num_agent_steps_sampled": 176000, "num_agent_steps_trained": 176000}, "env_runners": {"episode_reward_max": 364.5, "episode_reward_min": -176.2, "episode_reward_mean": 70.67999999999995, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -368.30000000000007, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 199.1, "predator_policy": 242.0}, "policy_reward_mean": {"prey_policy": -19.57000000000003, "predator_policy": 54.91}, "custom_metrics": {}, "hist_stats": {"episode_reward": [148.4, -6.199999999999996, 10.299999999999946, 63.89999999999998, 142.7, 24.700000000000045, -155.1, -171.00000000000009, -30.299999999999876, 2.500000000000046, -142.60000000000008, 129.4, 135.10000000000008, 357.7000000000001, 251.8, -85.89999999999998, 157.4, 84.1999999999993, 14.70000000000017, 72.90000000000006, 47.8000000000001, 206.69999999999996, 92.49999999999986, 250.79999999999995, 2.700000000000003, -29.6, 160.60000000000008, -6.499999999999989, 42.39999999999999, 89.99999999999997, -149.7, 135.89999999999998, -51.8, 41.30000000000002, 298.4000000000001, 48.30000000000003, 31.999999999999588, 130.6, -131.79999999999998, 104.99999999999972, -176.2, 146.99999999999994, 51.99999999999994, 296.79999999999984, 13.400000000000048, 40.0000000000003, 15.300000000000011, 51.10000000000011, 1.2999999999999972, 84.09999999999991, -10.59999999999988, -50.69999999999992, 96.59999999999953, 40.6, 57.599999999999994, 308.1999999999998, 14.800000000000018, -20.39999999999999, 159.99999999999997, 164.09999999999994, 144.89999999999964, 168.49999999999997, 364.5, -19.999999999999886, 52.60000000000012, 155.7999999999993, 87.19999999999936, -97.50000000000091, 44.9, 133.0, 40.10000000000027, 78.59999999999991, 31.20000000000018, 25.999999999999993, 90.79999999999997, 102.89999999999988, -12.099999999999874, -35.89999999999967, 175.79999999999998, 48.69999999999985, 27.19999999999999, 147.5, 103.99999999999974, 81.79999999999981, 30.50000000000002, 281.5, 75.90000000000006, 244.59999999999997, 172.3, -11.0, 110.29999999999998, 43.4000000000002, 48.10000000000001, 205.1999999999996, 173.59999999999977, 149.09999999999943, 33.00000000000001, -122.40000000000094, 70.2, 18.0], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [89.0, -28.599999999999994, -85.6, -148.6, 20.000000000000014, -36.699999999999754, -18.400000000000006, -24.7, 37.099999999999994, 20.599999999999994, -55.89999999999997, -27.40000000000005, -290.8, -142.3, -368.30000000000007, -147.7, -126.69999999999999, -34.599999999999994, -72.10000000000005, -15.400000000000006, -157.60000000000008, -133.0, 8.0, 52.4, 47.3, 18.79999999999997, 198.2, 141.49999999999997, 27.20000000000001, 182.6, -239.50000000000003, -111.39999999999999, -25.599999999999994, 92.0, 0.20000000000000284, 20.000000000000014, -28.300000000000033, 20.000000000000014, -14.200000000000017, 4.100000000000016, -118.60000000000045, 52.4, -72.40000000000003, 190.1, 78.19999999999999, -15.699999999999775, 137.29999999999998, 54.5, -106.00000000000003, -97.3, -8.5, -195.1, 53.59999999999998, 20.0, -39.39999999999999, -135.10000000000005, -95.50000000000001, -3.10000000000003, -40.29999999999999, 20.299999999999997, -184.9, -179.8, 20.300000000000004, 38.6, -91.0, -185.8, 21.79999999999997, -89.5, 125.0, 148.39999999999998, -24.70000000000001, 20.000000000000014, -130.0, 20.000000000000014, 11.0, 41.6, -225.7, -165.10000000000002, 156.19999999999982, -143.20000000000002, -255.70000000000005, -128.5, -37.30000000000001, 77.30000000000001, -52.3, -27.69999999999999, 191.9, 101.9, -92.8, -35.800000000000026, 20.000000000000014, 20.000000000000014, -4.0, -150.70000000000007, -199.9, 20.000000000000014, -172.3, 38.6, -94.30000000000001, 109.4, -217.60000000000002, 20.000000000000014, -100.9, -56.80000000000001, 20.000000000000014, 26.599999999999994, -91.0, -6.3999999999999915, 28.099999999999998, -158.5, 109.99999999999997, 198.2, -91.90000000000009, -145.3, -205.0, -6.399999999999995, -74.80000000000007, 102.8, 70.1, 28.999999999999964, 20.000000000000014, 74.9, 106.4, -22.900000000000006, 154.4, 199.1, -29.199999999999925, -164.80000000000024, -17.20000000000003, -62.20000000000002, -17.79999999999974, 149.59999999999988, -127.00000000000051, 144.19999999999968, -9.700000000000038, -235.80000000000047, -86.8000000000003, -25.299999999999997, 26.30000000000001, 25.699999999999996, -115.90000000000018, 20.000000000000014, -82.0, -6.400000000000022, 20.000000000000014, 3.1999999999999704, -3.1000000000000365, -4.900000000000038, 11.900000000000002, -21.099999999999998, -71.2000000000001, 52.10000000000003, -17.500000000000036, -202.60000000000002, 20.000000000000014, -124.90000000000055, -55.900000000000034, 136.6999999999999, -6.699999999999967, -37.600000000000136, -62.80000000000004, 20.000000000000014, 16.70000000000001, 36.80000000000001, 93.49999999999989, -23.500000000000036, -15.699999999999754, 27.500000000000007, -31.29999999999999, -47.19999999999997, 99.19999999999999, 155.29999999999995, -37.30000000000003, 0.1999999999999993, 124.99999999999999, 77.60000000000001, 99.19999999999997, 19.100000000000023, -70.6, -99.40000000000003, 25.400000000000006, 26.899999999999984, -1.3000000000000007, -28.29999999999975, 89.59999999999985, -158.50000000000048, 77.8999999999997, 83.30000000000001, 38.00000000000007, 68.6, 39.500000000000014, 26.600000000000122, -96.99999999999999, 20.000000000000014, -127.0000000000006, -135.39999999999992, -38.20000000000002, -7.599999999999973, -29.799999999999983, -71.20000000000005], "policy_predator_policy_reward": [8.0, 80.0, 89.0, 139.0, 27.0, 0.0, 91.0, 16.0, 7.0, 78.0, 9.0, 99.0, 175.0, 103.0, 242.0, 103.0, 58.0, 73.0, 25.0, 65.0, 27.0, 121.0, 34.0, 35.0, 0.0, 69.0, 0.0, 18.0, 17.0, 25.0, 138.0, 127.0, 73.0, 18.0, 41.0, 23.0, 12.0, 11.0, 20.0, 63.0, 59.0, 55.0, 0.0, 89.0, 30.0, 0.0, 0.0, 59.0, 124.0, 82.0, 105.0, 69.0, 24.0, 63.0, 76.0, 92.0, 52.0, 89.0, 6.0, 104.0, 64.0, 151.0, 58.0, 19.0, 112.0, 113.0, 94.0, 15.0, 25.0, 0.0, 0.0, 53.0, 99.0, 43.0, 59.0, 19.0, 137.0, 122.0, 3.0, 89.0, 145.0, 63.0, 51.0, 56.0, 77.0, 55.0, 0.0, 3.0, 48.0, 94.0, 0.0, 0.0, 29.0, 141.0, 115.0, 116.0, 134.0, 1.0, 61.0, 8.0, 82.0, 105.0, 53.0, 54.0, 18.0, 32.0, 63.0, 75.0, 56.0, 132.0, 0.0, 0.0, 137.0, 115.0, 83.0, 108.0, 83.0, 49.0, 65.0, 0.0, 12.0, 38.0, 29.0, 56.0, 0.0, 11.0, 74.0, 100.0, 48.0, 84.0, 23.0, 1.0, 70.0, 0.0, 21.0, 127.0, 72.0, 85.0, 16.0, 65.0, 76.0, 60.0, 95.0, 72.0, 0.0, 8.0, 34.0, 0.0, 53.0, 47.0, 40.0, 82.0, 91.0, 117.0, 69.0, 0.0, 4.0, 91.0, 0.0, 93.0, 27.0, 43.0, 52.0, 42.0, 19.0, 15.0, 31.0, 39.0, 77.0, 32.0, 27.0, 0.0, 58.0, 55.0, 42.0, 0.0, 54.0, 0.0, 79.0, 80.0, 34.0, 24.0, 50.0, 23.0, 46.0, 71.0, 26.0, 18.0, 14.0, 53.0, 34.0, 49.0, 88.0, 22.0, 14.0, 126.0, 71.0, 45.0, 56.0, 63.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7053406156743616, "mean_inference_ms": 1.627483414939636, "mean_action_processing_ms": 0.2834600881976223, "mean_env_wait_ms": 0.21711722609035455, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005035877227783203, "StateBufferConnector_ms": 0.004818439483642578, "ViewRequirementAgentConnector_ms": 0.12124478816986084}, "num_episodes": 18, "episode_return_max": 364.5, "episode_return_min": -176.2, "episode_return_mean": 70.67999999999995, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 176000, "num_agent_steps_trained": 176000, "num_env_steps_sampled": 44000, "num_env_steps_trained": 44000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 79.09678135781745, "num_env_steps_trained_throughput_per_sec": 79.09678135781745, "timesteps_total": 44000, "num_env_steps_sampled_lifetime": 44000, "num_agent_steps_sampled_lifetime": 176000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 176000, "timers": {"training_iteration_time_ms": 51873.255, "restore_workers_time_ms": 0.018, "training_step_time_ms": 51873.206, "sample_time_ms": 1299.442, "learn_time_ms": 50560.508, "learn_throughput": 79.113, "synch_weights_time_ms": 10.853}, "counters": {"num_env_steps_sampled": 44000, "num_env_steps_trained": 44000, "num_agent_steps_sampled": 176000, "num_agent_steps_trained": 176000}, "done": false, "training_iteration": 11, "trial_id": "11e70_00000", "date": "2024-08-12_23-16-35", "timestamp": 1723518995, "time_this_iter_s": 50.60397696495056, "time_total_s": 576.1067357063293, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2b15d30>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 576.1067357063293, "iterations_since_restore": 11, "perf": {"cpu_util_percent": 36.56250000000001, "ram_util_percent": 82.94722222222221}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.767496784023507, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.714244432045669, "policy_loss": -0.01191839463392854, "vf_loss": 5.723204613236523, "vf_explained_var": 0.050734104050530325, "kl": 0.00986076884142657, "entropy": 1.5091797300747463, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 21735.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.798124014700531, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.838830523516135, "policy_loss": -0.010454044225206845, "vf_loss": 7.847626844537321, "vf_explained_var": -0.020056523753221703, "kl": 0.01105153254369311, "entropy": 1.449271149925454, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 21735.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 48000, "num_env_steps_trained": 48000, "num_agent_steps_sampled": 192000, "num_agent_steps_trained": 192000}, "env_runners": {"episode_reward_max": 364.5, "episode_reward_min": -189.60000000000034, "episode_reward_mean": 67.70299999999993, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -286.89999999999986, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 156.0}, "policy_reward_mean": {"prey_policy": -18.333500000000033, "predator_policy": 52.185}, "custom_metrics": {}, "hist_stats": {"episode_reward": [14.70000000000017, 72.90000000000006, 47.8000000000001, 206.69999999999996, 92.49999999999986, 250.79999999999995, 2.700000000000003, -29.6, 160.60000000000008, -6.499999999999989, 42.39999999999999, 89.99999999999997, -149.7, 135.89999999999998, -51.8, 41.30000000000002, 298.4000000000001, 48.30000000000003, 31.999999999999588, 130.6, -131.79999999999998, 104.99999999999972, -176.2, 146.99999999999994, 51.99999999999994, 296.79999999999984, 13.400000000000048, 40.0000000000003, 15.300000000000011, 51.10000000000011, 1.2999999999999972, 84.09999999999991, -10.59999999999988, -50.69999999999992, 96.59999999999953, 40.6, 57.599999999999994, 308.1999999999998, 14.800000000000018, -20.39999999999999, 159.99999999999997, 164.09999999999994, 144.89999999999964, 168.49999999999997, 364.5, -19.999999999999886, 52.60000000000012, 155.7999999999993, 87.19999999999936, -97.50000000000091, 44.9, 133.0, 40.10000000000027, 78.59999999999991, 31.20000000000018, 25.999999999999993, 90.79999999999997, 102.89999999999988, -12.099999999999874, -35.89999999999967, 175.79999999999998, 48.69999999999985, 27.19999999999999, 147.5, 103.99999999999974, 81.79999999999981, 30.50000000000002, 281.5, 75.90000000000006, 244.59999999999997, 172.3, -11.0, 110.29999999999998, 43.4000000000002, 48.10000000000001, 205.1999999999996, 173.59999999999977, 149.09999999999943, 33.00000000000001, -122.40000000000094, 70.2, 18.0, 77.89999999999995, 16.400000000000254, -25.899999999999928, 60.59999999999994, 136.39999999999938, 11.10000000000003, -9.200000000000214, -0.40000000000011493, -6.699999999999964, 169.89999999999947, -65.99999999999989, 141.39999999999998, -87.90000000000015, 24.099999999999838, 363.1000000000002, 10.300000000000008, -6.199999999999971, -189.60000000000034], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-28.300000000000033, 20.000000000000014, -14.200000000000017, 4.100000000000016, -118.60000000000045, 52.4, -72.40000000000003, 190.1, 78.19999999999999, -15.699999999999775, 137.29999999999998, 54.5, -106.00000000000003, -97.3, -8.5, -195.1, 53.59999999999998, 20.0, -39.39999999999999, -135.10000000000005, -95.50000000000001, -3.10000000000003, -40.29999999999999, 20.299999999999997, -184.9, -179.8, 20.300000000000004, 38.6, -91.0, -185.8, 21.79999999999997, -89.5, 125.0, 148.39999999999998, -24.70000000000001, 20.000000000000014, -130.0, 20.000000000000014, 11.0, 41.6, -225.7, -165.10000000000002, 156.19999999999982, -143.20000000000002, -255.70000000000005, -128.5, -37.30000000000001, 77.30000000000001, -52.3, -27.69999999999999, 191.9, 101.9, -92.8, -35.800000000000026, 20.000000000000014, 20.000000000000014, -4.0, -150.70000000000007, -199.9, 20.000000000000014, -172.3, 38.6, -94.30000000000001, 109.4, -217.60000000000002, 20.000000000000014, -100.9, -56.80000000000001, 20.000000000000014, 26.599999999999994, -91.0, -6.3999999999999915, 28.099999999999998, -158.5, 109.99999999999997, 198.2, -91.90000000000009, -145.3, -205.0, -6.399999999999995, -74.80000000000007, 102.8, 70.1, 28.999999999999964, 20.000000000000014, 74.9, 106.4, -22.900000000000006, 154.4, 199.1, -29.199999999999925, -164.80000000000024, -17.20000000000003, -62.20000000000002, -17.79999999999974, 149.59999999999988, -127.00000000000051, 144.19999999999968, -9.700000000000038, -235.80000000000047, -86.8000000000003, -25.299999999999997, 26.30000000000001, 25.699999999999996, -115.90000000000018, 20.000000000000014, -82.0, -6.400000000000022, 20.000000000000014, 3.1999999999999704, -3.1000000000000365, -4.900000000000038, 11.900000000000002, -21.099999999999998, -71.2000000000001, 52.10000000000003, -17.500000000000036, -202.60000000000002, 20.000000000000014, -124.90000000000055, -55.900000000000034, 136.6999999999999, -6.699999999999967, -37.600000000000136, -62.80000000000004, 20.000000000000014, 16.70000000000001, 36.80000000000001, 93.49999999999989, -23.500000000000036, -15.699999999999754, 27.500000000000007, -31.29999999999999, -47.19999999999997, 99.19999999999999, 155.29999999999995, -37.30000000000003, 0.1999999999999993, 124.99999999999999, 77.60000000000001, 99.19999999999997, 19.100000000000023, -70.6, -99.40000000000003, 25.400000000000006, 26.899999999999984, -1.3000000000000007, -28.29999999999975, 89.59999999999985, -158.50000000000048, 77.8999999999997, 83.30000000000001, 38.00000000000007, 68.6, 39.500000000000014, 26.600000000000122, -96.99999999999999, 20.000000000000014, -127.0000000000006, -135.39999999999992, -38.20000000000002, -7.599999999999973, -29.799999999999983, -71.20000000000005, 20.000000000000014, 8.900000000000007, -86.50000000000001, 17.899999999999988, 20.000000000000014, -139.90000000000003, -36.400000000000034, 20.000000000000014, 82.39999999999998, 20.000000000000014, -63.39999999999998, -44.5, -36.40000000000008, -98.8000000000005, -91.90000000000003, 0.5000000000000071, -10.299999999999999, -99.40000000000016, 28.399999999999956, 117.49999999999994, -112.60000000000002, -72.39999999999999, 65.29999999999995, 22.100000000000072, 20.000000000000014, -286.89999999999986, -17.79999999999994, -81.09999999999997, 163.09999999999997, 200.0, 9.499999999999972, -119.20000000000041, -99.70000000000007, -32.49999999999998, -200.20000000000013, -174.4000000000002], "policy_predator_policy_reward": [12.0, 11.0, 20.0, 63.0, 59.0, 55.0, 0.0, 89.0, 30.0, 0.0, 0.0, 59.0, 124.0, 82.0, 105.0, 69.0, 24.0, 63.0, 76.0, 92.0, 52.0, 89.0, 6.0, 104.0, 64.0, 151.0, 58.0, 19.0, 112.0, 113.0, 94.0, 15.0, 25.0, 0.0, 0.0, 53.0, 99.0, 43.0, 59.0, 19.0, 137.0, 122.0, 3.0, 89.0, 145.0, 63.0, 51.0, 56.0, 77.0, 55.0, 0.0, 3.0, 48.0, 94.0, 0.0, 0.0, 29.0, 141.0, 115.0, 116.0, 134.0, 1.0, 61.0, 8.0, 82.0, 105.0, 53.0, 54.0, 18.0, 32.0, 63.0, 75.0, 56.0, 132.0, 0.0, 0.0, 137.0, 115.0, 83.0, 108.0, 83.0, 49.0, 65.0, 0.0, 12.0, 38.0, 29.0, 56.0, 0.0, 11.0, 74.0, 100.0, 48.0, 84.0, 23.0, 1.0, 70.0, 0.0, 21.0, 127.0, 72.0, 85.0, 16.0, 65.0, 76.0, 60.0, 95.0, 72.0, 0.0, 8.0, 34.0, 0.0, 53.0, 47.0, 40.0, 82.0, 91.0, 117.0, 69.0, 0.0, 4.0, 91.0, 0.0, 93.0, 27.0, 43.0, 52.0, 42.0, 19.0, 15.0, 31.0, 39.0, 77.0, 32.0, 27.0, 0.0, 58.0, 55.0, 42.0, 0.0, 54.0, 0.0, 79.0, 80.0, 34.0, 24.0, 50.0, 23.0, 46.0, 71.0, 26.0, 18.0, 14.0, 53.0, 34.0, 49.0, 88.0, 22.0, 14.0, 126.0, 71.0, 45.0, 56.0, 63.0, 49.0, 0.0, 35.0, 50.0, 15.0, 79.0, 19.0, 58.0, 10.0, 24.0, 43.0, 76.0, 41.0, 85.0, 6.0, 85.0, 48.0, 55.0, 24.0, 0.0, 52.0, 67.0, 17.0, 37.0, 143.0, 36.0, 33.0, 90.0, 0.0, 0.0, 30.0, 90.0, 89.0, 37.0, 156.0, 29.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6989480413947368, "mean_inference_ms": 1.6111912202502807, "mean_action_processing_ms": 0.2805040528748734, "mean_env_wait_ms": 0.21484501512007548, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004236340522766113, "StateBufferConnector_ms": 0.003395676612854004, "ViewRequirementAgentConnector_ms": 0.12124311923980713}, "num_episodes": 18, "episode_return_max": 364.5, "episode_return_min": -189.60000000000034, "episode_return_mean": 67.70299999999993, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 192000, "num_agent_steps_trained": 192000, "num_env_steps_sampled": 48000, "num_env_steps_trained": 48000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 77.96639637207794, "num_env_steps_trained_throughput_per_sec": 77.96639637207794, "timesteps_total": 48000, "num_env_steps_sampled_lifetime": 48000, "num_agent_steps_sampled_lifetime": 192000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 192000, "timers": {"training_iteration_time_ms": 51581.101, "restore_workers_time_ms": 0.014, "training_step_time_ms": 51581.061, "sample_time_ms": 1269.651, "learn_time_ms": 50298.57, "learn_throughput": 79.525, "synch_weights_time_ms": 10.82}, "counters": {"num_env_steps_sampled": 48000, "num_env_steps_trained": 48000, "num_agent_steps_sampled": 192000, "num_agent_steps_trained": 192000}, "done": false, "training_iteration": 12, "trial_id": "11e70_00000", "date": "2024-08-12_23-17-26", "timestamp": 1723519046, "time_this_iter_s": 51.37837028503418, "time_total_s": 627.4851059913635, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2b159d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 627.4851059913635, "iterations_since_restore": 12, "perf": {"cpu_util_percent": 37.178082191780824, "ram_util_percent": 82.87808219178083}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.547092572848002, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.889828769744389, "policy_loss": -0.014347449645754837, "vf_loss": 7.900657114906917, "vf_explained_var": 0.04373921149622196, "kl": 0.01173033936174761, "entropy": 1.498989159657211, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 23625.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.7753468944597497, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.14808779847685, "policy_loss": -0.010804460762886617, "vf_loss": 8.157052210903672, "vf_explained_var": -0.12009925123244997, "kl": 0.012267014239815075, "entropy": 1.4389676024043372, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 23625.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 52000, "num_env_steps_trained": 52000, "num_agent_steps_sampled": 208000, "num_agent_steps_trained": 208000}, "env_runners": {"episode_reward_max": 364.5, "episode_reward_min": -256.20000000000016, "episode_reward_mean": 39.7849999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -351.4999999999998, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 262.0}, "policy_reward_mean": {"prey_policy": -36.70750000000004, "predator_policy": 56.6}, "custom_metrics": {}, "hist_stats": {"episode_reward": [31.999999999999588, 130.6, -131.79999999999998, 104.99999999999972, -176.2, 146.99999999999994, 51.99999999999994, 296.79999999999984, 13.400000000000048, 40.0000000000003, 15.300000000000011, 51.10000000000011, 1.2999999999999972, 84.09999999999991, -10.59999999999988, -50.69999999999992, 96.59999999999953, 40.6, 57.599999999999994, 308.1999999999998, 14.800000000000018, -20.39999999999999, 159.99999999999997, 164.09999999999994, 144.89999999999964, 168.49999999999997, 364.5, -19.999999999999886, 52.60000000000012, 155.7999999999993, 87.19999999999936, -97.50000000000091, 44.9, 133.0, 40.10000000000027, 78.59999999999991, 31.20000000000018, 25.999999999999993, 90.79999999999997, 102.89999999999988, -12.099999999999874, -35.89999999999967, 175.79999999999998, 48.69999999999985, 27.19999999999999, 147.5, 103.99999999999974, 81.79999999999981, 30.50000000000002, 281.5, 75.90000000000006, 244.59999999999997, 172.3, -11.0, 110.29999999999998, 43.4000000000002, 48.10000000000001, 205.1999999999996, 173.59999999999977, 149.09999999999943, 33.00000000000001, -122.40000000000094, 70.2, 18.0, 77.89999999999995, 16.400000000000254, -25.899999999999928, 60.59999999999994, 136.39999999999938, 11.10000000000003, -9.200000000000214, -0.40000000000011493, -6.699999999999964, 169.89999999999947, -65.99999999999989, 141.39999999999998, -87.90000000000015, 24.099999999999838, 363.1000000000002, 10.300000000000008, -6.199999999999971, -189.60000000000034, -117.70000000000007, -161.79999999999995, -66.29999999999987, -125.30000000000044, 140.09999999999923, -29.39999999999997, -52.69999999999981, -169.00000000000037, 33.69999999999989, -142.50000000000065, -90.79999999999998, -38.69999999999992, -174.50000000000014, -256.20000000000016, -207.20000000000005, -113.10000000000082, 69.19999999999928, -22.199999999999907], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-130.0, 20.000000000000014, 11.0, 41.6, -225.7, -165.10000000000002, 156.19999999999982, -143.20000000000002, -255.70000000000005, -128.5, -37.30000000000001, 77.30000000000001, -52.3, -27.69999999999999, 191.9, 101.9, -92.8, -35.800000000000026, 20.000000000000014, 20.000000000000014, -4.0, -150.70000000000007, -199.9, 20.000000000000014, -172.3, 38.6, -94.30000000000001, 109.4, -217.60000000000002, 20.000000000000014, -100.9, -56.80000000000001, 20.000000000000014, 26.599999999999994, -91.0, -6.3999999999999915, 28.099999999999998, -158.5, 109.99999999999997, 198.2, -91.90000000000009, -145.3, -205.0, -6.399999999999995, -74.80000000000007, 102.8, 70.1, 28.999999999999964, 20.000000000000014, 74.9, 106.4, -22.900000000000006, 154.4, 199.1, -29.199999999999925, -164.80000000000024, -17.20000000000003, -62.20000000000002, -17.79999999999974, 149.59999999999988, -127.00000000000051, 144.19999999999968, -9.700000000000038, -235.80000000000047, -86.8000000000003, -25.299999999999997, 26.30000000000001, 25.699999999999996, -115.90000000000018, 20.000000000000014, -82.0, -6.400000000000022, 20.000000000000014, 3.1999999999999704, -3.1000000000000365, -4.900000000000038, 11.900000000000002, -21.099999999999998, -71.2000000000001, 52.10000000000003, -17.500000000000036, -202.60000000000002, 20.000000000000014, -124.90000000000055, -55.900000000000034, 136.6999999999999, -6.699999999999967, -37.600000000000136, -62.80000000000004, 20.000000000000014, 16.70000000000001, 36.80000000000001, 93.49999999999989, -23.500000000000036, -15.699999999999754, 27.500000000000007, -31.29999999999999, -47.19999999999997, 99.19999999999999, 155.29999999999995, -37.30000000000003, 0.1999999999999993, 124.99999999999999, 77.60000000000001, 99.19999999999997, 19.100000000000023, -70.6, -99.40000000000003, 25.400000000000006, 26.899999999999984, -1.3000000000000007, -28.29999999999975, 89.59999999999985, -158.50000000000048, 77.8999999999997, 83.30000000000001, 38.00000000000007, 68.6, 39.500000000000014, 26.600000000000122, -96.99999999999999, 20.000000000000014, -127.0000000000006, -135.39999999999992, -38.20000000000002, -7.599999999999973, -29.799999999999983, -71.20000000000005, 20.000000000000014, 8.900000000000007, -86.50000000000001, 17.899999999999988, 20.000000000000014, -139.90000000000003, -36.400000000000034, 20.000000000000014, 82.39999999999998, 20.000000000000014, -63.39999999999998, -44.5, -36.40000000000008, -98.8000000000005, -91.90000000000003, 0.5000000000000071, -10.299999999999999, -99.40000000000016, 28.399999999999956, 117.49999999999994, -112.60000000000002, -72.39999999999999, 65.29999999999995, 22.100000000000072, 20.000000000000014, -286.89999999999986, -17.79999999999994, -81.09999999999997, 163.09999999999997, 200.0, 9.499999999999972, -119.20000000000041, -99.70000000000007, -32.49999999999998, -200.20000000000013, -174.4000000000002, -77.80000000000004, -199.90000000000015, -296.5, -76.30000000000001, -69.70000000000003, -67.60000000000005, -139.90000000000032, -135.40000000000018, 45.800000000000125, 47.300000000000075, -198.40000000000006, 20.000000000000014, -42.400000000000034, -187.30000000000015, -159.4000000000004, -229.59999999999997, 71.89999999999986, -182.19999999999996, 20.000000000000014, -341.4999999999999, -38.2, -187.60000000000025, -197.20000000000002, 21.499999999999982, -171.10000000000005, -195.4000000000001, -260.20000000000005, -226.00000000000009, -351.4999999999998, -186.70000000000002, -95.80000000000041, -154.30000000000038, 20.000000000000014, -11.799999999999983, -18.999999999999975, -143.20000000000016], "policy_predator_policy_reward": [99.0, 43.0, 59.0, 19.0, 137.0, 122.0, 3.0, 89.0, 145.0, 63.0, 51.0, 56.0, 77.0, 55.0, 0.0, 3.0, 48.0, 94.0, 0.0, 0.0, 29.0, 141.0, 115.0, 116.0, 134.0, 1.0, 61.0, 8.0, 82.0, 105.0, 53.0, 54.0, 18.0, 32.0, 63.0, 75.0, 56.0, 132.0, 0.0, 0.0, 137.0, 115.0, 83.0, 108.0, 83.0, 49.0, 65.0, 0.0, 12.0, 38.0, 29.0, 56.0, 0.0, 11.0, 74.0, 100.0, 48.0, 84.0, 23.0, 1.0, 70.0, 0.0, 21.0, 127.0, 72.0, 85.0, 16.0, 65.0, 76.0, 60.0, 95.0, 72.0, 0.0, 8.0, 34.0, 0.0, 53.0, 47.0, 40.0, 82.0, 91.0, 117.0, 69.0, 0.0, 4.0, 91.0, 0.0, 93.0, 27.0, 43.0, 52.0, 42.0, 19.0, 15.0, 31.0, 39.0, 77.0, 32.0, 27.0, 0.0, 58.0, 55.0, 42.0, 0.0, 54.0, 0.0, 79.0, 80.0, 34.0, 24.0, 50.0, 23.0, 46.0, 71.0, 26.0, 18.0, 14.0, 53.0, 34.0, 49.0, 88.0, 22.0, 14.0, 126.0, 71.0, 45.0, 56.0, 63.0, 49.0, 0.0, 35.0, 50.0, 15.0, 79.0, 19.0, 58.0, 10.0, 24.0, 43.0, 76.0, 41.0, 85.0, 6.0, 85.0, 48.0, 55.0, 24.0, 0.0, 52.0, 67.0, 17.0, 37.0, 143.0, 36.0, 33.0, 90.0, 0.0, 0.0, 30.0, 90.0, 89.0, 37.0, 156.0, 29.0, 148.0, 12.0, 56.0, 155.0, 57.0, 14.0, 141.0, 9.0, 47.0, 0.0, 51.0, 98.0, 60.0, 117.0, 99.0, 121.0, 58.0, 86.0, 179.0, 0.0, 16.0, 119.0, 84.0, 53.0, 133.0, 59.0, 150.0, 80.0, 262.0, 69.0, 57.0, 80.0, 0.0, 61.0, 96.0, 44.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6970160858850855, "mean_inference_ms": 1.603606427202192, "mean_action_processing_ms": 0.2788966468000786, "mean_env_wait_ms": 0.21322554630562535, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0042487382888793945, "StateBufferConnector_ms": 0.0034693479537963867, "ViewRequirementAgentConnector_ms": 0.1388871669769287}, "num_episodes": 18, "episode_return_max": 364.5, "episode_return_min": -256.20000000000016, "episode_return_mean": 39.7849999999999, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 208000, "num_agent_steps_trained": 208000, "num_env_steps_sampled": 52000, "num_env_steps_trained": 52000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 78.36701773162555, "num_env_steps_trained_throughput_per_sec": 78.36701773162555, "timesteps_total": 52000, "num_env_steps_sampled_lifetime": 52000, "num_agent_steps_sampled_lifetime": 208000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 208000, "timers": {"training_iteration_time_ms": 51538.078, "restore_workers_time_ms": 0.014, "training_step_time_ms": 51538.039, "sample_time_ms": 1294.674, "learn_time_ms": 50230.337, "learn_throughput": 79.633, "synch_weights_time_ms": 10.801}, "counters": {"num_env_steps_sampled": 52000, "num_env_steps_trained": 52000, "num_agent_steps_sampled": 208000, "num_agent_steps_trained": 208000}, "done": false, "training_iteration": 13, "trial_id": "11e70_00000", "date": "2024-08-12_23-18-17", "timestamp": 1723519097, "time_this_iter_s": 51.083431005477905, "time_total_s": 678.5685369968414, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2ad7f70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 678.5685369968414, "iterations_since_restore": 13, "perf": {"cpu_util_percent": 36.85138888888889, "ram_util_percent": 82.6902777777778}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.82555358946008, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.315834009836591, "policy_loss": -0.008842297830919504, "vf_loss": 4.3230311509793395, "vf_explained_var": 0.06809447808240457, "kl": 0.005483887340452148, "entropy": 1.4820144910030264, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 25515.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.70974660077423, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.503236997695196, "policy_loss": -0.013400433114581993, "vf_loss": 4.514613481299587, "vf_explained_var": -0.1330327207449252, "kl": 0.013492968390438898, "entropy": 1.3928663917319484, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 25515.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 56000, "num_env_steps_trained": 56000, "num_agent_steps_sampled": 224000, "num_agent_steps_trained": 224000}, "env_runners": {"episode_reward_max": 363.1000000000002, "episode_reward_min": -256.20000000000016, "episode_reward_mean": 14.295999999999914, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -351.4999999999998, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 262.0}, "policy_reward_mean": {"prey_policy": -46.68700000000006, "predator_policy": 53.835}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-19.999999999999886, 52.60000000000012, 155.7999999999993, 87.19999999999936, -97.50000000000091, 44.9, 133.0, 40.10000000000027, 78.59999999999991, 31.20000000000018, 25.999999999999993, 90.79999999999997, 102.89999999999988, -12.099999999999874, -35.89999999999967, 175.79999999999998, 48.69999999999985, 27.19999999999999, 147.5, 103.99999999999974, 81.79999999999981, 30.50000000000002, 281.5, 75.90000000000006, 244.59999999999997, 172.3, -11.0, 110.29999999999998, 43.4000000000002, 48.10000000000001, 205.1999999999996, 173.59999999999977, 149.09999999999943, 33.00000000000001, -122.40000000000094, 70.2, 18.0, 77.89999999999995, 16.400000000000254, -25.899999999999928, 60.59999999999994, 136.39999999999938, 11.10000000000003, -9.200000000000214, -0.40000000000011493, -6.699999999999964, 169.89999999999947, -65.99999999999989, 141.39999999999998, -87.90000000000015, 24.099999999999838, 363.1000000000002, 10.300000000000008, -6.199999999999971, -189.60000000000034, -117.70000000000007, -161.79999999999995, -66.29999999999987, -125.30000000000044, 140.09999999999923, -29.39999999999997, -52.69999999999981, -169.00000000000037, 33.69999999999989, -142.50000000000065, -90.79999999999998, -38.69999999999992, -174.50000000000014, -256.20000000000016, -207.20000000000005, -113.10000000000082, 69.19999999999928, -22.199999999999907, -103.30000000000027, 1.899999999999973, -129.60000000000036, -87.60000000000034, 45.700000000000436, -34.699999999999605, 45.50000000000009, 57.800000000000225, -65.6, -179.8000000000002, 10.899999999999938, 69.00000000000004, 23.000000000000057, 36.700000000000294, 79.89999999999911, -48.49999999999976, -31.19999999999964, -86.80000000000064, -115.20000000000005, 29.000000000000256, 66.40000000000019, -25.29999999999979, 40.0000000000003, -23.499999999999872, -10.29999999999997, 27.500000000000124, -42.10000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-29.199999999999925, -164.80000000000024, -17.20000000000003, -62.20000000000002, -17.79999999999974, 149.59999999999988, -127.00000000000051, 144.19999999999968, -9.700000000000038, -235.80000000000047, -86.8000000000003, -25.299999999999997, 26.30000000000001, 25.699999999999996, -115.90000000000018, 20.000000000000014, -82.0, -6.400000000000022, 20.000000000000014, 3.1999999999999704, -3.1000000000000365, -4.900000000000038, 11.900000000000002, -21.099999999999998, -71.2000000000001, 52.10000000000003, -17.500000000000036, -202.60000000000002, 20.000000000000014, -124.90000000000055, -55.900000000000034, 136.6999999999999, -6.699999999999967, -37.600000000000136, -62.80000000000004, 20.000000000000014, 16.70000000000001, 36.80000000000001, 93.49999999999989, -23.500000000000036, -15.699999999999754, 27.500000000000007, -31.29999999999999, -47.19999999999997, 99.19999999999999, 155.29999999999995, -37.30000000000003, 0.1999999999999993, 124.99999999999999, 77.60000000000001, 99.19999999999997, 19.100000000000023, -70.6, -99.40000000000003, 25.400000000000006, 26.899999999999984, -1.3000000000000007, -28.29999999999975, 89.59999999999985, -158.50000000000048, 77.8999999999997, 83.30000000000001, 38.00000000000007, 68.6, 39.500000000000014, 26.600000000000122, -96.99999999999999, 20.000000000000014, -127.0000000000006, -135.39999999999992, -38.20000000000002, -7.599999999999973, -29.799999999999983, -71.20000000000005, 20.000000000000014, 8.900000000000007, -86.50000000000001, 17.899999999999988, 20.000000000000014, -139.90000000000003, -36.400000000000034, 20.000000000000014, 82.39999999999998, 20.000000000000014, -63.39999999999998, -44.5, -36.40000000000008, -98.8000000000005, -91.90000000000003, 0.5000000000000071, -10.299999999999999, -99.40000000000016, 28.399999999999956, 117.49999999999994, -112.60000000000002, -72.39999999999999, 65.29999999999995, 22.100000000000072, 20.000000000000014, -286.89999999999986, -17.79999999999994, -81.09999999999997, 163.09999999999997, 200.0, 9.499999999999972, -119.20000000000041, -99.70000000000007, -32.49999999999998, -200.20000000000013, -174.4000000000002, -77.80000000000004, -199.90000000000015, -296.5, -76.30000000000001, -69.70000000000003, -67.60000000000005, -139.90000000000032, -135.40000000000018, 45.800000000000125, 47.300000000000075, -198.40000000000006, 20.000000000000014, -42.400000000000034, -187.30000000000015, -159.4000000000004, -229.59999999999997, 71.89999999999986, -182.19999999999996, 20.000000000000014, -341.4999999999999, -38.2, -187.60000000000025, -197.20000000000002, 21.499999999999982, -171.10000000000005, -195.4000000000001, -260.20000000000005, -226.00000000000009, -351.4999999999998, -186.70000000000002, -95.80000000000041, -154.30000000000038, 20.000000000000014, -11.799999999999983, -18.999999999999975, -143.20000000000016, -187.30000000000013, -127.0000000000001, -103.60000000000052, 30.500000000000192, -179.20000000000024, -162.4000000000001, -192.1000000000002, -83.50000000000024, -27.400000000000034, 43.10000000000024, 20.000000000000014, -153.70000000000059, -16.59999999999996, -16.899999999999956, 20.000000000000014, 0.7999999999999616, -299.5, 17.899999999999988, -237.10000000000016, -129.70000000000002, -66.10000000000078, 20.000000000000014, 43.700000000000195, -30.699999999999896, -27.999999999999787, 20.000000000000014, 20.000000000000014, 13.699999999999946, 20.000000000000014, 56.9000000000002, -101.80000000000078, -132.70000000000013, -85.00000000000055, -65.20000000000078, -51.99999999999989, -140.80000000000024, -112.60000000000005, -148.60000000000002, 62.30000000000022, -115.3000000000001, -45.699999999999804, 73.09999999999955, 20.000000000000014, -175.30000000000013, 20.000000000000014, 20.000000000000014, -54.399999999999885, -75.10000000000005, 15.79999999999995, -132.10000000000008, -17.499999999999822, -48.999999999999844, -41.79999999999979, -73.30000000000078], "policy_predator_policy_reward": [74.0, 100.0, 48.0, 84.0, 23.0, 1.0, 70.0, 0.0, 21.0, 127.0, 72.0, 85.0, 16.0, 65.0, 76.0, 60.0, 95.0, 72.0, 0.0, 8.0, 34.0, 0.0, 53.0, 47.0, 40.0, 82.0, 91.0, 117.0, 69.0, 0.0, 4.0, 91.0, 0.0, 93.0, 27.0, 43.0, 52.0, 42.0, 19.0, 15.0, 31.0, 39.0, 77.0, 32.0, 27.0, 0.0, 58.0, 55.0, 42.0, 0.0, 54.0, 0.0, 79.0, 80.0, 34.0, 24.0, 50.0, 23.0, 46.0, 71.0, 26.0, 18.0, 14.0, 53.0, 34.0, 49.0, 88.0, 22.0, 14.0, 126.0, 71.0, 45.0, 56.0, 63.0, 49.0, 0.0, 35.0, 50.0, 15.0, 79.0, 19.0, 58.0, 10.0, 24.0, 43.0, 76.0, 41.0, 85.0, 6.0, 85.0, 48.0, 55.0, 24.0, 0.0, 52.0, 67.0, 17.0, 37.0, 143.0, 36.0, 33.0, 90.0, 0.0, 0.0, 30.0, 90.0, 89.0, 37.0, 156.0, 29.0, 148.0, 12.0, 56.0, 155.0, 57.0, 14.0, 141.0, 9.0, 47.0, 0.0, 51.0, 98.0, 60.0, 117.0, 99.0, 121.0, 58.0, 86.0, 179.0, 0.0, 16.0, 119.0, 84.0, 53.0, 133.0, 59.0, 150.0, 80.0, 262.0, 69.0, 57.0, 80.0, 0.0, 61.0, 96.0, 44.0, 112.0, 99.0, 0.0, 75.0, 87.0, 125.0, 48.0, 140.0, 30.0, 0.0, 18.0, 81.0, 0.0, 79.0, 16.0, 21.0, 97.0, 119.0, 148.0, 39.0, 27.0, 30.0, 39.0, 17.0, 0.0, 31.0, 0.0, 3.0, 3.0, 0.0, 105.0, 81.0, 43.0, 76.0, 0.0, 106.0, 79.0, 67.0, 82.0, 0.0, 39.0, 0.0, 32.0, 98.0, 0.0, 0.0, 106.0, 0.0, 51.0, 55.0, 52.0, 42.0, 43.0, 30.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6962458297211767, "mean_inference_ms": 1.595387231872788, "mean_action_processing_ms": 0.2770908704539214, "mean_env_wait_ms": 0.21150305990704057, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004288077354431152, "StateBufferConnector_ms": 0.0034695863723754883, "ViewRequirementAgentConnector_ms": 0.13097012042999268}, "num_episodes": 27, "episode_return_max": 363.1000000000002, "episode_return_min": -256.20000000000016, "episode_return_mean": 14.295999999999914, "episodes_this_iter": 27}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 224000, "num_agent_steps_trained": 224000, "num_env_steps_sampled": 56000, "num_env_steps_trained": 56000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 78.73087260844797, "num_env_steps_trained_throughput_per_sec": 78.73087260844797, "timesteps_total": 56000, "num_env_steps_sampled_lifetime": 56000, "num_agent_steps_sampled_lifetime": 224000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 224000, "timers": {"training_iteration_time_ms": 51369.695, "restore_workers_time_ms": 0.014, "training_step_time_ms": 51369.657, "sample_time_ms": 1291.064, "learn_time_ms": 50065.583, "learn_throughput": 79.895, "synch_weights_time_ms": 10.775}, "counters": {"num_env_steps_sampled": 56000, "num_env_steps_trained": 56000, "num_agent_steps_sampled": 224000, "num_agent_steps_trained": 224000}, "done": false, "training_iteration": 14, "trial_id": "11e70_00000", "date": "2024-08-12_23-19-08", "timestamp": 1723519148, "time_this_iter_s": 50.85865807533264, "time_total_s": 729.4271950721741, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2b62790>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 729.4271950721741, "iterations_since_restore": 14, "perf": {"cpu_util_percent": 36.54305555555556, "ram_util_percent": 82.84444444444443}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.99133393493279, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.9586488838549014, "policy_loss": -0.008324517127836035, "vf_loss": 3.9647595833218285, "vf_explained_var": 0.07347143743404005, "kl": 0.007379393644323356, "entropy": 1.4597272917707131, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 27405.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.5330815423417974, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.5733631219813433, "policy_loss": -0.01314984057837772, "vf_loss": 3.584702283995492, "vf_explained_var": -0.08583066999596893, "kl": 0.012071232296104227, "entropy": 1.3682344270761682, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 27405.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 60000, "num_env_steps_trained": 60000, "num_agent_steps_sampled": 240000, "num_agent_steps_trained": 240000}, "env_runners": {"episode_reward_max": 363.1000000000002, "episode_reward_min": -256.20000000000016, "episode_reward_mean": 6.330999999999917, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -351.4999999999998, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 262.0}, "policy_reward_mean": {"prey_policy": -46.65450000000008, "predator_policy": 49.82}, "custom_metrics": {}, "hist_stats": {"episode_reward": [147.5, 103.99999999999974, 81.79999999999981, 30.50000000000002, 281.5, 75.90000000000006, 244.59999999999997, 172.3, -11.0, 110.29999999999998, 43.4000000000002, 48.10000000000001, 205.1999999999996, 173.59999999999977, 149.09999999999943, 33.00000000000001, -122.40000000000094, 70.2, 18.0, 77.89999999999995, 16.400000000000254, -25.899999999999928, 60.59999999999994, 136.39999999999938, 11.10000000000003, -9.200000000000214, -0.40000000000011493, -6.699999999999964, 169.89999999999947, -65.99999999999989, 141.39999999999998, -87.90000000000015, 24.099999999999838, 363.1000000000002, 10.300000000000008, -6.199999999999971, -189.60000000000034, -117.70000000000007, -161.79999999999995, -66.29999999999987, -125.30000000000044, 140.09999999999923, -29.39999999999997, -52.69999999999981, -169.00000000000037, 33.69999999999989, -142.50000000000065, -90.79999999999998, -38.69999999999992, -174.50000000000014, -256.20000000000016, -207.20000000000005, -113.10000000000082, 69.19999999999928, -22.199999999999907, -103.30000000000027, 1.899999999999973, -129.60000000000036, -87.60000000000034, 45.700000000000436, -34.699999999999605, 45.50000000000009, 57.800000000000225, -65.6, -179.8000000000002, 10.899999999999938, 69.00000000000004, 23.000000000000057, 36.700000000000294, 79.89999999999911, -48.49999999999976, -31.19999999999964, -86.80000000000064, -115.20000000000005, 29.000000000000256, 66.40000000000019, -25.29999999999979, 40.0000000000003, -23.499999999999872, -10.29999999999997, 27.500000000000124, -42.10000000000003, 2.4999999999999396, -19.999999999999673, 37.80000000000026, -4.4999999999997655, 26.6000000000002, 41.40000000000047, -57.40000000000096, -30.499999999999652, 27.60000000000009, 141.69999999999882, -125.2000000000009, 33.20000000000023, 76.49999999999872, -28.899999999999622, 9.099999999999973, -8.299999999999716, -15.499999999999556, 26.700000000000102], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [16.70000000000001, 36.80000000000001, 93.49999999999989, -23.500000000000036, -15.699999999999754, 27.500000000000007, -31.29999999999999, -47.19999999999997, 99.19999999999999, 155.29999999999995, -37.30000000000003, 0.1999999999999993, 124.99999999999999, 77.60000000000001, 99.19999999999997, 19.100000000000023, -70.6, -99.40000000000003, 25.400000000000006, 26.899999999999984, -1.3000000000000007, -28.29999999999975, 89.59999999999985, -158.50000000000048, 77.8999999999997, 83.30000000000001, 38.00000000000007, 68.6, 39.500000000000014, 26.600000000000122, -96.99999999999999, 20.000000000000014, -127.0000000000006, -135.39999999999992, -38.20000000000002, -7.599999999999973, -29.799999999999983, -71.20000000000005, 20.000000000000014, 8.900000000000007, -86.50000000000001, 17.899999999999988, 20.000000000000014, -139.90000000000003, -36.400000000000034, 20.000000000000014, 82.39999999999998, 20.000000000000014, -63.39999999999998, -44.5, -36.40000000000008, -98.8000000000005, -91.90000000000003, 0.5000000000000071, -10.299999999999999, -99.40000000000016, 28.399999999999956, 117.49999999999994, -112.60000000000002, -72.39999999999999, 65.29999999999995, 22.100000000000072, 20.000000000000014, -286.89999999999986, -17.79999999999994, -81.09999999999997, 163.09999999999997, 200.0, 9.499999999999972, -119.20000000000041, -99.70000000000007, -32.49999999999998, -200.20000000000013, -174.4000000000002, -77.80000000000004, -199.90000000000015, -296.5, -76.30000000000001, -69.70000000000003, -67.60000000000005, -139.90000000000032, -135.40000000000018, 45.800000000000125, 47.300000000000075, -198.40000000000006, 20.000000000000014, -42.400000000000034, -187.30000000000015, -159.4000000000004, -229.59999999999997, 71.89999999999986, -182.19999999999996, 20.000000000000014, -341.4999999999999, -38.2, -187.60000000000025, -197.20000000000002, 21.499999999999982, -171.10000000000005, -195.4000000000001, -260.20000000000005, -226.00000000000009, -351.4999999999998, -186.70000000000002, -95.80000000000041, -154.30000000000038, 20.000000000000014, -11.799999999999983, -18.999999999999975, -143.20000000000016, -187.30000000000013, -127.0000000000001, -103.60000000000052, 30.500000000000192, -179.20000000000024, -162.4000000000001, -192.1000000000002, -83.50000000000024, -27.400000000000034, 43.10000000000024, 20.000000000000014, -153.70000000000059, -16.59999999999996, -16.899999999999956, 20.000000000000014, 0.7999999999999616, -299.5, 17.899999999999988, -237.10000000000016, -129.70000000000002, -66.10000000000078, 20.000000000000014, 43.700000000000195, -30.699999999999896, -27.999999999999787, 20.000000000000014, 20.000000000000014, 13.699999999999946, 20.000000000000014, 56.9000000000002, -101.80000000000078, -132.70000000000013, -85.00000000000055, -65.20000000000078, -51.99999999999989, -140.80000000000024, -112.60000000000005, -148.60000000000002, 62.30000000000022, -115.3000000000001, -45.699999999999804, 73.09999999999955, 20.000000000000014, -175.30000000000013, 20.000000000000014, 20.000000000000014, -54.399999999999885, -75.10000000000005, 15.79999999999995, -132.10000000000008, -17.499999999999822, -48.999999999999844, -41.79999999999979, -73.30000000000078, -77.50000000000047, 20.000000000000014, 1.0999999999999865, -93.10000000000058, 15.799999999999958, 20.000000000000014, 20.000000000000014, -107.50000000000075, -9.699999999999903, 5.299999999999976, 16.699999999999996, -7.300000000000004, -56.50000000000015, -64.90000000000052, -23.79999999999979, -99.70000000000051, -24.699999999999797, -15.700000000000038, 121.69999999999955, 20.000000000000014, -148.60000000000048, -106.60000000000039, -7.299999999999976, 24.500000000000085, 24.50000000000009, 7.999999999999725, -92.80000000000067, -21.09999999999978, -77.80000000000021, -57.10000000000036, -109.30000000000078, 20.000000000000014, -89.50000000000082, 20.000000000000014, 20.000000000000014, -19.299999999999763], "policy_predator_policy_reward": [52.0, 42.0, 19.0, 15.0, 31.0, 39.0, 77.0, 32.0, 27.0, 0.0, 58.0, 55.0, 42.0, 0.0, 54.0, 0.0, 79.0, 80.0, 34.0, 24.0, 50.0, 23.0, 46.0, 71.0, 26.0, 18.0, 14.0, 53.0, 34.0, 49.0, 88.0, 22.0, 14.0, 126.0, 71.0, 45.0, 56.0, 63.0, 49.0, 0.0, 35.0, 50.0, 15.0, 79.0, 19.0, 58.0, 10.0, 24.0, 43.0, 76.0, 41.0, 85.0, 6.0, 85.0, 48.0, 55.0, 24.0, 0.0, 52.0, 67.0, 17.0, 37.0, 143.0, 36.0, 33.0, 90.0, 0.0, 0.0, 30.0, 90.0, 89.0, 37.0, 156.0, 29.0, 148.0, 12.0, 56.0, 155.0, 57.0, 14.0, 141.0, 9.0, 47.0, 0.0, 51.0, 98.0, 60.0, 117.0, 99.0, 121.0, 58.0, 86.0, 179.0, 0.0, 16.0, 119.0, 84.0, 53.0, 133.0, 59.0, 150.0, 80.0, 262.0, 69.0, 57.0, 80.0, 0.0, 61.0, 96.0, 44.0, 112.0, 99.0, 0.0, 75.0, 87.0, 125.0, 48.0, 140.0, 30.0, 0.0, 18.0, 81.0, 0.0, 79.0, 16.0, 21.0, 97.0, 119.0, 148.0, 39.0, 27.0, 30.0, 39.0, 17.0, 0.0, 31.0, 0.0, 3.0, 3.0, 0.0, 105.0, 81.0, 43.0, 76.0, 0.0, 106.0, 79.0, 67.0, 82.0, 0.0, 39.0, 0.0, 32.0, 98.0, 0.0, 0.0, 106.0, 0.0, 51.0, 55.0, 52.0, 42.0, 43.0, 30.0, 32.0, 28.0, 32.0, 40.0, 2.0, 0.0, 26.0, 57.0, 0.0, 31.0, 24.0, 8.0, 0.0, 64.0, 77.0, 16.0, 52.0, 16.0, 0.0, 0.0, 104.0, 26.0, 13.0, 3.0, 37.0, 7.0, 72.0, 13.0, 61.0, 83.0, 44.0, 37.0, 42.0, 12.0, 23.0, 3.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6942386434291996, "mean_inference_ms": 1.5935893003496553, "mean_action_processing_ms": 0.2759123134999106, "mean_env_wait_ms": 0.21070932025992622, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003920793533325195, "StateBufferConnector_ms": 0.0031931400299072266, "ViewRequirementAgentConnector_ms": 0.12668859958648682}, "num_episodes": 18, "episode_return_max": 363.1000000000002, "episode_return_min": -256.20000000000016, "episode_return_mean": 6.330999999999917, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 240000, "num_agent_steps_trained": 240000, "num_env_steps_sampled": 60000, "num_env_steps_trained": 60000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 78.6780760241496, "num_env_steps_trained_throughput_per_sec": 78.6780760241496, "timesteps_total": 60000, "num_env_steps_sampled_lifetime": 60000, "num_agent_steps_sampled_lifetime": 240000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 240000, "timers": {"training_iteration_time_ms": 51082.888, "restore_workers_time_ms": 0.014, "training_step_time_ms": 51082.847, "sample_time_ms": 1245.733, "learn_time_ms": 49823.552, "learn_throughput": 80.283, "synch_weights_time_ms": 10.912}, "counters": {"num_env_steps_sampled": 60000, "num_env_steps_trained": 60000, "num_agent_steps_sampled": 240000, "num_agent_steps_trained": 240000}, "done": false, "training_iteration": 15, "trial_id": "11e70_00000", "date": "2024-08-12_23-19-59", "timestamp": 1723519199, "time_this_iter_s": 50.87677311897278, "time_total_s": 780.3039681911469, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2b67ee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 780.3039681911469, "iterations_since_restore": 15, "perf": {"cpu_util_percent": 36.18630136986302, "ram_util_percent": 83.1027397260274}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.470429028909673, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.2052463024381606, "policy_loss": -0.006865057557643879, "vf_loss": 2.210643921895002, "vf_explained_var": 0.07306507460023991, "kl": 0.004891469472169688, "entropy": 1.4522614054578953, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 29295.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.9363689737975913, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.279902364526476, "policy_loss": -0.00988815017019906, "vf_loss": 2.288565153167361, "vf_explained_var": -0.08042743092491514, "kl": 0.008169073080028986, "entropy": 1.352583820416183, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 29295.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 64000, "num_env_steps_trained": 64000, "num_agent_steps_sampled": 256000, "num_agent_steps_trained": 256000}, "env_runners": {"episode_reward_max": 363.1000000000002, "episode_reward_min": -256.20000000000016, "episode_reward_mean": -11.230000000000057, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -351.4999999999998, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 262.0}, "policy_reward_mean": {"prey_policy": -53.115000000000094, "predator_policy": 47.5}, "custom_metrics": {}, "hist_stats": {"episode_reward": [18.0, 77.89999999999995, 16.400000000000254, -25.899999999999928, 60.59999999999994, 136.39999999999938, 11.10000000000003, -9.200000000000214, -0.40000000000011493, -6.699999999999964, 169.89999999999947, -65.99999999999989, 141.39999999999998, -87.90000000000015, 24.099999999999838, 363.1000000000002, 10.300000000000008, -6.199999999999971, -189.60000000000034, -117.70000000000007, -161.79999999999995, -66.29999999999987, -125.30000000000044, 140.09999999999923, -29.39999999999997, -52.69999999999981, -169.00000000000037, 33.69999999999989, -142.50000000000065, -90.79999999999998, -38.69999999999992, -174.50000000000014, -256.20000000000016, -207.20000000000005, -113.10000000000082, 69.19999999999928, -22.199999999999907, -103.30000000000027, 1.899999999999973, -129.60000000000036, -87.60000000000034, 45.700000000000436, -34.699999999999605, 45.50000000000009, 57.800000000000225, -65.6, -179.8000000000002, 10.899999999999938, 69.00000000000004, 23.000000000000057, 36.700000000000294, 79.89999999999911, -48.49999999999976, -31.19999999999964, -86.80000000000064, -115.20000000000005, 29.000000000000256, 66.40000000000019, -25.29999999999979, 40.0000000000003, -23.499999999999872, -10.29999999999997, 27.500000000000124, -42.10000000000003, 2.4999999999999396, -19.999999999999673, 37.80000000000026, -4.4999999999997655, 26.6000000000002, 41.40000000000047, -57.40000000000096, -30.499999999999652, 27.60000000000009, 141.69999999999882, -125.2000000000009, 33.20000000000023, 76.49999999999872, -28.899999999999622, 9.099999999999973, -8.299999999999716, -15.499999999999556, 26.700000000000102, 9.00000000000005, 39.10000000000041, 68.60000000000014, -105.20000000000104, 43.80000000000043, -6.299999999999816, -22.599999999999554, -2.8999999999998227, -97.00000000000117, 58.000000000000355, 40.0000000000003, 10.299999999999955, 62.10000000000045, 40.0000000000003, -111.10000000000146, 23.100000000000126, -7.399999999999904, 40.0000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-29.799999999999983, -71.20000000000005, 20.000000000000014, 8.900000000000007, -86.50000000000001, 17.899999999999988, 20.000000000000014, -139.90000000000003, -36.400000000000034, 20.000000000000014, 82.39999999999998, 20.000000000000014, -63.39999999999998, -44.5, -36.40000000000008, -98.8000000000005, -91.90000000000003, 0.5000000000000071, -10.299999999999999, -99.40000000000016, 28.399999999999956, 117.49999999999994, -112.60000000000002, -72.39999999999999, 65.29999999999995, 22.100000000000072, 20.000000000000014, -286.89999999999986, -17.79999999999994, -81.09999999999997, 163.09999999999997, 200.0, 9.499999999999972, -119.20000000000041, -99.70000000000007, -32.49999999999998, -200.20000000000013, -174.4000000000002, -77.80000000000004, -199.90000000000015, -296.5, -76.30000000000001, -69.70000000000003, -67.60000000000005, -139.90000000000032, -135.40000000000018, 45.800000000000125, 47.300000000000075, -198.40000000000006, 20.000000000000014, -42.400000000000034, -187.30000000000015, -159.4000000000004, -229.59999999999997, 71.89999999999986, -182.19999999999996, 20.000000000000014, -341.4999999999999, -38.2, -187.60000000000025, -197.20000000000002, 21.499999999999982, -171.10000000000005, -195.4000000000001, -260.20000000000005, -226.00000000000009, -351.4999999999998, -186.70000000000002, -95.80000000000041, -154.30000000000038, 20.000000000000014, -11.799999999999983, -18.999999999999975, -143.20000000000016, -187.30000000000013, -127.0000000000001, -103.60000000000052, 30.500000000000192, -179.20000000000024, -162.4000000000001, -192.1000000000002, -83.50000000000024, -27.400000000000034, 43.10000000000024, 20.000000000000014, -153.70000000000059, -16.59999999999996, -16.899999999999956, 20.000000000000014, 0.7999999999999616, -299.5, 17.899999999999988, -237.10000000000016, -129.70000000000002, -66.10000000000078, 20.000000000000014, 43.700000000000195, -30.699999999999896, -27.999999999999787, 20.000000000000014, 20.000000000000014, 13.699999999999946, 20.000000000000014, 56.9000000000002, -101.80000000000078, -132.70000000000013, -85.00000000000055, -65.20000000000078, -51.99999999999989, -140.80000000000024, -112.60000000000005, -148.60000000000002, 62.30000000000022, -115.3000000000001, -45.699999999999804, 73.09999999999955, 20.000000000000014, -175.30000000000013, 20.000000000000014, 20.000000000000014, -54.399999999999885, -75.10000000000005, 15.79999999999995, -132.10000000000008, -17.499999999999822, -48.999999999999844, -41.79999999999979, -73.30000000000078, -77.50000000000047, 20.000000000000014, 1.0999999999999865, -93.10000000000058, 15.799999999999958, 20.000000000000014, 20.000000000000014, -107.50000000000075, -9.699999999999903, 5.299999999999976, 16.699999999999996, -7.300000000000004, -56.50000000000015, -64.90000000000052, -23.79999999999979, -99.70000000000051, -24.699999999999797, -15.700000000000038, 121.69999999999955, 20.000000000000014, -148.60000000000048, -106.60000000000039, -7.299999999999976, 24.500000000000085, 24.50000000000009, 7.999999999999725, -92.80000000000067, -21.09999999999978, -77.80000000000021, -57.10000000000036, -109.30000000000078, 20.000000000000014, -89.50000000000082, 20.000000000000014, 20.000000000000014, -19.299999999999763, -79.00000000000085, 20.000000000000014, 21.50000000000004, -66.40000000000067, 20.000000000000014, 38.60000000000021, 20.000000000000014, -257.1999999999996, -5.1999999999999975, 20.000000000000014, -26.199999999999825, -45.09999999999976, -56.80000000000041, -17.799999999999784, -35.1999999999998, -12.699999999999864, -155.8000000000006, -50.19999999999986, -27.699999999999783, -4.300000000000033, 20.000000000000014, 20.000000000000014, 15.799999999999946, -65.50000000000087, 20.000000000000014, 16.09999999999996, 20.000000000000014, 20.000000000000014, -53.80000000000018, -196.30000000000055, 20.000000000000014, -31.8999999999998, -42.99999999999985, -66.40000000000035, 20.000000000000014, 20.000000000000014], "policy_predator_policy_reward": [56.0, 63.0, 49.0, 0.0, 35.0, 50.0, 15.0, 79.0, 19.0, 58.0, 10.0, 24.0, 43.0, 76.0, 41.0, 85.0, 6.0, 85.0, 48.0, 55.0, 24.0, 0.0, 52.0, 67.0, 17.0, 37.0, 143.0, 36.0, 33.0, 90.0, 0.0, 0.0, 30.0, 90.0, 89.0, 37.0, 156.0, 29.0, 148.0, 12.0, 56.0, 155.0, 57.0, 14.0, 141.0, 9.0, 47.0, 0.0, 51.0, 98.0, 60.0, 117.0, 99.0, 121.0, 58.0, 86.0, 179.0, 0.0, 16.0, 119.0, 84.0, 53.0, 133.0, 59.0, 150.0, 80.0, 262.0, 69.0, 57.0, 80.0, 0.0, 61.0, 96.0, 44.0, 112.0, 99.0, 0.0, 75.0, 87.0, 125.0, 48.0, 140.0, 30.0, 0.0, 18.0, 81.0, 0.0, 79.0, 16.0, 21.0, 97.0, 119.0, 148.0, 39.0, 27.0, 30.0, 39.0, 17.0, 0.0, 31.0, 0.0, 3.0, 3.0, 0.0, 105.0, 81.0, 43.0, 76.0, 0.0, 106.0, 79.0, 67.0, 82.0, 0.0, 39.0, 0.0, 32.0, 98.0, 0.0, 0.0, 106.0, 0.0, 51.0, 55.0, 52.0, 42.0, 43.0, 30.0, 32.0, 28.0, 32.0, 40.0, 2.0, 0.0, 26.0, 57.0, 0.0, 31.0, 24.0, 8.0, 0.0, 64.0, 77.0, 16.0, 52.0, 16.0, 0.0, 0.0, 104.0, 26.0, 13.0, 3.0, 37.0, 7.0, 72.0, 13.0, 61.0, 83.0, 44.0, 37.0, 42.0, 12.0, 23.0, 3.0, 48.0, 20.0, 47.0, 37.0, 9.0, 1.0, 0.0, 132.0, 24.0, 5.0, 61.0, 4.0, 47.0, 5.0, 26.0, 19.0, 75.0, 34.0, 37.0, 53.0, 0.0, 0.0, 33.0, 27.0, 16.0, 10.0, 0.0, 0.0, 103.0, 36.0, 0.0, 35.0, 76.0, 26.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6953980276087143, "mean_inference_ms": 1.595530683112606, "mean_action_processing_ms": 0.2756106812757774, "mean_env_wait_ms": 0.2101755411838456, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003554224967956543, "StateBufferConnector_ms": 0.0032063722610473633, "ViewRequirementAgentConnector_ms": 0.1344691514968872}, "num_episodes": 18, "episode_return_max": 363.1000000000002, "episode_return_min": -256.20000000000016, "episode_return_mean": -11.230000000000057, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 256000, "num_agent_steps_trained": 256000, "num_env_steps_sampled": 64000, "num_env_steps_trained": 64000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 77.37965254045355, "num_env_steps_trained_throughput_per_sec": 77.37965254045355, "timesteps_total": 64000, "num_env_steps_sampled_lifetime": 64000, "num_agent_steps_sampled_lifetime": 256000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 256000, "timers": {"training_iteration_time_ms": 51019.83, "restore_workers_time_ms": 0.014, "training_step_time_ms": 51019.789, "sample_time_ms": 1279.079, "learn_time_ms": 49727.174, "learn_throughput": 80.439, "synch_weights_time_ms": 10.831}, "counters": {"num_env_steps_sampled": 64000, "num_env_steps_trained": 64000, "num_agent_steps_sampled": 256000, "num_agent_steps_trained": 256000}, "done": false, "training_iteration": 16, "trial_id": "11e70_00000", "date": "2024-08-12_23-20-51", "timestamp": 1723519251, "time_this_iter_s": 51.77526617050171, "time_total_s": 832.0792343616486, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2ad7160>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 832.0792343616486, "iterations_since_restore": 16, "perf": {"cpu_util_percent": 39.4013698630137, "ram_util_percent": 82.94109589041096}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.276975890063735, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.376730472354031, "policy_loss": -0.010202336851655254, "vf_loss": 1.3854872223561403, "vf_explained_var": 0.07257088485848967, "kl": 0.009637220152323064, "entropy": 1.4313138283749738, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 31185.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.267815005116993, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.4556568734071873, "policy_loss": -0.010702973865982755, "vf_loss": 1.4654136698712747, "vf_explained_var": -0.08456561808232908, "kl": 0.006307855746230676, "entropy": 1.3816729927819873, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 31185.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 68000, "num_env_steps_trained": 68000, "num_agent_steps_sampled": 272000, "num_agent_steps_trained": 272000}, "env_runners": {"episode_reward_max": 141.69999999999882, "episode_reward_min": -256.20000000000016, "episode_reward_mean": -16.316000000000034, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -351.4999999999998, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 121.69999999999955, "predator_policy": 262.0}, "policy_reward_mean": {"prey_policy": -50.253000000000085, "predator_policy": 42.095}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-189.60000000000034, -117.70000000000007, -161.79999999999995, -66.29999999999987, -125.30000000000044, 140.09999999999923, -29.39999999999997, -52.69999999999981, -169.00000000000037, 33.69999999999989, -142.50000000000065, -90.79999999999998, -38.69999999999992, -174.50000000000014, -256.20000000000016, -207.20000000000005, -113.10000000000082, 69.19999999999928, -22.199999999999907, -103.30000000000027, 1.899999999999973, -129.60000000000036, -87.60000000000034, 45.700000000000436, -34.699999999999605, 45.50000000000009, 57.800000000000225, -65.6, -179.8000000000002, 10.899999999999938, 69.00000000000004, 23.000000000000057, 36.700000000000294, 79.89999999999911, -48.49999999999976, -31.19999999999964, -86.80000000000064, -115.20000000000005, 29.000000000000256, 66.40000000000019, -25.29999999999979, 40.0000000000003, -23.499999999999872, -10.29999999999997, 27.500000000000124, -42.10000000000003, 2.4999999999999396, -19.999999999999673, 37.80000000000026, -4.4999999999997655, 26.6000000000002, 41.40000000000047, -57.40000000000096, -30.499999999999652, 27.60000000000009, 141.69999999999882, -125.2000000000009, 33.20000000000023, 76.49999999999872, -28.899999999999622, 9.099999999999973, -8.299999999999716, -15.499999999999556, 26.700000000000102, 9.00000000000005, 39.10000000000041, 68.60000000000014, -105.20000000000104, 43.80000000000043, -6.299999999999816, -22.599999999999554, -2.8999999999998227, -97.00000000000117, 58.000000000000355, 40.0000000000003, 10.299999999999955, 62.10000000000045, 40.0000000000003, -111.10000000000146, 23.100000000000126, -7.399999999999904, 40.0000000000003, 14.099999999999953, -2.299999999999865, 57.50000000000047, 22.400000000000013, 22.50000000000007, 40.0000000000003, 4.89999999999994, 40.0000000000003, 40.0000000000003, 33.90000000000021, 24.100000000000172, 2.200000000000201, -68.0000000000017, 37.800000000000296, 24.500000000000103, 4.500000000000108, 36.50000000000025, -16.299999999999677], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-200.20000000000013, -174.4000000000002, -77.80000000000004, -199.90000000000015, -296.5, -76.30000000000001, -69.70000000000003, -67.60000000000005, -139.90000000000032, -135.40000000000018, 45.800000000000125, 47.300000000000075, -198.40000000000006, 20.000000000000014, -42.400000000000034, -187.30000000000015, -159.4000000000004, -229.59999999999997, 71.89999999999986, -182.19999999999996, 20.000000000000014, -341.4999999999999, -38.2, -187.60000000000025, -197.20000000000002, 21.499999999999982, -171.10000000000005, -195.4000000000001, -260.20000000000005, -226.00000000000009, -351.4999999999998, -186.70000000000002, -95.80000000000041, -154.30000000000038, 20.000000000000014, -11.799999999999983, -18.999999999999975, -143.20000000000016, -187.30000000000013, -127.0000000000001, -103.60000000000052, 30.500000000000192, -179.20000000000024, -162.4000000000001, -192.1000000000002, -83.50000000000024, -27.400000000000034, 43.10000000000024, 20.000000000000014, -153.70000000000059, -16.59999999999996, -16.899999999999956, 20.000000000000014, 0.7999999999999616, -299.5, 17.899999999999988, -237.10000000000016, -129.70000000000002, -66.10000000000078, 20.000000000000014, 43.700000000000195, -30.699999999999896, -27.999999999999787, 20.000000000000014, 20.000000000000014, 13.699999999999946, 20.000000000000014, 56.9000000000002, -101.80000000000078, -132.70000000000013, -85.00000000000055, -65.20000000000078, -51.99999999999989, -140.80000000000024, -112.60000000000005, -148.60000000000002, 62.30000000000022, -115.3000000000001, -45.699999999999804, 73.09999999999955, 20.000000000000014, -175.30000000000013, 20.000000000000014, 20.000000000000014, -54.399999999999885, -75.10000000000005, 15.79999999999995, -132.10000000000008, -17.499999999999822, -48.999999999999844, -41.79999999999979, -73.30000000000078, -77.50000000000047, 20.000000000000014, 1.0999999999999865, -93.10000000000058, 15.799999999999958, 20.000000000000014, 20.000000000000014, -107.50000000000075, -9.699999999999903, 5.299999999999976, 16.699999999999996, -7.300000000000004, -56.50000000000015, -64.90000000000052, -23.79999999999979, -99.70000000000051, -24.699999999999797, -15.700000000000038, 121.69999999999955, 20.000000000000014, -148.60000000000048, -106.60000000000039, -7.299999999999976, 24.500000000000085, 24.50000000000009, 7.999999999999725, -92.80000000000067, -21.09999999999978, -77.80000000000021, -57.10000000000036, -109.30000000000078, 20.000000000000014, -89.50000000000082, 20.000000000000014, 20.000000000000014, -19.299999999999763, -79.00000000000085, 20.000000000000014, 21.50000000000004, -66.40000000000067, 20.000000000000014, 38.60000000000021, 20.000000000000014, -257.1999999999996, -5.1999999999999975, 20.000000000000014, -26.199999999999825, -45.09999999999976, -56.80000000000041, -17.799999999999784, -35.1999999999998, -12.699999999999864, -155.8000000000006, -50.19999999999986, -27.699999999999783, -4.300000000000033, 20.000000000000014, 20.000000000000014, 15.799999999999946, -65.50000000000087, 20.000000000000014, 16.09999999999996, 20.000000000000014, 20.000000000000014, -53.80000000000018, -196.30000000000055, 20.000000000000014, -31.8999999999998, -42.99999999999985, -66.40000000000035, 20.000000000000014, 20.000000000000014, -31.899999999999757, 20.000000000000014, -5.49999999999994, -59.800000000000395, 20.000000000000014, 3.499999999999978, 20.000000000000014, -13.599999999999783, 17.29999999999997, -14.799999999999779, 20.000000000000014, 20.000000000000014, 18.19999999999997, -49.299999999999876, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -24.09999999999976, 20.000000000000014, -97.59999999999997, 37.70000000000018, -49.299999999999905, 15.499999999999964, -46.29999999999978, -78.70000000000081, 15.799999999999946, 20.000000000000014, 20.000000000000014, -41.49999999999984, 15.799999999999963, -49.29999999999977, 11.599999999999964, 20.900000000000027, -97.3000000000006, 20.000000000000014], "policy_predator_policy_reward": [156.0, 29.0, 148.0, 12.0, 56.0, 155.0, 57.0, 14.0, 141.0, 9.0, 47.0, 0.0, 51.0, 98.0, 60.0, 117.0, 99.0, 121.0, 58.0, 86.0, 179.0, 0.0, 16.0, 119.0, 84.0, 53.0, 133.0, 59.0, 150.0, 80.0, 262.0, 69.0, 57.0, 80.0, 0.0, 61.0, 96.0, 44.0, 112.0, 99.0, 0.0, 75.0, 87.0, 125.0, 48.0, 140.0, 30.0, 0.0, 18.0, 81.0, 0.0, 79.0, 16.0, 21.0, 97.0, 119.0, 148.0, 39.0, 27.0, 30.0, 39.0, 17.0, 0.0, 31.0, 0.0, 3.0, 3.0, 0.0, 105.0, 81.0, 43.0, 76.0, 0.0, 106.0, 79.0, 67.0, 82.0, 0.0, 39.0, 0.0, 32.0, 98.0, 0.0, 0.0, 106.0, 0.0, 51.0, 55.0, 52.0, 42.0, 43.0, 30.0, 32.0, 28.0, 32.0, 40.0, 2.0, 0.0, 26.0, 57.0, 0.0, 31.0, 24.0, 8.0, 0.0, 64.0, 77.0, 16.0, 52.0, 16.0, 0.0, 0.0, 104.0, 26.0, 13.0, 3.0, 37.0, 7.0, 72.0, 13.0, 61.0, 83.0, 44.0, 37.0, 42.0, 12.0, 23.0, 3.0, 48.0, 20.0, 47.0, 37.0, 9.0, 1.0, 0.0, 132.0, 24.0, 5.0, 61.0, 4.0, 47.0, 5.0, 26.0, 19.0, 75.0, 34.0, 37.0, 53.0, 0.0, 0.0, 33.0, 27.0, 16.0, 10.0, 0.0, 0.0, 103.0, 36.0, 0.0, 35.0, 76.0, 26.0, 0.0, 0.0, 21.0, 5.0, 55.0, 8.0, 18.0, 16.0, 0.0, 16.0, 20.0, 0.0, 0.0, 0.0, 0.0, 36.0, 0.0, 0.0, 0.0, 0.0, 15.0, 23.0, 67.0, 17.0, 3.0, 33.0, 52.0, 5.0, 0.0, 2.0, 2.0, 44.0, 8.0, 30.0, 0.0, 4.0, 0.0, 61.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6960633152240991, "mean_inference_ms": 1.595076161552468, "mean_action_processing_ms": 0.27516092388122987, "mean_env_wait_ms": 0.20924999548773626, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0036525726318359375, "StateBufferConnector_ms": 0.0037440061569213867, "ViewRequirementAgentConnector_ms": 0.13515961170196533}, "num_episodes": 18, "episode_return_max": 141.69999999999882, "episode_return_min": -256.20000000000016, "episode_return_mean": -16.316000000000034, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 272000, "num_agent_steps_trained": 272000, "num_env_steps_sampled": 68000, "num_env_steps_trained": 68000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 79.07370045316655, "num_env_steps_trained_throughput_per_sec": 79.07370045316655, "timesteps_total": 68000, "num_env_steps_sampled_lifetime": 68000, "num_agent_steps_sampled_lifetime": 272000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 272000, "timers": {"training_iteration_time_ms": 50965.887, "restore_workers_time_ms": 0.014, "training_step_time_ms": 50965.846, "sample_time_ms": 1263.082, "learn_time_ms": 49689.233, "learn_throughput": 80.5, "synch_weights_time_ms": 10.759}, "counters": {"num_env_steps_sampled": 68000, "num_env_steps_trained": 68000, "num_agent_steps_sampled": 272000, "num_agent_steps_trained": 272000}, "done": false, "training_iteration": 17, "trial_id": "11e70_00000", "date": "2024-08-12_23-21-42", "timestamp": 1723519302, "time_this_iter_s": 50.631877183914185, "time_total_s": 882.7111115455627, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2b15670>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 882.7111115455627, "iterations_since_restore": 17, "perf": {"cpu_util_percent": 35.34583333333333, "ram_util_percent": 82.85000000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.841540192170118, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.271326809206968, "policy_loss": -0.01257770596954124, "vf_loss": 2.2824233923008834, "vf_explained_var": 0.08182751895889404, "kl": 0.009874178566027177, "entropy": 1.4425862865473227, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 33075.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.340320845444997, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.345103060253083, "policy_loss": -0.010025153241598259, "vf_loss": 3.3536484582714303, "vf_explained_var": 0.0450013537570913, "kl": 0.009865034348209836, "entropy": 1.4339518030484517, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 33075.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 72000, "num_env_steps_trained": 72000, "num_agent_steps_sampled": 288000, "num_agent_steps_trained": 288000}, "env_runners": {"episode_reward_max": 141.69999999999882, "episode_reward_min": -342.70000000000016, "episode_reward_mean": 6.360000000000027, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -299.5, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 121.69999999999955, "predator_policy": 170.0}, "policy_reward_mean": {"prey_policy": -26.200000000000074, "predator_policy": 29.38}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-87.60000000000034, 45.700000000000436, -34.699999999999605, 45.50000000000009, 57.800000000000225, -65.6, -179.8000000000002, 10.899999999999938, 69.00000000000004, 23.000000000000057, 36.700000000000294, 79.89999999999911, -48.49999999999976, -31.19999999999964, -86.80000000000064, -115.20000000000005, 29.000000000000256, 66.40000000000019, -25.29999999999979, 40.0000000000003, -23.499999999999872, -10.29999999999997, 27.500000000000124, -42.10000000000003, 2.4999999999999396, -19.999999999999673, 37.80000000000026, -4.4999999999997655, 26.6000000000002, 41.40000000000047, -57.40000000000096, -30.499999999999652, 27.60000000000009, 141.69999999999882, -125.2000000000009, 33.20000000000023, 76.49999999999872, -28.899999999999622, 9.099999999999973, -8.299999999999716, -15.499999999999556, 26.700000000000102, 9.00000000000005, 39.10000000000041, 68.60000000000014, -105.20000000000104, 43.80000000000043, -6.299999999999816, -22.599999999999554, -2.8999999999998227, -97.00000000000117, 58.000000000000355, 40.0000000000003, 10.299999999999955, 62.10000000000045, 40.0000000000003, -111.10000000000146, 23.100000000000126, -7.399999999999904, 40.0000000000003, 14.099999999999953, -2.299999999999865, 57.50000000000047, 22.400000000000013, 22.50000000000007, 40.0000000000003, 4.89999999999994, 40.0000000000003, 40.0000000000003, 33.90000000000021, 24.100000000000172, 2.200000000000201, -68.0000000000017, 37.800000000000296, 24.500000000000103, 4.500000000000108, 36.50000000000025, -16.299999999999677, 15.699999999999948, -28.399999999999594, 116.49999999999879, 40.900000000000475, -5.999999999999815, 68.59999999999962, -10.499999999999652, -342.70000000000016, 71.1000000000002, 59.200000000000436, 52.900000000000134, 35.80000000000039, 8.00000000000006, 92.1999999999994, -27.699999999999655, 32.40000000000018, 40.90000000000031, -86.20000000000098, 5.000000000000092, 51.70000000000049, 40.0000000000003, 93.19999999999995], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-192.1000000000002, -83.50000000000024, -27.400000000000034, 43.10000000000024, 20.000000000000014, -153.70000000000059, -16.59999999999996, -16.899999999999956, 20.000000000000014, 0.7999999999999616, -299.5, 17.899999999999988, -237.10000000000016, -129.70000000000002, -66.10000000000078, 20.000000000000014, 43.700000000000195, -30.699999999999896, -27.999999999999787, 20.000000000000014, 20.000000000000014, 13.699999999999946, 20.000000000000014, 56.9000000000002, -101.80000000000078, -132.70000000000013, -85.00000000000055, -65.20000000000078, -51.99999999999989, -140.80000000000024, -112.60000000000005, -148.60000000000002, 62.30000000000022, -115.3000000000001, -45.699999999999804, 73.09999999999955, 20.000000000000014, -175.30000000000013, 20.000000000000014, 20.000000000000014, -54.399999999999885, -75.10000000000005, 15.79999999999995, -132.10000000000008, -17.499999999999822, -48.999999999999844, -41.79999999999979, -73.30000000000078, -77.50000000000047, 20.000000000000014, 1.0999999999999865, -93.10000000000058, 15.799999999999958, 20.000000000000014, 20.000000000000014, -107.50000000000075, -9.699999999999903, 5.299999999999976, 16.699999999999996, -7.300000000000004, -56.50000000000015, -64.90000000000052, -23.79999999999979, -99.70000000000051, -24.699999999999797, -15.700000000000038, 121.69999999999955, 20.000000000000014, -148.60000000000048, -106.60000000000039, -7.299999999999976, 24.500000000000085, 24.50000000000009, 7.999999999999725, -92.80000000000067, -21.09999999999978, -77.80000000000021, -57.10000000000036, -109.30000000000078, 20.000000000000014, -89.50000000000082, 20.000000000000014, 20.000000000000014, -19.299999999999763, -79.00000000000085, 20.000000000000014, 21.50000000000004, -66.40000000000067, 20.000000000000014, 38.60000000000021, 20.000000000000014, -257.1999999999996, -5.1999999999999975, 20.000000000000014, -26.199999999999825, -45.09999999999976, -56.80000000000041, -17.799999999999784, -35.1999999999998, -12.699999999999864, -155.8000000000006, -50.19999999999986, -27.699999999999783, -4.300000000000033, 20.000000000000014, 20.000000000000014, 15.799999999999946, -65.50000000000087, 20.000000000000014, 16.09999999999996, 20.000000000000014, 20.000000000000014, -53.80000000000018, -196.30000000000055, 20.000000000000014, -31.8999999999998, -42.99999999999985, -66.40000000000035, 20.000000000000014, 20.000000000000014, -31.899999999999757, 20.000000000000014, -5.49999999999994, -59.800000000000395, 20.000000000000014, 3.499999999999978, 20.000000000000014, -13.599999999999783, 17.29999999999997, -14.799999999999779, 20.000000000000014, 20.000000000000014, 18.19999999999997, -49.299999999999876, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -24.09999999999976, 20.000000000000014, -97.59999999999997, 37.70000000000018, -49.299999999999905, 15.499999999999964, -46.29999999999978, -78.70000000000081, 15.799999999999946, 20.000000000000014, 20.000000000000014, -41.49999999999984, 15.799999999999963, -49.29999999999977, 11.599999999999964, 20.900000000000027, -97.3000000000006, 20.000000000000014, -8.199999999999902, -3.099999999999958, -42.999999999999766, -66.4000000000006, 20.000000000000014, 96.49999999999949, 1.0999999999999723, 24.800000000000093, 20.000000000000014, -88.00000000000065, -21.399999999999935, 29.000000000000163, -32.199999999999775, -37.299999999999784, -297.10000000000025, -277.60000000000014, 14.599999999999962, 18.500000000000156, 39.8000000000002, 7.399999999999984, 8.599999999999984, -30.700000000000244, -5.200000000000047, 29.00000000000015, -64.00000000000085, 20.000000000000014, 72.19999999999987, 20.000000000000014, -168.10000000000062, 40.40000000000019, 15.799999999999963, 11.599999999999964, 20.000000000000014, 20.90000000000003, -47.199999999999775, -157.0000000000004, 20.000000000000014, -55.00000000000021, 31.700000000000212, 20.000000000000014, 20.000000000000014, 20.000000000000014, -26.199999999999754, 97.39999999999966], "policy_predator_policy_reward": [48.0, 140.0, 30.0, 0.0, 18.0, 81.0, 0.0, 79.0, 16.0, 21.0, 97.0, 119.0, 148.0, 39.0, 27.0, 30.0, 39.0, 17.0, 0.0, 31.0, 0.0, 3.0, 3.0, 0.0, 105.0, 81.0, 43.0, 76.0, 0.0, 106.0, 79.0, 67.0, 82.0, 0.0, 39.0, 0.0, 32.0, 98.0, 0.0, 0.0, 106.0, 0.0, 51.0, 55.0, 52.0, 42.0, 43.0, 30.0, 32.0, 28.0, 32.0, 40.0, 2.0, 0.0, 26.0, 57.0, 0.0, 31.0, 24.0, 8.0, 0.0, 64.0, 77.0, 16.0, 52.0, 16.0, 0.0, 0.0, 104.0, 26.0, 13.0, 3.0, 37.0, 7.0, 72.0, 13.0, 61.0, 83.0, 44.0, 37.0, 42.0, 12.0, 23.0, 3.0, 48.0, 20.0, 47.0, 37.0, 9.0, 1.0, 0.0, 132.0, 24.0, 5.0, 61.0, 4.0, 47.0, 5.0, 26.0, 19.0, 75.0, 34.0, 37.0, 53.0, 0.0, 0.0, 33.0, 27.0, 16.0, 10.0, 0.0, 0.0, 103.0, 36.0, 0.0, 35.0, 76.0, 26.0, 0.0, 0.0, 21.0, 5.0, 55.0, 8.0, 18.0, 16.0, 0.0, 16.0, 20.0, 0.0, 0.0, 0.0, 0.0, 36.0, 0.0, 0.0, 0.0, 0.0, 15.0, 23.0, 67.0, 17.0, 3.0, 33.0, 52.0, 5.0, 0.0, 2.0, 2.0, 44.0, 8.0, 30.0, 0.0, 4.0, 0.0, 61.0, 16.0, 11.0, 50.0, 31.0, 0.0, 0.0, 6.0, 9.0, 17.0, 45.0, 53.0, 8.0, 35.0, 24.0, 170.0, 62.0, 12.0, 26.0, 3.0, 9.0, 61.0, 14.0, 0.0, 12.0, 40.0, 12.0, 0.0, 0.0, 69.0, 31.0, 0.0, 5.0, 0.0, 0.0, 32.0, 86.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6943277773696505, "mean_inference_ms": 1.5914336887856768, "mean_action_processing_ms": 0.2748112160358861, "mean_env_wait_ms": 0.2079850809133611, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003511786460876465, "StateBufferConnector_ms": 0.0036133527755737305, "ViewRequirementAgentConnector_ms": 0.11410403251647949}, "num_episodes": 22, "episode_return_max": 141.69999999999882, "episode_return_min": -342.70000000000016, "episode_return_mean": 6.360000000000027, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 288000, "num_agent_steps_trained": 288000, "num_env_steps_sampled": 72000, "num_env_steps_trained": 72000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 79.3576488528611, "num_env_steps_trained_throughput_per_sec": 79.3576488528611, "timesteps_total": 72000, "num_env_steps_sampled_lifetime": 72000, "num_agent_steps_sampled_lifetime": 288000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 288000, "timers": {"training_iteration_time_ms": 50926.701, "restore_workers_time_ms": 0.014, "training_step_time_ms": 50926.661, "sample_time_ms": 1276.005, "learn_time_ms": 49636.908, "learn_throughput": 80.585, "synch_weights_time_ms": 10.69}, "counters": {"num_env_steps_sampled": 72000, "num_env_steps_trained": 72000, "num_agent_steps_sampled": 288000, "num_agent_steps_trained": 288000}, "done": false, "training_iteration": 18, "trial_id": "11e70_00000", "date": "2024-08-12_23-22-32", "timestamp": 1723519352, "time_this_iter_s": 50.450599908828735, "time_total_s": 933.1617114543915, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2b8c9d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 933.1617114543915, "iterations_since_restore": 18, "perf": {"cpu_util_percent": 35.05416666666667, "ram_util_percent": 83.12916666666666}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.775407625506164, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.195373610150877, "policy_loss": -0.010210065825142597, "vf_loss": 2.2038116394527374, "vf_explained_var": 0.05672815924599057, "kl": 0.011813544531219484, "entropy": 1.4086817988012204, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 34965.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.86550040746492, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.581427437855453, "policy_loss": -0.010254614213949671, "vf_loss": 3.590051469979463, "vf_explained_var": 0.07842468546811866, "kl": 0.01087049933930851, "entropy": 1.4021893061027324, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 34965.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 76000, "num_env_steps_trained": 76000, "num_agent_steps_sampled": 304000, "num_agent_steps_trained": 304000}, "env_runners": {"episode_reward_max": 141.69999999999882, "episode_reward_min": -342.70000000000016, "episode_reward_mean": 17.15499999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -297.10000000000025, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 147.79999999999998, "predator_policy": 170.0}, "policy_reward_mean": {"prey_policy": -14.45250000000006, "predator_policy": 23.03}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-42.10000000000003, 2.4999999999999396, -19.999999999999673, 37.80000000000026, -4.4999999999997655, 26.6000000000002, 41.40000000000047, -57.40000000000096, -30.499999999999652, 27.60000000000009, 141.69999999999882, -125.2000000000009, 33.20000000000023, 76.49999999999872, -28.899999999999622, 9.099999999999973, -8.299999999999716, -15.499999999999556, 26.700000000000102, 9.00000000000005, 39.10000000000041, 68.60000000000014, -105.20000000000104, 43.80000000000043, -6.299999999999816, -22.599999999999554, -2.8999999999998227, -97.00000000000117, 58.000000000000355, 40.0000000000003, 10.299999999999955, 62.10000000000045, 40.0000000000003, -111.10000000000146, 23.100000000000126, -7.399999999999904, 40.0000000000003, 14.099999999999953, -2.299999999999865, 57.50000000000047, 22.400000000000013, 22.50000000000007, 40.0000000000003, 4.89999999999994, 40.0000000000003, 40.0000000000003, 33.90000000000021, 24.100000000000172, 2.200000000000201, -68.0000000000017, 37.800000000000296, 24.500000000000103, 4.500000000000108, 36.50000000000025, -16.299999999999677, 15.699999999999948, -28.399999999999594, 116.49999999999879, 40.900000000000475, -5.999999999999815, 68.59999999999962, -10.499999999999652, -342.70000000000016, 71.1000000000002, 59.200000000000436, 52.900000000000134, 35.80000000000039, 8.00000000000006, 92.1999999999994, -27.699999999999655, 32.40000000000018, 40.90000000000031, -86.20000000000098, 5.000000000000092, 51.70000000000049, 40.0000000000003, 93.19999999999995, -57.60000000000123, 96.59999999999937, 89.89999999999893, -68.80000000000118, 76.9999999999997, 67.20000000000014, 107.69999999999982, -41.79999999999961, 54.30000000000043, 55.300000000000516, 93.69999999999968, 35.90000000000024, 40.0000000000003, 45.10000000000024, 29.10000000000013, 84.99999999999993, -191.9000000000008, 40.0000000000003, 130.29999999999959, 36.70000000000028, 74.3999999999998, 30.100000000000154, 74.19999999999968], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-41.79999999999979, -73.30000000000078, -77.50000000000047, 20.000000000000014, 1.0999999999999865, -93.10000000000058, 15.799999999999958, 20.000000000000014, 20.000000000000014, -107.50000000000075, -9.699999999999903, 5.299999999999976, 16.699999999999996, -7.300000000000004, -56.50000000000015, -64.90000000000052, -23.79999999999979, -99.70000000000051, -24.699999999999797, -15.700000000000038, 121.69999999999955, 20.000000000000014, -148.60000000000048, -106.60000000000039, -7.299999999999976, 24.500000000000085, 24.50000000000009, 7.999999999999725, -92.80000000000067, -21.09999999999978, -77.80000000000021, -57.10000000000036, -109.30000000000078, 20.000000000000014, -89.50000000000082, 20.000000000000014, 20.000000000000014, -19.299999999999763, -79.00000000000085, 20.000000000000014, 21.50000000000004, -66.40000000000067, 20.000000000000014, 38.60000000000021, 20.000000000000014, -257.1999999999996, -5.1999999999999975, 20.000000000000014, -26.199999999999825, -45.09999999999976, -56.80000000000041, -17.799999999999784, -35.1999999999998, -12.699999999999864, -155.8000000000006, -50.19999999999986, -27.699999999999783, -4.300000000000033, 20.000000000000014, 20.000000000000014, 15.799999999999946, -65.50000000000087, 20.000000000000014, 16.09999999999996, 20.000000000000014, 20.000000000000014, -53.80000000000018, -196.30000000000055, 20.000000000000014, -31.8999999999998, -42.99999999999985, -66.40000000000035, 20.000000000000014, 20.000000000000014, -31.899999999999757, 20.000000000000014, -5.49999999999994, -59.800000000000395, 20.000000000000014, 3.499999999999978, 20.000000000000014, -13.599999999999783, 17.29999999999997, -14.799999999999779, 20.000000000000014, 20.000000000000014, 18.19999999999997, -49.299999999999876, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -24.09999999999976, 20.000000000000014, -97.59999999999997, 37.70000000000018, -49.299999999999905, 15.499999999999964, -46.29999999999978, -78.70000000000081, 15.799999999999946, 20.000000000000014, 20.000000000000014, -41.49999999999984, 15.799999999999963, -49.29999999999977, 11.599999999999964, 20.900000000000027, -97.3000000000006, 20.000000000000014, -8.199999999999902, -3.099999999999958, -42.999999999999766, -66.4000000000006, 20.000000000000014, 96.49999999999949, 1.0999999999999723, 24.800000000000093, 20.000000000000014, -88.00000000000065, -21.399999999999935, 29.000000000000163, -32.199999999999775, -37.299999999999784, -297.10000000000025, -277.60000000000014, 14.599999999999962, 18.500000000000156, 39.8000000000002, 7.399999999999984, 8.599999999999984, -30.700000000000244, -5.200000000000047, 29.00000000000015, -64.00000000000085, 20.000000000000014, 72.19999999999987, 20.000000000000014, -168.10000000000062, 40.40000000000019, 15.799999999999963, 11.599999999999964, 20.000000000000014, 20.90000000000003, -47.199999999999775, -157.0000000000004, 20.000000000000014, -55.00000000000021, 31.700000000000212, 20.000000000000014, 20.000000000000014, 20.000000000000014, -26.199999999999754, 97.39999999999966, -91.60000000000082, -21.999999999999773, 53.30000000000005, -3.699999999999994, 53.900000000000134, 20.000000000000014, 15.799999999999963, -181.6000000000006, 20.000000000000014, 35.00000000000013, 50.600000000000236, -18.39999999999982, 70.69999999999995, 20.000000000000014, -158.50000000000063, 31.700000000000212, 9.499999999999964, 39.80000000000022, 20.000000000000014, 35.30000000000025, -15.699999999999967, 10.4, 20.000000000000014, 2.8999999999999613, 20.000000000000014, 20.000000000000014, 3.5000000000000426, -18.39999999999975, 3.4999999999999654, 11.599999999999964, 31.700000000000212, 53.300000000000054, -181.3000000000004, -155.60000000000045, 20.000000000000014, 20.000000000000014, -56.500000000000334, 147.79999999999998, 20.000000000000014, 13.699999999999955, 20.000000000000014, 28.40000000000004, 20.000000000000014, 1.09999999999996, 35.000000000000256, -2.799999999999926], "policy_predator_policy_reward": [43.0, 30.0, 32.0, 28.0, 32.0, 40.0, 2.0, 0.0, 26.0, 57.0, 0.0, 31.0, 24.0, 8.0, 0.0, 64.0, 77.0, 16.0, 52.0, 16.0, 0.0, 0.0, 104.0, 26.0, 13.0, 3.0, 37.0, 7.0, 72.0, 13.0, 61.0, 83.0, 44.0, 37.0, 42.0, 12.0, 23.0, 3.0, 48.0, 20.0, 47.0, 37.0, 9.0, 1.0, 0.0, 132.0, 24.0, 5.0, 61.0, 4.0, 47.0, 5.0, 26.0, 19.0, 75.0, 34.0, 37.0, 53.0, 0.0, 0.0, 33.0, 27.0, 16.0, 10.0, 0.0, 0.0, 103.0, 36.0, 0.0, 35.0, 76.0, 26.0, 0.0, 0.0, 21.0, 5.0, 55.0, 8.0, 18.0, 16.0, 0.0, 16.0, 20.0, 0.0, 0.0, 0.0, 0.0, 36.0, 0.0, 0.0, 0.0, 0.0, 15.0, 23.0, 67.0, 17.0, 3.0, 33.0, 52.0, 5.0, 0.0, 2.0, 2.0, 44.0, 8.0, 30.0, 0.0, 4.0, 0.0, 61.0, 16.0, 11.0, 50.0, 31.0, 0.0, 0.0, 6.0, 9.0, 17.0, 45.0, 53.0, 8.0, 35.0, 24.0, 170.0, 62.0, 12.0, 26.0, 3.0, 9.0, 61.0, 14.0, 0.0, 12.0, 40.0, 12.0, 0.0, 0.0, 69.0, 31.0, 0.0, 5.0, 0.0, 0.0, 32.0, 86.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 56.0, 0.0, 14.0, 33.0, 16.0, 0.0, 96.0, 1.0, 22.0, 0.0, 0.0, 35.0, 0.0, 17.0, 0.0, 85.0, 5.0, 0.0, 0.0, 0.0, 99.0, 0.0, 9.0, 4.0, 0.0, 0.0, 41.0, 19.0, 10.0, 4.0, 0.0, 0.0, 145.0, 0.0, 0.0, 0.0, 0.0, 39.0, 2.0, 1.0, 0.0, 26.0, 0.0, 9.0, 30.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6953781063430132, "mean_inference_ms": 1.5925542211915356, "mean_action_processing_ms": 0.274189677301241, "mean_env_wait_ms": 0.207333844591791, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005982160568237305, "StateBufferConnector_ms": 0.004567623138427734, "ViewRequirementAgentConnector_ms": 0.13677167892456055}, "num_episodes": 23, "episode_return_max": 141.69999999999882, "episode_return_min": -342.70000000000016, "episode_return_mean": 17.15499999999998, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 304000, "num_agent_steps_trained": 304000, "num_env_steps_sampled": 76000, "num_env_steps_trained": 76000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 78.25566218744088, "num_env_steps_trained_throughput_per_sec": 78.25566218744088, "timesteps_total": 76000, "num_env_steps_sampled_lifetime": 76000, "num_agent_steps_sampled_lifetime": 304000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 304000, "timers": {"training_iteration_time_ms": 50906.892, "restore_workers_time_ms": 0.014, "training_step_time_ms": 50906.853, "sample_time_ms": 1303.065, "learn_time_ms": 49590.03, "learn_throughput": 80.661, "synch_weights_time_ms": 10.778}, "counters": {"num_env_steps_sampled": 76000, "num_env_steps_trained": 76000, "num_agent_steps_sampled": 304000, "num_agent_steps_trained": 304000}, "done": false, "training_iteration": 19, "trial_id": "11e70_00000", "date": "2024-08-12_23-23-23", "timestamp": 1723519403, "time_this_iter_s": 51.15020179748535, "time_total_s": 984.3119132518768, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2af5af0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 984.3119132518768, "iterations_since_restore": 19, "perf": {"cpu_util_percent": 36.35479452054795, "ram_util_percent": 83.0986301369863}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.7549567248455435, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.329413412424622, "policy_loss": -0.007233587460020784, "vf_loss": 2.3356431297524267, "vf_explained_var": 0.037934766370783406, "kl": 0.006692494870429948, "entropy": 1.4210172819082068, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 36855.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.478038538133026, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.501053861840061, "policy_loss": -0.009731773634209599, "vf_loss": 4.509285443800467, "vf_explained_var": 0.11553027768614431, "kl": 0.010001286037257445, "entropy": 1.3815581152678797, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 36855.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 80000, "num_env_steps_trained": 80000, "num_agent_steps_sampled": 320000, "num_agent_steps_trained": 320000}, "env_runners": {"episode_reward_max": 142.9999999999999, "episode_reward_min": -342.70000000000016, "episode_reward_mean": 28.345999999999975, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -305.5, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 147.79999999999998, "predator_policy": 170.0}, "policy_reward_mean": {"prey_policy": -7.3020000000000325, "predator_policy": 21.475}, "custom_metrics": {}, "hist_stats": {"episode_reward": [26.700000000000102, 9.00000000000005, 39.10000000000041, 68.60000000000014, -105.20000000000104, 43.80000000000043, -6.299999999999816, -22.599999999999554, -2.8999999999998227, -97.00000000000117, 58.000000000000355, 40.0000000000003, 10.299999999999955, 62.10000000000045, 40.0000000000003, -111.10000000000146, 23.100000000000126, -7.399999999999904, 40.0000000000003, 14.099999999999953, -2.299999999999865, 57.50000000000047, 22.400000000000013, 22.50000000000007, 40.0000000000003, 4.89999999999994, 40.0000000000003, 40.0000000000003, 33.90000000000021, 24.100000000000172, 2.200000000000201, -68.0000000000017, 37.800000000000296, 24.500000000000103, 4.500000000000108, 36.50000000000025, -16.299999999999677, 15.699999999999948, -28.399999999999594, 116.49999999999879, 40.900000000000475, -5.999999999999815, 68.59999999999962, -10.499999999999652, -342.70000000000016, 71.1000000000002, 59.200000000000436, 52.900000000000134, 35.80000000000039, 8.00000000000006, 92.1999999999994, -27.699999999999655, 32.40000000000018, 40.90000000000031, -86.20000000000098, 5.000000000000092, 51.70000000000049, 40.0000000000003, 93.19999999999995, -57.60000000000123, 96.59999999999937, 89.89999999999893, -68.80000000000118, 76.9999999999997, 67.20000000000014, 107.69999999999982, -41.79999999999961, 54.30000000000043, 55.300000000000516, 93.69999999999968, 35.90000000000024, 40.0000000000003, 45.10000000000024, 29.10000000000013, 84.99999999999993, -191.9000000000008, 40.0000000000003, 130.29999999999959, 36.70000000000028, 74.3999999999998, 30.100000000000154, 74.19999999999968, 19.999999999999975, -11.99999999999993, 19.10000000000027, 110.29999999999973, -8.399999999999666, -40.19999999999988, 40.0000000000003, 42.300000000000345, 108.5999999999994, 22.600000000000012, 142.9999999999999, 81.49999999999967, 125.49999999999928, 134.29999999999987, 135.0999999999996, 141.69999999999922, 79.70000000000002, 40.0000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, -19.299999999999763, -79.00000000000085, 20.000000000000014, 21.50000000000004, -66.40000000000067, 20.000000000000014, 38.60000000000021, 20.000000000000014, -257.1999999999996, -5.1999999999999975, 20.000000000000014, -26.199999999999825, -45.09999999999976, -56.80000000000041, -17.799999999999784, -35.1999999999998, -12.699999999999864, -155.8000000000006, -50.19999999999986, -27.699999999999783, -4.300000000000033, 20.000000000000014, 20.000000000000014, 15.799999999999946, -65.50000000000087, 20.000000000000014, 16.09999999999996, 20.000000000000014, 20.000000000000014, -53.80000000000018, -196.30000000000055, 20.000000000000014, -31.8999999999998, -42.99999999999985, -66.40000000000035, 20.000000000000014, 20.000000000000014, -31.899999999999757, 20.000000000000014, -5.49999999999994, -59.800000000000395, 20.000000000000014, 3.499999999999978, 20.000000000000014, -13.599999999999783, 17.29999999999997, -14.799999999999779, 20.000000000000014, 20.000000000000014, 18.19999999999997, -49.299999999999876, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -24.09999999999976, 20.000000000000014, -97.59999999999997, 37.70000000000018, -49.299999999999905, 15.499999999999964, -46.29999999999978, -78.70000000000081, 15.799999999999946, 20.000000000000014, 20.000000000000014, -41.49999999999984, 15.799999999999963, -49.29999999999977, 11.599999999999964, 20.900000000000027, -97.3000000000006, 20.000000000000014, -8.199999999999902, -3.099999999999958, -42.999999999999766, -66.4000000000006, 20.000000000000014, 96.49999999999949, 1.0999999999999723, 24.800000000000093, 20.000000000000014, -88.00000000000065, -21.399999999999935, 29.000000000000163, -32.199999999999775, -37.299999999999784, -297.10000000000025, -277.60000000000014, 14.599999999999962, 18.500000000000156, 39.8000000000002, 7.399999999999984, 8.599999999999984, -30.700000000000244, -5.200000000000047, 29.00000000000015, -64.00000000000085, 20.000000000000014, 72.19999999999987, 20.000000000000014, -168.10000000000062, 40.40000000000019, 15.799999999999963, 11.599999999999964, 20.000000000000014, 20.90000000000003, -47.199999999999775, -157.0000000000004, 20.000000000000014, -55.00000000000021, 31.700000000000212, 20.000000000000014, 20.000000000000014, 20.000000000000014, -26.199999999999754, 97.39999999999966, -91.60000000000082, -21.999999999999773, 53.30000000000005, -3.699999999999994, 53.900000000000134, 20.000000000000014, 15.799999999999963, -181.6000000000006, 20.000000000000014, 35.00000000000013, 50.600000000000236, -18.39999999999982, 70.69999999999995, 20.000000000000014, -158.50000000000063, 31.700000000000212, 9.499999999999964, 39.80000000000022, 20.000000000000014, 35.30000000000025, -15.699999999999967, 10.4, 20.000000000000014, 2.8999999999999613, 20.000000000000014, 20.000000000000014, 3.5000000000000426, -18.39999999999975, 3.4999999999999654, 11.599999999999964, 31.700000000000212, 53.300000000000054, -181.3000000000004, -155.60000000000045, 20.000000000000014, 20.000000000000014, -56.500000000000334, 147.79999999999998, 20.000000000000014, 13.699999999999955, 20.000000000000014, 28.40000000000004, 20.000000000000014, 1.09999999999996, 35.000000000000256, -2.799999999999926, 20.000000000000014, -18.999999999999744, 63.50000000000009, -200.50000000000026, -19.900000000000016, 20.000000000000014, -146.50000000000048, 111.79999999999998, 20.000000000000014, -72.40000000000087, -305.5, 107.29999999999964, 20.000000000000014, 20.000000000000014, 33.50000000000024, -11.199999999999848, 20.000000000000014, 56.59999999999998, -5.199999999999934, 15.799999999999963, 53.59999999999999, 28.40000000000004, 57.500000000000185, 20.000000000000014, 20.000000000000014, 105.49999999999977, 28.400000000000134, 20.900000000000006, 115.69999999999996, 4.399999999999968, 41.60000000000016, 82.0999999999997, 20.000000000000014, -4.300000000000052, 20.000000000000014, 20.000000000000014], "policy_predator_policy_reward": [23.0, 3.0, 48.0, 20.0, 47.0, 37.0, 9.0, 1.0, 0.0, 132.0, 24.0, 5.0, 61.0, 4.0, 47.0, 5.0, 26.0, 19.0, 75.0, 34.0, 37.0, 53.0, 0.0, 0.0, 33.0, 27.0, 16.0, 10.0, 0.0, 0.0, 103.0, 36.0, 0.0, 35.0, 76.0, 26.0, 0.0, 0.0, 21.0, 5.0, 55.0, 8.0, 18.0, 16.0, 0.0, 16.0, 20.0, 0.0, 0.0, 0.0, 0.0, 36.0, 0.0, 0.0, 0.0, 0.0, 15.0, 23.0, 67.0, 17.0, 3.0, 33.0, 52.0, 5.0, 0.0, 2.0, 2.0, 44.0, 8.0, 30.0, 0.0, 4.0, 0.0, 61.0, 16.0, 11.0, 50.0, 31.0, 0.0, 0.0, 6.0, 9.0, 17.0, 45.0, 53.0, 8.0, 35.0, 24.0, 170.0, 62.0, 12.0, 26.0, 3.0, 9.0, 61.0, 14.0, 0.0, 12.0, 40.0, 12.0, 0.0, 0.0, 69.0, 31.0, 0.0, 5.0, 0.0, 0.0, 32.0, 86.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 56.0, 0.0, 14.0, 33.0, 16.0, 0.0, 96.0, 1.0, 22.0, 0.0, 0.0, 35.0, 0.0, 17.0, 0.0, 85.0, 5.0, 0.0, 0.0, 0.0, 99.0, 0.0, 9.0, 4.0, 0.0, 0.0, 41.0, 19.0, 10.0, 4.0, 0.0, 0.0, 145.0, 0.0, 0.0, 0.0, 0.0, 39.0, 2.0, 1.0, 0.0, 26.0, 0.0, 9.0, 30.0, 12.0, 0.0, 19.0, 20.0, 105.0, 0.0, 19.0, 70.0, 75.0, 44.0, 0.0, 3.0, 155.0, 0.0, 0.0, 0.0, 20.0, 1.0, 31.0, 12.0, 0.0, 61.0, 0.0, 4.0, 0.0, 0.0, 0.0, 33.0, 52.0, 14.0, 1.0, 18.0, 0.0, 25.0, 39.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.695380916297137, "mean_inference_ms": 1.5941804842563934, "mean_action_processing_ms": 0.27418113796080035, "mean_env_wait_ms": 0.20680920154396618, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006013035774230957, "StateBufferConnector_ms": 0.0046051740646362305, "ViewRequirementAgentConnector_ms": 0.13587462902069092}, "num_episodes": 18, "episode_return_max": 142.9999999999999, "episode_return_min": -342.70000000000016, "episode_return_mean": 28.345999999999975, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 320000, "num_agent_steps_trained": 320000, "num_env_steps_sampled": 80000, "num_env_steps_trained": 80000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 78.9466342257915, "num_env_steps_trained_throughput_per_sec": 78.9466342257915, "timesteps_total": 80000, "num_env_steps_sampled_lifetime": 80000, "num_agent_steps_sampled_lifetime": 320000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 320000, "timers": {"training_iteration_time_ms": 50902.84, "restore_workers_time_ms": 0.013, "training_step_time_ms": 50902.801, "sample_time_ms": 1303.58, "learn_time_ms": 49585.117, "learn_throughput": 80.669, "synch_weights_time_ms": 10.677}, "counters": {"num_env_steps_sampled": 80000, "num_env_steps_trained": 80000, "num_agent_steps_sampled": 320000, "num_agent_steps_trained": 320000}, "done": false, "training_iteration": 20, "trial_id": "11e70_00000", "date": "2024-08-12_23-24-14", "timestamp": 1723519454, "time_this_iter_s": 50.713751792907715, "time_total_s": 1035.0256650447845, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2b67ee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1035.0256650447845, "iterations_since_restore": 20, "perf": {"cpu_util_percent": 35.772222222222226, "ram_util_percent": 82.58749999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 6.477867591633368, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.794525553372802, "policy_loss": -0.007804410811513662, "vf_loss": 2.8010972168710495, "vf_explained_var": 0.02363857702603416, "kl": 0.00821826177302363, "entropy": 1.4164694453673388, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 38745.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 6.094443306910298, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.964857101945019, "policy_loss": -0.007175369342670791, "vf_loss": 5.970867073220551, "vf_explained_var": 0.17004200986453466, "kl": 0.007769370486086084, "entropy": 1.4050208800684207, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 38745.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 84000, "num_env_steps_trained": 84000, "num_agent_steps_sampled": 336000, "num_agent_steps_trained": 336000}, "env_runners": {"episode_reward_max": 250.59999999999945, "episode_reward_min": -511.4999999999998, "episode_reward_mean": 36.39199999999996, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -502.8999999999998, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 156.79999999999984, "predator_policy": 394.0}, "policy_reward_mean": {"prey_policy": -3.714000000000027, "predator_policy": 21.91}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.0000000000003, 14.099999999999953, -2.299999999999865, 57.50000000000047, 22.400000000000013, 22.50000000000007, 40.0000000000003, 4.89999999999994, 40.0000000000003, 40.0000000000003, 33.90000000000021, 24.100000000000172, 2.200000000000201, -68.0000000000017, 37.800000000000296, 24.500000000000103, 4.500000000000108, 36.50000000000025, -16.299999999999677, 15.699999999999948, -28.399999999999594, 116.49999999999879, 40.900000000000475, -5.999999999999815, 68.59999999999962, -10.499999999999652, -342.70000000000016, 71.1000000000002, 59.200000000000436, 52.900000000000134, 35.80000000000039, 8.00000000000006, 92.1999999999994, -27.699999999999655, 32.40000000000018, 40.90000000000031, -86.20000000000098, 5.000000000000092, 51.70000000000049, 40.0000000000003, 93.19999999999995, -57.60000000000123, 96.59999999999937, 89.89999999999893, -68.80000000000118, 76.9999999999997, 67.20000000000014, 107.69999999999982, -41.79999999999961, 54.30000000000043, 55.300000000000516, 93.69999999999968, 35.90000000000024, 40.0000000000003, 45.10000000000024, 29.10000000000013, 84.99999999999993, -191.9000000000008, 40.0000000000003, 130.29999999999959, 36.70000000000028, 74.3999999999998, 30.100000000000154, 74.19999999999968, 19.999999999999975, -11.99999999999993, 19.10000000000027, 110.29999999999973, -8.399999999999666, -40.19999999999988, 40.0000000000003, 42.300000000000345, 108.5999999999994, 22.600000000000012, 142.9999999999999, 81.49999999999967, 125.49999999999928, 134.29999999999987, 135.0999999999996, 141.69999999999922, 79.70000000000002, 40.0000000000003, 29.30000000000009, 87.79999999999984, -511.4999999999998, 250.59999999999945, 166.5999999999992, 78.3000000000001, 22.400000000000016, 66.30000000000011, 118.29999999999885, 2.600000000000068, 40.0000000000003, 26.300000000000125, 105.59999999999984, 244.99999999999937, 36.70000000000028, 20.50000000000012, 37.60000000000026, 50.40000000000033], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 20.000000000000014, -31.899999999999757, 20.000000000000014, -5.49999999999994, -59.800000000000395, 20.000000000000014, 3.499999999999978, 20.000000000000014, -13.599999999999783, 17.29999999999997, -14.799999999999779, 20.000000000000014, 20.000000000000014, 18.19999999999997, -49.299999999999876, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -24.09999999999976, 20.000000000000014, -97.59999999999997, 37.70000000000018, -49.299999999999905, 15.499999999999964, -46.29999999999978, -78.70000000000081, 15.799999999999946, 20.000000000000014, 20.000000000000014, -41.49999999999984, 15.799999999999963, -49.29999999999977, 11.599999999999964, 20.900000000000027, -97.3000000000006, 20.000000000000014, -8.199999999999902, -3.099999999999958, -42.999999999999766, -66.4000000000006, 20.000000000000014, 96.49999999999949, 1.0999999999999723, 24.800000000000093, 20.000000000000014, -88.00000000000065, -21.399999999999935, 29.000000000000163, -32.199999999999775, -37.299999999999784, -297.10000000000025, -277.60000000000014, 14.599999999999962, 18.500000000000156, 39.8000000000002, 7.399999999999984, 8.599999999999984, -30.700000000000244, -5.200000000000047, 29.00000000000015, -64.00000000000085, 20.000000000000014, 72.19999999999987, 20.000000000000014, -168.10000000000062, 40.40000000000019, 15.799999999999963, 11.599999999999964, 20.000000000000014, 20.90000000000003, -47.199999999999775, -157.0000000000004, 20.000000000000014, -55.00000000000021, 31.700000000000212, 20.000000000000014, 20.000000000000014, 20.000000000000014, -26.199999999999754, 97.39999999999966, -91.60000000000082, -21.999999999999773, 53.30000000000005, -3.699999999999994, 53.900000000000134, 20.000000000000014, 15.799999999999963, -181.6000000000006, 20.000000000000014, 35.00000000000013, 50.600000000000236, -18.39999999999982, 70.69999999999995, 20.000000000000014, -158.50000000000063, 31.700000000000212, 9.499999999999964, 39.80000000000022, 20.000000000000014, 35.30000000000025, -15.699999999999967, 10.4, 20.000000000000014, 2.8999999999999613, 20.000000000000014, 20.000000000000014, 3.5000000000000426, -18.39999999999975, 3.4999999999999654, 11.599999999999964, 31.700000000000212, 53.300000000000054, -181.3000000000004, -155.60000000000045, 20.000000000000014, 20.000000000000014, -56.500000000000334, 147.79999999999998, 20.000000000000014, 13.699999999999955, 20.000000000000014, 28.40000000000004, 20.000000000000014, 1.09999999999996, 35.000000000000256, -2.799999999999926, 20.000000000000014, -18.999999999999744, 63.50000000000009, -200.50000000000026, -19.900000000000016, 20.000000000000014, -146.50000000000048, 111.79999999999998, 20.000000000000014, -72.40000000000087, -305.5, 107.29999999999964, 20.000000000000014, 20.000000000000014, 33.50000000000024, -11.199999999999848, 20.000000000000014, 56.59999999999998, -5.199999999999934, 15.799999999999963, 53.59999999999999, 28.40000000000004, 57.500000000000185, 20.000000000000014, 20.000000000000014, 105.49999999999977, 28.400000000000134, 20.900000000000006, 115.69999999999996, 4.399999999999968, 41.60000000000016, 82.0999999999997, 20.000000000000014, -4.300000000000052, 20.000000000000014, 20.000000000000014, 20.000000000000014, -66.70000000000005, 9.799999999999963, 20.000000000000014, -502.8999999999998, -402.6, 156.79999999999984, 93.79999999999981, 7.4, 117.19999999999959, 60.499999999999964, 15.800000000000011, 20.000000000000014, -13.599999999999794, 11.59999999999997, -7.300000000000006, 20.000000000000014, 98.29999999999949, 15.799999999999946, -47.1999999999998, 20.000000000000014, 20.000000000000014, 130.7, -240.40000000000006, 90.19999999999999, 10.39999999999998, 137.29999999999976, 85.69999999999997, 13.699999999999955, 20.000000000000014, -295.1, 125.60000000000005, 20.000000000000014, -54.4, 16.99999999999999, -13.59999999999979], "policy_predator_policy_reward": [0.0, 0.0, 21.0, 5.0, 55.0, 8.0, 18.0, 16.0, 0.0, 16.0, 20.0, 0.0, 0.0, 0.0, 0.0, 36.0, 0.0, 0.0, 0.0, 0.0, 15.0, 23.0, 67.0, 17.0, 3.0, 33.0, 52.0, 5.0, 0.0, 2.0, 2.0, 44.0, 8.0, 30.0, 0.0, 4.0, 0.0, 61.0, 16.0, 11.0, 50.0, 31.0, 0.0, 0.0, 6.0, 9.0, 17.0, 45.0, 53.0, 8.0, 35.0, 24.0, 170.0, 62.0, 12.0, 26.0, 3.0, 9.0, 61.0, 14.0, 0.0, 12.0, 40.0, 12.0, 0.0, 0.0, 69.0, 31.0, 0.0, 5.0, 0.0, 0.0, 32.0, 86.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 56.0, 0.0, 14.0, 33.0, 16.0, 0.0, 96.0, 1.0, 22.0, 0.0, 0.0, 35.0, 0.0, 17.0, 0.0, 85.0, 5.0, 0.0, 0.0, 0.0, 99.0, 0.0, 9.0, 4.0, 0.0, 0.0, 41.0, 19.0, 10.0, 4.0, 0.0, 0.0, 145.0, 0.0, 0.0, 0.0, 0.0, 39.0, 2.0, 1.0, 0.0, 26.0, 0.0, 9.0, 30.0, 12.0, 0.0, 19.0, 20.0, 105.0, 0.0, 19.0, 70.0, 75.0, 44.0, 0.0, 3.0, 155.0, 0.0, 0.0, 0.0, 20.0, 1.0, 31.0, 12.0, 0.0, 61.0, 0.0, 4.0, 0.0, 0.0, 0.0, 33.0, 52.0, 14.0, 1.0, 18.0, 0.0, 25.0, 39.0, 0.0, 0.0, 76.0, 0.0, 34.0, 24.0, 0.0, 394.0, 0.0, 0.0, 42.0, 0.0, 2.0, 0.0, 16.0, 0.0, 19.0, 43.0, 0.0, 0.0, 2.0, 32.0, 0.0, 0.0, 124.0, 12.0, 5.0, 0.0, 0.0, 22.0, 3.0, 0.0, 14.0, 176.0, 38.0, 34.0, 20.0, 27.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6939199539401423, "mean_inference_ms": 1.591524447871671, "mean_action_processing_ms": 0.2737114042837661, "mean_env_wait_ms": 0.2060220253506737, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01069653034210205, "StateBufferConnector_ms": 0.004587411880493164, "ViewRequirementAgentConnector_ms": 0.1269296407699585}, "num_episodes": 18, "episode_return_max": 250.59999999999945, "episode_return_min": -511.4999999999998, "episode_return_mean": 36.39199999999996, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 336000, "num_agent_steps_trained": 336000, "num_env_steps_sampled": 84000, "num_env_steps_trained": 84000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 78.91723355819744, "num_env_steps_trained_throughput_per_sec": 78.91723355819744, "timesteps_total": 84000, "num_env_steps_sampled_lifetime": 84000, "num_agent_steps_sampled_lifetime": 336000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 336000, "timers": {"training_iteration_time_ms": 50914.346, "restore_workers_time_ms": 0.013, "training_step_time_ms": 50914.306, "sample_time_ms": 1303.872, "learn_time_ms": 49596.512, "learn_throughput": 80.651, "synch_weights_time_ms": 10.656}, "counters": {"num_env_steps_sampled": 84000, "num_env_steps_trained": 84000, "num_agent_steps_sampled": 336000, "num_agent_steps_trained": 336000}, "done": false, "training_iteration": 21, "trial_id": "11e70_00000", "date": "2024-08-12_23-25-05", "timestamp": 1723519505, "time_this_iter_s": 50.71295118331909, "time_total_s": 1085.7386162281036, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2b67d30>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1085.7386162281036, "iterations_since_restore": 21, "perf": {"cpu_util_percent": 35.697183098591545, "ram_util_percent": 82.81830985915495}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 6.4178062565742975, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.984763783248013, "policy_loss": -0.008570096938422433, "vf_loss": 3.9917228017534527, "vf_explained_var": 0.03367902236010032, "kl": 0.010740500161768233, "entropy": 1.4184058069552063, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 40635.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.577418981973456, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.120386125170995, "policy_loss": -0.013662484767427914, "vf_loss": 7.131946744868364, "vf_explained_var": 0.10958307088998259, "kl": 0.014012448145382297, "entropy": 1.4097833588640525, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 40635.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 88000, "num_env_steps_trained": 88000, "num_agent_steps_sampled": 352000, "num_agent_steps_trained": 352000}, "env_runners": {"episode_reward_max": 284.30000000000007, "episode_reward_min": -511.4999999999998, "episode_reward_mean": 50.599999999999916, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -502.8999999999998, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 161.59999999999997, "predator_policy": 394.0}, "policy_reward_mean": {"prey_policy": 1.1549999999999625, "predator_policy": 24.145}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-16.299999999999677, 15.699999999999948, -28.399999999999594, 116.49999999999879, 40.900000000000475, -5.999999999999815, 68.59999999999962, -10.499999999999652, -342.70000000000016, 71.1000000000002, 59.200000000000436, 52.900000000000134, 35.80000000000039, 8.00000000000006, 92.1999999999994, -27.699999999999655, 32.40000000000018, 40.90000000000031, -86.20000000000098, 5.000000000000092, 51.70000000000049, 40.0000000000003, 93.19999999999995, -57.60000000000123, 96.59999999999937, 89.89999999999893, -68.80000000000118, 76.9999999999997, 67.20000000000014, 107.69999999999982, -41.79999999999961, 54.30000000000043, 55.300000000000516, 93.69999999999968, 35.90000000000024, 40.0000000000003, 45.10000000000024, 29.10000000000013, 84.99999999999993, -191.9000000000008, 40.0000000000003, 130.29999999999959, 36.70000000000028, 74.3999999999998, 30.100000000000154, 74.19999999999968, 19.999999999999975, -11.99999999999993, 19.10000000000027, 110.29999999999973, -8.399999999999666, -40.19999999999988, 40.0000000000003, 42.300000000000345, 108.5999999999994, 22.600000000000012, 142.9999999999999, 81.49999999999967, 125.49999999999928, 134.29999999999987, 135.0999999999996, 141.69999999999922, 79.70000000000002, 40.0000000000003, 29.30000000000009, 87.79999999999984, -511.4999999999998, 250.59999999999945, 166.5999999999992, 78.3000000000001, 22.400000000000016, 66.30000000000011, 118.29999999999885, 2.600000000000068, 40.0000000000003, 26.300000000000125, 105.59999999999984, 244.99999999999937, 36.70000000000028, 20.50000000000012, 37.60000000000026, 50.40000000000033, 133.69999999999936, 134.1999999999999, 220.99999999999991, 211.59999999999988, 35.60000000000022, 40.0000000000003, 216.19999999999916, 147.49999999999963, 19.799999999999187, -155.99999999999994, 133.69999999999962, 89.79999999999995, 227.39999999999972, 23.800000000000253, 231.89999999999964, -239.1000000000003, 40.0000000000003, 284.30000000000007], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-97.3000000000006, 20.000000000000014, -8.199999999999902, -3.099999999999958, -42.999999999999766, -66.4000000000006, 20.000000000000014, 96.49999999999949, 1.0999999999999723, 24.800000000000093, 20.000000000000014, -88.00000000000065, -21.399999999999935, 29.000000000000163, -32.199999999999775, -37.299999999999784, -297.10000000000025, -277.60000000000014, 14.599999999999962, 18.500000000000156, 39.8000000000002, 7.399999999999984, 8.599999999999984, -30.700000000000244, -5.200000000000047, 29.00000000000015, -64.00000000000085, 20.000000000000014, 72.19999999999987, 20.000000000000014, -168.10000000000062, 40.40000000000019, 15.799999999999963, 11.599999999999964, 20.000000000000014, 20.90000000000003, -47.199999999999775, -157.0000000000004, 20.000000000000014, -55.00000000000021, 31.700000000000212, 20.000000000000014, 20.000000000000014, 20.000000000000014, -26.199999999999754, 97.39999999999966, -91.60000000000082, -21.999999999999773, 53.30000000000005, -3.699999999999994, 53.900000000000134, 20.000000000000014, 15.799999999999963, -181.6000000000006, 20.000000000000014, 35.00000000000013, 50.600000000000236, -18.39999999999982, 70.69999999999995, 20.000000000000014, -158.50000000000063, 31.700000000000212, 9.499999999999964, 39.80000000000022, 20.000000000000014, 35.30000000000025, -15.699999999999967, 10.4, 20.000000000000014, 2.8999999999999613, 20.000000000000014, 20.000000000000014, 3.5000000000000426, -18.39999999999975, 3.4999999999999654, 11.599999999999964, 31.700000000000212, 53.300000000000054, -181.3000000000004, -155.60000000000045, 20.000000000000014, 20.000000000000014, -56.500000000000334, 147.79999999999998, 20.000000000000014, 13.699999999999955, 20.000000000000014, 28.40000000000004, 20.000000000000014, 1.09999999999996, 35.000000000000256, -2.799999999999926, 20.000000000000014, -18.999999999999744, 63.50000000000009, -200.50000000000026, -19.900000000000016, 20.000000000000014, -146.50000000000048, 111.79999999999998, 20.000000000000014, -72.40000000000087, -305.5, 107.29999999999964, 20.000000000000014, 20.000000000000014, 33.50000000000024, -11.199999999999848, 20.000000000000014, 56.59999999999998, -5.199999999999934, 15.799999999999963, 53.59999999999999, 28.40000000000004, 57.500000000000185, 20.000000000000014, 20.000000000000014, 105.49999999999977, 28.400000000000134, 20.900000000000006, 115.69999999999996, 4.399999999999968, 41.60000000000016, 82.0999999999997, 20.000000000000014, -4.300000000000052, 20.000000000000014, 20.000000000000014, 20.000000000000014, -66.70000000000005, 9.799999999999963, 20.000000000000014, -502.8999999999998, -402.6, 156.79999999999984, 93.79999999999981, 7.4, 117.19999999999959, 60.499999999999964, 15.800000000000011, 20.000000000000014, -13.599999999999794, 11.59999999999997, -7.300000000000006, 20.000000000000014, 98.29999999999949, 15.799999999999946, -47.1999999999998, 20.000000000000014, 20.000000000000014, 130.7, -240.40000000000006, 90.19999999999999, 10.39999999999998, 137.29999999999976, 85.69999999999997, 13.699999999999955, 20.000000000000014, -295.1, 125.60000000000005, 20.000000000000014, -54.4, 16.99999999999999, -13.59999999999979, -7.3000000000000504, 127.99999999999982, -1.8999999999999986, 34.09999999999988, 28.39999999999999, 161.59999999999997, 5.899999999999885, 148.70000000000002, -6.399999999999993, 20.000000000000014, 20.000000000000014, 20.000000000000014, 108.79999999999978, 106.39999999999942, 132.49999999999997, -21.999999999999744, -4.2999999999998835, -46.89999999999991, -240.60000000000002, -109.40000000000003, 119.00000000000001, -7.3000000000000504, 96.49999999999997, -45.69999999999992, 156.2, 21.199999999999903, 20.000000000000014, -77.19999999999996, 106.99999999999997, 92.89999999999992, -215.2000000000001, -202.90000000000006, 20.000000000000014, 20.000000000000014, 159.49999999999997, 108.79999999999987], "policy_predator_policy_reward": [0.0, 61.0, 16.0, 11.0, 50.0, 31.0, 0.0, 0.0, 6.0, 9.0, 17.0, 45.0, 53.0, 8.0, 35.0, 24.0, 170.0, 62.0, 12.0, 26.0, 3.0, 9.0, 61.0, 14.0, 0.0, 12.0, 40.0, 12.0, 0.0, 0.0, 69.0, 31.0, 0.0, 5.0, 0.0, 0.0, 32.0, 86.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 56.0, 0.0, 14.0, 33.0, 16.0, 0.0, 96.0, 1.0, 22.0, 0.0, 0.0, 35.0, 0.0, 17.0, 0.0, 85.0, 5.0, 0.0, 0.0, 0.0, 99.0, 0.0, 9.0, 4.0, 0.0, 0.0, 41.0, 19.0, 10.0, 4.0, 0.0, 0.0, 145.0, 0.0, 0.0, 0.0, 0.0, 39.0, 2.0, 1.0, 0.0, 26.0, 0.0, 9.0, 30.0, 12.0, 0.0, 19.0, 20.0, 105.0, 0.0, 19.0, 70.0, 75.0, 44.0, 0.0, 3.0, 155.0, 0.0, 0.0, 0.0, 20.0, 1.0, 31.0, 12.0, 0.0, 61.0, 0.0, 4.0, 0.0, 0.0, 0.0, 33.0, 52.0, 14.0, 1.0, 18.0, 0.0, 25.0, 39.0, 0.0, 0.0, 76.0, 0.0, 34.0, 24.0, 0.0, 394.0, 0.0, 0.0, 42.0, 0.0, 2.0, 0.0, 16.0, 0.0, 19.0, 43.0, 0.0, 0.0, 2.0, 32.0, 0.0, 0.0, 124.0, 12.0, 5.0, 0.0, 0.0, 22.0, 3.0, 0.0, 14.0, 176.0, 38.0, 34.0, 20.0, 27.0, 0.0, 13.0, 30.0, 72.0, 0.0, 31.0, 0.0, 57.0, 0.0, 22.0, 0.0, 0.0, 0.0, 1.0, 29.0, 8.0, 71.0, 0.0, 0.0, 194.0, 0.0, 22.0, 19.0, 20.0, 50.0, 0.0, 81.0, 0.0, 1.0, 31.0, 179.0, 0.0, 0.0, 0.0, 12.0, 4.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6926315378310034, "mean_inference_ms": 1.5891013290133191, "mean_action_processing_ms": 0.273101873573574, "mean_env_wait_ms": 0.20545946488570516, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01056814193725586, "StateBufferConnector_ms": 0.004006385803222656, "ViewRequirementAgentConnector_ms": 0.13131499290466309}, "num_episodes": 18, "episode_return_max": 284.30000000000007, "episode_return_min": -511.4999999999998, "episode_return_mean": 50.599999999999916, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 352000, "num_agent_steps_trained": 352000, "num_env_steps_sampled": 88000, "num_env_steps_trained": 88000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 78.84903602455019, "num_env_steps_trained_throughput_per_sec": 78.84903602455019, "timesteps_total": 88000, "num_env_steps_sampled_lifetime": 88000, "num_agent_steps_sampled_lifetime": 352000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 352000, "timers": {"training_iteration_time_ms": 50856.916, "restore_workers_time_ms": 0.013, "training_step_time_ms": 50856.864, "sample_time_ms": 1291.771, "learn_time_ms": 49550.814, "learn_throughput": 80.725, "synch_weights_time_ms": 10.708}, "counters": {"num_env_steps_sampled": 88000, "num_env_steps_trained": 88000, "num_agent_steps_sampled": 352000, "num_agent_steps_trained": 352000}, "done": false, "training_iteration": 22, "trial_id": "11e70_00000", "date": "2024-08-12_23-25-56", "timestamp": 1723519556, "time_this_iter_s": 50.76962900161743, "time_total_s": 1136.508245229721, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2af5820>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1136.508245229721, "iterations_since_restore": 22, "perf": {"cpu_util_percent": 36.09166666666667, "ram_util_percent": 82.95555555555556}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.541679283613881, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.329818991756944, "policy_loss": -0.008130261611942418, "vf_loss": 4.336716346639805, "vf_explained_var": 0.023595103006514292, "kl": 0.008219354216660134, "entropy": 1.4053579886123617, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 42525.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.884335337681745, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.403598064341873, "policy_loss": -0.00908904017143878, "vf_loss": 6.411237482545237, "vf_explained_var": 0.05484040540362161, "kl": 0.00966420501884242, "entropy": 1.408920187294168, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 42525.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 92000, "num_env_steps_trained": 92000, "num_agent_steps_sampled": 368000, "num_agent_steps_trained": 368000}, "env_runners": {"episode_reward_max": 313.60000000000014, "episode_reward_min": -511.4999999999998, "episode_reward_mean": 67.52499999999993, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -829.9, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 197.29999999999998, "predator_policy": 496.0}, "policy_reward_mean": {"prey_policy": 1.567499999999981, "predator_policy": 32.195}, "custom_metrics": {}, "hist_stats": {"episode_reward": [76.9999999999997, 67.20000000000014, 107.69999999999982, -41.79999999999961, 54.30000000000043, 55.300000000000516, 93.69999999999968, 35.90000000000024, 40.0000000000003, 45.10000000000024, 29.10000000000013, 84.99999999999993, -191.9000000000008, 40.0000000000003, 130.29999999999959, 36.70000000000028, 74.3999999999998, 30.100000000000154, 74.19999999999968, 19.999999999999975, -11.99999999999993, 19.10000000000027, 110.29999999999973, -8.399999999999666, -40.19999999999988, 40.0000000000003, 42.300000000000345, 108.5999999999994, 22.600000000000012, 142.9999999999999, 81.49999999999967, 125.49999999999928, 134.29999999999987, 135.0999999999996, 141.69999999999922, 79.70000000000002, 40.0000000000003, 29.30000000000009, 87.79999999999984, -511.4999999999998, 250.59999999999945, 166.5999999999992, 78.3000000000001, 22.400000000000016, 66.30000000000011, 118.29999999999885, 2.600000000000068, 40.0000000000003, 26.300000000000125, 105.59999999999984, 244.99999999999937, 36.70000000000028, 20.50000000000012, 37.60000000000026, 50.40000000000033, 133.69999999999936, 134.1999999999999, 220.99999999999991, 211.59999999999988, 35.60000000000022, 40.0000000000003, 216.19999999999916, 147.49999999999963, 19.799999999999187, -155.99999999999994, 133.69999999999962, 89.79999999999995, 227.39999999999972, 23.800000000000253, 231.89999999999964, -239.1000000000003, 40.0000000000003, 284.30000000000007, 245.79999999999973, 247.3999999999997, 40.0000000000003, 205.09999999999965, 10.500000000000059, 60.80000000000027, 40.0000000000003, 297.7000000000004, -56.499999999999964, 24.60000000000028, 107.59999999999991, 154.99999999999946, 1.000000000000032, -300.4, -123.90000000000003, -82.00000000000014, 40.0000000000003, 5.3000000000000105, 138.5999999999994, 313.60000000000014, 145.3, -102.80000000000024, 282.5999999999999, 203.79999999999933, 28.49999999999985, 90.39999999999975, 40.90000000000031], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 35.00000000000013, 50.600000000000236, -18.39999999999982, 70.69999999999995, 20.000000000000014, -158.50000000000063, 31.700000000000212, 9.499999999999964, 39.80000000000022, 20.000000000000014, 35.30000000000025, -15.699999999999967, 10.4, 20.000000000000014, 2.8999999999999613, 20.000000000000014, 20.000000000000014, 3.5000000000000426, -18.39999999999975, 3.4999999999999654, 11.599999999999964, 31.700000000000212, 53.300000000000054, -181.3000000000004, -155.60000000000045, 20.000000000000014, 20.000000000000014, -56.500000000000334, 147.79999999999998, 20.000000000000014, 13.699999999999955, 20.000000000000014, 28.40000000000004, 20.000000000000014, 1.09999999999996, 35.000000000000256, -2.799999999999926, 20.000000000000014, -18.999999999999744, 63.50000000000009, -200.50000000000026, -19.900000000000016, 20.000000000000014, -146.50000000000048, 111.79999999999998, 20.000000000000014, -72.40000000000087, -305.5, 107.29999999999964, 20.000000000000014, 20.000000000000014, 33.50000000000024, -11.199999999999848, 20.000000000000014, 56.59999999999998, -5.199999999999934, 15.799999999999963, 53.59999999999999, 28.40000000000004, 57.500000000000185, 20.000000000000014, 20.000000000000014, 105.49999999999977, 28.400000000000134, 20.900000000000006, 115.69999999999996, 4.399999999999968, 41.60000000000016, 82.0999999999997, 20.000000000000014, -4.300000000000052, 20.000000000000014, 20.000000000000014, 20.000000000000014, -66.70000000000005, 9.799999999999963, 20.000000000000014, -502.8999999999998, -402.6, 156.79999999999984, 93.79999999999981, 7.4, 117.19999999999959, 60.499999999999964, 15.800000000000011, 20.000000000000014, -13.599999999999794, 11.59999999999997, -7.300000000000006, 20.000000000000014, 98.29999999999949, 15.799999999999946, -47.1999999999998, 20.000000000000014, 20.000000000000014, 130.7, -240.40000000000006, 90.19999999999999, 10.39999999999998, 137.29999999999976, 85.69999999999997, 13.699999999999955, 20.000000000000014, -295.1, 125.60000000000005, 20.000000000000014, -54.4, 16.99999999999999, -13.59999999999979, -7.3000000000000504, 127.99999999999982, -1.8999999999999986, 34.09999999999988, 28.39999999999999, 161.59999999999997, 5.899999999999885, 148.70000000000002, -6.399999999999993, 20.000000000000014, 20.000000000000014, 20.000000000000014, 108.79999999999978, 106.39999999999942, 132.49999999999997, -21.999999999999744, -4.2999999999998835, -46.89999999999991, -240.60000000000002, -109.40000000000003, 119.00000000000001, -7.3000000000000504, 96.49999999999997, -45.69999999999992, 156.2, 21.199999999999903, 20.000000000000014, -77.19999999999996, 106.99999999999997, 92.89999999999992, -215.2000000000001, -202.90000000000006, 20.000000000000014, 20.000000000000014, 159.49999999999997, 108.79999999999987, 123.19999999999996, 95.59999999999992, 119.30000000000005, 88.09999999999997, 20.000000000000014, 20.000000000000014, 55.700000000000024, 112.39999999999998, -17.79999999999974, -0.7000000000000169, -26.19999999999999, 20.000000000000014, 20.000000000000014, 20.000000000000014, 145.99999999999991, 139.69999999999993, -104.50000000000003, -124.0, 20.000000000000014, -9.40000000000003, 20.000000000000014, 38.60000000000002, 62.599999999999994, 52.400000000000205, -146.80000000000007, -26.19999999999998, -234.39999999999998, -288.99999999999994, -89.50000000000001, -171.39999999999998, -64.00000000000004, -84.99999999999999, 20.000000000000014, 20.000000000000014, -118.00000000000003, 5.299999999999965, 95.29999999999995, 5.299999999999965, 116.29999999999993, 197.29999999999998, 28.10000000000001, 63.2, 2.5999999999999717, -527.4, 168.49999999999991, -829.9, 20.000000000000014, 183.8, -134.5, 46.99999999999987, -203.90000000000003, 176.2999999999999, 20.000000000000014, 20.900000000000027], "policy_predator_policy_reward": [22.0, 0.0, 0.0, 35.0, 0.0, 17.0, 0.0, 85.0, 5.0, 0.0, 0.0, 0.0, 99.0, 0.0, 9.0, 4.0, 0.0, 0.0, 41.0, 19.0, 10.0, 4.0, 0.0, 0.0, 145.0, 0.0, 0.0, 0.0, 0.0, 39.0, 2.0, 1.0, 0.0, 26.0, 0.0, 9.0, 30.0, 12.0, 0.0, 19.0, 20.0, 105.0, 0.0, 19.0, 70.0, 75.0, 44.0, 0.0, 3.0, 155.0, 0.0, 0.0, 0.0, 20.0, 1.0, 31.0, 12.0, 0.0, 61.0, 0.0, 4.0, 0.0, 0.0, 0.0, 33.0, 52.0, 14.0, 1.0, 18.0, 0.0, 25.0, 39.0, 0.0, 0.0, 76.0, 0.0, 34.0, 24.0, 0.0, 394.0, 0.0, 0.0, 42.0, 0.0, 2.0, 0.0, 16.0, 0.0, 19.0, 43.0, 0.0, 0.0, 2.0, 32.0, 0.0, 0.0, 124.0, 12.0, 5.0, 0.0, 0.0, 22.0, 3.0, 0.0, 14.0, 176.0, 38.0, 34.0, 20.0, 27.0, 0.0, 13.0, 30.0, 72.0, 0.0, 31.0, 0.0, 57.0, 0.0, 22.0, 0.0, 0.0, 0.0, 1.0, 29.0, 8.0, 71.0, 0.0, 0.0, 194.0, 0.0, 22.0, 19.0, 20.0, 50.0, 0.0, 81.0, 0.0, 1.0, 31.0, 179.0, 0.0, 0.0, 0.0, 12.0, 4.0, 27.0, 0.0, 35.0, 5.0, 0.0, 0.0, 0.0, 37.0, 29.0, 0.0, 46.0, 21.0, 0.0, 0.0, 12.0, 0.0, 83.0, 89.0, 0.0, 14.0, 43.0, 6.0, 30.0, 10.0, 83.0, 91.0, 103.0, 120.0, 63.0, 74.0, 67.0, 0.0, 0.0, 0.0, 37.0, 81.0, 7.0, 31.0, 0.0, 0.0, 54.0, 0.0, 406.0, 16.0, 496.0, 448.0, 0.0, 0.0, 116.0, 0.0, 118.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.691737426937245, "mean_inference_ms": 1.5840898248434079, "mean_action_processing_ms": 0.27246941793335283, "mean_env_wait_ms": 0.20466554514665744, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.011226296424865723, "StateBufferConnector_ms": 0.004681110382080078, "ViewRequirementAgentConnector_ms": 0.15232551097869873}, "num_episodes": 27, "episode_return_max": 313.60000000000014, "episode_return_min": -511.4999999999998, "episode_return_mean": 67.52499999999993, "episodes_this_iter": 27}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 368000, "num_agent_steps_trained": 368000, "num_env_steps_sampled": 92000, "num_env_steps_trained": 92000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 79.03615553943676, "num_env_steps_trained_throughput_per_sec": 79.03615553943676, "timesteps_total": 92000, "num_env_steps_sampled_lifetime": 92000, "num_agent_steps_sampled_lifetime": 368000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 368000, "timers": {"training_iteration_time_ms": 50813.703, "restore_workers_time_ms": 0.013, "training_step_time_ms": 50813.651, "sample_time_ms": 1269.241, "learn_time_ms": 49530.332, "learn_throughput": 80.759, "synch_weights_time_ms": 10.705}, "counters": {"num_env_steps_sampled": 92000, "num_env_steps_trained": 92000, "num_agent_steps_sampled": 368000, "num_agent_steps_trained": 368000}, "done": false, "training_iteration": 23, "trial_id": "11e70_00000", "date": "2024-08-12_23-26-46", "timestamp": 1723519606, "time_this_iter_s": 50.66078996658325, "time_total_s": 1187.1690351963043, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2b8ce50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1187.1690351963043, "iterations_since_restore": 23, "perf": {"cpu_util_percent": 35.584722222222226, "ram_util_percent": 82.92916666666666}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 6.421409040090269, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.03770284703169, "policy_loss": -0.01147535858828594, "vf_loss": 7.047603756536252, "vf_explained_var": 0.09201585745054577, "kl": 0.010496280081042277, "entropy": 1.4115250967797779, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 44415.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.367684032235827, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.440421790925283, "policy_loss": -0.010209181984497244, "vf_loss": 7.449464644830694, "vf_explained_var": -0.14986950979030952, "kl": 0.007775648256935369, "entropy": 1.442961941825019, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 44415.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 96000, "num_env_steps_trained": 96000, "num_agent_steps_sampled": 384000, "num_agent_steps_trained": 384000}, "env_runners": {"episode_reward_max": 313.60000000000014, "episode_reward_min": -511.4999999999998, "episode_reward_mean": 54.47999999999993, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -829.9, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 197.29999999999998, "predator_policy": 496.0}, "policy_reward_mean": {"prey_policy": -13.480000000000018, "predator_policy": 40.72}, "custom_metrics": {}, "hist_stats": {"episode_reward": [74.19999999999968, 19.999999999999975, -11.99999999999993, 19.10000000000027, 110.29999999999973, -8.399999999999666, -40.19999999999988, 40.0000000000003, 42.300000000000345, 108.5999999999994, 22.600000000000012, 142.9999999999999, 81.49999999999967, 125.49999999999928, 134.29999999999987, 135.0999999999996, 141.69999999999922, 79.70000000000002, 40.0000000000003, 29.30000000000009, 87.79999999999984, -511.4999999999998, 250.59999999999945, 166.5999999999992, 78.3000000000001, 22.400000000000016, 66.30000000000011, 118.29999999999885, 2.600000000000068, 40.0000000000003, 26.300000000000125, 105.59999999999984, 244.99999999999937, 36.70000000000028, 20.50000000000012, 37.60000000000026, 50.40000000000033, 133.69999999999936, 134.1999999999999, 220.99999999999991, 211.59999999999988, 35.60000000000022, 40.0000000000003, 216.19999999999916, 147.49999999999963, 19.799999999999187, -155.99999999999994, 133.69999999999962, 89.79999999999995, 227.39999999999972, 23.800000000000253, 231.89999999999964, -239.1000000000003, 40.0000000000003, 284.30000000000007, 245.79999999999973, 247.3999999999997, 40.0000000000003, 205.09999999999965, 10.500000000000059, 60.80000000000027, 40.0000000000003, 297.7000000000004, -56.499999999999964, 24.60000000000028, 107.59999999999991, 154.99999999999946, 1.000000000000032, -300.4, -123.90000000000003, -82.00000000000014, 40.0000000000003, 5.3000000000000105, 138.5999999999994, 313.60000000000014, 145.3, -102.80000000000024, 282.5999999999999, 203.79999999999933, 28.49999999999985, 90.39999999999975, 40.90000000000031, 49.89999999999972, 23.50000000000012, 64.50000000000014, 7.000000000000007, -179.90000000000003, 50.89999999999998, -154.8999999999999, -328.4999999999999, 47.90000000000014, -4.2999999999999865, -22.09999999999995, -117.90000000000003, -121.00000000000006, 53.20000000000012, 37.10000000000002, 2.9000000000001394, 8.700000000000182, 46.60000000000008], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [35.000000000000256, -2.799999999999926, 20.000000000000014, -18.999999999999744, 63.50000000000009, -200.50000000000026, -19.900000000000016, 20.000000000000014, -146.50000000000048, 111.79999999999998, 20.000000000000014, -72.40000000000087, -305.5, 107.29999999999964, 20.000000000000014, 20.000000000000014, 33.50000000000024, -11.199999999999848, 20.000000000000014, 56.59999999999998, -5.199999999999934, 15.799999999999963, 53.59999999999999, 28.40000000000004, 57.500000000000185, 20.000000000000014, 20.000000000000014, 105.49999999999977, 28.400000000000134, 20.900000000000006, 115.69999999999996, 4.399999999999968, 41.60000000000016, 82.0999999999997, 20.000000000000014, -4.300000000000052, 20.000000000000014, 20.000000000000014, 20.000000000000014, -66.70000000000005, 9.799999999999963, 20.000000000000014, -502.8999999999998, -402.6, 156.79999999999984, 93.79999999999981, 7.4, 117.19999999999959, 60.499999999999964, 15.800000000000011, 20.000000000000014, -13.599999999999794, 11.59999999999997, -7.300000000000006, 20.000000000000014, 98.29999999999949, 15.799999999999946, -47.1999999999998, 20.000000000000014, 20.000000000000014, 130.7, -240.40000000000006, 90.19999999999999, 10.39999999999998, 137.29999999999976, 85.69999999999997, 13.699999999999955, 20.000000000000014, -295.1, 125.60000000000005, 20.000000000000014, -54.4, 16.99999999999999, -13.59999999999979, -7.3000000000000504, 127.99999999999982, -1.8999999999999986, 34.09999999999988, 28.39999999999999, 161.59999999999997, 5.899999999999885, 148.70000000000002, -6.399999999999993, 20.000000000000014, 20.000000000000014, 20.000000000000014, 108.79999999999978, 106.39999999999942, 132.49999999999997, -21.999999999999744, -4.2999999999998835, -46.89999999999991, -240.60000000000002, -109.40000000000003, 119.00000000000001, -7.3000000000000504, 96.49999999999997, -45.69999999999992, 156.2, 21.199999999999903, 20.000000000000014, -77.19999999999996, 106.99999999999997, 92.89999999999992, -215.2000000000001, -202.90000000000006, 20.000000000000014, 20.000000000000014, 159.49999999999997, 108.79999999999987, 123.19999999999996, 95.59999999999992, 119.30000000000005, 88.09999999999997, 20.000000000000014, 20.000000000000014, 55.700000000000024, 112.39999999999998, -17.79999999999974, -0.7000000000000169, -26.19999999999999, 20.000000000000014, 20.000000000000014, 20.000000000000014, 145.99999999999991, 139.69999999999993, -104.50000000000003, -124.0, 20.000000000000014, -9.40000000000003, 20.000000000000014, 38.60000000000002, 62.599999999999994, 52.400000000000205, -146.80000000000007, -26.19999999999998, -234.39999999999998, -288.99999999999994, -89.50000000000001, -171.39999999999998, -64.00000000000004, -84.99999999999999, 20.000000000000014, 20.000000000000014, -118.00000000000003, 5.299999999999965, 95.29999999999995, 5.299999999999965, 116.29999999999993, 197.29999999999998, 28.10000000000001, 63.2, 2.5999999999999717, -527.4, 168.49999999999991, -829.9, 20.000000000000014, 183.8, -134.5, 46.99999999999987, -203.90000000000003, 176.2999999999999, 20.000000000000014, 20.900000000000027, -70.9, 30.800000000000196, -56.5, 20.000000000000014, -82.89999999999998, 7.399999999999965, -24.39999999999999, -82.60000000000002, -202.9, -172.00000000000003, -31.899999999999977, -26.19999999999999, -186.70000000000013, -113.20000000000002, -187.90000000000003, -313.5999999999999, -91.30000000000025, 30.200000000000003, -124.3, 20.000000000000014, 17.899999999999988, -208.0, -147.7, -92.19999999999999, -174.1, -145.90000000000006, -87.09999999999997, 44.3, -85.89999999999998, 4.999999999999972, 20.000000000000014, -198.10000000000005, -64.30000000000005, 20.000000000000014, -49.00000000000001, -9.400000000000011], "policy_predator_policy_reward": [30.0, 12.0, 0.0, 19.0, 20.0, 105.0, 0.0, 19.0, 70.0, 75.0, 44.0, 0.0, 3.0, 155.0, 0.0, 0.0, 0.0, 20.0, 1.0, 31.0, 12.0, 0.0, 61.0, 0.0, 4.0, 0.0, 0.0, 0.0, 33.0, 52.0, 14.0, 1.0, 18.0, 0.0, 25.0, 39.0, 0.0, 0.0, 76.0, 0.0, 34.0, 24.0, 0.0, 394.0, 0.0, 0.0, 42.0, 0.0, 2.0, 0.0, 16.0, 0.0, 19.0, 43.0, 0.0, 0.0, 2.0, 32.0, 0.0, 0.0, 124.0, 12.0, 5.0, 0.0, 0.0, 22.0, 3.0, 0.0, 14.0, 176.0, 38.0, 34.0, 20.0, 27.0, 0.0, 13.0, 30.0, 72.0, 0.0, 31.0, 0.0, 57.0, 0.0, 22.0, 0.0, 0.0, 0.0, 1.0, 29.0, 8.0, 71.0, 0.0, 0.0, 194.0, 0.0, 22.0, 19.0, 20.0, 50.0, 0.0, 81.0, 0.0, 1.0, 31.0, 179.0, 0.0, 0.0, 0.0, 12.0, 4.0, 27.0, 0.0, 35.0, 5.0, 0.0, 0.0, 0.0, 37.0, 29.0, 0.0, 46.0, 21.0, 0.0, 0.0, 12.0, 0.0, 83.0, 89.0, 0.0, 14.0, 43.0, 6.0, 30.0, 10.0, 83.0, 91.0, 103.0, 120.0, 63.0, 74.0, 67.0, 0.0, 0.0, 0.0, 37.0, 81.0, 7.0, 31.0, 0.0, 0.0, 54.0, 0.0, 406.0, 16.0, 496.0, 448.0, 0.0, 0.0, 116.0, 0.0, 118.0, 0.0, 0.0, 0.0, 0.0, 90.0, 60.0, 0.0, 51.0, 89.0, 18.0, 96.0, 67.0, 128.0, 109.0, 0.0, 68.0, 77.0, 173.0, 0.0, 56.0, 53.0, 36.0, 64.0, 55.0, 113.0, 0.0, 122.0, 131.0, 68.0, 51.0, 45.0, 40.0, 78.0, 102.0, 79.0, 15.0, 38.0, 105.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6886276750392938, "mean_inference_ms": 1.5794255926351617, "mean_action_processing_ms": 0.27135529424578236, "mean_env_wait_ms": 0.2039874076057655, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.009261131286621094, "StateBufferConnector_ms": 0.0037592649459838867, "ViewRequirementAgentConnector_ms": 0.12959551811218262}, "num_episodes": 18, "episode_return_max": 313.60000000000014, "episode_return_min": -511.4999999999998, "episode_return_mean": 54.47999999999993, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 384000, "num_agent_steps_trained": 384000, "num_env_steps_sampled": 96000, "num_env_steps_trained": 96000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 75.87130265455785, "num_env_steps_trained_throughput_per_sec": 75.87130265455785, "timesteps_total": 96000, "num_env_steps_sampled_lifetime": 96000, "num_agent_steps_sampled_lifetime": 384000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 384000, "timers": {"training_iteration_time_ms": 51005.189, "restore_workers_time_ms": 0.013, "training_step_time_ms": 51005.137, "sample_time_ms": 1274.624, "learn_time_ms": 49716.245, "learn_throughput": 80.457, "synch_weights_time_ms": 10.87}, "counters": {"num_env_steps_sampled": 96000, "num_env_steps_trained": 96000, "num_agent_steps_sampled": 384000, "num_agent_steps_trained": 384000}, "done": false, "training_iteration": 24, "trial_id": "11e70_00000", "date": "2024-08-12_23-27-39", "timestamp": 1723519659, "time_this_iter_s": 52.7682728767395, "time_total_s": 1239.9373080730438, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3f39ca0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1239.9373080730438, "iterations_since_restore": 24, "perf": {"cpu_util_percent": 44.45945945945945, "ram_util_percent": 82.32837837837837}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 6.356159284379747, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.777637240747926, "policy_loss": -0.010510687074973863, "vf_loss": 6.786651933508575, "vf_explained_var": 0.0526248056421835, "kl": 0.00997334841601635, "entropy": 1.3882181410436276, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 46305.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.3080704494128153, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.242192718970082, "policy_loss": -0.011115914989243109, "vf_loss": 7.251943342774003, "vf_explained_var": -0.17578746477762858, "kl": 0.00910196362966515, "entropy": 1.384039458143648, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 46305.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 100000, "num_env_steps_trained": 100000, "num_agent_steps_sampled": 400000, "num_agent_steps_trained": 400000}, "env_runners": {"episode_reward_max": 313.60000000000014, "episode_reward_min": -511.4999999999998, "episode_reward_mean": 30.769999999999953, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -829.9, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 197.29999999999998, "predator_policy": 496.0}, "policy_reward_mean": {"prey_policy": -34.990000000000016, "predator_policy": 50.375}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.0000000000003, 29.30000000000009, 87.79999999999984, -511.4999999999998, 250.59999999999945, 166.5999999999992, 78.3000000000001, 22.400000000000016, 66.30000000000011, 118.29999999999885, 2.600000000000068, 40.0000000000003, 26.300000000000125, 105.59999999999984, 244.99999999999937, 36.70000000000028, 20.50000000000012, 37.60000000000026, 50.40000000000033, 133.69999999999936, 134.1999999999999, 220.99999999999991, 211.59999999999988, 35.60000000000022, 40.0000000000003, 216.19999999999916, 147.49999999999963, 19.799999999999187, -155.99999999999994, 133.69999999999962, 89.79999999999995, 227.39999999999972, 23.800000000000253, 231.89999999999964, -239.1000000000003, 40.0000000000003, 284.30000000000007, 245.79999999999973, 247.3999999999997, 40.0000000000003, 205.09999999999965, 10.500000000000059, 60.80000000000027, 40.0000000000003, 297.7000000000004, -56.499999999999964, 24.60000000000028, 107.59999999999991, 154.99999999999946, 1.000000000000032, -300.4, -123.90000000000003, -82.00000000000014, 40.0000000000003, 5.3000000000000105, 138.5999999999994, 313.60000000000014, 145.3, -102.80000000000024, 282.5999999999999, 203.79999999999933, 28.49999999999985, 90.39999999999975, 40.90000000000031, 49.89999999999972, 23.50000000000012, 64.50000000000014, 7.000000000000007, -179.90000000000003, 50.89999999999998, -154.8999999999999, -328.4999999999999, 47.90000000000014, -4.2999999999999865, -22.09999999999995, -117.90000000000003, -121.00000000000006, 53.20000000000012, 37.10000000000002, 2.9000000000001394, 8.700000000000182, 46.60000000000008, -47.00000000000005, -303.7000000000001, -84.30000000000001, -105.90000000000005, -72.09999999999994, -118.00000000000081, -67.8000000000002, -30.400000000000034, -46.89999999999993, -20.3999999999999, -40.199999999999854, -45.29999999999988, -52.69999999999999, -272.0999999999997, 57.00000000000019, 45.000000000000064, 2.300000000000149, 48.80000000000027], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 20.000000000000014, 20.000000000000014, -66.70000000000005, 9.799999999999963, 20.000000000000014, -502.8999999999998, -402.6, 156.79999999999984, 93.79999999999981, 7.4, 117.19999999999959, 60.499999999999964, 15.800000000000011, 20.000000000000014, -13.599999999999794, 11.59999999999997, -7.300000000000006, 20.000000000000014, 98.29999999999949, 15.799999999999946, -47.1999999999998, 20.000000000000014, 20.000000000000014, 130.7, -240.40000000000006, 90.19999999999999, 10.39999999999998, 137.29999999999976, 85.69999999999997, 13.699999999999955, 20.000000000000014, -295.1, 125.60000000000005, 20.000000000000014, -54.4, 16.99999999999999, -13.59999999999979, -7.3000000000000504, 127.99999999999982, -1.8999999999999986, 34.09999999999988, 28.39999999999999, 161.59999999999997, 5.899999999999885, 148.70000000000002, -6.399999999999993, 20.000000000000014, 20.000000000000014, 20.000000000000014, 108.79999999999978, 106.39999999999942, 132.49999999999997, -21.999999999999744, -4.2999999999998835, -46.89999999999991, -240.60000000000002, -109.40000000000003, 119.00000000000001, -7.3000000000000504, 96.49999999999997, -45.69999999999992, 156.2, 21.199999999999903, 20.000000000000014, -77.19999999999996, 106.99999999999997, 92.89999999999992, -215.2000000000001, -202.90000000000006, 20.000000000000014, 20.000000000000014, 159.49999999999997, 108.79999999999987, 123.19999999999996, 95.59999999999992, 119.30000000000005, 88.09999999999997, 20.000000000000014, 20.000000000000014, 55.700000000000024, 112.39999999999998, -17.79999999999974, -0.7000000000000169, -26.19999999999999, 20.000000000000014, 20.000000000000014, 20.000000000000014, 145.99999999999991, 139.69999999999993, -104.50000000000003, -124.0, 20.000000000000014, -9.40000000000003, 20.000000000000014, 38.60000000000002, 62.599999999999994, 52.400000000000205, -146.80000000000007, -26.19999999999998, -234.39999999999998, -288.99999999999994, -89.50000000000001, -171.39999999999998, -64.00000000000004, -84.99999999999999, 20.000000000000014, 20.000000000000014, -118.00000000000003, 5.299999999999965, 95.29999999999995, 5.299999999999965, 116.29999999999993, 197.29999999999998, 28.10000000000001, 63.2, 2.5999999999999717, -527.4, 168.49999999999991, -829.9, 20.000000000000014, 183.8, -134.5, 46.99999999999987, -203.90000000000003, 176.2999999999999, 20.000000000000014, 20.900000000000027, -70.9, 30.800000000000196, -56.5, 20.000000000000014, -82.89999999999998, 7.399999999999965, -24.39999999999999, -82.60000000000002, -202.9, -172.00000000000003, -31.899999999999977, -26.19999999999999, -186.70000000000013, -113.20000000000002, -187.90000000000003, -313.5999999999999, -91.30000000000025, 30.200000000000003, -124.3, 20.000000000000014, 17.899999999999988, -208.0, -147.7, -92.19999999999999, -174.1, -145.90000000000006, -87.09999999999997, 44.3, -85.89999999999998, 4.999999999999972, 20.000000000000014, -198.10000000000005, -64.30000000000005, 20.000000000000014, -49.00000000000001, -9.400000000000011, -119.20000000000005, -80.80000000000084, -337.9, -239.80000000000004, 20.000000000000014, -253.30000000000004, -220.60000000000008, -22.299999999999997, -267.1, 20.000000000000014, -459.9999999999991, 20.000000000000014, -119.50000000000001, -61.300000000000026, -13.599999999999826, -80.80000000000004, -40.899999999999956, -139.0, 7.399999999999965, -149.8, 34.39999999999999, -325.59999999999997, 20.000000000000014, -229.30000000000004, -133.90000000000018, -56.80000000000007, -202.60000000000005, -209.50000000000003, 40.39999999999998, 11.599999999999978, -4.299999999999956, -57.70000000000003, -168.7, 20.000000000000014, -167.2, 20.000000000000014], "policy_predator_policy_reward": [0.0, 0.0, 76.0, 0.0, 34.0, 24.0, 0.0, 394.0, 0.0, 0.0, 42.0, 0.0, 2.0, 0.0, 16.0, 0.0, 19.0, 43.0, 0.0, 0.0, 2.0, 32.0, 0.0, 0.0, 124.0, 12.0, 5.0, 0.0, 0.0, 22.0, 3.0, 0.0, 14.0, 176.0, 38.0, 34.0, 20.0, 27.0, 0.0, 13.0, 30.0, 72.0, 0.0, 31.0, 0.0, 57.0, 0.0, 22.0, 0.0, 0.0, 0.0, 1.0, 29.0, 8.0, 71.0, 0.0, 0.0, 194.0, 0.0, 22.0, 19.0, 20.0, 50.0, 0.0, 81.0, 0.0, 1.0, 31.0, 179.0, 0.0, 0.0, 0.0, 12.0, 4.0, 27.0, 0.0, 35.0, 5.0, 0.0, 0.0, 0.0, 37.0, 29.0, 0.0, 46.0, 21.0, 0.0, 0.0, 12.0, 0.0, 83.0, 89.0, 0.0, 14.0, 43.0, 6.0, 30.0, 10.0, 83.0, 91.0, 103.0, 120.0, 63.0, 74.0, 67.0, 0.0, 0.0, 0.0, 37.0, 81.0, 7.0, 31.0, 0.0, 0.0, 54.0, 0.0, 406.0, 16.0, 496.0, 448.0, 0.0, 0.0, 116.0, 0.0, 118.0, 0.0, 0.0, 0.0, 0.0, 90.0, 60.0, 0.0, 51.0, 89.0, 18.0, 96.0, 67.0, 128.0, 109.0, 0.0, 68.0, 77.0, 173.0, 0.0, 56.0, 53.0, 36.0, 64.0, 55.0, 113.0, 0.0, 122.0, 131.0, 68.0, 51.0, 45.0, 40.0, 78.0, 102.0, 79.0, 15.0, 38.0, 105.0, 0.0, 57.0, 96.0, 152.0, 122.0, 0.0, 149.0, 137.0, 0.0, 106.0, 69.0, 322.0, 0.0, 0.0, 113.0, 48.0, 16.0, 29.0, 104.0, 122.0, 0.0, 117.0, 134.0, 107.0, 57.0, 58.0, 80.0, 0.0, 140.0, 4.0, 1.0, 37.0, 70.0, 60.0, 91.0, 77.0, 119.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.68750735471023, "mean_inference_ms": 1.5747694505477685, "mean_action_processing_ms": 0.27071992503075354, "mean_env_wait_ms": 0.20352128776180733, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.009835600852966309, "StateBufferConnector_ms": 0.0037952661514282227, "ViewRequirementAgentConnector_ms": 0.13524949550628662}, "num_episodes": 18, "episode_return_max": 313.60000000000014, "episode_return_min": -511.4999999999998, "episode_return_mean": 30.769999999999953, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 400000, "num_agent_steps_trained": 400000, "num_env_steps_sampled": 100000, "num_env_steps_trained": 100000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 79.28298519822688, "num_env_steps_trained_throughput_per_sec": 79.28298519822688, "timesteps_total": 100000, "num_env_steps_sampled_lifetime": 100000, "num_agent_steps_sampled_lifetime": 400000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 400000, "timers": {"training_iteration_time_ms": 50966.399, "restore_workers_time_ms": 0.013, "training_step_time_ms": 50966.346, "sample_time_ms": 1282.202, "learn_time_ms": 49670.388, "learn_throughput": 80.531, "synch_weights_time_ms": 10.724}, "counters": {"num_env_steps_sampled": 100000, "num_env_steps_trained": 100000, "num_agent_steps_sampled": 400000, "num_agent_steps_trained": 400000}, "done": false, "training_iteration": 25, "trial_id": "11e70_00000", "date": "2024-08-12_23-28-30", "timestamp": 1723519710, "time_this_iter_s": 50.48325181007385, "time_total_s": 1290.4205598831177, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2b61790>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1290.4205598831177, "iterations_since_restore": 25, "perf": {"cpu_util_percent": 35.37777777777777, "ram_util_percent": 83.04444444444445}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 7.594724556819472, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.895911289144445, "policy_loss": -0.008712265589988973, "vf_loss": 6.903395823574571, "vf_explained_var": 0.08740981369422227, "kl": 0.008184885807785428, "entropy": 1.383727574726892, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 48195.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.7679842020784107, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.641602175576346, "policy_loss": -0.009314301056743022, "vf_loss": 6.649485776790235, "vf_explained_var": -0.15231039971901625, "kl": 0.009537945023673593, "entropy": 1.3621493959553028, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 48195.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 104000, "num_env_steps_trained": 104000, "num_agent_steps_sampled": 416000, "num_agent_steps_trained": 416000}, "env_runners": {"episode_reward_max": 313.60000000000014, "episode_reward_min": -428.6000000000001, "episode_reward_mean": 4.406999999999951, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -829.9, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 197.29999999999998, "predator_policy": 496.0}, "policy_reward_mean": {"prey_policy": -57.54650000000002, "predator_policy": 59.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [50.40000000000033, 133.69999999999936, 134.1999999999999, 220.99999999999991, 211.59999999999988, 35.60000000000022, 40.0000000000003, 216.19999999999916, 147.49999999999963, 19.799999999999187, -155.99999999999994, 133.69999999999962, 89.79999999999995, 227.39999999999972, 23.800000000000253, 231.89999999999964, -239.1000000000003, 40.0000000000003, 284.30000000000007, 245.79999999999973, 247.3999999999997, 40.0000000000003, 205.09999999999965, 10.500000000000059, 60.80000000000027, 40.0000000000003, 297.7000000000004, -56.499999999999964, 24.60000000000028, 107.59999999999991, 154.99999999999946, 1.000000000000032, -300.4, -123.90000000000003, -82.00000000000014, 40.0000000000003, 5.3000000000000105, 138.5999999999994, 313.60000000000014, 145.3, -102.80000000000024, 282.5999999999999, 203.79999999999933, 28.49999999999985, 90.39999999999975, 40.90000000000031, 49.89999999999972, 23.50000000000012, 64.50000000000014, 7.000000000000007, -179.90000000000003, 50.89999999999998, -154.8999999999999, -328.4999999999999, 47.90000000000014, -4.2999999999999865, -22.09999999999995, -117.90000000000003, -121.00000000000006, 53.20000000000012, 37.10000000000002, 2.9000000000001394, 8.700000000000182, 46.60000000000008, -47.00000000000005, -303.7000000000001, -84.30000000000001, -105.90000000000005, -72.09999999999994, -118.00000000000081, -67.8000000000002, -30.400000000000034, -46.89999999999993, -20.3999999999999, -40.199999999999854, -45.29999999999988, -52.69999999999999, -272.0999999999997, 57.00000000000019, 45.000000000000064, 2.300000000000149, 48.80000000000027, -411.89999999999986, -126.00000000000034, -428.6000000000001, 3.5000000000002025, -109.80000000000041, -219.3, -263.90000000000003, 75.59999999999937, -99.30000000000044, -52.89999999999985, 61.600000000000115, 183.7999999999994, -13.199999999999882, -2.199999999999936, -194.7000000000001, -14.599999999999916, -2.1999999999999265, -159.8], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [16.99999999999999, -13.59999999999979, -7.3000000000000504, 127.99999999999982, -1.8999999999999986, 34.09999999999988, 28.39999999999999, 161.59999999999997, 5.899999999999885, 148.70000000000002, -6.399999999999993, 20.000000000000014, 20.000000000000014, 20.000000000000014, 108.79999999999978, 106.39999999999942, 132.49999999999997, -21.999999999999744, -4.2999999999998835, -46.89999999999991, -240.60000000000002, -109.40000000000003, 119.00000000000001, -7.3000000000000504, 96.49999999999997, -45.69999999999992, 156.2, 21.199999999999903, 20.000000000000014, -77.19999999999996, 106.99999999999997, 92.89999999999992, -215.2000000000001, -202.90000000000006, 20.000000000000014, 20.000000000000014, 159.49999999999997, 108.79999999999987, 123.19999999999996, 95.59999999999992, 119.30000000000005, 88.09999999999997, 20.000000000000014, 20.000000000000014, 55.700000000000024, 112.39999999999998, -17.79999999999974, -0.7000000000000169, -26.19999999999999, 20.000000000000014, 20.000000000000014, 20.000000000000014, 145.99999999999991, 139.69999999999993, -104.50000000000003, -124.0, 20.000000000000014, -9.40000000000003, 20.000000000000014, 38.60000000000002, 62.599999999999994, 52.400000000000205, -146.80000000000007, -26.19999999999998, -234.39999999999998, -288.99999999999994, -89.50000000000001, -171.39999999999998, -64.00000000000004, -84.99999999999999, 20.000000000000014, 20.000000000000014, -118.00000000000003, 5.299999999999965, 95.29999999999995, 5.299999999999965, 116.29999999999993, 197.29999999999998, 28.10000000000001, 63.2, 2.5999999999999717, -527.4, 168.49999999999991, -829.9, 20.000000000000014, 183.8, -134.5, 46.99999999999987, -203.90000000000003, 176.2999999999999, 20.000000000000014, 20.900000000000027, -70.9, 30.800000000000196, -56.5, 20.000000000000014, -82.89999999999998, 7.399999999999965, -24.39999999999999, -82.60000000000002, -202.9, -172.00000000000003, -31.899999999999977, -26.19999999999999, -186.70000000000013, -113.20000000000002, -187.90000000000003, -313.5999999999999, -91.30000000000025, 30.200000000000003, -124.3, 20.000000000000014, 17.899999999999988, -208.0, -147.7, -92.19999999999999, -174.1, -145.90000000000006, -87.09999999999997, 44.3, -85.89999999999998, 4.999999999999972, 20.000000000000014, -198.10000000000005, -64.30000000000005, 20.000000000000014, -49.00000000000001, -9.400000000000011, -119.20000000000005, -80.80000000000084, -337.9, -239.80000000000004, 20.000000000000014, -253.30000000000004, -220.60000000000008, -22.299999999999997, -267.1, 20.000000000000014, -459.9999999999991, 20.000000000000014, -119.50000000000001, -61.300000000000026, -13.599999999999826, -80.80000000000004, -40.899999999999956, -139.0, 7.399999999999965, -149.8, 34.39999999999999, -325.59999999999997, 20.000000000000014, -229.30000000000004, -133.90000000000018, -56.80000000000007, -202.60000000000005, -209.50000000000003, 40.39999999999998, 11.599999999999978, -4.299999999999956, -57.70000000000003, -168.7, 20.000000000000014, -167.2, 20.000000000000014, -288.70000000000005, -302.1999999999998, -326.0999999999999, 4.1, -321.1, -362.5, 22.400000000000052, -133.9, 20.000000000000014, -293.79999999999995, -221.50000000000006, -179.8, -204.10000000000002, -200.8, 10.39999999999998, 36.20000000000026, -301.59999999999997, -72.70000000000059, -268.90000000000003, 20.000000000000014, 24.50000000000008, -7.899999999999999, 183.79999999999998, -106.0000000000008, -34.59999999999975, -139.60000000000002, -89.2000000000005, 20.000000000000014, -261.7, -178.00000000000003, 20.000000000000014, -244.60000000000002, -245.2, 20.000000000000014, -178.00000000000003, -179.8], "policy_predator_policy_reward": [20.0, 27.0, 0.0, 13.0, 30.0, 72.0, 0.0, 31.0, 0.0, 57.0, 0.0, 22.0, 0.0, 0.0, 0.0, 1.0, 29.0, 8.0, 71.0, 0.0, 0.0, 194.0, 0.0, 22.0, 19.0, 20.0, 50.0, 0.0, 81.0, 0.0, 1.0, 31.0, 179.0, 0.0, 0.0, 0.0, 12.0, 4.0, 27.0, 0.0, 35.0, 5.0, 0.0, 0.0, 0.0, 37.0, 29.0, 0.0, 46.0, 21.0, 0.0, 0.0, 12.0, 0.0, 83.0, 89.0, 0.0, 14.0, 43.0, 6.0, 30.0, 10.0, 83.0, 91.0, 103.0, 120.0, 63.0, 74.0, 67.0, 0.0, 0.0, 0.0, 37.0, 81.0, 7.0, 31.0, 0.0, 0.0, 54.0, 0.0, 406.0, 16.0, 496.0, 448.0, 0.0, 0.0, 116.0, 0.0, 118.0, 0.0, 0.0, 0.0, 0.0, 90.0, 60.0, 0.0, 51.0, 89.0, 18.0, 96.0, 67.0, 128.0, 109.0, 0.0, 68.0, 77.0, 173.0, 0.0, 56.0, 53.0, 36.0, 64.0, 55.0, 113.0, 0.0, 122.0, 131.0, 68.0, 51.0, 45.0, 40.0, 78.0, 102.0, 79.0, 15.0, 38.0, 105.0, 0.0, 57.0, 96.0, 152.0, 122.0, 0.0, 149.0, 137.0, 0.0, 106.0, 69.0, 322.0, 0.0, 0.0, 113.0, 48.0, 16.0, 29.0, 104.0, 122.0, 0.0, 117.0, 134.0, 107.0, 57.0, 58.0, 80.0, 0.0, 140.0, 4.0, 1.0, 37.0, 70.0, 60.0, 91.0, 77.0, 119.0, 179.0, 0.0, 26.0, 170.0, 73.0, 182.0, 115.0, 0.0, 164.0, 0.0, 0.0, 182.0, 141.0, 0.0, 0.0, 29.0, 105.0, 170.0, 90.0, 106.0, 45.0, 0.0, 59.0, 47.0, 107.0, 54.0, 67.0, 0.0, 146.0, 99.0, 135.0, 75.0, 137.0, 86.0, 110.0, 88.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6862625275075106, "mean_inference_ms": 1.5704729830813804, "mean_action_processing_ms": 0.2700491022056608, "mean_env_wait_ms": 0.20309492366998225, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005648255348205566, "StateBufferConnector_ms": 0.003763556480407715, "ViewRequirementAgentConnector_ms": 0.13332462310791016}, "num_episodes": 18, "episode_return_max": 313.60000000000014, "episode_return_min": -428.6000000000001, "episode_return_mean": 4.406999999999951, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 416000, "num_agent_steps_trained": 416000, "num_env_steps_sampled": 104000, "num_env_steps_trained": 104000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 78.88024017499123, "num_env_steps_trained_throughput_per_sec": 78.88024017499123, "timesteps_total": 104000, "num_env_steps_sampled_lifetime": 104000, "num_agent_steps_sampled_lifetime": 416000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 416000, "timers": {"training_iteration_time_ms": 50868.06, "restore_workers_time_ms": 0.013, "training_step_time_ms": 50868.007, "sample_time_ms": 1251.805, "learn_time_ms": 49602.355, "learn_throughput": 80.641, "synch_weights_time_ms": 10.857}, "counters": {"num_env_steps_sampled": 104000, "num_env_steps_trained": 104000, "num_agent_steps_sampled": 416000, "num_agent_steps_trained": 416000}, "done": false, "training_iteration": 26, "trial_id": "11e70_00000", "date": "2024-08-12_23-29-20", "timestamp": 1723519760, "time_this_iter_s": 50.74709177017212, "time_total_s": 1341.1676516532898, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2b624c0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1341.1676516532898, "iterations_since_restore": 26, "perf": {"cpu_util_percent": 36.04929577464789, "ram_util_percent": 82.62535211267605}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 7.432343908214064, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.001966211278603, "policy_loss": -0.011579632731006732, "vf_loss": 7.012086843561243, "vf_explained_var": 0.09382759947625417, "kl": 0.00972664497416696, "entropy": 1.3766304791919768, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 50085.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.2619271093890783, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.372526699651486, "policy_loss": -0.012514008842679676, "vf_loss": 6.383499821405562, "vf_explained_var": -0.2433374496994826, "kl": 0.010272562004632996, "entropy": 1.3588160499693855, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 50085.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 108000, "num_env_steps_trained": 108000, "num_agent_steps_sampled": 432000, "num_agent_steps_trained": 432000}, "env_runners": {"episode_reward_max": 313.60000000000014, "episode_reward_min": -428.6000000000001, "episode_reward_mean": -36.693000000000005, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -829.9, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 197.29999999999998, "predator_policy": 496.0}, "policy_reward_mean": {"prey_policy": -93.51650000000001, "predator_policy": 75.17}, "custom_metrics": {}, "hist_stats": {"episode_reward": [205.09999999999965, 10.500000000000059, 60.80000000000027, 40.0000000000003, 297.7000000000004, -56.499999999999964, 24.60000000000028, 107.59999999999991, 154.99999999999946, 1.000000000000032, -300.4, -123.90000000000003, -82.00000000000014, 40.0000000000003, 5.3000000000000105, 138.5999999999994, 313.60000000000014, 145.3, -102.80000000000024, 282.5999999999999, 203.79999999999933, 28.49999999999985, 90.39999999999975, 40.90000000000031, 49.89999999999972, 23.50000000000012, 64.50000000000014, 7.000000000000007, -179.90000000000003, 50.89999999999998, -154.8999999999999, -328.4999999999999, 47.90000000000014, -4.2999999999999865, -22.09999999999995, -117.90000000000003, -121.00000000000006, 53.20000000000012, 37.10000000000002, 2.9000000000001394, 8.700000000000182, 46.60000000000008, -47.00000000000005, -303.7000000000001, -84.30000000000001, -105.90000000000005, -72.09999999999994, -118.00000000000081, -67.8000000000002, -30.400000000000034, -46.89999999999993, -20.3999999999999, -40.199999999999854, -45.29999999999988, -52.69999999999999, -272.0999999999997, 57.00000000000019, 45.000000000000064, 2.300000000000149, 48.80000000000027, -411.89999999999986, -126.00000000000034, -428.6000000000001, 3.5000000000002025, -109.80000000000041, -219.3, -263.90000000000003, 75.59999999999937, -99.30000000000044, -52.89999999999985, 61.600000000000115, 183.7999999999994, -13.199999999999882, -2.199999999999936, -194.7000000000001, -14.599999999999916, -2.1999999999999265, -159.8, -307.4999999999999, -191.9, -316.30000000000007, -3.3999999999998938, 30.900000000000148, -37.19999999999985, 0.7000000000002005, -141.9, -334.2999999999998, 45.300000000000246, 37.80000000000027, 0.30000000000001936, -267.30000000000007, -130.50000000000037, 1.4000000000000057, 101.39999999999932, -58.699999999999996, -27.499999999999957, -37.399999999999785, -31.299999999999834, -57.19999999999998, -6.39999999999983], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [55.700000000000024, 112.39999999999998, -17.79999999999974, -0.7000000000000169, -26.19999999999999, 20.000000000000014, 20.000000000000014, 20.000000000000014, 145.99999999999991, 139.69999999999993, -104.50000000000003, -124.0, 20.000000000000014, -9.40000000000003, 20.000000000000014, 38.60000000000002, 62.599999999999994, 52.400000000000205, -146.80000000000007, -26.19999999999998, -234.39999999999998, -288.99999999999994, -89.50000000000001, -171.39999999999998, -64.00000000000004, -84.99999999999999, 20.000000000000014, 20.000000000000014, -118.00000000000003, 5.299999999999965, 95.29999999999995, 5.299999999999965, 116.29999999999993, 197.29999999999998, 28.10000000000001, 63.2, 2.5999999999999717, -527.4, 168.49999999999991, -829.9, 20.000000000000014, 183.8, -134.5, 46.99999999999987, -203.90000000000003, 176.2999999999999, 20.000000000000014, 20.900000000000027, -70.9, 30.800000000000196, -56.5, 20.000000000000014, -82.89999999999998, 7.399999999999965, -24.39999999999999, -82.60000000000002, -202.9, -172.00000000000003, -31.899999999999977, -26.19999999999999, -186.70000000000013, -113.20000000000002, -187.90000000000003, -313.5999999999999, -91.30000000000025, 30.200000000000003, -124.3, 20.000000000000014, 17.899999999999988, -208.0, -147.7, -92.19999999999999, -174.1, -145.90000000000006, -87.09999999999997, 44.3, -85.89999999999998, 4.999999999999972, 20.000000000000014, -198.10000000000005, -64.30000000000005, 20.000000000000014, -49.00000000000001, -9.400000000000011, -119.20000000000005, -80.80000000000084, -337.9, -239.80000000000004, 20.000000000000014, -253.30000000000004, -220.60000000000008, -22.299999999999997, -267.1, 20.000000000000014, -459.9999999999991, 20.000000000000014, -119.50000000000001, -61.300000000000026, -13.599999999999826, -80.80000000000004, -40.899999999999956, -139.0, 7.399999999999965, -149.8, 34.39999999999999, -325.59999999999997, 20.000000000000014, -229.30000000000004, -133.90000000000018, -56.80000000000007, -202.60000000000005, -209.50000000000003, 40.39999999999998, 11.599999999999978, -4.299999999999956, -57.70000000000003, -168.7, 20.000000000000014, -167.2, 20.000000000000014, -288.70000000000005, -302.1999999999998, -326.0999999999999, 4.1, -321.1, -362.5, 22.400000000000052, -133.9, 20.000000000000014, -293.79999999999995, -221.50000000000006, -179.8, -204.10000000000002, -200.8, 10.39999999999998, 36.20000000000026, -301.59999999999997, -72.70000000000059, -268.90000000000003, 20.000000000000014, 24.50000000000008, -7.899999999999999, 183.79999999999998, -106.0000000000008, -34.59999999999975, -139.60000000000002, -89.2000000000005, 20.000000000000014, -261.7, -178.00000000000003, 20.000000000000014, -244.60000000000002, -245.2, 20.000000000000014, -178.00000000000003, -179.8, -219.4, -255.10000000000014, -235.0, -220.9, -239.80000000000007, -239.5, -207.4, 20.000000000000014, 48.8000000000002, -121.90000000000002, 20.000000000000014, -263.20000000000016, -262.3, 20.000000000000014, -151.3, -298.6, -340.6, -345.69999999999976, 20.000000000000014, -48.69999999999989, 15.799999999999963, 20.000000000000014, 12.79999999999997, -278.5, -259.30000000000007, -307.0, -323.5, 20.000000000000014, 21.799999999999997, -135.40000000000003, 44.3000000000001, 28.100000000000158, 20.000000000000014, -171.7, 20.000000000000014, -302.5, -336.4, 20.000000000000014, 7.399999999999968, -288.70000000000005, -97.30000000000027, -106.90000000000005, -184.0, 5.599999999999975], "policy_predator_policy_reward": [0.0, 37.0, 29.0, 0.0, 46.0, 21.0, 0.0, 0.0, 12.0, 0.0, 83.0, 89.0, 0.0, 14.0, 43.0, 6.0, 30.0, 10.0, 83.0, 91.0, 103.0, 120.0, 63.0, 74.0, 67.0, 0.0, 0.0, 0.0, 37.0, 81.0, 7.0, 31.0, 0.0, 0.0, 54.0, 0.0, 406.0, 16.0, 496.0, 448.0, 0.0, 0.0, 116.0, 0.0, 118.0, 0.0, 0.0, 0.0, 0.0, 90.0, 60.0, 0.0, 51.0, 89.0, 18.0, 96.0, 67.0, 128.0, 109.0, 0.0, 68.0, 77.0, 173.0, 0.0, 56.0, 53.0, 36.0, 64.0, 55.0, 113.0, 0.0, 122.0, 131.0, 68.0, 51.0, 45.0, 40.0, 78.0, 102.0, 79.0, 15.0, 38.0, 105.0, 0.0, 57.0, 96.0, 152.0, 122.0, 0.0, 149.0, 137.0, 0.0, 106.0, 69.0, 322.0, 0.0, 0.0, 113.0, 48.0, 16.0, 29.0, 104.0, 122.0, 0.0, 117.0, 134.0, 107.0, 57.0, 58.0, 80.0, 0.0, 140.0, 4.0, 1.0, 37.0, 70.0, 60.0, 91.0, 77.0, 119.0, 179.0, 0.0, 26.0, 170.0, 73.0, 182.0, 115.0, 0.0, 164.0, 0.0, 0.0, 182.0, 141.0, 0.0, 0.0, 29.0, 105.0, 170.0, 90.0, 106.0, 45.0, 0.0, 59.0, 47.0, 107.0, 54.0, 67.0, 0.0, 146.0, 99.0, 135.0, 75.0, 137.0, 86.0, 110.0, 88.0, 167.0, 0.0, 116.0, 148.0, 163.0, 0.0, 74.0, 110.0, 104.0, 0.0, 101.0, 105.0, 107.0, 136.0, 145.0, 163.0, 160.0, 192.0, 33.0, 41.0, 0.0, 2.0, 140.0, 126.0, 152.0, 147.0, 0.0, 173.0, 71.0, 44.0, 2.0, 27.0, 0.0, 93.0, 122.0, 133.0, 142.0, 137.0, 142.0, 108.0, 54.0, 93.0, 104.0, 68.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6847908906631887, "mean_inference_ms": 1.5658393796407213, "mean_action_processing_ms": 0.26983926993185653, "mean_env_wait_ms": 0.2026511349872896, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006745815277099609, "StateBufferConnector_ms": 0.0033637285232543945, "ViewRequirementAgentConnector_ms": 0.12154412269592285}, "num_episodes": 22, "episode_return_max": 313.60000000000014, "episode_return_min": -428.6000000000001, "episode_return_mean": -36.693000000000005, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 432000, "num_agent_steps_trained": 432000, "num_env_steps_sampled": 108000, "num_env_steps_trained": 108000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 78.75404028209083, "num_env_steps_trained_throughput_per_sec": 78.75404028209083, "timesteps_total": 108000, "num_env_steps_sampled_lifetime": 108000, "num_agent_steps_sampled_lifetime": 432000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 432000, "timers": {"training_iteration_time_ms": 50888.593, "restore_workers_time_ms": 0.013, "training_step_time_ms": 50888.539, "sample_time_ms": 1246.338, "learn_time_ms": 49627.483, "learn_throughput": 80.601, "synch_weights_time_ms": 10.955}, "counters": {"num_env_steps_sampled": 108000, "num_env_steps_trained": 108000, "num_agent_steps_sampled": 432000, "num_agent_steps_trained": 432000}, "done": false, "training_iteration": 27, "trial_id": "11e70_00000", "date": "2024-08-12_23-30-11", "timestamp": 1723519811, "time_this_iter_s": 50.82705593109131, "time_total_s": 1391.994707584381, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2b67b80>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1391.994707584381, "iterations_since_restore": 27, "perf": {"cpu_util_percent": 36.358333333333334, "ram_util_percent": 82.68611111111112}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 9.819093929522882, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.624945917835942, "policy_loss": -0.010240164899548132, "vf_loss": 5.633745719263794, "vf_explained_var": 0.10504642731298215, "kl": 0.009602336742629449, "entropy": 1.3730012478651823, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 51975.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.4684612091886935, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.962845265171516, "policy_loss": -0.011548688970309086, "vf_loss": 5.972692534027907, "vf_explained_var": -0.18965266022101912, "kl": 0.011342837240951172, "entropy": 1.3232687862461836, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 51975.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 112000, "num_env_steps_trained": 112000, "num_agent_steps_sampled": 448000, "num_agent_steps_trained": 448000}, "env_runners": {"episode_reward_max": 183.7999999999994, "episode_reward_min": -428.6000000000001, "episode_reward_mean": -62.94500000000001, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -459.9999999999991, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 183.79999999999998, "predator_policy": 322.0}, "policy_reward_mean": {"prey_policy": -108.38250000000004, "predator_policy": 76.91}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.90000000000031, 49.89999999999972, 23.50000000000012, 64.50000000000014, 7.000000000000007, -179.90000000000003, 50.89999999999998, -154.8999999999999, -328.4999999999999, 47.90000000000014, -4.2999999999999865, -22.09999999999995, -117.90000000000003, -121.00000000000006, 53.20000000000012, 37.10000000000002, 2.9000000000001394, 8.700000000000182, 46.60000000000008, -47.00000000000005, -303.7000000000001, -84.30000000000001, -105.90000000000005, -72.09999999999994, -118.00000000000081, -67.8000000000002, -30.400000000000034, -46.89999999999993, -20.3999999999999, -40.199999999999854, -45.29999999999988, -52.69999999999999, -272.0999999999997, 57.00000000000019, 45.000000000000064, 2.300000000000149, 48.80000000000027, -411.89999999999986, -126.00000000000034, -428.6000000000001, 3.5000000000002025, -109.80000000000041, -219.3, -263.90000000000003, 75.59999999999937, -99.30000000000044, -52.89999999999985, 61.600000000000115, 183.7999999999994, -13.199999999999882, -2.199999999999936, -194.7000000000001, -14.599999999999916, -2.1999999999999265, -159.8, -307.4999999999999, -191.9, -316.30000000000007, -3.3999999999998938, 30.900000000000148, -37.19999999999985, 0.7000000000002005, -141.9, -334.2999999999998, 45.300000000000246, 37.80000000000027, 0.30000000000001936, -267.30000000000007, -130.50000000000037, 1.4000000000000057, 101.39999999999932, -58.699999999999996, -27.499999999999957, -37.399999999999785, -31.299999999999834, -57.19999999999998, -6.39999999999983, -271.29999999999995, 64.30000000000048, -114.10000000000002, -30.999999999999957, 13.600000000000131, 73.29999999999998, -27.299999999999926, 105.19999999999966, 140.29999999999927, 49.39999999999989, -138.10000000000002, 21.4, -201.000000000001, 24.60000000000005, -177.09999999999994, 5.399999999999942, 26.90000000000009, -310.0, -11.999999999999924, -253.2000000000002, -74.10000000000034, 53.70000000000015, -109.30000000000021], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 20.900000000000027, -70.9, 30.800000000000196, -56.5, 20.000000000000014, -82.89999999999998, 7.399999999999965, -24.39999999999999, -82.60000000000002, -202.9, -172.00000000000003, -31.899999999999977, -26.19999999999999, -186.70000000000013, -113.20000000000002, -187.90000000000003, -313.5999999999999, -91.30000000000025, 30.200000000000003, -124.3, 20.000000000000014, 17.899999999999988, -208.0, -147.7, -92.19999999999999, -174.1, -145.90000000000006, -87.09999999999997, 44.3, -85.89999999999998, 4.999999999999972, 20.000000000000014, -198.10000000000005, -64.30000000000005, 20.000000000000014, -49.00000000000001, -9.400000000000011, -119.20000000000005, -80.80000000000084, -337.9, -239.80000000000004, 20.000000000000014, -253.30000000000004, -220.60000000000008, -22.299999999999997, -267.1, 20.000000000000014, -459.9999999999991, 20.000000000000014, -119.50000000000001, -61.300000000000026, -13.599999999999826, -80.80000000000004, -40.899999999999956, -139.0, 7.399999999999965, -149.8, 34.39999999999999, -325.59999999999997, 20.000000000000014, -229.30000000000004, -133.90000000000018, -56.80000000000007, -202.60000000000005, -209.50000000000003, 40.39999999999998, 11.599999999999978, -4.299999999999956, -57.70000000000003, -168.7, 20.000000000000014, -167.2, 20.000000000000014, -288.70000000000005, -302.1999999999998, -326.0999999999999, 4.1, -321.1, -362.5, 22.400000000000052, -133.9, 20.000000000000014, -293.79999999999995, -221.50000000000006, -179.8, -204.10000000000002, -200.8, 10.39999999999998, 36.20000000000026, -301.59999999999997, -72.70000000000059, -268.90000000000003, 20.000000000000014, 24.50000000000008, -7.899999999999999, 183.79999999999998, -106.0000000000008, -34.59999999999975, -139.60000000000002, -89.2000000000005, 20.000000000000014, -261.7, -178.00000000000003, 20.000000000000014, -244.60000000000002, -245.2, 20.000000000000014, -178.00000000000003, -179.8, -219.4, -255.10000000000014, -235.0, -220.9, -239.80000000000007, -239.5, -207.4, 20.000000000000014, 48.8000000000002, -121.90000000000002, 20.000000000000014, -263.20000000000016, -262.3, 20.000000000000014, -151.3, -298.6, -340.6, -345.69999999999976, 20.000000000000014, -48.69999999999989, 15.799999999999963, 20.000000000000014, 12.79999999999997, -278.5, -259.30000000000007, -307.0, -323.5, 20.000000000000014, 21.799999999999997, -135.40000000000003, 44.3000000000001, 28.100000000000158, 20.000000000000014, -171.7, 20.000000000000014, -302.5, -336.4, 20.000000000000014, 7.399999999999968, -288.70000000000005, -97.30000000000027, -106.90000000000005, -184.0, 5.599999999999975, -154.30000000000004, -283.0, 20.000000000000014, 44.300000000000246, -151.00000000000006, -204.10000000000005, -14.49999999999995, -95.50000000000017, -102.40000000000006, 20.000000000000014, 2.299999999999991, -34.000000000000156, 20.000000000000014, -250.3, 36.20000000000001, -1.0000000000000142, 78.49999999999984, 27.80000000000016, 71.89999999999962, -128.5, -125.20000000000002, -253.9, 24.50000000000008, -24.099999999999746, -250.49999999999994, -179.50000000000057, -9.399999999999855, 20.000000000000014, -177.70000000000005, -141.4, -198.70000000000005, 13.099999999999968, 17.899999999999988, -0.9999999999999952, -259.0, -340.0, -148.0, 20.000000000000014, -225.40000000000003, -332.8000000000002, -3.0999999999999863, -325.00000000000006, -58.299999999999955, 20.000000000000014, -9.399999999999869, -274.9], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 90.0, 60.0, 0.0, 51.0, 89.0, 18.0, 96.0, 67.0, 128.0, 109.0, 0.0, 68.0, 77.0, 173.0, 0.0, 56.0, 53.0, 36.0, 64.0, 55.0, 113.0, 0.0, 122.0, 131.0, 68.0, 51.0, 45.0, 40.0, 78.0, 102.0, 79.0, 15.0, 38.0, 105.0, 0.0, 57.0, 96.0, 152.0, 122.0, 0.0, 149.0, 137.0, 0.0, 106.0, 69.0, 322.0, 0.0, 0.0, 113.0, 48.0, 16.0, 29.0, 104.0, 122.0, 0.0, 117.0, 134.0, 107.0, 57.0, 58.0, 80.0, 0.0, 140.0, 4.0, 1.0, 37.0, 70.0, 60.0, 91.0, 77.0, 119.0, 179.0, 0.0, 26.0, 170.0, 73.0, 182.0, 115.0, 0.0, 164.0, 0.0, 0.0, 182.0, 141.0, 0.0, 0.0, 29.0, 105.0, 170.0, 90.0, 106.0, 45.0, 0.0, 59.0, 47.0, 107.0, 54.0, 67.0, 0.0, 146.0, 99.0, 135.0, 75.0, 137.0, 86.0, 110.0, 88.0, 167.0, 0.0, 116.0, 148.0, 163.0, 0.0, 74.0, 110.0, 104.0, 0.0, 101.0, 105.0, 107.0, 136.0, 145.0, 163.0, 160.0, 192.0, 33.0, 41.0, 0.0, 2.0, 140.0, 126.0, 152.0, 147.0, 0.0, 173.0, 71.0, 44.0, 2.0, 27.0, 0.0, 93.0, 122.0, 133.0, 142.0, 137.0, 142.0, 108.0, 54.0, 93.0, 104.0, 68.0, 166.0, 0.0, 0.0, 0.0, 130.0, 111.0, 21.0, 58.0, 96.0, 0.0, 42.0, 63.0, 105.0, 98.0, 40.0, 30.0, 12.0, 22.0, 106.0, 0.0, 75.0, 166.0, 0.0, 21.0, 95.0, 134.0, 14.0, 0.0, 0.0, 142.0, 115.0, 76.0, 0.0, 10.0, 111.0, 178.0, 116.0, 0.0, 137.0, 168.0, 131.0, 123.0, 54.0, 38.0, 0.0, 175.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6836186702095898, "mean_inference_ms": 1.5888621585248461, "mean_action_processing_ms": 0.2684731305621696, "mean_env_wait_ms": 0.20213802051107355, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01018667221069336, "StateBufferConnector_ms": 0.0033004283905029297, "ViewRequirementAgentConnector_ms": 0.09888756275177002}, "num_episodes": 23, "episode_return_max": 183.7999999999994, "episode_return_min": -428.6000000000001, "episode_return_mean": -62.94500000000001, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 448000, "num_agent_steps_trained": 448000, "num_env_steps_sampled": 112000, "num_env_steps_trained": 112000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 76.1331342222854, "num_env_steps_trained_throughput_per_sec": 76.1331342222854, "timesteps_total": 112000, "num_env_steps_sampled_lifetime": 112000, "num_agent_steps_sampled_lifetime": 448000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 448000, "timers": {"training_iteration_time_ms": 51102.075, "restore_workers_time_ms": 0.012, "training_step_time_ms": 51102.021, "sample_time_ms": 1394.966, "learn_time_ms": 49692.661, "learn_throughput": 80.495, "synch_weights_time_ms": 10.881}, "counters": {"num_env_steps_sampled": 112000, "num_env_steps_trained": 112000, "num_agent_steps_sampled": 448000, "num_agent_steps_trained": 448000}, "done": false, "training_iteration": 28, "trial_id": "11e70_00000", "date": "2024-08-12_23-31-04", "timestamp": 1723519864, "time_this_iter_s": 52.582016706466675, "time_total_s": 1444.5767242908478, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2b61700>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1444.5767242908478, "iterations_since_restore": 28, "perf": {"cpu_util_percent": 39.06133333333333, "ram_util_percent": 83.20666666666666}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 8.00639273968954, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.3852257493942504, "policy_loss": -0.008475280276908682, "vf_loss": 3.392540904138454, "vf_explained_var": 0.15236663682750923, "kl": 0.007734160422777769, "entropy": 1.3771429027829851, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 53865.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.581721623265554, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.884731767795704, "policy_loss": -0.01792722959551842, "vf_loss": 3.900877177652228, "vf_explained_var": -0.2325783472843271, "kl": 0.011878771368177995, "entropy": 1.2999853614776853, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 53865.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 116000, "num_env_steps_trained": 116000, "num_agent_steps_sampled": 464000, "num_agent_steps_trained": 464000}, "env_runners": {"episode_reward_max": 183.7999999999994, "episode_reward_min": -428.6000000000001, "episode_reward_mean": -55.03000000000004, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -459.9999999999991, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 183.79999999999998, "predator_policy": 322.0}, "policy_reward_mean": {"prey_policy": -101.7, "predator_policy": 74.185}, "custom_metrics": {}, "hist_stats": {"episode_reward": [46.60000000000008, -47.00000000000005, -303.7000000000001, -84.30000000000001, -105.90000000000005, -72.09999999999994, -118.00000000000081, -67.8000000000002, -30.400000000000034, -46.89999999999993, -20.3999999999999, -40.199999999999854, -45.29999999999988, -52.69999999999999, -272.0999999999997, 57.00000000000019, 45.000000000000064, 2.300000000000149, 48.80000000000027, -411.89999999999986, -126.00000000000034, -428.6000000000001, 3.5000000000002025, -109.80000000000041, -219.3, -263.90000000000003, 75.59999999999937, -99.30000000000044, -52.89999999999985, 61.600000000000115, 183.7999999999994, -13.199999999999882, -2.199999999999936, -194.7000000000001, -14.599999999999916, -2.1999999999999265, -159.8, -307.4999999999999, -191.9, -316.30000000000007, -3.3999999999998938, 30.900000000000148, -37.19999999999985, 0.7000000000002005, -141.9, -334.2999999999998, 45.300000000000246, 37.80000000000027, 0.30000000000001936, -267.30000000000007, -130.50000000000037, 1.4000000000000057, 101.39999999999932, -58.699999999999996, -27.499999999999957, -37.399999999999785, -31.299999999999834, -57.19999999999998, -6.39999999999983, -271.29999999999995, 64.30000000000048, -114.10000000000002, -30.999999999999957, 13.600000000000131, 73.29999999999998, -27.299999999999926, 105.19999999999966, 140.29999999999927, 49.39999999999989, -138.10000000000002, 21.4, -201.000000000001, 24.60000000000005, -177.09999999999994, 5.399999999999942, 26.90000000000009, -310.0, -11.999999999999924, -253.2000000000002, -74.10000000000034, 53.70000000000015, -109.30000000000021, -15.299999999999926, 52.10000000000003, -179.5, -41.39999999999978, 37.80000000000027, 71.29999999999964, -41.200000000000074, -84.69999999999999, 24.400000000000052, 83.19999999999906, -140.8, 53.50000000000029, 88.89999999999863, 111.09999999999927, 61.60000000000051, 58.70000000000042, 63.10000000000038, 46.600000000000406], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-49.00000000000001, -9.400000000000011, -119.20000000000005, -80.80000000000084, -337.9, -239.80000000000004, 20.000000000000014, -253.30000000000004, -220.60000000000008, -22.299999999999997, -267.1, 20.000000000000014, -459.9999999999991, 20.000000000000014, -119.50000000000001, -61.300000000000026, -13.599999999999826, -80.80000000000004, -40.899999999999956, -139.0, 7.399999999999965, -149.8, 34.39999999999999, -325.59999999999997, 20.000000000000014, -229.30000000000004, -133.90000000000018, -56.80000000000007, -202.60000000000005, -209.50000000000003, 40.39999999999998, 11.599999999999978, -4.299999999999956, -57.70000000000003, -168.7, 20.000000000000014, -167.2, 20.000000000000014, -288.70000000000005, -302.1999999999998, -326.0999999999999, 4.1, -321.1, -362.5, 22.400000000000052, -133.9, 20.000000000000014, -293.79999999999995, -221.50000000000006, -179.8, -204.10000000000002, -200.8, 10.39999999999998, 36.20000000000026, -301.59999999999997, -72.70000000000059, -268.90000000000003, 20.000000000000014, 24.50000000000008, -7.899999999999999, 183.79999999999998, -106.0000000000008, -34.59999999999975, -139.60000000000002, -89.2000000000005, 20.000000000000014, -261.7, -178.00000000000003, 20.000000000000014, -244.60000000000002, -245.2, 20.000000000000014, -178.00000000000003, -179.8, -219.4, -255.10000000000014, -235.0, -220.9, -239.80000000000007, -239.5, -207.4, 20.000000000000014, 48.8000000000002, -121.90000000000002, 20.000000000000014, -263.20000000000016, -262.3, 20.000000000000014, -151.3, -298.6, -340.6, -345.69999999999976, 20.000000000000014, -48.69999999999989, 15.799999999999963, 20.000000000000014, 12.79999999999997, -278.5, -259.30000000000007, -307.0, -323.5, 20.000000000000014, 21.799999999999997, -135.40000000000003, 44.3000000000001, 28.100000000000158, 20.000000000000014, -171.7, 20.000000000000014, -302.5, -336.4, 20.000000000000014, 7.399999999999968, -288.70000000000005, -97.30000000000027, -106.90000000000005, -184.0, 5.599999999999975, -154.30000000000004, -283.0, 20.000000000000014, 44.300000000000246, -151.00000000000006, -204.10000000000005, -14.49999999999995, -95.50000000000017, -102.40000000000006, 20.000000000000014, 2.299999999999991, -34.000000000000156, 20.000000000000014, -250.3, 36.20000000000001, -1.0000000000000142, 78.49999999999984, 27.80000000000016, 71.89999999999962, -128.5, -125.20000000000002, -253.9, 24.50000000000008, -24.099999999999746, -250.49999999999994, -179.50000000000057, -9.399999999999855, 20.000000000000014, -177.70000000000005, -141.4, -198.70000000000005, 13.099999999999968, 17.899999999999988, -0.9999999999999952, -259.0, -340.0, -148.0, 20.000000000000014, -225.40000000000003, -332.8000000000002, -3.0999999999999863, -325.00000000000006, -58.299999999999955, 20.000000000000014, -9.399999999999869, -274.9, 8.6, -289.9, 7.399999999999965, -64.29999999999991, -124.0, -215.50000000000003, 30.20000000000019, -292.6, 15.799999999999963, 20.000000000000014, 25.400000000000098, -27.099999999999994, 63.499999999999986, -255.70000000000005, -84.1, -268.6, -0.7000000000000169, 1.0999999999999865, 63.200000000000195, 20.000000000000014, -50.5, -271.3, 33.50000000000014, 20.000000000000014, -33.0999999999998, 65.00000000000013, 20.000000000000014, 91.09999999999971, 41.60000000000025, 20.000000000000014, 28.700000000000177, 20.000000000000014, -58.9000000000001, 20.000000000000014, 23.60000000000007, 20.000000000000014], "policy_predator_policy_reward": [105.0, 0.0, 57.0, 96.0, 152.0, 122.0, 0.0, 149.0, 137.0, 0.0, 106.0, 69.0, 322.0, 0.0, 0.0, 113.0, 48.0, 16.0, 29.0, 104.0, 122.0, 0.0, 117.0, 134.0, 107.0, 57.0, 58.0, 80.0, 0.0, 140.0, 4.0, 1.0, 37.0, 70.0, 60.0, 91.0, 77.0, 119.0, 179.0, 0.0, 26.0, 170.0, 73.0, 182.0, 115.0, 0.0, 164.0, 0.0, 0.0, 182.0, 141.0, 0.0, 0.0, 29.0, 105.0, 170.0, 90.0, 106.0, 45.0, 0.0, 59.0, 47.0, 107.0, 54.0, 67.0, 0.0, 146.0, 99.0, 135.0, 75.0, 137.0, 86.0, 110.0, 88.0, 167.0, 0.0, 116.0, 148.0, 163.0, 0.0, 74.0, 110.0, 104.0, 0.0, 101.0, 105.0, 107.0, 136.0, 145.0, 163.0, 160.0, 192.0, 33.0, 41.0, 0.0, 2.0, 140.0, 126.0, 152.0, 147.0, 0.0, 173.0, 71.0, 44.0, 2.0, 27.0, 0.0, 93.0, 122.0, 133.0, 142.0, 137.0, 142.0, 108.0, 54.0, 93.0, 104.0, 68.0, 166.0, 0.0, 0.0, 0.0, 130.0, 111.0, 21.0, 58.0, 96.0, 0.0, 42.0, 63.0, 105.0, 98.0, 40.0, 30.0, 12.0, 22.0, 106.0, 0.0, 75.0, 166.0, 0.0, 21.0, 95.0, 134.0, 14.0, 0.0, 0.0, 142.0, 115.0, 76.0, 0.0, 10.0, 111.0, 178.0, 116.0, 0.0, 137.0, 168.0, 131.0, 123.0, 54.0, 38.0, 0.0, 175.0, 134.0, 132.0, 61.0, 48.0, 160.0, 0.0, 147.0, 74.0, 0.0, 2.0, 73.0, 0.0, 0.0, 151.0, 135.0, 133.0, 12.0, 12.0, 0.0, 0.0, 181.0, 0.0, 0.0, 0.0, 31.0, 26.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 58.0, 44.0, 3.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6829935407630643, "mean_inference_ms": 1.607311415419491, "mean_action_processing_ms": 0.2679783522561065, "mean_env_wait_ms": 0.20190570212879966, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.009807348251342773, "StateBufferConnector_ms": 0.0033844709396362305, "ViewRequirementAgentConnector_ms": 0.10908639430999756}, "num_episodes": 18, "episode_return_max": 183.7999999999994, "episode_return_min": -428.6000000000001, "episode_return_mean": -55.03000000000004, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 464000, "num_agent_steps_trained": 464000, "num_env_steps_sampled": 116000, "num_env_steps_trained": 116000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 77.34797480556665, "num_env_steps_trained_throughput_per_sec": 77.34797480556665, "timesteps_total": 116000, "num_env_steps_sampled_lifetime": 116000, "num_agent_steps_sampled_lifetime": 464000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 464000, "timers": {"training_iteration_time_ms": 51162.059, "restore_workers_time_ms": 0.013, "training_step_time_ms": 51162.004, "sample_time_ms": 1375.993, "learn_time_ms": 49771.451, "learn_throughput": 80.367, "synch_weights_time_ms": 10.927}, "counters": {"num_env_steps_sampled": 116000, "num_env_steps_trained": 116000, "num_agent_steps_sampled": 464000, "num_agent_steps_trained": 464000}, "done": false, "training_iteration": 29, "trial_id": "11e70_00000", "date": "2024-08-12_23-31-56", "timestamp": 1723519916, "time_this_iter_s": 51.768059968948364, "time_total_s": 1496.3447842597961, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2b93af0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1496.3447842597961, "iterations_since_restore": 29, "perf": {"cpu_util_percent": 36.93150684931506, "ram_util_percent": 83.26575342465755}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 6.02512079679146, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.1077383375672436, "policy_loss": -0.007900876493474084, "vf_loss": 1.1143994458611048, "vf_explained_var": 0.11923811009952, "kl": 0.00826512954268496, "entropy": 1.3751492516704338, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 55755.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.220628144532915, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.5784777900529288, "policy_loss": -0.020598644657163986, "vf_loss": 2.597202024447224, "vf_explained_var": 0.21796657471429734, "kl": 0.012496134890526105, "entropy": 1.2925641098350444, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 55755.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 120000, "num_env_steps_trained": 120000, "num_agent_steps_sampled": 480000, "num_agent_steps_trained": 480000}, "env_runners": {"episode_reward_max": 257.79999999999995, "episode_reward_min": -428.6000000000001, "episode_reward_mean": -29.167000000000034, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -362.5, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 185.60000000000002, "predator_policy": 192.0}, "policy_reward_mean": {"prey_policy": -77.65350000000002, "predator_policy": 63.07}, "custom_metrics": {}, "hist_stats": {"episode_reward": [48.80000000000027, -411.89999999999986, -126.00000000000034, -428.6000000000001, 3.5000000000002025, -109.80000000000041, -219.3, -263.90000000000003, 75.59999999999937, -99.30000000000044, -52.89999999999985, 61.600000000000115, 183.7999999999994, -13.199999999999882, -2.199999999999936, -194.7000000000001, -14.599999999999916, -2.1999999999999265, -159.8, -307.4999999999999, -191.9, -316.30000000000007, -3.3999999999998938, 30.900000000000148, -37.19999999999985, 0.7000000000002005, -141.9, -334.2999999999998, 45.300000000000246, 37.80000000000027, 0.30000000000001936, -267.30000000000007, -130.50000000000037, 1.4000000000000057, 101.39999999999932, -58.699999999999996, -27.499999999999957, -37.399999999999785, -31.299999999999834, -57.19999999999998, -6.39999999999983, -271.29999999999995, 64.30000000000048, -114.10000000000002, -30.999999999999957, 13.600000000000131, 73.29999999999998, -27.299999999999926, 105.19999999999966, 140.29999999999927, 49.39999999999989, -138.10000000000002, 21.4, -201.000000000001, 24.60000000000005, -177.09999999999994, 5.399999999999942, 26.90000000000009, -310.0, -11.999999999999924, -253.2000000000002, -74.10000000000034, 53.70000000000015, -109.30000000000021, -15.299999999999926, 52.10000000000003, -179.5, -41.39999999999978, 37.80000000000027, 71.29999999999964, -41.200000000000074, -84.69999999999999, 24.400000000000052, 83.19999999999906, -140.8, 53.50000000000029, 88.89999999999863, 111.09999999999927, 61.60000000000051, 58.70000000000042, 63.10000000000038, 46.600000000000406, 137.499999999999, 42.90000000000036, 40.0000000000003, -0.6999999999998354, 118.29999999999899, 40.0000000000003, 53.000000000000306, 49.000000000000455, 99.69999999999989, 55.50000000000036, 26.800000000000097, 40.0000000000003, 109.69999999999874, 226.89999999999984, 15.799999999999939, 63.80000000000041, 54.40000000000053, 257.79999999999995], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-167.2, 20.000000000000014, -288.70000000000005, -302.1999999999998, -326.0999999999999, 4.1, -321.1, -362.5, 22.400000000000052, -133.9, 20.000000000000014, -293.79999999999995, -221.50000000000006, -179.8, -204.10000000000002, -200.8, 10.39999999999998, 36.20000000000026, -301.59999999999997, -72.70000000000059, -268.90000000000003, 20.000000000000014, 24.50000000000008, -7.899999999999999, 183.79999999999998, -106.0000000000008, -34.59999999999975, -139.60000000000002, -89.2000000000005, 20.000000000000014, -261.7, -178.00000000000003, 20.000000000000014, -244.60000000000002, -245.2, 20.000000000000014, -178.00000000000003, -179.8, -219.4, -255.10000000000014, -235.0, -220.9, -239.80000000000007, -239.5, -207.4, 20.000000000000014, 48.8000000000002, -121.90000000000002, 20.000000000000014, -263.20000000000016, -262.3, 20.000000000000014, -151.3, -298.6, -340.6, -345.69999999999976, 20.000000000000014, -48.69999999999989, 15.799999999999963, 20.000000000000014, 12.79999999999997, -278.5, -259.30000000000007, -307.0, -323.5, 20.000000000000014, 21.799999999999997, -135.40000000000003, 44.3000000000001, 28.100000000000158, 20.000000000000014, -171.7, 20.000000000000014, -302.5, -336.4, 20.000000000000014, 7.399999999999968, -288.70000000000005, -97.30000000000027, -106.90000000000005, -184.0, 5.599999999999975, -154.30000000000004, -283.0, 20.000000000000014, 44.300000000000246, -151.00000000000006, -204.10000000000005, -14.49999999999995, -95.50000000000017, -102.40000000000006, 20.000000000000014, 2.299999999999991, -34.000000000000156, 20.000000000000014, -250.3, 36.20000000000001, -1.0000000000000142, 78.49999999999984, 27.80000000000016, 71.89999999999962, -128.5, -125.20000000000002, -253.9, 24.50000000000008, -24.099999999999746, -250.49999999999994, -179.50000000000057, -9.399999999999855, 20.000000000000014, -177.70000000000005, -141.4, -198.70000000000005, 13.099999999999968, 17.899999999999988, -0.9999999999999952, -259.0, -340.0, -148.0, 20.000000000000014, -225.40000000000003, -332.8000000000002, -3.0999999999999863, -325.00000000000006, -58.299999999999955, 20.000000000000014, -9.399999999999869, -274.9, 8.6, -289.9, 7.399999999999965, -64.29999999999991, -124.0, -215.50000000000003, 30.20000000000019, -292.6, 15.799999999999963, 20.000000000000014, 25.400000000000098, -27.099999999999994, 63.499999999999986, -255.70000000000005, -84.1, -268.6, -0.7000000000000169, 1.0999999999999865, 63.200000000000195, 20.000000000000014, -50.5, -271.3, 33.50000000000014, 20.000000000000014, -33.0999999999998, 65.00000000000013, 20.000000000000014, 91.09999999999971, 41.60000000000025, 20.000000000000014, 28.700000000000177, 20.000000000000014, -58.9000000000001, 20.000000000000014, 23.60000000000007, 20.000000000000014, 20.000000000000014, 87.49999999999976, 20.000000000000014, 5.900000000000011, 20.000000000000014, 20.000000000000014, -60.400000000000574, 13.699999999999966, 20.000000000000014, 98.29999999999957, 20.000000000000014, 20.000000000000014, 20.000000000000014, -27.999999999999886, 20.000000000000014, 29.000000000000174, 75.49999999999945, -65.80000000000001, 11.29999999999998, 12.199999999999974, 7.399999999999965, 7.399999999999982, 20.000000000000014, 20.000000000000014, 82.69999999999939, 20.000000000000014, 185.60000000000002, -84.70000000000019, 5.299999999999947, -11.499999999999819, 23.600000000000076, 3.1999999999999793, 29.90000000000018, 24.500000000000085, 150.4999999999997, 107.29999999999973], "policy_predator_policy_reward": [77.0, 119.0, 179.0, 0.0, 26.0, 170.0, 73.0, 182.0, 115.0, 0.0, 164.0, 0.0, 0.0, 182.0, 141.0, 0.0, 0.0, 29.0, 105.0, 170.0, 90.0, 106.0, 45.0, 0.0, 59.0, 47.0, 107.0, 54.0, 67.0, 0.0, 146.0, 99.0, 135.0, 75.0, 137.0, 86.0, 110.0, 88.0, 167.0, 0.0, 116.0, 148.0, 163.0, 0.0, 74.0, 110.0, 104.0, 0.0, 101.0, 105.0, 107.0, 136.0, 145.0, 163.0, 160.0, 192.0, 33.0, 41.0, 0.0, 2.0, 140.0, 126.0, 152.0, 147.0, 0.0, 173.0, 71.0, 44.0, 2.0, 27.0, 0.0, 93.0, 122.0, 133.0, 142.0, 137.0, 142.0, 108.0, 54.0, 93.0, 104.0, 68.0, 166.0, 0.0, 0.0, 0.0, 130.0, 111.0, 21.0, 58.0, 96.0, 0.0, 42.0, 63.0, 105.0, 98.0, 40.0, 30.0, 12.0, 22.0, 106.0, 0.0, 75.0, 166.0, 0.0, 21.0, 95.0, 134.0, 14.0, 0.0, 0.0, 142.0, 115.0, 76.0, 0.0, 10.0, 111.0, 178.0, 116.0, 0.0, 137.0, 168.0, 131.0, 123.0, 54.0, 38.0, 0.0, 175.0, 134.0, 132.0, 61.0, 48.0, 160.0, 0.0, 147.0, 74.0, 0.0, 2.0, 73.0, 0.0, 0.0, 151.0, 135.0, 133.0, 12.0, 12.0, 0.0, 0.0, 181.0, 0.0, 0.0, 0.0, 31.0, 26.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 58.0, 44.0, 3.0, 0.0, 17.0, 13.0, 17.0, 0.0, 0.0, 0.0, 35.0, 11.0, 0.0, 0.0, 0.0, 0.0, 16.0, 45.0, 0.0, 0.0, 0.0, 90.0, 27.0, 5.0, 6.0, 6.0, 0.0, 0.0, 7.0, 0.0, 58.0, 68.0, 15.0, 7.0, 14.0, 23.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6821304842684244, "mean_inference_ms": 1.6248222721813617, "mean_action_processing_ms": 0.26764054740500937, "mean_env_wait_ms": 0.20161026384568906, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.009269118309020996, "StateBufferConnector_ms": 0.0033565759658813477, "ViewRequirementAgentConnector_ms": 0.11419105529785156}, "num_episodes": 18, "episode_return_max": 257.79999999999995, "episode_return_min": -428.6000000000001, "episode_return_mean": -29.167000000000034, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 480000, "num_agent_steps_trained": 480000, "num_env_steps_sampled": 120000, "num_env_steps_trained": 120000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 76.57614284530699, "num_env_steps_trained_throughput_per_sec": 76.57614284530699, "timesteps_total": 120000, "num_env_steps_sampled_lifetime": 120000, "num_agent_steps_sampled_lifetime": 480000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 480000, "timers": {"training_iteration_time_ms": 51318.904, "restore_workers_time_ms": 0.013, "training_step_time_ms": 51318.848, "sample_time_ms": 1381.233, "learn_time_ms": 49922.777, "learn_throughput": 80.124, "synch_weights_time_ms": 11.172}, "counters": {"num_env_steps_sampled": 120000, "num_env_steps_trained": 120000, "num_agent_steps_sampled": 480000, "num_agent_steps_trained": 480000}, "done": false, "training_iteration": 30, "trial_id": "11e70_00000", "date": "2024-08-12_23-32-48", "timestamp": 1723519968, "time_this_iter_s": 52.27495718002319, "time_total_s": 1548.6197414398193, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2b93940>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1548.6197414398193, "iterations_since_restore": 30, "perf": {"cpu_util_percent": 36.41621621621622, "ram_util_percent": 83.17297297297297}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.5666600555339185, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.0183039262969658, "policy_loss": -0.009120960034203356, "vf_loss": 1.02657810411756, "vf_explained_var": 0.16340738421394713, "kl": 0.005645212344890177, "entropy": 1.3645247036817842, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 57645.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.623615572566078, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.780863127380452, "policy_loss": -0.010955220838717958, "vf_loss": 3.7905700881645163, "vf_explained_var": 0.24499857958662447, "kl": 0.008321725135971443, "entropy": 1.2979992228210289, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 57645.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 124000, "num_env_steps_trained": 124000, "num_agent_steps_sampled": 496000, "num_agent_steps_trained": 496000}, "env_runners": {"episode_reward_max": 257.79999999999995, "episode_reward_min": -334.2999999999998, "episode_reward_mean": 1.2719999999999607, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -345.69999999999976, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 185.60000000000002, "predator_policy": 192.0}, "policy_reward_mean": {"prey_policy": -48.854000000000006, "predator_policy": 49.49}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-159.8, -307.4999999999999, -191.9, -316.30000000000007, -3.3999999999998938, 30.900000000000148, -37.19999999999985, 0.7000000000002005, -141.9, -334.2999999999998, 45.300000000000246, 37.80000000000027, 0.30000000000001936, -267.30000000000007, -130.50000000000037, 1.4000000000000057, 101.39999999999932, -58.699999999999996, -27.499999999999957, -37.399999999999785, -31.299999999999834, -57.19999999999998, -6.39999999999983, -271.29999999999995, 64.30000000000048, -114.10000000000002, -30.999999999999957, 13.600000000000131, 73.29999999999998, -27.299999999999926, 105.19999999999966, 140.29999999999927, 49.39999999999989, -138.10000000000002, 21.4, -201.000000000001, 24.60000000000005, -177.09999999999994, 5.399999999999942, 26.90000000000009, -310.0, -11.999999999999924, -253.2000000000002, -74.10000000000034, 53.70000000000015, -109.30000000000021, -15.299999999999926, 52.10000000000003, -179.5, -41.39999999999978, 37.80000000000027, 71.29999999999964, -41.200000000000074, -84.69999999999999, 24.400000000000052, 83.19999999999906, -140.8, 53.50000000000029, 88.89999999999863, 111.09999999999927, 61.60000000000051, 58.70000000000042, 63.10000000000038, 46.600000000000406, 137.499999999999, 42.90000000000036, 40.0000000000003, -0.6999999999998354, 118.29999999999899, 40.0000000000003, 53.000000000000306, 49.000000000000455, 99.69999999999989, 55.50000000000036, 26.800000000000097, 40.0000000000003, 109.69999999999874, 226.89999999999984, 15.799999999999939, 63.80000000000041, 54.40000000000053, 257.79999999999995, 38.90000000000028, 37.80000000000027, 30.100000000000147, 139.29999999999907, 158.79999999999922, 185.19999999999916, 40.0000000000003, 40.0000000000003, 87.39999999999975, 56.80000000000045, 115.29999999999887, 49.90000000000046, 18.299999999999958, 132.59999999999957, 30.400000000000134, 40.0000000000003, 40.0000000000003, 237.79999999999944], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-178.00000000000003, -179.8, -219.4, -255.10000000000014, -235.0, -220.9, -239.80000000000007, -239.5, -207.4, 20.000000000000014, 48.8000000000002, -121.90000000000002, 20.000000000000014, -263.20000000000016, -262.3, 20.000000000000014, -151.3, -298.6, -340.6, -345.69999999999976, 20.000000000000014, -48.69999999999989, 15.799999999999963, 20.000000000000014, 12.79999999999997, -278.5, -259.30000000000007, -307.0, -323.5, 20.000000000000014, 21.799999999999997, -135.40000000000003, 44.3000000000001, 28.100000000000158, 20.000000000000014, -171.7, 20.000000000000014, -302.5, -336.4, 20.000000000000014, 7.399999999999968, -288.70000000000005, -97.30000000000027, -106.90000000000005, -184.0, 5.599999999999975, -154.30000000000004, -283.0, 20.000000000000014, 44.300000000000246, -151.00000000000006, -204.10000000000005, -14.49999999999995, -95.50000000000017, -102.40000000000006, 20.000000000000014, 2.299999999999991, -34.000000000000156, 20.000000000000014, -250.3, 36.20000000000001, -1.0000000000000142, 78.49999999999984, 27.80000000000016, 71.89999999999962, -128.5, -125.20000000000002, -253.9, 24.50000000000008, -24.099999999999746, -250.49999999999994, -179.50000000000057, -9.399999999999855, 20.000000000000014, -177.70000000000005, -141.4, -198.70000000000005, 13.099999999999968, 17.899999999999988, -0.9999999999999952, -259.0, -340.0, -148.0, 20.000000000000014, -225.40000000000003, -332.8000000000002, -3.0999999999999863, -325.00000000000006, -58.299999999999955, 20.000000000000014, -9.399999999999869, -274.9, 8.6, -289.9, 7.399999999999965, -64.29999999999991, -124.0, -215.50000000000003, 30.20000000000019, -292.6, 15.799999999999963, 20.000000000000014, 25.400000000000098, -27.099999999999994, 63.499999999999986, -255.70000000000005, -84.1, -268.6, -0.7000000000000169, 1.0999999999999865, 63.200000000000195, 20.000000000000014, -50.5, -271.3, 33.50000000000014, 20.000000000000014, -33.0999999999998, 65.00000000000013, 20.000000000000014, 91.09999999999971, 41.60000000000025, 20.000000000000014, 28.700000000000177, 20.000000000000014, -58.9000000000001, 20.000000000000014, 23.60000000000007, 20.000000000000014, 20.000000000000014, 87.49999999999976, 20.000000000000014, 5.900000000000011, 20.000000000000014, 20.000000000000014, -60.400000000000574, 13.699999999999966, 20.000000000000014, 98.29999999999957, 20.000000000000014, 20.000000000000014, 20.000000000000014, -27.999999999999886, 20.000000000000014, 29.000000000000174, 75.49999999999945, -65.80000000000001, 11.29999999999998, 12.199999999999974, 7.399999999999965, 7.399999999999982, 20.000000000000014, 20.000000000000014, 82.69999999999939, 20.000000000000014, 185.60000000000002, -84.70000000000019, 5.299999999999947, -11.499999999999819, 23.600000000000076, 3.1999999999999793, 29.90000000000018, 24.500000000000085, 150.4999999999997, 107.29999999999973, 20.000000000000014, 17.899999999999988, 20.000000000000014, 15.799999999999963, -7.899999999999924, 20.000000000000014, 20.000000000000014, 116.29999999999971, 119.89999999999972, 38.90000000000015, 129.79999999999995, 22.400000000000066, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 34.4000000000002, 44.00000000000019, -11.199999999999852, 29.000000000000163, 29.90000000000018, 79.3999999999995, 29.90000000000018, 20.000000000000014, 20.900000000000013, -43.59999999999982, 130.7, -30.099999999999795, -49.299999999999905, -4.299999999999962, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 102.49999999999994, 134.2999999999996], "policy_predator_policy_reward": [110.0, 88.0, 167.0, 0.0, 116.0, 148.0, 163.0, 0.0, 74.0, 110.0, 104.0, 0.0, 101.0, 105.0, 107.0, 136.0, 145.0, 163.0, 160.0, 192.0, 33.0, 41.0, 0.0, 2.0, 140.0, 126.0, 152.0, 147.0, 0.0, 173.0, 71.0, 44.0, 2.0, 27.0, 0.0, 93.0, 122.0, 133.0, 142.0, 137.0, 142.0, 108.0, 54.0, 93.0, 104.0, 68.0, 166.0, 0.0, 0.0, 0.0, 130.0, 111.0, 21.0, 58.0, 96.0, 0.0, 42.0, 63.0, 105.0, 98.0, 40.0, 30.0, 12.0, 22.0, 106.0, 0.0, 75.0, 166.0, 0.0, 21.0, 95.0, 134.0, 14.0, 0.0, 0.0, 142.0, 115.0, 76.0, 0.0, 10.0, 111.0, 178.0, 116.0, 0.0, 137.0, 168.0, 131.0, 123.0, 54.0, 38.0, 0.0, 175.0, 134.0, 132.0, 61.0, 48.0, 160.0, 0.0, 147.0, 74.0, 0.0, 2.0, 73.0, 0.0, 0.0, 151.0, 135.0, 133.0, 12.0, 12.0, 0.0, 0.0, 181.0, 0.0, 0.0, 0.0, 31.0, 26.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 58.0, 44.0, 3.0, 0.0, 17.0, 13.0, 17.0, 0.0, 0.0, 0.0, 35.0, 11.0, 0.0, 0.0, 0.0, 0.0, 16.0, 45.0, 0.0, 0.0, 0.0, 90.0, 27.0, 5.0, 6.0, 6.0, 0.0, 0.0, 7.0, 0.0, 58.0, 68.0, 15.0, 7.0, 14.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 18.0, 0.0, 0.0, 3.0, 0.0, 0.0, 17.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 32.0, 7.0, 2.0, 4.0, 0.0, 0.0, 26.0, 15.0, 32.0, 0.0, 51.0, 33.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6813315752450291, "mean_inference_ms": 1.6423683938817966, "mean_action_processing_ms": 0.2675789281409482, "mean_env_wait_ms": 0.20133064065111075, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01007533073425293, "StateBufferConnector_ms": 0.0034133195877075195, "ViewRequirementAgentConnector_ms": 0.11874663829803467}, "num_episodes": 18, "episode_return_max": 257.79999999999995, "episode_return_min": -334.2999999999998, "episode_return_mean": 1.2719999999999607, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 496000, "num_agent_steps_trained": 496000, "num_env_steps_sampled": 124000, "num_env_steps_trained": 124000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 74.35454519866504, "num_env_steps_trained_throughput_per_sec": 74.35454519866504, "timesteps_total": 124000, "num_env_steps_sampled_lifetime": 124000, "num_agent_steps_sampled_lifetime": 496000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 496000, "timers": {"training_iteration_time_ms": 51629.934, "restore_workers_time_ms": 0.013, "training_step_time_ms": 51629.878, "sample_time_ms": 1382.9, "learn_time_ms": 50231.865, "learn_throughput": 79.631, "synch_weights_time_ms": 11.414}, "counters": {"num_env_steps_sampled": 124000, "num_env_steps_trained": 124000, "num_agent_steps_sampled": 496000, "num_agent_steps_trained": 496000}, "done": false, "training_iteration": 31, "trial_id": "11e70_00000", "date": "2024-08-12_23-33-42", "timestamp": 1723520022, "time_this_iter_s": 53.83136796951294, "time_total_s": 1602.4511094093323, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2b61ca0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1602.4511094093323, "iterations_since_restore": 31, "perf": {"cpu_util_percent": 42.04473684210526, "ram_util_percent": 81.48157894736843}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 8.17427811950603, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.9440393676202763, "policy_loss": -0.009189258310722098, "vf_loss": 1.9519887435373175, "vf_explained_var": 0.18578127039172662, "kl": 0.008265862110942483, "entropy": 1.349505373220595, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 59535.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.802425305553214, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.153164479719899, "policy_loss": -0.013792067557997095, "vf_loss": 4.165474080534839, "vf_explained_var": 0.418496896665563, "kl": 0.009883066239075965, "entropy": 1.2713491868089746, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 59535.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 128000, "num_env_steps_trained": 128000, "num_agent_steps_sampled": 512000, "num_agent_steps_trained": 512000}, "env_runners": {"episode_reward_max": 391.90000000000003, "episode_reward_min": -310.0, "episode_reward_mean": 56.278999999999925, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -340.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 198.2, "predator_policy": 181.0}, "policy_reward_mean": {"prey_policy": -0.7955000000000019, "predator_policy": 28.935}, "custom_metrics": {}, "hist_stats": {"episode_reward": [13.600000000000131, 73.29999999999998, -27.299999999999926, 105.19999999999966, 140.29999999999927, 49.39999999999989, -138.10000000000002, 21.4, -201.000000000001, 24.60000000000005, -177.09999999999994, 5.399999999999942, 26.90000000000009, -310.0, -11.999999999999924, -253.2000000000002, -74.10000000000034, 53.70000000000015, -109.30000000000021, -15.299999999999926, 52.10000000000003, -179.5, -41.39999999999978, 37.80000000000027, 71.29999999999964, -41.200000000000074, -84.69999999999999, 24.400000000000052, 83.19999999999906, -140.8, 53.50000000000029, 88.89999999999863, 111.09999999999927, 61.60000000000051, 58.70000000000042, 63.10000000000038, 46.600000000000406, 137.499999999999, 42.90000000000036, 40.0000000000003, -0.6999999999998354, 118.29999999999899, 40.0000000000003, 53.000000000000306, 49.000000000000455, 99.69999999999989, 55.50000000000036, 26.800000000000097, 40.0000000000003, 109.69999999999874, 226.89999999999984, 15.799999999999939, 63.80000000000041, 54.40000000000053, 257.79999999999995, 38.90000000000028, 37.80000000000027, 30.100000000000147, 139.29999999999907, 158.79999999999922, 185.19999999999916, 40.0000000000003, 40.0000000000003, 87.39999999999975, 56.80000000000045, 115.29999999999887, 49.90000000000046, 18.299999999999958, 132.59999999999957, 30.400000000000134, 40.0000000000003, 40.0000000000003, 237.79999999999944, 61.700000000000294, 79.40000000000005, 40.0000000000003, 40.0000000000003, 26.000000000000117, 339.09999999999985, 182.39999999999998, 164.29999999999944, 41.30000000000032, 58.50000000000047, 190.7999999999997, 391.90000000000003, 293.7, 184.99999999999932, 175.99999999999935, -57.40000000000036, 40.0000000000003, 40.0000000000003, 40.0000000000003, 50.80000000000048, 177.49999999999926, 191.59999999999934, 183.09999999999926, -31.39999999999955, 154.69999999999962, 160.9999999999994, 37.80000000000027], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-102.40000000000006, 20.000000000000014, 2.299999999999991, -34.000000000000156, 20.000000000000014, -250.3, 36.20000000000001, -1.0000000000000142, 78.49999999999984, 27.80000000000016, 71.89999999999962, -128.5, -125.20000000000002, -253.9, 24.50000000000008, -24.099999999999746, -250.49999999999994, -179.50000000000057, -9.399999999999855, 20.000000000000014, -177.70000000000005, -141.4, -198.70000000000005, 13.099999999999968, 17.899999999999988, -0.9999999999999952, -259.0, -340.0, -148.0, 20.000000000000014, -225.40000000000003, -332.8000000000002, -3.0999999999999863, -325.00000000000006, -58.299999999999955, 20.000000000000014, -9.399999999999869, -274.9, 8.6, -289.9, 7.399999999999965, -64.29999999999991, -124.0, -215.50000000000003, 30.20000000000019, -292.6, 15.799999999999963, 20.000000000000014, 25.400000000000098, -27.099999999999994, 63.499999999999986, -255.70000000000005, -84.1, -268.6, -0.7000000000000169, 1.0999999999999865, 63.200000000000195, 20.000000000000014, -50.5, -271.3, 33.50000000000014, 20.000000000000014, -33.0999999999998, 65.00000000000013, 20.000000000000014, 91.09999999999971, 41.60000000000025, 20.000000000000014, 28.700000000000177, 20.000000000000014, -58.9000000000001, 20.000000000000014, 23.60000000000007, 20.000000000000014, 20.000000000000014, 87.49999999999976, 20.000000000000014, 5.900000000000011, 20.000000000000014, 20.000000000000014, -60.400000000000574, 13.699999999999966, 20.000000000000014, 98.29999999999957, 20.000000000000014, 20.000000000000014, 20.000000000000014, -27.999999999999886, 20.000000000000014, 29.000000000000174, 75.49999999999945, -65.80000000000001, 11.29999999999998, 12.199999999999974, 7.399999999999965, 7.399999999999982, 20.000000000000014, 20.000000000000014, 82.69999999999939, 20.000000000000014, 185.60000000000002, -84.70000000000019, 5.299999999999947, -11.499999999999819, 23.600000000000076, 3.1999999999999793, 29.90000000000018, 24.500000000000085, 150.4999999999997, 107.29999999999973, 20.000000000000014, 17.899999999999988, 20.000000000000014, 15.799999999999963, -7.899999999999924, 20.000000000000014, 20.000000000000014, 116.29999999999971, 119.89999999999972, 38.90000000000015, 129.79999999999995, 22.400000000000066, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 34.4000000000002, 44.00000000000019, -11.199999999999852, 29.000000000000163, 29.90000000000018, 79.3999999999995, 29.90000000000018, 20.000000000000014, 20.900000000000013, -43.59999999999982, 130.7, -30.099999999999795, -49.299999999999905, -4.299999999999962, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 102.49999999999994, 134.2999999999996, 20.000000000000014, -25.299999999999876, 52.39999999999996, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -8.7999999999999, 0.7999999999999545, 152.5999999999999, 174.5, 16.399999999999984, 59.0, 20.000000000000014, 116.30000000000001, 14.299999999999967, 20.000000000000014, -10.59999999999985, 49.10000000000023, 14.300000000000166, 138.5, 193.7, 198.2, 164.3, 91.39999999999998, 20.000000000000014, 160.99999999999997, -31.599999999999845, 152.59999999999997, -290.79999999999916, 85.39999999999976, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 30.800000000000196, -45.6999999999998, 180.1999999999999, 164.59999999999997, 20.000000000000014, 20.000000000000014, 163.09999999999988, -64.00000000000091, -30.3999999999998, 29.90000000000018, 117.79999999999998, 114.19999999999999, 15.799999999999962, 20.000000000000014, 15.799999999999962], "policy_predator_policy_reward": [96.0, 0.0, 42.0, 63.0, 105.0, 98.0, 40.0, 30.0, 12.0, 22.0, 106.0, 0.0, 75.0, 166.0, 0.0, 21.0, 95.0, 134.0, 14.0, 0.0, 0.0, 142.0, 115.0, 76.0, 0.0, 10.0, 111.0, 178.0, 116.0, 0.0, 137.0, 168.0, 131.0, 123.0, 54.0, 38.0, 0.0, 175.0, 134.0, 132.0, 61.0, 48.0, 160.0, 0.0, 147.0, 74.0, 0.0, 2.0, 73.0, 0.0, 0.0, 151.0, 135.0, 133.0, 12.0, 12.0, 0.0, 0.0, 181.0, 0.0, 0.0, 0.0, 31.0, 26.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 58.0, 44.0, 3.0, 0.0, 17.0, 13.0, 17.0, 0.0, 0.0, 0.0, 35.0, 11.0, 0.0, 0.0, 0.0, 0.0, 16.0, 45.0, 0.0, 0.0, 0.0, 90.0, 27.0, 5.0, 6.0, 6.0, 0.0, 0.0, 7.0, 0.0, 58.0, 68.0, 15.0, 7.0, 14.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 18.0, 0.0, 0.0, 3.0, 0.0, 0.0, 17.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 32.0, 7.0, 2.0, 4.0, 0.0, 0.0, 26.0, 15.0, 32.0, 0.0, 51.0, 33.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 35.0, 32.0, 4.0, 3.0, 0.0, 0.0, 0.0, 0.0, 10.0, 24.0, 9.0, 3.0, 47.0, 60.0, 14.0, 14.0, 5.0, 2.0, 20.0, 0.0, 18.0, 20.0, 0.0, 0.0, 24.0, 14.0, 0.0, 4.0, 26.0, 29.0, 0.0, 148.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 18.0, 25.0, 6.0, 1.0, 0.0, 0.0, 63.0, 0.0, 6.0, 1.0, 20.0, 11.0, 0.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.681377143654182, "mean_inference_ms": 1.663565594999809, "mean_action_processing_ms": 0.2678569584304581, "mean_env_wait_ms": 0.20107183297890155, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.010631680488586426, "StateBufferConnector_ms": 0.004575610160827637, "ViewRequirementAgentConnector_ms": 0.12929105758666992}, "num_episodes": 27, "episode_return_max": 391.90000000000003, "episode_return_min": -310.0, "episode_return_mean": 56.278999999999925, "episodes_this_iter": 27}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 512000, "num_agent_steps_trained": 512000, "num_env_steps_sampled": 128000, "num_env_steps_trained": 128000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 77.11266717938094, "num_env_steps_trained_throughput_per_sec": 77.11266717938094, "timesteps_total": 128000, "num_env_steps_sampled_lifetime": 128000, "num_agent_steps_sampled_lifetime": 512000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 512000, "timers": {"training_iteration_time_ms": 51744.164, "restore_workers_time_ms": 0.013, "training_step_time_ms": 51744.12, "sample_time_ms": 1389.95, "learn_time_ms": 50338.936, "learn_throughput": 79.461, "synch_weights_time_ms": 11.606}, "counters": {"num_env_steps_sampled": 128000, "num_env_steps_trained": 128000, "num_agent_steps_sampled": 512000, "num_agent_steps_trained": 512000}, "done": false, "training_iteration": 32, "trial_id": "11e70_00000", "date": "2024-08-12_23-34-34", "timestamp": 1723520074, "time_this_iter_s": 51.904165267944336, "time_total_s": 1654.3552746772766, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2b67dc0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1654.3552746772766, "iterations_since_restore": 32, "perf": {"cpu_util_percent": 34.83378378378379, "ram_util_percent": 79.8662162162162}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 8.903201913076733, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.058259905646087, "policy_loss": -0.01052056470092524, "vf_loss": 2.067315820474473, "vf_explained_var": 0.09351043489874986, "kl": 0.009764327511630467, "entropy": 1.3214091111112525, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 61425.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.034658233576981, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.090742213890035, "policy_loss": -0.011402233450786857, "vf_loss": 6.100574049621663, "vf_explained_var": 0.40505732919173265, "kl": 0.010469257385011971, "entropy": 1.302028363533121, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 61425.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 132000, "num_env_steps_trained": 132000, "num_agent_steps_sampled": 528000, "num_agent_steps_trained": 528000}, "env_runners": {"episode_reward_max": 391.90000000000003, "episode_reward_min": -179.5, "episode_reward_mean": 96.65599999999989, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -292.6, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 198.2, "predator_policy": 181.0}, "policy_reward_mean": {"prey_policy": 29.857999999999997, "predator_policy": 18.47}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-109.30000000000021, -15.299999999999926, 52.10000000000003, -179.5, -41.39999999999978, 37.80000000000027, 71.29999999999964, -41.200000000000074, -84.69999999999999, 24.400000000000052, 83.19999999999906, -140.8, 53.50000000000029, 88.89999999999863, 111.09999999999927, 61.60000000000051, 58.70000000000042, 63.10000000000038, 46.600000000000406, 137.499999999999, 42.90000000000036, 40.0000000000003, -0.6999999999998354, 118.29999999999899, 40.0000000000003, 53.000000000000306, 49.000000000000455, 99.69999999999989, 55.50000000000036, 26.800000000000097, 40.0000000000003, 109.69999999999874, 226.89999999999984, 15.799999999999939, 63.80000000000041, 54.40000000000053, 257.79999999999995, 38.90000000000028, 37.80000000000027, 30.100000000000147, 139.29999999999907, 158.79999999999922, 185.19999999999916, 40.0000000000003, 40.0000000000003, 87.39999999999975, 56.80000000000045, 115.29999999999887, 49.90000000000046, 18.299999999999958, 132.59999999999957, 30.400000000000134, 40.0000000000003, 40.0000000000003, 237.79999999999944, 61.700000000000294, 79.40000000000005, 40.0000000000003, 40.0000000000003, 26.000000000000117, 339.09999999999985, 182.39999999999998, 164.29999999999944, 41.30000000000032, 58.50000000000047, 190.7999999999997, 391.90000000000003, 293.7, 184.99999999999932, 175.99999999999935, -57.40000000000036, 40.0000000000003, 40.0000000000003, 40.0000000000003, 50.80000000000048, 177.49999999999926, 191.59999999999934, 183.09999999999926, -31.39999999999955, 154.69999999999962, 160.9999999999994, 37.80000000000027, 103.99999999999947, 169.69999999999905, 278.09999999999985, 68.80000000000011, 187.3999999999993, 69.49999999999996, 320.4000000000001, 149.89999999999964, 47.700000000000074, 347.49999999999994, 149.7999999999995, 202.79999999999927, 201.99999999999926, 274.9, 141.0999999999995, 240.1999999999998, 286.4, 118.49999999999974], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-9.399999999999869, -274.9, 8.6, -289.9, 7.399999999999965, -64.29999999999991, -124.0, -215.50000000000003, 30.20000000000019, -292.6, 15.799999999999963, 20.000000000000014, 25.400000000000098, -27.099999999999994, 63.499999999999986, -255.70000000000005, -84.1, -268.6, -0.7000000000000169, 1.0999999999999865, 63.200000000000195, 20.000000000000014, -50.5, -271.3, 33.50000000000014, 20.000000000000014, -33.0999999999998, 65.00000000000013, 20.000000000000014, 91.09999999999971, 41.60000000000025, 20.000000000000014, 28.700000000000177, 20.000000000000014, -58.9000000000001, 20.000000000000014, 23.60000000000007, 20.000000000000014, 20.000000000000014, 87.49999999999976, 20.000000000000014, 5.900000000000011, 20.000000000000014, 20.000000000000014, -60.400000000000574, 13.699999999999966, 20.000000000000014, 98.29999999999957, 20.000000000000014, 20.000000000000014, 20.000000000000014, -27.999999999999886, 20.000000000000014, 29.000000000000174, 75.49999999999945, -65.80000000000001, 11.29999999999998, 12.199999999999974, 7.399999999999965, 7.399999999999982, 20.000000000000014, 20.000000000000014, 82.69999999999939, 20.000000000000014, 185.60000000000002, -84.70000000000019, 5.299999999999947, -11.499999999999819, 23.600000000000076, 3.1999999999999793, 29.90000000000018, 24.500000000000085, 150.4999999999997, 107.29999999999973, 20.000000000000014, 17.899999999999988, 20.000000000000014, 15.799999999999963, -7.899999999999924, 20.000000000000014, 20.000000000000014, 116.29999999999971, 119.89999999999972, 38.90000000000015, 129.79999999999995, 22.400000000000066, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 34.4000000000002, 44.00000000000019, -11.199999999999852, 29.000000000000163, 29.90000000000018, 79.3999999999995, 29.90000000000018, 20.000000000000014, 20.900000000000013, -43.59999999999982, 130.7, -30.099999999999795, -49.299999999999905, -4.299999999999962, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 102.49999999999994, 134.2999999999996, 20.000000000000014, -25.299999999999876, 52.39999999999996, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -8.7999999999999, 0.7999999999999545, 152.5999999999999, 174.5, 16.399999999999984, 59.0, 20.000000000000014, 116.30000000000001, 14.299999999999967, 20.000000000000014, -10.59999999999985, 49.10000000000023, 14.300000000000166, 138.5, 193.7, 198.2, 164.3, 91.39999999999998, 20.000000000000014, 160.99999999999997, -31.599999999999845, 152.59999999999997, -290.79999999999916, 85.39999999999976, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 30.800000000000196, -45.6999999999998, 180.1999999999999, 164.59999999999997, 20.000000000000014, 20.000000000000014, 163.09999999999988, -64.00000000000091, -30.3999999999998, 29.90000000000018, 117.79999999999998, 114.19999999999999, 15.799999999999962, 20.000000000000014, 15.799999999999962, -55.600000000000335, 104.59999999999988, 147.79999999999976, 17.899999999999977, 175.99999999999994, 76.10000000000001, 48.80000000000021, 20.000000000000014, 133.69999999999996, 31.70000000000021, 20.000000000000014, 6.499999999999999, 133.99999999999994, 163.39999999999998, -0.9999999999999952, 137.90000000000003, 6.499999999999992, -14.799999999999912, 183.79999999999995, 154.70000000000002, 102.79999999999994, 20.000000000000014, 20.000000000000014, 177.79999999999995, 20.000000000000014, 181.99999999999994, 83.90000000000002, 172.99999999999997, 20.000000000000014, 58.1, 87.19999999999997, 137.0, 154.7, 94.69999999999996, 5.299999999999993, 105.19999999999999], "policy_predator_policy_reward": [0.0, 175.0, 134.0, 132.0, 61.0, 48.0, 160.0, 0.0, 147.0, 74.0, 0.0, 2.0, 73.0, 0.0, 0.0, 151.0, 135.0, 133.0, 12.0, 12.0, 0.0, 0.0, 181.0, 0.0, 0.0, 0.0, 31.0, 26.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 58.0, 44.0, 3.0, 0.0, 17.0, 13.0, 17.0, 0.0, 0.0, 0.0, 35.0, 11.0, 0.0, 0.0, 0.0, 0.0, 16.0, 45.0, 0.0, 0.0, 0.0, 90.0, 27.0, 5.0, 6.0, 6.0, 0.0, 0.0, 7.0, 0.0, 58.0, 68.0, 15.0, 7.0, 14.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 18.0, 0.0, 0.0, 3.0, 0.0, 0.0, 17.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 32.0, 7.0, 2.0, 4.0, 0.0, 0.0, 26.0, 15.0, 32.0, 0.0, 51.0, 33.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 35.0, 32.0, 4.0, 3.0, 0.0, 0.0, 0.0, 0.0, 10.0, 24.0, 9.0, 3.0, 47.0, 60.0, 14.0, 14.0, 5.0, 2.0, 20.0, 0.0, 18.0, 20.0, 0.0, 0.0, 24.0, 14.0, 0.0, 4.0, 26.0, 29.0, 0.0, 148.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 18.0, 25.0, 6.0, 1.0, 0.0, 0.0, 63.0, 0.0, 6.0, 1.0, 20.0, 11.0, 0.0, 2.0, 50.0, 5.0, 3.0, 1.0, 3.0, 23.0, 0.0, 0.0, 8.0, 14.0, 8.0, 35.0, 9.0, 14.0, 13.0, 0.0, 33.0, 23.0, 0.0, 9.0, 27.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 18.0, 34.0, 29.0, 15.0, 1.0, 9.0, 28.0, 4.0, 4.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6802052413624906, "mean_inference_ms": 1.659833816396486, "mean_action_processing_ms": 0.26800628840137697, "mean_env_wait_ms": 0.20085583998353707, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006727099418640137, "StateBufferConnector_ms": 0.004340648651123047, "ViewRequirementAgentConnector_ms": 0.13581764698028564}, "num_episodes": 18, "episode_return_max": 391.90000000000003, "episode_return_min": -179.5, "episode_return_mean": 96.65599999999989, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 528000, "num_agent_steps_trained": 528000, "num_env_steps_sampled": 132000, "num_env_steps_trained": 132000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 76.46015086969943, "num_env_steps_trained_throughput_per_sec": 76.46015086969943, "timesteps_total": 132000, "num_env_steps_sampled_lifetime": 132000, "num_agent_steps_sampled_lifetime": 528000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 528000, "timers": {"training_iteration_time_ms": 51914.672, "restore_workers_time_ms": 0.013, "training_step_time_ms": 51914.628, "sample_time_ms": 1387.47, "learn_time_ms": 50510.891, "learn_throughput": 79.191, "synch_weights_time_ms": 11.983}, "counters": {"num_env_steps_sampled": 132000, "num_env_steps_trained": 132000, "num_agent_steps_sampled": 528000, "num_agent_steps_trained": 528000}, "done": false, "training_iteration": 33, "trial_id": "11e70_00000", "date": "2024-08-12_23-35-26", "timestamp": 1723520126, "time_this_iter_s": 52.3496150970459, "time_total_s": 1706.7048897743225, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2b15c10>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1706.7048897743225, "iterations_since_restore": 33, "perf": {"cpu_util_percent": 35.26756756756757, "ram_util_percent": 80.03513513513512}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 7.406283540195889, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.985412778047027, "policy_loss": -0.009867808985075464, "vf_loss": 2.994165521134775, "vf_explained_var": 0.13863159601019803, "kl": 0.007433768511747507, "entropy": 1.323303574355191, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 63315.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.602261108759219, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.106090491158621, "policy_loss": -0.010599033063691523, "vf_loss": 6.115090008639784, "vf_explained_var": 0.4512352162883395, "kl": 0.010663468846067784, "entropy": 1.2954423484978852, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 63315.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 136000, "num_env_steps_trained": 136000, "num_agent_steps_sampled": 544000, "num_agent_steps_trained": 544000}, "env_runners": {"episode_reward_max": 391.90000000000003, "episode_reward_min": -57.40000000000036, "episode_reward_mean": 126.22799999999988, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -290.79999999999916, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 198.2, "predator_policy": 148.0}, "policy_reward_mean": {"prey_policy": 51.073999999999984, "predator_policy": 12.04}, "custom_metrics": {}, "hist_stats": {"episode_reward": [46.600000000000406, 137.499999999999, 42.90000000000036, 40.0000000000003, -0.6999999999998354, 118.29999999999899, 40.0000000000003, 53.000000000000306, 49.000000000000455, 99.69999999999989, 55.50000000000036, 26.800000000000097, 40.0000000000003, 109.69999999999874, 226.89999999999984, 15.799999999999939, 63.80000000000041, 54.40000000000053, 257.79999999999995, 38.90000000000028, 37.80000000000027, 30.100000000000147, 139.29999999999907, 158.79999999999922, 185.19999999999916, 40.0000000000003, 40.0000000000003, 87.39999999999975, 56.80000000000045, 115.29999999999887, 49.90000000000046, 18.299999999999958, 132.59999999999957, 30.400000000000134, 40.0000000000003, 40.0000000000003, 237.79999999999944, 61.700000000000294, 79.40000000000005, 40.0000000000003, 40.0000000000003, 26.000000000000117, 339.09999999999985, 182.39999999999998, 164.29999999999944, 41.30000000000032, 58.50000000000047, 190.7999999999997, 391.90000000000003, 293.7, 184.99999999999932, 175.99999999999935, -57.40000000000036, 40.0000000000003, 40.0000000000003, 40.0000000000003, 50.80000000000048, 177.49999999999926, 191.59999999999934, 183.09999999999926, -31.39999999999955, 154.69999999999962, 160.9999999999994, 37.80000000000027, 103.99999999999947, 169.69999999999905, 278.09999999999985, 68.80000000000011, 187.3999999999993, 69.49999999999996, 320.4000000000001, 149.89999999999964, 47.700000000000074, 347.49999999999994, 149.7999999999995, 202.79999999999927, 201.99999999999926, 274.9, 141.0999999999995, 240.1999999999998, 286.4, 118.49999999999974, 110.19999999999983, 168.9999999999994, 40.0000000000003, 177.29999999999924, 199.79999999999922, 258.1999999999997, 75.9, 89.69999999999999, 180.39999999999927, 134.09999999999965, 40.0000000000003, 174.29999999999933, 298.00000000000006, 267.0999999999999, 190.59999999999994, 239.3999999999997, 40.0000000000003, 366.69999999999993], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [23.60000000000007, 20.000000000000014, 20.000000000000014, 87.49999999999976, 20.000000000000014, 5.900000000000011, 20.000000000000014, 20.000000000000014, -60.400000000000574, 13.699999999999966, 20.000000000000014, 98.29999999999957, 20.000000000000014, 20.000000000000014, 20.000000000000014, -27.999999999999886, 20.000000000000014, 29.000000000000174, 75.49999999999945, -65.80000000000001, 11.29999999999998, 12.199999999999974, 7.399999999999965, 7.399999999999982, 20.000000000000014, 20.000000000000014, 82.69999999999939, 20.000000000000014, 185.60000000000002, -84.70000000000019, 5.299999999999947, -11.499999999999819, 23.600000000000076, 3.1999999999999793, 29.90000000000018, 24.500000000000085, 150.4999999999997, 107.29999999999973, 20.000000000000014, 17.899999999999988, 20.000000000000014, 15.799999999999963, -7.899999999999924, 20.000000000000014, 20.000000000000014, 116.29999999999971, 119.89999999999972, 38.90000000000015, 129.79999999999995, 22.400000000000066, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 34.4000000000002, 44.00000000000019, -11.199999999999852, 29.000000000000163, 29.90000000000018, 79.3999999999995, 29.90000000000018, 20.000000000000014, 20.900000000000013, -43.59999999999982, 130.7, -30.099999999999795, -49.299999999999905, -4.299999999999962, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 102.49999999999994, 134.2999999999996, 20.000000000000014, -25.299999999999876, 52.39999999999996, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -8.7999999999999, 0.7999999999999545, 152.5999999999999, 174.5, 16.399999999999984, 59.0, 20.000000000000014, 116.30000000000001, 14.299999999999967, 20.000000000000014, -10.59999999999985, 49.10000000000023, 14.300000000000166, 138.5, 193.7, 198.2, 164.3, 91.39999999999998, 20.000000000000014, 160.99999999999997, -31.599999999999845, 152.59999999999997, -290.79999999999916, 85.39999999999976, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 30.800000000000196, -45.6999999999998, 180.1999999999999, 164.59999999999997, 20.000000000000014, 20.000000000000014, 163.09999999999988, -64.00000000000091, -30.3999999999998, 29.90000000000018, 117.79999999999998, 114.19999999999999, 15.799999999999962, 20.000000000000014, 15.799999999999962, -55.600000000000335, 104.59999999999988, 147.79999999999976, 17.899999999999977, 175.99999999999994, 76.10000000000001, 48.80000000000021, 20.000000000000014, 133.69999999999996, 31.70000000000021, 20.000000000000014, 6.499999999999999, 133.99999999999994, 163.39999999999998, -0.9999999999999952, 137.90000000000003, 6.499999999999992, -14.799999999999912, 183.79999999999995, 154.70000000000002, 102.79999999999994, 20.000000000000014, 20.000000000000014, 177.79999999999995, 20.000000000000014, 181.99999999999994, 83.90000000000002, 172.99999999999997, 20.000000000000014, 58.1, 87.19999999999997, 137.0, 154.7, 94.69999999999996, 5.299999999999993, 105.19999999999999, 20.000000000000014, 45.20000000000002, 98.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 156.19999999999993, 1.0999999999999617, 20.000000000000014, 177.79999999999993, 88.99999999999997, 162.19999999999996, -30.099999999999987, 20.000000000000014, 16.699999999999875, 20.000000000000014, 20.000000000000014, 142.39999999999998, 20.000000000000014, 112.1, 20.000000000000014, 20.000000000000014, 137.3, 20.000000000000014, 107.89999999999998, 145.1, 111.8, 128.29999999999995, 41.300000000000004, 29.300000000000004, 57.49999999999999, 161.89999999999995, 20.000000000000014, 20.000000000000014, 168.5, 198.2], "policy_predator_policy_reward": [3.0, 0.0, 17.0, 13.0, 17.0, 0.0, 0.0, 0.0, 35.0, 11.0, 0.0, 0.0, 0.0, 0.0, 16.0, 45.0, 0.0, 0.0, 0.0, 90.0, 27.0, 5.0, 6.0, 6.0, 0.0, 0.0, 7.0, 0.0, 58.0, 68.0, 15.0, 7.0, 14.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 18.0, 0.0, 0.0, 3.0, 0.0, 0.0, 17.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 32.0, 7.0, 2.0, 4.0, 0.0, 0.0, 26.0, 15.0, 32.0, 0.0, 51.0, 33.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 35.0, 32.0, 4.0, 3.0, 0.0, 0.0, 0.0, 0.0, 10.0, 24.0, 9.0, 3.0, 47.0, 60.0, 14.0, 14.0, 5.0, 2.0, 20.0, 0.0, 18.0, 20.0, 0.0, 0.0, 24.0, 14.0, 0.0, 4.0, 26.0, 29.0, 0.0, 148.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 18.0, 25.0, 6.0, 1.0, 0.0, 0.0, 63.0, 0.0, 6.0, 1.0, 20.0, 11.0, 0.0, 2.0, 50.0, 5.0, 3.0, 1.0, 3.0, 23.0, 0.0, 0.0, 8.0, 14.0, 8.0, 35.0, 9.0, 14.0, 13.0, 0.0, 33.0, 23.0, 0.0, 9.0, 27.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 18.0, 34.0, 29.0, 15.0, 1.0, 9.0, 28.0, 4.0, 4.0, 25.0, 20.0, 18.0, 33.0, 0.0, 0.0, 10.0, 10.0, 0.0, 2.0, 0.0, 7.0, 59.0, 27.0, 52.0, 1.0, 16.0, 2.0, 0.0, 2.0, 0.0, 0.0, 10.0, 7.0, 25.0, 20.0, 13.0, 14.0, 65.0, 55.0, 3.0, 17.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.679500261278101, "mean_inference_ms": 1.6543334920159265, "mean_action_processing_ms": 0.2681106968119831, "mean_env_wait_ms": 0.20060252618924593, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006826996803283691, "StateBufferConnector_ms": 0.004316806793212891, "ViewRequirementAgentConnector_ms": 0.1296989917755127}, "num_episodes": 18, "episode_return_max": 391.90000000000003, "episode_return_min": -57.40000000000036, "episode_return_mean": 126.22799999999988, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 544000, "num_agent_steps_trained": 544000, "num_env_steps_sampled": 136000, "num_env_steps_trained": 136000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 77.32310657889539, "num_env_steps_trained_throughput_per_sec": 77.32310657889539, "timesteps_total": 136000, "num_env_steps_sampled_lifetime": 136000, "num_agent_steps_sampled_lifetime": 544000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 544000, "timers": {"training_iteration_time_ms": 51815.685, "restore_workers_time_ms": 0.013, "training_step_time_ms": 51815.641, "sample_time_ms": 1383.012, "learn_time_ms": 50416.232, "learn_throughput": 79.34, "synch_weights_time_ms": 12.078}, "counters": {"num_env_steps_sampled": 136000, "num_env_steps_trained": 136000, "num_agent_steps_sampled": 544000, "num_agent_steps_trained": 544000}, "done": false, "training_iteration": 34, "trial_id": "11e70_00000", "date": "2024-08-12_23-36-18", "timestamp": 1723520178, "time_this_iter_s": 51.77617788314819, "time_total_s": 1758.4810676574707, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2b93430>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1758.4810676574707, "iterations_since_restore": 34, "perf": {"cpu_util_percent": 34.82027027027027, "ram_util_percent": 80.12567567567568}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 6.866020640431258, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.703265991286626, "policy_loss": -0.01241745913349506, "vf_loss": 2.7141541941456064, "vf_explained_var": 0.11933098224105028, "kl": 0.010195073038769722, "entropy": 1.3137625534698445, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 65205.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.784864335274571, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.406249728783098, "policy_loss": -0.012474925979902898, "vf_loss": 6.4171998432704385, "vf_explained_var": 0.47486808757302623, "kl": 0.010165328162903019, "entropy": 1.2600837354937557, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 65205.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 140000, "num_env_steps_trained": 140000, "num_agent_steps_sampled": 560000, "num_agent_steps_trained": 560000}, "env_runners": {"episode_reward_max": 391.90000000000003, "episode_reward_min": -57.40000000000036, "episode_reward_mean": 149.89099999999982, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -290.79999999999916, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 198.2, "predator_policy": 148.0}, "policy_reward_mean": {"prey_policy": 62.2655, "predator_policy": 12.68}, "custom_metrics": {}, "hist_stats": {"episode_reward": [257.79999999999995, 38.90000000000028, 37.80000000000027, 30.100000000000147, 139.29999999999907, 158.79999999999922, 185.19999999999916, 40.0000000000003, 40.0000000000003, 87.39999999999975, 56.80000000000045, 115.29999999999887, 49.90000000000046, 18.299999999999958, 132.59999999999957, 30.400000000000134, 40.0000000000003, 40.0000000000003, 237.79999999999944, 61.700000000000294, 79.40000000000005, 40.0000000000003, 40.0000000000003, 26.000000000000117, 339.09999999999985, 182.39999999999998, 164.29999999999944, 41.30000000000032, 58.50000000000047, 190.7999999999997, 391.90000000000003, 293.7, 184.99999999999932, 175.99999999999935, -57.40000000000036, 40.0000000000003, 40.0000000000003, 40.0000000000003, 50.80000000000048, 177.49999999999926, 191.59999999999934, 183.09999999999926, -31.39999999999955, 154.69999999999962, 160.9999999999994, 37.80000000000027, 103.99999999999947, 169.69999999999905, 278.09999999999985, 68.80000000000011, 187.3999999999993, 69.49999999999996, 320.4000000000001, 149.89999999999964, 47.700000000000074, 347.49999999999994, 149.7999999999995, 202.79999999999927, 201.99999999999926, 274.9, 141.0999999999995, 240.1999999999998, 286.4, 118.49999999999974, 110.19999999999983, 168.9999999999994, 40.0000000000003, 177.29999999999924, 199.79999999999922, 258.1999999999997, 75.9, 89.69999999999999, 180.39999999999927, 134.09999999999965, 40.0000000000003, 174.29999999999933, 298.00000000000006, 267.0999999999999, 190.59999999999994, 239.3999999999997, 40.0000000000003, 366.69999999999993, 126.39999999999966, 225.1999999999999, 185.10000000000002, 193.29999999999927, 107.40000000000003, 276.5, 90.79999999999978, 160.3999999999992, 326.09999999999997, 325.9, 188.39999999999932, 183.0999999999992, 206.09999999999994, 349.60000000000036, 153.39999999999932, 40.0000000000003, 139.7999999999992, 308.0], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [150.4999999999997, 107.29999999999973, 20.000000000000014, 17.899999999999988, 20.000000000000014, 15.799999999999963, -7.899999999999924, 20.000000000000014, 20.000000000000014, 116.29999999999971, 119.89999999999972, 38.90000000000015, 129.79999999999995, 22.400000000000066, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 34.4000000000002, 44.00000000000019, -11.199999999999852, 29.000000000000163, 29.90000000000018, 79.3999999999995, 29.90000000000018, 20.000000000000014, 20.900000000000013, -43.59999999999982, 130.7, -30.099999999999795, -49.299999999999905, -4.299999999999962, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 102.49999999999994, 134.2999999999996, 20.000000000000014, -25.299999999999876, 52.39999999999996, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -8.7999999999999, 0.7999999999999545, 152.5999999999999, 174.5, 16.399999999999984, 59.0, 20.000000000000014, 116.30000000000001, 14.299999999999967, 20.000000000000014, -10.59999999999985, 49.10000000000023, 14.300000000000166, 138.5, 193.7, 198.2, 164.3, 91.39999999999998, 20.000000000000014, 160.99999999999997, -31.599999999999845, 152.59999999999997, -290.79999999999916, 85.39999999999976, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 30.800000000000196, -45.6999999999998, 180.1999999999999, 164.59999999999997, 20.000000000000014, 20.000000000000014, 163.09999999999988, -64.00000000000091, -30.3999999999998, 29.90000000000018, 117.79999999999998, 114.19999999999999, 15.799999999999962, 20.000000000000014, 15.799999999999962, -55.600000000000335, 104.59999999999988, 147.79999999999976, 17.899999999999977, 175.99999999999994, 76.10000000000001, 48.80000000000021, 20.000000000000014, 133.69999999999996, 31.70000000000021, 20.000000000000014, 6.499999999999999, 133.99999999999994, 163.39999999999998, -0.9999999999999952, 137.90000000000003, 6.499999999999992, -14.799999999999912, 183.79999999999995, 154.70000000000002, 102.79999999999994, 20.000000000000014, 20.000000000000014, 177.79999999999995, 20.000000000000014, 181.99999999999994, 83.90000000000002, 172.99999999999997, 20.000000000000014, 58.1, 87.19999999999997, 137.0, 154.7, 94.69999999999996, 5.299999999999993, 105.19999999999999, 20.000000000000014, 45.20000000000002, 98.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 156.19999999999993, 1.0999999999999617, 20.000000000000014, 177.79999999999993, 88.99999999999997, 162.19999999999996, -30.099999999999987, 20.000000000000014, 16.699999999999875, 20.000000000000014, 20.000000000000014, 142.39999999999998, 20.000000000000014, 112.1, 20.000000000000014, 20.000000000000014, 137.3, 20.000000000000014, 107.89999999999998, 145.1, 111.8, 128.29999999999995, 41.300000000000004, 29.300000000000004, 57.49999999999999, 161.89999999999995, 20.000000000000014, 20.000000000000014, 168.5, 198.2, 128.89999999999998, -32.49999999999975, 89.89999999999998, 86.30000000000001, 41.900000000000006, 78.2, -29.499999999999815, 183.79999999999998, 77.29999999999998, -73.9, 185.0, 63.5, 17.899999999999988, 14.900000000000006, 20.000000000000014, 121.39999999999988, 197.29999999999998, 96.80000000000001, 192.79999999999995, 109.1, 163.39999999999998, 20.000000000000014, 163.0999999999999, 20.000000000000014, 70.1, 47.000000000000014, 187.39999999999992, 153.19999999999996, 15.799999999999963, 119.59999999999991, 20.000000000000014, 20.000000000000014, 87.79999999999997, 20.000000000000014, 147.8, 150.19999999999996], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 18.0, 0.0, 0.0, 3.0, 0.0, 0.0, 17.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 32.0, 7.0, 2.0, 4.0, 0.0, 0.0, 26.0, 15.0, 32.0, 0.0, 51.0, 33.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 35.0, 32.0, 4.0, 3.0, 0.0, 0.0, 0.0, 0.0, 10.0, 24.0, 9.0, 3.0, 47.0, 60.0, 14.0, 14.0, 5.0, 2.0, 20.0, 0.0, 18.0, 20.0, 0.0, 0.0, 24.0, 14.0, 0.0, 4.0, 26.0, 29.0, 0.0, 148.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 18.0, 25.0, 6.0, 1.0, 0.0, 0.0, 63.0, 0.0, 6.0, 1.0, 20.0, 11.0, 0.0, 2.0, 50.0, 5.0, 3.0, 1.0, 3.0, 23.0, 0.0, 0.0, 8.0, 14.0, 8.0, 35.0, 9.0, 14.0, 13.0, 0.0, 33.0, 23.0, 0.0, 9.0, 27.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 18.0, 34.0, 29.0, 15.0, 1.0, 9.0, 28.0, 4.0, 4.0, 25.0, 20.0, 18.0, 33.0, 0.0, 0.0, 10.0, 10.0, 0.0, 2.0, 0.0, 7.0, 59.0, 27.0, 52.0, 1.0, 16.0, 2.0, 0.0, 2.0, 0.0, 0.0, 10.0, 7.0, 25.0, 20.0, 13.0, 14.0, 65.0, 55.0, 3.0, 17.0, 0.0, 0.0, 0.0, 0.0, 5.0, 25.0, 0.0, 49.0, 40.0, 25.0, 23.0, 16.0, 33.0, 71.0, 28.0, 0.0, 32.0, 26.0, 0.0, 19.0, 0.0, 32.0, 24.0, 0.0, 5.0, 0.0, 0.0, 0.0, 55.0, 34.0, 3.0, 6.0, 16.0, 2.0, 0.0, 0.0, 32.0, 0.0, 0.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6788647915357403, "mean_inference_ms": 1.6497119154632411, "mean_action_processing_ms": 0.26811286330033407, "mean_env_wait_ms": 0.20041505404600612, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0068035125732421875, "StateBufferConnector_ms": 0.004320859909057617, "ViewRequirementAgentConnector_ms": 0.12022435665130615}, "num_episodes": 18, "episode_return_max": 391.90000000000003, "episode_return_min": -57.40000000000036, "episode_return_mean": 149.89099999999982, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 560000, "num_agent_steps_trained": 560000, "num_env_steps_sampled": 140000, "num_env_steps_trained": 140000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 76.75498222381249, "num_env_steps_trained_throughput_per_sec": 76.75498222381249, "timesteps_total": 140000, "num_env_steps_sampled_lifetime": 140000, "num_agent_steps_sampled_lifetime": 560000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 560000, "timers": {"training_iteration_time_ms": 51981.854, "restore_workers_time_ms": 0.013, "training_step_time_ms": 51981.813, "sample_time_ms": 1385.327, "learn_time_ms": 50579.71, "learn_throughput": 79.083, "synch_weights_time_ms": 12.53}, "counters": {"num_env_steps_sampled": 140000, "num_env_steps_trained": 140000, "num_agent_steps_sampled": 560000, "num_agent_steps_trained": 560000}, "done": false, "training_iteration": 35, "trial_id": "11e70_00000", "date": "2024-08-12_23-37-10", "timestamp": 1723520230, "time_this_iter_s": 52.1341278553009, "time_total_s": 1810.6151955127716, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2b96dc0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1810.6151955127716, "iterations_since_restore": 35, "perf": {"cpu_util_percent": 34.54459459459459, "ram_util_percent": 80.71081081081081}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 7.531752513577699, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.6285150721590353, "policy_loss": -0.016966388151591655, "vf_loss": 2.6433674669770335, "vf_explained_var": 0.1226474523228943, "kl": 0.014093297357272766, "entropy": 1.2882611977360237, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 67095.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 6.519924459823225, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.091827094113385, "policy_loss": -0.011211840289758232, "vf_loss": 6.1016694041156265, "vf_explained_var": 0.4780056526421239, "kl": 0.00913028112647139, "entropy": 1.223637530727992, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 67095.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 144000, "num_env_steps_trained": 144000, "num_agent_steps_sampled": 576000, "num_agent_steps_trained": 576000}, "env_runners": {"episode_reward_max": 391.90000000000003, "episode_reward_min": -57.40000000000036, "episode_reward_mean": 166.85199999999978, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -290.79999999999916, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 198.2, "predator_policy": 148.0}, "policy_reward_mean": {"prey_policy": 69.116, "predator_policy": 14.31}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.0000000000003, 26.000000000000117, 339.09999999999985, 182.39999999999998, 164.29999999999944, 41.30000000000032, 58.50000000000047, 190.7999999999997, 391.90000000000003, 293.7, 184.99999999999932, 175.99999999999935, -57.40000000000036, 40.0000000000003, 40.0000000000003, 40.0000000000003, 50.80000000000048, 177.49999999999926, 191.59999999999934, 183.09999999999926, -31.39999999999955, 154.69999999999962, 160.9999999999994, 37.80000000000027, 103.99999999999947, 169.69999999999905, 278.09999999999985, 68.80000000000011, 187.3999999999993, 69.49999999999996, 320.4000000000001, 149.89999999999964, 47.700000000000074, 347.49999999999994, 149.7999999999995, 202.79999999999927, 201.99999999999926, 274.9, 141.0999999999995, 240.1999999999998, 286.4, 118.49999999999974, 110.19999999999983, 168.9999999999994, 40.0000000000003, 177.29999999999924, 199.79999999999922, 258.1999999999997, 75.9, 89.69999999999999, 180.39999999999927, 134.09999999999965, 40.0000000000003, 174.29999999999933, 298.00000000000006, 267.0999999999999, 190.59999999999994, 239.3999999999997, 40.0000000000003, 366.69999999999993, 126.39999999999966, 225.1999999999999, 185.10000000000002, 193.29999999999927, 107.40000000000003, 276.5, 90.79999999999978, 160.3999999999992, 326.09999999999997, 325.9, 188.39999999999932, 183.0999999999992, 206.09999999999994, 349.60000000000036, 153.39999999999932, 40.0000000000003, 139.7999999999992, 308.0, 88.69999999999997, 85.79999999999986, 136.69999999999948, 125.09999999999934, 163.89999999999947, 215.49999999999923, 40.0000000000003, 327.69999999999993, 108.29999999999967, 136.59999999999977, 27.90000000000012, 215.99999999999926, 184.89999999999932, 88.00000000000006, 241.9, 355.00000000000006, 290.3999999999999, 104.00000000000003, 63.40000000000021, 183.09999999999945, 136.99999999999994, 293.70000000000005], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 20.000000000000014, -8.7999999999999, 0.7999999999999545, 152.5999999999999, 174.5, 16.399999999999984, 59.0, 20.000000000000014, 116.30000000000001, 14.299999999999967, 20.000000000000014, -10.59999999999985, 49.10000000000023, 14.300000000000166, 138.5, 193.7, 198.2, 164.3, 91.39999999999998, 20.000000000000014, 160.99999999999997, -31.599999999999845, 152.59999999999997, -290.79999999999916, 85.39999999999976, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 30.800000000000196, -45.6999999999998, 180.1999999999999, 164.59999999999997, 20.000000000000014, 20.000000000000014, 163.09999999999988, -64.00000000000091, -30.3999999999998, 29.90000000000018, 117.79999999999998, 114.19999999999999, 15.799999999999962, 20.000000000000014, 15.799999999999962, -55.600000000000335, 104.59999999999988, 147.79999999999976, 17.899999999999977, 175.99999999999994, 76.10000000000001, 48.80000000000021, 20.000000000000014, 133.69999999999996, 31.70000000000021, 20.000000000000014, 6.499999999999999, 133.99999999999994, 163.39999999999998, -0.9999999999999952, 137.90000000000003, 6.499999999999992, -14.799999999999912, 183.79999999999995, 154.70000000000002, 102.79999999999994, 20.000000000000014, 20.000000000000014, 177.79999999999995, 20.000000000000014, 181.99999999999994, 83.90000000000002, 172.99999999999997, 20.000000000000014, 58.1, 87.19999999999997, 137.0, 154.7, 94.69999999999996, 5.299999999999993, 105.19999999999999, 20.000000000000014, 45.20000000000002, 98.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 156.19999999999993, 1.0999999999999617, 20.000000000000014, 177.79999999999993, 88.99999999999997, 162.19999999999996, -30.099999999999987, 20.000000000000014, 16.699999999999875, 20.000000000000014, 20.000000000000014, 142.39999999999998, 20.000000000000014, 112.1, 20.000000000000014, 20.000000000000014, 137.3, 20.000000000000014, 107.89999999999998, 145.1, 111.8, 128.29999999999995, 41.300000000000004, 29.300000000000004, 57.49999999999999, 161.89999999999995, 20.000000000000014, 20.000000000000014, 168.5, 198.2, 128.89999999999998, -32.49999999999975, 89.89999999999998, 86.30000000000001, 41.900000000000006, 78.2, -29.499999999999815, 183.79999999999998, 77.29999999999998, -73.9, 185.0, 63.5, 17.899999999999988, 14.900000000000006, 20.000000000000014, 121.39999999999988, 197.29999999999998, 96.80000000000001, 192.79999999999995, 109.1, 163.39999999999998, 20.000000000000014, 163.0999999999999, 20.000000000000014, 70.1, 47.000000000000014, 187.39999999999992, 153.19999999999996, 15.799999999999963, 119.59999999999991, 20.000000000000014, 20.000000000000014, 87.79999999999997, 20.000000000000014, 147.8, 150.19999999999996, -13.29999999999999, 20.000000000000014, 33.79999999999998, 20.000000000000014, 82.70000000000002, 20.000000000000014, 58.10000000000002, 20.000000000000014, 20.000000000000014, 119.89999999999998, 20.000000000000014, 195.49999999999997, 20.000000000000014, 20.000000000000014, 125.29999999999995, 178.4, -32.49999999999978, 84.8, 4.100000000000012, 45.50000000000001, -3.099999999999979, 20.000000000000014, 194.0, 20.000000000000014, 20.000000000000014, 164.89999999999992, 20.000000000000014, 64.99999999999997, 53.00000000000001, 140.9, 160.39999999999998, 194.6, 130.99999999999997, 133.39999999999998, 28.69999999999999, -12.699999999999996, 20.000000000000014, 34.39999999999996, 20.000000000000014, 163.1, 92.6, -28.599999999999987, 109.69999999999999, 161.0], "policy_predator_policy_reward": [0.0, 0.0, 10.0, 24.0, 9.0, 3.0, 47.0, 60.0, 14.0, 14.0, 5.0, 2.0, 20.0, 0.0, 18.0, 20.0, 0.0, 0.0, 24.0, 14.0, 0.0, 4.0, 26.0, 29.0, 0.0, 148.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 18.0, 25.0, 6.0, 1.0, 0.0, 0.0, 63.0, 0.0, 6.0, 1.0, 20.0, 11.0, 0.0, 2.0, 50.0, 5.0, 3.0, 1.0, 3.0, 23.0, 0.0, 0.0, 8.0, 14.0, 8.0, 35.0, 9.0, 14.0, 13.0, 0.0, 33.0, 23.0, 0.0, 9.0, 27.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 18.0, 34.0, 29.0, 15.0, 1.0, 9.0, 28.0, 4.0, 4.0, 25.0, 20.0, 18.0, 33.0, 0.0, 0.0, 10.0, 10.0, 0.0, 2.0, 0.0, 7.0, 59.0, 27.0, 52.0, 1.0, 16.0, 2.0, 0.0, 2.0, 0.0, 0.0, 10.0, 7.0, 25.0, 20.0, 13.0, 14.0, 65.0, 55.0, 3.0, 17.0, 0.0, 0.0, 0.0, 0.0, 5.0, 25.0, 0.0, 49.0, 40.0, 25.0, 23.0, 16.0, 33.0, 71.0, 28.0, 0.0, 32.0, 26.0, 0.0, 19.0, 0.0, 32.0, 24.0, 0.0, 5.0, 0.0, 0.0, 0.0, 55.0, 34.0, 3.0, 6.0, 16.0, 2.0, 0.0, 0.0, 32.0, 0.0, 0.0, 10.0, 59.0, 23.0, 17.0, 15.0, 26.0, 8.0, 21.0, 26.0, 24.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.0, 0.0, 24.0, 32.0, 56.0, 31.0, 0.0, 11.0, 2.0, 0.0, 0.0, 0.0, 1.0, 2.0, 48.0, 0.0, 0.0, 0.0, 26.0, 0.0, 11.0, 77.0, 0.0, 9.0, 0.0, 0.0, 73.0, 0.0, 0.0, 23.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6801730281664305, "mean_inference_ms": 1.6490749053663256, "mean_action_processing_ms": 0.26934770745739534, "mean_env_wait_ms": 0.20108420045322817, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005104660987854004, "StateBufferConnector_ms": 0.003905653953552246, "ViewRequirementAgentConnector_ms": 0.11320352554321289}, "num_episodes": 22, "episode_return_max": 391.90000000000003, "episode_return_min": -57.40000000000036, "episode_return_mean": 166.85199999999978, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 576000, "num_agent_steps_trained": 576000, "num_env_steps_sampled": 144000, "num_env_steps_trained": 144000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 75.08373617392554, "num_env_steps_trained_throughput_per_sec": 75.08373617392554, "timesteps_total": 144000, "num_env_steps_sampled_lifetime": 144000, "num_agent_steps_sampled_lifetime": 576000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 576000, "timers": {"training_iteration_time_ms": 52238.261, "restore_workers_time_ms": 0.013, "training_step_time_ms": 52238.22, "sample_time_ms": 1454.603, "learn_time_ms": 50766.179, "learn_throughput": 78.793, "synch_weights_time_ms": 12.915}, "counters": {"num_env_steps_sampled": 144000, "num_env_steps_trained": 144000, "num_agent_steps_sampled": 576000, "num_agent_steps_trained": 576000}, "done": false, "training_iteration": 36, "trial_id": "11e70_00000", "date": "2024-08-12_23-38-04", "timestamp": 1723520284, "time_this_iter_s": 53.32525086402893, "time_total_s": 1863.9404463768005, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3f39af0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1863.9404463768005, "iterations_since_restore": 36, "perf": {"cpu_util_percent": 38.27631578947368, "ram_util_percent": 82.22631578947367}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 6.284601674256502, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.7317685446411213, "policy_loss": -0.007384162160282136, "vf_loss": 3.7375485130088038, "vf_explained_var": 0.023617696131347978, "kl": 0.010694632833266788, "entropy": 1.2822838131082122, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 68985.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 6.1543825611550975, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.699375645067326, "policy_loss": -0.007202179782664177, "vf_loss": 5.70517907344475, "vf_explained_var": 0.19506748520508013, "kl": 0.00932502675252465, "entropy": 1.2162475473666317, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 68985.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 148000, "num_env_steps_trained": 148000, "num_agent_steps_sampled": 592000, "num_agent_steps_trained": 592000}, "env_runners": {"episode_reward_max": 366.69999999999993, "episode_reward_min": -60.60000000000002, "episode_reward_mean": 165.4889999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -630.1, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 198.2, "predator_policy": 512.0}, "policy_reward_mean": {"prey_policy": 65.0195, "predator_policy": 17.725}, "custom_metrics": {}, "hist_stats": {"episode_reward": [37.80000000000027, 103.99999999999947, 169.69999999999905, 278.09999999999985, 68.80000000000011, 187.3999999999993, 69.49999999999996, 320.4000000000001, 149.89999999999964, 47.700000000000074, 347.49999999999994, 149.7999999999995, 202.79999999999927, 201.99999999999926, 274.9, 141.0999999999995, 240.1999999999998, 286.4, 118.49999999999974, 110.19999999999983, 168.9999999999994, 40.0000000000003, 177.29999999999924, 199.79999999999922, 258.1999999999997, 75.9, 89.69999999999999, 180.39999999999927, 134.09999999999965, 40.0000000000003, 174.29999999999933, 298.00000000000006, 267.0999999999999, 190.59999999999994, 239.3999999999997, 40.0000000000003, 366.69999999999993, 126.39999999999966, 225.1999999999999, 185.10000000000002, 193.29999999999927, 107.40000000000003, 276.5, 90.79999999999978, 160.3999999999992, 326.09999999999997, 325.9, 188.39999999999932, 183.0999999999992, 206.09999999999994, 349.60000000000036, 153.39999999999932, 40.0000000000003, 139.7999999999992, 308.0, 88.69999999999997, 85.79999999999986, 136.69999999999948, 125.09999999999934, 163.89999999999947, 215.49999999999923, 40.0000000000003, 327.69999999999993, 108.29999999999967, 136.59999999999977, 27.90000000000012, 215.99999999999926, 184.89999999999932, 88.00000000000006, 241.9, 355.00000000000006, 290.3999999999999, 104.00000000000003, 63.40000000000021, 183.09999999999945, 136.99999999999994, 293.70000000000005, 140.49999999999957, 40.0000000000003, 212.79999999999924, 190.2999999999994, 67.00000000000024, 135.39999999999966, 221.79999999999998, 165.89999999999947, 177.49999999999932, 34.50000000000022, -60.60000000000002, 83.89999999999989, 73.2999999999997, 225.2, 296.8, 233.69999999999985, 121.19999999999996, 211.8999999999993, -48.70000000000085, 45.600000000000165, 143.49999999999926, 132.6999999999998, 58.39999999999999], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 15.799999999999962, -55.600000000000335, 104.59999999999988, 147.79999999999976, 17.899999999999977, 175.99999999999994, 76.10000000000001, 48.80000000000021, 20.000000000000014, 133.69999999999996, 31.70000000000021, 20.000000000000014, 6.499999999999999, 133.99999999999994, 163.39999999999998, -0.9999999999999952, 137.90000000000003, 6.499999999999992, -14.799999999999912, 183.79999999999995, 154.70000000000002, 102.79999999999994, 20.000000000000014, 20.000000000000014, 177.79999999999995, 20.000000000000014, 181.99999999999994, 83.90000000000002, 172.99999999999997, 20.000000000000014, 58.1, 87.19999999999997, 137.0, 154.7, 94.69999999999996, 5.299999999999993, 105.19999999999999, 20.000000000000014, 45.20000000000002, 98.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 156.19999999999993, 1.0999999999999617, 20.000000000000014, 177.79999999999993, 88.99999999999997, 162.19999999999996, -30.099999999999987, 20.000000000000014, 16.699999999999875, 20.000000000000014, 20.000000000000014, 142.39999999999998, 20.000000000000014, 112.1, 20.000000000000014, 20.000000000000014, 137.3, 20.000000000000014, 107.89999999999998, 145.1, 111.8, 128.29999999999995, 41.300000000000004, 29.300000000000004, 57.49999999999999, 161.89999999999995, 20.000000000000014, 20.000000000000014, 168.5, 198.2, 128.89999999999998, -32.49999999999975, 89.89999999999998, 86.30000000000001, 41.900000000000006, 78.2, -29.499999999999815, 183.79999999999998, 77.29999999999998, -73.9, 185.0, 63.5, 17.899999999999988, 14.900000000000006, 20.000000000000014, 121.39999999999988, 197.29999999999998, 96.80000000000001, 192.79999999999995, 109.1, 163.39999999999998, 20.000000000000014, 163.0999999999999, 20.000000000000014, 70.1, 47.000000000000014, 187.39999999999992, 153.19999999999996, 15.799999999999963, 119.59999999999991, 20.000000000000014, 20.000000000000014, 87.79999999999997, 20.000000000000014, 147.8, 150.19999999999996, -13.29999999999999, 20.000000000000014, 33.79999999999998, 20.000000000000014, 82.70000000000002, 20.000000000000014, 58.10000000000002, 20.000000000000014, 20.000000000000014, 119.89999999999998, 20.000000000000014, 195.49999999999997, 20.000000000000014, 20.000000000000014, 125.29999999999995, 178.4, -32.49999999999978, 84.8, 4.100000000000012, 45.50000000000001, -3.099999999999979, 20.000000000000014, 194.0, 20.000000000000014, 20.000000000000014, 164.89999999999992, 20.000000000000014, 64.99999999999997, 53.00000000000001, 140.9, 160.39999999999998, 194.6, 130.99999999999997, 133.39999999999998, 28.69999999999999, -12.699999999999996, 20.000000000000014, 34.39999999999996, 20.000000000000014, 163.1, 92.6, -28.599999999999987, 109.69999999999999, 161.0, 169.7, -89.20000000000083, 20.000000000000014, 20.000000000000014, 20.000000000000014, 192.79999999999995, 20.000000000000014, 170.3, 20.000000000000014, 46.99999999999997, 88.4, 20.000000000000014, 62.6, 99.19999999999999, 131.89999999999998, 20.000000000000014, 20.000000000000014, 138.5, 20.000000000000014, 9.499999999999964, -630.1, -2.499999999999986, 26.90000000000004, 20.000000000000014, -18.69999999999999, 20.000000000000014, 79.4, 93.79999999999998, 151.7, 124.1, 139.3999999999999, 77.29999999999998, 33.799999999999955, 19.400000000000006, 191.9, 20.000000000000014, -45.09999999999976, -34.59999999999975, 20.000000000000014, -30.40000000000002, 20.000000000000014, 87.5, 76.7, 20.000000000000014, 6.200000000000001, -89.79999999999998], "policy_predator_policy_reward": [0.0, 2.0, 50.0, 5.0, 3.0, 1.0, 3.0, 23.0, 0.0, 0.0, 8.0, 14.0, 8.0, 35.0, 9.0, 14.0, 13.0, 0.0, 33.0, 23.0, 0.0, 9.0, 27.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 18.0, 34.0, 29.0, 15.0, 1.0, 9.0, 28.0, 4.0, 4.0, 25.0, 20.0, 18.0, 33.0, 0.0, 0.0, 10.0, 10.0, 0.0, 2.0, 0.0, 7.0, 59.0, 27.0, 52.0, 1.0, 16.0, 2.0, 0.0, 2.0, 0.0, 0.0, 10.0, 7.0, 25.0, 20.0, 13.0, 14.0, 65.0, 55.0, 3.0, 17.0, 0.0, 0.0, 0.0, 0.0, 5.0, 25.0, 0.0, 49.0, 40.0, 25.0, 23.0, 16.0, 33.0, 71.0, 28.0, 0.0, 32.0, 26.0, 0.0, 19.0, 0.0, 32.0, 24.0, 0.0, 5.0, 0.0, 0.0, 0.0, 55.0, 34.0, 3.0, 6.0, 16.0, 2.0, 0.0, 0.0, 32.0, 0.0, 0.0, 10.0, 59.0, 23.0, 17.0, 15.0, 26.0, 8.0, 21.0, 26.0, 24.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.0, 0.0, 24.0, 32.0, 56.0, 31.0, 0.0, 11.0, 2.0, 0.0, 0.0, 0.0, 1.0, 2.0, 48.0, 0.0, 0.0, 0.0, 26.0, 0.0, 11.0, 77.0, 0.0, 9.0, 0.0, 0.0, 73.0, 0.0, 0.0, 23.0, 52.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 14.0, 13.0, 40.0, 20.0, 14.0, 0.0, 15.0, 4.0, 0.0, 5.0, 512.0, 60.0, 35.0, 2.0, 34.0, 38.0, 33.0, 19.0, 3.0, 18.0, 0.0, 17.0, 0.0, 68.0, 0.0, 0.0, 0.0, 31.0, 40.0, 16.0, 36.0, 0.0, 18.0, 18.0, 78.0, 64.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6819902784854304, "mean_inference_ms": 1.6491385011600426, "mean_action_processing_ms": 0.2695998889398255, "mean_env_wait_ms": 0.20147069769039924, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003917098045349121, "StateBufferConnector_ms": 0.0030933618545532227, "ViewRequirementAgentConnector_ms": 0.1083989143371582}, "num_episodes": 23, "episode_return_max": 366.69999999999993, "episode_return_min": -60.60000000000002, "episode_return_mean": 165.4889999999998, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 592000, "num_agent_steps_trained": 592000, "num_env_steps_sampled": 148000, "num_env_steps_trained": 148000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 76.27411756592089, "num_env_steps_trained_throughput_per_sec": 76.27411756592089, "timesteps_total": 148000, "num_env_steps_sampled_lifetime": 148000, "num_agent_steps_sampled_lifetime": 592000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 592000, "timers": {"training_iteration_time_ms": 52403.399, "restore_workers_time_ms": 0.013, "training_step_time_ms": 52403.358, "sample_time_ms": 1466.272, "learn_time_ms": 50920.229, "learn_throughput": 78.554, "synch_weights_time_ms": 13.134}, "counters": {"num_env_steps_sampled": 148000, "num_env_steps_trained": 148000, "num_agent_steps_sampled": 592000, "num_agent_steps_trained": 592000}, "done": false, "training_iteration": 37, "trial_id": "11e70_00000", "date": "2024-08-12_23-38-56", "timestamp": 1723520336, "time_this_iter_s": 52.49139404296875, "time_total_s": 1916.4318404197693, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2b62670>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1916.4318404197693, "iterations_since_restore": 37, "perf": {"cpu_util_percent": 37.645945945945954, "ram_util_percent": 83.10675675675677}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 9.207463085083734, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.4049227674171405, "policy_loss": -0.014225131173485091, "vf_loss": 4.416925214964246, "vf_explained_var": 0.14072679378998973, "kl": 0.014817965800606658, "entropy": 1.2746497642426264, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 70875.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 7.49965733005887, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.382019876550745, "policy_loss": -0.009063781467118552, "vf_loss": 6.390082606562862, "vf_explained_var": 0.1280458551866037, "kl": 0.006673605210516812, "entropy": 1.2263213978242622, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 70875.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 152000, "num_env_steps_trained": 152000, "num_agent_steps_sampled": 608000, "num_agent_steps_trained": 608000}, "env_runners": {"episode_reward_max": 366.69999999999993, "episode_reward_min": -60.60000000000002, "episode_reward_mean": 154.32599999999977, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -630.1, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 198.2, "predator_policy": 512.0}, "policy_reward_mean": {"prey_policy": 56.88799999999999, "predator_policy": 20.275}, "custom_metrics": {}, "hist_stats": {"episode_reward": [118.49999999999974, 110.19999999999983, 168.9999999999994, 40.0000000000003, 177.29999999999924, 199.79999999999922, 258.1999999999997, 75.9, 89.69999999999999, 180.39999999999927, 134.09999999999965, 40.0000000000003, 174.29999999999933, 298.00000000000006, 267.0999999999999, 190.59999999999994, 239.3999999999997, 40.0000000000003, 366.69999999999993, 126.39999999999966, 225.1999999999999, 185.10000000000002, 193.29999999999927, 107.40000000000003, 276.5, 90.79999999999978, 160.3999999999992, 326.09999999999997, 325.9, 188.39999999999932, 183.0999999999992, 206.09999999999994, 349.60000000000036, 153.39999999999932, 40.0000000000003, 139.7999999999992, 308.0, 88.69999999999997, 85.79999999999986, 136.69999999999948, 125.09999999999934, 163.89999999999947, 215.49999999999923, 40.0000000000003, 327.69999999999993, 108.29999999999967, 136.59999999999977, 27.90000000000012, 215.99999999999926, 184.89999999999932, 88.00000000000006, 241.9, 355.00000000000006, 290.3999999999999, 104.00000000000003, 63.40000000000021, 183.09999999999945, 136.99999999999994, 293.70000000000005, 140.49999999999957, 40.0000000000003, 212.79999999999924, 190.2999999999994, 67.00000000000024, 135.39999999999966, 221.79999999999998, 165.89999999999947, 177.49999999999932, 34.50000000000022, -60.60000000000002, 83.89999999999989, 73.2999999999997, 225.2, 296.8, 233.69999999999985, 121.19999999999996, 211.8999999999993, -48.70000000000085, 45.600000000000165, 143.49999999999926, 132.6999999999998, 58.39999999999999, 15.399999999999926, 90.59999999999974, 320.8000000000002, 86.1, 143.5999999999993, 167.2999999999993, 281.5000000000008, 132.9999999999996, 138.79999999999947, 71.29999999999993, 115.69999999999963, 22.000000000000092, 115.60000000000001, 49.20000000000023, 40.0000000000003, 94.9, 161.3999999999994, 114.49999999999997], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [5.299999999999993, 105.19999999999999, 20.000000000000014, 45.20000000000002, 98.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 156.19999999999993, 1.0999999999999617, 20.000000000000014, 177.79999999999993, 88.99999999999997, 162.19999999999996, -30.099999999999987, 20.000000000000014, 16.699999999999875, 20.000000000000014, 20.000000000000014, 142.39999999999998, 20.000000000000014, 112.1, 20.000000000000014, 20.000000000000014, 137.3, 20.000000000000014, 107.89999999999998, 145.1, 111.8, 128.29999999999995, 41.300000000000004, 29.300000000000004, 57.49999999999999, 161.89999999999995, 20.000000000000014, 20.000000000000014, 168.5, 198.2, 128.89999999999998, -32.49999999999975, 89.89999999999998, 86.30000000000001, 41.900000000000006, 78.2, -29.499999999999815, 183.79999999999998, 77.29999999999998, -73.9, 185.0, 63.5, 17.899999999999988, 14.900000000000006, 20.000000000000014, 121.39999999999988, 197.29999999999998, 96.80000000000001, 192.79999999999995, 109.1, 163.39999999999998, 20.000000000000014, 163.0999999999999, 20.000000000000014, 70.1, 47.000000000000014, 187.39999999999992, 153.19999999999996, 15.799999999999963, 119.59999999999991, 20.000000000000014, 20.000000000000014, 87.79999999999997, 20.000000000000014, 147.8, 150.19999999999996, -13.29999999999999, 20.000000000000014, 33.79999999999998, 20.000000000000014, 82.70000000000002, 20.000000000000014, 58.10000000000002, 20.000000000000014, 20.000000000000014, 119.89999999999998, 20.000000000000014, 195.49999999999997, 20.000000000000014, 20.000000000000014, 125.29999999999995, 178.4, -32.49999999999978, 84.8, 4.100000000000012, 45.50000000000001, -3.099999999999979, 20.000000000000014, 194.0, 20.000000000000014, 20.000000000000014, 164.89999999999992, 20.000000000000014, 64.99999999999997, 53.00000000000001, 140.9, 160.39999999999998, 194.6, 130.99999999999997, 133.39999999999998, 28.69999999999999, -12.699999999999996, 20.000000000000014, 34.39999999999996, 20.000000000000014, 163.1, 92.6, -28.599999999999987, 109.69999999999999, 161.0, 169.7, -89.20000000000083, 20.000000000000014, 20.000000000000014, 20.000000000000014, 192.79999999999995, 20.000000000000014, 170.3, 20.000000000000014, 46.99999999999997, 88.4, 20.000000000000014, 62.6, 99.19999999999999, 131.89999999999998, 20.000000000000014, 20.000000000000014, 138.5, 20.000000000000014, 9.499999999999964, -630.1, -2.499999999999986, 26.90000000000004, 20.000000000000014, -18.69999999999999, 20.000000000000014, 79.4, 93.79999999999998, 151.7, 124.1, 139.3999999999999, 77.29999999999998, 33.799999999999955, 19.400000000000006, 191.9, 20.000000000000014, -45.09999999999976, -34.59999999999975, 20.000000000000014, -30.40000000000002, 20.000000000000014, 87.5, 76.7, 20.000000000000014, 6.200000000000001, -89.79999999999998, -48.99999999999999, -13.600000000000072, -0.40000000000000346, 20.000000000000014, 121.1, 178.69999999999996, 14.900000000000006, -53.80000000000001, 130.39999999999984, -17.79999999999974, 131.29999999999998, 20.000000000000014, 125.59999999999975, 131.89999999999998, 74.0, 20.000000000000014, 20.000000000000014, 81.80000000000001, 20.000000000000014, -12.699999999999992, 73.70000000000006, 20.000000000000014, -45.099999999999774, -40.9, 107.9, -94.29999999999998, 20.000000000000014, 12.19999999999996, 20.000000000000014, 20.000000000000014, 28.400000000000006, -8.499999999999993, 146.89999999999992, 9.499999999999966, 51.20000000000001, -30.699999999999996], "policy_predator_policy_reward": [4.0, 4.0, 25.0, 20.0, 18.0, 33.0, 0.0, 0.0, 10.0, 10.0, 0.0, 2.0, 0.0, 7.0, 59.0, 27.0, 52.0, 1.0, 16.0, 2.0, 0.0, 2.0, 0.0, 0.0, 10.0, 7.0, 25.0, 20.0, 13.0, 14.0, 65.0, 55.0, 3.0, 17.0, 0.0, 0.0, 0.0, 0.0, 5.0, 25.0, 0.0, 49.0, 40.0, 25.0, 23.0, 16.0, 33.0, 71.0, 28.0, 0.0, 32.0, 26.0, 0.0, 19.0, 0.0, 32.0, 24.0, 0.0, 5.0, 0.0, 0.0, 0.0, 55.0, 34.0, 3.0, 6.0, 16.0, 2.0, 0.0, 0.0, 32.0, 0.0, 0.0, 10.0, 59.0, 23.0, 17.0, 15.0, 26.0, 8.0, 21.0, 26.0, 24.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.0, 0.0, 24.0, 32.0, 56.0, 31.0, 0.0, 11.0, 2.0, 0.0, 0.0, 0.0, 1.0, 2.0, 48.0, 0.0, 0.0, 0.0, 26.0, 0.0, 11.0, 77.0, 0.0, 9.0, 0.0, 0.0, 73.0, 0.0, 0.0, 23.0, 52.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 14.0, 13.0, 40.0, 20.0, 14.0, 0.0, 15.0, 4.0, 0.0, 5.0, 512.0, 60.0, 35.0, 2.0, 34.0, 38.0, 33.0, 19.0, 3.0, 18.0, 0.0, 17.0, 0.0, 68.0, 0.0, 0.0, 0.0, 31.0, 40.0, 16.0, 36.0, 0.0, 18.0, 18.0, 78.0, 64.0, 31.0, 47.0, 46.0, 25.0, 0.0, 21.0, 52.0, 73.0, 13.0, 18.0, 10.0, 6.0, 5.0, 19.0, 25.0, 14.0, 4.0, 33.0, 33.0, 31.0, 22.0, 0.0, 31.0, 77.0, 23.0, 79.0, 17.0, 0.0, 0.0, 0.0, 75.0, 0.0, 0.0, 5.0, 46.0, 48.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6833121831408981, "mean_inference_ms": 1.6491681470456752, "mean_action_processing_ms": 0.2701751252475044, "mean_env_wait_ms": 0.2018845878622947, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003914237022399902, "StateBufferConnector_ms": 0.0031752586364746094, "ViewRequirementAgentConnector_ms": 0.10603713989257812}, "num_episodes": 18, "episode_return_max": 366.69999999999993, "episode_return_min": -60.60000000000002, "episode_return_mean": 154.32599999999977, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 608000, "num_agent_steps_trained": 608000, "num_env_steps_sampled": 152000, "num_env_steps_trained": 152000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 76.16786079903147, "num_env_steps_trained_throughput_per_sec": 76.16786079903147, "timesteps_total": 152000, "num_env_steps_sampled_lifetime": 152000, "num_agent_steps_sampled_lifetime": 608000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 608000, "timers": {"training_iteration_time_ms": 52401.004, "restore_workers_time_ms": 0.013, "training_step_time_ms": 52400.963, "sample_time_ms": 1313.038, "learn_time_ms": 51070.781, "learn_throughput": 78.323, "synch_weights_time_ms": 13.579}, "counters": {"num_env_steps_sampled": 152000, "num_env_steps_trained": 152000, "num_agent_steps_sampled": 608000, "num_agent_steps_trained": 608000}, "done": false, "training_iteration": 38, "trial_id": "11e70_00000", "date": "2024-08-12_23-39-49", "timestamp": 1723520389, "time_this_iter_s": 52.52934288978577, "time_total_s": 1968.961183309555, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2b02430>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1968.961183309555, "iterations_since_restore": 38, "perf": {"cpu_util_percent": 37.54666666666667, "ram_util_percent": 82.39333333333335}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 8.859639986103804, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.356945865368717, "policy_loss": -0.015410746402654146, "vf_loss": 5.369634285931864, "vf_explained_var": 0.14046782457008564, "kl": 0.01814874883303197, "entropy": 1.2748223287718636, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 72765.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 6.973291199926346, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.773106209184758, "policy_loss": -0.009679492546748074, "vf_loss": 6.781195668568687, "vf_explained_var": -0.04565952880672677, "kl": 0.010600148667893716, "entropy": 1.2454613519724085, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 72765.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 156000, "num_env_steps_trained": 156000, "num_agent_steps_sampled": 624000, "num_agent_steps_trained": 624000}, "env_runners": {"episode_reward_max": 366.69999999999993, "episode_reward_min": -118.90000000000002, "episode_reward_mean": 143.1409999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -630.1, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 198.2, "predator_policy": 512.0}, "policy_reward_mean": {"prey_policy": 47.040499999999994, "predator_policy": 24.53}, "custom_metrics": {}, "hist_stats": {"episode_reward": [366.69999999999993, 126.39999999999966, 225.1999999999999, 185.10000000000002, 193.29999999999927, 107.40000000000003, 276.5, 90.79999999999978, 160.3999999999992, 326.09999999999997, 325.9, 188.39999999999932, 183.0999999999992, 206.09999999999994, 349.60000000000036, 153.39999999999932, 40.0000000000003, 139.7999999999992, 308.0, 88.69999999999997, 85.79999999999986, 136.69999999999948, 125.09999999999934, 163.89999999999947, 215.49999999999923, 40.0000000000003, 327.69999999999993, 108.29999999999967, 136.59999999999977, 27.90000000000012, 215.99999999999926, 184.89999999999932, 88.00000000000006, 241.9, 355.00000000000006, 290.3999999999999, 104.00000000000003, 63.40000000000021, 183.09999999999945, 136.99999999999994, 293.70000000000005, 140.49999999999957, 40.0000000000003, 212.79999999999924, 190.2999999999994, 67.00000000000024, 135.39999999999966, 221.79999999999998, 165.89999999999947, 177.49999999999932, 34.50000000000022, -60.60000000000002, 83.89999999999989, 73.2999999999997, 225.2, 296.8, 233.69999999999985, 121.19999999999996, 211.8999999999993, -48.70000000000085, 45.600000000000165, 143.49999999999926, 132.6999999999998, 58.39999999999999, 15.399999999999926, 90.59999999999974, 320.8000000000002, 86.1, 143.5999999999993, 167.2999999999993, 281.5000000000008, 132.9999999999996, 138.79999999999947, 71.29999999999993, 115.69999999999963, 22.000000000000092, 115.60000000000001, 49.20000000000023, 40.0000000000003, 94.9, 161.3999999999994, 114.49999999999997, -62.5, 104.99999999999991, -118.90000000000002, 8.100000000000025, 148.1999999999992, -16.799999999999883, 121.89999999999996, 15.500000000000021, 156.5, 188.29999999999936, 316.9, 157.60000000000002, 280.4000000000001, -5.80000000000004, 68.3, 148.79999999999998, 73.30000000000013, 99.19999999999999], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [168.5, 198.2, 128.89999999999998, -32.49999999999975, 89.89999999999998, 86.30000000000001, 41.900000000000006, 78.2, -29.499999999999815, 183.79999999999998, 77.29999999999998, -73.9, 185.0, 63.5, 17.899999999999988, 14.900000000000006, 20.000000000000014, 121.39999999999988, 197.29999999999998, 96.80000000000001, 192.79999999999995, 109.1, 163.39999999999998, 20.000000000000014, 163.0999999999999, 20.000000000000014, 70.1, 47.000000000000014, 187.39999999999992, 153.19999999999996, 15.799999999999963, 119.59999999999991, 20.000000000000014, 20.000000000000014, 87.79999999999997, 20.000000000000014, 147.8, 150.19999999999996, -13.29999999999999, 20.000000000000014, 33.79999999999998, 20.000000000000014, 82.70000000000002, 20.000000000000014, 58.10000000000002, 20.000000000000014, 20.000000000000014, 119.89999999999998, 20.000000000000014, 195.49999999999997, 20.000000000000014, 20.000000000000014, 125.29999999999995, 178.4, -32.49999999999978, 84.8, 4.100000000000012, 45.50000000000001, -3.099999999999979, 20.000000000000014, 194.0, 20.000000000000014, 20.000000000000014, 164.89999999999992, 20.000000000000014, 64.99999999999997, 53.00000000000001, 140.9, 160.39999999999998, 194.6, 130.99999999999997, 133.39999999999998, 28.69999999999999, -12.699999999999996, 20.000000000000014, 34.39999999999996, 20.000000000000014, 163.1, 92.6, -28.599999999999987, 109.69999999999999, 161.0, 169.7, -89.20000000000083, 20.000000000000014, 20.000000000000014, 20.000000000000014, 192.79999999999995, 20.000000000000014, 170.3, 20.000000000000014, 46.99999999999997, 88.4, 20.000000000000014, 62.6, 99.19999999999999, 131.89999999999998, 20.000000000000014, 20.000000000000014, 138.5, 20.000000000000014, 9.499999999999964, -630.1, -2.499999999999986, 26.90000000000004, 20.000000000000014, -18.69999999999999, 20.000000000000014, 79.4, 93.79999999999998, 151.7, 124.1, 139.3999999999999, 77.29999999999998, 33.799999999999955, 19.400000000000006, 191.9, 20.000000000000014, -45.09999999999976, -34.59999999999975, 20.000000000000014, -30.40000000000002, 20.000000000000014, 87.5, 76.7, 20.000000000000014, 6.200000000000001, -89.79999999999998, -48.99999999999999, -13.600000000000072, -0.40000000000000346, 20.000000000000014, 121.1, 178.69999999999996, 14.900000000000006, -53.80000000000001, 130.39999999999984, -17.79999999999974, 131.29999999999998, 20.000000000000014, 125.59999999999975, 131.89999999999998, 74.0, 20.000000000000014, 20.000000000000014, 81.80000000000001, 20.000000000000014, -12.699999999999992, 73.70000000000006, 20.000000000000014, -45.099999999999774, -40.9, 107.9, -94.29999999999998, 20.000000000000014, 12.19999999999996, 20.000000000000014, 20.000000000000014, 28.400000000000006, -8.499999999999993, 146.89999999999992, 9.499999999999966, 51.20000000000001, -30.699999999999996, -145.0, -65.5, 32.000000000000014, 14.0, -127.6, -133.3, -40.89999999999979, 20.000000000000014, 102.1999999999999, 20.000000000000014, 20.000000000000014, -182.8, -3.3999999999999932, 41.300000000000004, -95.20000000000002, -25.299999999999997, 77.29999999999998, 12.200000000000003, 27.499999999999993, 141.79999999999998, 137.0, 155.89999999999998, 59.89999999999999, 58.699999999999974, 113.0, 124.39999999999998, 20.000000000000014, -119.8, 20.000000000000014, -30.699999999999996, 46.4, 37.39999999999999, 41.0, -57.70000000000048, 46.099999999999994, -28.900000000000006], "policy_predator_policy_reward": [0.0, 0.0, 5.0, 25.0, 0.0, 49.0, 40.0, 25.0, 23.0, 16.0, 33.0, 71.0, 28.0, 0.0, 32.0, 26.0, 0.0, 19.0, 0.0, 32.0, 24.0, 0.0, 5.0, 0.0, 0.0, 0.0, 55.0, 34.0, 3.0, 6.0, 16.0, 2.0, 0.0, 0.0, 32.0, 0.0, 0.0, 10.0, 59.0, 23.0, 17.0, 15.0, 26.0, 8.0, 21.0, 26.0, 24.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.0, 0.0, 24.0, 32.0, 56.0, 31.0, 0.0, 11.0, 2.0, 0.0, 0.0, 0.0, 1.0, 2.0, 48.0, 0.0, 0.0, 0.0, 26.0, 0.0, 11.0, 77.0, 0.0, 9.0, 0.0, 0.0, 73.0, 0.0, 0.0, 23.0, 52.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 14.0, 13.0, 40.0, 20.0, 14.0, 0.0, 15.0, 4.0, 0.0, 5.0, 512.0, 60.0, 35.0, 2.0, 34.0, 38.0, 33.0, 19.0, 3.0, 18.0, 0.0, 17.0, 0.0, 68.0, 0.0, 0.0, 0.0, 31.0, 40.0, 16.0, 36.0, 0.0, 18.0, 18.0, 78.0, 64.0, 31.0, 47.0, 46.0, 25.0, 0.0, 21.0, 52.0, 73.0, 13.0, 18.0, 10.0, 6.0, 5.0, 19.0, 25.0, 14.0, 4.0, 33.0, 33.0, 31.0, 22.0, 0.0, 31.0, 77.0, 23.0, 79.0, 17.0, 0.0, 0.0, 0.0, 75.0, 0.0, 0.0, 5.0, 46.0, 48.0, 66.0, 82.0, 0.0, 59.0, 82.0, 60.0, 0.0, 29.0, 26.0, 0.0, 35.0, 111.0, 0.0, 84.0, 82.0, 54.0, 39.0, 28.0, 0.0, 19.0, 24.0, 0.0, 39.0, 0.0, 5.0, 38.0, 30.0, 64.0, 22.0, 57.0, 1.0, 64.0, 37.0, 53.0, 0.0, 82.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6848116739735967, "mean_inference_ms": 1.6495108167416646, "mean_action_processing_ms": 0.2708021287541957, "mean_env_wait_ms": 0.20228266639530795, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004189968109130859, "StateBufferConnector_ms": 0.0031834840774536133, "ViewRequirementAgentConnector_ms": 0.10563242435455322}, "num_episodes": 18, "episode_return_max": 366.69999999999993, "episode_return_min": -118.90000000000002, "episode_return_mean": 143.1409999999998, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 624000, "num_agent_steps_trained": 624000, "num_env_steps_sampled": 156000, "num_env_steps_trained": 156000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 74.28069643908628, "num_env_steps_trained_throughput_per_sec": 74.28069643908628, "timesteps_total": 156000, "num_env_steps_sampled_lifetime": 156000, "num_agent_steps_sampled_lifetime": 624000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 624000, "timers": {"training_iteration_time_ms": 52614.548, "restore_workers_time_ms": 0.013, "training_step_time_ms": 52614.508, "sample_time_ms": 1303.836, "learn_time_ms": 51293.452, "learn_throughput": 77.983, "synch_weights_time_ms": 13.725}, "counters": {"num_env_steps_sampled": 156000, "num_env_steps_trained": 156000, "num_agent_steps_sampled": 624000, "num_agent_steps_trained": 624000}, "done": false, "training_iteration": 39, "trial_id": "11e70_00000", "date": "2024-08-12_23-40-43", "timestamp": 1723520443, "time_this_iter_s": 53.8982207775116, "time_total_s": 2022.8594040870667, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3f39670>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2022.8594040870667, "iterations_since_restore": 39, "perf": {"cpu_util_percent": 41.664935064935065, "ram_util_percent": 82.69999999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 8.251548038651704, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.181452002348723, "policy_loss": -0.012688902779802601, "vf_loss": 6.1916977482498, "vf_explained_var": 0.13443278074264525, "kl": 0.016287652211041014, "entropy": 1.214928575419875, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 74655.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 6.117815164661912, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.29979270526341, "policy_loss": -0.010408175793333502, "vf_loss": 7.308812363690169, "vf_explained_var": -0.19078002007550032, "kl": 0.009256813137274684, "entropy": 1.236761036184099, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 74655.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 160000, "num_env_steps_trained": 160000, "num_agent_steps_sampled": 640000, "num_agent_steps_trained": 640000}, "env_runners": {"episode_reward_max": 355.00000000000006, "episode_reward_min": -168.1, "episode_reward_mean": 106.96399999999987, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -630.1, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 195.49999999999997, "predator_policy": 512.0}, "policy_reward_mean": {"prey_policy": 21.076999999999998, "predator_policy": 32.405}, "custom_metrics": {}, "hist_stats": {"episode_reward": [125.09999999999934, 163.89999999999947, 215.49999999999923, 40.0000000000003, 327.69999999999993, 108.29999999999967, 136.59999999999977, 27.90000000000012, 215.99999999999926, 184.89999999999932, 88.00000000000006, 241.9, 355.00000000000006, 290.3999999999999, 104.00000000000003, 63.40000000000021, 183.09999999999945, 136.99999999999994, 293.70000000000005, 140.49999999999957, 40.0000000000003, 212.79999999999924, 190.2999999999994, 67.00000000000024, 135.39999999999966, 221.79999999999998, 165.89999999999947, 177.49999999999932, 34.50000000000022, -60.60000000000002, 83.89999999999989, 73.2999999999997, 225.2, 296.8, 233.69999999999985, 121.19999999999996, 211.8999999999993, -48.70000000000085, 45.600000000000165, 143.49999999999926, 132.6999999999998, 58.39999999999999, 15.399999999999926, 90.59999999999974, 320.8000000000002, 86.1, 143.5999999999993, 167.2999999999993, 281.5000000000008, 132.9999999999996, 138.79999999999947, 71.29999999999993, 115.69999999999963, 22.000000000000092, 115.60000000000001, 49.20000000000023, 40.0000000000003, 94.9, 161.3999999999994, 114.49999999999997, -62.5, 104.99999999999991, -118.90000000000002, 8.100000000000025, 148.1999999999992, -16.799999999999883, 121.89999999999996, 15.500000000000021, 156.5, 188.29999999999936, 316.9, 157.60000000000002, 280.4000000000001, -5.80000000000004, 68.3, 148.79999999999998, 73.30000000000013, 99.19999999999999, -39.79999999999986, -119.79999999999993, 22.400000000000013, 91.69999999999999, 65.60000000000028, -20.69999999999999, 113.89999999999961, -38.39999999999982, 113.6, 40.0000000000003, 82.80000000000001, 126.69999999999993, -4.699999999999994, 169.09999999999994, 32.700000000000216, -8.199999999999898, 38.30000000000026, -96.5, -45.699999999999896, 180.79999999999995, 109.99999999999991, -168.1], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [58.10000000000002, 20.000000000000014, 20.000000000000014, 119.89999999999998, 20.000000000000014, 195.49999999999997, 20.000000000000014, 20.000000000000014, 125.29999999999995, 178.4, -32.49999999999978, 84.8, 4.100000000000012, 45.50000000000001, -3.099999999999979, 20.000000000000014, 194.0, 20.000000000000014, 20.000000000000014, 164.89999999999992, 20.000000000000014, 64.99999999999997, 53.00000000000001, 140.9, 160.39999999999998, 194.6, 130.99999999999997, 133.39999999999998, 28.69999999999999, -12.699999999999996, 20.000000000000014, 34.39999999999996, 20.000000000000014, 163.1, 92.6, -28.599999999999987, 109.69999999999999, 161.0, 169.7, -89.20000000000083, 20.000000000000014, 20.000000000000014, 20.000000000000014, 192.79999999999995, 20.000000000000014, 170.3, 20.000000000000014, 46.99999999999997, 88.4, 20.000000000000014, 62.6, 99.19999999999999, 131.89999999999998, 20.000000000000014, 20.000000000000014, 138.5, 20.000000000000014, 9.499999999999964, -630.1, -2.499999999999986, 26.90000000000004, 20.000000000000014, -18.69999999999999, 20.000000000000014, 79.4, 93.79999999999998, 151.7, 124.1, 139.3999999999999, 77.29999999999998, 33.799999999999955, 19.400000000000006, 191.9, 20.000000000000014, -45.09999999999976, -34.59999999999975, 20.000000000000014, -30.40000000000002, 20.000000000000014, 87.5, 76.7, 20.000000000000014, 6.200000000000001, -89.79999999999998, -48.99999999999999, -13.600000000000072, -0.40000000000000346, 20.000000000000014, 121.1, 178.69999999999996, 14.900000000000006, -53.80000000000001, 130.39999999999984, -17.79999999999974, 131.29999999999998, 20.000000000000014, 125.59999999999975, 131.89999999999998, 74.0, 20.000000000000014, 20.000000000000014, 81.80000000000001, 20.000000000000014, -12.699999999999992, 73.70000000000006, 20.000000000000014, -45.099999999999774, -40.9, 107.9, -94.29999999999998, 20.000000000000014, 12.19999999999996, 20.000000000000014, 20.000000000000014, 28.400000000000006, -8.499999999999993, 146.89999999999992, 9.499999999999966, 51.20000000000001, -30.699999999999996, -145.0, -65.5, 32.000000000000014, 14.0, -127.6, -133.3, -40.89999999999979, 20.000000000000014, 102.1999999999999, 20.000000000000014, 20.000000000000014, -182.8, -3.3999999999999932, 41.300000000000004, -95.20000000000002, -25.299999999999997, 77.29999999999998, 12.200000000000003, 27.499999999999993, 141.79999999999998, 137.0, 155.89999999999998, 59.89999999999999, 58.699999999999974, 113.0, 124.39999999999998, 20.000000000000014, -119.8, 20.000000000000014, -30.699999999999996, 46.4, 37.39999999999999, 41.0, -57.70000000000048, 46.099999999999994, -28.900000000000006, 20.000000000000014, -224.8, -97.30000000000001, -200.5, -13.599999999999783, 20.000000000000014, -57.39999999999999, 34.099999999999994, 20.000000000000014, -24.39999999999999, -147.7, -19.00000000000002, 44.90000000000001, 20.000000000000014, 20.000000000000014, -219.4, 17.3, 26.300000000000004, 20.000000000000014, 20.000000000000014, 15.500000000000005, -33.7, 55.99999999999997, -1.2999999999999972, -156.70000000000002, 20.000000000000014, 10.099999999999994, 94.99999999999997, 20.000000000000014, -91.29999999999998, 20.000000000000014, -182.20000000000005, 20.000000000000014, -108.69999999999999, -133.9, -112.60000000000002, -67.00000000000001, -72.70000000000002, 45.500000000000014, 74.30000000000001, 21.800000000000008, 18.199999999999967, -212.2, -190.9], "policy_predator_policy_reward": [21.0, 26.0, 24.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.0, 0.0, 24.0, 32.0, 56.0, 31.0, 0.0, 11.0, 2.0, 0.0, 0.0, 0.0, 1.0, 2.0, 48.0, 0.0, 0.0, 0.0, 26.0, 0.0, 11.0, 77.0, 0.0, 9.0, 0.0, 0.0, 73.0, 0.0, 0.0, 23.0, 52.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 14.0, 13.0, 40.0, 20.0, 14.0, 0.0, 15.0, 4.0, 0.0, 5.0, 512.0, 60.0, 35.0, 2.0, 34.0, 38.0, 33.0, 19.0, 3.0, 18.0, 0.0, 17.0, 0.0, 68.0, 0.0, 0.0, 0.0, 31.0, 40.0, 16.0, 36.0, 0.0, 18.0, 18.0, 78.0, 64.0, 31.0, 47.0, 46.0, 25.0, 0.0, 21.0, 52.0, 73.0, 13.0, 18.0, 10.0, 6.0, 5.0, 19.0, 25.0, 14.0, 4.0, 33.0, 33.0, 31.0, 22.0, 0.0, 31.0, 77.0, 23.0, 79.0, 17.0, 0.0, 0.0, 0.0, 75.0, 0.0, 0.0, 5.0, 46.0, 48.0, 66.0, 82.0, 0.0, 59.0, 82.0, 60.0, 0.0, 29.0, 26.0, 0.0, 35.0, 111.0, 0.0, 84.0, 82.0, 54.0, 39.0, 28.0, 0.0, 19.0, 24.0, 0.0, 39.0, 0.0, 5.0, 38.0, 30.0, 64.0, 22.0, 57.0, 1.0, 64.0, 37.0, 53.0, 0.0, 82.0, 128.0, 37.0, 71.0, 107.0, 16.0, 0.0, 60.0, 55.0, 0.0, 70.0, 47.0, 99.0, 44.0, 5.0, 78.0, 83.0, 0.0, 70.0, 0.0, 0.0, 59.0, 42.0, 0.0, 72.0, 43.0, 89.0, 0.0, 64.0, 57.0, 47.0, 110.0, 44.0, 56.0, 71.0, 115.0, 35.0, 94.0, 0.0, 61.0, 0.0, 70.0, 0.0, 125.0, 110.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.685480529087541, "mean_inference_ms": 1.6482794571094979, "mean_action_processing_ms": 0.2717324174274112, "mean_env_wait_ms": 0.2024952689584406, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004236817359924316, "StateBufferConnector_ms": 0.0034323930740356445, "ViewRequirementAgentConnector_ms": 0.1059105396270752}, "num_episodes": 22, "episode_return_max": 355.00000000000006, "episode_return_min": -168.1, "episode_return_mean": 106.96399999999987, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 640000, "num_agent_steps_trained": 640000, "num_env_steps_sampled": 160000, "num_env_steps_trained": 160000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 76.56852799819717, "num_env_steps_trained_throughput_per_sec": 76.56852799819717, "timesteps_total": 160000, "num_env_steps_sampled_lifetime": 160000, "num_agent_steps_sampled_lifetime": 640000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 640000, "timers": {"training_iteration_time_ms": 52615.067, "restore_workers_time_ms": 0.013, "training_step_time_ms": 52615.029, "sample_time_ms": 1295.53, "learn_time_ms": 51302.787, "learn_throughput": 77.968, "synch_weights_time_ms": 13.552}, "counters": {"num_env_steps_sampled": 160000, "num_env_steps_trained": 160000, "num_agent_steps_sampled": 640000, "num_agent_steps_trained": 640000}, "done": false, "training_iteration": 40, "trial_id": "11e70_00000", "date": "2024-08-12_23-41-35", "timestamp": 1723520495, "time_this_iter_s": 52.31073594093323, "time_total_s": 2075.170140028, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2b96c10>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2075.170140028, "iterations_since_restore": 40, "perf": {"cpu_util_percent": 37.63108108108108, "ram_util_percent": 82.32702702702701}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 6.460059175541792, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.862739525396357, "policy_loss": -0.012947134183788742, "vf_loss": 6.873616665885562, "vf_explained_var": 0.13736886328490322, "kl": 0.01380003797494475, "entropy": 1.2040842572217265, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 76545.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.7562019079135207, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.173964383110167, "policy_loss": -0.009174337483223074, "vf_loss": 6.181640173140027, "vf_explained_var": -0.5120317175905541, "kl": 0.009990350452474477, "entropy": 1.1708014019582638, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 76545.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 164000, "num_env_steps_trained": 164000, "num_agent_steps_sampled": 656000, "num_agent_steps_trained": 656000}, "env_runners": {"episode_reward_max": 320.8000000000002, "episode_reward_min": -378.19999999999993, "episode_reward_mean": 55.596999999999944, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -630.1, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 191.9, "predator_policy": 512.0}, "policy_reward_mean": {"prey_policy": -18.026500000000002, "predator_policy": 45.825}, "custom_metrics": {}, "hist_stats": {"episode_reward": [67.00000000000024, 135.39999999999966, 221.79999999999998, 165.89999999999947, 177.49999999999932, 34.50000000000022, -60.60000000000002, 83.89999999999989, 73.2999999999997, 225.2, 296.8, 233.69999999999985, 121.19999999999996, 211.8999999999993, -48.70000000000085, 45.600000000000165, 143.49999999999926, 132.6999999999998, 58.39999999999999, 15.399999999999926, 90.59999999999974, 320.8000000000002, 86.1, 143.5999999999993, 167.2999999999993, 281.5000000000008, 132.9999999999996, 138.79999999999947, 71.29999999999993, 115.69999999999963, 22.000000000000092, 115.60000000000001, 49.20000000000023, 40.0000000000003, 94.9, 161.3999999999994, 114.49999999999997, -62.5, 104.99999999999991, -118.90000000000002, 8.100000000000025, 148.1999999999992, -16.799999999999883, 121.89999999999996, 15.500000000000021, 156.5, 188.29999999999936, 316.9, 157.60000000000002, 280.4000000000001, -5.80000000000004, 68.3, 148.79999999999998, 73.30000000000013, 99.19999999999999, -39.79999999999986, -119.79999999999993, 22.400000000000013, 91.69999999999999, 65.60000000000028, -20.69999999999999, 113.89999999999961, -38.39999999999982, 113.6, 40.0000000000003, 82.80000000000001, 126.69999999999993, -4.699999999999994, 169.09999999999994, 32.700000000000216, -8.199999999999898, 38.30000000000026, -96.5, -45.699999999999896, 180.79999999999995, 109.99999999999991, -168.1, -117.70000000000002, 18.200000000000173, -116.00000000000003, -93.80000000000014, -378.19999999999993, 40.0000000000003, -252.10000000000002, 40.0000000000003, -97.89999999999993, 61.30000000000018, -40.299999999999876, -130.8, -107.20000000000002, 48.600000000000115, 42.10000000000028, -20.99999999999995, 45.50000000000018, -1.1999999999998403, -56.99999999999984, 7.200000000000001, 152.59999999999928, -186.6, -106.40000000000015], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 46.99999999999997, 88.4, 20.000000000000014, 62.6, 99.19999999999999, 131.89999999999998, 20.000000000000014, 20.000000000000014, 138.5, 20.000000000000014, 9.499999999999964, -630.1, -2.499999999999986, 26.90000000000004, 20.000000000000014, -18.69999999999999, 20.000000000000014, 79.4, 93.79999999999998, 151.7, 124.1, 139.3999999999999, 77.29999999999998, 33.799999999999955, 19.400000000000006, 191.9, 20.000000000000014, -45.09999999999976, -34.59999999999975, 20.000000000000014, -30.40000000000002, 20.000000000000014, 87.5, 76.7, 20.000000000000014, 6.200000000000001, -89.79999999999998, -48.99999999999999, -13.600000000000072, -0.40000000000000346, 20.000000000000014, 121.1, 178.69999999999996, 14.900000000000006, -53.80000000000001, 130.39999999999984, -17.79999999999974, 131.29999999999998, 20.000000000000014, 125.59999999999975, 131.89999999999998, 74.0, 20.000000000000014, 20.000000000000014, 81.80000000000001, 20.000000000000014, -12.699999999999992, 73.70000000000006, 20.000000000000014, -45.099999999999774, -40.9, 107.9, -94.29999999999998, 20.000000000000014, 12.19999999999996, 20.000000000000014, 20.000000000000014, 28.400000000000006, -8.499999999999993, 146.89999999999992, 9.499999999999966, 51.20000000000001, -30.699999999999996, -145.0, -65.5, 32.000000000000014, 14.0, -127.6, -133.3, -40.89999999999979, 20.000000000000014, 102.1999999999999, 20.000000000000014, 20.000000000000014, -182.8, -3.3999999999999932, 41.300000000000004, -95.20000000000002, -25.299999999999997, 77.29999999999998, 12.200000000000003, 27.499999999999993, 141.79999999999998, 137.0, 155.89999999999998, 59.89999999999999, 58.699999999999974, 113.0, 124.39999999999998, 20.000000000000014, -119.8, 20.000000000000014, -30.699999999999996, 46.4, 37.39999999999999, 41.0, -57.70000000000048, 46.099999999999994, -28.900000000000006, 20.000000000000014, -224.8, -97.30000000000001, -200.5, -13.599999999999783, 20.000000000000014, -57.39999999999999, 34.099999999999994, 20.000000000000014, -24.39999999999999, -147.7, -19.00000000000002, 44.90000000000001, 20.000000000000014, 20.000000000000014, -219.4, 17.3, 26.300000000000004, 20.000000000000014, 20.000000000000014, 15.500000000000005, -33.7, 55.99999999999997, -1.2999999999999972, -156.70000000000002, 20.000000000000014, 10.099999999999994, 94.99999999999997, 20.000000000000014, -91.29999999999998, 20.000000000000014, -182.20000000000005, 20.000000000000014, -108.69999999999999, -133.9, -112.60000000000002, -67.00000000000001, -72.70000000000002, 45.500000000000014, 74.30000000000001, 21.800000000000008, 18.199999999999967, -212.2, -190.9, -161.20000000000002, -179.5, 20.000000000000014, -101.80000000000001, -87.4, -172.60000000000002, -320.8, 20.000000000000014, -355.9, -229.30000000000004, 20.000000000000014, 20.000000000000014, -217.9, -269.2, 20.000000000000014, 20.000000000000014, -148.00000000000003, -67.9, 20.000000000000014, 23.299999999999983, 20.000000000000014, -229.3, -137.8, -163.0, -52.599999999999994, -190.60000000000002, 20.000000000000014, -141.4, -149.80000000000004, 17.899999999999988, 20.000000000000014, -301.00000000000006, -59.49999999999999, 20.000000000000014, 20.000000000000014, -128.2, -211.0, 20.000000000000014, 20.000000000000014, -155.8, 101.59999999999997, 20.000000000000014, -160.29999999999998, -259.3, -312.70000000000005, 5.299999999999965], "policy_predator_policy_reward": [0.0, 0.0, 14.0, 13.0, 40.0, 20.0, 14.0, 0.0, 15.0, 4.0, 0.0, 5.0, 512.0, 60.0, 35.0, 2.0, 34.0, 38.0, 33.0, 19.0, 3.0, 18.0, 0.0, 17.0, 0.0, 68.0, 0.0, 0.0, 0.0, 31.0, 40.0, 16.0, 36.0, 0.0, 18.0, 18.0, 78.0, 64.0, 31.0, 47.0, 46.0, 25.0, 0.0, 21.0, 52.0, 73.0, 13.0, 18.0, 10.0, 6.0, 5.0, 19.0, 25.0, 14.0, 4.0, 33.0, 33.0, 31.0, 22.0, 0.0, 31.0, 77.0, 23.0, 79.0, 17.0, 0.0, 0.0, 0.0, 75.0, 0.0, 0.0, 5.0, 46.0, 48.0, 66.0, 82.0, 0.0, 59.0, 82.0, 60.0, 0.0, 29.0, 26.0, 0.0, 35.0, 111.0, 0.0, 84.0, 82.0, 54.0, 39.0, 28.0, 0.0, 19.0, 24.0, 0.0, 39.0, 0.0, 5.0, 38.0, 30.0, 64.0, 22.0, 57.0, 1.0, 64.0, 37.0, 53.0, 0.0, 82.0, 128.0, 37.0, 71.0, 107.0, 16.0, 0.0, 60.0, 55.0, 0.0, 70.0, 47.0, 99.0, 44.0, 5.0, 78.0, 83.0, 0.0, 70.0, 0.0, 0.0, 59.0, 42.0, 0.0, 72.0, 43.0, 89.0, 0.0, 64.0, 57.0, 47.0, 110.0, 44.0, 56.0, 71.0, 115.0, 35.0, 94.0, 0.0, 61.0, 0.0, 70.0, 0.0, 125.0, 110.0, 114.0, 109.0, 100.0, 0.0, 144.0, 0.0, 156.0, 51.0, 186.0, 21.0, 0.0, 0.0, 159.0, 76.0, 0.0, 0.0, 112.0, 6.0, 13.0, 5.0, 106.0, 63.0, 122.0, 48.0, 136.0, 0.0, 92.0, 78.0, 61.0, 113.0, 153.0, 107.0, 0.0, 85.0, 0.0, 107.0, 134.0, 0.0, 47.0, 96.0, 31.0, 0.0, 163.0, 70.0, 136.0, 65.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6856844353536442, "mean_inference_ms": 1.6422898103145764, "mean_action_processing_ms": 0.271095244049914, "mean_env_wait_ms": 0.202015546758647, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004186391830444336, "StateBufferConnector_ms": 0.0034012794494628906, "ViewRequirementAgentConnector_ms": 0.10513007640838623}, "num_episodes": 23, "episode_return_max": 320.8000000000002, "episode_return_min": -378.19999999999993, "episode_return_mean": 55.596999999999944, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 656000, "num_agent_steps_trained": 656000, "num_env_steps_sampled": 164000, "num_env_steps_trained": 164000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 73.61588064139637, "num_env_steps_trained_throughput_per_sec": 73.61588064139637, "timesteps_total": 164000, "num_env_steps_sampled_lifetime": 164000, "num_agent_steps_sampled_lifetime": 656000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 656000, "timers": {"training_iteration_time_ms": 52669.046, "restore_workers_time_ms": 0.013, "training_step_time_ms": 52669.008, "sample_time_ms": 1294.448, "learn_time_ms": 51358.025, "learn_throughput": 77.885, "synch_weights_time_ms": 13.364}, "counters": {"num_env_steps_sampled": 164000, "num_env_steps_trained": 164000, "num_agent_steps_sampled": 656000, "num_agent_steps_trained": 656000}, "done": false, "training_iteration": 41, "trial_id": "11e70_00000", "date": "2024-08-12_23-42-29", "timestamp": 1723520549, "time_this_iter_s": 54.37961721420288, "time_total_s": 2129.5497572422028, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2b02430>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2129.5497572422028, "iterations_since_restore": 41, "perf": {"cpu_util_percent": 44.65194805194805, "ram_util_percent": 82.43766233766232}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 9.378468221583695, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.977188215558491, "policy_loss": -0.009568164218709898, "vf_loss": 5.9849906853267125, "vf_explained_var": 0.19362296865730688, "kl": 0.0117711688100275, "entropy": 1.1796513463454272, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 78435.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.56280682563151, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.429723696986203, "policy_loss": -0.009249987833635518, "vf_loss": 6.437511049502741, "vf_explained_var": -0.46157817216146557, "kl": 0.009750947196749052, "entropy": 1.1589646604956774, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 78435.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 168000, "num_env_steps_trained": 168000, "num_agent_steps_sampled": 672000, "num_agent_steps_trained": 672000}, "env_runners": {"episode_reward_max": 320.8000000000002, "episode_reward_min": -378.19999999999993, "episode_reward_mean": 19.695999999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -356.4999999999999, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 178.69999999999996, "predator_policy": 186.0}, "policy_reward_mean": {"prey_policy": -42.172, "predator_policy": 52.02}, "custom_metrics": {}, "hist_stats": {"episode_reward": [58.39999999999999, 15.399999999999926, 90.59999999999974, 320.8000000000002, 86.1, 143.5999999999993, 167.2999999999993, 281.5000000000008, 132.9999999999996, 138.79999999999947, 71.29999999999993, 115.69999999999963, 22.000000000000092, 115.60000000000001, 49.20000000000023, 40.0000000000003, 94.9, 161.3999999999994, 114.49999999999997, -62.5, 104.99999999999991, -118.90000000000002, 8.100000000000025, 148.1999999999992, -16.799999999999883, 121.89999999999996, 15.500000000000021, 156.5, 188.29999999999936, 316.9, 157.60000000000002, 280.4000000000001, -5.80000000000004, 68.3, 148.79999999999998, 73.30000000000013, 99.19999999999999, -39.79999999999986, -119.79999999999993, 22.400000000000013, 91.69999999999999, 65.60000000000028, -20.69999999999999, 113.89999999999961, -38.39999999999982, 113.6, 40.0000000000003, 82.80000000000001, 126.69999999999993, -4.699999999999994, 169.09999999999994, 32.700000000000216, -8.199999999999898, 38.30000000000026, -96.5, -45.699999999999896, 180.79999999999995, 109.99999999999991, -168.1, -117.70000000000002, 18.200000000000173, -116.00000000000003, -93.80000000000014, -378.19999999999993, 40.0000000000003, -252.10000000000002, 40.0000000000003, -97.89999999999993, 61.30000000000018, -40.299999999999876, -130.8, -107.20000000000002, 48.600000000000115, 42.10000000000028, -20.99999999999995, 45.50000000000018, -1.1999999999998403, -56.99999999999984, 7.200000000000001, 152.59999999999928, -186.6, -106.40000000000015, 3.1000000000000485, -51.79999999999978, -367.29999999999995, 40.0000000000003, -326.5999999999998, -27.999999999999908, -39.50000000000003, 60.5, -88.00000000000006, -203.99999999999997, -87.70000000000002, -100.50000000000045, -27.20000000000003, -86.70000000000002, -19.99999999999987, -71.89999999999996, 26.100000000000016, 40.0000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [6.200000000000001, -89.79999999999998, -48.99999999999999, -13.600000000000072, -0.40000000000000346, 20.000000000000014, 121.1, 178.69999999999996, 14.900000000000006, -53.80000000000001, 130.39999999999984, -17.79999999999974, 131.29999999999998, 20.000000000000014, 125.59999999999975, 131.89999999999998, 74.0, 20.000000000000014, 20.000000000000014, 81.80000000000001, 20.000000000000014, -12.699999999999992, 73.70000000000006, 20.000000000000014, -45.099999999999774, -40.9, 107.9, -94.29999999999998, 20.000000000000014, 12.19999999999996, 20.000000000000014, 20.000000000000014, 28.400000000000006, -8.499999999999993, 146.89999999999992, 9.499999999999966, 51.20000000000001, -30.699999999999996, -145.0, -65.5, 32.000000000000014, 14.0, -127.6, -133.3, -40.89999999999979, 20.000000000000014, 102.1999999999999, 20.000000000000014, 20.000000000000014, -182.8, -3.3999999999999932, 41.300000000000004, -95.20000000000002, -25.299999999999997, 77.29999999999998, 12.200000000000003, 27.499999999999993, 141.79999999999998, 137.0, 155.89999999999998, 59.89999999999999, 58.699999999999974, 113.0, 124.39999999999998, 20.000000000000014, -119.8, 20.000000000000014, -30.699999999999996, 46.4, 37.39999999999999, 41.0, -57.70000000000048, 46.099999999999994, -28.900000000000006, 20.000000000000014, -224.8, -97.30000000000001, -200.5, -13.599999999999783, 20.000000000000014, -57.39999999999999, 34.099999999999994, 20.000000000000014, -24.39999999999999, -147.7, -19.00000000000002, 44.90000000000001, 20.000000000000014, 20.000000000000014, -219.4, 17.3, 26.300000000000004, 20.000000000000014, 20.000000000000014, 15.500000000000005, -33.7, 55.99999999999997, -1.2999999999999972, -156.70000000000002, 20.000000000000014, 10.099999999999994, 94.99999999999997, 20.000000000000014, -91.29999999999998, 20.000000000000014, -182.20000000000005, 20.000000000000014, -108.69999999999999, -133.9, -112.60000000000002, -67.00000000000001, -72.70000000000002, 45.500000000000014, 74.30000000000001, 21.800000000000008, 18.199999999999967, -212.2, -190.9, -161.20000000000002, -179.5, 20.000000000000014, -101.80000000000001, -87.4, -172.60000000000002, -320.8, 20.000000000000014, -355.9, -229.30000000000004, 20.000000000000014, 20.000000000000014, -217.9, -269.2, 20.000000000000014, 20.000000000000014, -148.00000000000003, -67.9, 20.000000000000014, 23.299999999999983, 20.000000000000014, -229.3, -137.8, -163.0, -52.599999999999994, -190.60000000000002, 20.000000000000014, -141.4, -149.80000000000004, 17.899999999999988, 20.000000000000014, -301.00000000000006, -59.49999999999999, 20.000000000000014, 20.000000000000014, -128.2, -211.0, 20.000000000000014, 20.000000000000014, -155.8, 101.59999999999997, 20.000000000000014, -160.29999999999998, -259.3, -312.70000000000005, 5.299999999999965, -115.89999999999999, 20.000000000000014, -281.8, 20.000000000000014, -273.7, -328.59999999999997, 20.000000000000014, 20.000000000000014, -258.3999999999998, -239.2, 20.000000000000014, -175.0, -25.0, -137.5, -72.1, 44.599999999999994, 11.599999999999971, -301.6, -190.60000000000002, -168.39999999999992, -79.6, -135.1, 20.000000000000014, -356.4999999999999, -73.3, -61.900000000000034, 20.000000000000014, -273.70000000000005, -28.300000000000033, -90.70000000000002, 9.5, -225.4, -64.89999999999999, 20.000000000000014, 20.000000000000014, 20.000000000000014], "policy_predator_policy_reward": [78.0, 64.0, 31.0, 47.0, 46.0, 25.0, 0.0, 21.0, 52.0, 73.0, 13.0, 18.0, 10.0, 6.0, 5.0, 19.0, 25.0, 14.0, 4.0, 33.0, 33.0, 31.0, 22.0, 0.0, 31.0, 77.0, 23.0, 79.0, 17.0, 0.0, 0.0, 0.0, 75.0, 0.0, 0.0, 5.0, 46.0, 48.0, 66.0, 82.0, 0.0, 59.0, 82.0, 60.0, 0.0, 29.0, 26.0, 0.0, 35.0, 111.0, 0.0, 84.0, 82.0, 54.0, 39.0, 28.0, 0.0, 19.0, 24.0, 0.0, 39.0, 0.0, 5.0, 38.0, 30.0, 64.0, 22.0, 57.0, 1.0, 64.0, 37.0, 53.0, 0.0, 82.0, 128.0, 37.0, 71.0, 107.0, 16.0, 0.0, 60.0, 55.0, 0.0, 70.0, 47.0, 99.0, 44.0, 5.0, 78.0, 83.0, 0.0, 70.0, 0.0, 0.0, 59.0, 42.0, 0.0, 72.0, 43.0, 89.0, 0.0, 64.0, 57.0, 47.0, 110.0, 44.0, 56.0, 71.0, 115.0, 35.0, 94.0, 0.0, 61.0, 0.0, 70.0, 0.0, 125.0, 110.0, 114.0, 109.0, 100.0, 0.0, 144.0, 0.0, 156.0, 51.0, 186.0, 21.0, 0.0, 0.0, 159.0, 76.0, 0.0, 0.0, 112.0, 6.0, 13.0, 5.0, 106.0, 63.0, 122.0, 48.0, 136.0, 0.0, 92.0, 78.0, 61.0, 113.0, 153.0, 107.0, 0.0, 85.0, 0.0, 107.0, 134.0, 0.0, 47.0, 96.0, 31.0, 0.0, 163.0, 70.0, 136.0, 65.0, 99.0, 0.0, 68.0, 142.0, 179.0, 56.0, 0.0, 0.0, 165.0, 6.0, 118.0, 9.0, 115.0, 8.0, 0.0, 88.0, 74.0, 128.0, 142.0, 13.0, 125.0, 2.0, 159.0, 77.0, 31.0, 77.0, 157.0, 10.0, 99.0, 0.0, 117.0, 27.0, 35.0, 36.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6842966655808854, "mean_inference_ms": 1.638767619751065, "mean_action_processing_ms": 0.27074583417646275, "mean_env_wait_ms": 0.20198929983309152, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004025578498840332, "StateBufferConnector_ms": 0.0033675432205200195, "ViewRequirementAgentConnector_ms": 0.099587082862854}, "num_episodes": 18, "episode_return_max": 320.8000000000002, "episode_return_min": -378.19999999999993, "episode_return_mean": 19.695999999999998, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 672000, "num_agent_steps_trained": 672000, "num_env_steps_sampled": 168000, "num_env_steps_trained": 168000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 72.6457287920579, "num_env_steps_trained_throughput_per_sec": 72.6457287920579, "timesteps_total": 168000, "num_env_steps_sampled_lifetime": 168000, "num_agent_steps_sampled_lifetime": 672000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 672000, "timers": {"training_iteration_time_ms": 52988.005, "restore_workers_time_ms": 0.013, "training_step_time_ms": 52987.962, "sample_time_ms": 1297.026, "learn_time_ms": 51674.43, "learn_throughput": 77.408, "synch_weights_time_ms": 13.383}, "counters": {"num_env_steps_sampled": 168000, "num_env_steps_trained": 168000, "num_agent_steps_sampled": 672000, "num_agent_steps_trained": 672000}, "done": false, "training_iteration": 42, "trial_id": "11e70_00000", "date": "2024-08-12_23-43-24", "timestamp": 1723520604, "time_this_iter_s": 55.112717151641846, "time_total_s": 2184.6624743938446, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2b96f70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2184.6624743938446, "iterations_since_restore": 42, "perf": {"cpu_util_percent": 44.96455696202532, "ram_util_percent": 83.25822784810126}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 9.735271527653648, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.098658259709676, "policy_loss": -0.008610479372785126, "vf_loss": 5.10572733021287, "vf_explained_var": 0.2381180346958221, "kl": 0.010276129991209956, "entropy": 1.2085553477680873, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 80325.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.69691064143307, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.785844864416375, "policy_loss": -0.01201926131274492, "vf_loss": 5.796253587581493, "vf_explained_var": -0.18979853139352545, "kl": 0.010736822818371183, "entropy": 1.0384645779296835, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 80325.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 172000, "num_env_steps_trained": 172000, "num_agent_steps_sampled": 688000, "num_agent_steps_trained": 688000}, "env_runners": {"episode_reward_max": 373.9000000000001, "episode_reward_min": -378.19999999999993, "episode_reward_mean": -12.373999999999993, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -356.4999999999999, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 197.29999999999998, "predator_policy": 186.0}, "policy_reward_mean": {"prey_policy": -67.28200000000001, "predator_policy": 61.095}, "custom_metrics": {}, "hist_stats": {"episode_reward": [114.49999999999997, -62.5, 104.99999999999991, -118.90000000000002, 8.100000000000025, 148.1999999999992, -16.799999999999883, 121.89999999999996, 15.500000000000021, 156.5, 188.29999999999936, 316.9, 157.60000000000002, 280.4000000000001, -5.80000000000004, 68.3, 148.79999999999998, 73.30000000000013, 99.19999999999999, -39.79999999999986, -119.79999999999993, 22.400000000000013, 91.69999999999999, 65.60000000000028, -20.69999999999999, 113.89999999999961, -38.39999999999982, 113.6, 40.0000000000003, 82.80000000000001, 126.69999999999993, -4.699999999999994, 169.09999999999994, 32.700000000000216, -8.199999999999898, 38.30000000000026, -96.5, -45.699999999999896, 180.79999999999995, 109.99999999999991, -168.1, -117.70000000000002, 18.200000000000173, -116.00000000000003, -93.80000000000014, -378.19999999999993, 40.0000000000003, -252.10000000000002, 40.0000000000003, -97.89999999999993, 61.30000000000018, -40.299999999999876, -130.8, -107.20000000000002, 48.600000000000115, 42.10000000000028, -20.99999999999995, 45.50000000000018, -1.1999999999998403, -56.99999999999984, 7.200000000000001, 152.59999999999928, -186.6, -106.40000000000015, 3.1000000000000485, -51.79999999999978, -367.29999999999995, 40.0000000000003, -326.5999999999998, -27.999999999999908, -39.50000000000003, 60.5, -88.00000000000006, -203.99999999999997, -87.70000000000002, -100.50000000000045, -27.20000000000003, -86.70000000000002, -19.99999999999987, -71.89999999999996, 26.100000000000016, 40.0000000000003, 12.800000000000022, 33.400000000000205, -369.5999999999998, 213.69999999999922, -57.99999999999987, -120.90000000000029, -63.99999999999986, -250.10000000000002, -82.8000000000001, -270.1, 71.5000000000002, 373.9000000000001, -112.80000000000041, -141.69999999999996, -18.499999999999964, -100.10000000000039, -258.1, 40.0000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [51.20000000000001, -30.699999999999996, -145.0, -65.5, 32.000000000000014, 14.0, -127.6, -133.3, -40.89999999999979, 20.000000000000014, 102.1999999999999, 20.000000000000014, 20.000000000000014, -182.8, -3.3999999999999932, 41.300000000000004, -95.20000000000002, -25.299999999999997, 77.29999999999998, 12.200000000000003, 27.499999999999993, 141.79999999999998, 137.0, 155.89999999999998, 59.89999999999999, 58.699999999999974, 113.0, 124.39999999999998, 20.000000000000014, -119.8, 20.000000000000014, -30.699999999999996, 46.4, 37.39999999999999, 41.0, -57.70000000000048, 46.099999999999994, -28.900000000000006, 20.000000000000014, -224.8, -97.30000000000001, -200.5, -13.599999999999783, 20.000000000000014, -57.39999999999999, 34.099999999999994, 20.000000000000014, -24.39999999999999, -147.7, -19.00000000000002, 44.90000000000001, 20.000000000000014, 20.000000000000014, -219.4, 17.3, 26.300000000000004, 20.000000000000014, 20.000000000000014, 15.500000000000005, -33.7, 55.99999999999997, -1.2999999999999972, -156.70000000000002, 20.000000000000014, 10.099999999999994, 94.99999999999997, 20.000000000000014, -91.29999999999998, 20.000000000000014, -182.20000000000005, 20.000000000000014, -108.69999999999999, -133.9, -112.60000000000002, -67.00000000000001, -72.70000000000002, 45.500000000000014, 74.30000000000001, 21.800000000000008, 18.199999999999967, -212.2, -190.9, -161.20000000000002, -179.5, 20.000000000000014, -101.80000000000001, -87.4, -172.60000000000002, -320.8, 20.000000000000014, -355.9, -229.30000000000004, 20.000000000000014, 20.000000000000014, -217.9, -269.2, 20.000000000000014, 20.000000000000014, -148.00000000000003, -67.9, 20.000000000000014, 23.299999999999983, 20.000000000000014, -229.3, -137.8, -163.0, -52.599999999999994, -190.60000000000002, 20.000000000000014, -141.4, -149.80000000000004, 17.899999999999988, 20.000000000000014, -301.00000000000006, -59.49999999999999, 20.000000000000014, 20.000000000000014, -128.2, -211.0, 20.000000000000014, 20.000000000000014, -155.8, 101.59999999999997, 20.000000000000014, -160.29999999999998, -259.3, -312.70000000000005, 5.299999999999965, -115.89999999999999, 20.000000000000014, -281.8, 20.000000000000014, -273.7, -328.59999999999997, 20.000000000000014, 20.000000000000014, -258.3999999999998, -239.2, 20.000000000000014, -175.0, -25.0, -137.5, -72.1, 44.599999999999994, 11.599999999999971, -301.6, -190.60000000000002, -168.39999999999992, -79.6, -135.1, 20.000000000000014, -356.4999999999999, -73.3, -61.900000000000034, 20.000000000000014, -273.70000000000005, -28.300000000000033, -90.70000000000002, 9.5, -225.4, -64.89999999999999, 20.000000000000014, 20.000000000000014, 20.000000000000014, 51.499999999999964, -255.70000000000002, 20.000000000000014, 7.399999999999965, -330.4, -302.1999999999999, 193.7, 20.000000000000014, -289.0, 20.000000000000014, 20.000000000000014, -310.9, 20.000000000000014, -217.00000000000003, -276.4, -228.70000000000002, 20.000000000000014, -353.79999999999995, -258.4, -312.7, 20.000000000000014, 51.499999999999964, 197.29999999999998, 176.6, 20.000000000000014, -338.8, -97.0, -234.7, -332.5, 20.000000000000014, -276.1, 20.000000000000014, -176.5, -220.6, 20.000000000000014, 20.000000000000014], "policy_predator_policy_reward": [46.0, 48.0, 66.0, 82.0, 0.0, 59.0, 82.0, 60.0, 0.0, 29.0, 26.0, 0.0, 35.0, 111.0, 0.0, 84.0, 82.0, 54.0, 39.0, 28.0, 0.0, 19.0, 24.0, 0.0, 39.0, 0.0, 5.0, 38.0, 30.0, 64.0, 22.0, 57.0, 1.0, 64.0, 37.0, 53.0, 0.0, 82.0, 128.0, 37.0, 71.0, 107.0, 16.0, 0.0, 60.0, 55.0, 0.0, 70.0, 47.0, 99.0, 44.0, 5.0, 78.0, 83.0, 0.0, 70.0, 0.0, 0.0, 59.0, 42.0, 0.0, 72.0, 43.0, 89.0, 0.0, 64.0, 57.0, 47.0, 110.0, 44.0, 56.0, 71.0, 115.0, 35.0, 94.0, 0.0, 61.0, 0.0, 70.0, 0.0, 125.0, 110.0, 114.0, 109.0, 100.0, 0.0, 144.0, 0.0, 156.0, 51.0, 186.0, 21.0, 0.0, 0.0, 159.0, 76.0, 0.0, 0.0, 112.0, 6.0, 13.0, 5.0, 106.0, 63.0, 122.0, 48.0, 136.0, 0.0, 92.0, 78.0, 61.0, 113.0, 153.0, 107.0, 0.0, 85.0, 0.0, 107.0, 134.0, 0.0, 47.0, 96.0, 31.0, 0.0, 163.0, 70.0, 136.0, 65.0, 99.0, 0.0, 68.0, 142.0, 179.0, 56.0, 0.0, 0.0, 165.0, 6.0, 118.0, 9.0, 115.0, 8.0, 0.0, 88.0, 74.0, 128.0, 142.0, 13.0, 125.0, 2.0, 159.0, 77.0, 31.0, 77.0, 157.0, 10.0, 99.0, 0.0, 117.0, 27.0, 35.0, 36.0, 0.0, 0.0, 85.0, 132.0, 6.0, 0.0, 98.0, 165.0, 0.0, 0.0, 72.0, 139.0, 0.0, 170.0, 133.0, 0.0, 145.0, 110.0, 149.0, 102.0, 162.0, 139.0, 0.0, 0.0, 0.0, 0.0, 27.0, 179.0, 90.0, 100.0, 158.0, 136.0, 0.0, 156.0, 0.0, 139.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6834972416771639, "mean_inference_ms": 1.6348706069993375, "mean_action_processing_ms": 0.2705091769083042, "mean_env_wait_ms": 0.20180983507047542, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003957390785217285, "StateBufferConnector_ms": 0.0033490657806396484, "ViewRequirementAgentConnector_ms": 0.09837353229522705}, "num_episodes": 18, "episode_return_max": 373.9000000000001, "episode_return_min": -378.19999999999993, "episode_return_mean": -12.373999999999993, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 688000, "num_agent_steps_trained": 688000, "num_env_steps_sampled": 172000, "num_env_steps_trained": 172000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 73.9075520100906, "num_env_steps_trained_throughput_per_sec": 73.9075520100906, "timesteps_total": 172000, "num_env_steps_sampled_lifetime": 172000, "num_agent_steps_sampled_lifetime": 688000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 688000, "timers": {"training_iteration_time_ms": 53168.689, "restore_workers_time_ms": 0.013, "training_step_time_ms": 53168.645, "sample_time_ms": 1300.641, "learn_time_ms": 51851.871, "learn_throughput": 77.143, "synch_weights_time_ms": 13.054}, "counters": {"num_env_steps_sampled": 172000, "num_env_steps_trained": 172000, "num_agent_steps_sampled": 688000, "num_agent_steps_trained": 688000}, "done": false, "training_iteration": 43, "trial_id": "11e70_00000", "date": "2024-08-12_23-44-19", "timestamp": 1723520659, "time_this_iter_s": 54.16507911682129, "time_total_s": 2238.827553510666, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3f39790>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2238.827553510666, "iterations_since_restore": 43, "perf": {"cpu_util_percent": 42.65974025974026, "ram_util_percent": 81.80649350649348}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 8.762666103764186, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.539968499683199, "policy_loss": -0.009876198033314375, "vf_loss": 6.548466431148468, "vf_explained_var": 0.23495733924012965, "kl": 0.009188411340953514, "entropy": 1.1917796172162212, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 82215.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.843507262575564, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.1616873168440724, "policy_loss": -0.011403820317524372, "vf_loss": 6.171809498973625, "vf_explained_var": -0.24248961777914138, "kl": 0.008544313620731128, "entropy": 1.0972866067179927, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 82215.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 176000, "num_env_steps_trained": 176000, "num_agent_steps_sampled": 704000, "num_agent_steps_trained": 704000}, "env_runners": {"episode_reward_max": 373.9000000000001, "episode_reward_min": -421.5999999999997, "episode_reward_mean": -42.358999999999966, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -374.79999999999995, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 197.29999999999998, "predator_policy": 192.0}, "policy_reward_mean": {"prey_policy": -87.01449999999998, "predator_policy": 65.835}, "custom_metrics": {}, "hist_stats": {"episode_reward": [99.19999999999999, -39.79999999999986, -119.79999999999993, 22.400000000000013, 91.69999999999999, 65.60000000000028, -20.69999999999999, 113.89999999999961, -38.39999999999982, 113.6, 40.0000000000003, 82.80000000000001, 126.69999999999993, -4.699999999999994, 169.09999999999994, 32.700000000000216, -8.199999999999898, 38.30000000000026, -96.5, -45.699999999999896, 180.79999999999995, 109.99999999999991, -168.1, -117.70000000000002, 18.200000000000173, -116.00000000000003, -93.80000000000014, -378.19999999999993, 40.0000000000003, -252.10000000000002, 40.0000000000003, -97.89999999999993, 61.30000000000018, -40.299999999999876, -130.8, -107.20000000000002, 48.600000000000115, 42.10000000000028, -20.99999999999995, 45.50000000000018, -1.1999999999998403, -56.99999999999984, 7.200000000000001, 152.59999999999928, -186.6, -106.40000000000015, 3.1000000000000485, -51.79999999999978, -367.29999999999995, 40.0000000000003, -326.5999999999998, -27.999999999999908, -39.50000000000003, 60.5, -88.00000000000006, -203.99999999999997, -87.70000000000002, -100.50000000000045, -27.20000000000003, -86.70000000000002, -19.99999999999987, -71.89999999999996, 26.100000000000016, 40.0000000000003, 12.800000000000022, 33.400000000000205, -369.5999999999998, 213.69999999999922, -57.99999999999987, -120.90000000000029, -63.99999999999986, -250.10000000000002, -82.8000000000001, -270.1, 71.5000000000002, 373.9000000000001, -112.80000000000041, -141.69999999999996, -18.499999999999964, -100.10000000000039, -258.1, 40.0000000000003, 40.0000000000003, -297.4000000000001, 29.000000000000014, -25.699999999999992, 40.0000000000003, -328.4999999999999, -113.40000000000023, -358.79999999999995, 14.69999999999993, -421.5999999999997, -7.999999999999913, 40.0000000000003, 363.10000000000014, -22.299999999999834, 36.70000000000025, 108.99999999999926, -231.1000000000001, -164.9000000000006], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [46.099999999999994, -28.900000000000006, 20.000000000000014, -224.8, -97.30000000000001, -200.5, -13.599999999999783, 20.000000000000014, -57.39999999999999, 34.099999999999994, 20.000000000000014, -24.39999999999999, -147.7, -19.00000000000002, 44.90000000000001, 20.000000000000014, 20.000000000000014, -219.4, 17.3, 26.300000000000004, 20.000000000000014, 20.000000000000014, 15.500000000000005, -33.7, 55.99999999999997, -1.2999999999999972, -156.70000000000002, 20.000000000000014, 10.099999999999994, 94.99999999999997, 20.000000000000014, -91.29999999999998, 20.000000000000014, -182.20000000000005, 20.000000000000014, -108.69999999999999, -133.9, -112.60000000000002, -67.00000000000001, -72.70000000000002, 45.500000000000014, 74.30000000000001, 21.800000000000008, 18.199999999999967, -212.2, -190.9, -161.20000000000002, -179.5, 20.000000000000014, -101.80000000000001, -87.4, -172.60000000000002, -320.8, 20.000000000000014, -355.9, -229.30000000000004, 20.000000000000014, 20.000000000000014, -217.9, -269.2, 20.000000000000014, 20.000000000000014, -148.00000000000003, -67.9, 20.000000000000014, 23.299999999999983, 20.000000000000014, -229.3, -137.8, -163.0, -52.599999999999994, -190.60000000000002, 20.000000000000014, -141.4, -149.80000000000004, 17.899999999999988, 20.000000000000014, -301.00000000000006, -59.49999999999999, 20.000000000000014, 20.000000000000014, -128.2, -211.0, 20.000000000000014, 20.000000000000014, -155.8, 101.59999999999997, 20.000000000000014, -160.29999999999998, -259.3, -312.70000000000005, 5.299999999999965, -115.89999999999999, 20.000000000000014, -281.8, 20.000000000000014, -273.7, -328.59999999999997, 20.000000000000014, 20.000000000000014, -258.3999999999998, -239.2, 20.000000000000014, -175.0, -25.0, -137.5, -72.1, 44.599999999999994, 11.599999999999971, -301.6, -190.60000000000002, -168.39999999999992, -79.6, -135.1, 20.000000000000014, -356.4999999999999, -73.3, -61.900000000000034, 20.000000000000014, -273.70000000000005, -28.300000000000033, -90.70000000000002, 9.5, -225.4, -64.89999999999999, 20.000000000000014, 20.000000000000014, 20.000000000000014, 51.499999999999964, -255.70000000000002, 20.000000000000014, 7.399999999999965, -330.4, -302.1999999999999, 193.7, 20.000000000000014, -289.0, 20.000000000000014, 20.000000000000014, -310.9, 20.000000000000014, -217.00000000000003, -276.4, -228.70000000000002, 20.000000000000014, -353.79999999999995, -258.4, -312.7, 20.000000000000014, 51.499999999999964, 197.29999999999998, 176.6, 20.000000000000014, -338.8, -97.0, -234.7, -332.5, 20.000000000000014, -276.1, 20.000000000000014, -176.5, -220.6, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -286.0, -258.4000000000001, -287.8, 105.79999999999998, -201.70000000000005, 20.000000000000014, 20.000000000000014, 20.000000000000014, -310.0, -266.5, -297.40000000000003, 20.000000000000014, -295.0, -356.79999999999995, 20.000000000000014, -28.299999999999777, -319.5999999999998, -292.0, -259.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 181.99999999999994, 181.1, -160.3, 20.000000000000014, 13.699999999999964, 20.000000000000014, 20.0, 20.000000000000014, -269.20000000000005, -148.90000000000006, -374.79999999999995, 17.899999999999988], "policy_predator_policy_reward": [0.0, 82.0, 128.0, 37.0, 71.0, 107.0, 16.0, 0.0, 60.0, 55.0, 0.0, 70.0, 47.0, 99.0, 44.0, 5.0, 78.0, 83.0, 0.0, 70.0, 0.0, 0.0, 59.0, 42.0, 0.0, 72.0, 43.0, 89.0, 0.0, 64.0, 57.0, 47.0, 110.0, 44.0, 56.0, 71.0, 115.0, 35.0, 94.0, 0.0, 61.0, 0.0, 70.0, 0.0, 125.0, 110.0, 114.0, 109.0, 100.0, 0.0, 144.0, 0.0, 156.0, 51.0, 186.0, 21.0, 0.0, 0.0, 159.0, 76.0, 0.0, 0.0, 112.0, 6.0, 13.0, 5.0, 106.0, 63.0, 122.0, 48.0, 136.0, 0.0, 92.0, 78.0, 61.0, 113.0, 153.0, 107.0, 0.0, 85.0, 0.0, 107.0, 134.0, 0.0, 47.0, 96.0, 31.0, 0.0, 163.0, 70.0, 136.0, 65.0, 99.0, 0.0, 68.0, 142.0, 179.0, 56.0, 0.0, 0.0, 165.0, 6.0, 118.0, 9.0, 115.0, 8.0, 0.0, 88.0, 74.0, 128.0, 142.0, 13.0, 125.0, 2.0, 159.0, 77.0, 31.0, 77.0, 157.0, 10.0, 99.0, 0.0, 117.0, 27.0, 35.0, 36.0, 0.0, 0.0, 85.0, 132.0, 6.0, 0.0, 98.0, 165.0, 0.0, 0.0, 72.0, 139.0, 0.0, 170.0, 133.0, 0.0, 145.0, 110.0, 149.0, 102.0, 162.0, 139.0, 0.0, 0.0, 0.0, 0.0, 27.0, 179.0, 90.0, 100.0, 158.0, 136.0, 0.0, 156.0, 0.0, 139.0, 0.0, 0.0, 0.0, 0.0, 132.0, 115.0, 76.0, 135.0, 49.0, 107.0, 0.0, 0.0, 122.0, 126.0, 2.0, 162.0, 126.0, 167.0, 23.0, 0.0, 0.0, 190.0, 126.0, 105.0, 0.0, 0.0, 0.0, 0.0, 118.0, 0.0, 0.0, 3.0, 19.0, 50.0, 62.0, 125.0, 192.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6830145187171308, "mean_inference_ms": 1.632298007551459, "mean_action_processing_ms": 0.2703587069258766, "mean_env_wait_ms": 0.2017553092153696, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0037131309509277344, "StateBufferConnector_ms": 0.003304600715637207, "ViewRequirementAgentConnector_ms": 0.10476052761077881}, "num_episodes": 18, "episode_return_max": 373.9000000000001, "episode_return_min": -421.5999999999997, "episode_return_mean": -42.358999999999966, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 704000, "num_agent_steps_trained": 704000, "num_env_steps_sampled": 176000, "num_env_steps_trained": 176000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 74.59602826904526, "num_env_steps_trained_throughput_per_sec": 74.59602826904526, "timesteps_total": 176000, "num_env_steps_sampled_lifetime": 176000, "num_agent_steps_sampled_lifetime": 704000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 704000, "timers": {"training_iteration_time_ms": 53357.806, "restore_workers_time_ms": 0.013, "training_step_time_ms": 53357.763, "sample_time_ms": 1320.89, "learn_time_ms": 52020.347, "learn_throughput": 76.893, "synch_weights_time_ms": 12.989}, "counters": {"num_env_steps_sampled": 176000, "num_env_steps_trained": 176000, "num_agent_steps_sampled": 704000, "num_agent_steps_trained": 704000}, "done": false, "training_iteration": 44, "trial_id": "11e70_00000", "date": "2024-08-12_23-45-12", "timestamp": 1723520712, "time_this_iter_s": 53.67284297943115, "time_total_s": 2292.500396490097, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2b679d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2292.500396490097, "iterations_since_restore": 44, "perf": {"cpu_util_percent": 40.51578947368421, "ram_util_percent": 80.80657894736842}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 11.303916132576251, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.974137092771985, "policy_loss": -0.007129070200839095, "vf_loss": 5.9801234727183346, "vf_explained_var": 0.23460298108045385, "kl": 0.0076179408079359015, "entropy": 1.1400776231730425, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 84105.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.3520363704237357, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.683982930486164, "policy_loss": -0.013359672771569676, "vf_loss": 5.696045590203906, "vf_explained_var": -0.21038513808023362, "kl": 0.008646738830487105, "entropy": 1.0837614596836151, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 84105.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 180000, "num_env_steps_trained": 180000, "num_agent_steps_sampled": 720000, "num_agent_steps_trained": 720000}, "env_runners": {"episode_reward_max": 373.9000000000001, "episode_reward_min": -421.5999999999997, "episode_reward_mean": -63.104999999999976, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -374.79999999999995, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 197.29999999999998, "predator_policy": 192.0}, "policy_reward_mean": {"prey_policy": -107.5525, "predator_policy": 76.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-168.1, -117.70000000000002, 18.200000000000173, -116.00000000000003, -93.80000000000014, -378.19999999999993, 40.0000000000003, -252.10000000000002, 40.0000000000003, -97.89999999999993, 61.30000000000018, -40.299999999999876, -130.8, -107.20000000000002, 48.600000000000115, 42.10000000000028, -20.99999999999995, 45.50000000000018, -1.1999999999998403, -56.99999999999984, 7.200000000000001, 152.59999999999928, -186.6, -106.40000000000015, 3.1000000000000485, -51.79999999999978, -367.29999999999995, 40.0000000000003, -326.5999999999998, -27.999999999999908, -39.50000000000003, 60.5, -88.00000000000006, -203.99999999999997, -87.70000000000002, -100.50000000000045, -27.20000000000003, -86.70000000000002, -19.99999999999987, -71.89999999999996, 26.100000000000016, 40.0000000000003, 12.800000000000022, 33.400000000000205, -369.5999999999998, 213.69999999999922, -57.99999999999987, -120.90000000000029, -63.99999999999986, -250.10000000000002, -82.8000000000001, -270.1, 71.5000000000002, 373.9000000000001, -112.80000000000041, -141.69999999999996, -18.499999999999964, -100.10000000000039, -258.1, 40.0000000000003, 40.0000000000003, -297.4000000000001, 29.000000000000014, -25.699999999999992, 40.0000000000003, -328.4999999999999, -113.40000000000023, -358.79999999999995, 14.69999999999993, -421.5999999999997, -7.999999999999913, 40.0000000000003, 363.10000000000014, -22.299999999999834, 36.70000000000025, 108.99999999999926, -231.1000000000001, -164.9000000000006, -57.399999999999835, 16.899999999999945, 0.499999999999976, -28.099999999999902, 161.39999999999998, -118.10000000000022, 140.39999999999995, -41.69999999999983, 150.29999999999959, -378.5, 276.0, -306.2, -40.7999999999998, -128.90000000000038, -20.70000000000003, 40.0000000000003, -281.1999999999996, -27.399999999999814, -96.40000000000018, -92.4, 33.400000000000205, -362.7], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-212.2, -190.9, -161.20000000000002, -179.5, 20.000000000000014, -101.80000000000001, -87.4, -172.60000000000002, -320.8, 20.000000000000014, -355.9, -229.30000000000004, 20.000000000000014, 20.000000000000014, -217.9, -269.2, 20.000000000000014, 20.000000000000014, -148.00000000000003, -67.9, 20.000000000000014, 23.299999999999983, 20.000000000000014, -229.3, -137.8, -163.0, -52.599999999999994, -190.60000000000002, 20.000000000000014, -141.4, -149.80000000000004, 17.899999999999988, 20.000000000000014, -301.00000000000006, -59.49999999999999, 20.000000000000014, 20.000000000000014, -128.2, -211.0, 20.000000000000014, 20.000000000000014, -155.8, 101.59999999999997, 20.000000000000014, -160.29999999999998, -259.3, -312.70000000000005, 5.299999999999965, -115.89999999999999, 20.000000000000014, -281.8, 20.000000000000014, -273.7, -328.59999999999997, 20.000000000000014, 20.000000000000014, -258.3999999999998, -239.2, 20.000000000000014, -175.0, -25.0, -137.5, -72.1, 44.599999999999994, 11.599999999999971, -301.6, -190.60000000000002, -168.39999999999992, -79.6, -135.1, 20.000000000000014, -356.4999999999999, -73.3, -61.900000000000034, 20.000000000000014, -273.70000000000005, -28.300000000000033, -90.70000000000002, 9.5, -225.4, -64.89999999999999, 20.000000000000014, 20.000000000000014, 20.000000000000014, 51.499999999999964, -255.70000000000002, 20.000000000000014, 7.399999999999965, -330.4, -302.1999999999999, 193.7, 20.000000000000014, -289.0, 20.000000000000014, 20.000000000000014, -310.9, 20.000000000000014, -217.00000000000003, -276.4, -228.70000000000002, 20.000000000000014, -353.79999999999995, -258.4, -312.7, 20.000000000000014, 51.499999999999964, 197.29999999999998, 176.6, 20.000000000000014, -338.8, -97.0, -234.7, -332.5, 20.000000000000014, -276.1, 20.000000000000014, -176.5, -220.6, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -286.0, -258.4000000000001, -287.8, 105.79999999999998, -201.70000000000005, 20.000000000000014, 20.000000000000014, 20.000000000000014, -310.0, -266.5, -297.40000000000003, 20.000000000000014, -295.0, -356.79999999999995, 20.000000000000014, -28.299999999999777, -319.5999999999998, -292.0, -259.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 181.99999999999994, 181.1, -160.3, 20.000000000000014, 13.699999999999964, 20.000000000000014, 20.0, 20.000000000000014, -269.20000000000005, -148.90000000000006, -374.79999999999995, 17.899999999999988, -213.40000000000003, 20.000000000000014, -1.0000000000000133, -3.099999999999958, -302.5, 20.000000000000014, -243.10000000000002, 20.000000000000014, 186.2, -266.8, 20.000000000000014, -303.1, -255.4, 165.79999999999995, 20.000000000000014, -351.69999999999993, 20.000000000000014, 128.3, -327.69999999999993, -344.8, 152.89999999999998, 97.10000000000005, -340.6, -334.6, -259.9, 1.0999999999999528, 20.000000000000014, -313.9, -369.7, 20.000000000000014, 20.000000000000014, 20.000000000000014, -293.7999999999996, -291.4, 20.000000000000014, -321.3999999999999, 20.000000000000014, -345.4, 20.000000000000014, -270.40000000000003, 20.000000000000014, 7.399999999999965, -323.8, -316.9], "policy_predator_policy_reward": [125.0, 110.0, 114.0, 109.0, 100.0, 0.0, 144.0, 0.0, 156.0, 51.0, 186.0, 21.0, 0.0, 0.0, 159.0, 76.0, 0.0, 0.0, 112.0, 6.0, 13.0, 5.0, 106.0, 63.0, 122.0, 48.0, 136.0, 0.0, 92.0, 78.0, 61.0, 113.0, 153.0, 107.0, 0.0, 85.0, 0.0, 107.0, 134.0, 0.0, 47.0, 96.0, 31.0, 0.0, 163.0, 70.0, 136.0, 65.0, 99.0, 0.0, 68.0, 142.0, 179.0, 56.0, 0.0, 0.0, 165.0, 6.0, 118.0, 9.0, 115.0, 8.0, 0.0, 88.0, 74.0, 128.0, 142.0, 13.0, 125.0, 2.0, 159.0, 77.0, 31.0, 77.0, 157.0, 10.0, 99.0, 0.0, 117.0, 27.0, 35.0, 36.0, 0.0, 0.0, 85.0, 132.0, 6.0, 0.0, 98.0, 165.0, 0.0, 0.0, 72.0, 139.0, 0.0, 170.0, 133.0, 0.0, 145.0, 110.0, 149.0, 102.0, 162.0, 139.0, 0.0, 0.0, 0.0, 0.0, 27.0, 179.0, 90.0, 100.0, 158.0, 136.0, 0.0, 156.0, 0.0, 139.0, 0.0, 0.0, 0.0, 0.0, 132.0, 115.0, 76.0, 135.0, 49.0, 107.0, 0.0, 0.0, 122.0, 126.0, 2.0, 162.0, 126.0, 167.0, 23.0, 0.0, 0.0, 190.0, 126.0, 105.0, 0.0, 0.0, 0.0, 0.0, 118.0, 0.0, 0.0, 3.0, 19.0, 50.0, 62.0, 125.0, 192.0, 0.0, 136.0, 0.0, 0.0, 21.0, 131.0, 152.0, 107.0, 88.0, 90.0, 152.0, 0.0, 165.0, 82.0, 148.0, 136.0, 154.0, 2.0, 0.0, 126.0, 168.0, 0.0, 26.0, 191.0, 178.0, 72.0, 146.0, 31.0, 134.0, 177.0, 152.0, 0.0, 0.0, 141.0, 163.0, 163.0, 111.0, 171.0, 58.0, 155.0, 3.0, 0.0, 6.0, 152.0, 126.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6849065966206852, "mean_inference_ms": 1.6323842218558355, "mean_action_processing_ms": 0.27060663003412083, "mean_env_wait_ms": 0.202047060366397, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003975391387939453, "StateBufferConnector_ms": 0.0032929182052612305, "ViewRequirementAgentConnector_ms": 0.13716983795166016}, "num_episodes": 22, "episode_return_max": 373.9000000000001, "episode_return_min": -421.5999999999997, "episode_return_mean": -63.104999999999976, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 720000, "num_agent_steps_trained": 720000, "num_env_steps_sampled": 180000, "num_env_steps_trained": 180000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 71.98739289009622, "num_env_steps_trained_throughput_per_sec": 71.98739289009622, "timesteps_total": 180000, "num_env_steps_sampled_lifetime": 180000, "num_agent_steps_sampled_lifetime": 720000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 720000, "timers": {"training_iteration_time_ms": 53702.947, "restore_workers_time_ms": 0.013, "training_step_time_ms": 53702.903, "sample_time_ms": 1363.23, "learn_time_ms": 52320.853, "learn_throughput": 76.451, "synch_weights_time_ms": 14.994}, "counters": {"num_env_steps_sampled": 180000, "num_env_steps_trained": 180000, "num_agent_steps_sampled": 720000, "num_agent_steps_trained": 720000}, "done": false, "training_iteration": 45, "trial_id": "11e70_00000", "date": "2024-08-12_23-46-08", "timestamp": 1723520768, "time_this_iter_s": 55.6485698223114, "time_total_s": 2348.1489663124084, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2b931f0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2348.1489663124084, "iterations_since_restore": 45, "perf": {"cpu_util_percent": 46.42658227848101, "ram_util_percent": 82.87088607594937}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 8.22610214179155, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.041091209492356, "policy_loss": -0.010350800015860133, "vf_loss": 6.050101250189322, "vf_explained_var": 0.28913160972494295, "kl": 0.008938381879833398, "entropy": 1.129245100765632, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 85995.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.3661834304925624, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.256693452502054, "policy_loss": -0.012415460193229139, "vf_loss": 6.267157454970022, "vf_explained_var": -0.16994443406503668, "kl": 0.013009684609301391, "entropy": 1.0413025864217647, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 85995.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 184000, "num_env_steps_trained": 184000, "num_agent_steps_sampled": 736000, "num_agent_steps_trained": 736000}, "env_runners": {"episode_reward_max": 373.9000000000001, "episode_reward_min": -421.5999999999997, "episode_reward_mean": -59.73300000000003, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -394.9, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 199.1, "predator_policy": 198.0}, "policy_reward_mean": {"prey_policy": -107.41149999999998, "predator_policy": 77.545}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-106.40000000000015, 3.1000000000000485, -51.79999999999978, -367.29999999999995, 40.0000000000003, -326.5999999999998, -27.999999999999908, -39.50000000000003, 60.5, -88.00000000000006, -203.99999999999997, -87.70000000000002, -100.50000000000045, -27.20000000000003, -86.70000000000002, -19.99999999999987, -71.89999999999996, 26.100000000000016, 40.0000000000003, 12.800000000000022, 33.400000000000205, -369.5999999999998, 213.69999999999922, -57.99999999999987, -120.90000000000029, -63.99999999999986, -250.10000000000002, -82.8000000000001, -270.1, 71.5000000000002, 373.9000000000001, -112.80000000000041, -141.69999999999996, -18.499999999999964, -100.10000000000039, -258.1, 40.0000000000003, 40.0000000000003, -297.4000000000001, 29.000000000000014, -25.699999999999992, 40.0000000000003, -328.4999999999999, -113.40000000000023, -358.79999999999995, 14.69999999999993, -421.5999999999997, -7.999999999999913, 40.0000000000003, 363.10000000000014, -22.299999999999834, 36.70000000000025, 108.99999999999926, -231.1000000000001, -164.9000000000006, -57.399999999999835, 16.899999999999945, 0.499999999999976, -28.099999999999902, 161.39999999999998, -118.10000000000022, 140.39999999999995, -41.69999999999983, 150.29999999999959, -378.5, 276.0, -306.2, -40.7999999999998, -128.90000000000038, -20.70000000000003, 40.0000000000003, -281.1999999999996, -27.399999999999814, -96.40000000000018, -92.4, 33.400000000000205, -362.7, 40.70000000000009, 163.29999999999953, 40.0000000000003, -224.20000000000078, -51.8999999999998, -270.6, -42.799999999999805, -335.6, 144.9999999999995, 40.0000000000003, 110.6, -5.799999999999976, 40.0000000000003, -307.70000000000016, 121.49999999999932, 160.99999999999937, -283.4000000000001, -286.2, 219.09999999999926, -38.599999999999966, 176.69999999999948, -47.799999999999926, -338.49999999999983], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-312.70000000000005, 5.299999999999965, -115.89999999999999, 20.000000000000014, -281.8, 20.000000000000014, -273.7, -328.59999999999997, 20.000000000000014, 20.000000000000014, -258.3999999999998, -239.2, 20.000000000000014, -175.0, -25.0, -137.5, -72.1, 44.599999999999994, 11.599999999999971, -301.6, -190.60000000000002, -168.39999999999992, -79.6, -135.1, 20.000000000000014, -356.4999999999999, -73.3, -61.900000000000034, 20.000000000000014, -273.70000000000005, -28.300000000000033, -90.70000000000002, 9.5, -225.4, -64.89999999999999, 20.000000000000014, 20.000000000000014, 20.000000000000014, 51.499999999999964, -255.70000000000002, 20.000000000000014, 7.399999999999965, -330.4, -302.1999999999999, 193.7, 20.000000000000014, -289.0, 20.000000000000014, 20.000000000000014, -310.9, 20.000000000000014, -217.00000000000003, -276.4, -228.70000000000002, 20.000000000000014, -353.79999999999995, -258.4, -312.7, 20.000000000000014, 51.499999999999964, 197.29999999999998, 176.6, 20.000000000000014, -338.8, -97.0, -234.7, -332.5, 20.000000000000014, -276.1, 20.000000000000014, -176.5, -220.6, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -286.0, -258.4000000000001, -287.8, 105.79999999999998, -201.70000000000005, 20.000000000000014, 20.000000000000014, 20.000000000000014, -310.0, -266.5, -297.40000000000003, 20.000000000000014, -295.0, -356.79999999999995, 20.000000000000014, -28.299999999999777, -319.5999999999998, -292.0, -259.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 181.99999999999994, 181.1, -160.3, 20.000000000000014, 13.699999999999964, 20.000000000000014, 20.0, 20.000000000000014, -269.20000000000005, -148.90000000000006, -374.79999999999995, 17.899999999999988, -213.40000000000003, 20.000000000000014, -1.0000000000000133, -3.099999999999958, -302.5, 20.000000000000014, -243.10000000000002, 20.000000000000014, 186.2, -266.8, 20.000000000000014, -303.1, -255.4, 165.79999999999995, 20.000000000000014, -351.69999999999993, 20.000000000000014, 128.3, -327.69999999999993, -344.8, 152.89999999999998, 97.10000000000005, -340.6, -334.6, -259.9, 1.0999999999999528, 20.000000000000014, -313.9, -369.7, 20.000000000000014, 20.000000000000014, 20.000000000000014, -293.7999999999996, -291.4, 20.000000000000014, -321.3999999999999, 20.000000000000014, -345.4, 20.000000000000014, -270.40000000000003, 20.000000000000014, 7.399999999999965, -323.8, -316.9, -326.8, 87.49999999999997, 20.000000000000014, 143.3, 20.000000000000014, 20.000000000000014, -394.9, -70.30000000000078, -90.70000000000002, -47.199999999999875, -256.90000000000003, -273.70000000000005, -314.8, 20.000000000000014, -293.8, -218.8, 106.69999999999999, 5.299999999999967, 20.000000000000014, 20.000000000000014, -269.79999999999995, 136.4, -299.5000000000001, 13.699999999999964, 20.000000000000014, 20.000000000000014, -233.80000000000013, -319.90000000000003, 11.599999999999964, 62.900000000000006, 11.599999999999964, 106.4, -301.0, -276.4000000000001, -300.70000000000005, -293.5, 199.1, 20.000000000000014, -115.60000000000001, -130.00000000000003, 142.7, 20.000000000000014, 20.000000000000014, -320.8, -333.6999999999998, -347.8], "policy_predator_policy_reward": [136.0, 65.0, 99.0, 0.0, 68.0, 142.0, 179.0, 56.0, 0.0, 0.0, 165.0, 6.0, 118.0, 9.0, 115.0, 8.0, 0.0, 88.0, 74.0, 128.0, 142.0, 13.0, 125.0, 2.0, 159.0, 77.0, 31.0, 77.0, 157.0, 10.0, 99.0, 0.0, 117.0, 27.0, 35.0, 36.0, 0.0, 0.0, 85.0, 132.0, 6.0, 0.0, 98.0, 165.0, 0.0, 0.0, 72.0, 139.0, 0.0, 170.0, 133.0, 0.0, 145.0, 110.0, 149.0, 102.0, 162.0, 139.0, 0.0, 0.0, 0.0, 0.0, 27.0, 179.0, 90.0, 100.0, 158.0, 136.0, 0.0, 156.0, 0.0, 139.0, 0.0, 0.0, 0.0, 0.0, 132.0, 115.0, 76.0, 135.0, 49.0, 107.0, 0.0, 0.0, 122.0, 126.0, 2.0, 162.0, 126.0, 167.0, 23.0, 0.0, 0.0, 190.0, 126.0, 105.0, 0.0, 0.0, 0.0, 0.0, 118.0, 0.0, 0.0, 3.0, 19.0, 50.0, 62.0, 125.0, 192.0, 0.0, 136.0, 0.0, 0.0, 21.0, 131.0, 152.0, 107.0, 88.0, 90.0, 152.0, 0.0, 165.0, 82.0, 148.0, 136.0, 154.0, 2.0, 0.0, 126.0, 168.0, 0.0, 26.0, 191.0, 178.0, 72.0, 146.0, 31.0, 134.0, 177.0, 152.0, 0.0, 0.0, 141.0, 163.0, 163.0, 111.0, 171.0, 58.0, 155.0, 3.0, 0.0, 6.0, 152.0, 126.0, 128.0, 152.0, 0.0, 0.0, 0.0, 0.0, 198.0, 43.0, 45.0, 41.0, 110.0, 150.0, 93.0, 159.0, 177.0, 0.0, 7.0, 26.0, 0.0, 0.0, 149.0, 95.0, 120.0, 160.0, 0.0, 0.0, 177.0, 69.0, 4.0, 43.0, 34.0, 9.0, 112.0, 182.0, 140.0, 168.0, 0.0, 0.0, 131.0, 76.0, 0.0, 14.0, 146.0, 107.0, 181.0, 162.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.688112939474612, "mean_inference_ms": 1.6365280878984436, "mean_action_processing_ms": 0.27168945529462724, "mean_env_wait_ms": 0.20303409420725074, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00518953800201416, "StateBufferConnector_ms": 0.003452301025390625, "ViewRequirementAgentConnector_ms": 0.15518271923065186}, "num_episodes": 23, "episode_return_max": 373.9000000000001, "episode_return_min": -421.5999999999997, "episode_return_mean": -59.73300000000003, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 736000, "num_agent_steps_trained": 736000, "num_env_steps_sampled": 184000, "num_env_steps_trained": 184000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 72.73950072998701, "num_env_steps_trained_throughput_per_sec": 72.73950072998701, "timesteps_total": 184000, "num_env_steps_sampled_lifetime": 184000, "num_agent_steps_sampled_lifetime": 736000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 736000, "timers": {"training_iteration_time_ms": 53874.637, "restore_workers_time_ms": 0.013, "training_step_time_ms": 53874.592, "sample_time_ms": 1360.3, "learn_time_ms": 52496.048, "learn_throughput": 76.196, "synch_weights_time_ms": 14.658}, "counters": {"num_env_steps_sampled": 184000, "num_env_steps_trained": 184000, "num_agent_steps_sampled": 736000, "num_agent_steps_trained": 736000}, "done": false, "training_iteration": 46, "trial_id": "11e70_00000", "date": "2024-08-12_23-47-03", "timestamp": 1723520823, "time_this_iter_s": 55.050110816955566, "time_total_s": 2403.199077129364, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2b619d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2403.199077129364, "iterations_since_restore": 46, "perf": {"cpu_util_percent": 47.6474358974359, "ram_util_percent": 83.2474358974359}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 8.55368710125565, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.34280758812314, "policy_loss": -0.009671765297932166, "vf_loss": 5.351154551808796, "vf_explained_var": 0.28776015062180776, "kl": 0.008832040579536096, "entropy": 1.138418026260598, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 87885.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.204576378083103, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.960314854616842, "policy_loss": -0.011984840633283571, "vf_loss": 4.970933370993881, "vf_explained_var": -0.16531515966647517, "kl": 0.009108737480950905, "entropy": 0.9945219085330055, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 87885.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 188000, "num_env_steps_trained": 188000, "num_agent_steps_sampled": 752000, "num_agent_steps_trained": 752000}, "env_runners": {"episode_reward_max": 373.9000000000001, "episode_reward_min": -421.5999999999997, "episode_reward_mean": -43.512000000000036, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -394.9, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 198.0}, "policy_reward_mean": {"prey_policy": -99.21100000000003, "predator_policy": 77.455}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.0000000000003, 12.800000000000022, 33.400000000000205, -369.5999999999998, 213.69999999999922, -57.99999999999987, -120.90000000000029, -63.99999999999986, -250.10000000000002, -82.8000000000001, -270.1, 71.5000000000002, 373.9000000000001, -112.80000000000041, -141.69999999999996, -18.499999999999964, -100.10000000000039, -258.1, 40.0000000000003, 40.0000000000003, -297.4000000000001, 29.000000000000014, -25.699999999999992, 40.0000000000003, -328.4999999999999, -113.40000000000023, -358.79999999999995, 14.69999999999993, -421.5999999999997, -7.999999999999913, 40.0000000000003, 363.10000000000014, -22.299999999999834, 36.70000000000025, 108.99999999999926, -231.1000000000001, -164.9000000000006, -57.399999999999835, 16.899999999999945, 0.499999999999976, -28.099999999999902, 161.39999999999998, -118.10000000000022, 140.39999999999995, -41.69999999999983, 150.29999999999959, -378.5, 276.0, -306.2, -40.7999999999998, -128.90000000000038, -20.70000000000003, 40.0000000000003, -281.1999999999996, -27.399999999999814, -96.40000000000018, -92.4, 33.400000000000205, -362.7, 40.70000000000009, 163.29999999999953, 40.0000000000003, -224.20000000000078, -51.8999999999998, -270.6, -42.799999999999805, -335.6, 144.9999999999995, 40.0000000000003, 110.6, -5.799999999999976, 40.0000000000003, -307.70000000000016, 121.49999999999932, 160.99999999999937, -283.4000000000001, -286.2, 219.09999999999926, -38.599999999999966, 176.69999999999948, -47.799999999999926, -338.49999999999983, 1.9999999999999374, 98.29999999999987, -219.90000000000015, 137.09999999999926, 40.0000000000003, -38.09999999999973, 40.0000000000003, 34.50000000000022, -78.80000000000018, -118.40000000000055, -33.89999999999983, -2.7000000000000473, 37.80000000000027, 325.1, 51.40000000000002, -28.3999999999999, -110.50000000000023, 10.700000000000182], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 20.000000000000014, 51.499999999999964, -255.70000000000002, 20.000000000000014, 7.399999999999965, -330.4, -302.1999999999999, 193.7, 20.000000000000014, -289.0, 20.000000000000014, 20.000000000000014, -310.9, 20.000000000000014, -217.00000000000003, -276.4, -228.70000000000002, 20.000000000000014, -353.79999999999995, -258.4, -312.7, 20.000000000000014, 51.499999999999964, 197.29999999999998, 176.6, 20.000000000000014, -338.8, -97.0, -234.7, -332.5, 20.000000000000014, -276.1, 20.000000000000014, -176.5, -220.6, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -286.0, -258.4000000000001, -287.8, 105.79999999999998, -201.70000000000005, 20.000000000000014, 20.000000000000014, 20.000000000000014, -310.0, -266.5, -297.40000000000003, 20.000000000000014, -295.0, -356.79999999999995, 20.000000000000014, -28.299999999999777, -319.5999999999998, -292.0, -259.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 181.99999999999994, 181.1, -160.3, 20.000000000000014, 13.699999999999964, 20.000000000000014, 20.0, 20.000000000000014, -269.20000000000005, -148.90000000000006, -374.79999999999995, 17.899999999999988, -213.40000000000003, 20.000000000000014, -1.0000000000000133, -3.099999999999958, -302.5, 20.000000000000014, -243.10000000000002, 20.000000000000014, 186.2, -266.8, 20.000000000000014, -303.1, -255.4, 165.79999999999995, 20.000000000000014, -351.69999999999993, 20.000000000000014, 128.3, -327.69999999999993, -344.8, 152.89999999999998, 97.10000000000005, -340.6, -334.6, -259.9, 1.0999999999999528, 20.000000000000014, -313.9, -369.7, 20.000000000000014, 20.000000000000014, 20.000000000000014, -293.7999999999996, -291.4, 20.000000000000014, -321.3999999999999, 20.000000000000014, -345.4, 20.000000000000014, -270.40000000000003, 20.000000000000014, 7.399999999999965, -323.8, -316.9, -326.8, 87.49999999999997, 20.000000000000014, 143.3, 20.000000000000014, 20.000000000000014, -394.9, -70.30000000000078, -90.70000000000002, -47.199999999999875, -256.90000000000003, -273.70000000000005, -314.8, 20.000000000000014, -293.8, -218.8, 106.69999999999999, 5.299999999999967, 20.000000000000014, 20.000000000000014, -269.79999999999995, 136.4, -299.5000000000001, 13.699999999999964, 20.000000000000014, 20.000000000000014, -233.80000000000013, -319.90000000000003, 11.599999999999964, 62.900000000000006, 11.599999999999964, 106.4, -301.0, -276.4000000000001, -300.70000000000005, -293.5, 199.1, 20.000000000000014, -115.60000000000001, -130.00000000000003, 142.7, 20.000000000000014, 20.000000000000014, -320.8, -333.6999999999998, -347.8, -274.0, 20.000000000000014, -97.60000000000079, 131.90000000000003, -96.39999999999998, -284.5, 64.1, 20.000000000000014, 20.000000000000014, 20.000000000000014, -383.49999999999994, 7.399999999999968, 20.000000000000014, 20.000000000000014, 9.499999999999966, 20.000000000000014, 20.000000000000014, -272.80000000000007, -300.4000000000001, 20.000000000000014, 1.09999999999996, -199.00000000000009, 20.000000000000014, -309.70000000000005, 20.000000000000014, 15.799999999999963, 155.6, 159.5, -307.6, 200.0, -312.4000000000001, 20.000000000000014, 9.499999999999964, -336.99999999999994, -185.8, -32.49999999999976], "policy_predator_policy_reward": [0.0, 0.0, 85.0, 132.0, 6.0, 0.0, 98.0, 165.0, 0.0, 0.0, 72.0, 139.0, 0.0, 170.0, 133.0, 0.0, 145.0, 110.0, 149.0, 102.0, 162.0, 139.0, 0.0, 0.0, 0.0, 0.0, 27.0, 179.0, 90.0, 100.0, 158.0, 136.0, 0.0, 156.0, 0.0, 139.0, 0.0, 0.0, 0.0, 0.0, 132.0, 115.0, 76.0, 135.0, 49.0, 107.0, 0.0, 0.0, 122.0, 126.0, 2.0, 162.0, 126.0, 167.0, 23.0, 0.0, 0.0, 190.0, 126.0, 105.0, 0.0, 0.0, 0.0, 0.0, 118.0, 0.0, 0.0, 3.0, 19.0, 50.0, 62.0, 125.0, 192.0, 0.0, 136.0, 0.0, 0.0, 21.0, 131.0, 152.0, 107.0, 88.0, 90.0, 152.0, 0.0, 165.0, 82.0, 148.0, 136.0, 154.0, 2.0, 0.0, 126.0, 168.0, 0.0, 26.0, 191.0, 178.0, 72.0, 146.0, 31.0, 134.0, 177.0, 152.0, 0.0, 0.0, 141.0, 163.0, 163.0, 111.0, 171.0, 58.0, 155.0, 3.0, 0.0, 6.0, 152.0, 126.0, 128.0, 152.0, 0.0, 0.0, 0.0, 0.0, 198.0, 43.0, 45.0, 41.0, 110.0, 150.0, 93.0, 159.0, 177.0, 0.0, 7.0, 26.0, 0.0, 0.0, 149.0, 95.0, 120.0, 160.0, 0.0, 0.0, 177.0, 69.0, 4.0, 43.0, 34.0, 9.0, 112.0, 182.0, 140.0, 168.0, 0.0, 0.0, 131.0, 76.0, 0.0, 14.0, 146.0, 107.0, 181.0, 162.0, 123.0, 133.0, 0.0, 64.0, 161.0, 0.0, 21.0, 32.0, 0.0, 0.0, 182.0, 156.0, 0.0, 0.0, 0.0, 5.0, 20.0, 154.0, 0.0, 162.0, 55.0, 109.0, 144.0, 143.0, 2.0, 0.0, 0.0, 10.0, 0.0, 159.0, 141.0, 123.0, 47.0, 170.0, 105.0, 124.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6908522130110897, "mean_inference_ms": 1.6404037709089048, "mean_action_processing_ms": 0.2726241067790562, "mean_env_wait_ms": 0.20386755420591599, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006202220916748047, "StateBufferConnector_ms": 0.003695368766784668, "ViewRequirementAgentConnector_ms": 0.15975475311279297}, "num_episodes": 18, "episode_return_max": 373.9000000000001, "episode_return_min": -421.5999999999997, "episode_return_mean": -43.512000000000036, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 752000, "num_agent_steps_trained": 752000, "num_env_steps_sampled": 188000, "num_env_steps_trained": 188000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 60.29927701784986, "num_env_steps_trained_throughput_per_sec": 60.29927701784986, "timesteps_total": 188000, "num_env_steps_sampled_lifetime": 188000, "num_agent_steps_sampled_lifetime": 752000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 752000, "timers": {"training_iteration_time_ms": 55263.973, "restore_workers_time_ms": 0.014, "training_step_time_ms": 55263.92, "sample_time_ms": 1371.06, "learn_time_ms": 53873.632, "learn_throughput": 74.248, "synch_weights_time_ms": 15.105}, "counters": {"num_env_steps_sampled": 188000, "num_env_steps_trained": 188000, "num_agent_steps_sampled": 752000, "num_agent_steps_trained": 752000}, "done": false, "training_iteration": 47, "trial_id": "11e70_00000", "date": "2024-08-12_23-48-10", "timestamp": 1723520890, "time_this_iter_s": 66.3908429145813, "time_total_s": 2469.5899200439453, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3f8ac10>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2469.5899200439453, "iterations_since_restore": 47, "perf": {"cpu_util_percent": 68.81595744680853, "ram_util_percent": 83.47872340425533}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 9.930765189632536, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.082512713487817, "policy_loss": -0.013612665876588494, "vf_loss": 4.094207447294205, "vf_explained_var": 0.336804836168491, "kl": 0.01278620048086701, "entropy": 1.140040662427428, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 89775.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.51853574624768, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.328330041870238, "policy_loss": -0.013734932327224189, "vf_loss": 5.340348334539504, "vf_explained_var": -0.07300562536905682, "kl": 0.011444170609833113, "entropy": 0.958485636036232, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 89775.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 192000, "num_env_steps_trained": 192000, "num_agent_steps_sampled": 768000, "num_agent_steps_trained": 768000}, "env_runners": {"episode_reward_max": 371.29999999999995, "episode_reward_min": -421.5999999999997, "episode_reward_mean": -25.018000000000058, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -394.9, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 198.0}, "policy_reward_mean": {"prey_policy": -88.15900000000002, "predator_policy": 75.65}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.0000000000003, 40.0000000000003, -297.4000000000001, 29.000000000000014, -25.699999999999992, 40.0000000000003, -328.4999999999999, -113.40000000000023, -358.79999999999995, 14.69999999999993, -421.5999999999997, -7.999999999999913, 40.0000000000003, 363.10000000000014, -22.299999999999834, 36.70000000000025, 108.99999999999926, -231.1000000000001, -164.9000000000006, -57.399999999999835, 16.899999999999945, 0.499999999999976, -28.099999999999902, 161.39999999999998, -118.10000000000022, 140.39999999999995, -41.69999999999983, 150.29999999999959, -378.5, 276.0, -306.2, -40.7999999999998, -128.90000000000038, -20.70000000000003, 40.0000000000003, -281.1999999999996, -27.399999999999814, -96.40000000000018, -92.4, 33.400000000000205, -362.7, 40.70000000000009, 163.29999999999953, 40.0000000000003, -224.20000000000078, -51.8999999999998, -270.6, -42.799999999999805, -335.6, 144.9999999999995, 40.0000000000003, 110.6, -5.799999999999976, 40.0000000000003, -307.70000000000016, 121.49999999999932, 160.99999999999937, -283.4000000000001, -286.2, 219.09999999999926, -38.599999999999966, 176.69999999999948, -47.799999999999926, -338.49999999999983, 1.9999999999999374, 98.29999999999987, -219.90000000000015, 137.09999999999926, 40.0000000000003, -38.09999999999973, 40.0000000000003, 34.50000000000022, -78.80000000000018, -118.40000000000055, -33.89999999999983, -2.7000000000000473, 37.80000000000027, 325.1, 51.40000000000002, -28.3999999999999, -110.50000000000023, 10.700000000000182, -93.10000000000035, 46.60000000000005, 371.29999999999995, -147.5000000000006, 269.49999999999955, 212.79999999999922, -12.29999999999994, -24.899999999999743, 40.0000000000003, -260.2000000000004, -48.59999999999978, 197.99999999999937, 40.0000000000003, -92.30000000000024, 94.89999999999934, 131.39999999999992, 143.1, -120.70000000000056], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -286.0, -258.4000000000001, -287.8, 105.79999999999998, -201.70000000000005, 20.000000000000014, 20.000000000000014, 20.000000000000014, -310.0, -266.5, -297.40000000000003, 20.000000000000014, -295.0, -356.79999999999995, 20.000000000000014, -28.299999999999777, -319.5999999999998, -292.0, -259.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 181.99999999999994, 181.1, -160.3, 20.000000000000014, 13.699999999999964, 20.000000000000014, 20.0, 20.000000000000014, -269.20000000000005, -148.90000000000006, -374.79999999999995, 17.899999999999988, -213.40000000000003, 20.000000000000014, -1.0000000000000133, -3.099999999999958, -302.5, 20.000000000000014, -243.10000000000002, 20.000000000000014, 186.2, -266.8, 20.000000000000014, -303.1, -255.4, 165.79999999999995, 20.000000000000014, -351.69999999999993, 20.000000000000014, 128.3, -327.69999999999993, -344.8, 152.89999999999998, 97.10000000000005, -340.6, -334.6, -259.9, 1.0999999999999528, 20.000000000000014, -313.9, -369.7, 20.000000000000014, 20.000000000000014, 20.000000000000014, -293.7999999999996, -291.4, 20.000000000000014, -321.3999999999999, 20.000000000000014, -345.4, 20.000000000000014, -270.40000000000003, 20.000000000000014, 7.399999999999965, -323.8, -316.9, -326.8, 87.49999999999997, 20.000000000000014, 143.3, 20.000000000000014, 20.000000000000014, -394.9, -70.30000000000078, -90.70000000000002, -47.199999999999875, -256.90000000000003, -273.70000000000005, -314.8, 20.000000000000014, -293.8, -218.8, 106.69999999999999, 5.299999999999967, 20.000000000000014, 20.000000000000014, -269.79999999999995, 136.4, -299.5000000000001, 13.699999999999964, 20.000000000000014, 20.000000000000014, -233.80000000000013, -319.90000000000003, 11.599999999999964, 62.900000000000006, 11.599999999999964, 106.4, -301.0, -276.4000000000001, -300.70000000000005, -293.5, 199.1, 20.000000000000014, -115.60000000000001, -130.00000000000003, 142.7, 20.000000000000014, 20.000000000000014, -320.8, -333.6999999999998, -347.8, -274.0, 20.000000000000014, -97.60000000000079, 131.90000000000003, -96.39999999999998, -284.5, 64.1, 20.000000000000014, 20.000000000000014, 20.000000000000014, -383.49999999999994, 7.399999999999968, 20.000000000000014, 20.000000000000014, 9.499999999999966, 20.000000000000014, 20.000000000000014, -272.80000000000007, -300.4000000000001, 20.000000000000014, 1.09999999999996, -199.00000000000009, 20.000000000000014, -309.70000000000005, 20.000000000000014, 15.799999999999963, 155.6, 159.5, -307.6, 200.0, -312.4000000000001, 20.000000000000014, 9.499999999999964, -336.99999999999994, -185.8, -32.49999999999976, -245.80000000000018, 13.699999999999969, 163.4, -242.8000000000004, 170.0, 191.29999999999998, -315.39999999999986, -3.0999999999999828, 199.1, 70.39999999999996, 20.000000000000014, 192.79999999999995, 15.799999999999962, -198.10000000000005, -394.9, 20.000000000000014, 20.000000000000014, 20.000000000000014, -249.40000000000038, -347.8, -361.6, 20.000000000000014, 20.000000000000014, 167.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, -343.29999999999995, 74.8999999999997, 20.000000000000014, 200.0, -196.60000000000008, -358.29999999999995, 196.39999999999998, 20.000000000000014, -300.69999999999953], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 0.0, 132.0, 115.0, 76.0, 135.0, 49.0, 107.0, 0.0, 0.0, 122.0, 126.0, 2.0, 162.0, 126.0, 167.0, 23.0, 0.0, 0.0, 190.0, 126.0, 105.0, 0.0, 0.0, 0.0, 0.0, 118.0, 0.0, 0.0, 3.0, 19.0, 50.0, 62.0, 125.0, 192.0, 0.0, 136.0, 0.0, 0.0, 21.0, 131.0, 152.0, 107.0, 88.0, 90.0, 152.0, 0.0, 165.0, 82.0, 148.0, 136.0, 154.0, 2.0, 0.0, 126.0, 168.0, 0.0, 26.0, 191.0, 178.0, 72.0, 146.0, 31.0, 134.0, 177.0, 152.0, 0.0, 0.0, 141.0, 163.0, 163.0, 111.0, 171.0, 58.0, 155.0, 3.0, 0.0, 6.0, 152.0, 126.0, 128.0, 152.0, 0.0, 0.0, 0.0, 0.0, 198.0, 43.0, 45.0, 41.0, 110.0, 150.0, 93.0, 159.0, 177.0, 0.0, 7.0, 26.0, 0.0, 0.0, 149.0, 95.0, 120.0, 160.0, 0.0, 0.0, 177.0, 69.0, 4.0, 43.0, 34.0, 9.0, 112.0, 182.0, 140.0, 168.0, 0.0, 0.0, 131.0, 76.0, 0.0, 14.0, 146.0, 107.0, 181.0, 162.0, 123.0, 133.0, 0.0, 64.0, 161.0, 0.0, 21.0, 32.0, 0.0, 0.0, 182.0, 156.0, 0.0, 0.0, 0.0, 5.0, 20.0, 154.0, 0.0, 162.0, 55.0, 109.0, 144.0, 143.0, 2.0, 0.0, 0.0, 10.0, 0.0, 159.0, 141.0, 123.0, 47.0, 170.0, 105.0, 124.0, 3.0, 136.0, 126.0, 0.0, 10.0, 0.0, 0.0, 171.0, 0.0, 0.0, 0.0, 0.0, 64.0, 106.0, 157.0, 193.0, 0.0, 0.0, 173.0, 164.0, 107.0, 186.0, 11.0, 0.0, 0.0, 0.0, 172.0, 59.0, 0.0, 0.0, 128.0, 0.0, 148.0, 157.0, 0.0, 160.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6953476501608992, "mean_inference_ms": 1.6487391146589723, "mean_action_processing_ms": 0.2740428455780963, "mean_env_wait_ms": 0.20523198055819464, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.009795308113098145, "StateBufferConnector_ms": 0.0037668943405151367, "ViewRequirementAgentConnector_ms": 0.16873407363891602}, "num_episodes": 18, "episode_return_max": 371.29999999999995, "episode_return_min": -421.5999999999997, "episode_return_mean": -25.018000000000058, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 768000, "num_agent_steps_trained": 768000, "num_env_steps_sampled": 192000, "num_env_steps_trained": 192000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 63.12259273435842, "num_env_steps_trained_throughput_per_sec": 63.12259273435842, "timesteps_total": 192000, "num_env_steps_sampled_lifetime": 192000, "num_agent_steps_sampled_lifetime": 768000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 768000, "timers": {"training_iteration_time_ms": 56349.289, "restore_workers_time_ms": 0.014, "training_step_time_ms": 56349.237, "sample_time_ms": 1464.249, "learn_time_ms": 54865.773, "learn_throughput": 72.905, "synch_weights_time_ms": 15.028}, "counters": {"num_env_steps_sampled": 192000, "num_env_steps_trained": 192000, "num_agent_steps_sampled": 768000, "num_agent_steps_trained": 768000}, "done": false, "training_iteration": 48, "trial_id": "11e70_00000", "date": "2024-08-12_23-49-13", "timestamp": 1723520953, "time_this_iter_s": 63.407971143722534, "time_total_s": 2532.997891187668, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2b93280>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2532.997891187668, "iterations_since_restore": 48, "perf": {"cpu_util_percent": 68.56333333333332, "ram_util_percent": 83.17333333333333}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 9.85564765576963, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.3953566349372664, "policy_loss": -0.009276955870655242, "vf_loss": 2.4031160425887537, "vf_explained_var": 0.278392846685238, "kl": 0.01011696805219189, "entropy": 1.1802083559137173, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 91665.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.309653502481955, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.589380116563626, "policy_loss": -0.016265179873468778, "vf_loss": 4.604060357840604, "vf_explained_var": 0.033813498985199704, "kl": 0.010566173619633622, "entropy": 0.8962468823743245, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 91665.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 196000, "num_env_steps_trained": 196000, "num_agent_steps_sampled": 784000, "num_agent_steps_trained": 784000}, "env_runners": {"episode_reward_max": 377.7000000000001, "episode_reward_min": -378.5, "episode_reward_mean": 4.629999999999904, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -394.9, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 198.0}, "policy_reward_mean": {"prey_policy": -66.98500000000001, "predator_policy": 69.3}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-28.099999999999902, 161.39999999999998, -118.10000000000022, 140.39999999999995, -41.69999999999983, 150.29999999999959, -378.5, 276.0, -306.2, -40.7999999999998, -128.90000000000038, -20.70000000000003, 40.0000000000003, -281.1999999999996, -27.399999999999814, -96.40000000000018, -92.4, 33.400000000000205, -362.7, 40.70000000000009, 163.29999999999953, 40.0000000000003, -224.20000000000078, -51.8999999999998, -270.6, -42.799999999999805, -335.6, 144.9999999999995, 40.0000000000003, 110.6, -5.799999999999976, 40.0000000000003, -307.70000000000016, 121.49999999999932, 160.99999999999937, -283.4000000000001, -286.2, 219.09999999999926, -38.599999999999966, 176.69999999999948, -47.799999999999926, -338.49999999999983, 1.9999999999999374, 98.29999999999987, -219.90000000000015, 137.09999999999926, 40.0000000000003, -38.09999999999973, 40.0000000000003, 34.50000000000022, -78.80000000000018, -118.40000000000055, -33.89999999999983, -2.7000000000000473, 37.80000000000027, 325.1, 51.40000000000002, -28.3999999999999, -110.50000000000023, 10.700000000000182, -93.10000000000035, 46.60000000000005, 371.29999999999995, -147.5000000000006, 269.49999999999955, 212.79999999999922, -12.29999999999994, -24.899999999999743, 40.0000000000003, -260.2000000000004, -48.59999999999978, 197.99999999999937, 40.0000000000003, -92.30000000000024, 94.89999999999934, 131.39999999999992, 143.1, -120.70000000000056, 40.0000000000003, 219.99999999999926, 127.29999999999976, 142.3999999999996, -0.899999999999987, -64.60000000000011, 161.49999999999955, 58.8, 76.69999999999928, -9.00000000000006, -244.20000000000056, 40.0000000000003, -10.999999999999991, 377.7000000000001, -17.899999999999665, 24.60000000000005, 139.89999999999964, -13.999999999999625, 219.99999999999926, 250.79999999999959, 40.0000000000003, 107.49999999999989], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-243.10000000000002, 20.000000000000014, 186.2, -266.8, 20.000000000000014, -303.1, -255.4, 165.79999999999995, 20.000000000000014, -351.69999999999993, 20.000000000000014, 128.3, -327.69999999999993, -344.8, 152.89999999999998, 97.10000000000005, -340.6, -334.6, -259.9, 1.0999999999999528, 20.000000000000014, -313.9, -369.7, 20.000000000000014, 20.000000000000014, 20.000000000000014, -293.7999999999996, -291.4, 20.000000000000014, -321.3999999999999, 20.000000000000014, -345.4, 20.000000000000014, -270.40000000000003, 20.000000000000014, 7.399999999999965, -323.8, -316.9, -326.8, 87.49999999999997, 20.000000000000014, 143.3, 20.000000000000014, 20.000000000000014, -394.9, -70.30000000000078, -90.70000000000002, -47.199999999999875, -256.90000000000003, -273.70000000000005, -314.8, 20.000000000000014, -293.8, -218.8, 106.69999999999999, 5.299999999999967, 20.000000000000014, 20.000000000000014, -269.79999999999995, 136.4, -299.5000000000001, 13.699999999999964, 20.000000000000014, 20.000000000000014, -233.80000000000013, -319.90000000000003, 11.599999999999964, 62.900000000000006, 11.599999999999964, 106.4, -301.0, -276.4000000000001, -300.70000000000005, -293.5, 199.1, 20.000000000000014, -115.60000000000001, -130.00000000000003, 142.7, 20.000000000000014, 20.000000000000014, -320.8, -333.6999999999998, -347.8, -274.0, 20.000000000000014, -97.60000000000079, 131.90000000000003, -96.39999999999998, -284.5, 64.1, 20.000000000000014, 20.000000000000014, 20.000000000000014, -383.49999999999994, 7.399999999999968, 20.000000000000014, 20.000000000000014, 9.499999999999966, 20.000000000000014, 20.000000000000014, -272.80000000000007, -300.4000000000001, 20.000000000000014, 1.09999999999996, -199.00000000000009, 20.000000000000014, -309.70000000000005, 20.000000000000014, 15.799999999999963, 155.6, 159.5, -307.6, 200.0, -312.4000000000001, 20.000000000000014, 9.499999999999964, -336.99999999999994, -185.8, -32.49999999999976, -245.80000000000018, 13.699999999999969, 163.4, -242.8000000000004, 170.0, 191.29999999999998, -315.39999999999986, -3.0999999999999828, 199.1, 70.39999999999996, 20.000000000000014, 192.79999999999995, 15.799999999999962, -198.10000000000005, -394.9, 20.000000000000014, 20.000000000000014, 20.000000000000014, -249.40000000000038, -347.8, -361.6, 20.000000000000014, 20.000000000000014, 167.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, -343.29999999999995, 74.8999999999997, 20.000000000000014, 200.0, -196.60000000000008, -358.29999999999995, 196.39999999999998, 20.000000000000014, -300.69999999999953, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 107.29999999999998, 103.40000000000006, 20.000000000000014, -112.90000000000009, 20.000000000000014, -326.19999999999936, 11.599999999999964, 20.000000000000014, 141.5, 105.49999999999997, -267.6999999999996, -46.59999999999994, 56.30000000000012, -32.49999999999975, -140.50000000000028, -328.0, -194.20000000000056, 20.000000000000014, 20.000000000000014, -294.9999999999991, 20.000000000000014, 200.0, 169.7, 20.000000000000014, -106.9000000000006, -9.399999999999855, 20.000000000000014, 20.000000000000014, 119.89999999999998, 20.000000000000014, -85.00000000000074, 20.000000000000014, 200.0, 62.299999999999976, 183.5, 20.000000000000014, 20.000000000000014, 87.49999999999997, 20.000000000000014], "policy_predator_policy_reward": [107.0, 88.0, 90.0, 152.0, 0.0, 165.0, 82.0, 148.0, 136.0, 154.0, 2.0, 0.0, 126.0, 168.0, 0.0, 26.0, 191.0, 178.0, 72.0, 146.0, 31.0, 134.0, 177.0, 152.0, 0.0, 0.0, 141.0, 163.0, 163.0, 111.0, 171.0, 58.0, 155.0, 3.0, 0.0, 6.0, 152.0, 126.0, 128.0, 152.0, 0.0, 0.0, 0.0, 0.0, 198.0, 43.0, 45.0, 41.0, 110.0, 150.0, 93.0, 159.0, 177.0, 0.0, 7.0, 26.0, 0.0, 0.0, 149.0, 95.0, 120.0, 160.0, 0.0, 0.0, 177.0, 69.0, 4.0, 43.0, 34.0, 9.0, 112.0, 182.0, 140.0, 168.0, 0.0, 0.0, 131.0, 76.0, 0.0, 14.0, 146.0, 107.0, 181.0, 162.0, 123.0, 133.0, 0.0, 64.0, 161.0, 0.0, 21.0, 32.0, 0.0, 0.0, 182.0, 156.0, 0.0, 0.0, 0.0, 5.0, 20.0, 154.0, 0.0, 162.0, 55.0, 109.0, 144.0, 143.0, 2.0, 0.0, 0.0, 10.0, 0.0, 159.0, 141.0, 123.0, 47.0, 170.0, 105.0, 124.0, 3.0, 136.0, 126.0, 0.0, 10.0, 0.0, 0.0, 171.0, 0.0, 0.0, 0.0, 0.0, 64.0, 106.0, 157.0, 193.0, 0.0, 0.0, 173.0, 164.0, 107.0, 186.0, 11.0, 0.0, 0.0, 0.0, 172.0, 59.0, 0.0, 0.0, 128.0, 0.0, 148.0, 157.0, 0.0, 160.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 19.0, 0.0, 35.0, 57.0, 148.0, 102.0, 0.0, 0.0, 105.0, 116.0, 67.0, 0.0, 96.0, 68.0, 176.0, 102.0, 0.0, 0.0, 139.0, 125.0, 8.0, 0.0, 0.0, 69.0, 0.0, 14.0, 0.0, 0.0, 47.0, 4.0, 0.0, 0.0, 4.0, 1.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7064236496040318, "mean_inference_ms": 1.6697514776500313, "mean_action_processing_ms": 0.27842030224560455, "mean_env_wait_ms": 0.20820468950168464, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.012104153633117676, "StateBufferConnector_ms": 0.004590153694152832, "ViewRequirementAgentConnector_ms": 0.24934077262878418}, "num_episodes": 22, "episode_return_max": 377.7000000000001, "episode_return_min": -378.5, "episode_return_mean": 4.629999999999904, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 784000, "num_agent_steps_trained": 784000, "num_env_steps_sampled": 196000, "num_env_steps_trained": 196000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 63.781199081217366, "num_env_steps_trained_throughput_per_sec": 63.781199081217366, "timesteps_total": 196000, "num_env_steps_sampled_lifetime": 196000, "num_agent_steps_sampled_lifetime": 784000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 784000, "timers": {"training_iteration_time_ms": 57235.751, "restore_workers_time_ms": 0.014, "training_step_time_ms": 57235.697, "sample_time_ms": 1706.229, "learn_time_ms": 55509.242, "learn_throughput": 72.06, "synch_weights_time_ms": 15.967}, "counters": {"num_env_steps_sampled": 196000, "num_env_steps_trained": 196000, "num_agent_steps_sampled": 784000, "num_agent_steps_trained": 784000}, "done": false, "training_iteration": 49, "trial_id": "11e70_00000", "date": "2024-08-12_23-50-16", "timestamp": 1723521016, "time_this_iter_s": 62.757364988327026, "time_total_s": 2595.755256175995, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2b805e0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2595.755256175995, "iterations_since_restore": 49, "perf": {"cpu_util_percent": 65.42111111111112, "ram_util_percent": 83.25}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 8.16090429592385, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.1823925260671233, "policy_loss": -0.009556392102290399, "vf_loss": 1.1903410514511128, "vf_explained_var": 0.23880093990179596, "kl": 0.010719118435521029, "entropy": 1.1541486313734104, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 93555.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.481876343425619, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.500347177439896, "policy_loss": -0.011052443359106306, "vf_loss": 4.5105359352454935, "vf_explained_var": 0.2610761997245607, "kl": 0.005757916989331998, "entropy": 0.8101576612424598, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 93555.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 200000, "num_env_steps_trained": 200000, "num_agent_steps_sampled": 800000, "num_agent_steps_trained": 800000}, "env_runners": {"episode_reward_max": 377.7000000000001, "episode_reward_min": -338.49999999999983, "episode_reward_mean": 43.78199999999989, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -394.9, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 193.0}, "policy_reward_mean": {"prey_policy": -28.909000000000013, "predator_policy": 50.8}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-51.8999999999998, -270.6, -42.799999999999805, -335.6, 144.9999999999995, 40.0000000000003, 110.6, -5.799999999999976, 40.0000000000003, -307.70000000000016, 121.49999999999932, 160.99999999999937, -283.4000000000001, -286.2, 219.09999999999926, -38.599999999999966, 176.69999999999948, -47.799999999999926, -338.49999999999983, 1.9999999999999374, 98.29999999999987, -219.90000000000015, 137.09999999999926, 40.0000000000003, -38.09999999999973, 40.0000000000003, 34.50000000000022, -78.80000000000018, -118.40000000000055, -33.89999999999983, -2.7000000000000473, 37.80000000000027, 325.1, 51.40000000000002, -28.3999999999999, -110.50000000000023, 10.700000000000182, -93.10000000000035, 46.60000000000005, 371.29999999999995, -147.5000000000006, 269.49999999999955, 212.79999999999922, -12.29999999999994, -24.899999999999743, 40.0000000000003, -260.2000000000004, -48.59999999999978, 197.99999999999937, 40.0000000000003, -92.30000000000024, 94.89999999999934, 131.39999999999992, 143.1, -120.70000000000056, 40.0000000000003, 219.99999999999926, 127.29999999999976, 142.3999999999996, -0.899999999999987, -64.60000000000011, 161.49999999999955, 58.8, 76.69999999999928, -9.00000000000006, -244.20000000000056, 40.0000000000003, -10.999999999999991, 377.7000000000001, -17.899999999999665, 24.60000000000005, 139.89999999999964, -13.999999999999625, 219.99999999999926, 250.79999999999959, 40.0000000000003, 107.49999999999989, 23.400000000000045, 217.29999999999927, 353.4, 22.100000000000033, 50.80000000000048, 27.80000000000011, 238.0, 172.29999999999913, 184.59999999999943, 179.49999999999997, 40.0000000000003, 354.1000000000009, 374.79999999999984, -65.60000000000116, 22.400000000000013, 23.100000000000044, 261.7999999999994, 36.70000000000025, 23.50000000000006, 7.999999999999986, 38.90000000000028, 186.5, 40.0000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-90.70000000000002, -47.199999999999875, -256.90000000000003, -273.70000000000005, -314.8, 20.000000000000014, -293.8, -218.8, 106.69999999999999, 5.299999999999967, 20.000000000000014, 20.000000000000014, -269.79999999999995, 136.4, -299.5000000000001, 13.699999999999964, 20.000000000000014, 20.000000000000014, -233.80000000000013, -319.90000000000003, 11.599999999999964, 62.900000000000006, 11.599999999999964, 106.4, -301.0, -276.4000000000001, -300.70000000000005, -293.5, 199.1, 20.000000000000014, -115.60000000000001, -130.00000000000003, 142.7, 20.000000000000014, 20.000000000000014, -320.8, -333.6999999999998, -347.8, -274.0, 20.000000000000014, -97.60000000000079, 131.90000000000003, -96.39999999999998, -284.5, 64.1, 20.000000000000014, 20.000000000000014, 20.000000000000014, -383.49999999999994, 7.399999999999968, 20.000000000000014, 20.000000000000014, 9.499999999999966, 20.000000000000014, 20.000000000000014, -272.80000000000007, -300.4000000000001, 20.000000000000014, 1.09999999999996, -199.00000000000009, 20.000000000000014, -309.70000000000005, 20.000000000000014, 15.799999999999963, 155.6, 159.5, -307.6, 200.0, -312.4000000000001, 20.000000000000014, 9.499999999999964, -336.99999999999994, -185.8, -32.49999999999976, -245.80000000000018, 13.699999999999969, 163.4, -242.8000000000004, 170.0, 191.29999999999998, -315.39999999999986, -3.0999999999999828, 199.1, 70.39999999999996, 20.000000000000014, 192.79999999999995, 15.799999999999962, -198.10000000000005, -394.9, 20.000000000000014, 20.000000000000014, 20.000000000000014, -249.40000000000038, -347.8, -361.6, 20.000000000000014, 20.000000000000014, 167.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, -343.29999999999995, 74.8999999999997, 20.000000000000014, 200.0, -196.60000000000008, -358.29999999999995, 196.39999999999998, 20.000000000000014, -300.69999999999953, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 107.29999999999998, 103.40000000000006, 20.000000000000014, -112.90000000000009, 20.000000000000014, -326.19999999999936, 11.599999999999964, 20.000000000000014, 141.5, 105.49999999999997, -267.6999999999996, -46.59999999999994, 56.30000000000012, -32.49999999999975, -140.50000000000028, -328.0, -194.20000000000056, 20.000000000000014, 20.000000000000014, -294.9999999999991, 20.000000000000014, 200.0, 169.7, 20.000000000000014, -106.9000000000006, -9.399999999999855, 20.000000000000014, 20.000000000000014, 119.89999999999998, 20.000000000000014, -85.00000000000074, 20.000000000000014, 200.0, 62.299999999999976, 183.5, 20.000000000000014, 20.000000000000014, 87.49999999999997, 20.000000000000014, -25.59999999999978, 20.000000000000014, 20.000000000000014, 197.3, 169.3999999999998, 176.0, -61.90000000000067, 20.000000000000014, 20.000000000000014, 30.800000000000196, -13.599999999999783, 25.4000000000001, 83.0, 95.0, 152.2999999999998, 20.000000000000014, 170.0, -9.399999999999855, 115.39999999999998, 64.09999999999998, 20.000000000000014, 20.000000000000014, 200.0, 154.09999999999977, 200.0, 174.79999999999987, -124.90000000000074, -36.699999999999875, -13.599999999999783, 20.000000000000014, -124.90000000000074, 20.000000000000014, 74.59999999999944, 180.2, 20.000000000000014, 13.699999999999966, 20.000000000000014, -11.499999999999883, 20.000000000000014, -118.0, 20.000000000000014, 17.899999999999988, 70.10000000000008, 94.40000000000006, 20.000000000000014, 20.000000000000014], "policy_predator_policy_reward": [45.0, 41.0, 110.0, 150.0, 93.0, 159.0, 177.0, 0.0, 7.0, 26.0, 0.0, 0.0, 149.0, 95.0, 120.0, 160.0, 0.0, 0.0, 177.0, 69.0, 4.0, 43.0, 34.0, 9.0, 112.0, 182.0, 140.0, 168.0, 0.0, 0.0, 131.0, 76.0, 0.0, 14.0, 146.0, 107.0, 181.0, 162.0, 123.0, 133.0, 0.0, 64.0, 161.0, 0.0, 21.0, 32.0, 0.0, 0.0, 182.0, 156.0, 0.0, 0.0, 0.0, 5.0, 20.0, 154.0, 0.0, 162.0, 55.0, 109.0, 144.0, 143.0, 2.0, 0.0, 0.0, 10.0, 0.0, 159.0, 141.0, 123.0, 47.0, 170.0, 105.0, 124.0, 3.0, 136.0, 126.0, 0.0, 10.0, 0.0, 0.0, 171.0, 0.0, 0.0, 0.0, 0.0, 64.0, 106.0, 157.0, 193.0, 0.0, 0.0, 173.0, 164.0, 107.0, 186.0, 11.0, 0.0, 0.0, 0.0, 172.0, 59.0, 0.0, 0.0, 128.0, 0.0, 148.0, 157.0, 0.0, 160.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 19.0, 0.0, 35.0, 57.0, 148.0, 102.0, 0.0, 0.0, 105.0, 116.0, 67.0, 0.0, 96.0, 68.0, 176.0, 102.0, 0.0, 0.0, 139.0, 125.0, 8.0, 0.0, 0.0, 69.0, 0.0, 14.0, 0.0, 0.0, 47.0, 4.0, 0.0, 0.0, 4.0, 1.0, 0.0, 0.0, 0.0, 0.0, 29.0, 0.0, 0.0, 0.0, 0.0, 8.0, 29.0, 35.0, 0.0, 0.0, 0.0, 16.0, 46.0, 14.0, 0.0, 0.0, 14.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 96.0, 0.0, 0.0, 16.0, 59.0, 69.0, 0.0, 7.0, 3.0, 0.0, 15.0, 0.0, 0.0, 106.0, 0.0, 1.0, 22.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7174458501817739, "mean_inference_ms": 1.6913247180762252, "mean_action_processing_ms": 0.28243255992866517, "mean_env_wait_ms": 0.21116006671308804, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01971876621246338, "StateBufferConnector_ms": 0.005751252174377441, "ViewRequirementAgentConnector_ms": 0.23525691032409668}, "num_episodes": 23, "episode_return_max": 377.7000000000001, "episode_return_min": -338.49999999999983, "episode_return_mean": 43.78199999999989, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 800000, "num_agent_steps_trained": 800000, "num_env_steps_sampled": 200000, "num_env_steps_trained": 200000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 64.10854045639886, "num_env_steps_trained_throughput_per_sec": 64.10854045639886, "timesteps_total": 200000, "num_env_steps_sampled_lifetime": 200000, "num_agent_steps_sampled_lifetime": 800000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 800000, "timers": {"training_iteration_time_ms": 58251.091, "restore_workers_time_ms": 0.014, "training_step_time_ms": 58251.037, "sample_time_ms": 1767.686, "learn_time_ms": 56461.591, "learn_throughput": 70.845, "synch_weights_time_ms": 17.69}, "counters": {"num_env_steps_sampled": 200000, "num_env_steps_trained": 200000, "num_agent_steps_sampled": 800000, "num_agent_steps_trained": 800000}, "done": false, "training_iteration": 50, "trial_id": "11e70_00000", "date": "2024-08-12_23-51-18", "timestamp": 1723521078, "time_this_iter_s": 62.46900415420532, "time_total_s": 2658.2242603302, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2b963a0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2658.2242603302, "iterations_since_restore": 50, "perf": {"cpu_util_percent": 66.37272727272727, "ram_util_percent": 83.41250000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 8.395820585318974, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.1540287371823397, "policy_loss": -0.010658434662652552, "vf_loss": 1.1634668959353966, "vf_explained_var": 0.1456433427712274, "kl": 0.008135144958308898, "entropy": 1.1346868547812972, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 95445.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.558929346982764, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.1516512294294974, "policy_loss": -0.00945020222546109, "vf_loss": 3.160049965394237, "vf_explained_var": 0.33059571968815316, "kl": 0.007009834693121264, "entropy": 0.7584783052956616, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 95445.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 204000, "num_env_steps_trained": 204000, "num_agent_steps_sampled": 816000, "num_agent_steps_trained": 816000}, "env_runners": {"episode_reward_max": 377.7000000000001, "episode_reward_min": -338.49999999999983, "episode_reward_mean": 65.47199999999991, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -394.9, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 209.0}, "policy_reward_mean": {"prey_policy": -6.684000000000017, "predator_policy": 39.42}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-338.49999999999983, 1.9999999999999374, 98.29999999999987, -219.90000000000015, 137.09999999999926, 40.0000000000003, -38.09999999999973, 40.0000000000003, 34.50000000000022, -78.80000000000018, -118.40000000000055, -33.89999999999983, -2.7000000000000473, 37.80000000000027, 325.1, 51.40000000000002, -28.3999999999999, -110.50000000000023, 10.700000000000182, -93.10000000000035, 46.60000000000005, 371.29999999999995, -147.5000000000006, 269.49999999999955, 212.79999999999922, -12.29999999999994, -24.899999999999743, 40.0000000000003, -260.2000000000004, -48.59999999999978, 197.99999999999937, 40.0000000000003, -92.30000000000024, 94.89999999999934, 131.39999999999992, 143.1, -120.70000000000056, 40.0000000000003, 219.99999999999926, 127.29999999999976, 142.3999999999996, -0.899999999999987, -64.60000000000011, 161.49999999999955, 58.8, 76.69999999999928, -9.00000000000006, -244.20000000000056, 40.0000000000003, -10.999999999999991, 377.7000000000001, -17.899999999999665, 24.60000000000005, 139.89999999999964, -13.999999999999625, 219.99999999999926, 250.79999999999959, 40.0000000000003, 107.49999999999989, 23.400000000000045, 217.29999999999927, 353.4, 22.100000000000033, 50.80000000000048, 27.80000000000011, 238.0, 172.29999999999913, 184.59999999999943, 179.49999999999997, 40.0000000000003, 354.1000000000009, 374.79999999999984, -65.60000000000116, 22.400000000000013, 23.100000000000044, 261.7999999999994, 36.70000000000025, 23.50000000000006, 7.999999999999986, 38.90000000000028, 186.5, 40.0000000000003, 173.19999999999956, 183.99999999999943, -135.40000000000086, 34.50000000000022, 22.100000000000023, 40.0000000000003, 344.2000000000004, 215.49999999999923, 27.90000000000011, 40.0000000000003, 35.600000000000236, 40.0000000000003, 11.599999999999946, 91.30000000000004, 219.99999999999926, -3.2999999999998373, 162.19999999999953, 9.100000000000184], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-333.6999999999998, -347.8, -274.0, 20.000000000000014, -97.60000000000079, 131.90000000000003, -96.39999999999998, -284.5, 64.1, 20.000000000000014, 20.000000000000014, 20.000000000000014, -383.49999999999994, 7.399999999999968, 20.000000000000014, 20.000000000000014, 9.499999999999966, 20.000000000000014, 20.000000000000014, -272.80000000000007, -300.4000000000001, 20.000000000000014, 1.09999999999996, -199.00000000000009, 20.000000000000014, -309.70000000000005, 20.000000000000014, 15.799999999999963, 155.6, 159.5, -307.6, 200.0, -312.4000000000001, 20.000000000000014, 9.499999999999964, -336.99999999999994, -185.8, -32.49999999999976, -245.80000000000018, 13.699999999999969, 163.4, -242.8000000000004, 170.0, 191.29999999999998, -315.39999999999986, -3.0999999999999828, 199.1, 70.39999999999996, 20.000000000000014, 192.79999999999995, 15.799999999999962, -198.10000000000005, -394.9, 20.000000000000014, 20.000000000000014, 20.000000000000014, -249.40000000000038, -347.8, -361.6, 20.000000000000014, 20.000000000000014, 167.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, -343.29999999999995, 74.8999999999997, 20.000000000000014, 200.0, -196.60000000000008, -358.29999999999995, 196.39999999999998, 20.000000000000014, -300.69999999999953, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 107.29999999999998, 103.40000000000006, 20.000000000000014, -112.90000000000009, 20.000000000000014, -326.19999999999936, 11.599999999999964, 20.000000000000014, 141.5, 105.49999999999997, -267.6999999999996, -46.59999999999994, 56.30000000000012, -32.49999999999975, -140.50000000000028, -328.0, -194.20000000000056, 20.000000000000014, 20.000000000000014, -294.9999999999991, 20.000000000000014, 200.0, 169.7, 20.000000000000014, -106.9000000000006, -9.399999999999855, 20.000000000000014, 20.000000000000014, 119.89999999999998, 20.000000000000014, -85.00000000000074, 20.000000000000014, 200.0, 62.299999999999976, 183.5, 20.000000000000014, 20.000000000000014, 87.49999999999997, 20.000000000000014, -25.59999999999978, 20.000000000000014, 20.000000000000014, 197.3, 169.3999999999998, 176.0, -61.90000000000067, 20.000000000000014, 20.000000000000014, 30.800000000000196, -13.599999999999783, 25.4000000000001, 83.0, 95.0, 152.2999999999998, 20.000000000000014, 170.0, -9.399999999999855, 115.39999999999998, 64.09999999999998, 20.000000000000014, 20.000000000000014, 200.0, 154.09999999999977, 200.0, 174.79999999999987, -124.90000000000074, -36.699999999999875, -13.599999999999783, 20.000000000000014, -124.90000000000074, 20.000000000000014, 74.59999999999944, 180.2, 20.000000000000014, 13.699999999999966, 20.000000000000014, -11.499999999999883, 20.000000000000014, -118.0, 20.000000000000014, 17.899999999999988, 70.10000000000008, 94.40000000000006, 20.000000000000014, 20.000000000000014, 153.20000000000005, 20.000000000000014, 20.000000000000014, 146.0, 20.000000000000014, -364.4000000000001, 20.000000000000014, 9.499999999999964, 20.000000000000014, -28.899999999999764, 20.000000000000014, 20.000000000000014, 184.6999999999999, 159.5, 195.49999999999997, 20.000000000000014, 20.000000000000014, -3.099999999999958, 20.000000000000014, 20.000000000000014, 20.000000000000014, 11.599999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, -51.39999999999988, 20.000000000000014, 71.29999999999997, 200.0, 20.000000000000014, -31.899999999999785, -75.40000000000069, 141.2, 20.000000000000014, 20.000000000000014, -52.900000000000155], "policy_predator_policy_reward": [181.0, 162.0, 123.0, 133.0, 0.0, 64.0, 161.0, 0.0, 21.0, 32.0, 0.0, 0.0, 182.0, 156.0, 0.0, 0.0, 0.0, 5.0, 20.0, 154.0, 0.0, 162.0, 55.0, 109.0, 144.0, 143.0, 2.0, 0.0, 0.0, 10.0, 0.0, 159.0, 141.0, 123.0, 47.0, 170.0, 105.0, 124.0, 3.0, 136.0, 126.0, 0.0, 10.0, 0.0, 0.0, 171.0, 0.0, 0.0, 0.0, 0.0, 64.0, 106.0, 157.0, 193.0, 0.0, 0.0, 173.0, 164.0, 107.0, 186.0, 11.0, 0.0, 0.0, 0.0, 172.0, 59.0, 0.0, 0.0, 128.0, 0.0, 148.0, 157.0, 0.0, 160.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 19.0, 0.0, 35.0, 57.0, 148.0, 102.0, 0.0, 0.0, 105.0, 116.0, 67.0, 0.0, 96.0, 68.0, 176.0, 102.0, 0.0, 0.0, 139.0, 125.0, 8.0, 0.0, 0.0, 69.0, 0.0, 14.0, 0.0, 0.0, 47.0, 4.0, 0.0, 0.0, 4.0, 1.0, 0.0, 0.0, 0.0, 0.0, 29.0, 0.0, 0.0, 0.0, 0.0, 8.0, 29.0, 35.0, 0.0, 0.0, 0.0, 16.0, 46.0, 14.0, 0.0, 0.0, 14.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 96.0, 0.0, 0.0, 16.0, 59.0, 69.0, 0.0, 7.0, 3.0, 0.0, 15.0, 0.0, 0.0, 106.0, 0.0, 1.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 18.0, 0.0, 209.0, 0.0, 5.0, 0.0, 8.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 43.0, 0.0, 0.0, 0.0, 0.0, 0.0, 48.0, 56.0, 1.0, 0.0, 0.0, 42.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7245696854037912, "mean_inference_ms": 1.7087402356948218, "mean_action_processing_ms": 0.28536894875668845, "mean_env_wait_ms": 0.21365093148292347, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.018874406814575195, "StateBufferConnector_ms": 0.0059517621994018555, "ViewRequirementAgentConnector_ms": 0.2280055284500122}, "num_episodes": 18, "episode_return_max": 377.7000000000001, "episode_return_min": -338.49999999999983, "episode_return_mean": 65.47199999999991, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 816000, "num_agent_steps_trained": 816000, "num_env_steps_sampled": 204000, "num_env_steps_trained": 204000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 55.02905274850393, "num_env_steps_trained_throughput_per_sec": 55.02905274850393, "timesteps_total": 204000, "num_env_steps_sampled_lifetime": 204000, "num_agent_steps_sampled_lifetime": 816000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 816000, "timers": {"training_iteration_time_ms": 60086.368, "restore_workers_time_ms": 0.014, "training_step_time_ms": 60086.314, "sample_time_ms": 1816.522, "learn_time_ms": 58247.52, "learn_throughput": 68.672, "synch_weights_time_ms": 18.14}, "counters": {"num_env_steps_sampled": 204000, "num_env_steps_trained": 204000, "num_agent_steps_sampled": 816000, "num_agent_steps_trained": 816000}, "done": false, "training_iteration": 51, "trial_id": "11e70_00000", "date": "2024-08-12_23-52-31", "timestamp": 1723521151, "time_this_iter_s": 72.75641965866089, "time_total_s": 2730.980679988861, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2b80700>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2730.980679988861, "iterations_since_restore": 51, "perf": {"cpu_util_percent": 82.58173076923077, "ram_util_percent": 83.66538461538462}}
