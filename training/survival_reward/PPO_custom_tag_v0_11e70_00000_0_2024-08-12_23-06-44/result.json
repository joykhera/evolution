{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6814542869726817, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.920146265673259, "policy_loss": 0.0010854221043970298, "vf_loss": 2.9149202129828238, "vf_explained_var": 0.003947857069590735, "kl": 0.02070311488849776, "entropy": 1.6025439478102184, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 945.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.1824771218198946, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.536903250658954, "policy_loss": -0.005113448849854567, "vf_loss": 7.5372467293310415, "vf_explained_var": -0.013383193463875504, "kl": 0.02384979013530981, "entropy": 1.6026754217173056, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 945.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 4000, "num_env_steps_trained": 4000, "num_agent_steps_sampled": 16000, "num_agent_steps_trained": 16000}, "env_runners": {"episode_reward_max": 205.2999999999997, "episode_reward_min": -123.10000000000036, "episode_reward_mean": 44.26666666666664, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 3600, "policy_reward_min": {"prey_policy": -269.8, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 120.7999999999995, "predator_policy": 138.0}, "policy_reward_mean": {"prey_policy": 2.0499999999999776, "predator_policy": 20.083333333333332}, "custom_metrics": {}, "hist_stats": {"episode_reward": [205.2999999999997, 26.10000000000045, 85.00000000000006, 166.09999999999897, 0.20000000000001794, -123.10000000000036, 35.20000000000038, 43.600000000000364, -14.399999999999972, 59.30000000000049, 33.400000000000205, 29.59999999999996, 62.80000000000026, 24.700000000000287, -42.400000000000176, 68.59999999999997, 140.79999999999876, -3.9999999999997313], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [117.49999999999974, 69.80000000000004, 47.90000000000024, -59.79999999999996, 14.599999999999959, 43.4, 101.60000000000001, 51.50000000000022, 30.80000000000002, -76.59999999999995, -269.8, -7.300000000000029, -3.9999999999998934, -17.79999999999974, 20.000000000000014, 23.60000000000008, 37.100000000000094, -116.50000000000011, 20.000000000000014, 32.30000000000023, 20.000000000000014, 7.399999999999965, 42.2, -55.600000000000016, -23.49999999999993, 20.30000000000007, -21.999999999999744, -16.299999999999997, -9.399999999999855, -85.00000000000085, 9.499999999999972, 31.09999999999998, 20.000000000000014, 120.7999999999995, 20.000000000000014, -64.00000000000091], "policy_predator_policy_reward": [0.0, 18.0, 0.0, 38.0, 27.0, 0.0, 13.0, 0.0, 0.0, 46.0, 16.0, 138.0, 8.0, 49.0, 0.0, 0.0, 65.0, 0.0, 0.0, 7.0, 6.0, 0.0, 43.0, 0.0, 29.0, 37.0, 0.0, 63.0, 50.0, 2.0, 0.0, 28.0, 0.0, 0.0, 0.0, 40.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7953175688321418, "mean_inference_ms": 1.8497698087723171, "mean_action_processing_ms": 0.3149636378818728, "mean_env_wait_ms": 0.24297500837538147, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0064392884572347, "StateBufferConnector_ms": 0.003247128592597114, "ViewRequirementAgentConnector_ms": 0.10932419035169813}, "num_episodes": 18, "episode_return_max": 205.2999999999997, "episode_return_min": -123.10000000000036, "episode_return_mean": 44.26666666666664, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 16000, "num_agent_steps_trained": 16000, "num_env_steps_sampled": 4000, "num_env_steps_trained": 4000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 70.23585853816977, "num_env_steps_trained_throughput_per_sec": 70.23585853816977, "timesteps_total": 4000, "num_env_steps_sampled_lifetime": 4000, "num_agent_steps_sampled_lifetime": 16000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 16000, "timers": {"training_iteration_time_ms": 56950.974, "restore_workers_time_ms": 0.018, "training_step_time_ms": 56950.924, "sample_time_ms": 1557.568, "learn_time_ms": 55375.966, "learn_throughput": 72.234, "synch_weights_time_ms": 11.343}, "counters": {"num_env_steps_sampled": 4000, "num_env_steps_trained": 4000, "num_agent_steps_sampled": 16000, "num_agent_steps_trained": 16000}, "done": false, "training_iteration": 1, "trial_id": "11e70_00000", "date": "2024-08-12_23-07-53", "timestamp": 1723518473, "time_this_iter_s": 57.01151514053345, "time_total_s": 57.01151514053345, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2ad7e50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 57.01151514053345, "iterations_since_restore": 1, "perf": {"cpu_util_percent": 49.611111111111114, "ram_util_percent": 83.48271604938272}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6557076118610523, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.0913939872116005, "policy_loss": -0.010414980000707877, "vf_loss": 4.100190023518113, "vf_explained_var": 0.0014689797446841286, "kl": 0.005396486977459787, "entropy": 1.5950437980354149, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 2835.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.592025606121336, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.265093356339389, "policy_loss": -0.008191729390811392, "vf_loss": 7.272091883200186, "vf_explained_var": -0.008012627861487171, "kl": 0.003977357404226305, "entropy": 1.5957450415722276, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 2835.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 8000, "num_env_steps_trained": 8000, "num_agent_steps_sampled": 32000, "num_agent_steps_trained": 32000}, "env_runners": {"episode_reward_max": 318.5000000000001, "episode_reward_min": -123.10000000000036, "episode_reward_mean": 52.54999999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 7200, "policy_reward_min": {"prey_policy": -269.8, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 186.49999999999997, "predator_policy": 138.0}, "policy_reward_mean": {"prey_policy": -2.475000000000052, "predator_policy": 28.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [205.2999999999997, 26.10000000000045, 85.00000000000006, 166.09999999999897, 0.20000000000001794, -123.10000000000036, 35.20000000000038, 43.600000000000364, -14.399999999999972, 59.30000000000049, 33.400000000000205, 29.59999999999996, 62.80000000000026, 24.700000000000287, -42.400000000000176, 68.59999999999997, 140.79999999999876, -3.9999999999997313, 109.59999999999982, 83.40000000000006, 318.5000000000001, 25.600000000000193, -52.59999999999982, 18.600000000000044, 88.49999999999997, 42.39999999999997, -7.299999999999805, 213.9999999999992, -81.00000000000009, -44.299999999999876, 34.9000000000001, 178.09999999999997, 81.89999999999962, 72.60000000000001, 32.400000000000226, -20.300000000000054], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [117.49999999999974, 69.80000000000004, 47.90000000000024, -59.79999999999996, 14.599999999999959, 43.4, 101.60000000000001, 51.50000000000022, 30.80000000000002, -76.59999999999995, -269.8, -7.300000000000029, -3.9999999999998934, -17.79999999999974, 20.000000000000014, 23.60000000000008, 37.100000000000094, -116.50000000000011, 20.000000000000014, 32.30000000000023, 20.000000000000014, 7.399999999999965, 42.2, -55.600000000000016, -23.49999999999993, 20.30000000000007, -21.999999999999744, -16.299999999999997, -9.399999999999855, -85.00000000000085, 9.499999999999972, 31.09999999999998, 20.000000000000014, 120.7999999999995, 20.000000000000014, -64.00000000000091, -129.1000000000006, 166.70000000000002, 141.2, -164.8000000000001, 172.6999999999999, 138.79999999999998, -115.60000000000068, 60.20000000000008, -54.9999999999999, -184.6, 4.999999999999979, -39.39999999999996, 0.4999999999999716, 26.000000000000128, -190.90000000000018, 125.29999999999978, -70.30000000000067, 20.000000000000014, 24.50000000000009, 186.49999999999997, -211.00000000000017, 20.000000000000014, 1.0999999999999794, -168.40000000000023, 20.000000000000014, -21.099999999999802, -33.10000000000004, 126.19999999999999, 59.90000000000021, 20.000000000000014, 97.40000000000003, -152.8000000000002, 95.59999999999998, -152.20000000000056, -36.70000000000003, -34.599999999999866], "policy_predator_policy_reward": [0.0, 18.0, 0.0, 38.0, 27.0, 0.0, 13.0, 0.0, 0.0, 46.0, 16.0, 138.0, 8.0, 49.0, 0.0, 0.0, 65.0, 0.0, 0.0, 7.0, 6.0, 0.0, 43.0, 0.0, 29.0, 37.0, 0.0, 63.0, 50.0, 2.0, 0.0, 28.0, 0.0, 0.0, 0.0, 40.0, 71.0, 1.0, 97.0, 10.0, 3.0, 4.0, 13.0, 68.0, 52.0, 135.0, 8.0, 45.0, 54.0, 8.0, 106.0, 2.0, 0.0, 43.0, 3.0, 0.0, 0.0, 110.0, 75.0, 48.0, 30.0, 6.0, 3.0, 82.0, 1.0, 1.0, 5.0, 123.0, 82.0, 7.0, 0.0, 51.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8029784024033437, "mean_inference_ms": 1.872199748160512, "mean_action_processing_ms": 0.32255816552031924, "mean_env_wait_ms": 0.24815825568124625, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007304549217224121, "StateBufferConnector_ms": 0.0036428372065226236, "ViewRequirementAgentConnector_ms": 0.23034479882982042}, "num_episodes": 18, "episode_return_max": 318.5000000000001, "episode_return_min": -123.10000000000036, "episode_return_mean": 52.54999999999998, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 32000, "num_agent_steps_trained": 32000, "num_env_steps_sampled": 8000, "num_env_steps_trained": 8000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 73.76579600185563, "num_env_steps_trained_throughput_per_sec": 73.76579600185563, "timesteps_total": 8000, "num_env_steps_sampled_lifetime": 8000, "num_agent_steps_sampled_lifetime": 32000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 32000, "timers": {"training_iteration_time_ms": 55588.338, "restore_workers_time_ms": 0.035, "training_step_time_ms": 55588.248, "sample_time_ms": 1577.038, "learn_time_ms": 53994.015, "learn_throughput": 74.082, "synch_weights_time_ms": 11.241}, "counters": {"num_env_steps_sampled": 8000, "num_env_steps_trained": 8000, "num_agent_steps_sampled": 32000, "num_agent_steps_trained": 32000}, "done": false, "training_iteration": 2, "trial_id": "11e70_00000", "date": "2024-08-12_23-08-50", "timestamp": 1723518530, "time_this_iter_s": 54.24736189842224, "time_total_s": 111.25887703895569, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2b59700>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 111.25887703895569, "iterations_since_restore": 2, "perf": {"cpu_util_percent": 43.13333333333333, "ram_util_percent": 80.59753086419754}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7892567942066797, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.457775247286237, "policy_loss": -0.010485536178140334, "vf_loss": 4.466621523307114, "vf_explained_var": 0.010459462233952114, "kl": 0.005464200843043067, "entropy": 1.5840066469535625, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 4725.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.238677484900863, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.980084675077408, "policy_loss": -0.014821235798225398, "vf_loss": 7.99270704763907, "vf_explained_var": 0.0090733373291278, "kl": 0.014659046555231054, "entropy": 1.5731455399245813, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 4725.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 12000, "num_env_steps_trained": 12000, "num_agent_steps_sampled": 48000, "num_agent_steps_trained": 48000}, "env_runners": {"episode_reward_max": 318.5000000000001, "episode_reward_min": -128.40000000000043, "episode_reward_mean": 55.59444444444438, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 10800, "policy_reward_min": {"prey_policy": -314.7999999999998, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 194.59999999999997, "predator_policy": 166.0}, "policy_reward_mean": {"prey_policy": -7.3138888888889575, "predator_policy": 35.111111111111114}, "custom_metrics": {}, "hist_stats": {"episode_reward": [205.2999999999997, 26.10000000000045, 85.00000000000006, 166.09999999999897, 0.20000000000001794, -123.10000000000036, 35.20000000000038, 43.600000000000364, -14.399999999999972, 59.30000000000049, 33.400000000000205, 29.59999999999996, 62.80000000000026, 24.700000000000287, -42.400000000000176, 68.59999999999997, 140.79999999999876, -3.9999999999997313, 109.59999999999982, 83.40000000000006, 318.5000000000001, 25.600000000000193, -52.59999999999982, 18.600000000000044, 88.49999999999997, 42.39999999999997, -7.299999999999805, 213.9999999999992, -81.00000000000009, -44.299999999999876, 34.9000000000001, 178.09999999999997, 81.89999999999962, 72.60000000000001, 32.400000000000226, -20.300000000000054, 47.80000000000027, 254.4999999999999, -103.80000000000103, 42.10000000000008, 124.59999999999874, 34.0000000000002, -1.3999999999999861, -24.4999999999999, -128.40000000000043, 219.69999999999908, 142.79999999999984, 137.79999999999987, 77.09999999999997, 279.79999999999995, 107.49999999999991, -8.299999999999953, -62.30000000000004, -28.699999999999847], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [117.49999999999974, 69.80000000000004, 47.90000000000024, -59.79999999999996, 14.599999999999959, 43.4, 101.60000000000001, 51.50000000000022, 30.80000000000002, -76.59999999999995, -269.8, -7.300000000000029, -3.9999999999998934, -17.79999999999974, 20.000000000000014, 23.60000000000008, 37.100000000000094, -116.50000000000011, 20.000000000000014, 32.30000000000023, 20.000000000000014, 7.399999999999965, 42.2, -55.600000000000016, -23.49999999999993, 20.30000000000007, -21.999999999999744, -16.299999999999997, -9.399999999999855, -85.00000000000085, 9.499999999999972, 31.09999999999998, 20.000000000000014, 120.7999999999995, 20.000000000000014, -64.00000000000091, -129.1000000000006, 166.70000000000002, 141.2, -164.8000000000001, 172.6999999999999, 138.79999999999998, -115.60000000000068, 60.20000000000008, -54.9999999999999, -184.6, 4.999999999999979, -39.39999999999996, 0.4999999999999716, 26.000000000000128, -190.90000000000018, 125.29999999999978, -70.30000000000067, 20.000000000000014, 24.50000000000009, 186.49999999999997, -211.00000000000017, 20.000000000000014, 1.0999999999999794, -168.40000000000023, 20.000000000000014, -21.099999999999802, -33.10000000000004, 126.19999999999999, 59.90000000000021, 20.000000000000014, 97.40000000000003, -152.8000000000002, 95.59999999999998, -152.20000000000056, -36.70000000000003, -34.599999999999866, 20.000000000000014, 21.800000000000004, 67.4, 145.09999999999988, -127.90000000000006, -88.90000000000069, -94.89999999999998, 70.99999999999999, 20.000000000000014, 104.59999999999944, -68.50000000000003, 9.499999999999947, -126.10000000000008, 10.699999999999974, 71.30000000000013, -314.7999999999998, -221.20000000000024, -215.20000000000013, 104.59999999999948, 109.09999999999965, -5.50000000000027, 74.2999999999999, 27.499999999999993, 41.300000000000075, -166.90000000000015, 119.0, 42.199999999999875, 194.59999999999997, 87.49999999999997, 20.000000000000014, -261.40000000000003, 70.09999999999988, -253.0, 22.700000000000063, 9.79999999999999, -131.5000000000004], "policy_predator_policy_reward": [0.0, 18.0, 0.0, 38.0, 27.0, 0.0, 13.0, 0.0, 0.0, 46.0, 16.0, 138.0, 8.0, 49.0, 0.0, 0.0, 65.0, 0.0, 0.0, 7.0, 6.0, 0.0, 43.0, 0.0, 29.0, 37.0, 0.0, 63.0, 50.0, 2.0, 0.0, 28.0, 0.0, 0.0, 0.0, 40.0, 71.0, 1.0, 97.0, 10.0, 3.0, 4.0, 13.0, 68.0, 52.0, 135.0, 8.0, 45.0, 54.0, 8.0, 106.0, 2.0, 0.0, 43.0, 3.0, 0.0, 0.0, 110.0, 75.0, 48.0, 30.0, 6.0, 3.0, 82.0, 1.0, 1.0, 5.0, 123.0, 82.0, 7.0, 0.0, 51.0, 6.0, 0.0, 0.0, 42.0, 62.0, 51.0, 10.0, 56.0, 0.0, 0.0, 93.0, 0.0, 114.0, 0.0, 154.0, 65.0, 165.0, 143.0, 0.0, 6.0, 22.0, 52.0, 34.0, 35.0, 0.0, 125.0, 43.0, 0.0, 0.0, 0.0, 166.0, 17.0, 38.0, 130.0, 49.0, 44.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7849396189524588, "mean_inference_ms": 1.836833524763357, "mean_action_processing_ms": 0.31606629150442317, "mean_env_wait_ms": 0.2430231638536353, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007048138865718135, "StateBufferConnector_ms": 0.0034453692259611905, "ViewRequirementAgentConnector_ms": 0.18711090087890625}, "num_episodes": 18, "episode_return_max": 318.5000000000001, "episode_return_min": -128.40000000000043, "episode_return_mean": 55.59444444444438, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 48000, "num_agent_steps_trained": 48000, "num_env_steps_sampled": 12000, "num_env_steps_trained": 12000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 77.71198805397259, "num_env_steps_trained_throughput_per_sec": 77.71198805397259, "timesteps_total": 12000, "num_env_steps_sampled_lifetime": 12000, "num_agent_steps_sampled_lifetime": 48000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 48000, "timers": {"training_iteration_time_ms": 54216.264, "restore_workers_time_ms": 0.028, "training_step_time_ms": 54216.19, "sample_time_ms": 1455.33, "learn_time_ms": 52745.17, "learn_throughput": 75.836, "synch_weights_time_ms": 11.207}, "counters": {"num_env_steps_sampled": 12000, "num_env_steps_trained": 12000, "num_agent_steps_sampled": 48000, "num_agent_steps_trained": 48000}, "done": false, "training_iteration": 3, "trial_id": "11e70_00000", "date": "2024-08-12_23-09-41", "timestamp": 1723518581, "time_this_iter_s": 51.48535919189453, "time_total_s": 162.74423623085022, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2af5d30>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 162.74423623085022, "iterations_since_restore": 3, "perf": {"cpu_util_percent": 38.22027027027027, "ram_util_percent": 81.36351351351352}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5378904705798184, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.476772289175205, "policy_loss": -0.012201770534615708, "vf_loss": 3.4870147529733244, "vf_explained_var": 0.00912992761879371, "kl": 0.006531006887197697, "entropy": 1.5816458823188904, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 6615.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.9664585196467304, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.474794582841257, "policy_loss": -0.0120695919424256, "vf_loss": 6.485553711684292, "vf_explained_var": 0.029866930826631173, "kl": 0.008736503005187761, "entropy": 1.5607386124827873, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 6615.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 16000, "num_env_steps_trained": 16000, "num_agent_steps_sampled": 64000, "num_agent_steps_trained": 64000}, "env_runners": {"episode_reward_max": 318.5000000000001, "episode_reward_min": -293.20000000000016, "episode_reward_mean": 59.12222222222211, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 14400, "policy_reward_min": {"prey_policy": -322.8, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 194.59999999999997, "predator_policy": 186.0}, "policy_reward_mean": {"prey_policy": -5.855555555555609, "predator_policy": 35.416666666666664}, "custom_metrics": {}, "hist_stats": {"episode_reward": [205.2999999999997, 26.10000000000045, 85.00000000000006, 166.09999999999897, 0.20000000000001794, -123.10000000000036, 35.20000000000038, 43.600000000000364, -14.399999999999972, 59.30000000000049, 33.400000000000205, 29.59999999999996, 62.80000000000026, 24.700000000000287, -42.400000000000176, 68.59999999999997, 140.79999999999876, -3.9999999999997313, 109.59999999999982, 83.40000000000006, 318.5000000000001, 25.600000000000193, -52.59999999999982, 18.600000000000044, 88.49999999999997, 42.39999999999997, -7.299999999999805, 213.9999999999992, -81.00000000000009, -44.299999999999876, 34.9000000000001, 178.09999999999997, 81.89999999999962, 72.60000000000001, 32.400000000000226, -20.300000000000054, 47.80000000000027, 254.4999999999999, -103.80000000000103, 42.10000000000008, 124.59999999999874, 34.0000000000002, -1.3999999999999861, -24.4999999999999, -128.40000000000043, 219.69999999999908, 142.79999999999984, 137.79999999999987, 77.09999999999997, 279.79999999999995, 107.49999999999991, -8.299999999999953, -62.30000000000004, -28.699999999999847, -2.2000000000000064, -21.999999999999854, -84.19999999999987, 152.29999999999944, -293.20000000000016, 148.29999999999964, -30.099999999999888, -8.599999999999842, 163.4999999999995, 98.19999999999993, 247.4999999999996, 208.59999999999943, 87.00000000000006, 27.300000000000253, 18.90000000000007, 105.9999999999996, 230.89999999999938, 206.49999999999918], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [117.49999999999974, 69.80000000000004, 47.90000000000024, -59.79999999999996, 14.599999999999959, 43.4, 101.60000000000001, 51.50000000000022, 30.80000000000002, -76.59999999999995, -269.8, -7.300000000000029, -3.9999999999998934, -17.79999999999974, 20.000000000000014, 23.60000000000008, 37.100000000000094, -116.50000000000011, 20.000000000000014, 32.30000000000023, 20.000000000000014, 7.399999999999965, 42.2, -55.600000000000016, -23.49999999999993, 20.30000000000007, -21.999999999999744, -16.299999999999997, -9.399999999999855, -85.00000000000085, 9.499999999999972, 31.09999999999998, 20.000000000000014, 120.7999999999995, 20.000000000000014, -64.00000000000091, -129.1000000000006, 166.70000000000002, 141.2, -164.8000000000001, 172.6999999999999, 138.79999999999998, -115.60000000000068, 60.20000000000008, -54.9999999999999, -184.6, 4.999999999999979, -39.39999999999996, 0.4999999999999716, 26.000000000000128, -190.90000000000018, 125.29999999999978, -70.30000000000067, 20.000000000000014, 24.50000000000009, 186.49999999999997, -211.00000000000017, 20.000000000000014, 1.0999999999999794, -168.40000000000023, 20.000000000000014, -21.099999999999802, -33.10000000000004, 126.19999999999999, 59.90000000000021, 20.000000000000014, 97.40000000000003, -152.8000000000002, 95.59999999999998, -152.20000000000056, -36.70000000000003, -34.599999999999866, 20.000000000000014, 21.800000000000004, 67.4, 145.09999999999988, -127.90000000000006, -88.90000000000069, -94.89999999999998, 70.99999999999999, 20.000000000000014, 104.59999999999944, -68.50000000000003, 9.499999999999947, -126.10000000000008, 10.699999999999974, 71.30000000000013, -314.7999999999998, -221.20000000000024, -215.20000000000013, 104.59999999999948, 109.09999999999965, -5.50000000000027, 74.2999999999999, 27.499999999999993, 41.300000000000075, -166.90000000000015, 119.0, 42.199999999999875, 194.59999999999997, 87.49999999999997, 20.000000000000014, -261.40000000000003, 70.09999999999988, -253.0, 22.700000000000063, 9.79999999999999, -131.5000000000004, -230.79999999999998, 38.60000000000001, -181.0, 20.000000000000014, 29.000000000000163, -257.2000000000003, -76.90000000000055, 162.19999999999993, -322.8, -156.4, 98.30000000000001, 20.000000000000014, -97.6, -50.50000000000003, 20.000000000000014, -118.60000000000036, 83.60000000000002, 35.9000000000002, -50.8, 59.000000000000036, 90.20000000000007, 155.29999999999995, 181.1, 24.500000000000068, 58.99999999999997, 20.000000000000014, 20.000000000000014, -33.70000000000003, -47.8, -28.29999999999975, 94.1, -45.09999999999976, 143.29999999999978, 83.59999999999997, 186.49999999999991, 20.000000000000014], "policy_predator_policy_reward": [0.0, 18.0, 0.0, 38.0, 27.0, 0.0, 13.0, 0.0, 0.0, 46.0, 16.0, 138.0, 8.0, 49.0, 0.0, 0.0, 65.0, 0.0, 0.0, 7.0, 6.0, 0.0, 43.0, 0.0, 29.0, 37.0, 0.0, 63.0, 50.0, 2.0, 0.0, 28.0, 0.0, 0.0, 0.0, 40.0, 71.0, 1.0, 97.0, 10.0, 3.0, 4.0, 13.0, 68.0, 52.0, 135.0, 8.0, 45.0, 54.0, 8.0, 106.0, 2.0, 0.0, 43.0, 3.0, 0.0, 0.0, 110.0, 75.0, 48.0, 30.0, 6.0, 3.0, 82.0, 1.0, 1.0, 5.0, 123.0, 82.0, 7.0, 0.0, 51.0, 6.0, 0.0, 0.0, 42.0, 62.0, 51.0, 10.0, 56.0, 0.0, 0.0, 93.0, 0.0, 114.0, 0.0, 154.0, 65.0, 165.0, 143.0, 0.0, 6.0, 22.0, 52.0, 34.0, 35.0, 0.0, 125.0, 43.0, 0.0, 0.0, 0.0, 166.0, 17.0, 38.0, 130.0, 49.0, 44.0, 131.0, 59.0, 34.0, 105.0, 73.0, 71.0, 5.0, 62.0, 0.0, 186.0, 0.0, 30.0, 0.0, 118.0, 3.0, 87.0, 13.0, 31.0, 26.0, 64.0, 0.0, 2.0, 3.0, 0.0, 8.0, 0.0, 41.0, 0.0, 46.0, 49.0, 57.0, 0.0, 0.0, 4.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7679545795033051, "mean_inference_ms": 1.798425905074305, "mean_action_processing_ms": 0.30952824591256023, "mean_env_wait_ms": 0.23752901864619258, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006920927100711399, "StateBufferConnector_ms": 0.0033918354246351454, "ViewRequirementAgentConnector_ms": 0.16552060842514038}, "num_episodes": 18, "episode_return_max": 318.5000000000001, "episode_return_min": -293.20000000000016, "episode_return_mean": 59.12222222222211, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 64000, "num_agent_steps_trained": 64000, "num_env_steps_sampled": 16000, "num_env_steps_trained": 16000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 76.20525136221777, "num_env_steps_trained_throughput_per_sec": 76.20525136221777, "timesteps_total": 16000, "num_env_steps_sampled_lifetime": 16000, "num_agent_steps_sampled_lifetime": 64000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 64000, "timers": {"training_iteration_time_ms": 53784.655, "restore_workers_time_ms": 0.024, "training_step_time_ms": 53784.589, "sample_time_ms": 1387.909, "learn_time_ms": 52381.651, "learn_throughput": 76.363, "synch_weights_time_ms": 11.162}, "counters": {"num_env_steps_sampled": 16000, "num_env_steps_trained": 16000, "num_agent_steps_sampled": 64000, "num_agent_steps_trained": 64000}, "done": false, "training_iteration": 4, "trial_id": "11e70_00000", "date": "2024-08-12_23-10-34", "timestamp": 1723518634, "time_this_iter_s": 52.53674006462097, "time_total_s": 215.2809762954712, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2b624c0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 215.2809762954712, "iterations_since_restore": 4, "perf": {"cpu_util_percent": 41.21621621621621, "ram_util_percent": 82.60000000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5196869665668125, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.7282437190807687, "policy_loss": -0.011309246233388505, "vf_loss": 2.7370657400479392, "vf_explained_var": 0.01582812089768667, "kl": 0.008290768203768934, "entropy": 1.5778723713582155, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 8505.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.281099994409652, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.749038871886238, "policy_loss": -0.010468807142282092, "vf_loss": 6.75806615718458, "vf_explained_var": 0.059277668548008755, "kl": 0.009610212243947256, "entropy": 1.55540513147122, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 8505.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 20000, "num_env_steps_trained": 20000, "num_agent_steps_sampled": 80000, "num_agent_steps_trained": 80000}, "env_runners": {"episode_reward_max": 337.0, "episode_reward_min": -293.20000000000016, "episode_reward_mean": 73.4222222222221, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 19800, "policy_reward_min": {"prey_policy": -322.8, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 199.0}, "policy_reward_mean": {"prey_policy": 3.6555555555555186, "predator_policy": 33.05555555555556}, "custom_metrics": {}, "hist_stats": {"episode_reward": [205.2999999999997, 26.10000000000045, 85.00000000000006, 166.09999999999897, 0.20000000000001794, -123.10000000000036, 35.20000000000038, 43.600000000000364, -14.399999999999972, 59.30000000000049, 33.400000000000205, 29.59999999999996, 62.80000000000026, 24.700000000000287, -42.400000000000176, 68.59999999999997, 140.79999999999876, -3.9999999999997313, 109.59999999999982, 83.40000000000006, 318.5000000000001, 25.600000000000193, -52.59999999999982, 18.600000000000044, 88.49999999999997, 42.39999999999997, -7.299999999999805, 213.9999999999992, -81.00000000000009, -44.299999999999876, 34.9000000000001, 178.09999999999997, 81.89999999999962, 72.60000000000001, 32.400000000000226, -20.300000000000054, 47.80000000000027, 254.4999999999999, -103.80000000000103, 42.10000000000008, 124.59999999999874, 34.0000000000002, -1.3999999999999861, -24.4999999999999, -128.40000000000043, 219.69999999999908, 142.79999999999984, 137.79999999999987, 77.09999999999997, 279.79999999999995, 107.49999999999991, -8.299999999999953, -62.30000000000004, -28.699999999999847, -2.2000000000000064, -21.999999999999854, -84.19999999999987, 152.29999999999944, -293.20000000000016, 148.29999999999964, -30.099999999999888, -8.599999999999842, 163.4999999999995, 98.19999999999993, 247.4999999999996, 208.59999999999943, 87.00000000000006, 27.300000000000253, 18.90000000000007, 105.9999999999996, 230.89999999999938, 206.49999999999918, 60.4000000000002, 74.20000000000019, 190.5, 119.49999999999974, 47.20000000000017, 157.1, 67.39999999999984, 325.69999999999993, 80.00000000000006, 42.000000000000014, 128.39999999999972, 56.20000000000046, 42.700000000000294, 35.600000000000236, 86.20000000000007, 157.99999999999926, 185.6999999999994, -41.49999999999997, 126.59999999999978, 258.7999999999997, 192.19999999999928, 332.0, -237.9000000000012, -33.599999999999866, 51.700000000000095, 337.0, 169.8999999999989], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [117.49999999999974, 69.80000000000004, 47.90000000000024, -59.79999999999996, 14.599999999999959, 43.4, 101.60000000000001, 51.50000000000022, 30.80000000000002, -76.59999999999995, -269.8, -7.300000000000029, -3.9999999999998934, -17.79999999999974, 20.000000000000014, 23.60000000000008, 37.100000000000094, -116.50000000000011, 20.000000000000014, 32.30000000000023, 20.000000000000014, 7.399999999999965, 42.2, -55.600000000000016, -23.49999999999993, 20.30000000000007, -21.999999999999744, -16.299999999999997, -9.399999999999855, -85.00000000000085, 9.499999999999972, 31.09999999999998, 20.000000000000014, 120.7999999999995, 20.000000000000014, -64.00000000000091, -129.1000000000006, 166.70000000000002, 141.2, -164.8000000000001, 172.6999999999999, 138.79999999999998, -115.60000000000068, 60.20000000000008, -54.9999999999999, -184.6, 4.999999999999979, -39.39999999999996, 0.4999999999999716, 26.000000000000128, -190.90000000000018, 125.29999999999978, -70.30000000000067, 20.000000000000014, 24.50000000000009, 186.49999999999997, -211.00000000000017, 20.000000000000014, 1.0999999999999794, -168.40000000000023, 20.000000000000014, -21.099999999999802, -33.10000000000004, 126.19999999999999, 59.90000000000021, 20.000000000000014, 97.40000000000003, -152.8000000000002, 95.59999999999998, -152.20000000000056, -36.70000000000003, -34.599999999999866, 20.000000000000014, 21.800000000000004, 67.4, 145.09999999999988, -127.90000000000006, -88.90000000000069, -94.89999999999998, 70.99999999999999, 20.000000000000014, 104.59999999999944, -68.50000000000003, 9.499999999999947, -126.10000000000008, 10.699999999999974, 71.30000000000013, -314.7999999999998, -221.20000000000024, -215.20000000000013, 104.59999999999948, 109.09999999999965, -5.50000000000027, 74.2999999999999, 27.499999999999993, 41.300000000000075, -166.90000000000015, 119.0, 42.199999999999875, 194.59999999999997, 87.49999999999997, 20.000000000000014, -261.40000000000003, 70.09999999999988, -253.0, 22.700000000000063, 9.79999999999999, -131.5000000000004, -230.79999999999998, 38.60000000000001, -181.0, 20.000000000000014, 29.000000000000163, -257.2000000000003, -76.90000000000055, 162.19999999999993, -322.8, -156.4, 98.30000000000001, 20.000000000000014, -97.6, -50.50000000000003, 20.000000000000014, -118.60000000000036, 83.60000000000002, 35.9000000000002, -50.8, 59.000000000000036, 90.20000000000007, 155.29999999999995, 181.1, 24.500000000000068, 58.99999999999997, 20.000000000000014, 20.000000000000014, -33.70000000000003, -47.8, -28.29999999999975, 94.1, -45.09999999999976, 143.29999999999978, 83.59999999999997, 186.49999999999991, 20.000000000000014, -37.599999999999994, 20.000000000000014, 20.000000000000014, 54.199999999999974, 186.5, -97.0, 120.49999999999999, -21.999999999999808, 49.70000000000006, -74.50000000000045, 109.1, -28.0, -50.79999999999998, 24.20000000000011, 118.1, 182.6, 7.999999999999972, -7.0, 13.99999999999999, -85.0, 108.8, -30.399999999999757, 20.000000000000014, 36.20000000000022, 22.700000000000063, 20.000000000000014, 11.599999999999964, 20.000000000000014, 25.39999999999999, -5.19999999999993, 44.0, 65.00000000000014, 30.799999999999997, 140.89999999999998, -146.8, -36.69999999999977, 110.90000000000003, -28.299999999999777, 157.4, 88.39999999999966, 165.5, 13.699999999999946, 170.9, 160.1, -251.09999999999957, -185.80000000000052, -68.20000000000006, -60.39999999999998, 134.0, -175.30000000000038, 137.0, 200.0, 111.80000000000013, 55.10000000000021], "policy_predator_policy_reward": [0.0, 18.0, 0.0, 38.0, 27.0, 0.0, 13.0, 0.0, 0.0, 46.0, 16.0, 138.0, 8.0, 49.0, 0.0, 0.0, 65.0, 0.0, 0.0, 7.0, 6.0, 0.0, 43.0, 0.0, 29.0, 37.0, 0.0, 63.0, 50.0, 2.0, 0.0, 28.0, 0.0, 0.0, 0.0, 40.0, 71.0, 1.0, 97.0, 10.0, 3.0, 4.0, 13.0, 68.0, 52.0, 135.0, 8.0, 45.0, 54.0, 8.0, 106.0, 2.0, 0.0, 43.0, 3.0, 0.0, 0.0, 110.0, 75.0, 48.0, 30.0, 6.0, 3.0, 82.0, 1.0, 1.0, 5.0, 123.0, 82.0, 7.0, 0.0, 51.0, 6.0, 0.0, 0.0, 42.0, 62.0, 51.0, 10.0, 56.0, 0.0, 0.0, 93.0, 0.0, 114.0, 0.0, 154.0, 65.0, 165.0, 143.0, 0.0, 6.0, 22.0, 52.0, 34.0, 35.0, 0.0, 125.0, 43.0, 0.0, 0.0, 0.0, 166.0, 17.0, 38.0, 130.0, 49.0, 44.0, 131.0, 59.0, 34.0, 105.0, 73.0, 71.0, 5.0, 62.0, 0.0, 186.0, 0.0, 30.0, 0.0, 118.0, 3.0, 87.0, 13.0, 31.0, 26.0, 64.0, 0.0, 2.0, 3.0, 0.0, 8.0, 0.0, 41.0, 0.0, 46.0, 49.0, 57.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 78.0, 0.0, 0.0, 98.0, 3.0, 0.0, 21.0, 72.0, 0.0, 0.0, 76.0, 21.0, 73.0, 25.0, 0.0, 79.0, 0.0, 89.0, 24.0, 0.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 12.0, 54.0, 49.0, 0.0, 14.0, 0.0, 97.0, 45.0, 12.0, 32.0, 0.0, 13.0, 3.0, 10.0, 1.0, 0.0, 0.0, 199.0, 59.0, 36.0, 93.0, 0.0, 0.0, 0.0, 3.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7612660845441268, "mean_inference_ms": 1.786010938316093, "mean_action_processing_ms": 0.30673965185444185, "mean_env_wait_ms": 0.23565575810169828, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007270442114935981, "StateBufferConnector_ms": 0.003792541195647885, "ViewRequirementAgentConnector_ms": 0.16087125046084624}, "num_episodes": 27, "episode_return_max": 337.0, "episode_return_min": -293.20000000000016, "episode_return_mean": 73.4222222222221, "episodes_this_iter": 27}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 80000, "num_agent_steps_trained": 80000, "num_env_steps_sampled": 20000, "num_env_steps_trained": 20000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 74.47658003401862, "num_env_steps_trained_throughput_per_sec": 74.47658003401862, "timesteps_total": 20000, "num_env_steps_sampled_lifetime": 20000, "num_agent_steps_sampled_lifetime": 80000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 80000, "timers": {"training_iteration_time_ms": 53769.357, "restore_workers_time_ms": 0.022, "training_step_time_ms": 53769.297, "sample_time_ms": 1442.731, "learn_time_ms": 52312.313, "learn_throughput": 76.464, "synch_weights_time_ms": 10.905}, "counters": {"num_env_steps_sampled": 20000, "num_env_steps_trained": 20000, "num_agent_steps_sampled": 80000, "num_agent_steps_trained": 80000}, "done": false, "training_iteration": 5, "trial_id": "11e70_00000", "date": "2024-08-12_23-11-28", "timestamp": 1723518688, "time_this_iter_s": 53.721609354019165, "time_total_s": 269.00258564949036, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2b61700>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 269.00258564949036, "iterations_since_restore": 5, "perf": {"cpu_util_percent": 43.38181818181818, "ram_util_percent": 82.63766233766232}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.848484000989369, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.543545341743994, "policy_loss": -0.010705803956087463, "vf_loss": 4.55188996577389, "vf_explained_var": 0.02173439008849008, "kl": 0.007870589324116143, "entropy": 1.5810490974042781, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 10395.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.7223818762907905, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.850488162671448, "policy_loss": -0.0112663999297188, "vf_loss": 8.859814155921734, "vf_explained_var": 0.08336956595617627, "kl": 0.012936210028642776, "entropy": 1.535103233844515, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 10395.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 24000, "num_env_steps_trained": 24000, "num_agent_steps_sampled": 96000, "num_agent_steps_trained": 96000}, "env_runners": {"episode_reward_max": 343.5, "episode_reward_min": -293.20000000000016, "episode_reward_mean": 89.01199999999989, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -322.8, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 199.0}, "policy_reward_mean": {"prey_policy": 7.5959999999999575, "predator_policy": 36.91}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-3.9999999999997313, 109.59999999999982, 83.40000000000006, 318.5000000000001, 25.600000000000193, -52.59999999999982, 18.600000000000044, 88.49999999999997, 42.39999999999997, -7.299999999999805, 213.9999999999992, -81.00000000000009, -44.299999999999876, 34.9000000000001, 178.09999999999997, 81.89999999999962, 72.60000000000001, 32.400000000000226, -20.300000000000054, 47.80000000000027, 254.4999999999999, -103.80000000000103, 42.10000000000008, 124.59999999999874, 34.0000000000002, -1.3999999999999861, -24.4999999999999, -128.40000000000043, 219.69999999999908, 142.79999999999984, 137.79999999999987, 77.09999999999997, 279.79999999999995, 107.49999999999991, -8.299999999999953, -62.30000000000004, -28.699999999999847, -2.2000000000000064, -21.999999999999854, -84.19999999999987, 152.29999999999944, -293.20000000000016, 148.29999999999964, -30.099999999999888, -8.599999999999842, 163.4999999999995, 98.19999999999993, 247.4999999999996, 208.59999999999943, 87.00000000000006, 27.300000000000253, 18.90000000000007, 105.9999999999996, 230.89999999999938, 206.49999999999918, 60.4000000000002, 74.20000000000019, 190.5, 119.49999999999974, 47.20000000000017, 157.1, 67.39999999999984, 325.69999999999993, 80.00000000000006, 42.000000000000014, 128.39999999999972, 56.20000000000046, 42.700000000000294, 35.600000000000236, 86.20000000000007, 157.99999999999926, 185.6999999999994, -41.49999999999997, 126.59999999999978, 258.7999999999997, 192.19999999999928, 332.0, -237.9000000000012, -33.599999999999866, 51.700000000000095, 337.0, 169.8999999999989, 97.40000000000003, 202.9, 269.20000000000005, 316.6, -137.7000000000002, 100.69999999999987, 141.99999999999963, 120.00000000000003, -69.0, 343.5, 303.19999999999993, 83.20000000000019, 137.3, 52.30000000000018, -192.3000000000005, 303.5999999999999, 211.8999999999993, 148.4], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, -64.00000000000091, -129.1000000000006, 166.70000000000002, 141.2, -164.8000000000001, 172.6999999999999, 138.79999999999998, -115.60000000000068, 60.20000000000008, -54.9999999999999, -184.6, 4.999999999999979, -39.39999999999996, 0.4999999999999716, 26.000000000000128, -190.90000000000018, 125.29999999999978, -70.30000000000067, 20.000000000000014, 24.50000000000009, 186.49999999999997, -211.00000000000017, 20.000000000000014, 1.0999999999999794, -168.40000000000023, 20.000000000000014, -21.099999999999802, -33.10000000000004, 126.19999999999999, 59.90000000000021, 20.000000000000014, 97.40000000000003, -152.8000000000002, 95.59999999999998, -152.20000000000056, -36.70000000000003, -34.599999999999866, 20.000000000000014, 21.800000000000004, 67.4, 145.09999999999988, -127.90000000000006, -88.90000000000069, -94.89999999999998, 70.99999999999999, 20.000000000000014, 104.59999999999944, -68.50000000000003, 9.499999999999947, -126.10000000000008, 10.699999999999974, 71.30000000000013, -314.7999999999998, -221.20000000000024, -215.20000000000013, 104.59999999999948, 109.09999999999965, -5.50000000000027, 74.2999999999999, 27.499999999999993, 41.300000000000075, -166.90000000000015, 119.0, 42.199999999999875, 194.59999999999997, 87.49999999999997, 20.000000000000014, -261.40000000000003, 70.09999999999988, -253.0, 22.700000000000063, 9.79999999999999, -131.5000000000004, -230.79999999999998, 38.60000000000001, -181.0, 20.000000000000014, 29.000000000000163, -257.2000000000003, -76.90000000000055, 162.19999999999993, -322.8, -156.4, 98.30000000000001, 20.000000000000014, -97.6, -50.50000000000003, 20.000000000000014, -118.60000000000036, 83.60000000000002, 35.9000000000002, -50.8, 59.000000000000036, 90.20000000000007, 155.29999999999995, 181.1, 24.500000000000068, 58.99999999999997, 20.000000000000014, 20.000000000000014, -33.70000000000003, -47.8, -28.29999999999975, 94.1, -45.09999999999976, 143.29999999999978, 83.59999999999997, 186.49999999999991, 20.000000000000014, -37.599999999999994, 20.000000000000014, 20.000000000000014, 54.199999999999974, 186.5, -97.0, 120.49999999999999, -21.999999999999808, 49.70000000000006, -74.50000000000045, 109.1, -28.0, -50.79999999999998, 24.20000000000011, 118.1, 182.6, 7.999999999999972, -7.0, 13.99999999999999, -85.0, 108.8, -30.399999999999757, 20.000000000000014, 36.20000000000022, 22.700000000000063, 20.000000000000014, 11.599999999999964, 20.000000000000014, 25.39999999999999, -5.19999999999993, 44.0, 65.00000000000014, 30.799999999999997, 140.89999999999998, -146.8, -36.69999999999977, 110.90000000000003, -28.299999999999777, 157.4, 88.39999999999966, 165.5, 13.699999999999946, 170.9, 160.1, -251.09999999999957, -185.80000000000052, -68.20000000000006, -60.39999999999998, 134.0, -175.30000000000038, 137.0, 200.0, 111.80000000000013, 55.10000000000021, 29.0, -55.60000000000008, 71.6, 62.3, 158.6, 77.60000000000002, 158.0, 134.6, -204.70000000000016, -157.0, -183.70000000000053, 187.39999999999995, 38.900000000000254, 73.1, -45.10000000000018, 70.10000000000002, -277.0, -31.0, 167.0, 159.5, 123.2, 154.99999999999994, 7.700000000000109, -5.5, -90.70000000000002, 116.0, 7.39999999999996, -21.099999999999994, -80.79999999999978, -284.50000000000034, 196.4, 84.20000000000005, 191.9, 20.000000000000014, 89.0, -28.599999999999994], "policy_predator_policy_reward": [0.0, 40.0, 71.0, 1.0, 97.0, 10.0, 3.0, 4.0, 13.0, 68.0, 52.0, 135.0, 8.0, 45.0, 54.0, 8.0, 106.0, 2.0, 0.0, 43.0, 3.0, 0.0, 0.0, 110.0, 75.0, 48.0, 30.0, 6.0, 3.0, 82.0, 1.0, 1.0, 5.0, 123.0, 82.0, 7.0, 0.0, 51.0, 6.0, 0.0, 0.0, 42.0, 62.0, 51.0, 10.0, 56.0, 0.0, 0.0, 93.0, 0.0, 114.0, 0.0, 154.0, 65.0, 165.0, 143.0, 0.0, 6.0, 22.0, 52.0, 34.0, 35.0, 0.0, 125.0, 43.0, 0.0, 0.0, 0.0, 166.0, 17.0, 38.0, 130.0, 49.0, 44.0, 131.0, 59.0, 34.0, 105.0, 73.0, 71.0, 5.0, 62.0, 0.0, 186.0, 0.0, 30.0, 0.0, 118.0, 3.0, 87.0, 13.0, 31.0, 26.0, 64.0, 0.0, 2.0, 3.0, 0.0, 8.0, 0.0, 41.0, 0.0, 46.0, 49.0, 57.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 78.0, 0.0, 0.0, 98.0, 3.0, 0.0, 21.0, 72.0, 0.0, 0.0, 76.0, 21.0, 73.0, 25.0, 0.0, 79.0, 0.0, 89.0, 24.0, 0.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 12.0, 54.0, 49.0, 0.0, 14.0, 0.0, 97.0, 45.0, 12.0, 32.0, 0.0, 13.0, 3.0, 10.0, 1.0, 0.0, 0.0, 199.0, 59.0, 36.0, 93.0, 0.0, 0.0, 0.0, 3.0, 0.0, 107.0, 17.0, 51.0, 18.0, 33.0, 0.0, 24.0, 0.0, 120.0, 104.0, 0.0, 97.0, 0.0, 30.0, 27.0, 68.0, 78.0, 161.0, 3.0, 14.0, 23.0, 2.0, 30.0, 51.0, 32.0, 80.0, 12.0, 54.0, 133.0, 40.0, 0.0, 23.0, 0.0, 0.0, 8.0, 80.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7483047643512932, "mean_inference_ms": 1.760985089414413, "mean_action_processing_ms": 0.3032172759833582, "mean_env_wait_ms": 0.23260142833920347, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006705760955810547, "StateBufferConnector_ms": 0.003782510757446289, "ViewRequirementAgentConnector_ms": 0.15968823432922363}, "num_episodes": 18, "episode_return_max": 343.5, "episode_return_min": -293.20000000000016, "episode_return_mean": 89.01199999999989, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 96000, "num_agent_steps_trained": 96000, "num_env_steps_sampled": 24000, "num_env_steps_trained": 24000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 76.44711553737112, "num_env_steps_trained_throughput_per_sec": 76.44711553737112, "timesteps_total": 24000, "num_env_steps_sampled_lifetime": 24000, "num_agent_steps_sampled_lifetime": 96000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 96000, "timers": {"training_iteration_time_ms": 53528.425, "restore_workers_time_ms": 0.02, "training_step_time_ms": 53528.368, "sample_time_ms": 1400.615, "learn_time_ms": 52113.942, "learn_throughput": 76.755, "synch_weights_time_ms": 10.788}, "counters": {"num_env_steps_sampled": 24000, "num_env_steps_trained": 24000, "num_agent_steps_sampled": 96000, "num_agent_steps_trained": 96000}, "done": false, "training_iteration": 6, "trial_id": "11e70_00000", "date": "2024-08-12_23-12-20", "timestamp": 1723518740, "time_this_iter_s": 52.37441110610962, "time_total_s": 321.3769967556, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2b619d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 321.3769967556, "iterations_since_restore": 6, "perf": {"cpu_util_percent": 44.85945945945946, "ram_util_percent": 82.4108108108108}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.9381276550747097, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.1316053191190045, "policy_loss": -0.01406508788901317, "vf_loss": 6.142548459673685, "vf_explained_var": 0.024082523205923655, "kl": 0.01040647447655603, "entropy": 1.5570437653985605, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 12285.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.62289956770246, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.231916338552242, "policy_loss": -0.013467126501423538, "vf_loss": 8.243339987911245, "vf_explained_var": 0.03490723891863747, "kl": 0.013623056649393455, "entropy": 1.528271795328332, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 12285.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 28000, "num_env_steps_trained": 28000, "num_agent_steps_sampled": 112000, "num_agent_steps_trained": 112000}, "env_runners": {"episode_reward_max": 357.7000000000001, "episode_reward_min": -293.20000000000016, "episode_reward_mean": 85.73199999999989, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -368.30000000000007, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 242.0}, "policy_reward_mean": {"prey_policy": 1.6959999999999786, "predator_policy": 41.17}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.300000000000054, 47.80000000000027, 254.4999999999999, -103.80000000000103, 42.10000000000008, 124.59999999999874, 34.0000000000002, -1.3999999999999861, -24.4999999999999, -128.40000000000043, 219.69999999999908, 142.79999999999984, 137.79999999999987, 77.09999999999997, 279.79999999999995, 107.49999999999991, -8.299999999999953, -62.30000000000004, -28.699999999999847, -2.2000000000000064, -21.999999999999854, -84.19999999999987, 152.29999999999944, -293.20000000000016, 148.29999999999964, -30.099999999999888, -8.599999999999842, 163.4999999999995, 98.19999999999993, 247.4999999999996, 208.59999999999943, 87.00000000000006, 27.300000000000253, 18.90000000000007, 105.9999999999996, 230.89999999999938, 206.49999999999918, 60.4000000000002, 74.20000000000019, 190.5, 119.49999999999974, 47.20000000000017, 157.1, 67.39999999999984, 325.69999999999993, 80.00000000000006, 42.000000000000014, 128.39999999999972, 56.20000000000046, 42.700000000000294, 35.600000000000236, 86.20000000000007, 157.99999999999926, 185.6999999999994, -41.49999999999997, 126.59999999999978, 258.7999999999997, 192.19999999999928, 332.0, -237.9000000000012, -33.599999999999866, 51.700000000000095, 337.0, 169.8999999999989, 97.40000000000003, 202.9, 269.20000000000005, 316.6, -137.7000000000002, 100.69999999999987, 141.99999999999963, 120.00000000000003, -69.0, 343.5, 303.19999999999993, 83.20000000000019, 137.3, 52.30000000000018, -192.3000000000005, 303.5999999999999, 211.8999999999993, 148.4, -6.199999999999996, 10.299999999999946, 63.89999999999998, 142.7, 24.700000000000045, -155.1, -171.00000000000009, -30.299999999999876, 2.500000000000046, -142.60000000000008, 129.4, 135.10000000000008, 357.7000000000001, 251.8, -85.89999999999998, 157.4, 84.1999999999993, 14.70000000000017], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-36.70000000000003, -34.599999999999866, 20.000000000000014, 21.800000000000004, 67.4, 145.09999999999988, -127.90000000000006, -88.90000000000069, -94.89999999999998, 70.99999999999999, 20.000000000000014, 104.59999999999944, -68.50000000000003, 9.499999999999947, -126.10000000000008, 10.699999999999974, 71.30000000000013, -314.7999999999998, -221.20000000000024, -215.20000000000013, 104.59999999999948, 109.09999999999965, -5.50000000000027, 74.2999999999999, 27.499999999999993, 41.300000000000075, -166.90000000000015, 119.0, 42.199999999999875, 194.59999999999997, 87.49999999999997, 20.000000000000014, -261.40000000000003, 70.09999999999988, -253.0, 22.700000000000063, 9.79999999999999, -131.5000000000004, -230.79999999999998, 38.60000000000001, -181.0, 20.000000000000014, 29.000000000000163, -257.2000000000003, -76.90000000000055, 162.19999999999993, -322.8, -156.4, 98.30000000000001, 20.000000000000014, -97.6, -50.50000000000003, 20.000000000000014, -118.60000000000036, 83.60000000000002, 35.9000000000002, -50.8, 59.000000000000036, 90.20000000000007, 155.29999999999995, 181.1, 24.500000000000068, 58.99999999999997, 20.000000000000014, 20.000000000000014, -33.70000000000003, -47.8, -28.29999999999975, 94.1, -45.09999999999976, 143.29999999999978, 83.59999999999997, 186.49999999999991, 20.000000000000014, -37.599999999999994, 20.000000000000014, 20.000000000000014, 54.199999999999974, 186.5, -97.0, 120.49999999999999, -21.999999999999808, 49.70000000000006, -74.50000000000045, 109.1, -28.0, -50.79999999999998, 24.20000000000011, 118.1, 182.6, 7.999999999999972, -7.0, 13.99999999999999, -85.0, 108.8, -30.399999999999757, 20.000000000000014, 36.20000000000022, 22.700000000000063, 20.000000000000014, 11.599999999999964, 20.000000000000014, 25.39999999999999, -5.19999999999993, 44.0, 65.00000000000014, 30.799999999999997, 140.89999999999998, -146.8, -36.69999999999977, 110.90000000000003, -28.299999999999777, 157.4, 88.39999999999966, 165.5, 13.699999999999946, 170.9, 160.1, -251.09999999999957, -185.80000000000052, -68.20000000000006, -60.39999999999998, 134.0, -175.30000000000038, 137.0, 200.0, 111.80000000000013, 55.10000000000021, 29.0, -55.60000000000008, 71.6, 62.3, 158.6, 77.60000000000002, 158.0, 134.6, -204.70000000000016, -157.0, -183.70000000000053, 187.39999999999995, 38.900000000000254, 73.1, -45.10000000000018, 70.10000000000002, -277.0, -31.0, 167.0, 159.5, 123.2, 154.99999999999994, 7.700000000000109, -5.5, -90.70000000000002, 116.0, 7.39999999999996, -21.099999999999994, -80.79999999999978, -284.50000000000034, 196.4, 84.20000000000005, 191.9, 20.000000000000014, 89.0, -28.599999999999994, -85.6, -148.6, 20.000000000000014, -36.699999999999754, -18.400000000000006, -24.7, 37.099999999999994, 20.599999999999994, -55.89999999999997, -27.40000000000005, -290.8, -142.3, -368.30000000000007, -147.7, -126.69999999999999, -34.599999999999994, -72.10000000000005, -15.400000000000006, -157.60000000000008, -133.0, 8.0, 52.4, 47.3, 18.79999999999997, 198.2, 141.49999999999997, 27.20000000000001, 182.6, -239.50000000000003, -111.39999999999999, -25.599999999999994, 92.0, 0.20000000000000284, 20.000000000000014, -28.300000000000033, 20.000000000000014], "policy_predator_policy_reward": [0.0, 51.0, 6.0, 0.0, 0.0, 42.0, 62.0, 51.0, 10.0, 56.0, 0.0, 0.0, 93.0, 0.0, 114.0, 0.0, 154.0, 65.0, 165.0, 143.0, 0.0, 6.0, 22.0, 52.0, 34.0, 35.0, 0.0, 125.0, 43.0, 0.0, 0.0, 0.0, 166.0, 17.0, 38.0, 130.0, 49.0, 44.0, 131.0, 59.0, 34.0, 105.0, 73.0, 71.0, 5.0, 62.0, 0.0, 186.0, 0.0, 30.0, 0.0, 118.0, 3.0, 87.0, 13.0, 31.0, 26.0, 64.0, 0.0, 2.0, 3.0, 0.0, 8.0, 0.0, 41.0, 0.0, 46.0, 49.0, 57.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 78.0, 0.0, 0.0, 98.0, 3.0, 0.0, 21.0, 72.0, 0.0, 0.0, 76.0, 21.0, 73.0, 25.0, 0.0, 79.0, 0.0, 89.0, 24.0, 0.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 12.0, 54.0, 49.0, 0.0, 14.0, 0.0, 97.0, 45.0, 12.0, 32.0, 0.0, 13.0, 3.0, 10.0, 1.0, 0.0, 0.0, 199.0, 59.0, 36.0, 93.0, 0.0, 0.0, 0.0, 3.0, 0.0, 107.0, 17.0, 51.0, 18.0, 33.0, 0.0, 24.0, 0.0, 120.0, 104.0, 0.0, 97.0, 0.0, 30.0, 27.0, 68.0, 78.0, 161.0, 3.0, 14.0, 23.0, 2.0, 30.0, 51.0, 32.0, 80.0, 12.0, 54.0, 133.0, 40.0, 0.0, 23.0, 0.0, 0.0, 8.0, 80.0, 89.0, 139.0, 27.0, 0.0, 91.0, 16.0, 7.0, 78.0, 9.0, 99.0, 175.0, 103.0, 242.0, 103.0, 58.0, 73.0, 25.0, 65.0, 27.0, 121.0, 34.0, 35.0, 0.0, 69.0, 0.0, 18.0, 17.0, 25.0, 138.0, 127.0, 73.0, 18.0, 41.0, 23.0, 12.0, 11.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7341914744736425, "mean_inference_ms": 1.721192946958997, "mean_action_processing_ms": 0.2963483790318077, "mean_env_wait_ms": 0.22815037244327221, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006753444671630859, "StateBufferConnector_ms": 0.00510561466217041, "ViewRequirementAgentConnector_ms": 0.15724647045135498}, "num_episodes": 18, "episode_return_max": 357.7000000000001, "episode_return_min": -293.20000000000016, "episode_return_mean": 85.73199999999989, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 112000, "num_agent_steps_trained": 112000, "num_env_steps_sampled": 28000, "num_env_steps_trained": 28000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 78.23937492352266, "num_env_steps_trained_throughput_per_sec": 78.23937492352266, "timesteps_total": 28000, "num_env_steps_sampled_lifetime": 28000, "num_agent_steps_sampled_lifetime": 112000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 112000, "timers": {"training_iteration_time_ms": 53185.101, "restore_workers_time_ms": 0.02, "training_step_time_ms": 53185.048, "sample_time_ms": 1397.857, "learn_time_ms": 51773.567, "learn_throughput": 77.26, "synch_weights_time_ms": 10.835}, "counters": {"num_env_steps_sampled": 28000, "num_env_steps_trained": 28000, "num_agent_steps_sampled": 112000, "num_agent_steps_trained": 112000}, "done": false, "training_iteration": 7, "trial_id": "11e70_00000", "date": "2024-08-12_23-13-11", "timestamp": 1723518791, "time_this_iter_s": 51.15910506248474, "time_total_s": 372.5361018180847, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2ad7280>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 372.5361018180847, "iterations_since_restore": 7, "perf": {"cpu_util_percent": 37.24109589041096, "ram_util_percent": 83.35068493150685}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.558110775644817, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.672740006068397, "policy_loss": -0.015220923131706301, "vf_loss": 6.684874479858964, "vf_explained_var": 0.04528013269106547, "kl": 0.010288141892846922, "entropy": 1.5522357087917429, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 14175.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.231568965142366, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.900073229320466, "policy_loss": -0.011422610729218277, "vf_loss": 8.909750633391123, "vf_explained_var": 0.027259028084063656, "kl": 0.011634602690815685, "entropy": 1.5264101664855998, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 14175.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 32000, "num_env_steps_trained": 32000, "num_agent_steps_sampled": 128000, "num_agent_steps_trained": 128000}, "env_runners": {"episode_reward_max": 357.7000000000001, "episode_reward_min": -293.20000000000016, "episode_reward_mean": 87.3919999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -368.30000000000007, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 242.0}, "policy_reward_mean": {"prey_policy": 0.39099999999999, "predator_policy": 43.305}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-28.699999999999847, -2.2000000000000064, -21.999999999999854, -84.19999999999987, 152.29999999999944, -293.20000000000016, 148.29999999999964, -30.099999999999888, -8.599999999999842, 163.4999999999995, 98.19999999999993, 247.4999999999996, 208.59999999999943, 87.00000000000006, 27.300000000000253, 18.90000000000007, 105.9999999999996, 230.89999999999938, 206.49999999999918, 60.4000000000002, 74.20000000000019, 190.5, 119.49999999999974, 47.20000000000017, 157.1, 67.39999999999984, 325.69999999999993, 80.00000000000006, 42.000000000000014, 128.39999999999972, 56.20000000000046, 42.700000000000294, 35.600000000000236, 86.20000000000007, 157.99999999999926, 185.6999999999994, -41.49999999999997, 126.59999999999978, 258.7999999999997, 192.19999999999928, 332.0, -237.9000000000012, -33.599999999999866, 51.700000000000095, 337.0, 169.8999999999989, 97.40000000000003, 202.9, 269.20000000000005, 316.6, -137.7000000000002, 100.69999999999987, 141.99999999999963, 120.00000000000003, -69.0, 343.5, 303.19999999999993, 83.20000000000019, 137.3, 52.30000000000018, -192.3000000000005, 303.5999999999999, 211.8999999999993, 148.4, -6.199999999999996, 10.299999999999946, 63.89999999999998, 142.7, 24.700000000000045, -155.1, -171.00000000000009, -30.299999999999876, 2.500000000000046, -142.60000000000008, 129.4, 135.10000000000008, 357.7000000000001, 251.8, -85.89999999999998, 157.4, 84.1999999999993, 14.70000000000017, 72.90000000000006, 47.8000000000001, 206.69999999999996, 92.49999999999986, 250.79999999999995, 2.700000000000003, -29.6, 160.60000000000008, -6.499999999999989, 42.39999999999999, 89.99999999999997, -149.7, 135.89999999999998, -51.8, 41.30000000000002, 298.4000000000001, 48.30000000000003, 31.999999999999588], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [9.79999999999999, -131.5000000000004, -230.79999999999998, 38.60000000000001, -181.0, 20.000000000000014, 29.000000000000163, -257.2000000000003, -76.90000000000055, 162.19999999999993, -322.8, -156.4, 98.30000000000001, 20.000000000000014, -97.6, -50.50000000000003, 20.000000000000014, -118.60000000000036, 83.60000000000002, 35.9000000000002, -50.8, 59.000000000000036, 90.20000000000007, 155.29999999999995, 181.1, 24.500000000000068, 58.99999999999997, 20.000000000000014, 20.000000000000014, -33.70000000000003, -47.8, -28.29999999999975, 94.1, -45.09999999999976, 143.29999999999978, 83.59999999999997, 186.49999999999991, 20.000000000000014, -37.599999999999994, 20.000000000000014, 20.000000000000014, 54.199999999999974, 186.5, -97.0, 120.49999999999999, -21.999999999999808, 49.70000000000006, -74.50000000000045, 109.1, -28.0, -50.79999999999998, 24.20000000000011, 118.1, 182.6, 7.999999999999972, -7.0, 13.99999999999999, -85.0, 108.8, -30.399999999999757, 20.000000000000014, 36.20000000000022, 22.700000000000063, 20.000000000000014, 11.599999999999964, 20.000000000000014, 25.39999999999999, -5.19999999999993, 44.0, 65.00000000000014, 30.799999999999997, 140.89999999999998, -146.8, -36.69999999999977, 110.90000000000003, -28.299999999999777, 157.4, 88.39999999999966, 165.5, 13.699999999999946, 170.9, 160.1, -251.09999999999957, -185.80000000000052, -68.20000000000006, -60.39999999999998, 134.0, -175.30000000000038, 137.0, 200.0, 111.80000000000013, 55.10000000000021, 29.0, -55.60000000000008, 71.6, 62.3, 158.6, 77.60000000000002, 158.0, 134.6, -204.70000000000016, -157.0, -183.70000000000053, 187.39999999999995, 38.900000000000254, 73.1, -45.10000000000018, 70.10000000000002, -277.0, -31.0, 167.0, 159.5, 123.2, 154.99999999999994, 7.700000000000109, -5.5, -90.70000000000002, 116.0, 7.39999999999996, -21.099999999999994, -80.79999999999978, -284.50000000000034, 196.4, 84.20000000000005, 191.9, 20.000000000000014, 89.0, -28.599999999999994, -85.6, -148.6, 20.000000000000014, -36.699999999999754, -18.400000000000006, -24.7, 37.099999999999994, 20.599999999999994, -55.89999999999997, -27.40000000000005, -290.8, -142.3, -368.30000000000007, -147.7, -126.69999999999999, -34.599999999999994, -72.10000000000005, -15.400000000000006, -157.60000000000008, -133.0, 8.0, 52.4, 47.3, 18.79999999999997, 198.2, 141.49999999999997, 27.20000000000001, 182.6, -239.50000000000003, -111.39999999999999, -25.599999999999994, 92.0, 0.20000000000000284, 20.000000000000014, -28.300000000000033, 20.000000000000014, -14.200000000000017, 4.100000000000016, -118.60000000000045, 52.4, -72.40000000000003, 190.1, 78.19999999999999, -15.699999999999775, 137.29999999999998, 54.5, -106.00000000000003, -97.3, -8.5, -195.1, 53.59999999999998, 20.0, -39.39999999999999, -135.10000000000005, -95.50000000000001, -3.10000000000003, -40.29999999999999, 20.299999999999997, -184.9, -179.8, 20.300000000000004, 38.6, -91.0, -185.8, 21.79999999999997, -89.5, 125.0, 148.39999999999998, -24.70000000000001, 20.000000000000014, -130.0, 20.000000000000014], "policy_predator_policy_reward": [49.0, 44.0, 131.0, 59.0, 34.0, 105.0, 73.0, 71.0, 5.0, 62.0, 0.0, 186.0, 0.0, 30.0, 0.0, 118.0, 3.0, 87.0, 13.0, 31.0, 26.0, 64.0, 0.0, 2.0, 3.0, 0.0, 8.0, 0.0, 41.0, 0.0, 46.0, 49.0, 57.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 78.0, 0.0, 0.0, 98.0, 3.0, 0.0, 21.0, 72.0, 0.0, 0.0, 76.0, 21.0, 73.0, 25.0, 0.0, 79.0, 0.0, 89.0, 24.0, 0.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 12.0, 54.0, 49.0, 0.0, 14.0, 0.0, 97.0, 45.0, 12.0, 32.0, 0.0, 13.0, 3.0, 10.0, 1.0, 0.0, 0.0, 199.0, 59.0, 36.0, 93.0, 0.0, 0.0, 0.0, 3.0, 0.0, 107.0, 17.0, 51.0, 18.0, 33.0, 0.0, 24.0, 0.0, 120.0, 104.0, 0.0, 97.0, 0.0, 30.0, 27.0, 68.0, 78.0, 161.0, 3.0, 14.0, 23.0, 2.0, 30.0, 51.0, 32.0, 80.0, 12.0, 54.0, 133.0, 40.0, 0.0, 23.0, 0.0, 0.0, 8.0, 80.0, 89.0, 139.0, 27.0, 0.0, 91.0, 16.0, 7.0, 78.0, 9.0, 99.0, 175.0, 103.0, 242.0, 103.0, 58.0, 73.0, 25.0, 65.0, 27.0, 121.0, 34.0, 35.0, 0.0, 69.0, 0.0, 18.0, 17.0, 25.0, 138.0, 127.0, 73.0, 18.0, 41.0, 23.0, 12.0, 11.0, 20.0, 63.0, 59.0, 55.0, 0.0, 89.0, 30.0, 0.0, 0.0, 59.0, 124.0, 82.0, 105.0, 69.0, 24.0, 63.0, 76.0, 92.0, 52.0, 89.0, 6.0, 104.0, 64.0, 151.0, 58.0, 19.0, 112.0, 113.0, 94.0, 15.0, 25.0, 0.0, 0.0, 53.0, 99.0, 43.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7265410594718921, "mean_inference_ms": 1.6994820235161117, "mean_action_processing_ms": 0.293169319450483, "mean_env_wait_ms": 0.225513246506968, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0062334537506103516, "StateBufferConnector_ms": 0.005131959915161133, "ViewRequirementAgentConnector_ms": 0.12093198299407959}, "num_episodes": 18, "episode_return_max": 357.7000000000001, "episode_return_min": -293.20000000000016, "episode_return_mean": 87.3919999999999, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 128000, "num_agent_steps_trained": 128000, "num_env_steps_sampled": 32000, "num_env_steps_trained": 32000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 78.74546981764709, "num_env_steps_trained_throughput_per_sec": 78.74546981764709, "timesteps_total": 32000, "num_env_steps_sampled_lifetime": 32000, "num_agent_steps_sampled_lifetime": 128000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 128000, "timers": {"training_iteration_time_ms": 52886.537, "restore_workers_time_ms": 0.019, "training_step_time_ms": 52886.483, "sample_time_ms": 1365.171, "learn_time_ms": 51507.485, "learn_throughput": 77.659, "synch_weights_time_ms": 11.0}, "counters": {"num_env_steps_sampled": 32000, "num_env_steps_trained": 32000, "num_agent_steps_sampled": 128000, "num_agent_steps_trained": 128000}, "done": false, "training_iteration": 8, "trial_id": "11e70_00000", "date": "2024-08-12_23-14-02", "timestamp": 1723518842, "time_this_iter_s": 50.81870126724243, "time_total_s": 423.35480308532715, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2b62430>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 423.35480308532715, "iterations_since_restore": 8, "perf": {"cpu_util_percent": 38.60555555555556, "ram_util_percent": 83.00833333333333}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.258746185819939, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.492197943742944, "policy_loss": -0.010989883615113006, "vf_loss": 7.500796067273176, "vf_explained_var": 0.027353288067711725, "kl": 0.007972522794371136, "entropy": 1.5420917509724854, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 16065.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.6851724421536485, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.833105351432922, "policy_loss": -0.018334942952749473, "vf_loss": 7.848892009573639, "vf_explained_var": -0.04524695311904584, "kl": 0.01698879470871746, "entropy": 1.4991391411534063, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 16065.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 36000, "num_env_steps_trained": 36000, "num_agent_steps_sampled": 144000, "num_agent_steps_trained": 144000}, "env_runners": {"episode_reward_max": 357.7000000000001, "episode_reward_min": -237.9000000000012, "episode_reward_mean": 84.12799999999994, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -368.30000000000007, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 242.0}, "policy_reward_mean": {"prey_policy": -7.696000000000007, "predator_policy": 49.76}, "custom_metrics": {}, "hist_stats": {"episode_reward": [119.49999999999974, 47.20000000000017, 157.1, 67.39999999999984, 325.69999999999993, 80.00000000000006, 42.000000000000014, 128.39999999999972, 56.20000000000046, 42.700000000000294, 35.600000000000236, 86.20000000000007, 157.99999999999926, 185.6999999999994, -41.49999999999997, 126.59999999999978, 258.7999999999997, 192.19999999999928, 332.0, -237.9000000000012, -33.599999999999866, 51.700000000000095, 337.0, 169.8999999999989, 97.40000000000003, 202.9, 269.20000000000005, 316.6, -137.7000000000002, 100.69999999999987, 141.99999999999963, 120.00000000000003, -69.0, 343.5, 303.19999999999993, 83.20000000000019, 137.3, 52.30000000000018, -192.3000000000005, 303.5999999999999, 211.8999999999993, 148.4, -6.199999999999996, 10.299999999999946, 63.89999999999998, 142.7, 24.700000000000045, -155.1, -171.00000000000009, -30.299999999999876, 2.500000000000046, -142.60000000000008, 129.4, 135.10000000000008, 357.7000000000001, 251.8, -85.89999999999998, 157.4, 84.1999999999993, 14.70000000000017, 72.90000000000006, 47.8000000000001, 206.69999999999996, 92.49999999999986, 250.79999999999995, 2.700000000000003, -29.6, 160.60000000000008, -6.499999999999989, 42.39999999999999, 89.99999999999997, -149.7, 135.89999999999998, -51.8, 41.30000000000002, 298.4000000000001, 48.30000000000003, 31.999999999999588, 130.6, -131.79999999999998, 104.99999999999972, -176.2, 146.99999999999994, 51.99999999999994, 296.79999999999984, 13.400000000000048, 40.0000000000003, 15.300000000000011, 51.10000000000011, 1.2999999999999972, 84.09999999999991, -10.59999999999988, -50.69999999999992, 96.59999999999953, 40.6, 57.599999999999994, 308.1999999999998, 14.800000000000018, -20.39999999999999, 159.99999999999997], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [120.49999999999999, -21.999999999999808, 49.70000000000006, -74.50000000000045, 109.1, -28.0, -50.79999999999998, 24.20000000000011, 118.1, 182.6, 7.999999999999972, -7.0, 13.99999999999999, -85.0, 108.8, -30.399999999999757, 20.000000000000014, 36.20000000000022, 22.700000000000063, 20.000000000000014, 11.599999999999964, 20.000000000000014, 25.39999999999999, -5.19999999999993, 44.0, 65.00000000000014, 30.799999999999997, 140.89999999999998, -146.8, -36.69999999999977, 110.90000000000003, -28.299999999999777, 157.4, 88.39999999999966, 165.5, 13.699999999999946, 170.9, 160.1, -251.09999999999957, -185.80000000000052, -68.20000000000006, -60.39999999999998, 134.0, -175.30000000000038, 137.0, 200.0, 111.80000000000013, 55.10000000000021, 29.0, -55.60000000000008, 71.6, 62.3, 158.6, 77.60000000000002, 158.0, 134.6, -204.70000000000016, -157.0, -183.70000000000053, 187.39999999999995, 38.900000000000254, 73.1, -45.10000000000018, 70.10000000000002, -277.0, -31.0, 167.0, 159.5, 123.2, 154.99999999999994, 7.700000000000109, -5.5, -90.70000000000002, 116.0, 7.39999999999996, -21.099999999999994, -80.79999999999978, -284.50000000000034, 196.4, 84.20000000000005, 191.9, 20.000000000000014, 89.0, -28.599999999999994, -85.6, -148.6, 20.000000000000014, -36.699999999999754, -18.400000000000006, -24.7, 37.099999999999994, 20.599999999999994, -55.89999999999997, -27.40000000000005, -290.8, -142.3, -368.30000000000007, -147.7, -126.69999999999999, -34.599999999999994, -72.10000000000005, -15.400000000000006, -157.60000000000008, -133.0, 8.0, 52.4, 47.3, 18.79999999999997, 198.2, 141.49999999999997, 27.20000000000001, 182.6, -239.50000000000003, -111.39999999999999, -25.599999999999994, 92.0, 0.20000000000000284, 20.000000000000014, -28.300000000000033, 20.000000000000014, -14.200000000000017, 4.100000000000016, -118.60000000000045, 52.4, -72.40000000000003, 190.1, 78.19999999999999, -15.699999999999775, 137.29999999999998, 54.5, -106.00000000000003, -97.3, -8.5, -195.1, 53.59999999999998, 20.0, -39.39999999999999, -135.10000000000005, -95.50000000000001, -3.10000000000003, -40.29999999999999, 20.299999999999997, -184.9, -179.8, 20.300000000000004, 38.6, -91.0, -185.8, 21.79999999999997, -89.5, 125.0, 148.39999999999998, -24.70000000000001, 20.000000000000014, -130.0, 20.000000000000014, 11.0, 41.6, -225.7, -165.10000000000002, 156.19999999999982, -143.20000000000002, -255.70000000000005, -128.5, -37.30000000000001, 77.30000000000001, -52.3, -27.69999999999999, 191.9, 101.9, -92.8, -35.800000000000026, 20.000000000000014, 20.000000000000014, -4.0, -150.70000000000007, -199.9, 20.000000000000014, -172.3, 38.6, -94.30000000000001, 109.4, -217.60000000000002, 20.000000000000014, -100.9, -56.80000000000001, 20.000000000000014, 26.599999999999994, -91.0, -6.3999999999999915, 28.099999999999998, -158.5, 109.99999999999997, 198.2, -91.90000000000009, -145.3, -205.0, -6.399999999999995, -74.80000000000007, 102.8], "policy_predator_policy_reward": [0.0, 21.0, 72.0, 0.0, 0.0, 76.0, 21.0, 73.0, 25.0, 0.0, 79.0, 0.0, 89.0, 24.0, 0.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 12.0, 54.0, 49.0, 0.0, 14.0, 0.0, 97.0, 45.0, 12.0, 32.0, 0.0, 13.0, 3.0, 10.0, 1.0, 0.0, 0.0, 199.0, 59.0, 36.0, 93.0, 0.0, 0.0, 0.0, 3.0, 0.0, 107.0, 17.0, 51.0, 18.0, 33.0, 0.0, 24.0, 0.0, 120.0, 104.0, 0.0, 97.0, 0.0, 30.0, 27.0, 68.0, 78.0, 161.0, 3.0, 14.0, 23.0, 2.0, 30.0, 51.0, 32.0, 80.0, 12.0, 54.0, 133.0, 40.0, 0.0, 23.0, 0.0, 0.0, 8.0, 80.0, 89.0, 139.0, 27.0, 0.0, 91.0, 16.0, 7.0, 78.0, 9.0, 99.0, 175.0, 103.0, 242.0, 103.0, 58.0, 73.0, 25.0, 65.0, 27.0, 121.0, 34.0, 35.0, 0.0, 69.0, 0.0, 18.0, 17.0, 25.0, 138.0, 127.0, 73.0, 18.0, 41.0, 23.0, 12.0, 11.0, 20.0, 63.0, 59.0, 55.0, 0.0, 89.0, 30.0, 0.0, 0.0, 59.0, 124.0, 82.0, 105.0, 69.0, 24.0, 63.0, 76.0, 92.0, 52.0, 89.0, 6.0, 104.0, 64.0, 151.0, 58.0, 19.0, 112.0, 113.0, 94.0, 15.0, 25.0, 0.0, 0.0, 53.0, 99.0, 43.0, 59.0, 19.0, 137.0, 122.0, 3.0, 89.0, 145.0, 63.0, 51.0, 56.0, 77.0, 55.0, 0.0, 3.0, 48.0, 94.0, 0.0, 0.0, 29.0, 141.0, 115.0, 116.0, 134.0, 1.0, 61.0, 8.0, 82.0, 105.0, 53.0, 54.0, 18.0, 32.0, 63.0, 75.0, 56.0, 132.0, 0.0, 0.0, 137.0, 115.0, 83.0, 108.0, 83.0, 49.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7223051744458115, "mean_inference_ms": 1.6833765757524934, "mean_action_processing_ms": 0.29208813805672296, "mean_env_wait_ms": 0.22326185110066432, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005429983139038086, "StateBufferConnector_ms": 0.0050934553146362305, "ViewRequirementAgentConnector_ms": 0.1285700798034668}, "num_episodes": 22, "episode_return_max": 357.7000000000001, "episode_return_min": -237.9000000000012, "episode_return_mean": 84.12799999999994, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 144000, "num_agent_steps_trained": 144000, "num_env_steps_sampled": 36000, "num_env_steps_trained": 36000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 77.95356321837585, "num_env_steps_trained_throughput_per_sec": 77.95356321837585, "timesteps_total": 36000, "num_env_steps_sampled_lifetime": 36000, "num_agent_steps_sampled_lifetime": 144000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 144000, "timers": {"training_iteration_time_ms": 52711.656, "restore_workers_time_ms": 0.019, "training_step_time_ms": 52711.604, "sample_time_ms": 1345.357, "learn_time_ms": 51352.597, "learn_throughput": 77.893, "synch_weights_time_ms": 10.887}, "counters": {"num_env_steps_sampled": 36000, "num_env_steps_trained": 36000, "num_agent_steps_sampled": 144000, "num_agent_steps_trained": 144000}, "done": false, "training_iteration": 9, "trial_id": "11e70_00000", "date": "2024-08-12_23-14-53", "timestamp": 1723518893, "time_this_iter_s": 51.36851477622986, "time_total_s": 474.723317861557, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2a91f70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 474.723317861557, "iterations_since_restore": 9, "perf": {"cpu_util_percent": 38.25342465753425, "ram_util_percent": 82.95342465753426}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.466499249140422, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.586441404352743, "policy_loss": -0.009794059040754166, "vf_loss": 5.594187673185237, "vf_explained_var": 0.015075775460591393, "kl": 0.006825994477605404, "entropy": 1.5295302799139072, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 17955.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.06554748646166, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.513021145926581, "policy_loss": -0.014099792168825549, "vf_loss": 7.525175847452154, "vf_explained_var": 0.15834324258975882, "kl": 0.012967239830473586, "entropy": 1.4866756529404372, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 17955.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 40000, "num_env_steps_trained": 40000, "num_agent_steps_sampled": 160000, "num_agent_steps_trained": 160000}, "env_runners": {"episode_reward_max": 364.5, "episode_reward_min": -192.3000000000005, "episode_reward_mean": 78.14599999999994, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -368.30000000000007, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 199.1, "predator_policy": 242.0}, "policy_reward_mean": {"prey_policy": -15.337000000000023, "predator_policy": 54.41}, "custom_metrics": {}, "hist_stats": {"episode_reward": [169.8999999999989, 97.40000000000003, 202.9, 269.20000000000005, 316.6, -137.7000000000002, 100.69999999999987, 141.99999999999963, 120.00000000000003, -69.0, 343.5, 303.19999999999993, 83.20000000000019, 137.3, 52.30000000000018, -192.3000000000005, 303.5999999999999, 211.8999999999993, 148.4, -6.199999999999996, 10.299999999999946, 63.89999999999998, 142.7, 24.700000000000045, -155.1, -171.00000000000009, -30.299999999999876, 2.500000000000046, -142.60000000000008, 129.4, 135.10000000000008, 357.7000000000001, 251.8, -85.89999999999998, 157.4, 84.1999999999993, 14.70000000000017, 72.90000000000006, 47.8000000000001, 206.69999999999996, 92.49999999999986, 250.79999999999995, 2.700000000000003, -29.6, 160.60000000000008, -6.499999999999989, 42.39999999999999, 89.99999999999997, -149.7, 135.89999999999998, -51.8, 41.30000000000002, 298.4000000000001, 48.30000000000003, 31.999999999999588, 130.6, -131.79999999999998, 104.99999999999972, -176.2, 146.99999999999994, 51.99999999999994, 296.79999999999984, 13.400000000000048, 40.0000000000003, 15.300000000000011, 51.10000000000011, 1.2999999999999972, 84.09999999999991, -10.59999999999988, -50.69999999999992, 96.59999999999953, 40.6, 57.599999999999994, 308.1999999999998, 14.800000000000018, -20.39999999999999, 159.99999999999997, 164.09999999999994, 144.89999999999964, 168.49999999999997, 364.5, -19.999999999999886, 52.60000000000012, 155.7999999999993, 87.19999999999936, -97.50000000000091, 44.9, 133.0, 40.10000000000027, 78.59999999999991, 31.20000000000018, 25.999999999999993, 90.79999999999997, 102.89999999999988, -12.099999999999874, -35.89999999999967, 175.79999999999998, 48.69999999999985, 27.19999999999999, 147.5], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [111.80000000000013, 55.10000000000021, 29.0, -55.60000000000008, 71.6, 62.3, 158.6, 77.60000000000002, 158.0, 134.6, -204.70000000000016, -157.0, -183.70000000000053, 187.39999999999995, 38.900000000000254, 73.1, -45.10000000000018, 70.10000000000002, -277.0, -31.0, 167.0, 159.5, 123.2, 154.99999999999994, 7.700000000000109, -5.5, -90.70000000000002, 116.0, 7.39999999999996, -21.099999999999994, -80.79999999999978, -284.50000000000034, 196.4, 84.20000000000005, 191.9, 20.000000000000014, 89.0, -28.599999999999994, -85.6, -148.6, 20.000000000000014, -36.699999999999754, -18.400000000000006, -24.7, 37.099999999999994, 20.599999999999994, -55.89999999999997, -27.40000000000005, -290.8, -142.3, -368.30000000000007, -147.7, -126.69999999999999, -34.599999999999994, -72.10000000000005, -15.400000000000006, -157.60000000000008, -133.0, 8.0, 52.4, 47.3, 18.79999999999997, 198.2, 141.49999999999997, 27.20000000000001, 182.6, -239.50000000000003, -111.39999999999999, -25.599999999999994, 92.0, 0.20000000000000284, 20.000000000000014, -28.300000000000033, 20.000000000000014, -14.200000000000017, 4.100000000000016, -118.60000000000045, 52.4, -72.40000000000003, 190.1, 78.19999999999999, -15.699999999999775, 137.29999999999998, 54.5, -106.00000000000003, -97.3, -8.5, -195.1, 53.59999999999998, 20.0, -39.39999999999999, -135.10000000000005, -95.50000000000001, -3.10000000000003, -40.29999999999999, 20.299999999999997, -184.9, -179.8, 20.300000000000004, 38.6, -91.0, -185.8, 21.79999999999997, -89.5, 125.0, 148.39999999999998, -24.70000000000001, 20.000000000000014, -130.0, 20.000000000000014, 11.0, 41.6, -225.7, -165.10000000000002, 156.19999999999982, -143.20000000000002, -255.70000000000005, -128.5, -37.30000000000001, 77.30000000000001, -52.3, -27.69999999999999, 191.9, 101.9, -92.8, -35.800000000000026, 20.000000000000014, 20.000000000000014, -4.0, -150.70000000000007, -199.9, 20.000000000000014, -172.3, 38.6, -94.30000000000001, 109.4, -217.60000000000002, 20.000000000000014, -100.9, -56.80000000000001, 20.000000000000014, 26.599999999999994, -91.0, -6.3999999999999915, 28.099999999999998, -158.5, 109.99999999999997, 198.2, -91.90000000000009, -145.3, -205.0, -6.399999999999995, -74.80000000000007, 102.8, 70.1, 28.999999999999964, 20.000000000000014, 74.9, 106.4, -22.900000000000006, 154.4, 199.1, -29.199999999999925, -164.80000000000024, -17.20000000000003, -62.20000000000002, -17.79999999999974, 149.59999999999988, -127.00000000000051, 144.19999999999968, -9.700000000000038, -235.80000000000047, -86.8000000000003, -25.299999999999997, 26.30000000000001, 25.699999999999996, -115.90000000000018, 20.000000000000014, -82.0, -6.400000000000022, 20.000000000000014, 3.1999999999999704, -3.1000000000000365, -4.900000000000038, 11.900000000000002, -21.099999999999998, -71.2000000000001, 52.10000000000003, -17.500000000000036, -202.60000000000002, 20.000000000000014, -124.90000000000055, -55.900000000000034, 136.6999999999999, -6.699999999999967, -37.600000000000136, -62.80000000000004, 20.000000000000014, 16.70000000000001, 36.80000000000001], "policy_predator_policy_reward": [3.0, 0.0, 107.0, 17.0, 51.0, 18.0, 33.0, 0.0, 24.0, 0.0, 120.0, 104.0, 0.0, 97.0, 0.0, 30.0, 27.0, 68.0, 78.0, 161.0, 3.0, 14.0, 23.0, 2.0, 30.0, 51.0, 32.0, 80.0, 12.0, 54.0, 133.0, 40.0, 0.0, 23.0, 0.0, 0.0, 8.0, 80.0, 89.0, 139.0, 27.0, 0.0, 91.0, 16.0, 7.0, 78.0, 9.0, 99.0, 175.0, 103.0, 242.0, 103.0, 58.0, 73.0, 25.0, 65.0, 27.0, 121.0, 34.0, 35.0, 0.0, 69.0, 0.0, 18.0, 17.0, 25.0, 138.0, 127.0, 73.0, 18.0, 41.0, 23.0, 12.0, 11.0, 20.0, 63.0, 59.0, 55.0, 0.0, 89.0, 30.0, 0.0, 0.0, 59.0, 124.0, 82.0, 105.0, 69.0, 24.0, 63.0, 76.0, 92.0, 52.0, 89.0, 6.0, 104.0, 64.0, 151.0, 58.0, 19.0, 112.0, 113.0, 94.0, 15.0, 25.0, 0.0, 0.0, 53.0, 99.0, 43.0, 59.0, 19.0, 137.0, 122.0, 3.0, 89.0, 145.0, 63.0, 51.0, 56.0, 77.0, 55.0, 0.0, 3.0, 48.0, 94.0, 0.0, 0.0, 29.0, 141.0, 115.0, 116.0, 134.0, 1.0, 61.0, 8.0, 82.0, 105.0, 53.0, 54.0, 18.0, 32.0, 63.0, 75.0, 56.0, 132.0, 0.0, 0.0, 137.0, 115.0, 83.0, 108.0, 83.0, 49.0, 65.0, 0.0, 12.0, 38.0, 29.0, 56.0, 0.0, 11.0, 74.0, 100.0, 48.0, 84.0, 23.0, 1.0, 70.0, 0.0, 21.0, 127.0, 72.0, 85.0, 16.0, 65.0, 76.0, 60.0, 95.0, 72.0, 0.0, 8.0, 34.0, 0.0, 53.0, 47.0, 40.0, 82.0, 91.0, 117.0, 69.0, 0.0, 4.0, 91.0, 0.0, 93.0, 27.0, 43.0, 52.0, 42.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7110804320375671, "mean_inference_ms": 1.6479246987159013, "mean_action_processing_ms": 0.28642161810583183, "mean_env_wait_ms": 0.21953624345480077, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004627346992492676, "StateBufferConnector_ms": 0.004849791526794434, "ViewRequirementAgentConnector_ms": 0.1217566728591919}, "num_episodes": 23, "episode_return_max": 364.5, "episode_return_min": -192.3000000000005, "episode_return_mean": 78.14599999999994, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 160000, "num_agent_steps_trained": 160000, "num_env_steps_sampled": 40000, "num_env_steps_trained": 40000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 78.88355956179598, "num_env_steps_trained_throughput_per_sec": 78.88355956179598, "timesteps_total": 40000, "num_env_steps_sampled_lifetime": 40000, "num_agent_steps_sampled_lifetime": 160000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 160000, "timers": {"training_iteration_time_ms": 52511.256, "restore_workers_time_ms": 0.018, "training_step_time_ms": 52511.206, "sample_time_ms": 1329.678, "learn_time_ms": 51167.949, "learn_throughput": 78.174, "synch_weights_time_ms": 10.896}, "counters": {"num_env_steps_sampled": 40000, "num_env_steps_trained": 40000, "num_agent_steps_sampled": 160000, "num_agent_steps_trained": 160000}, "done": false, "training_iteration": 10, "trial_id": "11e70_00000", "date": "2024-08-12_23-15-44", "timestamp": 1723518944, "time_this_iter_s": 50.77944087982178, "time_total_s": 525.5027587413788, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2ad7940>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 525.5027587413788, "iterations_since_restore": 10, "perf": {"cpu_util_percent": 40.201388888888886, "ram_util_percent": 83.08611111111112}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.5443858331473415, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.529795863893297, "policy_loss": -0.01462377679605707, "vf_loss": 5.54115721157619, "vf_explained_var": 0.03628436822109121, "kl": 0.01087477204501406, "entropy": 1.525347004744111, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 19845.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.658853183347712, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.174304462614513, "policy_loss": -0.013769747228632686, "vf_loss": 8.185934770422637, "vf_explained_var": 0.0904506091402952, "kl": 0.014262973707734411, "entropy": 1.4579705240865233, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 19845.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 44000, "num_env_steps_trained": 44000, "num_agent_steps_sampled": 176000, "num_agent_steps_trained": 176000}, "env_runners": {"episode_reward_max": 364.5, "episode_reward_min": -176.2, "episode_reward_mean": 70.67999999999995, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -368.30000000000007, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 199.1, "predator_policy": 242.0}, "policy_reward_mean": {"prey_policy": -19.57000000000003, "predator_policy": 54.91}, "custom_metrics": {}, "hist_stats": {"episode_reward": [148.4, -6.199999999999996, 10.299999999999946, 63.89999999999998, 142.7, 24.700000000000045, -155.1, -171.00000000000009, -30.299999999999876, 2.500000000000046, -142.60000000000008, 129.4, 135.10000000000008, 357.7000000000001, 251.8, -85.89999999999998, 157.4, 84.1999999999993, 14.70000000000017, 72.90000000000006, 47.8000000000001, 206.69999999999996, 92.49999999999986, 250.79999999999995, 2.700000000000003, -29.6, 160.60000000000008, -6.499999999999989, 42.39999999999999, 89.99999999999997, -149.7, 135.89999999999998, -51.8, 41.30000000000002, 298.4000000000001, 48.30000000000003, 31.999999999999588, 130.6, -131.79999999999998, 104.99999999999972, -176.2, 146.99999999999994, 51.99999999999994, 296.79999999999984, 13.400000000000048, 40.0000000000003, 15.300000000000011, 51.10000000000011, 1.2999999999999972, 84.09999999999991, -10.59999999999988, -50.69999999999992, 96.59999999999953, 40.6, 57.599999999999994, 308.1999999999998, 14.800000000000018, -20.39999999999999, 159.99999999999997, 164.09999999999994, 144.89999999999964, 168.49999999999997, 364.5, -19.999999999999886, 52.60000000000012, 155.7999999999993, 87.19999999999936, -97.50000000000091, 44.9, 133.0, 40.10000000000027, 78.59999999999991, 31.20000000000018, 25.999999999999993, 90.79999999999997, 102.89999999999988, -12.099999999999874, -35.89999999999967, 175.79999999999998, 48.69999999999985, 27.19999999999999, 147.5, 103.99999999999974, 81.79999999999981, 30.50000000000002, 281.5, 75.90000000000006, 244.59999999999997, 172.3, -11.0, 110.29999999999998, 43.4000000000002, 48.10000000000001, 205.1999999999996, 173.59999999999977, 149.09999999999943, 33.00000000000001, -122.40000000000094, 70.2, 18.0], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [89.0, -28.599999999999994, -85.6, -148.6, 20.000000000000014, -36.699999999999754, -18.400000000000006, -24.7, 37.099999999999994, 20.599999999999994, -55.89999999999997, -27.40000000000005, -290.8, -142.3, -368.30000000000007, -147.7, -126.69999999999999, -34.599999999999994, -72.10000000000005, -15.400000000000006, -157.60000000000008, -133.0, 8.0, 52.4, 47.3, 18.79999999999997, 198.2, 141.49999999999997, 27.20000000000001, 182.6, -239.50000000000003, -111.39999999999999, -25.599999999999994, 92.0, 0.20000000000000284, 20.000000000000014, -28.300000000000033, 20.000000000000014, -14.200000000000017, 4.100000000000016, -118.60000000000045, 52.4, -72.40000000000003, 190.1, 78.19999999999999, -15.699999999999775, 137.29999999999998, 54.5, -106.00000000000003, -97.3, -8.5, -195.1, 53.59999999999998, 20.0, -39.39999999999999, -135.10000000000005, -95.50000000000001, -3.10000000000003, -40.29999999999999, 20.299999999999997, -184.9, -179.8, 20.300000000000004, 38.6, -91.0, -185.8, 21.79999999999997, -89.5, 125.0, 148.39999999999998, -24.70000000000001, 20.000000000000014, -130.0, 20.000000000000014, 11.0, 41.6, -225.7, -165.10000000000002, 156.19999999999982, -143.20000000000002, -255.70000000000005, -128.5, -37.30000000000001, 77.30000000000001, -52.3, -27.69999999999999, 191.9, 101.9, -92.8, -35.800000000000026, 20.000000000000014, 20.000000000000014, -4.0, -150.70000000000007, -199.9, 20.000000000000014, -172.3, 38.6, -94.30000000000001, 109.4, -217.60000000000002, 20.000000000000014, -100.9, -56.80000000000001, 20.000000000000014, 26.599999999999994, -91.0, -6.3999999999999915, 28.099999999999998, -158.5, 109.99999999999997, 198.2, -91.90000000000009, -145.3, -205.0, -6.399999999999995, -74.80000000000007, 102.8, 70.1, 28.999999999999964, 20.000000000000014, 74.9, 106.4, -22.900000000000006, 154.4, 199.1, -29.199999999999925, -164.80000000000024, -17.20000000000003, -62.20000000000002, -17.79999999999974, 149.59999999999988, -127.00000000000051, 144.19999999999968, -9.700000000000038, -235.80000000000047, -86.8000000000003, -25.299999999999997, 26.30000000000001, 25.699999999999996, -115.90000000000018, 20.000000000000014, -82.0, -6.400000000000022, 20.000000000000014, 3.1999999999999704, -3.1000000000000365, -4.900000000000038, 11.900000000000002, -21.099999999999998, -71.2000000000001, 52.10000000000003, -17.500000000000036, -202.60000000000002, 20.000000000000014, -124.90000000000055, -55.900000000000034, 136.6999999999999, -6.699999999999967, -37.600000000000136, -62.80000000000004, 20.000000000000014, 16.70000000000001, 36.80000000000001, 93.49999999999989, -23.500000000000036, -15.699999999999754, 27.500000000000007, -31.29999999999999, -47.19999999999997, 99.19999999999999, 155.29999999999995, -37.30000000000003, 0.1999999999999993, 124.99999999999999, 77.60000000000001, 99.19999999999997, 19.100000000000023, -70.6, -99.40000000000003, 25.400000000000006, 26.899999999999984, -1.3000000000000007, -28.29999999999975, 89.59999999999985, -158.50000000000048, 77.8999999999997, 83.30000000000001, 38.00000000000007, 68.6, 39.500000000000014, 26.600000000000122, -96.99999999999999, 20.000000000000014, -127.0000000000006, -135.39999999999992, -38.20000000000002, -7.599999999999973, -29.799999999999983, -71.20000000000005], "policy_predator_policy_reward": [8.0, 80.0, 89.0, 139.0, 27.0, 0.0, 91.0, 16.0, 7.0, 78.0, 9.0, 99.0, 175.0, 103.0, 242.0, 103.0, 58.0, 73.0, 25.0, 65.0, 27.0, 121.0, 34.0, 35.0, 0.0, 69.0, 0.0, 18.0, 17.0, 25.0, 138.0, 127.0, 73.0, 18.0, 41.0, 23.0, 12.0, 11.0, 20.0, 63.0, 59.0, 55.0, 0.0, 89.0, 30.0, 0.0, 0.0, 59.0, 124.0, 82.0, 105.0, 69.0, 24.0, 63.0, 76.0, 92.0, 52.0, 89.0, 6.0, 104.0, 64.0, 151.0, 58.0, 19.0, 112.0, 113.0, 94.0, 15.0, 25.0, 0.0, 0.0, 53.0, 99.0, 43.0, 59.0, 19.0, 137.0, 122.0, 3.0, 89.0, 145.0, 63.0, 51.0, 56.0, 77.0, 55.0, 0.0, 3.0, 48.0, 94.0, 0.0, 0.0, 29.0, 141.0, 115.0, 116.0, 134.0, 1.0, 61.0, 8.0, 82.0, 105.0, 53.0, 54.0, 18.0, 32.0, 63.0, 75.0, 56.0, 132.0, 0.0, 0.0, 137.0, 115.0, 83.0, 108.0, 83.0, 49.0, 65.0, 0.0, 12.0, 38.0, 29.0, 56.0, 0.0, 11.0, 74.0, 100.0, 48.0, 84.0, 23.0, 1.0, 70.0, 0.0, 21.0, 127.0, 72.0, 85.0, 16.0, 65.0, 76.0, 60.0, 95.0, 72.0, 0.0, 8.0, 34.0, 0.0, 53.0, 47.0, 40.0, 82.0, 91.0, 117.0, 69.0, 0.0, 4.0, 91.0, 0.0, 93.0, 27.0, 43.0, 52.0, 42.0, 19.0, 15.0, 31.0, 39.0, 77.0, 32.0, 27.0, 0.0, 58.0, 55.0, 42.0, 0.0, 54.0, 0.0, 79.0, 80.0, 34.0, 24.0, 50.0, 23.0, 46.0, 71.0, 26.0, 18.0, 14.0, 53.0, 34.0, 49.0, 88.0, 22.0, 14.0, 126.0, 71.0, 45.0, 56.0, 63.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7053406156743616, "mean_inference_ms": 1.627483414939636, "mean_action_processing_ms": 0.2834600881976223, "mean_env_wait_ms": 0.21711722609035455, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005035877227783203, "StateBufferConnector_ms": 0.004818439483642578, "ViewRequirementAgentConnector_ms": 0.12124478816986084}, "num_episodes": 18, "episode_return_max": 364.5, "episode_return_min": -176.2, "episode_return_mean": 70.67999999999995, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 176000, "num_agent_steps_trained": 176000, "num_env_steps_sampled": 44000, "num_env_steps_trained": 44000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 79.09678135781745, "num_env_steps_trained_throughput_per_sec": 79.09678135781745, "timesteps_total": 44000, "num_env_steps_sampled_lifetime": 44000, "num_agent_steps_sampled_lifetime": 176000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 176000, "timers": {"training_iteration_time_ms": 51873.255, "restore_workers_time_ms": 0.018, "training_step_time_ms": 51873.206, "sample_time_ms": 1299.442, "learn_time_ms": 50560.508, "learn_throughput": 79.113, "synch_weights_time_ms": 10.853}, "counters": {"num_env_steps_sampled": 44000, "num_env_steps_trained": 44000, "num_agent_steps_sampled": 176000, "num_agent_steps_trained": 176000}, "done": false, "training_iteration": 11, "trial_id": "11e70_00000", "date": "2024-08-12_23-16-35", "timestamp": 1723518995, "time_this_iter_s": 50.60397696495056, "time_total_s": 576.1067357063293, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2b15d30>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 576.1067357063293, "iterations_since_restore": 11, "perf": {"cpu_util_percent": 36.56250000000001, "ram_util_percent": 82.94722222222221}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.767496784023507, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.714244432045669, "policy_loss": -0.01191839463392854, "vf_loss": 5.723204613236523, "vf_explained_var": 0.050734104050530325, "kl": 0.00986076884142657, "entropy": 1.5091797300747463, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 21735.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.798124014700531, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.838830523516135, "policy_loss": -0.010454044225206845, "vf_loss": 7.847626844537321, "vf_explained_var": -0.020056523753221703, "kl": 0.01105153254369311, "entropy": 1.449271149925454, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 21735.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 48000, "num_env_steps_trained": 48000, "num_agent_steps_sampled": 192000, "num_agent_steps_trained": 192000}, "env_runners": {"episode_reward_max": 364.5, "episode_reward_min": -189.60000000000034, "episode_reward_mean": 67.70299999999993, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -286.89999999999986, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 156.0}, "policy_reward_mean": {"prey_policy": -18.333500000000033, "predator_policy": 52.185}, "custom_metrics": {}, "hist_stats": {"episode_reward": [14.70000000000017, 72.90000000000006, 47.8000000000001, 206.69999999999996, 92.49999999999986, 250.79999999999995, 2.700000000000003, -29.6, 160.60000000000008, -6.499999999999989, 42.39999999999999, 89.99999999999997, -149.7, 135.89999999999998, -51.8, 41.30000000000002, 298.4000000000001, 48.30000000000003, 31.999999999999588, 130.6, -131.79999999999998, 104.99999999999972, -176.2, 146.99999999999994, 51.99999999999994, 296.79999999999984, 13.400000000000048, 40.0000000000003, 15.300000000000011, 51.10000000000011, 1.2999999999999972, 84.09999999999991, -10.59999999999988, -50.69999999999992, 96.59999999999953, 40.6, 57.599999999999994, 308.1999999999998, 14.800000000000018, -20.39999999999999, 159.99999999999997, 164.09999999999994, 144.89999999999964, 168.49999999999997, 364.5, -19.999999999999886, 52.60000000000012, 155.7999999999993, 87.19999999999936, -97.50000000000091, 44.9, 133.0, 40.10000000000027, 78.59999999999991, 31.20000000000018, 25.999999999999993, 90.79999999999997, 102.89999999999988, -12.099999999999874, -35.89999999999967, 175.79999999999998, 48.69999999999985, 27.19999999999999, 147.5, 103.99999999999974, 81.79999999999981, 30.50000000000002, 281.5, 75.90000000000006, 244.59999999999997, 172.3, -11.0, 110.29999999999998, 43.4000000000002, 48.10000000000001, 205.1999999999996, 173.59999999999977, 149.09999999999943, 33.00000000000001, -122.40000000000094, 70.2, 18.0, 77.89999999999995, 16.400000000000254, -25.899999999999928, 60.59999999999994, 136.39999999999938, 11.10000000000003, -9.200000000000214, -0.40000000000011493, -6.699999999999964, 169.89999999999947, -65.99999999999989, 141.39999999999998, -87.90000000000015, 24.099999999999838, 363.1000000000002, 10.300000000000008, -6.199999999999971, -189.60000000000034], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-28.300000000000033, 20.000000000000014, -14.200000000000017, 4.100000000000016, -118.60000000000045, 52.4, -72.40000000000003, 190.1, 78.19999999999999, -15.699999999999775, 137.29999999999998, 54.5, -106.00000000000003, -97.3, -8.5, -195.1, 53.59999999999998, 20.0, -39.39999999999999, -135.10000000000005, -95.50000000000001, -3.10000000000003, -40.29999999999999, 20.299999999999997, -184.9, -179.8, 20.300000000000004, 38.6, -91.0, -185.8, 21.79999999999997, -89.5, 125.0, 148.39999999999998, -24.70000000000001, 20.000000000000014, -130.0, 20.000000000000014, 11.0, 41.6, -225.7, -165.10000000000002, 156.19999999999982, -143.20000000000002, -255.70000000000005, -128.5, -37.30000000000001, 77.30000000000001, -52.3, -27.69999999999999, 191.9, 101.9, -92.8, -35.800000000000026, 20.000000000000014, 20.000000000000014, -4.0, -150.70000000000007, -199.9, 20.000000000000014, -172.3, 38.6, -94.30000000000001, 109.4, -217.60000000000002, 20.000000000000014, -100.9, -56.80000000000001, 20.000000000000014, 26.599999999999994, -91.0, -6.3999999999999915, 28.099999999999998, -158.5, 109.99999999999997, 198.2, -91.90000000000009, -145.3, -205.0, -6.399999999999995, -74.80000000000007, 102.8, 70.1, 28.999999999999964, 20.000000000000014, 74.9, 106.4, -22.900000000000006, 154.4, 199.1, -29.199999999999925, -164.80000000000024, -17.20000000000003, -62.20000000000002, -17.79999999999974, 149.59999999999988, -127.00000000000051, 144.19999999999968, -9.700000000000038, -235.80000000000047, -86.8000000000003, -25.299999999999997, 26.30000000000001, 25.699999999999996, -115.90000000000018, 20.000000000000014, -82.0, -6.400000000000022, 20.000000000000014, 3.1999999999999704, -3.1000000000000365, -4.900000000000038, 11.900000000000002, -21.099999999999998, -71.2000000000001, 52.10000000000003, -17.500000000000036, -202.60000000000002, 20.000000000000014, -124.90000000000055, -55.900000000000034, 136.6999999999999, -6.699999999999967, -37.600000000000136, -62.80000000000004, 20.000000000000014, 16.70000000000001, 36.80000000000001, 93.49999999999989, -23.500000000000036, -15.699999999999754, 27.500000000000007, -31.29999999999999, -47.19999999999997, 99.19999999999999, 155.29999999999995, -37.30000000000003, 0.1999999999999993, 124.99999999999999, 77.60000000000001, 99.19999999999997, 19.100000000000023, -70.6, -99.40000000000003, 25.400000000000006, 26.899999999999984, -1.3000000000000007, -28.29999999999975, 89.59999999999985, -158.50000000000048, 77.8999999999997, 83.30000000000001, 38.00000000000007, 68.6, 39.500000000000014, 26.600000000000122, -96.99999999999999, 20.000000000000014, -127.0000000000006, -135.39999999999992, -38.20000000000002, -7.599999999999973, -29.799999999999983, -71.20000000000005, 20.000000000000014, 8.900000000000007, -86.50000000000001, 17.899999999999988, 20.000000000000014, -139.90000000000003, -36.400000000000034, 20.000000000000014, 82.39999999999998, 20.000000000000014, -63.39999999999998, -44.5, -36.40000000000008, -98.8000000000005, -91.90000000000003, 0.5000000000000071, -10.299999999999999, -99.40000000000016, 28.399999999999956, 117.49999999999994, -112.60000000000002, -72.39999999999999, 65.29999999999995, 22.100000000000072, 20.000000000000014, -286.89999999999986, -17.79999999999994, -81.09999999999997, 163.09999999999997, 200.0, 9.499999999999972, -119.20000000000041, -99.70000000000007, -32.49999999999998, -200.20000000000013, -174.4000000000002], "policy_predator_policy_reward": [12.0, 11.0, 20.0, 63.0, 59.0, 55.0, 0.0, 89.0, 30.0, 0.0, 0.0, 59.0, 124.0, 82.0, 105.0, 69.0, 24.0, 63.0, 76.0, 92.0, 52.0, 89.0, 6.0, 104.0, 64.0, 151.0, 58.0, 19.0, 112.0, 113.0, 94.0, 15.0, 25.0, 0.0, 0.0, 53.0, 99.0, 43.0, 59.0, 19.0, 137.0, 122.0, 3.0, 89.0, 145.0, 63.0, 51.0, 56.0, 77.0, 55.0, 0.0, 3.0, 48.0, 94.0, 0.0, 0.0, 29.0, 141.0, 115.0, 116.0, 134.0, 1.0, 61.0, 8.0, 82.0, 105.0, 53.0, 54.0, 18.0, 32.0, 63.0, 75.0, 56.0, 132.0, 0.0, 0.0, 137.0, 115.0, 83.0, 108.0, 83.0, 49.0, 65.0, 0.0, 12.0, 38.0, 29.0, 56.0, 0.0, 11.0, 74.0, 100.0, 48.0, 84.0, 23.0, 1.0, 70.0, 0.0, 21.0, 127.0, 72.0, 85.0, 16.0, 65.0, 76.0, 60.0, 95.0, 72.0, 0.0, 8.0, 34.0, 0.0, 53.0, 47.0, 40.0, 82.0, 91.0, 117.0, 69.0, 0.0, 4.0, 91.0, 0.0, 93.0, 27.0, 43.0, 52.0, 42.0, 19.0, 15.0, 31.0, 39.0, 77.0, 32.0, 27.0, 0.0, 58.0, 55.0, 42.0, 0.0, 54.0, 0.0, 79.0, 80.0, 34.0, 24.0, 50.0, 23.0, 46.0, 71.0, 26.0, 18.0, 14.0, 53.0, 34.0, 49.0, 88.0, 22.0, 14.0, 126.0, 71.0, 45.0, 56.0, 63.0, 49.0, 0.0, 35.0, 50.0, 15.0, 79.0, 19.0, 58.0, 10.0, 24.0, 43.0, 76.0, 41.0, 85.0, 6.0, 85.0, 48.0, 55.0, 24.0, 0.0, 52.0, 67.0, 17.0, 37.0, 143.0, 36.0, 33.0, 90.0, 0.0, 0.0, 30.0, 90.0, 89.0, 37.0, 156.0, 29.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6989480413947368, "mean_inference_ms": 1.6111912202502807, "mean_action_processing_ms": 0.2805040528748734, "mean_env_wait_ms": 0.21484501512007548, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004236340522766113, "StateBufferConnector_ms": 0.003395676612854004, "ViewRequirementAgentConnector_ms": 0.12124311923980713}, "num_episodes": 18, "episode_return_max": 364.5, "episode_return_min": -189.60000000000034, "episode_return_mean": 67.70299999999993, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 192000, "num_agent_steps_trained": 192000, "num_env_steps_sampled": 48000, "num_env_steps_trained": 48000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 77.96639637207794, "num_env_steps_trained_throughput_per_sec": 77.96639637207794, "timesteps_total": 48000, "num_env_steps_sampled_lifetime": 48000, "num_agent_steps_sampled_lifetime": 192000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 192000, "timers": {"training_iteration_time_ms": 51581.101, "restore_workers_time_ms": 0.014, "training_step_time_ms": 51581.061, "sample_time_ms": 1269.651, "learn_time_ms": 50298.57, "learn_throughput": 79.525, "synch_weights_time_ms": 10.82}, "counters": {"num_env_steps_sampled": 48000, "num_env_steps_trained": 48000, "num_agent_steps_sampled": 192000, "num_agent_steps_trained": 192000}, "done": false, "training_iteration": 12, "trial_id": "11e70_00000", "date": "2024-08-12_23-17-26", "timestamp": 1723519046, "time_this_iter_s": 51.37837028503418, "time_total_s": 627.4851059913635, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2b159d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 627.4851059913635, "iterations_since_restore": 12, "perf": {"cpu_util_percent": 37.178082191780824, "ram_util_percent": 82.87808219178083}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.547092572848002, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.889828769744389, "policy_loss": -0.014347449645754837, "vf_loss": 7.900657114906917, "vf_explained_var": 0.04373921149622196, "kl": 0.01173033936174761, "entropy": 1.498989159657211, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 23625.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.7753468944597497, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.14808779847685, "policy_loss": -0.010804460762886617, "vf_loss": 8.157052210903672, "vf_explained_var": -0.12009925123244997, "kl": 0.012267014239815075, "entropy": 1.4389676024043372, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 23625.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 52000, "num_env_steps_trained": 52000, "num_agent_steps_sampled": 208000, "num_agent_steps_trained": 208000}, "env_runners": {"episode_reward_max": 364.5, "episode_reward_min": -256.20000000000016, "episode_reward_mean": 39.7849999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -351.4999999999998, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 262.0}, "policy_reward_mean": {"prey_policy": -36.70750000000004, "predator_policy": 56.6}, "custom_metrics": {}, "hist_stats": {"episode_reward": [31.999999999999588, 130.6, -131.79999999999998, 104.99999999999972, -176.2, 146.99999999999994, 51.99999999999994, 296.79999999999984, 13.400000000000048, 40.0000000000003, 15.300000000000011, 51.10000000000011, 1.2999999999999972, 84.09999999999991, -10.59999999999988, -50.69999999999992, 96.59999999999953, 40.6, 57.599999999999994, 308.1999999999998, 14.800000000000018, -20.39999999999999, 159.99999999999997, 164.09999999999994, 144.89999999999964, 168.49999999999997, 364.5, -19.999999999999886, 52.60000000000012, 155.7999999999993, 87.19999999999936, -97.50000000000091, 44.9, 133.0, 40.10000000000027, 78.59999999999991, 31.20000000000018, 25.999999999999993, 90.79999999999997, 102.89999999999988, -12.099999999999874, -35.89999999999967, 175.79999999999998, 48.69999999999985, 27.19999999999999, 147.5, 103.99999999999974, 81.79999999999981, 30.50000000000002, 281.5, 75.90000000000006, 244.59999999999997, 172.3, -11.0, 110.29999999999998, 43.4000000000002, 48.10000000000001, 205.1999999999996, 173.59999999999977, 149.09999999999943, 33.00000000000001, -122.40000000000094, 70.2, 18.0, 77.89999999999995, 16.400000000000254, -25.899999999999928, 60.59999999999994, 136.39999999999938, 11.10000000000003, -9.200000000000214, -0.40000000000011493, -6.699999999999964, 169.89999999999947, -65.99999999999989, 141.39999999999998, -87.90000000000015, 24.099999999999838, 363.1000000000002, 10.300000000000008, -6.199999999999971, -189.60000000000034, -117.70000000000007, -161.79999999999995, -66.29999999999987, -125.30000000000044, 140.09999999999923, -29.39999999999997, -52.69999999999981, -169.00000000000037, 33.69999999999989, -142.50000000000065, -90.79999999999998, -38.69999999999992, -174.50000000000014, -256.20000000000016, -207.20000000000005, -113.10000000000082, 69.19999999999928, -22.199999999999907], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-130.0, 20.000000000000014, 11.0, 41.6, -225.7, -165.10000000000002, 156.19999999999982, -143.20000000000002, -255.70000000000005, -128.5, -37.30000000000001, 77.30000000000001, -52.3, -27.69999999999999, 191.9, 101.9, -92.8, -35.800000000000026, 20.000000000000014, 20.000000000000014, -4.0, -150.70000000000007, -199.9, 20.000000000000014, -172.3, 38.6, -94.30000000000001, 109.4, -217.60000000000002, 20.000000000000014, -100.9, -56.80000000000001, 20.000000000000014, 26.599999999999994, -91.0, -6.3999999999999915, 28.099999999999998, -158.5, 109.99999999999997, 198.2, -91.90000000000009, -145.3, -205.0, -6.399999999999995, -74.80000000000007, 102.8, 70.1, 28.999999999999964, 20.000000000000014, 74.9, 106.4, -22.900000000000006, 154.4, 199.1, -29.199999999999925, -164.80000000000024, -17.20000000000003, -62.20000000000002, -17.79999999999974, 149.59999999999988, -127.00000000000051, 144.19999999999968, -9.700000000000038, -235.80000000000047, -86.8000000000003, -25.299999999999997, 26.30000000000001, 25.699999999999996, -115.90000000000018, 20.000000000000014, -82.0, -6.400000000000022, 20.000000000000014, 3.1999999999999704, -3.1000000000000365, -4.900000000000038, 11.900000000000002, -21.099999999999998, -71.2000000000001, 52.10000000000003, -17.500000000000036, -202.60000000000002, 20.000000000000014, -124.90000000000055, -55.900000000000034, 136.6999999999999, -6.699999999999967, -37.600000000000136, -62.80000000000004, 20.000000000000014, 16.70000000000001, 36.80000000000001, 93.49999999999989, -23.500000000000036, -15.699999999999754, 27.500000000000007, -31.29999999999999, -47.19999999999997, 99.19999999999999, 155.29999999999995, -37.30000000000003, 0.1999999999999993, 124.99999999999999, 77.60000000000001, 99.19999999999997, 19.100000000000023, -70.6, -99.40000000000003, 25.400000000000006, 26.899999999999984, -1.3000000000000007, -28.29999999999975, 89.59999999999985, -158.50000000000048, 77.8999999999997, 83.30000000000001, 38.00000000000007, 68.6, 39.500000000000014, 26.600000000000122, -96.99999999999999, 20.000000000000014, -127.0000000000006, -135.39999999999992, -38.20000000000002, -7.599999999999973, -29.799999999999983, -71.20000000000005, 20.000000000000014, 8.900000000000007, -86.50000000000001, 17.899999999999988, 20.000000000000014, -139.90000000000003, -36.400000000000034, 20.000000000000014, 82.39999999999998, 20.000000000000014, -63.39999999999998, -44.5, -36.40000000000008, -98.8000000000005, -91.90000000000003, 0.5000000000000071, -10.299999999999999, -99.40000000000016, 28.399999999999956, 117.49999999999994, -112.60000000000002, -72.39999999999999, 65.29999999999995, 22.100000000000072, 20.000000000000014, -286.89999999999986, -17.79999999999994, -81.09999999999997, 163.09999999999997, 200.0, 9.499999999999972, -119.20000000000041, -99.70000000000007, -32.49999999999998, -200.20000000000013, -174.4000000000002, -77.80000000000004, -199.90000000000015, -296.5, -76.30000000000001, -69.70000000000003, -67.60000000000005, -139.90000000000032, -135.40000000000018, 45.800000000000125, 47.300000000000075, -198.40000000000006, 20.000000000000014, -42.400000000000034, -187.30000000000015, -159.4000000000004, -229.59999999999997, 71.89999999999986, -182.19999999999996, 20.000000000000014, -341.4999999999999, -38.2, -187.60000000000025, -197.20000000000002, 21.499999999999982, -171.10000000000005, -195.4000000000001, -260.20000000000005, -226.00000000000009, -351.4999999999998, -186.70000000000002, -95.80000000000041, -154.30000000000038, 20.000000000000014, -11.799999999999983, -18.999999999999975, -143.20000000000016], "policy_predator_policy_reward": [99.0, 43.0, 59.0, 19.0, 137.0, 122.0, 3.0, 89.0, 145.0, 63.0, 51.0, 56.0, 77.0, 55.0, 0.0, 3.0, 48.0, 94.0, 0.0, 0.0, 29.0, 141.0, 115.0, 116.0, 134.0, 1.0, 61.0, 8.0, 82.0, 105.0, 53.0, 54.0, 18.0, 32.0, 63.0, 75.0, 56.0, 132.0, 0.0, 0.0, 137.0, 115.0, 83.0, 108.0, 83.0, 49.0, 65.0, 0.0, 12.0, 38.0, 29.0, 56.0, 0.0, 11.0, 74.0, 100.0, 48.0, 84.0, 23.0, 1.0, 70.0, 0.0, 21.0, 127.0, 72.0, 85.0, 16.0, 65.0, 76.0, 60.0, 95.0, 72.0, 0.0, 8.0, 34.0, 0.0, 53.0, 47.0, 40.0, 82.0, 91.0, 117.0, 69.0, 0.0, 4.0, 91.0, 0.0, 93.0, 27.0, 43.0, 52.0, 42.0, 19.0, 15.0, 31.0, 39.0, 77.0, 32.0, 27.0, 0.0, 58.0, 55.0, 42.0, 0.0, 54.0, 0.0, 79.0, 80.0, 34.0, 24.0, 50.0, 23.0, 46.0, 71.0, 26.0, 18.0, 14.0, 53.0, 34.0, 49.0, 88.0, 22.0, 14.0, 126.0, 71.0, 45.0, 56.0, 63.0, 49.0, 0.0, 35.0, 50.0, 15.0, 79.0, 19.0, 58.0, 10.0, 24.0, 43.0, 76.0, 41.0, 85.0, 6.0, 85.0, 48.0, 55.0, 24.0, 0.0, 52.0, 67.0, 17.0, 37.0, 143.0, 36.0, 33.0, 90.0, 0.0, 0.0, 30.0, 90.0, 89.0, 37.0, 156.0, 29.0, 148.0, 12.0, 56.0, 155.0, 57.0, 14.0, 141.0, 9.0, 47.0, 0.0, 51.0, 98.0, 60.0, 117.0, 99.0, 121.0, 58.0, 86.0, 179.0, 0.0, 16.0, 119.0, 84.0, 53.0, 133.0, 59.0, 150.0, 80.0, 262.0, 69.0, 57.0, 80.0, 0.0, 61.0, 96.0, 44.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6970160858850855, "mean_inference_ms": 1.603606427202192, "mean_action_processing_ms": 0.2788966468000786, "mean_env_wait_ms": 0.21322554630562535, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0042487382888793945, "StateBufferConnector_ms": 0.0034693479537963867, "ViewRequirementAgentConnector_ms": 0.1388871669769287}, "num_episodes": 18, "episode_return_max": 364.5, "episode_return_min": -256.20000000000016, "episode_return_mean": 39.7849999999999, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 208000, "num_agent_steps_trained": 208000, "num_env_steps_sampled": 52000, "num_env_steps_trained": 52000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 78.36701773162555, "num_env_steps_trained_throughput_per_sec": 78.36701773162555, "timesteps_total": 52000, "num_env_steps_sampled_lifetime": 52000, "num_agent_steps_sampled_lifetime": 208000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 208000, "timers": {"training_iteration_time_ms": 51538.078, "restore_workers_time_ms": 0.014, "training_step_time_ms": 51538.039, "sample_time_ms": 1294.674, "learn_time_ms": 50230.337, "learn_throughput": 79.633, "synch_weights_time_ms": 10.801}, "counters": {"num_env_steps_sampled": 52000, "num_env_steps_trained": 52000, "num_agent_steps_sampled": 208000, "num_agent_steps_trained": 208000}, "done": false, "training_iteration": 13, "trial_id": "11e70_00000", "date": "2024-08-12_23-18-17", "timestamp": 1723519097, "time_this_iter_s": 51.083431005477905, "time_total_s": 678.5685369968414, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2ad7f70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 678.5685369968414, "iterations_since_restore": 13, "perf": {"cpu_util_percent": 36.85138888888889, "ram_util_percent": 82.6902777777778}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.82555358946008, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.315834009836591, "policy_loss": -0.008842297830919504, "vf_loss": 4.3230311509793395, "vf_explained_var": 0.06809447808240457, "kl": 0.005483887340452148, "entropy": 1.4820144910030264, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 25515.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.70974660077423, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.503236997695196, "policy_loss": -0.013400433114581993, "vf_loss": 4.514613481299587, "vf_explained_var": -0.1330327207449252, "kl": 0.013492968390438898, "entropy": 1.3928663917319484, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 25515.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 56000, "num_env_steps_trained": 56000, "num_agent_steps_sampled": 224000, "num_agent_steps_trained": 224000}, "env_runners": {"episode_reward_max": 363.1000000000002, "episode_reward_min": -256.20000000000016, "episode_reward_mean": 14.295999999999914, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -351.4999999999998, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 262.0}, "policy_reward_mean": {"prey_policy": -46.68700000000006, "predator_policy": 53.835}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-19.999999999999886, 52.60000000000012, 155.7999999999993, 87.19999999999936, -97.50000000000091, 44.9, 133.0, 40.10000000000027, 78.59999999999991, 31.20000000000018, 25.999999999999993, 90.79999999999997, 102.89999999999988, -12.099999999999874, -35.89999999999967, 175.79999999999998, 48.69999999999985, 27.19999999999999, 147.5, 103.99999999999974, 81.79999999999981, 30.50000000000002, 281.5, 75.90000000000006, 244.59999999999997, 172.3, -11.0, 110.29999999999998, 43.4000000000002, 48.10000000000001, 205.1999999999996, 173.59999999999977, 149.09999999999943, 33.00000000000001, -122.40000000000094, 70.2, 18.0, 77.89999999999995, 16.400000000000254, -25.899999999999928, 60.59999999999994, 136.39999999999938, 11.10000000000003, -9.200000000000214, -0.40000000000011493, -6.699999999999964, 169.89999999999947, -65.99999999999989, 141.39999999999998, -87.90000000000015, 24.099999999999838, 363.1000000000002, 10.300000000000008, -6.199999999999971, -189.60000000000034, -117.70000000000007, -161.79999999999995, -66.29999999999987, -125.30000000000044, 140.09999999999923, -29.39999999999997, -52.69999999999981, -169.00000000000037, 33.69999999999989, -142.50000000000065, -90.79999999999998, -38.69999999999992, -174.50000000000014, -256.20000000000016, -207.20000000000005, -113.10000000000082, 69.19999999999928, -22.199999999999907, -103.30000000000027, 1.899999999999973, -129.60000000000036, -87.60000000000034, 45.700000000000436, -34.699999999999605, 45.50000000000009, 57.800000000000225, -65.6, -179.8000000000002, 10.899999999999938, 69.00000000000004, 23.000000000000057, 36.700000000000294, 79.89999999999911, -48.49999999999976, -31.19999999999964, -86.80000000000064, -115.20000000000005, 29.000000000000256, 66.40000000000019, -25.29999999999979, 40.0000000000003, -23.499999999999872, -10.29999999999997, 27.500000000000124, -42.10000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-29.199999999999925, -164.80000000000024, -17.20000000000003, -62.20000000000002, -17.79999999999974, 149.59999999999988, -127.00000000000051, 144.19999999999968, -9.700000000000038, -235.80000000000047, -86.8000000000003, -25.299999999999997, 26.30000000000001, 25.699999999999996, -115.90000000000018, 20.000000000000014, -82.0, -6.400000000000022, 20.000000000000014, 3.1999999999999704, -3.1000000000000365, -4.900000000000038, 11.900000000000002, -21.099999999999998, -71.2000000000001, 52.10000000000003, -17.500000000000036, -202.60000000000002, 20.000000000000014, -124.90000000000055, -55.900000000000034, 136.6999999999999, -6.699999999999967, -37.600000000000136, -62.80000000000004, 20.000000000000014, 16.70000000000001, 36.80000000000001, 93.49999999999989, -23.500000000000036, -15.699999999999754, 27.500000000000007, -31.29999999999999, -47.19999999999997, 99.19999999999999, 155.29999999999995, -37.30000000000003, 0.1999999999999993, 124.99999999999999, 77.60000000000001, 99.19999999999997, 19.100000000000023, -70.6, -99.40000000000003, 25.400000000000006, 26.899999999999984, -1.3000000000000007, -28.29999999999975, 89.59999999999985, -158.50000000000048, 77.8999999999997, 83.30000000000001, 38.00000000000007, 68.6, 39.500000000000014, 26.600000000000122, -96.99999999999999, 20.000000000000014, -127.0000000000006, -135.39999999999992, -38.20000000000002, -7.599999999999973, -29.799999999999983, -71.20000000000005, 20.000000000000014, 8.900000000000007, -86.50000000000001, 17.899999999999988, 20.000000000000014, -139.90000000000003, -36.400000000000034, 20.000000000000014, 82.39999999999998, 20.000000000000014, -63.39999999999998, -44.5, -36.40000000000008, -98.8000000000005, -91.90000000000003, 0.5000000000000071, -10.299999999999999, -99.40000000000016, 28.399999999999956, 117.49999999999994, -112.60000000000002, -72.39999999999999, 65.29999999999995, 22.100000000000072, 20.000000000000014, -286.89999999999986, -17.79999999999994, -81.09999999999997, 163.09999999999997, 200.0, 9.499999999999972, -119.20000000000041, -99.70000000000007, -32.49999999999998, -200.20000000000013, -174.4000000000002, -77.80000000000004, -199.90000000000015, -296.5, -76.30000000000001, -69.70000000000003, -67.60000000000005, -139.90000000000032, -135.40000000000018, 45.800000000000125, 47.300000000000075, -198.40000000000006, 20.000000000000014, -42.400000000000034, -187.30000000000015, -159.4000000000004, -229.59999999999997, 71.89999999999986, -182.19999999999996, 20.000000000000014, -341.4999999999999, -38.2, -187.60000000000025, -197.20000000000002, 21.499999999999982, -171.10000000000005, -195.4000000000001, -260.20000000000005, -226.00000000000009, -351.4999999999998, -186.70000000000002, -95.80000000000041, -154.30000000000038, 20.000000000000014, -11.799999999999983, -18.999999999999975, -143.20000000000016, -187.30000000000013, -127.0000000000001, -103.60000000000052, 30.500000000000192, -179.20000000000024, -162.4000000000001, -192.1000000000002, -83.50000000000024, -27.400000000000034, 43.10000000000024, 20.000000000000014, -153.70000000000059, -16.59999999999996, -16.899999999999956, 20.000000000000014, 0.7999999999999616, -299.5, 17.899999999999988, -237.10000000000016, -129.70000000000002, -66.10000000000078, 20.000000000000014, 43.700000000000195, -30.699999999999896, -27.999999999999787, 20.000000000000014, 20.000000000000014, 13.699999999999946, 20.000000000000014, 56.9000000000002, -101.80000000000078, -132.70000000000013, -85.00000000000055, -65.20000000000078, -51.99999999999989, -140.80000000000024, -112.60000000000005, -148.60000000000002, 62.30000000000022, -115.3000000000001, -45.699999999999804, 73.09999999999955, 20.000000000000014, -175.30000000000013, 20.000000000000014, 20.000000000000014, -54.399999999999885, -75.10000000000005, 15.79999999999995, -132.10000000000008, -17.499999999999822, -48.999999999999844, -41.79999999999979, -73.30000000000078], "policy_predator_policy_reward": [74.0, 100.0, 48.0, 84.0, 23.0, 1.0, 70.0, 0.0, 21.0, 127.0, 72.0, 85.0, 16.0, 65.0, 76.0, 60.0, 95.0, 72.0, 0.0, 8.0, 34.0, 0.0, 53.0, 47.0, 40.0, 82.0, 91.0, 117.0, 69.0, 0.0, 4.0, 91.0, 0.0, 93.0, 27.0, 43.0, 52.0, 42.0, 19.0, 15.0, 31.0, 39.0, 77.0, 32.0, 27.0, 0.0, 58.0, 55.0, 42.0, 0.0, 54.0, 0.0, 79.0, 80.0, 34.0, 24.0, 50.0, 23.0, 46.0, 71.0, 26.0, 18.0, 14.0, 53.0, 34.0, 49.0, 88.0, 22.0, 14.0, 126.0, 71.0, 45.0, 56.0, 63.0, 49.0, 0.0, 35.0, 50.0, 15.0, 79.0, 19.0, 58.0, 10.0, 24.0, 43.0, 76.0, 41.0, 85.0, 6.0, 85.0, 48.0, 55.0, 24.0, 0.0, 52.0, 67.0, 17.0, 37.0, 143.0, 36.0, 33.0, 90.0, 0.0, 0.0, 30.0, 90.0, 89.0, 37.0, 156.0, 29.0, 148.0, 12.0, 56.0, 155.0, 57.0, 14.0, 141.0, 9.0, 47.0, 0.0, 51.0, 98.0, 60.0, 117.0, 99.0, 121.0, 58.0, 86.0, 179.0, 0.0, 16.0, 119.0, 84.0, 53.0, 133.0, 59.0, 150.0, 80.0, 262.0, 69.0, 57.0, 80.0, 0.0, 61.0, 96.0, 44.0, 112.0, 99.0, 0.0, 75.0, 87.0, 125.0, 48.0, 140.0, 30.0, 0.0, 18.0, 81.0, 0.0, 79.0, 16.0, 21.0, 97.0, 119.0, 148.0, 39.0, 27.0, 30.0, 39.0, 17.0, 0.0, 31.0, 0.0, 3.0, 3.0, 0.0, 105.0, 81.0, 43.0, 76.0, 0.0, 106.0, 79.0, 67.0, 82.0, 0.0, 39.0, 0.0, 32.0, 98.0, 0.0, 0.0, 106.0, 0.0, 51.0, 55.0, 52.0, 42.0, 43.0, 30.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6962458297211767, "mean_inference_ms": 1.595387231872788, "mean_action_processing_ms": 0.2770908704539214, "mean_env_wait_ms": 0.21150305990704057, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004288077354431152, "StateBufferConnector_ms": 0.0034695863723754883, "ViewRequirementAgentConnector_ms": 0.13097012042999268}, "num_episodes": 27, "episode_return_max": 363.1000000000002, "episode_return_min": -256.20000000000016, "episode_return_mean": 14.295999999999914, "episodes_this_iter": 27}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 224000, "num_agent_steps_trained": 224000, "num_env_steps_sampled": 56000, "num_env_steps_trained": 56000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 78.73087260844797, "num_env_steps_trained_throughput_per_sec": 78.73087260844797, "timesteps_total": 56000, "num_env_steps_sampled_lifetime": 56000, "num_agent_steps_sampled_lifetime": 224000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 224000, "timers": {"training_iteration_time_ms": 51369.695, "restore_workers_time_ms": 0.014, "training_step_time_ms": 51369.657, "sample_time_ms": 1291.064, "learn_time_ms": 50065.583, "learn_throughput": 79.895, "synch_weights_time_ms": 10.775}, "counters": {"num_env_steps_sampled": 56000, "num_env_steps_trained": 56000, "num_agent_steps_sampled": 224000, "num_agent_steps_trained": 224000}, "done": false, "training_iteration": 14, "trial_id": "11e70_00000", "date": "2024-08-12_23-19-08", "timestamp": 1723519148, "time_this_iter_s": 50.85865807533264, "time_total_s": 729.4271950721741, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2b62790>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 729.4271950721741, "iterations_since_restore": 14, "perf": {"cpu_util_percent": 36.54305555555556, "ram_util_percent": 82.84444444444443}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.99133393493279, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.9586488838549014, "policy_loss": -0.008324517127836035, "vf_loss": 3.9647595833218285, "vf_explained_var": 0.07347143743404005, "kl": 0.007379393644323356, "entropy": 1.4597272917707131, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 27405.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.5330815423417974, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.5733631219813433, "policy_loss": -0.01314984057837772, "vf_loss": 3.584702283995492, "vf_explained_var": -0.08583066999596893, "kl": 0.012071232296104227, "entropy": 1.3682344270761682, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 27405.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 60000, "num_env_steps_trained": 60000, "num_agent_steps_sampled": 240000, "num_agent_steps_trained": 240000}, "env_runners": {"episode_reward_max": 363.1000000000002, "episode_reward_min": -256.20000000000016, "episode_reward_mean": 6.330999999999917, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -351.4999999999998, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 262.0}, "policy_reward_mean": {"prey_policy": -46.65450000000008, "predator_policy": 49.82}, "custom_metrics": {}, "hist_stats": {"episode_reward": [147.5, 103.99999999999974, 81.79999999999981, 30.50000000000002, 281.5, 75.90000000000006, 244.59999999999997, 172.3, -11.0, 110.29999999999998, 43.4000000000002, 48.10000000000001, 205.1999999999996, 173.59999999999977, 149.09999999999943, 33.00000000000001, -122.40000000000094, 70.2, 18.0, 77.89999999999995, 16.400000000000254, -25.899999999999928, 60.59999999999994, 136.39999999999938, 11.10000000000003, -9.200000000000214, -0.40000000000011493, -6.699999999999964, 169.89999999999947, -65.99999999999989, 141.39999999999998, -87.90000000000015, 24.099999999999838, 363.1000000000002, 10.300000000000008, -6.199999999999971, -189.60000000000034, -117.70000000000007, -161.79999999999995, -66.29999999999987, -125.30000000000044, 140.09999999999923, -29.39999999999997, -52.69999999999981, -169.00000000000037, 33.69999999999989, -142.50000000000065, -90.79999999999998, -38.69999999999992, -174.50000000000014, -256.20000000000016, -207.20000000000005, -113.10000000000082, 69.19999999999928, -22.199999999999907, -103.30000000000027, 1.899999999999973, -129.60000000000036, -87.60000000000034, 45.700000000000436, -34.699999999999605, 45.50000000000009, 57.800000000000225, -65.6, -179.8000000000002, 10.899999999999938, 69.00000000000004, 23.000000000000057, 36.700000000000294, 79.89999999999911, -48.49999999999976, -31.19999999999964, -86.80000000000064, -115.20000000000005, 29.000000000000256, 66.40000000000019, -25.29999999999979, 40.0000000000003, -23.499999999999872, -10.29999999999997, 27.500000000000124, -42.10000000000003, 2.4999999999999396, -19.999999999999673, 37.80000000000026, -4.4999999999997655, 26.6000000000002, 41.40000000000047, -57.40000000000096, -30.499999999999652, 27.60000000000009, 141.69999999999882, -125.2000000000009, 33.20000000000023, 76.49999999999872, -28.899999999999622, 9.099999999999973, -8.299999999999716, -15.499999999999556, 26.700000000000102], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [16.70000000000001, 36.80000000000001, 93.49999999999989, -23.500000000000036, -15.699999999999754, 27.500000000000007, -31.29999999999999, -47.19999999999997, 99.19999999999999, 155.29999999999995, -37.30000000000003, 0.1999999999999993, 124.99999999999999, 77.60000000000001, 99.19999999999997, 19.100000000000023, -70.6, -99.40000000000003, 25.400000000000006, 26.899999999999984, -1.3000000000000007, -28.29999999999975, 89.59999999999985, -158.50000000000048, 77.8999999999997, 83.30000000000001, 38.00000000000007, 68.6, 39.500000000000014, 26.600000000000122, -96.99999999999999, 20.000000000000014, -127.0000000000006, -135.39999999999992, -38.20000000000002, -7.599999999999973, -29.799999999999983, -71.20000000000005, 20.000000000000014, 8.900000000000007, -86.50000000000001, 17.899999999999988, 20.000000000000014, -139.90000000000003, -36.400000000000034, 20.000000000000014, 82.39999999999998, 20.000000000000014, -63.39999999999998, -44.5, -36.40000000000008, -98.8000000000005, -91.90000000000003, 0.5000000000000071, -10.299999999999999, -99.40000000000016, 28.399999999999956, 117.49999999999994, -112.60000000000002, -72.39999999999999, 65.29999999999995, 22.100000000000072, 20.000000000000014, -286.89999999999986, -17.79999999999994, -81.09999999999997, 163.09999999999997, 200.0, 9.499999999999972, -119.20000000000041, -99.70000000000007, -32.49999999999998, -200.20000000000013, -174.4000000000002, -77.80000000000004, -199.90000000000015, -296.5, -76.30000000000001, -69.70000000000003, -67.60000000000005, -139.90000000000032, -135.40000000000018, 45.800000000000125, 47.300000000000075, -198.40000000000006, 20.000000000000014, -42.400000000000034, -187.30000000000015, -159.4000000000004, -229.59999999999997, 71.89999999999986, -182.19999999999996, 20.000000000000014, -341.4999999999999, -38.2, -187.60000000000025, -197.20000000000002, 21.499999999999982, -171.10000000000005, -195.4000000000001, -260.20000000000005, -226.00000000000009, -351.4999999999998, -186.70000000000002, -95.80000000000041, -154.30000000000038, 20.000000000000014, -11.799999999999983, -18.999999999999975, -143.20000000000016, -187.30000000000013, -127.0000000000001, -103.60000000000052, 30.500000000000192, -179.20000000000024, -162.4000000000001, -192.1000000000002, -83.50000000000024, -27.400000000000034, 43.10000000000024, 20.000000000000014, -153.70000000000059, -16.59999999999996, -16.899999999999956, 20.000000000000014, 0.7999999999999616, -299.5, 17.899999999999988, -237.10000000000016, -129.70000000000002, -66.10000000000078, 20.000000000000014, 43.700000000000195, -30.699999999999896, -27.999999999999787, 20.000000000000014, 20.000000000000014, 13.699999999999946, 20.000000000000014, 56.9000000000002, -101.80000000000078, -132.70000000000013, -85.00000000000055, -65.20000000000078, -51.99999999999989, -140.80000000000024, -112.60000000000005, -148.60000000000002, 62.30000000000022, -115.3000000000001, -45.699999999999804, 73.09999999999955, 20.000000000000014, -175.30000000000013, 20.000000000000014, 20.000000000000014, -54.399999999999885, -75.10000000000005, 15.79999999999995, -132.10000000000008, -17.499999999999822, -48.999999999999844, -41.79999999999979, -73.30000000000078, -77.50000000000047, 20.000000000000014, 1.0999999999999865, -93.10000000000058, 15.799999999999958, 20.000000000000014, 20.000000000000014, -107.50000000000075, -9.699999999999903, 5.299999999999976, 16.699999999999996, -7.300000000000004, -56.50000000000015, -64.90000000000052, -23.79999999999979, -99.70000000000051, -24.699999999999797, -15.700000000000038, 121.69999999999955, 20.000000000000014, -148.60000000000048, -106.60000000000039, -7.299999999999976, 24.500000000000085, 24.50000000000009, 7.999999999999725, -92.80000000000067, -21.09999999999978, -77.80000000000021, -57.10000000000036, -109.30000000000078, 20.000000000000014, -89.50000000000082, 20.000000000000014, 20.000000000000014, -19.299999999999763], "policy_predator_policy_reward": [52.0, 42.0, 19.0, 15.0, 31.0, 39.0, 77.0, 32.0, 27.0, 0.0, 58.0, 55.0, 42.0, 0.0, 54.0, 0.0, 79.0, 80.0, 34.0, 24.0, 50.0, 23.0, 46.0, 71.0, 26.0, 18.0, 14.0, 53.0, 34.0, 49.0, 88.0, 22.0, 14.0, 126.0, 71.0, 45.0, 56.0, 63.0, 49.0, 0.0, 35.0, 50.0, 15.0, 79.0, 19.0, 58.0, 10.0, 24.0, 43.0, 76.0, 41.0, 85.0, 6.0, 85.0, 48.0, 55.0, 24.0, 0.0, 52.0, 67.0, 17.0, 37.0, 143.0, 36.0, 33.0, 90.0, 0.0, 0.0, 30.0, 90.0, 89.0, 37.0, 156.0, 29.0, 148.0, 12.0, 56.0, 155.0, 57.0, 14.0, 141.0, 9.0, 47.0, 0.0, 51.0, 98.0, 60.0, 117.0, 99.0, 121.0, 58.0, 86.0, 179.0, 0.0, 16.0, 119.0, 84.0, 53.0, 133.0, 59.0, 150.0, 80.0, 262.0, 69.0, 57.0, 80.0, 0.0, 61.0, 96.0, 44.0, 112.0, 99.0, 0.0, 75.0, 87.0, 125.0, 48.0, 140.0, 30.0, 0.0, 18.0, 81.0, 0.0, 79.0, 16.0, 21.0, 97.0, 119.0, 148.0, 39.0, 27.0, 30.0, 39.0, 17.0, 0.0, 31.0, 0.0, 3.0, 3.0, 0.0, 105.0, 81.0, 43.0, 76.0, 0.0, 106.0, 79.0, 67.0, 82.0, 0.0, 39.0, 0.0, 32.0, 98.0, 0.0, 0.0, 106.0, 0.0, 51.0, 55.0, 52.0, 42.0, 43.0, 30.0, 32.0, 28.0, 32.0, 40.0, 2.0, 0.0, 26.0, 57.0, 0.0, 31.0, 24.0, 8.0, 0.0, 64.0, 77.0, 16.0, 52.0, 16.0, 0.0, 0.0, 104.0, 26.0, 13.0, 3.0, 37.0, 7.0, 72.0, 13.0, 61.0, 83.0, 44.0, 37.0, 42.0, 12.0, 23.0, 3.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6942386434291996, "mean_inference_ms": 1.5935893003496553, "mean_action_processing_ms": 0.2759123134999106, "mean_env_wait_ms": 0.21070932025992622, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003920793533325195, "StateBufferConnector_ms": 0.0031931400299072266, "ViewRequirementAgentConnector_ms": 0.12668859958648682}, "num_episodes": 18, "episode_return_max": 363.1000000000002, "episode_return_min": -256.20000000000016, "episode_return_mean": 6.330999999999917, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 240000, "num_agent_steps_trained": 240000, "num_env_steps_sampled": 60000, "num_env_steps_trained": 60000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 78.6780760241496, "num_env_steps_trained_throughput_per_sec": 78.6780760241496, "timesteps_total": 60000, "num_env_steps_sampled_lifetime": 60000, "num_agent_steps_sampled_lifetime": 240000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 240000, "timers": {"training_iteration_time_ms": 51082.888, "restore_workers_time_ms": 0.014, "training_step_time_ms": 51082.847, "sample_time_ms": 1245.733, "learn_time_ms": 49823.552, "learn_throughput": 80.283, "synch_weights_time_ms": 10.912}, "counters": {"num_env_steps_sampled": 60000, "num_env_steps_trained": 60000, "num_agent_steps_sampled": 240000, "num_agent_steps_trained": 240000}, "done": false, "training_iteration": 15, "trial_id": "11e70_00000", "date": "2024-08-12_23-19-59", "timestamp": 1723519199, "time_this_iter_s": 50.87677311897278, "time_total_s": 780.3039681911469, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2b67ee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 780.3039681911469, "iterations_since_restore": 15, "perf": {"cpu_util_percent": 36.18630136986302, "ram_util_percent": 83.1027397260274}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.470429028909673, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.2052463024381606, "policy_loss": -0.006865057557643879, "vf_loss": 2.210643921895002, "vf_explained_var": 0.07306507460023991, "kl": 0.004891469472169688, "entropy": 1.4522614054578953, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 29295.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.9363689737975913, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.279902364526476, "policy_loss": -0.00988815017019906, "vf_loss": 2.288565153167361, "vf_explained_var": -0.08042743092491514, "kl": 0.008169073080028986, "entropy": 1.352583820416183, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 29295.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 64000, "num_env_steps_trained": 64000, "num_agent_steps_sampled": 256000, "num_agent_steps_trained": 256000}, "env_runners": {"episode_reward_max": 363.1000000000002, "episode_reward_min": -256.20000000000016, "episode_reward_mean": -11.230000000000057, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -351.4999999999998, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 262.0}, "policy_reward_mean": {"prey_policy": -53.115000000000094, "predator_policy": 47.5}, "custom_metrics": {}, "hist_stats": {"episode_reward": [18.0, 77.89999999999995, 16.400000000000254, -25.899999999999928, 60.59999999999994, 136.39999999999938, 11.10000000000003, -9.200000000000214, -0.40000000000011493, -6.699999999999964, 169.89999999999947, -65.99999999999989, 141.39999999999998, -87.90000000000015, 24.099999999999838, 363.1000000000002, 10.300000000000008, -6.199999999999971, -189.60000000000034, -117.70000000000007, -161.79999999999995, -66.29999999999987, -125.30000000000044, 140.09999999999923, -29.39999999999997, -52.69999999999981, -169.00000000000037, 33.69999999999989, -142.50000000000065, -90.79999999999998, -38.69999999999992, -174.50000000000014, -256.20000000000016, -207.20000000000005, -113.10000000000082, 69.19999999999928, -22.199999999999907, -103.30000000000027, 1.899999999999973, -129.60000000000036, -87.60000000000034, 45.700000000000436, -34.699999999999605, 45.50000000000009, 57.800000000000225, -65.6, -179.8000000000002, 10.899999999999938, 69.00000000000004, 23.000000000000057, 36.700000000000294, 79.89999999999911, -48.49999999999976, -31.19999999999964, -86.80000000000064, -115.20000000000005, 29.000000000000256, 66.40000000000019, -25.29999999999979, 40.0000000000003, -23.499999999999872, -10.29999999999997, 27.500000000000124, -42.10000000000003, 2.4999999999999396, -19.999999999999673, 37.80000000000026, -4.4999999999997655, 26.6000000000002, 41.40000000000047, -57.40000000000096, -30.499999999999652, 27.60000000000009, 141.69999999999882, -125.2000000000009, 33.20000000000023, 76.49999999999872, -28.899999999999622, 9.099999999999973, -8.299999999999716, -15.499999999999556, 26.700000000000102, 9.00000000000005, 39.10000000000041, 68.60000000000014, -105.20000000000104, 43.80000000000043, -6.299999999999816, -22.599999999999554, -2.8999999999998227, -97.00000000000117, 58.000000000000355, 40.0000000000003, 10.299999999999955, 62.10000000000045, 40.0000000000003, -111.10000000000146, 23.100000000000126, -7.399999999999904, 40.0000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-29.799999999999983, -71.20000000000005, 20.000000000000014, 8.900000000000007, -86.50000000000001, 17.899999999999988, 20.000000000000014, -139.90000000000003, -36.400000000000034, 20.000000000000014, 82.39999999999998, 20.000000000000014, -63.39999999999998, -44.5, -36.40000000000008, -98.8000000000005, -91.90000000000003, 0.5000000000000071, -10.299999999999999, -99.40000000000016, 28.399999999999956, 117.49999999999994, -112.60000000000002, -72.39999999999999, 65.29999999999995, 22.100000000000072, 20.000000000000014, -286.89999999999986, -17.79999999999994, -81.09999999999997, 163.09999999999997, 200.0, 9.499999999999972, -119.20000000000041, -99.70000000000007, -32.49999999999998, -200.20000000000013, -174.4000000000002, -77.80000000000004, -199.90000000000015, -296.5, -76.30000000000001, -69.70000000000003, -67.60000000000005, -139.90000000000032, -135.40000000000018, 45.800000000000125, 47.300000000000075, -198.40000000000006, 20.000000000000014, -42.400000000000034, -187.30000000000015, -159.4000000000004, -229.59999999999997, 71.89999999999986, -182.19999999999996, 20.000000000000014, -341.4999999999999, -38.2, -187.60000000000025, -197.20000000000002, 21.499999999999982, -171.10000000000005, -195.4000000000001, -260.20000000000005, -226.00000000000009, -351.4999999999998, -186.70000000000002, -95.80000000000041, -154.30000000000038, 20.000000000000014, -11.799999999999983, -18.999999999999975, -143.20000000000016, -187.30000000000013, -127.0000000000001, -103.60000000000052, 30.500000000000192, -179.20000000000024, -162.4000000000001, -192.1000000000002, -83.50000000000024, -27.400000000000034, 43.10000000000024, 20.000000000000014, -153.70000000000059, -16.59999999999996, -16.899999999999956, 20.000000000000014, 0.7999999999999616, -299.5, 17.899999999999988, -237.10000000000016, -129.70000000000002, -66.10000000000078, 20.000000000000014, 43.700000000000195, -30.699999999999896, -27.999999999999787, 20.000000000000014, 20.000000000000014, 13.699999999999946, 20.000000000000014, 56.9000000000002, -101.80000000000078, -132.70000000000013, -85.00000000000055, -65.20000000000078, -51.99999999999989, -140.80000000000024, -112.60000000000005, -148.60000000000002, 62.30000000000022, -115.3000000000001, -45.699999999999804, 73.09999999999955, 20.000000000000014, -175.30000000000013, 20.000000000000014, 20.000000000000014, -54.399999999999885, -75.10000000000005, 15.79999999999995, -132.10000000000008, -17.499999999999822, -48.999999999999844, -41.79999999999979, -73.30000000000078, -77.50000000000047, 20.000000000000014, 1.0999999999999865, -93.10000000000058, 15.799999999999958, 20.000000000000014, 20.000000000000014, -107.50000000000075, -9.699999999999903, 5.299999999999976, 16.699999999999996, -7.300000000000004, -56.50000000000015, -64.90000000000052, -23.79999999999979, -99.70000000000051, -24.699999999999797, -15.700000000000038, 121.69999999999955, 20.000000000000014, -148.60000000000048, -106.60000000000039, -7.299999999999976, 24.500000000000085, 24.50000000000009, 7.999999999999725, -92.80000000000067, -21.09999999999978, -77.80000000000021, -57.10000000000036, -109.30000000000078, 20.000000000000014, -89.50000000000082, 20.000000000000014, 20.000000000000014, -19.299999999999763, -79.00000000000085, 20.000000000000014, 21.50000000000004, -66.40000000000067, 20.000000000000014, 38.60000000000021, 20.000000000000014, -257.1999999999996, -5.1999999999999975, 20.000000000000014, -26.199999999999825, -45.09999999999976, -56.80000000000041, -17.799999999999784, -35.1999999999998, -12.699999999999864, -155.8000000000006, -50.19999999999986, -27.699999999999783, -4.300000000000033, 20.000000000000014, 20.000000000000014, 15.799999999999946, -65.50000000000087, 20.000000000000014, 16.09999999999996, 20.000000000000014, 20.000000000000014, -53.80000000000018, -196.30000000000055, 20.000000000000014, -31.8999999999998, -42.99999999999985, -66.40000000000035, 20.000000000000014, 20.000000000000014], "policy_predator_policy_reward": [56.0, 63.0, 49.0, 0.0, 35.0, 50.0, 15.0, 79.0, 19.0, 58.0, 10.0, 24.0, 43.0, 76.0, 41.0, 85.0, 6.0, 85.0, 48.0, 55.0, 24.0, 0.0, 52.0, 67.0, 17.0, 37.0, 143.0, 36.0, 33.0, 90.0, 0.0, 0.0, 30.0, 90.0, 89.0, 37.0, 156.0, 29.0, 148.0, 12.0, 56.0, 155.0, 57.0, 14.0, 141.0, 9.0, 47.0, 0.0, 51.0, 98.0, 60.0, 117.0, 99.0, 121.0, 58.0, 86.0, 179.0, 0.0, 16.0, 119.0, 84.0, 53.0, 133.0, 59.0, 150.0, 80.0, 262.0, 69.0, 57.0, 80.0, 0.0, 61.0, 96.0, 44.0, 112.0, 99.0, 0.0, 75.0, 87.0, 125.0, 48.0, 140.0, 30.0, 0.0, 18.0, 81.0, 0.0, 79.0, 16.0, 21.0, 97.0, 119.0, 148.0, 39.0, 27.0, 30.0, 39.0, 17.0, 0.0, 31.0, 0.0, 3.0, 3.0, 0.0, 105.0, 81.0, 43.0, 76.0, 0.0, 106.0, 79.0, 67.0, 82.0, 0.0, 39.0, 0.0, 32.0, 98.0, 0.0, 0.0, 106.0, 0.0, 51.0, 55.0, 52.0, 42.0, 43.0, 30.0, 32.0, 28.0, 32.0, 40.0, 2.0, 0.0, 26.0, 57.0, 0.0, 31.0, 24.0, 8.0, 0.0, 64.0, 77.0, 16.0, 52.0, 16.0, 0.0, 0.0, 104.0, 26.0, 13.0, 3.0, 37.0, 7.0, 72.0, 13.0, 61.0, 83.0, 44.0, 37.0, 42.0, 12.0, 23.0, 3.0, 48.0, 20.0, 47.0, 37.0, 9.0, 1.0, 0.0, 132.0, 24.0, 5.0, 61.0, 4.0, 47.0, 5.0, 26.0, 19.0, 75.0, 34.0, 37.0, 53.0, 0.0, 0.0, 33.0, 27.0, 16.0, 10.0, 0.0, 0.0, 103.0, 36.0, 0.0, 35.0, 76.0, 26.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6953980276087143, "mean_inference_ms": 1.595530683112606, "mean_action_processing_ms": 0.2756106812757774, "mean_env_wait_ms": 0.2101755411838456, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003554224967956543, "StateBufferConnector_ms": 0.0032063722610473633, "ViewRequirementAgentConnector_ms": 0.1344691514968872}, "num_episodes": 18, "episode_return_max": 363.1000000000002, "episode_return_min": -256.20000000000016, "episode_return_mean": -11.230000000000057, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 256000, "num_agent_steps_trained": 256000, "num_env_steps_sampled": 64000, "num_env_steps_trained": 64000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 77.37965254045355, "num_env_steps_trained_throughput_per_sec": 77.37965254045355, "timesteps_total": 64000, "num_env_steps_sampled_lifetime": 64000, "num_agent_steps_sampled_lifetime": 256000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 256000, "timers": {"training_iteration_time_ms": 51019.83, "restore_workers_time_ms": 0.014, "training_step_time_ms": 51019.789, "sample_time_ms": 1279.079, "learn_time_ms": 49727.174, "learn_throughput": 80.439, "synch_weights_time_ms": 10.831}, "counters": {"num_env_steps_sampled": 64000, "num_env_steps_trained": 64000, "num_agent_steps_sampled": 256000, "num_agent_steps_trained": 256000}, "done": false, "training_iteration": 16, "trial_id": "11e70_00000", "date": "2024-08-12_23-20-51", "timestamp": 1723519251, "time_this_iter_s": 51.77526617050171, "time_total_s": 832.0792343616486, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2ad7160>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 832.0792343616486, "iterations_since_restore": 16, "perf": {"cpu_util_percent": 39.4013698630137, "ram_util_percent": 82.94109589041096}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.276975890063735, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.376730472354031, "policy_loss": -0.010202336851655254, "vf_loss": 1.3854872223561403, "vf_explained_var": 0.07257088485848967, "kl": 0.009637220152323064, "entropy": 1.4313138283749738, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 31185.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.267815005116993, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.4556568734071873, "policy_loss": -0.010702973865982755, "vf_loss": 1.4654136698712747, "vf_explained_var": -0.08456561808232908, "kl": 0.006307855746230676, "entropy": 1.3816729927819873, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 31185.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 68000, "num_env_steps_trained": 68000, "num_agent_steps_sampled": 272000, "num_agent_steps_trained": 272000}, "env_runners": {"episode_reward_max": 141.69999999999882, "episode_reward_min": -256.20000000000016, "episode_reward_mean": -16.316000000000034, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -351.4999999999998, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 121.69999999999955, "predator_policy": 262.0}, "policy_reward_mean": {"prey_policy": -50.253000000000085, "predator_policy": 42.095}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-189.60000000000034, -117.70000000000007, -161.79999999999995, -66.29999999999987, -125.30000000000044, 140.09999999999923, -29.39999999999997, -52.69999999999981, -169.00000000000037, 33.69999999999989, -142.50000000000065, -90.79999999999998, -38.69999999999992, -174.50000000000014, -256.20000000000016, -207.20000000000005, -113.10000000000082, 69.19999999999928, -22.199999999999907, -103.30000000000027, 1.899999999999973, -129.60000000000036, -87.60000000000034, 45.700000000000436, -34.699999999999605, 45.50000000000009, 57.800000000000225, -65.6, -179.8000000000002, 10.899999999999938, 69.00000000000004, 23.000000000000057, 36.700000000000294, 79.89999999999911, -48.49999999999976, -31.19999999999964, -86.80000000000064, -115.20000000000005, 29.000000000000256, 66.40000000000019, -25.29999999999979, 40.0000000000003, -23.499999999999872, -10.29999999999997, 27.500000000000124, -42.10000000000003, 2.4999999999999396, -19.999999999999673, 37.80000000000026, -4.4999999999997655, 26.6000000000002, 41.40000000000047, -57.40000000000096, -30.499999999999652, 27.60000000000009, 141.69999999999882, -125.2000000000009, 33.20000000000023, 76.49999999999872, -28.899999999999622, 9.099999999999973, -8.299999999999716, -15.499999999999556, 26.700000000000102, 9.00000000000005, 39.10000000000041, 68.60000000000014, -105.20000000000104, 43.80000000000043, -6.299999999999816, -22.599999999999554, -2.8999999999998227, -97.00000000000117, 58.000000000000355, 40.0000000000003, 10.299999999999955, 62.10000000000045, 40.0000000000003, -111.10000000000146, 23.100000000000126, -7.399999999999904, 40.0000000000003, 14.099999999999953, -2.299999999999865, 57.50000000000047, 22.400000000000013, 22.50000000000007, 40.0000000000003, 4.89999999999994, 40.0000000000003, 40.0000000000003, 33.90000000000021, 24.100000000000172, 2.200000000000201, -68.0000000000017, 37.800000000000296, 24.500000000000103, 4.500000000000108, 36.50000000000025, -16.299999999999677], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-200.20000000000013, -174.4000000000002, -77.80000000000004, -199.90000000000015, -296.5, -76.30000000000001, -69.70000000000003, -67.60000000000005, -139.90000000000032, -135.40000000000018, 45.800000000000125, 47.300000000000075, -198.40000000000006, 20.000000000000014, -42.400000000000034, -187.30000000000015, -159.4000000000004, -229.59999999999997, 71.89999999999986, -182.19999999999996, 20.000000000000014, -341.4999999999999, -38.2, -187.60000000000025, -197.20000000000002, 21.499999999999982, -171.10000000000005, -195.4000000000001, -260.20000000000005, -226.00000000000009, -351.4999999999998, -186.70000000000002, -95.80000000000041, -154.30000000000038, 20.000000000000014, -11.799999999999983, -18.999999999999975, -143.20000000000016, -187.30000000000013, -127.0000000000001, -103.60000000000052, 30.500000000000192, -179.20000000000024, -162.4000000000001, -192.1000000000002, -83.50000000000024, -27.400000000000034, 43.10000000000024, 20.000000000000014, -153.70000000000059, -16.59999999999996, -16.899999999999956, 20.000000000000014, 0.7999999999999616, -299.5, 17.899999999999988, -237.10000000000016, -129.70000000000002, -66.10000000000078, 20.000000000000014, 43.700000000000195, -30.699999999999896, -27.999999999999787, 20.000000000000014, 20.000000000000014, 13.699999999999946, 20.000000000000014, 56.9000000000002, -101.80000000000078, -132.70000000000013, -85.00000000000055, -65.20000000000078, -51.99999999999989, -140.80000000000024, -112.60000000000005, -148.60000000000002, 62.30000000000022, -115.3000000000001, -45.699999999999804, 73.09999999999955, 20.000000000000014, -175.30000000000013, 20.000000000000014, 20.000000000000014, -54.399999999999885, -75.10000000000005, 15.79999999999995, -132.10000000000008, -17.499999999999822, -48.999999999999844, -41.79999999999979, -73.30000000000078, -77.50000000000047, 20.000000000000014, 1.0999999999999865, -93.10000000000058, 15.799999999999958, 20.000000000000014, 20.000000000000014, -107.50000000000075, -9.699999999999903, 5.299999999999976, 16.699999999999996, -7.300000000000004, -56.50000000000015, -64.90000000000052, -23.79999999999979, -99.70000000000051, -24.699999999999797, -15.700000000000038, 121.69999999999955, 20.000000000000014, -148.60000000000048, -106.60000000000039, -7.299999999999976, 24.500000000000085, 24.50000000000009, 7.999999999999725, -92.80000000000067, -21.09999999999978, -77.80000000000021, -57.10000000000036, -109.30000000000078, 20.000000000000014, -89.50000000000082, 20.000000000000014, 20.000000000000014, -19.299999999999763, -79.00000000000085, 20.000000000000014, 21.50000000000004, -66.40000000000067, 20.000000000000014, 38.60000000000021, 20.000000000000014, -257.1999999999996, -5.1999999999999975, 20.000000000000014, -26.199999999999825, -45.09999999999976, -56.80000000000041, -17.799999999999784, -35.1999999999998, -12.699999999999864, -155.8000000000006, -50.19999999999986, -27.699999999999783, -4.300000000000033, 20.000000000000014, 20.000000000000014, 15.799999999999946, -65.50000000000087, 20.000000000000014, 16.09999999999996, 20.000000000000014, 20.000000000000014, -53.80000000000018, -196.30000000000055, 20.000000000000014, -31.8999999999998, -42.99999999999985, -66.40000000000035, 20.000000000000014, 20.000000000000014, -31.899999999999757, 20.000000000000014, -5.49999999999994, -59.800000000000395, 20.000000000000014, 3.499999999999978, 20.000000000000014, -13.599999999999783, 17.29999999999997, -14.799999999999779, 20.000000000000014, 20.000000000000014, 18.19999999999997, -49.299999999999876, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -24.09999999999976, 20.000000000000014, -97.59999999999997, 37.70000000000018, -49.299999999999905, 15.499999999999964, -46.29999999999978, -78.70000000000081, 15.799999999999946, 20.000000000000014, 20.000000000000014, -41.49999999999984, 15.799999999999963, -49.29999999999977, 11.599999999999964, 20.900000000000027, -97.3000000000006, 20.000000000000014], "policy_predator_policy_reward": [156.0, 29.0, 148.0, 12.0, 56.0, 155.0, 57.0, 14.0, 141.0, 9.0, 47.0, 0.0, 51.0, 98.0, 60.0, 117.0, 99.0, 121.0, 58.0, 86.0, 179.0, 0.0, 16.0, 119.0, 84.0, 53.0, 133.0, 59.0, 150.0, 80.0, 262.0, 69.0, 57.0, 80.0, 0.0, 61.0, 96.0, 44.0, 112.0, 99.0, 0.0, 75.0, 87.0, 125.0, 48.0, 140.0, 30.0, 0.0, 18.0, 81.0, 0.0, 79.0, 16.0, 21.0, 97.0, 119.0, 148.0, 39.0, 27.0, 30.0, 39.0, 17.0, 0.0, 31.0, 0.0, 3.0, 3.0, 0.0, 105.0, 81.0, 43.0, 76.0, 0.0, 106.0, 79.0, 67.0, 82.0, 0.0, 39.0, 0.0, 32.0, 98.0, 0.0, 0.0, 106.0, 0.0, 51.0, 55.0, 52.0, 42.0, 43.0, 30.0, 32.0, 28.0, 32.0, 40.0, 2.0, 0.0, 26.0, 57.0, 0.0, 31.0, 24.0, 8.0, 0.0, 64.0, 77.0, 16.0, 52.0, 16.0, 0.0, 0.0, 104.0, 26.0, 13.0, 3.0, 37.0, 7.0, 72.0, 13.0, 61.0, 83.0, 44.0, 37.0, 42.0, 12.0, 23.0, 3.0, 48.0, 20.0, 47.0, 37.0, 9.0, 1.0, 0.0, 132.0, 24.0, 5.0, 61.0, 4.0, 47.0, 5.0, 26.0, 19.0, 75.0, 34.0, 37.0, 53.0, 0.0, 0.0, 33.0, 27.0, 16.0, 10.0, 0.0, 0.0, 103.0, 36.0, 0.0, 35.0, 76.0, 26.0, 0.0, 0.0, 21.0, 5.0, 55.0, 8.0, 18.0, 16.0, 0.0, 16.0, 20.0, 0.0, 0.0, 0.0, 0.0, 36.0, 0.0, 0.0, 0.0, 0.0, 15.0, 23.0, 67.0, 17.0, 3.0, 33.0, 52.0, 5.0, 0.0, 2.0, 2.0, 44.0, 8.0, 30.0, 0.0, 4.0, 0.0, 61.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6960633152240991, "mean_inference_ms": 1.595076161552468, "mean_action_processing_ms": 0.27516092388122987, "mean_env_wait_ms": 0.20924999548773626, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0036525726318359375, "StateBufferConnector_ms": 0.0037440061569213867, "ViewRequirementAgentConnector_ms": 0.13515961170196533}, "num_episodes": 18, "episode_return_max": 141.69999999999882, "episode_return_min": -256.20000000000016, "episode_return_mean": -16.316000000000034, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 272000, "num_agent_steps_trained": 272000, "num_env_steps_sampled": 68000, "num_env_steps_trained": 68000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 79.07370045316655, "num_env_steps_trained_throughput_per_sec": 79.07370045316655, "timesteps_total": 68000, "num_env_steps_sampled_lifetime": 68000, "num_agent_steps_sampled_lifetime": 272000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 272000, "timers": {"training_iteration_time_ms": 50965.887, "restore_workers_time_ms": 0.014, "training_step_time_ms": 50965.846, "sample_time_ms": 1263.082, "learn_time_ms": 49689.233, "learn_throughput": 80.5, "synch_weights_time_ms": 10.759}, "counters": {"num_env_steps_sampled": 68000, "num_env_steps_trained": 68000, "num_agent_steps_sampled": 272000, "num_agent_steps_trained": 272000}, "done": false, "training_iteration": 17, "trial_id": "11e70_00000", "date": "2024-08-12_23-21-42", "timestamp": 1723519302, "time_this_iter_s": 50.631877183914185, "time_total_s": 882.7111115455627, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2b15670>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 882.7111115455627, "iterations_since_restore": 17, "perf": {"cpu_util_percent": 35.34583333333333, "ram_util_percent": 82.85000000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.841540192170118, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.271326809206968, "policy_loss": -0.01257770596954124, "vf_loss": 2.2824233923008834, "vf_explained_var": 0.08182751895889404, "kl": 0.009874178566027177, "entropy": 1.4425862865473227, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 33075.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.340320845444997, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.345103060253083, "policy_loss": -0.010025153241598259, "vf_loss": 3.3536484582714303, "vf_explained_var": 0.0450013537570913, "kl": 0.009865034348209836, "entropy": 1.4339518030484517, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 33075.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 72000, "num_env_steps_trained": 72000, "num_agent_steps_sampled": 288000, "num_agent_steps_trained": 288000}, "env_runners": {"episode_reward_max": 141.69999999999882, "episode_reward_min": -342.70000000000016, "episode_reward_mean": 6.360000000000027, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -299.5, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 121.69999999999955, "predator_policy": 170.0}, "policy_reward_mean": {"prey_policy": -26.200000000000074, "predator_policy": 29.38}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-87.60000000000034, 45.700000000000436, -34.699999999999605, 45.50000000000009, 57.800000000000225, -65.6, -179.8000000000002, 10.899999999999938, 69.00000000000004, 23.000000000000057, 36.700000000000294, 79.89999999999911, -48.49999999999976, -31.19999999999964, -86.80000000000064, -115.20000000000005, 29.000000000000256, 66.40000000000019, -25.29999999999979, 40.0000000000003, -23.499999999999872, -10.29999999999997, 27.500000000000124, -42.10000000000003, 2.4999999999999396, -19.999999999999673, 37.80000000000026, -4.4999999999997655, 26.6000000000002, 41.40000000000047, -57.40000000000096, -30.499999999999652, 27.60000000000009, 141.69999999999882, -125.2000000000009, 33.20000000000023, 76.49999999999872, -28.899999999999622, 9.099999999999973, -8.299999999999716, -15.499999999999556, 26.700000000000102, 9.00000000000005, 39.10000000000041, 68.60000000000014, -105.20000000000104, 43.80000000000043, -6.299999999999816, -22.599999999999554, -2.8999999999998227, -97.00000000000117, 58.000000000000355, 40.0000000000003, 10.299999999999955, 62.10000000000045, 40.0000000000003, -111.10000000000146, 23.100000000000126, -7.399999999999904, 40.0000000000003, 14.099999999999953, -2.299999999999865, 57.50000000000047, 22.400000000000013, 22.50000000000007, 40.0000000000003, 4.89999999999994, 40.0000000000003, 40.0000000000003, 33.90000000000021, 24.100000000000172, 2.200000000000201, -68.0000000000017, 37.800000000000296, 24.500000000000103, 4.500000000000108, 36.50000000000025, -16.299999999999677, 15.699999999999948, -28.399999999999594, 116.49999999999879, 40.900000000000475, -5.999999999999815, 68.59999999999962, -10.499999999999652, -342.70000000000016, 71.1000000000002, 59.200000000000436, 52.900000000000134, 35.80000000000039, 8.00000000000006, 92.1999999999994, -27.699999999999655, 32.40000000000018, 40.90000000000031, -86.20000000000098, 5.000000000000092, 51.70000000000049, 40.0000000000003, 93.19999999999995], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-192.1000000000002, -83.50000000000024, -27.400000000000034, 43.10000000000024, 20.000000000000014, -153.70000000000059, -16.59999999999996, -16.899999999999956, 20.000000000000014, 0.7999999999999616, -299.5, 17.899999999999988, -237.10000000000016, -129.70000000000002, -66.10000000000078, 20.000000000000014, 43.700000000000195, -30.699999999999896, -27.999999999999787, 20.000000000000014, 20.000000000000014, 13.699999999999946, 20.000000000000014, 56.9000000000002, -101.80000000000078, -132.70000000000013, -85.00000000000055, -65.20000000000078, -51.99999999999989, -140.80000000000024, -112.60000000000005, -148.60000000000002, 62.30000000000022, -115.3000000000001, -45.699999999999804, 73.09999999999955, 20.000000000000014, -175.30000000000013, 20.000000000000014, 20.000000000000014, -54.399999999999885, -75.10000000000005, 15.79999999999995, -132.10000000000008, -17.499999999999822, -48.999999999999844, -41.79999999999979, -73.30000000000078, -77.50000000000047, 20.000000000000014, 1.0999999999999865, -93.10000000000058, 15.799999999999958, 20.000000000000014, 20.000000000000014, -107.50000000000075, -9.699999999999903, 5.299999999999976, 16.699999999999996, -7.300000000000004, -56.50000000000015, -64.90000000000052, -23.79999999999979, -99.70000000000051, -24.699999999999797, -15.700000000000038, 121.69999999999955, 20.000000000000014, -148.60000000000048, -106.60000000000039, -7.299999999999976, 24.500000000000085, 24.50000000000009, 7.999999999999725, -92.80000000000067, -21.09999999999978, -77.80000000000021, -57.10000000000036, -109.30000000000078, 20.000000000000014, -89.50000000000082, 20.000000000000014, 20.000000000000014, -19.299999999999763, -79.00000000000085, 20.000000000000014, 21.50000000000004, -66.40000000000067, 20.000000000000014, 38.60000000000021, 20.000000000000014, -257.1999999999996, -5.1999999999999975, 20.000000000000014, -26.199999999999825, -45.09999999999976, -56.80000000000041, -17.799999999999784, -35.1999999999998, -12.699999999999864, -155.8000000000006, -50.19999999999986, -27.699999999999783, -4.300000000000033, 20.000000000000014, 20.000000000000014, 15.799999999999946, -65.50000000000087, 20.000000000000014, 16.09999999999996, 20.000000000000014, 20.000000000000014, -53.80000000000018, -196.30000000000055, 20.000000000000014, -31.8999999999998, -42.99999999999985, -66.40000000000035, 20.000000000000014, 20.000000000000014, -31.899999999999757, 20.000000000000014, -5.49999999999994, -59.800000000000395, 20.000000000000014, 3.499999999999978, 20.000000000000014, -13.599999999999783, 17.29999999999997, -14.799999999999779, 20.000000000000014, 20.000000000000014, 18.19999999999997, -49.299999999999876, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -24.09999999999976, 20.000000000000014, -97.59999999999997, 37.70000000000018, -49.299999999999905, 15.499999999999964, -46.29999999999978, -78.70000000000081, 15.799999999999946, 20.000000000000014, 20.000000000000014, -41.49999999999984, 15.799999999999963, -49.29999999999977, 11.599999999999964, 20.900000000000027, -97.3000000000006, 20.000000000000014, -8.199999999999902, -3.099999999999958, -42.999999999999766, -66.4000000000006, 20.000000000000014, 96.49999999999949, 1.0999999999999723, 24.800000000000093, 20.000000000000014, -88.00000000000065, -21.399999999999935, 29.000000000000163, -32.199999999999775, -37.299999999999784, -297.10000000000025, -277.60000000000014, 14.599999999999962, 18.500000000000156, 39.8000000000002, 7.399999999999984, 8.599999999999984, -30.700000000000244, -5.200000000000047, 29.00000000000015, -64.00000000000085, 20.000000000000014, 72.19999999999987, 20.000000000000014, -168.10000000000062, 40.40000000000019, 15.799999999999963, 11.599999999999964, 20.000000000000014, 20.90000000000003, -47.199999999999775, -157.0000000000004, 20.000000000000014, -55.00000000000021, 31.700000000000212, 20.000000000000014, 20.000000000000014, 20.000000000000014, -26.199999999999754, 97.39999999999966], "policy_predator_policy_reward": [48.0, 140.0, 30.0, 0.0, 18.0, 81.0, 0.0, 79.0, 16.0, 21.0, 97.0, 119.0, 148.0, 39.0, 27.0, 30.0, 39.0, 17.0, 0.0, 31.0, 0.0, 3.0, 3.0, 0.0, 105.0, 81.0, 43.0, 76.0, 0.0, 106.0, 79.0, 67.0, 82.0, 0.0, 39.0, 0.0, 32.0, 98.0, 0.0, 0.0, 106.0, 0.0, 51.0, 55.0, 52.0, 42.0, 43.0, 30.0, 32.0, 28.0, 32.0, 40.0, 2.0, 0.0, 26.0, 57.0, 0.0, 31.0, 24.0, 8.0, 0.0, 64.0, 77.0, 16.0, 52.0, 16.0, 0.0, 0.0, 104.0, 26.0, 13.0, 3.0, 37.0, 7.0, 72.0, 13.0, 61.0, 83.0, 44.0, 37.0, 42.0, 12.0, 23.0, 3.0, 48.0, 20.0, 47.0, 37.0, 9.0, 1.0, 0.0, 132.0, 24.0, 5.0, 61.0, 4.0, 47.0, 5.0, 26.0, 19.0, 75.0, 34.0, 37.0, 53.0, 0.0, 0.0, 33.0, 27.0, 16.0, 10.0, 0.0, 0.0, 103.0, 36.0, 0.0, 35.0, 76.0, 26.0, 0.0, 0.0, 21.0, 5.0, 55.0, 8.0, 18.0, 16.0, 0.0, 16.0, 20.0, 0.0, 0.0, 0.0, 0.0, 36.0, 0.0, 0.0, 0.0, 0.0, 15.0, 23.0, 67.0, 17.0, 3.0, 33.0, 52.0, 5.0, 0.0, 2.0, 2.0, 44.0, 8.0, 30.0, 0.0, 4.0, 0.0, 61.0, 16.0, 11.0, 50.0, 31.0, 0.0, 0.0, 6.0, 9.0, 17.0, 45.0, 53.0, 8.0, 35.0, 24.0, 170.0, 62.0, 12.0, 26.0, 3.0, 9.0, 61.0, 14.0, 0.0, 12.0, 40.0, 12.0, 0.0, 0.0, 69.0, 31.0, 0.0, 5.0, 0.0, 0.0, 32.0, 86.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6943277773696505, "mean_inference_ms": 1.5914336887856768, "mean_action_processing_ms": 0.2748112160358861, "mean_env_wait_ms": 0.2079850809133611, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003511786460876465, "StateBufferConnector_ms": 0.0036133527755737305, "ViewRequirementAgentConnector_ms": 0.11410403251647949}, "num_episodes": 22, "episode_return_max": 141.69999999999882, "episode_return_min": -342.70000000000016, "episode_return_mean": 6.360000000000027, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 288000, "num_agent_steps_trained": 288000, "num_env_steps_sampled": 72000, "num_env_steps_trained": 72000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 79.3576488528611, "num_env_steps_trained_throughput_per_sec": 79.3576488528611, "timesteps_total": 72000, "num_env_steps_sampled_lifetime": 72000, "num_agent_steps_sampled_lifetime": 288000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 288000, "timers": {"training_iteration_time_ms": 50926.701, "restore_workers_time_ms": 0.014, "training_step_time_ms": 50926.661, "sample_time_ms": 1276.005, "learn_time_ms": 49636.908, "learn_throughput": 80.585, "synch_weights_time_ms": 10.69}, "counters": {"num_env_steps_sampled": 72000, "num_env_steps_trained": 72000, "num_agent_steps_sampled": 288000, "num_agent_steps_trained": 288000}, "done": false, "training_iteration": 18, "trial_id": "11e70_00000", "date": "2024-08-12_23-22-32", "timestamp": 1723519352, "time_this_iter_s": 50.450599908828735, "time_total_s": 933.1617114543915, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2b8c9d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 933.1617114543915, "iterations_since_restore": 18, "perf": {"cpu_util_percent": 35.05416666666667, "ram_util_percent": 83.12916666666666}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.775407625506164, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.195373610150877, "policy_loss": -0.010210065825142597, "vf_loss": 2.2038116394527374, "vf_explained_var": 0.05672815924599057, "kl": 0.011813544531219484, "entropy": 1.4086817988012204, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 34965.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.86550040746492, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.581427437855453, "policy_loss": -0.010254614213949671, "vf_loss": 3.590051469979463, "vf_explained_var": 0.07842468546811866, "kl": 0.01087049933930851, "entropy": 1.4021893061027324, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 34965.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 76000, "num_env_steps_trained": 76000, "num_agent_steps_sampled": 304000, "num_agent_steps_trained": 304000}, "env_runners": {"episode_reward_max": 141.69999999999882, "episode_reward_min": -342.70000000000016, "episode_reward_mean": 17.15499999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -297.10000000000025, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 147.79999999999998, "predator_policy": 170.0}, "policy_reward_mean": {"prey_policy": -14.45250000000006, "predator_policy": 23.03}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-42.10000000000003, 2.4999999999999396, -19.999999999999673, 37.80000000000026, -4.4999999999997655, 26.6000000000002, 41.40000000000047, -57.40000000000096, -30.499999999999652, 27.60000000000009, 141.69999999999882, -125.2000000000009, 33.20000000000023, 76.49999999999872, -28.899999999999622, 9.099999999999973, -8.299999999999716, -15.499999999999556, 26.700000000000102, 9.00000000000005, 39.10000000000041, 68.60000000000014, -105.20000000000104, 43.80000000000043, -6.299999999999816, -22.599999999999554, -2.8999999999998227, -97.00000000000117, 58.000000000000355, 40.0000000000003, 10.299999999999955, 62.10000000000045, 40.0000000000003, -111.10000000000146, 23.100000000000126, -7.399999999999904, 40.0000000000003, 14.099999999999953, -2.299999999999865, 57.50000000000047, 22.400000000000013, 22.50000000000007, 40.0000000000003, 4.89999999999994, 40.0000000000003, 40.0000000000003, 33.90000000000021, 24.100000000000172, 2.200000000000201, -68.0000000000017, 37.800000000000296, 24.500000000000103, 4.500000000000108, 36.50000000000025, -16.299999999999677, 15.699999999999948, -28.399999999999594, 116.49999999999879, 40.900000000000475, -5.999999999999815, 68.59999999999962, -10.499999999999652, -342.70000000000016, 71.1000000000002, 59.200000000000436, 52.900000000000134, 35.80000000000039, 8.00000000000006, 92.1999999999994, -27.699999999999655, 32.40000000000018, 40.90000000000031, -86.20000000000098, 5.000000000000092, 51.70000000000049, 40.0000000000003, 93.19999999999995, -57.60000000000123, 96.59999999999937, 89.89999999999893, -68.80000000000118, 76.9999999999997, 67.20000000000014, 107.69999999999982, -41.79999999999961, 54.30000000000043, 55.300000000000516, 93.69999999999968, 35.90000000000024, 40.0000000000003, 45.10000000000024, 29.10000000000013, 84.99999999999993, -191.9000000000008, 40.0000000000003, 130.29999999999959, 36.70000000000028, 74.3999999999998, 30.100000000000154, 74.19999999999968], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-41.79999999999979, -73.30000000000078, -77.50000000000047, 20.000000000000014, 1.0999999999999865, -93.10000000000058, 15.799999999999958, 20.000000000000014, 20.000000000000014, -107.50000000000075, -9.699999999999903, 5.299999999999976, 16.699999999999996, -7.300000000000004, -56.50000000000015, -64.90000000000052, -23.79999999999979, -99.70000000000051, -24.699999999999797, -15.700000000000038, 121.69999999999955, 20.000000000000014, -148.60000000000048, -106.60000000000039, -7.299999999999976, 24.500000000000085, 24.50000000000009, 7.999999999999725, -92.80000000000067, -21.09999999999978, -77.80000000000021, -57.10000000000036, -109.30000000000078, 20.000000000000014, -89.50000000000082, 20.000000000000014, 20.000000000000014, -19.299999999999763, -79.00000000000085, 20.000000000000014, 21.50000000000004, -66.40000000000067, 20.000000000000014, 38.60000000000021, 20.000000000000014, -257.1999999999996, -5.1999999999999975, 20.000000000000014, -26.199999999999825, -45.09999999999976, -56.80000000000041, -17.799999999999784, -35.1999999999998, -12.699999999999864, -155.8000000000006, -50.19999999999986, -27.699999999999783, -4.300000000000033, 20.000000000000014, 20.000000000000014, 15.799999999999946, -65.50000000000087, 20.000000000000014, 16.09999999999996, 20.000000000000014, 20.000000000000014, -53.80000000000018, -196.30000000000055, 20.000000000000014, -31.8999999999998, -42.99999999999985, -66.40000000000035, 20.000000000000014, 20.000000000000014, -31.899999999999757, 20.000000000000014, -5.49999999999994, -59.800000000000395, 20.000000000000014, 3.499999999999978, 20.000000000000014, -13.599999999999783, 17.29999999999997, -14.799999999999779, 20.000000000000014, 20.000000000000014, 18.19999999999997, -49.299999999999876, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -24.09999999999976, 20.000000000000014, -97.59999999999997, 37.70000000000018, -49.299999999999905, 15.499999999999964, -46.29999999999978, -78.70000000000081, 15.799999999999946, 20.000000000000014, 20.000000000000014, -41.49999999999984, 15.799999999999963, -49.29999999999977, 11.599999999999964, 20.900000000000027, -97.3000000000006, 20.000000000000014, -8.199999999999902, -3.099999999999958, -42.999999999999766, -66.4000000000006, 20.000000000000014, 96.49999999999949, 1.0999999999999723, 24.800000000000093, 20.000000000000014, -88.00000000000065, -21.399999999999935, 29.000000000000163, -32.199999999999775, -37.299999999999784, -297.10000000000025, -277.60000000000014, 14.599999999999962, 18.500000000000156, 39.8000000000002, 7.399999999999984, 8.599999999999984, -30.700000000000244, -5.200000000000047, 29.00000000000015, -64.00000000000085, 20.000000000000014, 72.19999999999987, 20.000000000000014, -168.10000000000062, 40.40000000000019, 15.799999999999963, 11.599999999999964, 20.000000000000014, 20.90000000000003, -47.199999999999775, -157.0000000000004, 20.000000000000014, -55.00000000000021, 31.700000000000212, 20.000000000000014, 20.000000000000014, 20.000000000000014, -26.199999999999754, 97.39999999999966, -91.60000000000082, -21.999999999999773, 53.30000000000005, -3.699999999999994, 53.900000000000134, 20.000000000000014, 15.799999999999963, -181.6000000000006, 20.000000000000014, 35.00000000000013, 50.600000000000236, -18.39999999999982, 70.69999999999995, 20.000000000000014, -158.50000000000063, 31.700000000000212, 9.499999999999964, 39.80000000000022, 20.000000000000014, 35.30000000000025, -15.699999999999967, 10.4, 20.000000000000014, 2.8999999999999613, 20.000000000000014, 20.000000000000014, 3.5000000000000426, -18.39999999999975, 3.4999999999999654, 11.599999999999964, 31.700000000000212, 53.300000000000054, -181.3000000000004, -155.60000000000045, 20.000000000000014, 20.000000000000014, -56.500000000000334, 147.79999999999998, 20.000000000000014, 13.699999999999955, 20.000000000000014, 28.40000000000004, 20.000000000000014, 1.09999999999996, 35.000000000000256, -2.799999999999926], "policy_predator_policy_reward": [43.0, 30.0, 32.0, 28.0, 32.0, 40.0, 2.0, 0.0, 26.0, 57.0, 0.0, 31.0, 24.0, 8.0, 0.0, 64.0, 77.0, 16.0, 52.0, 16.0, 0.0, 0.0, 104.0, 26.0, 13.0, 3.0, 37.0, 7.0, 72.0, 13.0, 61.0, 83.0, 44.0, 37.0, 42.0, 12.0, 23.0, 3.0, 48.0, 20.0, 47.0, 37.0, 9.0, 1.0, 0.0, 132.0, 24.0, 5.0, 61.0, 4.0, 47.0, 5.0, 26.0, 19.0, 75.0, 34.0, 37.0, 53.0, 0.0, 0.0, 33.0, 27.0, 16.0, 10.0, 0.0, 0.0, 103.0, 36.0, 0.0, 35.0, 76.0, 26.0, 0.0, 0.0, 21.0, 5.0, 55.0, 8.0, 18.0, 16.0, 0.0, 16.0, 20.0, 0.0, 0.0, 0.0, 0.0, 36.0, 0.0, 0.0, 0.0, 0.0, 15.0, 23.0, 67.0, 17.0, 3.0, 33.0, 52.0, 5.0, 0.0, 2.0, 2.0, 44.0, 8.0, 30.0, 0.0, 4.0, 0.0, 61.0, 16.0, 11.0, 50.0, 31.0, 0.0, 0.0, 6.0, 9.0, 17.0, 45.0, 53.0, 8.0, 35.0, 24.0, 170.0, 62.0, 12.0, 26.0, 3.0, 9.0, 61.0, 14.0, 0.0, 12.0, 40.0, 12.0, 0.0, 0.0, 69.0, 31.0, 0.0, 5.0, 0.0, 0.0, 32.0, 86.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 56.0, 0.0, 14.0, 33.0, 16.0, 0.0, 96.0, 1.0, 22.0, 0.0, 0.0, 35.0, 0.0, 17.0, 0.0, 85.0, 5.0, 0.0, 0.0, 0.0, 99.0, 0.0, 9.0, 4.0, 0.0, 0.0, 41.0, 19.0, 10.0, 4.0, 0.0, 0.0, 145.0, 0.0, 0.0, 0.0, 0.0, 39.0, 2.0, 1.0, 0.0, 26.0, 0.0, 9.0, 30.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6953781063430132, "mean_inference_ms": 1.5925542211915356, "mean_action_processing_ms": 0.274189677301241, "mean_env_wait_ms": 0.207333844591791, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005982160568237305, "StateBufferConnector_ms": 0.004567623138427734, "ViewRequirementAgentConnector_ms": 0.13677167892456055}, "num_episodes": 23, "episode_return_max": 141.69999999999882, "episode_return_min": -342.70000000000016, "episode_return_mean": 17.15499999999998, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 304000, "num_agent_steps_trained": 304000, "num_env_steps_sampled": 76000, "num_env_steps_trained": 76000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 78.25566218744088, "num_env_steps_trained_throughput_per_sec": 78.25566218744088, "timesteps_total": 76000, "num_env_steps_sampled_lifetime": 76000, "num_agent_steps_sampled_lifetime": 304000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 304000, "timers": {"training_iteration_time_ms": 50906.892, "restore_workers_time_ms": 0.014, "training_step_time_ms": 50906.853, "sample_time_ms": 1303.065, "learn_time_ms": 49590.03, "learn_throughput": 80.661, "synch_weights_time_ms": 10.778}, "counters": {"num_env_steps_sampled": 76000, "num_env_steps_trained": 76000, "num_agent_steps_sampled": 304000, "num_agent_steps_trained": 304000}, "done": false, "training_iteration": 19, "trial_id": "11e70_00000", "date": "2024-08-12_23-23-23", "timestamp": 1723519403, "time_this_iter_s": 51.15020179748535, "time_total_s": 984.3119132518768, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2af5af0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 984.3119132518768, "iterations_since_restore": 19, "perf": {"cpu_util_percent": 36.35479452054795, "ram_util_percent": 83.0986301369863}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.7549567248455435, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.329413412424622, "policy_loss": -0.007233587460020784, "vf_loss": 2.3356431297524267, "vf_explained_var": 0.037934766370783406, "kl": 0.006692494870429948, "entropy": 1.4210172819082068, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 36855.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.478038538133026, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.501053861840061, "policy_loss": -0.009731773634209599, "vf_loss": 4.509285443800467, "vf_explained_var": 0.11553027768614431, "kl": 0.010001286037257445, "entropy": 1.3815581152678797, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 36855.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 80000, "num_env_steps_trained": 80000, "num_agent_steps_sampled": 320000, "num_agent_steps_trained": 320000}, "env_runners": {"episode_reward_max": 142.9999999999999, "episode_reward_min": -342.70000000000016, "episode_reward_mean": 28.345999999999975, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -305.5, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 147.79999999999998, "predator_policy": 170.0}, "policy_reward_mean": {"prey_policy": -7.3020000000000325, "predator_policy": 21.475}, "custom_metrics": {}, "hist_stats": {"episode_reward": [26.700000000000102, 9.00000000000005, 39.10000000000041, 68.60000000000014, -105.20000000000104, 43.80000000000043, -6.299999999999816, -22.599999999999554, -2.8999999999998227, -97.00000000000117, 58.000000000000355, 40.0000000000003, 10.299999999999955, 62.10000000000045, 40.0000000000003, -111.10000000000146, 23.100000000000126, -7.399999999999904, 40.0000000000003, 14.099999999999953, -2.299999999999865, 57.50000000000047, 22.400000000000013, 22.50000000000007, 40.0000000000003, 4.89999999999994, 40.0000000000003, 40.0000000000003, 33.90000000000021, 24.100000000000172, 2.200000000000201, -68.0000000000017, 37.800000000000296, 24.500000000000103, 4.500000000000108, 36.50000000000025, -16.299999999999677, 15.699999999999948, -28.399999999999594, 116.49999999999879, 40.900000000000475, -5.999999999999815, 68.59999999999962, -10.499999999999652, -342.70000000000016, 71.1000000000002, 59.200000000000436, 52.900000000000134, 35.80000000000039, 8.00000000000006, 92.1999999999994, -27.699999999999655, 32.40000000000018, 40.90000000000031, -86.20000000000098, 5.000000000000092, 51.70000000000049, 40.0000000000003, 93.19999999999995, -57.60000000000123, 96.59999999999937, 89.89999999999893, -68.80000000000118, 76.9999999999997, 67.20000000000014, 107.69999999999982, -41.79999999999961, 54.30000000000043, 55.300000000000516, 93.69999999999968, 35.90000000000024, 40.0000000000003, 45.10000000000024, 29.10000000000013, 84.99999999999993, -191.9000000000008, 40.0000000000003, 130.29999999999959, 36.70000000000028, 74.3999999999998, 30.100000000000154, 74.19999999999968, 19.999999999999975, -11.99999999999993, 19.10000000000027, 110.29999999999973, -8.399999999999666, -40.19999999999988, 40.0000000000003, 42.300000000000345, 108.5999999999994, 22.600000000000012, 142.9999999999999, 81.49999999999967, 125.49999999999928, 134.29999999999987, 135.0999999999996, 141.69999999999922, 79.70000000000002, 40.0000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, -19.299999999999763, -79.00000000000085, 20.000000000000014, 21.50000000000004, -66.40000000000067, 20.000000000000014, 38.60000000000021, 20.000000000000014, -257.1999999999996, -5.1999999999999975, 20.000000000000014, -26.199999999999825, -45.09999999999976, -56.80000000000041, -17.799999999999784, -35.1999999999998, -12.699999999999864, -155.8000000000006, -50.19999999999986, -27.699999999999783, -4.300000000000033, 20.000000000000014, 20.000000000000014, 15.799999999999946, -65.50000000000087, 20.000000000000014, 16.09999999999996, 20.000000000000014, 20.000000000000014, -53.80000000000018, -196.30000000000055, 20.000000000000014, -31.8999999999998, -42.99999999999985, -66.40000000000035, 20.000000000000014, 20.000000000000014, -31.899999999999757, 20.000000000000014, -5.49999999999994, -59.800000000000395, 20.000000000000014, 3.499999999999978, 20.000000000000014, -13.599999999999783, 17.29999999999997, -14.799999999999779, 20.000000000000014, 20.000000000000014, 18.19999999999997, -49.299999999999876, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -24.09999999999976, 20.000000000000014, -97.59999999999997, 37.70000000000018, -49.299999999999905, 15.499999999999964, -46.29999999999978, -78.70000000000081, 15.799999999999946, 20.000000000000014, 20.000000000000014, -41.49999999999984, 15.799999999999963, -49.29999999999977, 11.599999999999964, 20.900000000000027, -97.3000000000006, 20.000000000000014, -8.199999999999902, -3.099999999999958, -42.999999999999766, -66.4000000000006, 20.000000000000014, 96.49999999999949, 1.0999999999999723, 24.800000000000093, 20.000000000000014, -88.00000000000065, -21.399999999999935, 29.000000000000163, -32.199999999999775, -37.299999999999784, -297.10000000000025, -277.60000000000014, 14.599999999999962, 18.500000000000156, 39.8000000000002, 7.399999999999984, 8.599999999999984, -30.700000000000244, -5.200000000000047, 29.00000000000015, -64.00000000000085, 20.000000000000014, 72.19999999999987, 20.000000000000014, -168.10000000000062, 40.40000000000019, 15.799999999999963, 11.599999999999964, 20.000000000000014, 20.90000000000003, -47.199999999999775, -157.0000000000004, 20.000000000000014, -55.00000000000021, 31.700000000000212, 20.000000000000014, 20.000000000000014, 20.000000000000014, -26.199999999999754, 97.39999999999966, -91.60000000000082, -21.999999999999773, 53.30000000000005, -3.699999999999994, 53.900000000000134, 20.000000000000014, 15.799999999999963, -181.6000000000006, 20.000000000000014, 35.00000000000013, 50.600000000000236, -18.39999999999982, 70.69999999999995, 20.000000000000014, -158.50000000000063, 31.700000000000212, 9.499999999999964, 39.80000000000022, 20.000000000000014, 35.30000000000025, -15.699999999999967, 10.4, 20.000000000000014, 2.8999999999999613, 20.000000000000014, 20.000000000000014, 3.5000000000000426, -18.39999999999975, 3.4999999999999654, 11.599999999999964, 31.700000000000212, 53.300000000000054, -181.3000000000004, -155.60000000000045, 20.000000000000014, 20.000000000000014, -56.500000000000334, 147.79999999999998, 20.000000000000014, 13.699999999999955, 20.000000000000014, 28.40000000000004, 20.000000000000014, 1.09999999999996, 35.000000000000256, -2.799999999999926, 20.000000000000014, -18.999999999999744, 63.50000000000009, -200.50000000000026, -19.900000000000016, 20.000000000000014, -146.50000000000048, 111.79999999999998, 20.000000000000014, -72.40000000000087, -305.5, 107.29999999999964, 20.000000000000014, 20.000000000000014, 33.50000000000024, -11.199999999999848, 20.000000000000014, 56.59999999999998, -5.199999999999934, 15.799999999999963, 53.59999999999999, 28.40000000000004, 57.500000000000185, 20.000000000000014, 20.000000000000014, 105.49999999999977, 28.400000000000134, 20.900000000000006, 115.69999999999996, 4.399999999999968, 41.60000000000016, 82.0999999999997, 20.000000000000014, -4.300000000000052, 20.000000000000014, 20.000000000000014], "policy_predator_policy_reward": [23.0, 3.0, 48.0, 20.0, 47.0, 37.0, 9.0, 1.0, 0.0, 132.0, 24.0, 5.0, 61.0, 4.0, 47.0, 5.0, 26.0, 19.0, 75.0, 34.0, 37.0, 53.0, 0.0, 0.0, 33.0, 27.0, 16.0, 10.0, 0.0, 0.0, 103.0, 36.0, 0.0, 35.0, 76.0, 26.0, 0.0, 0.0, 21.0, 5.0, 55.0, 8.0, 18.0, 16.0, 0.0, 16.0, 20.0, 0.0, 0.0, 0.0, 0.0, 36.0, 0.0, 0.0, 0.0, 0.0, 15.0, 23.0, 67.0, 17.0, 3.0, 33.0, 52.0, 5.0, 0.0, 2.0, 2.0, 44.0, 8.0, 30.0, 0.0, 4.0, 0.0, 61.0, 16.0, 11.0, 50.0, 31.0, 0.0, 0.0, 6.0, 9.0, 17.0, 45.0, 53.0, 8.0, 35.0, 24.0, 170.0, 62.0, 12.0, 26.0, 3.0, 9.0, 61.0, 14.0, 0.0, 12.0, 40.0, 12.0, 0.0, 0.0, 69.0, 31.0, 0.0, 5.0, 0.0, 0.0, 32.0, 86.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 56.0, 0.0, 14.0, 33.0, 16.0, 0.0, 96.0, 1.0, 22.0, 0.0, 0.0, 35.0, 0.0, 17.0, 0.0, 85.0, 5.0, 0.0, 0.0, 0.0, 99.0, 0.0, 9.0, 4.0, 0.0, 0.0, 41.0, 19.0, 10.0, 4.0, 0.0, 0.0, 145.0, 0.0, 0.0, 0.0, 0.0, 39.0, 2.0, 1.0, 0.0, 26.0, 0.0, 9.0, 30.0, 12.0, 0.0, 19.0, 20.0, 105.0, 0.0, 19.0, 70.0, 75.0, 44.0, 0.0, 3.0, 155.0, 0.0, 0.0, 0.0, 20.0, 1.0, 31.0, 12.0, 0.0, 61.0, 0.0, 4.0, 0.0, 0.0, 0.0, 33.0, 52.0, 14.0, 1.0, 18.0, 0.0, 25.0, 39.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.695380916297137, "mean_inference_ms": 1.5941804842563934, "mean_action_processing_ms": 0.27418113796080035, "mean_env_wait_ms": 0.20680920154396618, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006013035774230957, "StateBufferConnector_ms": 0.0046051740646362305, "ViewRequirementAgentConnector_ms": 0.13587462902069092}, "num_episodes": 18, "episode_return_max": 142.9999999999999, "episode_return_min": -342.70000000000016, "episode_return_mean": 28.345999999999975, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 320000, "num_agent_steps_trained": 320000, "num_env_steps_sampled": 80000, "num_env_steps_trained": 80000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 78.9466342257915, "num_env_steps_trained_throughput_per_sec": 78.9466342257915, "timesteps_total": 80000, "num_env_steps_sampled_lifetime": 80000, "num_agent_steps_sampled_lifetime": 320000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 320000, "timers": {"training_iteration_time_ms": 50902.84, "restore_workers_time_ms": 0.013, "training_step_time_ms": 50902.801, "sample_time_ms": 1303.58, "learn_time_ms": 49585.117, "learn_throughput": 80.669, "synch_weights_time_ms": 10.677}, "counters": {"num_env_steps_sampled": 80000, "num_env_steps_trained": 80000, "num_agent_steps_sampled": 320000, "num_agent_steps_trained": 320000}, "done": false, "training_iteration": 20, "trial_id": "11e70_00000", "date": "2024-08-12_23-24-14", "timestamp": 1723519454, "time_this_iter_s": 50.713751792907715, "time_total_s": 1035.0256650447845, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2b67ee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1035.0256650447845, "iterations_since_restore": 20, "perf": {"cpu_util_percent": 35.772222222222226, "ram_util_percent": 82.58749999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 6.477867591633368, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.794525553372802, "policy_loss": -0.007804410811513662, "vf_loss": 2.8010972168710495, "vf_explained_var": 0.02363857702603416, "kl": 0.00821826177302363, "entropy": 1.4164694453673388, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 38745.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 6.094443306910298, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.964857101945019, "policy_loss": -0.007175369342670791, "vf_loss": 5.970867073220551, "vf_explained_var": 0.17004200986453466, "kl": 0.007769370486086084, "entropy": 1.4050208800684207, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 38745.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 84000, "num_env_steps_trained": 84000, "num_agent_steps_sampled": 336000, "num_agent_steps_trained": 336000}, "env_runners": {"episode_reward_max": 250.59999999999945, "episode_reward_min": -511.4999999999998, "episode_reward_mean": 36.39199999999996, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -502.8999999999998, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 156.79999999999984, "predator_policy": 394.0}, "policy_reward_mean": {"prey_policy": -3.714000000000027, "predator_policy": 21.91}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.0000000000003, 14.099999999999953, -2.299999999999865, 57.50000000000047, 22.400000000000013, 22.50000000000007, 40.0000000000003, 4.89999999999994, 40.0000000000003, 40.0000000000003, 33.90000000000021, 24.100000000000172, 2.200000000000201, -68.0000000000017, 37.800000000000296, 24.500000000000103, 4.500000000000108, 36.50000000000025, -16.299999999999677, 15.699999999999948, -28.399999999999594, 116.49999999999879, 40.900000000000475, -5.999999999999815, 68.59999999999962, -10.499999999999652, -342.70000000000016, 71.1000000000002, 59.200000000000436, 52.900000000000134, 35.80000000000039, 8.00000000000006, 92.1999999999994, -27.699999999999655, 32.40000000000018, 40.90000000000031, -86.20000000000098, 5.000000000000092, 51.70000000000049, 40.0000000000003, 93.19999999999995, -57.60000000000123, 96.59999999999937, 89.89999999999893, -68.80000000000118, 76.9999999999997, 67.20000000000014, 107.69999999999982, -41.79999999999961, 54.30000000000043, 55.300000000000516, 93.69999999999968, 35.90000000000024, 40.0000000000003, 45.10000000000024, 29.10000000000013, 84.99999999999993, -191.9000000000008, 40.0000000000003, 130.29999999999959, 36.70000000000028, 74.3999999999998, 30.100000000000154, 74.19999999999968, 19.999999999999975, -11.99999999999993, 19.10000000000027, 110.29999999999973, -8.399999999999666, -40.19999999999988, 40.0000000000003, 42.300000000000345, 108.5999999999994, 22.600000000000012, 142.9999999999999, 81.49999999999967, 125.49999999999928, 134.29999999999987, 135.0999999999996, 141.69999999999922, 79.70000000000002, 40.0000000000003, 29.30000000000009, 87.79999999999984, -511.4999999999998, 250.59999999999945, 166.5999999999992, 78.3000000000001, 22.400000000000016, 66.30000000000011, 118.29999999999885, 2.600000000000068, 40.0000000000003, 26.300000000000125, 105.59999999999984, 244.99999999999937, 36.70000000000028, 20.50000000000012, 37.60000000000026, 50.40000000000033], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 20.000000000000014, -31.899999999999757, 20.000000000000014, -5.49999999999994, -59.800000000000395, 20.000000000000014, 3.499999999999978, 20.000000000000014, -13.599999999999783, 17.29999999999997, -14.799999999999779, 20.000000000000014, 20.000000000000014, 18.19999999999997, -49.299999999999876, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -24.09999999999976, 20.000000000000014, -97.59999999999997, 37.70000000000018, -49.299999999999905, 15.499999999999964, -46.29999999999978, -78.70000000000081, 15.799999999999946, 20.000000000000014, 20.000000000000014, -41.49999999999984, 15.799999999999963, -49.29999999999977, 11.599999999999964, 20.900000000000027, -97.3000000000006, 20.000000000000014, -8.199999999999902, -3.099999999999958, -42.999999999999766, -66.4000000000006, 20.000000000000014, 96.49999999999949, 1.0999999999999723, 24.800000000000093, 20.000000000000014, -88.00000000000065, -21.399999999999935, 29.000000000000163, -32.199999999999775, -37.299999999999784, -297.10000000000025, -277.60000000000014, 14.599999999999962, 18.500000000000156, 39.8000000000002, 7.399999999999984, 8.599999999999984, -30.700000000000244, -5.200000000000047, 29.00000000000015, -64.00000000000085, 20.000000000000014, 72.19999999999987, 20.000000000000014, -168.10000000000062, 40.40000000000019, 15.799999999999963, 11.599999999999964, 20.000000000000014, 20.90000000000003, -47.199999999999775, -157.0000000000004, 20.000000000000014, -55.00000000000021, 31.700000000000212, 20.000000000000014, 20.000000000000014, 20.000000000000014, -26.199999999999754, 97.39999999999966, -91.60000000000082, -21.999999999999773, 53.30000000000005, -3.699999999999994, 53.900000000000134, 20.000000000000014, 15.799999999999963, -181.6000000000006, 20.000000000000014, 35.00000000000013, 50.600000000000236, -18.39999999999982, 70.69999999999995, 20.000000000000014, -158.50000000000063, 31.700000000000212, 9.499999999999964, 39.80000000000022, 20.000000000000014, 35.30000000000025, -15.699999999999967, 10.4, 20.000000000000014, 2.8999999999999613, 20.000000000000014, 20.000000000000014, 3.5000000000000426, -18.39999999999975, 3.4999999999999654, 11.599999999999964, 31.700000000000212, 53.300000000000054, -181.3000000000004, -155.60000000000045, 20.000000000000014, 20.000000000000014, -56.500000000000334, 147.79999999999998, 20.000000000000014, 13.699999999999955, 20.000000000000014, 28.40000000000004, 20.000000000000014, 1.09999999999996, 35.000000000000256, -2.799999999999926, 20.000000000000014, -18.999999999999744, 63.50000000000009, -200.50000000000026, -19.900000000000016, 20.000000000000014, -146.50000000000048, 111.79999999999998, 20.000000000000014, -72.40000000000087, -305.5, 107.29999999999964, 20.000000000000014, 20.000000000000014, 33.50000000000024, -11.199999999999848, 20.000000000000014, 56.59999999999998, -5.199999999999934, 15.799999999999963, 53.59999999999999, 28.40000000000004, 57.500000000000185, 20.000000000000014, 20.000000000000014, 105.49999999999977, 28.400000000000134, 20.900000000000006, 115.69999999999996, 4.399999999999968, 41.60000000000016, 82.0999999999997, 20.000000000000014, -4.300000000000052, 20.000000000000014, 20.000000000000014, 20.000000000000014, -66.70000000000005, 9.799999999999963, 20.000000000000014, -502.8999999999998, -402.6, 156.79999999999984, 93.79999999999981, 7.4, 117.19999999999959, 60.499999999999964, 15.800000000000011, 20.000000000000014, -13.599999999999794, 11.59999999999997, -7.300000000000006, 20.000000000000014, 98.29999999999949, 15.799999999999946, -47.1999999999998, 20.000000000000014, 20.000000000000014, 130.7, -240.40000000000006, 90.19999999999999, 10.39999999999998, 137.29999999999976, 85.69999999999997, 13.699999999999955, 20.000000000000014, -295.1, 125.60000000000005, 20.000000000000014, -54.4, 16.99999999999999, -13.59999999999979], "policy_predator_policy_reward": [0.0, 0.0, 21.0, 5.0, 55.0, 8.0, 18.0, 16.0, 0.0, 16.0, 20.0, 0.0, 0.0, 0.0, 0.0, 36.0, 0.0, 0.0, 0.0, 0.0, 15.0, 23.0, 67.0, 17.0, 3.0, 33.0, 52.0, 5.0, 0.0, 2.0, 2.0, 44.0, 8.0, 30.0, 0.0, 4.0, 0.0, 61.0, 16.0, 11.0, 50.0, 31.0, 0.0, 0.0, 6.0, 9.0, 17.0, 45.0, 53.0, 8.0, 35.0, 24.0, 170.0, 62.0, 12.0, 26.0, 3.0, 9.0, 61.0, 14.0, 0.0, 12.0, 40.0, 12.0, 0.0, 0.0, 69.0, 31.0, 0.0, 5.0, 0.0, 0.0, 32.0, 86.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 56.0, 0.0, 14.0, 33.0, 16.0, 0.0, 96.0, 1.0, 22.0, 0.0, 0.0, 35.0, 0.0, 17.0, 0.0, 85.0, 5.0, 0.0, 0.0, 0.0, 99.0, 0.0, 9.0, 4.0, 0.0, 0.0, 41.0, 19.0, 10.0, 4.0, 0.0, 0.0, 145.0, 0.0, 0.0, 0.0, 0.0, 39.0, 2.0, 1.0, 0.0, 26.0, 0.0, 9.0, 30.0, 12.0, 0.0, 19.0, 20.0, 105.0, 0.0, 19.0, 70.0, 75.0, 44.0, 0.0, 3.0, 155.0, 0.0, 0.0, 0.0, 20.0, 1.0, 31.0, 12.0, 0.0, 61.0, 0.0, 4.0, 0.0, 0.0, 0.0, 33.0, 52.0, 14.0, 1.0, 18.0, 0.0, 25.0, 39.0, 0.0, 0.0, 76.0, 0.0, 34.0, 24.0, 0.0, 394.0, 0.0, 0.0, 42.0, 0.0, 2.0, 0.0, 16.0, 0.0, 19.0, 43.0, 0.0, 0.0, 2.0, 32.0, 0.0, 0.0, 124.0, 12.0, 5.0, 0.0, 0.0, 22.0, 3.0, 0.0, 14.0, 176.0, 38.0, 34.0, 20.0, 27.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6939199539401423, "mean_inference_ms": 1.591524447871671, "mean_action_processing_ms": 0.2737114042837661, "mean_env_wait_ms": 0.2060220253506737, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01069653034210205, "StateBufferConnector_ms": 0.004587411880493164, "ViewRequirementAgentConnector_ms": 0.1269296407699585}, "num_episodes": 18, "episode_return_max": 250.59999999999945, "episode_return_min": -511.4999999999998, "episode_return_mean": 36.39199999999996, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 336000, "num_agent_steps_trained": 336000, "num_env_steps_sampled": 84000, "num_env_steps_trained": 84000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 78.91723355819744, "num_env_steps_trained_throughput_per_sec": 78.91723355819744, "timesteps_total": 84000, "num_env_steps_sampled_lifetime": 84000, "num_agent_steps_sampled_lifetime": 336000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 336000, "timers": {"training_iteration_time_ms": 50914.346, "restore_workers_time_ms": 0.013, "training_step_time_ms": 50914.306, "sample_time_ms": 1303.872, "learn_time_ms": 49596.512, "learn_throughput": 80.651, "synch_weights_time_ms": 10.656}, "counters": {"num_env_steps_sampled": 84000, "num_env_steps_trained": 84000, "num_agent_steps_sampled": 336000, "num_agent_steps_trained": 336000}, "done": false, "training_iteration": 21, "trial_id": "11e70_00000", "date": "2024-08-12_23-25-05", "timestamp": 1723519505, "time_this_iter_s": 50.71295118331909, "time_total_s": 1085.7386162281036, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2b67d30>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1085.7386162281036, "iterations_since_restore": 21, "perf": {"cpu_util_percent": 35.697183098591545, "ram_util_percent": 82.81830985915495}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 6.4178062565742975, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.984763783248013, "policy_loss": -0.008570096938422433, "vf_loss": 3.9917228017534527, "vf_explained_var": 0.03367902236010032, "kl": 0.010740500161768233, "entropy": 1.4184058069552063, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 40635.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.577418981973456, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.120386125170995, "policy_loss": -0.013662484767427914, "vf_loss": 7.131946744868364, "vf_explained_var": 0.10958307088998259, "kl": 0.014012448145382297, "entropy": 1.4097833588640525, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 40635.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 88000, "num_env_steps_trained": 88000, "num_agent_steps_sampled": 352000, "num_agent_steps_trained": 352000}, "env_runners": {"episode_reward_max": 284.30000000000007, "episode_reward_min": -511.4999999999998, "episode_reward_mean": 50.599999999999916, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -502.8999999999998, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 161.59999999999997, "predator_policy": 394.0}, "policy_reward_mean": {"prey_policy": 1.1549999999999625, "predator_policy": 24.145}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-16.299999999999677, 15.699999999999948, -28.399999999999594, 116.49999999999879, 40.900000000000475, -5.999999999999815, 68.59999999999962, -10.499999999999652, -342.70000000000016, 71.1000000000002, 59.200000000000436, 52.900000000000134, 35.80000000000039, 8.00000000000006, 92.1999999999994, -27.699999999999655, 32.40000000000018, 40.90000000000031, -86.20000000000098, 5.000000000000092, 51.70000000000049, 40.0000000000003, 93.19999999999995, -57.60000000000123, 96.59999999999937, 89.89999999999893, -68.80000000000118, 76.9999999999997, 67.20000000000014, 107.69999999999982, -41.79999999999961, 54.30000000000043, 55.300000000000516, 93.69999999999968, 35.90000000000024, 40.0000000000003, 45.10000000000024, 29.10000000000013, 84.99999999999993, -191.9000000000008, 40.0000000000003, 130.29999999999959, 36.70000000000028, 74.3999999999998, 30.100000000000154, 74.19999999999968, 19.999999999999975, -11.99999999999993, 19.10000000000027, 110.29999999999973, -8.399999999999666, -40.19999999999988, 40.0000000000003, 42.300000000000345, 108.5999999999994, 22.600000000000012, 142.9999999999999, 81.49999999999967, 125.49999999999928, 134.29999999999987, 135.0999999999996, 141.69999999999922, 79.70000000000002, 40.0000000000003, 29.30000000000009, 87.79999999999984, -511.4999999999998, 250.59999999999945, 166.5999999999992, 78.3000000000001, 22.400000000000016, 66.30000000000011, 118.29999999999885, 2.600000000000068, 40.0000000000003, 26.300000000000125, 105.59999999999984, 244.99999999999937, 36.70000000000028, 20.50000000000012, 37.60000000000026, 50.40000000000033, 133.69999999999936, 134.1999999999999, 220.99999999999991, 211.59999999999988, 35.60000000000022, 40.0000000000003, 216.19999999999916, 147.49999999999963, 19.799999999999187, -155.99999999999994, 133.69999999999962, 89.79999999999995, 227.39999999999972, 23.800000000000253, 231.89999999999964, -239.1000000000003, 40.0000000000003, 284.30000000000007], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-97.3000000000006, 20.000000000000014, -8.199999999999902, -3.099999999999958, -42.999999999999766, -66.4000000000006, 20.000000000000014, 96.49999999999949, 1.0999999999999723, 24.800000000000093, 20.000000000000014, -88.00000000000065, -21.399999999999935, 29.000000000000163, -32.199999999999775, -37.299999999999784, -297.10000000000025, -277.60000000000014, 14.599999999999962, 18.500000000000156, 39.8000000000002, 7.399999999999984, 8.599999999999984, -30.700000000000244, -5.200000000000047, 29.00000000000015, -64.00000000000085, 20.000000000000014, 72.19999999999987, 20.000000000000014, -168.10000000000062, 40.40000000000019, 15.799999999999963, 11.599999999999964, 20.000000000000014, 20.90000000000003, -47.199999999999775, -157.0000000000004, 20.000000000000014, -55.00000000000021, 31.700000000000212, 20.000000000000014, 20.000000000000014, 20.000000000000014, -26.199999999999754, 97.39999999999966, -91.60000000000082, -21.999999999999773, 53.30000000000005, -3.699999999999994, 53.900000000000134, 20.000000000000014, 15.799999999999963, -181.6000000000006, 20.000000000000014, 35.00000000000013, 50.600000000000236, -18.39999999999982, 70.69999999999995, 20.000000000000014, -158.50000000000063, 31.700000000000212, 9.499999999999964, 39.80000000000022, 20.000000000000014, 35.30000000000025, -15.699999999999967, 10.4, 20.000000000000014, 2.8999999999999613, 20.000000000000014, 20.000000000000014, 3.5000000000000426, -18.39999999999975, 3.4999999999999654, 11.599999999999964, 31.700000000000212, 53.300000000000054, -181.3000000000004, -155.60000000000045, 20.000000000000014, 20.000000000000014, -56.500000000000334, 147.79999999999998, 20.000000000000014, 13.699999999999955, 20.000000000000014, 28.40000000000004, 20.000000000000014, 1.09999999999996, 35.000000000000256, -2.799999999999926, 20.000000000000014, -18.999999999999744, 63.50000000000009, -200.50000000000026, -19.900000000000016, 20.000000000000014, -146.50000000000048, 111.79999999999998, 20.000000000000014, -72.40000000000087, -305.5, 107.29999999999964, 20.000000000000014, 20.000000000000014, 33.50000000000024, -11.199999999999848, 20.000000000000014, 56.59999999999998, -5.199999999999934, 15.799999999999963, 53.59999999999999, 28.40000000000004, 57.500000000000185, 20.000000000000014, 20.000000000000014, 105.49999999999977, 28.400000000000134, 20.900000000000006, 115.69999999999996, 4.399999999999968, 41.60000000000016, 82.0999999999997, 20.000000000000014, -4.300000000000052, 20.000000000000014, 20.000000000000014, 20.000000000000014, -66.70000000000005, 9.799999999999963, 20.000000000000014, -502.8999999999998, -402.6, 156.79999999999984, 93.79999999999981, 7.4, 117.19999999999959, 60.499999999999964, 15.800000000000011, 20.000000000000014, -13.599999999999794, 11.59999999999997, -7.300000000000006, 20.000000000000014, 98.29999999999949, 15.799999999999946, -47.1999999999998, 20.000000000000014, 20.000000000000014, 130.7, -240.40000000000006, 90.19999999999999, 10.39999999999998, 137.29999999999976, 85.69999999999997, 13.699999999999955, 20.000000000000014, -295.1, 125.60000000000005, 20.000000000000014, -54.4, 16.99999999999999, -13.59999999999979, -7.3000000000000504, 127.99999999999982, -1.8999999999999986, 34.09999999999988, 28.39999999999999, 161.59999999999997, 5.899999999999885, 148.70000000000002, -6.399999999999993, 20.000000000000014, 20.000000000000014, 20.000000000000014, 108.79999999999978, 106.39999999999942, 132.49999999999997, -21.999999999999744, -4.2999999999998835, -46.89999999999991, -240.60000000000002, -109.40000000000003, 119.00000000000001, -7.3000000000000504, 96.49999999999997, -45.69999999999992, 156.2, 21.199999999999903, 20.000000000000014, -77.19999999999996, 106.99999999999997, 92.89999999999992, -215.2000000000001, -202.90000000000006, 20.000000000000014, 20.000000000000014, 159.49999999999997, 108.79999999999987], "policy_predator_policy_reward": [0.0, 61.0, 16.0, 11.0, 50.0, 31.0, 0.0, 0.0, 6.0, 9.0, 17.0, 45.0, 53.0, 8.0, 35.0, 24.0, 170.0, 62.0, 12.0, 26.0, 3.0, 9.0, 61.0, 14.0, 0.0, 12.0, 40.0, 12.0, 0.0, 0.0, 69.0, 31.0, 0.0, 5.0, 0.0, 0.0, 32.0, 86.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 56.0, 0.0, 14.0, 33.0, 16.0, 0.0, 96.0, 1.0, 22.0, 0.0, 0.0, 35.0, 0.0, 17.0, 0.0, 85.0, 5.0, 0.0, 0.0, 0.0, 99.0, 0.0, 9.0, 4.0, 0.0, 0.0, 41.0, 19.0, 10.0, 4.0, 0.0, 0.0, 145.0, 0.0, 0.0, 0.0, 0.0, 39.0, 2.0, 1.0, 0.0, 26.0, 0.0, 9.0, 30.0, 12.0, 0.0, 19.0, 20.0, 105.0, 0.0, 19.0, 70.0, 75.0, 44.0, 0.0, 3.0, 155.0, 0.0, 0.0, 0.0, 20.0, 1.0, 31.0, 12.0, 0.0, 61.0, 0.0, 4.0, 0.0, 0.0, 0.0, 33.0, 52.0, 14.0, 1.0, 18.0, 0.0, 25.0, 39.0, 0.0, 0.0, 76.0, 0.0, 34.0, 24.0, 0.0, 394.0, 0.0, 0.0, 42.0, 0.0, 2.0, 0.0, 16.0, 0.0, 19.0, 43.0, 0.0, 0.0, 2.0, 32.0, 0.0, 0.0, 124.0, 12.0, 5.0, 0.0, 0.0, 22.0, 3.0, 0.0, 14.0, 176.0, 38.0, 34.0, 20.0, 27.0, 0.0, 13.0, 30.0, 72.0, 0.0, 31.0, 0.0, 57.0, 0.0, 22.0, 0.0, 0.0, 0.0, 1.0, 29.0, 8.0, 71.0, 0.0, 0.0, 194.0, 0.0, 22.0, 19.0, 20.0, 50.0, 0.0, 81.0, 0.0, 1.0, 31.0, 179.0, 0.0, 0.0, 0.0, 12.0, 4.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6926315378310034, "mean_inference_ms": 1.5891013290133191, "mean_action_processing_ms": 0.273101873573574, "mean_env_wait_ms": 0.20545946488570516, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01056814193725586, "StateBufferConnector_ms": 0.004006385803222656, "ViewRequirementAgentConnector_ms": 0.13131499290466309}, "num_episodes": 18, "episode_return_max": 284.30000000000007, "episode_return_min": -511.4999999999998, "episode_return_mean": 50.599999999999916, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 352000, "num_agent_steps_trained": 352000, "num_env_steps_sampled": 88000, "num_env_steps_trained": 88000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 78.84903602455019, "num_env_steps_trained_throughput_per_sec": 78.84903602455019, "timesteps_total": 88000, "num_env_steps_sampled_lifetime": 88000, "num_agent_steps_sampled_lifetime": 352000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 352000, "timers": {"training_iteration_time_ms": 50856.916, "restore_workers_time_ms": 0.013, "training_step_time_ms": 50856.864, "sample_time_ms": 1291.771, "learn_time_ms": 49550.814, "learn_throughput": 80.725, "synch_weights_time_ms": 10.708}, "counters": {"num_env_steps_sampled": 88000, "num_env_steps_trained": 88000, "num_agent_steps_sampled": 352000, "num_agent_steps_trained": 352000}, "done": false, "training_iteration": 22, "trial_id": "11e70_00000", "date": "2024-08-12_23-25-56", "timestamp": 1723519556, "time_this_iter_s": 50.76962900161743, "time_total_s": 1136.508245229721, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2af5820>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1136.508245229721, "iterations_since_restore": 22, "perf": {"cpu_util_percent": 36.09166666666667, "ram_util_percent": 82.95555555555556}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.541679283613881, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.329818991756944, "policy_loss": -0.008130261611942418, "vf_loss": 4.336716346639805, "vf_explained_var": 0.023595103006514292, "kl": 0.008219354216660134, "entropy": 1.4053579886123617, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 42525.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.884335337681745, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.403598064341873, "policy_loss": -0.00908904017143878, "vf_loss": 6.411237482545237, "vf_explained_var": 0.05484040540362161, "kl": 0.00966420501884242, "entropy": 1.408920187294168, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 42525.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 92000, "num_env_steps_trained": 92000, "num_agent_steps_sampled": 368000, "num_agent_steps_trained": 368000}, "env_runners": {"episode_reward_max": 313.60000000000014, "episode_reward_min": -511.4999999999998, "episode_reward_mean": 67.52499999999993, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -829.9, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 197.29999999999998, "predator_policy": 496.0}, "policy_reward_mean": {"prey_policy": 1.567499999999981, "predator_policy": 32.195}, "custom_metrics": {}, "hist_stats": {"episode_reward": [76.9999999999997, 67.20000000000014, 107.69999999999982, -41.79999999999961, 54.30000000000043, 55.300000000000516, 93.69999999999968, 35.90000000000024, 40.0000000000003, 45.10000000000024, 29.10000000000013, 84.99999999999993, -191.9000000000008, 40.0000000000003, 130.29999999999959, 36.70000000000028, 74.3999999999998, 30.100000000000154, 74.19999999999968, 19.999999999999975, -11.99999999999993, 19.10000000000027, 110.29999999999973, -8.399999999999666, -40.19999999999988, 40.0000000000003, 42.300000000000345, 108.5999999999994, 22.600000000000012, 142.9999999999999, 81.49999999999967, 125.49999999999928, 134.29999999999987, 135.0999999999996, 141.69999999999922, 79.70000000000002, 40.0000000000003, 29.30000000000009, 87.79999999999984, -511.4999999999998, 250.59999999999945, 166.5999999999992, 78.3000000000001, 22.400000000000016, 66.30000000000011, 118.29999999999885, 2.600000000000068, 40.0000000000003, 26.300000000000125, 105.59999999999984, 244.99999999999937, 36.70000000000028, 20.50000000000012, 37.60000000000026, 50.40000000000033, 133.69999999999936, 134.1999999999999, 220.99999999999991, 211.59999999999988, 35.60000000000022, 40.0000000000003, 216.19999999999916, 147.49999999999963, 19.799999999999187, -155.99999999999994, 133.69999999999962, 89.79999999999995, 227.39999999999972, 23.800000000000253, 231.89999999999964, -239.1000000000003, 40.0000000000003, 284.30000000000007, 245.79999999999973, 247.3999999999997, 40.0000000000003, 205.09999999999965, 10.500000000000059, 60.80000000000027, 40.0000000000003, 297.7000000000004, -56.499999999999964, 24.60000000000028, 107.59999999999991, 154.99999999999946, 1.000000000000032, -300.4, -123.90000000000003, -82.00000000000014, 40.0000000000003, 5.3000000000000105, 138.5999999999994, 313.60000000000014, 145.3, -102.80000000000024, 282.5999999999999, 203.79999999999933, 28.49999999999985, 90.39999999999975, 40.90000000000031], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 35.00000000000013, 50.600000000000236, -18.39999999999982, 70.69999999999995, 20.000000000000014, -158.50000000000063, 31.700000000000212, 9.499999999999964, 39.80000000000022, 20.000000000000014, 35.30000000000025, -15.699999999999967, 10.4, 20.000000000000014, 2.8999999999999613, 20.000000000000014, 20.000000000000014, 3.5000000000000426, -18.39999999999975, 3.4999999999999654, 11.599999999999964, 31.700000000000212, 53.300000000000054, -181.3000000000004, -155.60000000000045, 20.000000000000014, 20.000000000000014, -56.500000000000334, 147.79999999999998, 20.000000000000014, 13.699999999999955, 20.000000000000014, 28.40000000000004, 20.000000000000014, 1.09999999999996, 35.000000000000256, -2.799999999999926, 20.000000000000014, -18.999999999999744, 63.50000000000009, -200.50000000000026, -19.900000000000016, 20.000000000000014, -146.50000000000048, 111.79999999999998, 20.000000000000014, -72.40000000000087, -305.5, 107.29999999999964, 20.000000000000014, 20.000000000000014, 33.50000000000024, -11.199999999999848, 20.000000000000014, 56.59999999999998, -5.199999999999934, 15.799999999999963, 53.59999999999999, 28.40000000000004, 57.500000000000185, 20.000000000000014, 20.000000000000014, 105.49999999999977, 28.400000000000134, 20.900000000000006, 115.69999999999996, 4.399999999999968, 41.60000000000016, 82.0999999999997, 20.000000000000014, -4.300000000000052, 20.000000000000014, 20.000000000000014, 20.000000000000014, -66.70000000000005, 9.799999999999963, 20.000000000000014, -502.8999999999998, -402.6, 156.79999999999984, 93.79999999999981, 7.4, 117.19999999999959, 60.499999999999964, 15.800000000000011, 20.000000000000014, -13.599999999999794, 11.59999999999997, -7.300000000000006, 20.000000000000014, 98.29999999999949, 15.799999999999946, -47.1999999999998, 20.000000000000014, 20.000000000000014, 130.7, -240.40000000000006, 90.19999999999999, 10.39999999999998, 137.29999999999976, 85.69999999999997, 13.699999999999955, 20.000000000000014, -295.1, 125.60000000000005, 20.000000000000014, -54.4, 16.99999999999999, -13.59999999999979, -7.3000000000000504, 127.99999999999982, -1.8999999999999986, 34.09999999999988, 28.39999999999999, 161.59999999999997, 5.899999999999885, 148.70000000000002, -6.399999999999993, 20.000000000000014, 20.000000000000014, 20.000000000000014, 108.79999999999978, 106.39999999999942, 132.49999999999997, -21.999999999999744, -4.2999999999998835, -46.89999999999991, -240.60000000000002, -109.40000000000003, 119.00000000000001, -7.3000000000000504, 96.49999999999997, -45.69999999999992, 156.2, 21.199999999999903, 20.000000000000014, -77.19999999999996, 106.99999999999997, 92.89999999999992, -215.2000000000001, -202.90000000000006, 20.000000000000014, 20.000000000000014, 159.49999999999997, 108.79999999999987, 123.19999999999996, 95.59999999999992, 119.30000000000005, 88.09999999999997, 20.000000000000014, 20.000000000000014, 55.700000000000024, 112.39999999999998, -17.79999999999974, -0.7000000000000169, -26.19999999999999, 20.000000000000014, 20.000000000000014, 20.000000000000014, 145.99999999999991, 139.69999999999993, -104.50000000000003, -124.0, 20.000000000000014, -9.40000000000003, 20.000000000000014, 38.60000000000002, 62.599999999999994, 52.400000000000205, -146.80000000000007, -26.19999999999998, -234.39999999999998, -288.99999999999994, -89.50000000000001, -171.39999999999998, -64.00000000000004, -84.99999999999999, 20.000000000000014, 20.000000000000014, -118.00000000000003, 5.299999999999965, 95.29999999999995, 5.299999999999965, 116.29999999999993, 197.29999999999998, 28.10000000000001, 63.2, 2.5999999999999717, -527.4, 168.49999999999991, -829.9, 20.000000000000014, 183.8, -134.5, 46.99999999999987, -203.90000000000003, 176.2999999999999, 20.000000000000014, 20.900000000000027], "policy_predator_policy_reward": [22.0, 0.0, 0.0, 35.0, 0.0, 17.0, 0.0, 85.0, 5.0, 0.0, 0.0, 0.0, 99.0, 0.0, 9.0, 4.0, 0.0, 0.0, 41.0, 19.0, 10.0, 4.0, 0.0, 0.0, 145.0, 0.0, 0.0, 0.0, 0.0, 39.0, 2.0, 1.0, 0.0, 26.0, 0.0, 9.0, 30.0, 12.0, 0.0, 19.0, 20.0, 105.0, 0.0, 19.0, 70.0, 75.0, 44.0, 0.0, 3.0, 155.0, 0.0, 0.0, 0.0, 20.0, 1.0, 31.0, 12.0, 0.0, 61.0, 0.0, 4.0, 0.0, 0.0, 0.0, 33.0, 52.0, 14.0, 1.0, 18.0, 0.0, 25.0, 39.0, 0.0, 0.0, 76.0, 0.0, 34.0, 24.0, 0.0, 394.0, 0.0, 0.0, 42.0, 0.0, 2.0, 0.0, 16.0, 0.0, 19.0, 43.0, 0.0, 0.0, 2.0, 32.0, 0.0, 0.0, 124.0, 12.0, 5.0, 0.0, 0.0, 22.0, 3.0, 0.0, 14.0, 176.0, 38.0, 34.0, 20.0, 27.0, 0.0, 13.0, 30.0, 72.0, 0.0, 31.0, 0.0, 57.0, 0.0, 22.0, 0.0, 0.0, 0.0, 1.0, 29.0, 8.0, 71.0, 0.0, 0.0, 194.0, 0.0, 22.0, 19.0, 20.0, 50.0, 0.0, 81.0, 0.0, 1.0, 31.0, 179.0, 0.0, 0.0, 0.0, 12.0, 4.0, 27.0, 0.0, 35.0, 5.0, 0.0, 0.0, 0.0, 37.0, 29.0, 0.0, 46.0, 21.0, 0.0, 0.0, 12.0, 0.0, 83.0, 89.0, 0.0, 14.0, 43.0, 6.0, 30.0, 10.0, 83.0, 91.0, 103.0, 120.0, 63.0, 74.0, 67.0, 0.0, 0.0, 0.0, 37.0, 81.0, 7.0, 31.0, 0.0, 0.0, 54.0, 0.0, 406.0, 16.0, 496.0, 448.0, 0.0, 0.0, 116.0, 0.0, 118.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.691737426937245, "mean_inference_ms": 1.5840898248434079, "mean_action_processing_ms": 0.27246941793335283, "mean_env_wait_ms": 0.20466554514665744, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.011226296424865723, "StateBufferConnector_ms": 0.004681110382080078, "ViewRequirementAgentConnector_ms": 0.15232551097869873}, "num_episodes": 27, "episode_return_max": 313.60000000000014, "episode_return_min": -511.4999999999998, "episode_return_mean": 67.52499999999993, "episodes_this_iter": 27}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 368000, "num_agent_steps_trained": 368000, "num_env_steps_sampled": 92000, "num_env_steps_trained": 92000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 79.03615553943676, "num_env_steps_trained_throughput_per_sec": 79.03615553943676, "timesteps_total": 92000, "num_env_steps_sampled_lifetime": 92000, "num_agent_steps_sampled_lifetime": 368000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 368000, "timers": {"training_iteration_time_ms": 50813.703, "restore_workers_time_ms": 0.013, "training_step_time_ms": 50813.651, "sample_time_ms": 1269.241, "learn_time_ms": 49530.332, "learn_throughput": 80.759, "synch_weights_time_ms": 10.705}, "counters": {"num_env_steps_sampled": 92000, "num_env_steps_trained": 92000, "num_agent_steps_sampled": 368000, "num_agent_steps_trained": 368000}, "done": false, "training_iteration": 23, "trial_id": "11e70_00000", "date": "2024-08-12_23-26-46", "timestamp": 1723519606, "time_this_iter_s": 50.66078996658325, "time_total_s": 1187.1690351963043, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2b8ce50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1187.1690351963043, "iterations_since_restore": 23, "perf": {"cpu_util_percent": 35.584722222222226, "ram_util_percent": 82.92916666666666}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 6.421409040090269, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.03770284703169, "policy_loss": -0.01147535858828594, "vf_loss": 7.047603756536252, "vf_explained_var": 0.09201585745054577, "kl": 0.010496280081042277, "entropy": 1.4115250967797779, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 44415.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.367684032235827, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.440421790925283, "policy_loss": -0.010209181984497244, "vf_loss": 7.449464644830694, "vf_explained_var": -0.14986950979030952, "kl": 0.007775648256935369, "entropy": 1.442961941825019, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 44415.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 96000, "num_env_steps_trained": 96000, "num_agent_steps_sampled": 384000, "num_agent_steps_trained": 384000}, "env_runners": {"episode_reward_max": 313.60000000000014, "episode_reward_min": -511.4999999999998, "episode_reward_mean": 54.47999999999993, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -829.9, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 197.29999999999998, "predator_policy": 496.0}, "policy_reward_mean": {"prey_policy": -13.480000000000018, "predator_policy": 40.72}, "custom_metrics": {}, "hist_stats": {"episode_reward": [74.19999999999968, 19.999999999999975, -11.99999999999993, 19.10000000000027, 110.29999999999973, -8.399999999999666, -40.19999999999988, 40.0000000000003, 42.300000000000345, 108.5999999999994, 22.600000000000012, 142.9999999999999, 81.49999999999967, 125.49999999999928, 134.29999999999987, 135.0999999999996, 141.69999999999922, 79.70000000000002, 40.0000000000003, 29.30000000000009, 87.79999999999984, -511.4999999999998, 250.59999999999945, 166.5999999999992, 78.3000000000001, 22.400000000000016, 66.30000000000011, 118.29999999999885, 2.600000000000068, 40.0000000000003, 26.300000000000125, 105.59999999999984, 244.99999999999937, 36.70000000000028, 20.50000000000012, 37.60000000000026, 50.40000000000033, 133.69999999999936, 134.1999999999999, 220.99999999999991, 211.59999999999988, 35.60000000000022, 40.0000000000003, 216.19999999999916, 147.49999999999963, 19.799999999999187, -155.99999999999994, 133.69999999999962, 89.79999999999995, 227.39999999999972, 23.800000000000253, 231.89999999999964, -239.1000000000003, 40.0000000000003, 284.30000000000007, 245.79999999999973, 247.3999999999997, 40.0000000000003, 205.09999999999965, 10.500000000000059, 60.80000000000027, 40.0000000000003, 297.7000000000004, -56.499999999999964, 24.60000000000028, 107.59999999999991, 154.99999999999946, 1.000000000000032, -300.4, -123.90000000000003, -82.00000000000014, 40.0000000000003, 5.3000000000000105, 138.5999999999994, 313.60000000000014, 145.3, -102.80000000000024, 282.5999999999999, 203.79999999999933, 28.49999999999985, 90.39999999999975, 40.90000000000031, 49.89999999999972, 23.50000000000012, 64.50000000000014, 7.000000000000007, -179.90000000000003, 50.89999999999998, -154.8999999999999, -328.4999999999999, 47.90000000000014, -4.2999999999999865, -22.09999999999995, -117.90000000000003, -121.00000000000006, 53.20000000000012, 37.10000000000002, 2.9000000000001394, 8.700000000000182, 46.60000000000008], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [35.000000000000256, -2.799999999999926, 20.000000000000014, -18.999999999999744, 63.50000000000009, -200.50000000000026, -19.900000000000016, 20.000000000000014, -146.50000000000048, 111.79999999999998, 20.000000000000014, -72.40000000000087, -305.5, 107.29999999999964, 20.000000000000014, 20.000000000000014, 33.50000000000024, -11.199999999999848, 20.000000000000014, 56.59999999999998, -5.199999999999934, 15.799999999999963, 53.59999999999999, 28.40000000000004, 57.500000000000185, 20.000000000000014, 20.000000000000014, 105.49999999999977, 28.400000000000134, 20.900000000000006, 115.69999999999996, 4.399999999999968, 41.60000000000016, 82.0999999999997, 20.000000000000014, -4.300000000000052, 20.000000000000014, 20.000000000000014, 20.000000000000014, -66.70000000000005, 9.799999999999963, 20.000000000000014, -502.8999999999998, -402.6, 156.79999999999984, 93.79999999999981, 7.4, 117.19999999999959, 60.499999999999964, 15.800000000000011, 20.000000000000014, -13.599999999999794, 11.59999999999997, -7.300000000000006, 20.000000000000014, 98.29999999999949, 15.799999999999946, -47.1999999999998, 20.000000000000014, 20.000000000000014, 130.7, -240.40000000000006, 90.19999999999999, 10.39999999999998, 137.29999999999976, 85.69999999999997, 13.699999999999955, 20.000000000000014, -295.1, 125.60000000000005, 20.000000000000014, -54.4, 16.99999999999999, -13.59999999999979, -7.3000000000000504, 127.99999999999982, -1.8999999999999986, 34.09999999999988, 28.39999999999999, 161.59999999999997, 5.899999999999885, 148.70000000000002, -6.399999999999993, 20.000000000000014, 20.000000000000014, 20.000000000000014, 108.79999999999978, 106.39999999999942, 132.49999999999997, -21.999999999999744, -4.2999999999998835, -46.89999999999991, -240.60000000000002, -109.40000000000003, 119.00000000000001, -7.3000000000000504, 96.49999999999997, -45.69999999999992, 156.2, 21.199999999999903, 20.000000000000014, -77.19999999999996, 106.99999999999997, 92.89999999999992, -215.2000000000001, -202.90000000000006, 20.000000000000014, 20.000000000000014, 159.49999999999997, 108.79999999999987, 123.19999999999996, 95.59999999999992, 119.30000000000005, 88.09999999999997, 20.000000000000014, 20.000000000000014, 55.700000000000024, 112.39999999999998, -17.79999999999974, -0.7000000000000169, -26.19999999999999, 20.000000000000014, 20.000000000000014, 20.000000000000014, 145.99999999999991, 139.69999999999993, -104.50000000000003, -124.0, 20.000000000000014, -9.40000000000003, 20.000000000000014, 38.60000000000002, 62.599999999999994, 52.400000000000205, -146.80000000000007, -26.19999999999998, -234.39999999999998, -288.99999999999994, -89.50000000000001, -171.39999999999998, -64.00000000000004, -84.99999999999999, 20.000000000000014, 20.000000000000014, -118.00000000000003, 5.299999999999965, 95.29999999999995, 5.299999999999965, 116.29999999999993, 197.29999999999998, 28.10000000000001, 63.2, 2.5999999999999717, -527.4, 168.49999999999991, -829.9, 20.000000000000014, 183.8, -134.5, 46.99999999999987, -203.90000000000003, 176.2999999999999, 20.000000000000014, 20.900000000000027, -70.9, 30.800000000000196, -56.5, 20.000000000000014, -82.89999999999998, 7.399999999999965, -24.39999999999999, -82.60000000000002, -202.9, -172.00000000000003, -31.899999999999977, -26.19999999999999, -186.70000000000013, -113.20000000000002, -187.90000000000003, -313.5999999999999, -91.30000000000025, 30.200000000000003, -124.3, 20.000000000000014, 17.899999999999988, -208.0, -147.7, -92.19999999999999, -174.1, -145.90000000000006, -87.09999999999997, 44.3, -85.89999999999998, 4.999999999999972, 20.000000000000014, -198.10000000000005, -64.30000000000005, 20.000000000000014, -49.00000000000001, -9.400000000000011], "policy_predator_policy_reward": [30.0, 12.0, 0.0, 19.0, 20.0, 105.0, 0.0, 19.0, 70.0, 75.0, 44.0, 0.0, 3.0, 155.0, 0.0, 0.0, 0.0, 20.0, 1.0, 31.0, 12.0, 0.0, 61.0, 0.0, 4.0, 0.0, 0.0, 0.0, 33.0, 52.0, 14.0, 1.0, 18.0, 0.0, 25.0, 39.0, 0.0, 0.0, 76.0, 0.0, 34.0, 24.0, 0.0, 394.0, 0.0, 0.0, 42.0, 0.0, 2.0, 0.0, 16.0, 0.0, 19.0, 43.0, 0.0, 0.0, 2.0, 32.0, 0.0, 0.0, 124.0, 12.0, 5.0, 0.0, 0.0, 22.0, 3.0, 0.0, 14.0, 176.0, 38.0, 34.0, 20.0, 27.0, 0.0, 13.0, 30.0, 72.0, 0.0, 31.0, 0.0, 57.0, 0.0, 22.0, 0.0, 0.0, 0.0, 1.0, 29.0, 8.0, 71.0, 0.0, 0.0, 194.0, 0.0, 22.0, 19.0, 20.0, 50.0, 0.0, 81.0, 0.0, 1.0, 31.0, 179.0, 0.0, 0.0, 0.0, 12.0, 4.0, 27.0, 0.0, 35.0, 5.0, 0.0, 0.0, 0.0, 37.0, 29.0, 0.0, 46.0, 21.0, 0.0, 0.0, 12.0, 0.0, 83.0, 89.0, 0.0, 14.0, 43.0, 6.0, 30.0, 10.0, 83.0, 91.0, 103.0, 120.0, 63.0, 74.0, 67.0, 0.0, 0.0, 0.0, 37.0, 81.0, 7.0, 31.0, 0.0, 0.0, 54.0, 0.0, 406.0, 16.0, 496.0, 448.0, 0.0, 0.0, 116.0, 0.0, 118.0, 0.0, 0.0, 0.0, 0.0, 90.0, 60.0, 0.0, 51.0, 89.0, 18.0, 96.0, 67.0, 128.0, 109.0, 0.0, 68.0, 77.0, 173.0, 0.0, 56.0, 53.0, 36.0, 64.0, 55.0, 113.0, 0.0, 122.0, 131.0, 68.0, 51.0, 45.0, 40.0, 78.0, 102.0, 79.0, 15.0, 38.0, 105.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6886276750392938, "mean_inference_ms": 1.5794255926351617, "mean_action_processing_ms": 0.27135529424578236, "mean_env_wait_ms": 0.2039874076057655, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.009261131286621094, "StateBufferConnector_ms": 0.0037592649459838867, "ViewRequirementAgentConnector_ms": 0.12959551811218262}, "num_episodes": 18, "episode_return_max": 313.60000000000014, "episode_return_min": -511.4999999999998, "episode_return_mean": 54.47999999999993, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 384000, "num_agent_steps_trained": 384000, "num_env_steps_sampled": 96000, "num_env_steps_trained": 96000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 75.87130265455785, "num_env_steps_trained_throughput_per_sec": 75.87130265455785, "timesteps_total": 96000, "num_env_steps_sampled_lifetime": 96000, "num_agent_steps_sampled_lifetime": 384000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 384000, "timers": {"training_iteration_time_ms": 51005.189, "restore_workers_time_ms": 0.013, "training_step_time_ms": 51005.137, "sample_time_ms": 1274.624, "learn_time_ms": 49716.245, "learn_throughput": 80.457, "synch_weights_time_ms": 10.87}, "counters": {"num_env_steps_sampled": 96000, "num_env_steps_trained": 96000, "num_agent_steps_sampled": 384000, "num_agent_steps_trained": 384000}, "done": false, "training_iteration": 24, "trial_id": "11e70_00000", "date": "2024-08-12_23-27-39", "timestamp": 1723519659, "time_this_iter_s": 52.7682728767395, "time_total_s": 1239.9373080730438, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3f39ca0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1239.9373080730438, "iterations_since_restore": 24, "perf": {"cpu_util_percent": 44.45945945945945, "ram_util_percent": 82.32837837837837}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 6.356159284379747, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.777637240747926, "policy_loss": -0.010510687074973863, "vf_loss": 6.786651933508575, "vf_explained_var": 0.0526248056421835, "kl": 0.00997334841601635, "entropy": 1.3882181410436276, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 46305.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.3080704494128153, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.242192718970082, "policy_loss": -0.011115914989243109, "vf_loss": 7.251943342774003, "vf_explained_var": -0.17578746477762858, "kl": 0.00910196362966515, "entropy": 1.384039458143648, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 46305.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 100000, "num_env_steps_trained": 100000, "num_agent_steps_sampled": 400000, "num_agent_steps_trained": 400000}, "env_runners": {"episode_reward_max": 313.60000000000014, "episode_reward_min": -511.4999999999998, "episode_reward_mean": 30.769999999999953, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -829.9, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 197.29999999999998, "predator_policy": 496.0}, "policy_reward_mean": {"prey_policy": -34.990000000000016, "predator_policy": 50.375}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.0000000000003, 29.30000000000009, 87.79999999999984, -511.4999999999998, 250.59999999999945, 166.5999999999992, 78.3000000000001, 22.400000000000016, 66.30000000000011, 118.29999999999885, 2.600000000000068, 40.0000000000003, 26.300000000000125, 105.59999999999984, 244.99999999999937, 36.70000000000028, 20.50000000000012, 37.60000000000026, 50.40000000000033, 133.69999999999936, 134.1999999999999, 220.99999999999991, 211.59999999999988, 35.60000000000022, 40.0000000000003, 216.19999999999916, 147.49999999999963, 19.799999999999187, -155.99999999999994, 133.69999999999962, 89.79999999999995, 227.39999999999972, 23.800000000000253, 231.89999999999964, -239.1000000000003, 40.0000000000003, 284.30000000000007, 245.79999999999973, 247.3999999999997, 40.0000000000003, 205.09999999999965, 10.500000000000059, 60.80000000000027, 40.0000000000003, 297.7000000000004, -56.499999999999964, 24.60000000000028, 107.59999999999991, 154.99999999999946, 1.000000000000032, -300.4, -123.90000000000003, -82.00000000000014, 40.0000000000003, 5.3000000000000105, 138.5999999999994, 313.60000000000014, 145.3, -102.80000000000024, 282.5999999999999, 203.79999999999933, 28.49999999999985, 90.39999999999975, 40.90000000000031, 49.89999999999972, 23.50000000000012, 64.50000000000014, 7.000000000000007, -179.90000000000003, 50.89999999999998, -154.8999999999999, -328.4999999999999, 47.90000000000014, -4.2999999999999865, -22.09999999999995, -117.90000000000003, -121.00000000000006, 53.20000000000012, 37.10000000000002, 2.9000000000001394, 8.700000000000182, 46.60000000000008, -47.00000000000005, -303.7000000000001, -84.30000000000001, -105.90000000000005, -72.09999999999994, -118.00000000000081, -67.8000000000002, -30.400000000000034, -46.89999999999993, -20.3999999999999, -40.199999999999854, -45.29999999999988, -52.69999999999999, -272.0999999999997, 57.00000000000019, 45.000000000000064, 2.300000000000149, 48.80000000000027], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 20.000000000000014, 20.000000000000014, -66.70000000000005, 9.799999999999963, 20.000000000000014, -502.8999999999998, -402.6, 156.79999999999984, 93.79999999999981, 7.4, 117.19999999999959, 60.499999999999964, 15.800000000000011, 20.000000000000014, -13.599999999999794, 11.59999999999997, -7.300000000000006, 20.000000000000014, 98.29999999999949, 15.799999999999946, -47.1999999999998, 20.000000000000014, 20.000000000000014, 130.7, -240.40000000000006, 90.19999999999999, 10.39999999999998, 137.29999999999976, 85.69999999999997, 13.699999999999955, 20.000000000000014, -295.1, 125.60000000000005, 20.000000000000014, -54.4, 16.99999999999999, -13.59999999999979, -7.3000000000000504, 127.99999999999982, -1.8999999999999986, 34.09999999999988, 28.39999999999999, 161.59999999999997, 5.899999999999885, 148.70000000000002, -6.399999999999993, 20.000000000000014, 20.000000000000014, 20.000000000000014, 108.79999999999978, 106.39999999999942, 132.49999999999997, -21.999999999999744, -4.2999999999998835, -46.89999999999991, -240.60000000000002, -109.40000000000003, 119.00000000000001, -7.3000000000000504, 96.49999999999997, -45.69999999999992, 156.2, 21.199999999999903, 20.000000000000014, -77.19999999999996, 106.99999999999997, 92.89999999999992, -215.2000000000001, -202.90000000000006, 20.000000000000014, 20.000000000000014, 159.49999999999997, 108.79999999999987, 123.19999999999996, 95.59999999999992, 119.30000000000005, 88.09999999999997, 20.000000000000014, 20.000000000000014, 55.700000000000024, 112.39999999999998, -17.79999999999974, -0.7000000000000169, -26.19999999999999, 20.000000000000014, 20.000000000000014, 20.000000000000014, 145.99999999999991, 139.69999999999993, -104.50000000000003, -124.0, 20.000000000000014, -9.40000000000003, 20.000000000000014, 38.60000000000002, 62.599999999999994, 52.400000000000205, -146.80000000000007, -26.19999999999998, -234.39999999999998, -288.99999999999994, -89.50000000000001, -171.39999999999998, -64.00000000000004, -84.99999999999999, 20.000000000000014, 20.000000000000014, -118.00000000000003, 5.299999999999965, 95.29999999999995, 5.299999999999965, 116.29999999999993, 197.29999999999998, 28.10000000000001, 63.2, 2.5999999999999717, -527.4, 168.49999999999991, -829.9, 20.000000000000014, 183.8, -134.5, 46.99999999999987, -203.90000000000003, 176.2999999999999, 20.000000000000014, 20.900000000000027, -70.9, 30.800000000000196, -56.5, 20.000000000000014, -82.89999999999998, 7.399999999999965, -24.39999999999999, -82.60000000000002, -202.9, -172.00000000000003, -31.899999999999977, -26.19999999999999, -186.70000000000013, -113.20000000000002, -187.90000000000003, -313.5999999999999, -91.30000000000025, 30.200000000000003, -124.3, 20.000000000000014, 17.899999999999988, -208.0, -147.7, -92.19999999999999, -174.1, -145.90000000000006, -87.09999999999997, 44.3, -85.89999999999998, 4.999999999999972, 20.000000000000014, -198.10000000000005, -64.30000000000005, 20.000000000000014, -49.00000000000001, -9.400000000000011, -119.20000000000005, -80.80000000000084, -337.9, -239.80000000000004, 20.000000000000014, -253.30000000000004, -220.60000000000008, -22.299999999999997, -267.1, 20.000000000000014, -459.9999999999991, 20.000000000000014, -119.50000000000001, -61.300000000000026, -13.599999999999826, -80.80000000000004, -40.899999999999956, -139.0, 7.399999999999965, -149.8, 34.39999999999999, -325.59999999999997, 20.000000000000014, -229.30000000000004, -133.90000000000018, -56.80000000000007, -202.60000000000005, -209.50000000000003, 40.39999999999998, 11.599999999999978, -4.299999999999956, -57.70000000000003, -168.7, 20.000000000000014, -167.2, 20.000000000000014], "policy_predator_policy_reward": [0.0, 0.0, 76.0, 0.0, 34.0, 24.0, 0.0, 394.0, 0.0, 0.0, 42.0, 0.0, 2.0, 0.0, 16.0, 0.0, 19.0, 43.0, 0.0, 0.0, 2.0, 32.0, 0.0, 0.0, 124.0, 12.0, 5.0, 0.0, 0.0, 22.0, 3.0, 0.0, 14.0, 176.0, 38.0, 34.0, 20.0, 27.0, 0.0, 13.0, 30.0, 72.0, 0.0, 31.0, 0.0, 57.0, 0.0, 22.0, 0.0, 0.0, 0.0, 1.0, 29.0, 8.0, 71.0, 0.0, 0.0, 194.0, 0.0, 22.0, 19.0, 20.0, 50.0, 0.0, 81.0, 0.0, 1.0, 31.0, 179.0, 0.0, 0.0, 0.0, 12.0, 4.0, 27.0, 0.0, 35.0, 5.0, 0.0, 0.0, 0.0, 37.0, 29.0, 0.0, 46.0, 21.0, 0.0, 0.0, 12.0, 0.0, 83.0, 89.0, 0.0, 14.0, 43.0, 6.0, 30.0, 10.0, 83.0, 91.0, 103.0, 120.0, 63.0, 74.0, 67.0, 0.0, 0.0, 0.0, 37.0, 81.0, 7.0, 31.0, 0.0, 0.0, 54.0, 0.0, 406.0, 16.0, 496.0, 448.0, 0.0, 0.0, 116.0, 0.0, 118.0, 0.0, 0.0, 0.0, 0.0, 90.0, 60.0, 0.0, 51.0, 89.0, 18.0, 96.0, 67.0, 128.0, 109.0, 0.0, 68.0, 77.0, 173.0, 0.0, 56.0, 53.0, 36.0, 64.0, 55.0, 113.0, 0.0, 122.0, 131.0, 68.0, 51.0, 45.0, 40.0, 78.0, 102.0, 79.0, 15.0, 38.0, 105.0, 0.0, 57.0, 96.0, 152.0, 122.0, 0.0, 149.0, 137.0, 0.0, 106.0, 69.0, 322.0, 0.0, 0.0, 113.0, 48.0, 16.0, 29.0, 104.0, 122.0, 0.0, 117.0, 134.0, 107.0, 57.0, 58.0, 80.0, 0.0, 140.0, 4.0, 1.0, 37.0, 70.0, 60.0, 91.0, 77.0, 119.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.68750735471023, "mean_inference_ms": 1.5747694505477685, "mean_action_processing_ms": 0.27071992503075354, "mean_env_wait_ms": 0.20352128776180733, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.009835600852966309, "StateBufferConnector_ms": 0.0037952661514282227, "ViewRequirementAgentConnector_ms": 0.13524949550628662}, "num_episodes": 18, "episode_return_max": 313.60000000000014, "episode_return_min": -511.4999999999998, "episode_return_mean": 30.769999999999953, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 400000, "num_agent_steps_trained": 400000, "num_env_steps_sampled": 100000, "num_env_steps_trained": 100000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 79.28298519822688, "num_env_steps_trained_throughput_per_sec": 79.28298519822688, "timesteps_total": 100000, "num_env_steps_sampled_lifetime": 100000, "num_agent_steps_sampled_lifetime": 400000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 400000, "timers": {"training_iteration_time_ms": 50966.399, "restore_workers_time_ms": 0.013, "training_step_time_ms": 50966.346, "sample_time_ms": 1282.202, "learn_time_ms": 49670.388, "learn_throughput": 80.531, "synch_weights_time_ms": 10.724}, "counters": {"num_env_steps_sampled": 100000, "num_env_steps_trained": 100000, "num_agent_steps_sampled": 400000, "num_agent_steps_trained": 400000}, "done": false, "training_iteration": 25, "trial_id": "11e70_00000", "date": "2024-08-12_23-28-30", "timestamp": 1723519710, "time_this_iter_s": 50.48325181007385, "time_total_s": 1290.4205598831177, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2b61790>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1290.4205598831177, "iterations_since_restore": 25, "perf": {"cpu_util_percent": 35.37777777777777, "ram_util_percent": 83.04444444444445}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 7.594724556819472, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.895911289144445, "policy_loss": -0.008712265589988973, "vf_loss": 6.903395823574571, "vf_explained_var": 0.08740981369422227, "kl": 0.008184885807785428, "entropy": 1.383727574726892, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 48195.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.7679842020784107, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.641602175576346, "policy_loss": -0.009314301056743022, "vf_loss": 6.649485776790235, "vf_explained_var": -0.15231039971901625, "kl": 0.009537945023673593, "entropy": 1.3621493959553028, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 48195.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 104000, "num_env_steps_trained": 104000, "num_agent_steps_sampled": 416000, "num_agent_steps_trained": 416000}, "env_runners": {"episode_reward_max": 313.60000000000014, "episode_reward_min": -428.6000000000001, "episode_reward_mean": 4.406999999999951, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -829.9, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 197.29999999999998, "predator_policy": 496.0}, "policy_reward_mean": {"prey_policy": -57.54650000000002, "predator_policy": 59.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [50.40000000000033, 133.69999999999936, 134.1999999999999, 220.99999999999991, 211.59999999999988, 35.60000000000022, 40.0000000000003, 216.19999999999916, 147.49999999999963, 19.799999999999187, -155.99999999999994, 133.69999999999962, 89.79999999999995, 227.39999999999972, 23.800000000000253, 231.89999999999964, -239.1000000000003, 40.0000000000003, 284.30000000000007, 245.79999999999973, 247.3999999999997, 40.0000000000003, 205.09999999999965, 10.500000000000059, 60.80000000000027, 40.0000000000003, 297.7000000000004, -56.499999999999964, 24.60000000000028, 107.59999999999991, 154.99999999999946, 1.000000000000032, -300.4, -123.90000000000003, -82.00000000000014, 40.0000000000003, 5.3000000000000105, 138.5999999999994, 313.60000000000014, 145.3, -102.80000000000024, 282.5999999999999, 203.79999999999933, 28.49999999999985, 90.39999999999975, 40.90000000000031, 49.89999999999972, 23.50000000000012, 64.50000000000014, 7.000000000000007, -179.90000000000003, 50.89999999999998, -154.8999999999999, -328.4999999999999, 47.90000000000014, -4.2999999999999865, -22.09999999999995, -117.90000000000003, -121.00000000000006, 53.20000000000012, 37.10000000000002, 2.9000000000001394, 8.700000000000182, 46.60000000000008, -47.00000000000005, -303.7000000000001, -84.30000000000001, -105.90000000000005, -72.09999999999994, -118.00000000000081, -67.8000000000002, -30.400000000000034, -46.89999999999993, -20.3999999999999, -40.199999999999854, -45.29999999999988, -52.69999999999999, -272.0999999999997, 57.00000000000019, 45.000000000000064, 2.300000000000149, 48.80000000000027, -411.89999999999986, -126.00000000000034, -428.6000000000001, 3.5000000000002025, -109.80000000000041, -219.3, -263.90000000000003, 75.59999999999937, -99.30000000000044, -52.89999999999985, 61.600000000000115, 183.7999999999994, -13.199999999999882, -2.199999999999936, -194.7000000000001, -14.599999999999916, -2.1999999999999265, -159.8], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [16.99999999999999, -13.59999999999979, -7.3000000000000504, 127.99999999999982, -1.8999999999999986, 34.09999999999988, 28.39999999999999, 161.59999999999997, 5.899999999999885, 148.70000000000002, -6.399999999999993, 20.000000000000014, 20.000000000000014, 20.000000000000014, 108.79999999999978, 106.39999999999942, 132.49999999999997, -21.999999999999744, -4.2999999999998835, -46.89999999999991, -240.60000000000002, -109.40000000000003, 119.00000000000001, -7.3000000000000504, 96.49999999999997, -45.69999999999992, 156.2, 21.199999999999903, 20.000000000000014, -77.19999999999996, 106.99999999999997, 92.89999999999992, -215.2000000000001, -202.90000000000006, 20.000000000000014, 20.000000000000014, 159.49999999999997, 108.79999999999987, 123.19999999999996, 95.59999999999992, 119.30000000000005, 88.09999999999997, 20.000000000000014, 20.000000000000014, 55.700000000000024, 112.39999999999998, -17.79999999999974, -0.7000000000000169, -26.19999999999999, 20.000000000000014, 20.000000000000014, 20.000000000000014, 145.99999999999991, 139.69999999999993, -104.50000000000003, -124.0, 20.000000000000014, -9.40000000000003, 20.000000000000014, 38.60000000000002, 62.599999999999994, 52.400000000000205, -146.80000000000007, -26.19999999999998, -234.39999999999998, -288.99999999999994, -89.50000000000001, -171.39999999999998, -64.00000000000004, -84.99999999999999, 20.000000000000014, 20.000000000000014, -118.00000000000003, 5.299999999999965, 95.29999999999995, 5.299999999999965, 116.29999999999993, 197.29999999999998, 28.10000000000001, 63.2, 2.5999999999999717, -527.4, 168.49999999999991, -829.9, 20.000000000000014, 183.8, -134.5, 46.99999999999987, -203.90000000000003, 176.2999999999999, 20.000000000000014, 20.900000000000027, -70.9, 30.800000000000196, -56.5, 20.000000000000014, -82.89999999999998, 7.399999999999965, -24.39999999999999, -82.60000000000002, -202.9, -172.00000000000003, -31.899999999999977, -26.19999999999999, -186.70000000000013, -113.20000000000002, -187.90000000000003, -313.5999999999999, -91.30000000000025, 30.200000000000003, -124.3, 20.000000000000014, 17.899999999999988, -208.0, -147.7, -92.19999999999999, -174.1, -145.90000000000006, -87.09999999999997, 44.3, -85.89999999999998, 4.999999999999972, 20.000000000000014, -198.10000000000005, -64.30000000000005, 20.000000000000014, -49.00000000000001, -9.400000000000011, -119.20000000000005, -80.80000000000084, -337.9, -239.80000000000004, 20.000000000000014, -253.30000000000004, -220.60000000000008, -22.299999999999997, -267.1, 20.000000000000014, -459.9999999999991, 20.000000000000014, -119.50000000000001, -61.300000000000026, -13.599999999999826, -80.80000000000004, -40.899999999999956, -139.0, 7.399999999999965, -149.8, 34.39999999999999, -325.59999999999997, 20.000000000000014, -229.30000000000004, -133.90000000000018, -56.80000000000007, -202.60000000000005, -209.50000000000003, 40.39999999999998, 11.599999999999978, -4.299999999999956, -57.70000000000003, -168.7, 20.000000000000014, -167.2, 20.000000000000014, -288.70000000000005, -302.1999999999998, -326.0999999999999, 4.1, -321.1, -362.5, 22.400000000000052, -133.9, 20.000000000000014, -293.79999999999995, -221.50000000000006, -179.8, -204.10000000000002, -200.8, 10.39999999999998, 36.20000000000026, -301.59999999999997, -72.70000000000059, -268.90000000000003, 20.000000000000014, 24.50000000000008, -7.899999999999999, 183.79999999999998, -106.0000000000008, -34.59999999999975, -139.60000000000002, -89.2000000000005, 20.000000000000014, -261.7, -178.00000000000003, 20.000000000000014, -244.60000000000002, -245.2, 20.000000000000014, -178.00000000000003, -179.8], "policy_predator_policy_reward": [20.0, 27.0, 0.0, 13.0, 30.0, 72.0, 0.0, 31.0, 0.0, 57.0, 0.0, 22.0, 0.0, 0.0, 0.0, 1.0, 29.0, 8.0, 71.0, 0.0, 0.0, 194.0, 0.0, 22.0, 19.0, 20.0, 50.0, 0.0, 81.0, 0.0, 1.0, 31.0, 179.0, 0.0, 0.0, 0.0, 12.0, 4.0, 27.0, 0.0, 35.0, 5.0, 0.0, 0.0, 0.0, 37.0, 29.0, 0.0, 46.0, 21.0, 0.0, 0.0, 12.0, 0.0, 83.0, 89.0, 0.0, 14.0, 43.0, 6.0, 30.0, 10.0, 83.0, 91.0, 103.0, 120.0, 63.0, 74.0, 67.0, 0.0, 0.0, 0.0, 37.0, 81.0, 7.0, 31.0, 0.0, 0.0, 54.0, 0.0, 406.0, 16.0, 496.0, 448.0, 0.0, 0.0, 116.0, 0.0, 118.0, 0.0, 0.0, 0.0, 0.0, 90.0, 60.0, 0.0, 51.0, 89.0, 18.0, 96.0, 67.0, 128.0, 109.0, 0.0, 68.0, 77.0, 173.0, 0.0, 56.0, 53.0, 36.0, 64.0, 55.0, 113.0, 0.0, 122.0, 131.0, 68.0, 51.0, 45.0, 40.0, 78.0, 102.0, 79.0, 15.0, 38.0, 105.0, 0.0, 57.0, 96.0, 152.0, 122.0, 0.0, 149.0, 137.0, 0.0, 106.0, 69.0, 322.0, 0.0, 0.0, 113.0, 48.0, 16.0, 29.0, 104.0, 122.0, 0.0, 117.0, 134.0, 107.0, 57.0, 58.0, 80.0, 0.0, 140.0, 4.0, 1.0, 37.0, 70.0, 60.0, 91.0, 77.0, 119.0, 179.0, 0.0, 26.0, 170.0, 73.0, 182.0, 115.0, 0.0, 164.0, 0.0, 0.0, 182.0, 141.0, 0.0, 0.0, 29.0, 105.0, 170.0, 90.0, 106.0, 45.0, 0.0, 59.0, 47.0, 107.0, 54.0, 67.0, 0.0, 146.0, 99.0, 135.0, 75.0, 137.0, 86.0, 110.0, 88.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6862625275075106, "mean_inference_ms": 1.5704729830813804, "mean_action_processing_ms": 0.2700491022056608, "mean_env_wait_ms": 0.20309492366998225, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005648255348205566, "StateBufferConnector_ms": 0.003763556480407715, "ViewRequirementAgentConnector_ms": 0.13332462310791016}, "num_episodes": 18, "episode_return_max": 313.60000000000014, "episode_return_min": -428.6000000000001, "episode_return_mean": 4.406999999999951, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 416000, "num_agent_steps_trained": 416000, "num_env_steps_sampled": 104000, "num_env_steps_trained": 104000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 78.88024017499123, "num_env_steps_trained_throughput_per_sec": 78.88024017499123, "timesteps_total": 104000, "num_env_steps_sampled_lifetime": 104000, "num_agent_steps_sampled_lifetime": 416000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 416000, "timers": {"training_iteration_time_ms": 50868.06, "restore_workers_time_ms": 0.013, "training_step_time_ms": 50868.007, "sample_time_ms": 1251.805, "learn_time_ms": 49602.355, "learn_throughput": 80.641, "synch_weights_time_ms": 10.857}, "counters": {"num_env_steps_sampled": 104000, "num_env_steps_trained": 104000, "num_agent_steps_sampled": 416000, "num_agent_steps_trained": 416000}, "done": false, "training_iteration": 26, "trial_id": "11e70_00000", "date": "2024-08-12_23-29-20", "timestamp": 1723519760, "time_this_iter_s": 50.74709177017212, "time_total_s": 1341.1676516532898, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2b624c0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1341.1676516532898, "iterations_since_restore": 26, "perf": {"cpu_util_percent": 36.04929577464789, "ram_util_percent": 82.62535211267605}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 7.432343908214064, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.001966211278603, "policy_loss": -0.011579632731006732, "vf_loss": 7.012086843561243, "vf_explained_var": 0.09382759947625417, "kl": 0.00972664497416696, "entropy": 1.3766304791919768, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 50085.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.2619271093890783, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.372526699651486, "policy_loss": -0.012514008842679676, "vf_loss": 6.383499821405562, "vf_explained_var": -0.2433374496994826, "kl": 0.010272562004632996, "entropy": 1.3588160499693855, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 50085.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 108000, "num_env_steps_trained": 108000, "num_agent_steps_sampled": 432000, "num_agent_steps_trained": 432000}, "env_runners": {"episode_reward_max": 313.60000000000014, "episode_reward_min": -428.6000000000001, "episode_reward_mean": -36.693000000000005, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -829.9, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 197.29999999999998, "predator_policy": 496.0}, "policy_reward_mean": {"prey_policy": -93.51650000000001, "predator_policy": 75.17}, "custom_metrics": {}, "hist_stats": {"episode_reward": [205.09999999999965, 10.500000000000059, 60.80000000000027, 40.0000000000003, 297.7000000000004, -56.499999999999964, 24.60000000000028, 107.59999999999991, 154.99999999999946, 1.000000000000032, -300.4, -123.90000000000003, -82.00000000000014, 40.0000000000003, 5.3000000000000105, 138.5999999999994, 313.60000000000014, 145.3, -102.80000000000024, 282.5999999999999, 203.79999999999933, 28.49999999999985, 90.39999999999975, 40.90000000000031, 49.89999999999972, 23.50000000000012, 64.50000000000014, 7.000000000000007, -179.90000000000003, 50.89999999999998, -154.8999999999999, -328.4999999999999, 47.90000000000014, -4.2999999999999865, -22.09999999999995, -117.90000000000003, -121.00000000000006, 53.20000000000012, 37.10000000000002, 2.9000000000001394, 8.700000000000182, 46.60000000000008, -47.00000000000005, -303.7000000000001, -84.30000000000001, -105.90000000000005, -72.09999999999994, -118.00000000000081, -67.8000000000002, -30.400000000000034, -46.89999999999993, -20.3999999999999, -40.199999999999854, -45.29999999999988, -52.69999999999999, -272.0999999999997, 57.00000000000019, 45.000000000000064, 2.300000000000149, 48.80000000000027, -411.89999999999986, -126.00000000000034, -428.6000000000001, 3.5000000000002025, -109.80000000000041, -219.3, -263.90000000000003, 75.59999999999937, -99.30000000000044, -52.89999999999985, 61.600000000000115, 183.7999999999994, -13.199999999999882, -2.199999999999936, -194.7000000000001, -14.599999999999916, -2.1999999999999265, -159.8, -307.4999999999999, -191.9, -316.30000000000007, -3.3999999999998938, 30.900000000000148, -37.19999999999985, 0.7000000000002005, -141.9, -334.2999999999998, 45.300000000000246, 37.80000000000027, 0.30000000000001936, -267.30000000000007, -130.50000000000037, 1.4000000000000057, 101.39999999999932, -58.699999999999996, -27.499999999999957, -37.399999999999785, -31.299999999999834, -57.19999999999998, -6.39999999999983], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [55.700000000000024, 112.39999999999998, -17.79999999999974, -0.7000000000000169, -26.19999999999999, 20.000000000000014, 20.000000000000014, 20.000000000000014, 145.99999999999991, 139.69999999999993, -104.50000000000003, -124.0, 20.000000000000014, -9.40000000000003, 20.000000000000014, 38.60000000000002, 62.599999999999994, 52.400000000000205, -146.80000000000007, -26.19999999999998, -234.39999999999998, -288.99999999999994, -89.50000000000001, -171.39999999999998, -64.00000000000004, -84.99999999999999, 20.000000000000014, 20.000000000000014, -118.00000000000003, 5.299999999999965, 95.29999999999995, 5.299999999999965, 116.29999999999993, 197.29999999999998, 28.10000000000001, 63.2, 2.5999999999999717, -527.4, 168.49999999999991, -829.9, 20.000000000000014, 183.8, -134.5, 46.99999999999987, -203.90000000000003, 176.2999999999999, 20.000000000000014, 20.900000000000027, -70.9, 30.800000000000196, -56.5, 20.000000000000014, -82.89999999999998, 7.399999999999965, -24.39999999999999, -82.60000000000002, -202.9, -172.00000000000003, -31.899999999999977, -26.19999999999999, -186.70000000000013, -113.20000000000002, -187.90000000000003, -313.5999999999999, -91.30000000000025, 30.200000000000003, -124.3, 20.000000000000014, 17.899999999999988, -208.0, -147.7, -92.19999999999999, -174.1, -145.90000000000006, -87.09999999999997, 44.3, -85.89999999999998, 4.999999999999972, 20.000000000000014, -198.10000000000005, -64.30000000000005, 20.000000000000014, -49.00000000000001, -9.400000000000011, -119.20000000000005, -80.80000000000084, -337.9, -239.80000000000004, 20.000000000000014, -253.30000000000004, -220.60000000000008, -22.299999999999997, -267.1, 20.000000000000014, -459.9999999999991, 20.000000000000014, -119.50000000000001, -61.300000000000026, -13.599999999999826, -80.80000000000004, -40.899999999999956, -139.0, 7.399999999999965, -149.8, 34.39999999999999, -325.59999999999997, 20.000000000000014, -229.30000000000004, -133.90000000000018, -56.80000000000007, -202.60000000000005, -209.50000000000003, 40.39999999999998, 11.599999999999978, -4.299999999999956, -57.70000000000003, -168.7, 20.000000000000014, -167.2, 20.000000000000014, -288.70000000000005, -302.1999999999998, -326.0999999999999, 4.1, -321.1, -362.5, 22.400000000000052, -133.9, 20.000000000000014, -293.79999999999995, -221.50000000000006, -179.8, -204.10000000000002, -200.8, 10.39999999999998, 36.20000000000026, -301.59999999999997, -72.70000000000059, -268.90000000000003, 20.000000000000014, 24.50000000000008, -7.899999999999999, 183.79999999999998, -106.0000000000008, -34.59999999999975, -139.60000000000002, -89.2000000000005, 20.000000000000014, -261.7, -178.00000000000003, 20.000000000000014, -244.60000000000002, -245.2, 20.000000000000014, -178.00000000000003, -179.8, -219.4, -255.10000000000014, -235.0, -220.9, -239.80000000000007, -239.5, -207.4, 20.000000000000014, 48.8000000000002, -121.90000000000002, 20.000000000000014, -263.20000000000016, -262.3, 20.000000000000014, -151.3, -298.6, -340.6, -345.69999999999976, 20.000000000000014, -48.69999999999989, 15.799999999999963, 20.000000000000014, 12.79999999999997, -278.5, -259.30000000000007, -307.0, -323.5, 20.000000000000014, 21.799999999999997, -135.40000000000003, 44.3000000000001, 28.100000000000158, 20.000000000000014, -171.7, 20.000000000000014, -302.5, -336.4, 20.000000000000014, 7.399999999999968, -288.70000000000005, -97.30000000000027, -106.90000000000005, -184.0, 5.599999999999975], "policy_predator_policy_reward": [0.0, 37.0, 29.0, 0.0, 46.0, 21.0, 0.0, 0.0, 12.0, 0.0, 83.0, 89.0, 0.0, 14.0, 43.0, 6.0, 30.0, 10.0, 83.0, 91.0, 103.0, 120.0, 63.0, 74.0, 67.0, 0.0, 0.0, 0.0, 37.0, 81.0, 7.0, 31.0, 0.0, 0.0, 54.0, 0.0, 406.0, 16.0, 496.0, 448.0, 0.0, 0.0, 116.0, 0.0, 118.0, 0.0, 0.0, 0.0, 0.0, 90.0, 60.0, 0.0, 51.0, 89.0, 18.0, 96.0, 67.0, 128.0, 109.0, 0.0, 68.0, 77.0, 173.0, 0.0, 56.0, 53.0, 36.0, 64.0, 55.0, 113.0, 0.0, 122.0, 131.0, 68.0, 51.0, 45.0, 40.0, 78.0, 102.0, 79.0, 15.0, 38.0, 105.0, 0.0, 57.0, 96.0, 152.0, 122.0, 0.0, 149.0, 137.0, 0.0, 106.0, 69.0, 322.0, 0.0, 0.0, 113.0, 48.0, 16.0, 29.0, 104.0, 122.0, 0.0, 117.0, 134.0, 107.0, 57.0, 58.0, 80.0, 0.0, 140.0, 4.0, 1.0, 37.0, 70.0, 60.0, 91.0, 77.0, 119.0, 179.0, 0.0, 26.0, 170.0, 73.0, 182.0, 115.0, 0.0, 164.0, 0.0, 0.0, 182.0, 141.0, 0.0, 0.0, 29.0, 105.0, 170.0, 90.0, 106.0, 45.0, 0.0, 59.0, 47.0, 107.0, 54.0, 67.0, 0.0, 146.0, 99.0, 135.0, 75.0, 137.0, 86.0, 110.0, 88.0, 167.0, 0.0, 116.0, 148.0, 163.0, 0.0, 74.0, 110.0, 104.0, 0.0, 101.0, 105.0, 107.0, 136.0, 145.0, 163.0, 160.0, 192.0, 33.0, 41.0, 0.0, 2.0, 140.0, 126.0, 152.0, 147.0, 0.0, 173.0, 71.0, 44.0, 2.0, 27.0, 0.0, 93.0, 122.0, 133.0, 142.0, 137.0, 142.0, 108.0, 54.0, 93.0, 104.0, 68.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6847908906631887, "mean_inference_ms": 1.5658393796407213, "mean_action_processing_ms": 0.26983926993185653, "mean_env_wait_ms": 0.2026511349872896, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006745815277099609, "StateBufferConnector_ms": 0.0033637285232543945, "ViewRequirementAgentConnector_ms": 0.12154412269592285}, "num_episodes": 22, "episode_return_max": 313.60000000000014, "episode_return_min": -428.6000000000001, "episode_return_mean": -36.693000000000005, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 432000, "num_agent_steps_trained": 432000, "num_env_steps_sampled": 108000, "num_env_steps_trained": 108000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 78.75404028209083, "num_env_steps_trained_throughput_per_sec": 78.75404028209083, "timesteps_total": 108000, "num_env_steps_sampled_lifetime": 108000, "num_agent_steps_sampled_lifetime": 432000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 432000, "timers": {"training_iteration_time_ms": 50888.593, "restore_workers_time_ms": 0.013, "training_step_time_ms": 50888.539, "sample_time_ms": 1246.338, "learn_time_ms": 49627.483, "learn_throughput": 80.601, "synch_weights_time_ms": 10.955}, "counters": {"num_env_steps_sampled": 108000, "num_env_steps_trained": 108000, "num_agent_steps_sampled": 432000, "num_agent_steps_trained": 432000}, "done": false, "training_iteration": 27, "trial_id": "11e70_00000", "date": "2024-08-12_23-30-11", "timestamp": 1723519811, "time_this_iter_s": 50.82705593109131, "time_total_s": 1391.994707584381, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2b67b80>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1391.994707584381, "iterations_since_restore": 27, "perf": {"cpu_util_percent": 36.358333333333334, "ram_util_percent": 82.68611111111112}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 9.819093929522882, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.624945917835942, "policy_loss": -0.010240164899548132, "vf_loss": 5.633745719263794, "vf_explained_var": 0.10504642731298215, "kl": 0.009602336742629449, "entropy": 1.3730012478651823, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 51975.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.4684612091886935, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.962845265171516, "policy_loss": -0.011548688970309086, "vf_loss": 5.972692534027907, "vf_explained_var": -0.18965266022101912, "kl": 0.011342837240951172, "entropy": 1.3232687862461836, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 51975.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 112000, "num_env_steps_trained": 112000, "num_agent_steps_sampled": 448000, "num_agent_steps_trained": 448000}, "env_runners": {"episode_reward_max": 183.7999999999994, "episode_reward_min": -428.6000000000001, "episode_reward_mean": -62.94500000000001, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -459.9999999999991, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 183.79999999999998, "predator_policy": 322.0}, "policy_reward_mean": {"prey_policy": -108.38250000000004, "predator_policy": 76.91}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.90000000000031, 49.89999999999972, 23.50000000000012, 64.50000000000014, 7.000000000000007, -179.90000000000003, 50.89999999999998, -154.8999999999999, -328.4999999999999, 47.90000000000014, -4.2999999999999865, -22.09999999999995, -117.90000000000003, -121.00000000000006, 53.20000000000012, 37.10000000000002, 2.9000000000001394, 8.700000000000182, 46.60000000000008, -47.00000000000005, -303.7000000000001, -84.30000000000001, -105.90000000000005, -72.09999999999994, -118.00000000000081, -67.8000000000002, -30.400000000000034, -46.89999999999993, -20.3999999999999, -40.199999999999854, -45.29999999999988, -52.69999999999999, -272.0999999999997, 57.00000000000019, 45.000000000000064, 2.300000000000149, 48.80000000000027, -411.89999999999986, -126.00000000000034, -428.6000000000001, 3.5000000000002025, -109.80000000000041, -219.3, -263.90000000000003, 75.59999999999937, -99.30000000000044, -52.89999999999985, 61.600000000000115, 183.7999999999994, -13.199999999999882, -2.199999999999936, -194.7000000000001, -14.599999999999916, -2.1999999999999265, -159.8, -307.4999999999999, -191.9, -316.30000000000007, -3.3999999999998938, 30.900000000000148, -37.19999999999985, 0.7000000000002005, -141.9, -334.2999999999998, 45.300000000000246, 37.80000000000027, 0.30000000000001936, -267.30000000000007, -130.50000000000037, 1.4000000000000057, 101.39999999999932, -58.699999999999996, -27.499999999999957, -37.399999999999785, -31.299999999999834, -57.19999999999998, -6.39999999999983, -271.29999999999995, 64.30000000000048, -114.10000000000002, -30.999999999999957, 13.600000000000131, 73.29999999999998, -27.299999999999926, 105.19999999999966, 140.29999999999927, 49.39999999999989, -138.10000000000002, 21.4, -201.000000000001, 24.60000000000005, -177.09999999999994, 5.399999999999942, 26.90000000000009, -310.0, -11.999999999999924, -253.2000000000002, -74.10000000000034, 53.70000000000015, -109.30000000000021], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 20.900000000000027, -70.9, 30.800000000000196, -56.5, 20.000000000000014, -82.89999999999998, 7.399999999999965, -24.39999999999999, -82.60000000000002, -202.9, -172.00000000000003, -31.899999999999977, -26.19999999999999, -186.70000000000013, -113.20000000000002, -187.90000000000003, -313.5999999999999, -91.30000000000025, 30.200000000000003, -124.3, 20.000000000000014, 17.899999999999988, -208.0, -147.7, -92.19999999999999, -174.1, -145.90000000000006, -87.09999999999997, 44.3, -85.89999999999998, 4.999999999999972, 20.000000000000014, -198.10000000000005, -64.30000000000005, 20.000000000000014, -49.00000000000001, -9.400000000000011, -119.20000000000005, -80.80000000000084, -337.9, -239.80000000000004, 20.000000000000014, -253.30000000000004, -220.60000000000008, -22.299999999999997, -267.1, 20.000000000000014, -459.9999999999991, 20.000000000000014, -119.50000000000001, -61.300000000000026, -13.599999999999826, -80.80000000000004, -40.899999999999956, -139.0, 7.399999999999965, -149.8, 34.39999999999999, -325.59999999999997, 20.000000000000014, -229.30000000000004, -133.90000000000018, -56.80000000000007, -202.60000000000005, -209.50000000000003, 40.39999999999998, 11.599999999999978, -4.299999999999956, -57.70000000000003, -168.7, 20.000000000000014, -167.2, 20.000000000000014, -288.70000000000005, -302.1999999999998, -326.0999999999999, 4.1, -321.1, -362.5, 22.400000000000052, -133.9, 20.000000000000014, -293.79999999999995, -221.50000000000006, -179.8, -204.10000000000002, -200.8, 10.39999999999998, 36.20000000000026, -301.59999999999997, -72.70000000000059, -268.90000000000003, 20.000000000000014, 24.50000000000008, -7.899999999999999, 183.79999999999998, -106.0000000000008, -34.59999999999975, -139.60000000000002, -89.2000000000005, 20.000000000000014, -261.7, -178.00000000000003, 20.000000000000014, -244.60000000000002, -245.2, 20.000000000000014, -178.00000000000003, -179.8, -219.4, -255.10000000000014, -235.0, -220.9, -239.80000000000007, -239.5, -207.4, 20.000000000000014, 48.8000000000002, -121.90000000000002, 20.000000000000014, -263.20000000000016, -262.3, 20.000000000000014, -151.3, -298.6, -340.6, -345.69999999999976, 20.000000000000014, -48.69999999999989, 15.799999999999963, 20.000000000000014, 12.79999999999997, -278.5, -259.30000000000007, -307.0, -323.5, 20.000000000000014, 21.799999999999997, -135.40000000000003, 44.3000000000001, 28.100000000000158, 20.000000000000014, -171.7, 20.000000000000014, -302.5, -336.4, 20.000000000000014, 7.399999999999968, -288.70000000000005, -97.30000000000027, -106.90000000000005, -184.0, 5.599999999999975, -154.30000000000004, -283.0, 20.000000000000014, 44.300000000000246, -151.00000000000006, -204.10000000000005, -14.49999999999995, -95.50000000000017, -102.40000000000006, 20.000000000000014, 2.299999999999991, -34.000000000000156, 20.000000000000014, -250.3, 36.20000000000001, -1.0000000000000142, 78.49999999999984, 27.80000000000016, 71.89999999999962, -128.5, -125.20000000000002, -253.9, 24.50000000000008, -24.099999999999746, -250.49999999999994, -179.50000000000057, -9.399999999999855, 20.000000000000014, -177.70000000000005, -141.4, -198.70000000000005, 13.099999999999968, 17.899999999999988, -0.9999999999999952, -259.0, -340.0, -148.0, 20.000000000000014, -225.40000000000003, -332.8000000000002, -3.0999999999999863, -325.00000000000006, -58.299999999999955, 20.000000000000014, -9.399999999999869, -274.9], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 90.0, 60.0, 0.0, 51.0, 89.0, 18.0, 96.0, 67.0, 128.0, 109.0, 0.0, 68.0, 77.0, 173.0, 0.0, 56.0, 53.0, 36.0, 64.0, 55.0, 113.0, 0.0, 122.0, 131.0, 68.0, 51.0, 45.0, 40.0, 78.0, 102.0, 79.0, 15.0, 38.0, 105.0, 0.0, 57.0, 96.0, 152.0, 122.0, 0.0, 149.0, 137.0, 0.0, 106.0, 69.0, 322.0, 0.0, 0.0, 113.0, 48.0, 16.0, 29.0, 104.0, 122.0, 0.0, 117.0, 134.0, 107.0, 57.0, 58.0, 80.0, 0.0, 140.0, 4.0, 1.0, 37.0, 70.0, 60.0, 91.0, 77.0, 119.0, 179.0, 0.0, 26.0, 170.0, 73.0, 182.0, 115.0, 0.0, 164.0, 0.0, 0.0, 182.0, 141.0, 0.0, 0.0, 29.0, 105.0, 170.0, 90.0, 106.0, 45.0, 0.0, 59.0, 47.0, 107.0, 54.0, 67.0, 0.0, 146.0, 99.0, 135.0, 75.0, 137.0, 86.0, 110.0, 88.0, 167.0, 0.0, 116.0, 148.0, 163.0, 0.0, 74.0, 110.0, 104.0, 0.0, 101.0, 105.0, 107.0, 136.0, 145.0, 163.0, 160.0, 192.0, 33.0, 41.0, 0.0, 2.0, 140.0, 126.0, 152.0, 147.0, 0.0, 173.0, 71.0, 44.0, 2.0, 27.0, 0.0, 93.0, 122.0, 133.0, 142.0, 137.0, 142.0, 108.0, 54.0, 93.0, 104.0, 68.0, 166.0, 0.0, 0.0, 0.0, 130.0, 111.0, 21.0, 58.0, 96.0, 0.0, 42.0, 63.0, 105.0, 98.0, 40.0, 30.0, 12.0, 22.0, 106.0, 0.0, 75.0, 166.0, 0.0, 21.0, 95.0, 134.0, 14.0, 0.0, 0.0, 142.0, 115.0, 76.0, 0.0, 10.0, 111.0, 178.0, 116.0, 0.0, 137.0, 168.0, 131.0, 123.0, 54.0, 38.0, 0.0, 175.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6836186702095898, "mean_inference_ms": 1.5888621585248461, "mean_action_processing_ms": 0.2684731305621696, "mean_env_wait_ms": 0.20213802051107355, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01018667221069336, "StateBufferConnector_ms": 0.0033004283905029297, "ViewRequirementAgentConnector_ms": 0.09888756275177002}, "num_episodes": 23, "episode_return_max": 183.7999999999994, "episode_return_min": -428.6000000000001, "episode_return_mean": -62.94500000000001, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 448000, "num_agent_steps_trained": 448000, "num_env_steps_sampled": 112000, "num_env_steps_trained": 112000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 76.1331342222854, "num_env_steps_trained_throughput_per_sec": 76.1331342222854, "timesteps_total": 112000, "num_env_steps_sampled_lifetime": 112000, "num_agent_steps_sampled_lifetime": 448000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 448000, "timers": {"training_iteration_time_ms": 51102.075, "restore_workers_time_ms": 0.012, "training_step_time_ms": 51102.021, "sample_time_ms": 1394.966, "learn_time_ms": 49692.661, "learn_throughput": 80.495, "synch_weights_time_ms": 10.881}, "counters": {"num_env_steps_sampled": 112000, "num_env_steps_trained": 112000, "num_agent_steps_sampled": 448000, "num_agent_steps_trained": 448000}, "done": false, "training_iteration": 28, "trial_id": "11e70_00000", "date": "2024-08-12_23-31-04", "timestamp": 1723519864, "time_this_iter_s": 52.582016706466675, "time_total_s": 1444.5767242908478, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2b61700>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1444.5767242908478, "iterations_since_restore": 28, "perf": {"cpu_util_percent": 39.06133333333333, "ram_util_percent": 83.20666666666666}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 8.00639273968954, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.3852257493942504, "policy_loss": -0.008475280276908682, "vf_loss": 3.392540904138454, "vf_explained_var": 0.15236663682750923, "kl": 0.007734160422777769, "entropy": 1.3771429027829851, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 53865.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.581721623265554, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.884731767795704, "policy_loss": -0.01792722959551842, "vf_loss": 3.900877177652228, "vf_explained_var": -0.2325783472843271, "kl": 0.011878771368177995, "entropy": 1.2999853614776853, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 53865.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 116000, "num_env_steps_trained": 116000, "num_agent_steps_sampled": 464000, "num_agent_steps_trained": 464000}, "env_runners": {"episode_reward_max": 183.7999999999994, "episode_reward_min": -428.6000000000001, "episode_reward_mean": -55.03000000000004, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -459.9999999999991, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 183.79999999999998, "predator_policy": 322.0}, "policy_reward_mean": {"prey_policy": -101.7, "predator_policy": 74.185}, "custom_metrics": {}, "hist_stats": {"episode_reward": [46.60000000000008, -47.00000000000005, -303.7000000000001, -84.30000000000001, -105.90000000000005, -72.09999999999994, -118.00000000000081, -67.8000000000002, -30.400000000000034, -46.89999999999993, -20.3999999999999, -40.199999999999854, -45.29999999999988, -52.69999999999999, -272.0999999999997, 57.00000000000019, 45.000000000000064, 2.300000000000149, 48.80000000000027, -411.89999999999986, -126.00000000000034, -428.6000000000001, 3.5000000000002025, -109.80000000000041, -219.3, -263.90000000000003, 75.59999999999937, -99.30000000000044, -52.89999999999985, 61.600000000000115, 183.7999999999994, -13.199999999999882, -2.199999999999936, -194.7000000000001, -14.599999999999916, -2.1999999999999265, -159.8, -307.4999999999999, -191.9, -316.30000000000007, -3.3999999999998938, 30.900000000000148, -37.19999999999985, 0.7000000000002005, -141.9, -334.2999999999998, 45.300000000000246, 37.80000000000027, 0.30000000000001936, -267.30000000000007, -130.50000000000037, 1.4000000000000057, 101.39999999999932, -58.699999999999996, -27.499999999999957, -37.399999999999785, -31.299999999999834, -57.19999999999998, -6.39999999999983, -271.29999999999995, 64.30000000000048, -114.10000000000002, -30.999999999999957, 13.600000000000131, 73.29999999999998, -27.299999999999926, 105.19999999999966, 140.29999999999927, 49.39999999999989, -138.10000000000002, 21.4, -201.000000000001, 24.60000000000005, -177.09999999999994, 5.399999999999942, 26.90000000000009, -310.0, -11.999999999999924, -253.2000000000002, -74.10000000000034, 53.70000000000015, -109.30000000000021, -15.299999999999926, 52.10000000000003, -179.5, -41.39999999999978, 37.80000000000027, 71.29999999999964, -41.200000000000074, -84.69999999999999, 24.400000000000052, 83.19999999999906, -140.8, 53.50000000000029, 88.89999999999863, 111.09999999999927, 61.60000000000051, 58.70000000000042, 63.10000000000038, 46.600000000000406], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-49.00000000000001, -9.400000000000011, -119.20000000000005, -80.80000000000084, -337.9, -239.80000000000004, 20.000000000000014, -253.30000000000004, -220.60000000000008, -22.299999999999997, -267.1, 20.000000000000014, -459.9999999999991, 20.000000000000014, -119.50000000000001, -61.300000000000026, -13.599999999999826, -80.80000000000004, -40.899999999999956, -139.0, 7.399999999999965, -149.8, 34.39999999999999, -325.59999999999997, 20.000000000000014, -229.30000000000004, -133.90000000000018, -56.80000000000007, -202.60000000000005, -209.50000000000003, 40.39999999999998, 11.599999999999978, -4.299999999999956, -57.70000000000003, -168.7, 20.000000000000014, -167.2, 20.000000000000014, -288.70000000000005, -302.1999999999998, -326.0999999999999, 4.1, -321.1, -362.5, 22.400000000000052, -133.9, 20.000000000000014, -293.79999999999995, -221.50000000000006, -179.8, -204.10000000000002, -200.8, 10.39999999999998, 36.20000000000026, -301.59999999999997, -72.70000000000059, -268.90000000000003, 20.000000000000014, 24.50000000000008, -7.899999999999999, 183.79999999999998, -106.0000000000008, -34.59999999999975, -139.60000000000002, -89.2000000000005, 20.000000000000014, -261.7, -178.00000000000003, 20.000000000000014, -244.60000000000002, -245.2, 20.000000000000014, -178.00000000000003, -179.8, -219.4, -255.10000000000014, -235.0, -220.9, -239.80000000000007, -239.5, -207.4, 20.000000000000014, 48.8000000000002, -121.90000000000002, 20.000000000000014, -263.20000000000016, -262.3, 20.000000000000014, -151.3, -298.6, -340.6, -345.69999999999976, 20.000000000000014, -48.69999999999989, 15.799999999999963, 20.000000000000014, 12.79999999999997, -278.5, -259.30000000000007, -307.0, -323.5, 20.000000000000014, 21.799999999999997, -135.40000000000003, 44.3000000000001, 28.100000000000158, 20.000000000000014, -171.7, 20.000000000000014, -302.5, -336.4, 20.000000000000014, 7.399999999999968, -288.70000000000005, -97.30000000000027, -106.90000000000005, -184.0, 5.599999999999975, -154.30000000000004, -283.0, 20.000000000000014, 44.300000000000246, -151.00000000000006, -204.10000000000005, -14.49999999999995, -95.50000000000017, -102.40000000000006, 20.000000000000014, 2.299999999999991, -34.000000000000156, 20.000000000000014, -250.3, 36.20000000000001, -1.0000000000000142, 78.49999999999984, 27.80000000000016, 71.89999999999962, -128.5, -125.20000000000002, -253.9, 24.50000000000008, -24.099999999999746, -250.49999999999994, -179.50000000000057, -9.399999999999855, 20.000000000000014, -177.70000000000005, -141.4, -198.70000000000005, 13.099999999999968, 17.899999999999988, -0.9999999999999952, -259.0, -340.0, -148.0, 20.000000000000014, -225.40000000000003, -332.8000000000002, -3.0999999999999863, -325.00000000000006, -58.299999999999955, 20.000000000000014, -9.399999999999869, -274.9, 8.6, -289.9, 7.399999999999965, -64.29999999999991, -124.0, -215.50000000000003, 30.20000000000019, -292.6, 15.799999999999963, 20.000000000000014, 25.400000000000098, -27.099999999999994, 63.499999999999986, -255.70000000000005, -84.1, -268.6, -0.7000000000000169, 1.0999999999999865, 63.200000000000195, 20.000000000000014, -50.5, -271.3, 33.50000000000014, 20.000000000000014, -33.0999999999998, 65.00000000000013, 20.000000000000014, 91.09999999999971, 41.60000000000025, 20.000000000000014, 28.700000000000177, 20.000000000000014, -58.9000000000001, 20.000000000000014, 23.60000000000007, 20.000000000000014], "policy_predator_policy_reward": [105.0, 0.0, 57.0, 96.0, 152.0, 122.0, 0.0, 149.0, 137.0, 0.0, 106.0, 69.0, 322.0, 0.0, 0.0, 113.0, 48.0, 16.0, 29.0, 104.0, 122.0, 0.0, 117.0, 134.0, 107.0, 57.0, 58.0, 80.0, 0.0, 140.0, 4.0, 1.0, 37.0, 70.0, 60.0, 91.0, 77.0, 119.0, 179.0, 0.0, 26.0, 170.0, 73.0, 182.0, 115.0, 0.0, 164.0, 0.0, 0.0, 182.0, 141.0, 0.0, 0.0, 29.0, 105.0, 170.0, 90.0, 106.0, 45.0, 0.0, 59.0, 47.0, 107.0, 54.0, 67.0, 0.0, 146.0, 99.0, 135.0, 75.0, 137.0, 86.0, 110.0, 88.0, 167.0, 0.0, 116.0, 148.0, 163.0, 0.0, 74.0, 110.0, 104.0, 0.0, 101.0, 105.0, 107.0, 136.0, 145.0, 163.0, 160.0, 192.0, 33.0, 41.0, 0.0, 2.0, 140.0, 126.0, 152.0, 147.0, 0.0, 173.0, 71.0, 44.0, 2.0, 27.0, 0.0, 93.0, 122.0, 133.0, 142.0, 137.0, 142.0, 108.0, 54.0, 93.0, 104.0, 68.0, 166.0, 0.0, 0.0, 0.0, 130.0, 111.0, 21.0, 58.0, 96.0, 0.0, 42.0, 63.0, 105.0, 98.0, 40.0, 30.0, 12.0, 22.0, 106.0, 0.0, 75.0, 166.0, 0.0, 21.0, 95.0, 134.0, 14.0, 0.0, 0.0, 142.0, 115.0, 76.0, 0.0, 10.0, 111.0, 178.0, 116.0, 0.0, 137.0, 168.0, 131.0, 123.0, 54.0, 38.0, 0.0, 175.0, 134.0, 132.0, 61.0, 48.0, 160.0, 0.0, 147.0, 74.0, 0.0, 2.0, 73.0, 0.0, 0.0, 151.0, 135.0, 133.0, 12.0, 12.0, 0.0, 0.0, 181.0, 0.0, 0.0, 0.0, 31.0, 26.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 58.0, 44.0, 3.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6829935407630643, "mean_inference_ms": 1.607311415419491, "mean_action_processing_ms": 0.2679783522561065, "mean_env_wait_ms": 0.20190570212879966, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.009807348251342773, "StateBufferConnector_ms": 0.0033844709396362305, "ViewRequirementAgentConnector_ms": 0.10908639430999756}, "num_episodes": 18, "episode_return_max": 183.7999999999994, "episode_return_min": -428.6000000000001, "episode_return_mean": -55.03000000000004, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 464000, "num_agent_steps_trained": 464000, "num_env_steps_sampled": 116000, "num_env_steps_trained": 116000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 77.34797480556665, "num_env_steps_trained_throughput_per_sec": 77.34797480556665, "timesteps_total": 116000, "num_env_steps_sampled_lifetime": 116000, "num_agent_steps_sampled_lifetime": 464000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 464000, "timers": {"training_iteration_time_ms": 51162.059, "restore_workers_time_ms": 0.013, "training_step_time_ms": 51162.004, "sample_time_ms": 1375.993, "learn_time_ms": 49771.451, "learn_throughput": 80.367, "synch_weights_time_ms": 10.927}, "counters": {"num_env_steps_sampled": 116000, "num_env_steps_trained": 116000, "num_agent_steps_sampled": 464000, "num_agent_steps_trained": 464000}, "done": false, "training_iteration": 29, "trial_id": "11e70_00000", "date": "2024-08-12_23-31-56", "timestamp": 1723519916, "time_this_iter_s": 51.768059968948364, "time_total_s": 1496.3447842597961, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2b93af0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1496.3447842597961, "iterations_since_restore": 29, "perf": {"cpu_util_percent": 36.93150684931506, "ram_util_percent": 83.26575342465755}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 6.02512079679146, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.1077383375672436, "policy_loss": -0.007900876493474084, "vf_loss": 1.1143994458611048, "vf_explained_var": 0.11923811009952, "kl": 0.00826512954268496, "entropy": 1.3751492516704338, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 55755.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.220628144532915, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.5784777900529288, "policy_loss": -0.020598644657163986, "vf_loss": 2.597202024447224, "vf_explained_var": 0.21796657471429734, "kl": 0.012496134890526105, "entropy": 1.2925641098350444, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 55755.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 120000, "num_env_steps_trained": 120000, "num_agent_steps_sampled": 480000, "num_agent_steps_trained": 480000}, "env_runners": {"episode_reward_max": 257.79999999999995, "episode_reward_min": -428.6000000000001, "episode_reward_mean": -29.167000000000034, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -362.5, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 185.60000000000002, "predator_policy": 192.0}, "policy_reward_mean": {"prey_policy": -77.65350000000002, "predator_policy": 63.07}, "custom_metrics": {}, "hist_stats": {"episode_reward": [48.80000000000027, -411.89999999999986, -126.00000000000034, -428.6000000000001, 3.5000000000002025, -109.80000000000041, -219.3, -263.90000000000003, 75.59999999999937, -99.30000000000044, -52.89999999999985, 61.600000000000115, 183.7999999999994, -13.199999999999882, -2.199999999999936, -194.7000000000001, -14.599999999999916, -2.1999999999999265, -159.8, -307.4999999999999, -191.9, -316.30000000000007, -3.3999999999998938, 30.900000000000148, -37.19999999999985, 0.7000000000002005, -141.9, -334.2999999999998, 45.300000000000246, 37.80000000000027, 0.30000000000001936, -267.30000000000007, -130.50000000000037, 1.4000000000000057, 101.39999999999932, -58.699999999999996, -27.499999999999957, -37.399999999999785, -31.299999999999834, -57.19999999999998, -6.39999999999983, -271.29999999999995, 64.30000000000048, -114.10000000000002, -30.999999999999957, 13.600000000000131, 73.29999999999998, -27.299999999999926, 105.19999999999966, 140.29999999999927, 49.39999999999989, -138.10000000000002, 21.4, -201.000000000001, 24.60000000000005, -177.09999999999994, 5.399999999999942, 26.90000000000009, -310.0, -11.999999999999924, -253.2000000000002, -74.10000000000034, 53.70000000000015, -109.30000000000021, -15.299999999999926, 52.10000000000003, -179.5, -41.39999999999978, 37.80000000000027, 71.29999999999964, -41.200000000000074, -84.69999999999999, 24.400000000000052, 83.19999999999906, -140.8, 53.50000000000029, 88.89999999999863, 111.09999999999927, 61.60000000000051, 58.70000000000042, 63.10000000000038, 46.600000000000406, 137.499999999999, 42.90000000000036, 40.0000000000003, -0.6999999999998354, 118.29999999999899, 40.0000000000003, 53.000000000000306, 49.000000000000455, 99.69999999999989, 55.50000000000036, 26.800000000000097, 40.0000000000003, 109.69999999999874, 226.89999999999984, 15.799999999999939, 63.80000000000041, 54.40000000000053, 257.79999999999995], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-167.2, 20.000000000000014, -288.70000000000005, -302.1999999999998, -326.0999999999999, 4.1, -321.1, -362.5, 22.400000000000052, -133.9, 20.000000000000014, -293.79999999999995, -221.50000000000006, -179.8, -204.10000000000002, -200.8, 10.39999999999998, 36.20000000000026, -301.59999999999997, -72.70000000000059, -268.90000000000003, 20.000000000000014, 24.50000000000008, -7.899999999999999, 183.79999999999998, -106.0000000000008, -34.59999999999975, -139.60000000000002, -89.2000000000005, 20.000000000000014, -261.7, -178.00000000000003, 20.000000000000014, -244.60000000000002, -245.2, 20.000000000000014, -178.00000000000003, -179.8, -219.4, -255.10000000000014, -235.0, -220.9, -239.80000000000007, -239.5, -207.4, 20.000000000000014, 48.8000000000002, -121.90000000000002, 20.000000000000014, -263.20000000000016, -262.3, 20.000000000000014, -151.3, -298.6, -340.6, -345.69999999999976, 20.000000000000014, -48.69999999999989, 15.799999999999963, 20.000000000000014, 12.79999999999997, -278.5, -259.30000000000007, -307.0, -323.5, 20.000000000000014, 21.799999999999997, -135.40000000000003, 44.3000000000001, 28.100000000000158, 20.000000000000014, -171.7, 20.000000000000014, -302.5, -336.4, 20.000000000000014, 7.399999999999968, -288.70000000000005, -97.30000000000027, -106.90000000000005, -184.0, 5.599999999999975, -154.30000000000004, -283.0, 20.000000000000014, 44.300000000000246, -151.00000000000006, -204.10000000000005, -14.49999999999995, -95.50000000000017, -102.40000000000006, 20.000000000000014, 2.299999999999991, -34.000000000000156, 20.000000000000014, -250.3, 36.20000000000001, -1.0000000000000142, 78.49999999999984, 27.80000000000016, 71.89999999999962, -128.5, -125.20000000000002, -253.9, 24.50000000000008, -24.099999999999746, -250.49999999999994, -179.50000000000057, -9.399999999999855, 20.000000000000014, -177.70000000000005, -141.4, -198.70000000000005, 13.099999999999968, 17.899999999999988, -0.9999999999999952, -259.0, -340.0, -148.0, 20.000000000000014, -225.40000000000003, -332.8000000000002, -3.0999999999999863, -325.00000000000006, -58.299999999999955, 20.000000000000014, -9.399999999999869, -274.9, 8.6, -289.9, 7.399999999999965, -64.29999999999991, -124.0, -215.50000000000003, 30.20000000000019, -292.6, 15.799999999999963, 20.000000000000014, 25.400000000000098, -27.099999999999994, 63.499999999999986, -255.70000000000005, -84.1, -268.6, -0.7000000000000169, 1.0999999999999865, 63.200000000000195, 20.000000000000014, -50.5, -271.3, 33.50000000000014, 20.000000000000014, -33.0999999999998, 65.00000000000013, 20.000000000000014, 91.09999999999971, 41.60000000000025, 20.000000000000014, 28.700000000000177, 20.000000000000014, -58.9000000000001, 20.000000000000014, 23.60000000000007, 20.000000000000014, 20.000000000000014, 87.49999999999976, 20.000000000000014, 5.900000000000011, 20.000000000000014, 20.000000000000014, -60.400000000000574, 13.699999999999966, 20.000000000000014, 98.29999999999957, 20.000000000000014, 20.000000000000014, 20.000000000000014, -27.999999999999886, 20.000000000000014, 29.000000000000174, 75.49999999999945, -65.80000000000001, 11.29999999999998, 12.199999999999974, 7.399999999999965, 7.399999999999982, 20.000000000000014, 20.000000000000014, 82.69999999999939, 20.000000000000014, 185.60000000000002, -84.70000000000019, 5.299999999999947, -11.499999999999819, 23.600000000000076, 3.1999999999999793, 29.90000000000018, 24.500000000000085, 150.4999999999997, 107.29999999999973], "policy_predator_policy_reward": [77.0, 119.0, 179.0, 0.0, 26.0, 170.0, 73.0, 182.0, 115.0, 0.0, 164.0, 0.0, 0.0, 182.0, 141.0, 0.0, 0.0, 29.0, 105.0, 170.0, 90.0, 106.0, 45.0, 0.0, 59.0, 47.0, 107.0, 54.0, 67.0, 0.0, 146.0, 99.0, 135.0, 75.0, 137.0, 86.0, 110.0, 88.0, 167.0, 0.0, 116.0, 148.0, 163.0, 0.0, 74.0, 110.0, 104.0, 0.0, 101.0, 105.0, 107.0, 136.0, 145.0, 163.0, 160.0, 192.0, 33.0, 41.0, 0.0, 2.0, 140.0, 126.0, 152.0, 147.0, 0.0, 173.0, 71.0, 44.0, 2.0, 27.0, 0.0, 93.0, 122.0, 133.0, 142.0, 137.0, 142.0, 108.0, 54.0, 93.0, 104.0, 68.0, 166.0, 0.0, 0.0, 0.0, 130.0, 111.0, 21.0, 58.0, 96.0, 0.0, 42.0, 63.0, 105.0, 98.0, 40.0, 30.0, 12.0, 22.0, 106.0, 0.0, 75.0, 166.0, 0.0, 21.0, 95.0, 134.0, 14.0, 0.0, 0.0, 142.0, 115.0, 76.0, 0.0, 10.0, 111.0, 178.0, 116.0, 0.0, 137.0, 168.0, 131.0, 123.0, 54.0, 38.0, 0.0, 175.0, 134.0, 132.0, 61.0, 48.0, 160.0, 0.0, 147.0, 74.0, 0.0, 2.0, 73.0, 0.0, 0.0, 151.0, 135.0, 133.0, 12.0, 12.0, 0.0, 0.0, 181.0, 0.0, 0.0, 0.0, 31.0, 26.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 58.0, 44.0, 3.0, 0.0, 17.0, 13.0, 17.0, 0.0, 0.0, 0.0, 35.0, 11.0, 0.0, 0.0, 0.0, 0.0, 16.0, 45.0, 0.0, 0.0, 0.0, 90.0, 27.0, 5.0, 6.0, 6.0, 0.0, 0.0, 7.0, 0.0, 58.0, 68.0, 15.0, 7.0, 14.0, 23.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6821304842684244, "mean_inference_ms": 1.6248222721813617, "mean_action_processing_ms": 0.26764054740500937, "mean_env_wait_ms": 0.20161026384568906, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.009269118309020996, "StateBufferConnector_ms": 0.0033565759658813477, "ViewRequirementAgentConnector_ms": 0.11419105529785156}, "num_episodes": 18, "episode_return_max": 257.79999999999995, "episode_return_min": -428.6000000000001, "episode_return_mean": -29.167000000000034, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 480000, "num_agent_steps_trained": 480000, "num_env_steps_sampled": 120000, "num_env_steps_trained": 120000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 76.57614284530699, "num_env_steps_trained_throughput_per_sec": 76.57614284530699, "timesteps_total": 120000, "num_env_steps_sampled_lifetime": 120000, "num_agent_steps_sampled_lifetime": 480000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 480000, "timers": {"training_iteration_time_ms": 51318.904, "restore_workers_time_ms": 0.013, "training_step_time_ms": 51318.848, "sample_time_ms": 1381.233, "learn_time_ms": 49922.777, "learn_throughput": 80.124, "synch_weights_time_ms": 11.172}, "counters": {"num_env_steps_sampled": 120000, "num_env_steps_trained": 120000, "num_agent_steps_sampled": 480000, "num_agent_steps_trained": 480000}, "done": false, "training_iteration": 30, "trial_id": "11e70_00000", "date": "2024-08-12_23-32-48", "timestamp": 1723519968, "time_this_iter_s": 52.27495718002319, "time_total_s": 1548.6197414398193, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2b93940>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1548.6197414398193, "iterations_since_restore": 30, "perf": {"cpu_util_percent": 36.41621621621622, "ram_util_percent": 83.17297297297297}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.5666600555339185, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.0183039262969658, "policy_loss": -0.009120960034203356, "vf_loss": 1.02657810411756, "vf_explained_var": 0.16340738421394713, "kl": 0.005645212344890177, "entropy": 1.3645247036817842, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 57645.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.623615572566078, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.780863127380452, "policy_loss": -0.010955220838717958, "vf_loss": 3.7905700881645163, "vf_explained_var": 0.24499857958662447, "kl": 0.008321725135971443, "entropy": 1.2979992228210289, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 57645.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 124000, "num_env_steps_trained": 124000, "num_agent_steps_sampled": 496000, "num_agent_steps_trained": 496000}, "env_runners": {"episode_reward_max": 257.79999999999995, "episode_reward_min": -334.2999999999998, "episode_reward_mean": 1.2719999999999607, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -345.69999999999976, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 185.60000000000002, "predator_policy": 192.0}, "policy_reward_mean": {"prey_policy": -48.854000000000006, "predator_policy": 49.49}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-159.8, -307.4999999999999, -191.9, -316.30000000000007, -3.3999999999998938, 30.900000000000148, -37.19999999999985, 0.7000000000002005, -141.9, -334.2999999999998, 45.300000000000246, 37.80000000000027, 0.30000000000001936, -267.30000000000007, -130.50000000000037, 1.4000000000000057, 101.39999999999932, -58.699999999999996, -27.499999999999957, -37.399999999999785, -31.299999999999834, -57.19999999999998, -6.39999999999983, -271.29999999999995, 64.30000000000048, -114.10000000000002, -30.999999999999957, 13.600000000000131, 73.29999999999998, -27.299999999999926, 105.19999999999966, 140.29999999999927, 49.39999999999989, -138.10000000000002, 21.4, -201.000000000001, 24.60000000000005, -177.09999999999994, 5.399999999999942, 26.90000000000009, -310.0, -11.999999999999924, -253.2000000000002, -74.10000000000034, 53.70000000000015, -109.30000000000021, -15.299999999999926, 52.10000000000003, -179.5, -41.39999999999978, 37.80000000000027, 71.29999999999964, -41.200000000000074, -84.69999999999999, 24.400000000000052, 83.19999999999906, -140.8, 53.50000000000029, 88.89999999999863, 111.09999999999927, 61.60000000000051, 58.70000000000042, 63.10000000000038, 46.600000000000406, 137.499999999999, 42.90000000000036, 40.0000000000003, -0.6999999999998354, 118.29999999999899, 40.0000000000003, 53.000000000000306, 49.000000000000455, 99.69999999999989, 55.50000000000036, 26.800000000000097, 40.0000000000003, 109.69999999999874, 226.89999999999984, 15.799999999999939, 63.80000000000041, 54.40000000000053, 257.79999999999995, 38.90000000000028, 37.80000000000027, 30.100000000000147, 139.29999999999907, 158.79999999999922, 185.19999999999916, 40.0000000000003, 40.0000000000003, 87.39999999999975, 56.80000000000045, 115.29999999999887, 49.90000000000046, 18.299999999999958, 132.59999999999957, 30.400000000000134, 40.0000000000003, 40.0000000000003, 237.79999999999944], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-178.00000000000003, -179.8, -219.4, -255.10000000000014, -235.0, -220.9, -239.80000000000007, -239.5, -207.4, 20.000000000000014, 48.8000000000002, -121.90000000000002, 20.000000000000014, -263.20000000000016, -262.3, 20.000000000000014, -151.3, -298.6, -340.6, -345.69999999999976, 20.000000000000014, -48.69999999999989, 15.799999999999963, 20.000000000000014, 12.79999999999997, -278.5, -259.30000000000007, -307.0, -323.5, 20.000000000000014, 21.799999999999997, -135.40000000000003, 44.3000000000001, 28.100000000000158, 20.000000000000014, -171.7, 20.000000000000014, -302.5, -336.4, 20.000000000000014, 7.399999999999968, -288.70000000000005, -97.30000000000027, -106.90000000000005, -184.0, 5.599999999999975, -154.30000000000004, -283.0, 20.000000000000014, 44.300000000000246, -151.00000000000006, -204.10000000000005, -14.49999999999995, -95.50000000000017, -102.40000000000006, 20.000000000000014, 2.299999999999991, -34.000000000000156, 20.000000000000014, -250.3, 36.20000000000001, -1.0000000000000142, 78.49999999999984, 27.80000000000016, 71.89999999999962, -128.5, -125.20000000000002, -253.9, 24.50000000000008, -24.099999999999746, -250.49999999999994, -179.50000000000057, -9.399999999999855, 20.000000000000014, -177.70000000000005, -141.4, -198.70000000000005, 13.099999999999968, 17.899999999999988, -0.9999999999999952, -259.0, -340.0, -148.0, 20.000000000000014, -225.40000000000003, -332.8000000000002, -3.0999999999999863, -325.00000000000006, -58.299999999999955, 20.000000000000014, -9.399999999999869, -274.9, 8.6, -289.9, 7.399999999999965, -64.29999999999991, -124.0, -215.50000000000003, 30.20000000000019, -292.6, 15.799999999999963, 20.000000000000014, 25.400000000000098, -27.099999999999994, 63.499999999999986, -255.70000000000005, -84.1, -268.6, -0.7000000000000169, 1.0999999999999865, 63.200000000000195, 20.000000000000014, -50.5, -271.3, 33.50000000000014, 20.000000000000014, -33.0999999999998, 65.00000000000013, 20.000000000000014, 91.09999999999971, 41.60000000000025, 20.000000000000014, 28.700000000000177, 20.000000000000014, -58.9000000000001, 20.000000000000014, 23.60000000000007, 20.000000000000014, 20.000000000000014, 87.49999999999976, 20.000000000000014, 5.900000000000011, 20.000000000000014, 20.000000000000014, -60.400000000000574, 13.699999999999966, 20.000000000000014, 98.29999999999957, 20.000000000000014, 20.000000000000014, 20.000000000000014, -27.999999999999886, 20.000000000000014, 29.000000000000174, 75.49999999999945, -65.80000000000001, 11.29999999999998, 12.199999999999974, 7.399999999999965, 7.399999999999982, 20.000000000000014, 20.000000000000014, 82.69999999999939, 20.000000000000014, 185.60000000000002, -84.70000000000019, 5.299999999999947, -11.499999999999819, 23.600000000000076, 3.1999999999999793, 29.90000000000018, 24.500000000000085, 150.4999999999997, 107.29999999999973, 20.000000000000014, 17.899999999999988, 20.000000000000014, 15.799999999999963, -7.899999999999924, 20.000000000000014, 20.000000000000014, 116.29999999999971, 119.89999999999972, 38.90000000000015, 129.79999999999995, 22.400000000000066, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 34.4000000000002, 44.00000000000019, -11.199999999999852, 29.000000000000163, 29.90000000000018, 79.3999999999995, 29.90000000000018, 20.000000000000014, 20.900000000000013, -43.59999999999982, 130.7, -30.099999999999795, -49.299999999999905, -4.299999999999962, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 102.49999999999994, 134.2999999999996], "policy_predator_policy_reward": [110.0, 88.0, 167.0, 0.0, 116.0, 148.0, 163.0, 0.0, 74.0, 110.0, 104.0, 0.0, 101.0, 105.0, 107.0, 136.0, 145.0, 163.0, 160.0, 192.0, 33.0, 41.0, 0.0, 2.0, 140.0, 126.0, 152.0, 147.0, 0.0, 173.0, 71.0, 44.0, 2.0, 27.0, 0.0, 93.0, 122.0, 133.0, 142.0, 137.0, 142.0, 108.0, 54.0, 93.0, 104.0, 68.0, 166.0, 0.0, 0.0, 0.0, 130.0, 111.0, 21.0, 58.0, 96.0, 0.0, 42.0, 63.0, 105.0, 98.0, 40.0, 30.0, 12.0, 22.0, 106.0, 0.0, 75.0, 166.0, 0.0, 21.0, 95.0, 134.0, 14.0, 0.0, 0.0, 142.0, 115.0, 76.0, 0.0, 10.0, 111.0, 178.0, 116.0, 0.0, 137.0, 168.0, 131.0, 123.0, 54.0, 38.0, 0.0, 175.0, 134.0, 132.0, 61.0, 48.0, 160.0, 0.0, 147.0, 74.0, 0.0, 2.0, 73.0, 0.0, 0.0, 151.0, 135.0, 133.0, 12.0, 12.0, 0.0, 0.0, 181.0, 0.0, 0.0, 0.0, 31.0, 26.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 58.0, 44.0, 3.0, 0.0, 17.0, 13.0, 17.0, 0.0, 0.0, 0.0, 35.0, 11.0, 0.0, 0.0, 0.0, 0.0, 16.0, 45.0, 0.0, 0.0, 0.0, 90.0, 27.0, 5.0, 6.0, 6.0, 0.0, 0.0, 7.0, 0.0, 58.0, 68.0, 15.0, 7.0, 14.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 18.0, 0.0, 0.0, 3.0, 0.0, 0.0, 17.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 32.0, 7.0, 2.0, 4.0, 0.0, 0.0, 26.0, 15.0, 32.0, 0.0, 51.0, 33.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6813315752450291, "mean_inference_ms": 1.6423683938817966, "mean_action_processing_ms": 0.2675789281409482, "mean_env_wait_ms": 0.20133064065111075, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01007533073425293, "StateBufferConnector_ms": 0.0034133195877075195, "ViewRequirementAgentConnector_ms": 0.11874663829803467}, "num_episodes": 18, "episode_return_max": 257.79999999999995, "episode_return_min": -334.2999999999998, "episode_return_mean": 1.2719999999999607, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 496000, "num_agent_steps_trained": 496000, "num_env_steps_sampled": 124000, "num_env_steps_trained": 124000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 74.35454519866504, "num_env_steps_trained_throughput_per_sec": 74.35454519866504, "timesteps_total": 124000, "num_env_steps_sampled_lifetime": 124000, "num_agent_steps_sampled_lifetime": 496000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 496000, "timers": {"training_iteration_time_ms": 51629.934, "restore_workers_time_ms": 0.013, "training_step_time_ms": 51629.878, "sample_time_ms": 1382.9, "learn_time_ms": 50231.865, "learn_throughput": 79.631, "synch_weights_time_ms": 11.414}, "counters": {"num_env_steps_sampled": 124000, "num_env_steps_trained": 124000, "num_agent_steps_sampled": 496000, "num_agent_steps_trained": 496000}, "done": false, "training_iteration": 31, "trial_id": "11e70_00000", "date": "2024-08-12_23-33-42", "timestamp": 1723520022, "time_this_iter_s": 53.83136796951294, "time_total_s": 1602.4511094093323, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2b61ca0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1602.4511094093323, "iterations_since_restore": 31, "perf": {"cpu_util_percent": 42.04473684210526, "ram_util_percent": 81.48157894736843}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 8.17427811950603, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.9440393676202763, "policy_loss": -0.009189258310722098, "vf_loss": 1.9519887435373175, "vf_explained_var": 0.18578127039172662, "kl": 0.008265862110942483, "entropy": 1.349505373220595, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 59535.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.802425305553214, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.153164479719899, "policy_loss": -0.013792067557997095, "vf_loss": 4.165474080534839, "vf_explained_var": 0.418496896665563, "kl": 0.009883066239075965, "entropy": 1.2713491868089746, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 59535.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 128000, "num_env_steps_trained": 128000, "num_agent_steps_sampled": 512000, "num_agent_steps_trained": 512000}, "env_runners": {"episode_reward_max": 391.90000000000003, "episode_reward_min": -310.0, "episode_reward_mean": 56.278999999999925, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -340.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 198.2, "predator_policy": 181.0}, "policy_reward_mean": {"prey_policy": -0.7955000000000019, "predator_policy": 28.935}, "custom_metrics": {}, "hist_stats": {"episode_reward": [13.600000000000131, 73.29999999999998, -27.299999999999926, 105.19999999999966, 140.29999999999927, 49.39999999999989, -138.10000000000002, 21.4, -201.000000000001, 24.60000000000005, -177.09999999999994, 5.399999999999942, 26.90000000000009, -310.0, -11.999999999999924, -253.2000000000002, -74.10000000000034, 53.70000000000015, -109.30000000000021, -15.299999999999926, 52.10000000000003, -179.5, -41.39999999999978, 37.80000000000027, 71.29999999999964, -41.200000000000074, -84.69999999999999, 24.400000000000052, 83.19999999999906, -140.8, 53.50000000000029, 88.89999999999863, 111.09999999999927, 61.60000000000051, 58.70000000000042, 63.10000000000038, 46.600000000000406, 137.499999999999, 42.90000000000036, 40.0000000000003, -0.6999999999998354, 118.29999999999899, 40.0000000000003, 53.000000000000306, 49.000000000000455, 99.69999999999989, 55.50000000000036, 26.800000000000097, 40.0000000000003, 109.69999999999874, 226.89999999999984, 15.799999999999939, 63.80000000000041, 54.40000000000053, 257.79999999999995, 38.90000000000028, 37.80000000000027, 30.100000000000147, 139.29999999999907, 158.79999999999922, 185.19999999999916, 40.0000000000003, 40.0000000000003, 87.39999999999975, 56.80000000000045, 115.29999999999887, 49.90000000000046, 18.299999999999958, 132.59999999999957, 30.400000000000134, 40.0000000000003, 40.0000000000003, 237.79999999999944, 61.700000000000294, 79.40000000000005, 40.0000000000003, 40.0000000000003, 26.000000000000117, 339.09999999999985, 182.39999999999998, 164.29999999999944, 41.30000000000032, 58.50000000000047, 190.7999999999997, 391.90000000000003, 293.7, 184.99999999999932, 175.99999999999935, -57.40000000000036, 40.0000000000003, 40.0000000000003, 40.0000000000003, 50.80000000000048, 177.49999999999926, 191.59999999999934, 183.09999999999926, -31.39999999999955, 154.69999999999962, 160.9999999999994, 37.80000000000027], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-102.40000000000006, 20.000000000000014, 2.299999999999991, -34.000000000000156, 20.000000000000014, -250.3, 36.20000000000001, -1.0000000000000142, 78.49999999999984, 27.80000000000016, 71.89999999999962, -128.5, -125.20000000000002, -253.9, 24.50000000000008, -24.099999999999746, -250.49999999999994, -179.50000000000057, -9.399999999999855, 20.000000000000014, -177.70000000000005, -141.4, -198.70000000000005, 13.099999999999968, 17.899999999999988, -0.9999999999999952, -259.0, -340.0, -148.0, 20.000000000000014, -225.40000000000003, -332.8000000000002, -3.0999999999999863, -325.00000000000006, -58.299999999999955, 20.000000000000014, -9.399999999999869, -274.9, 8.6, -289.9, 7.399999999999965, -64.29999999999991, -124.0, -215.50000000000003, 30.20000000000019, -292.6, 15.799999999999963, 20.000000000000014, 25.400000000000098, -27.099999999999994, 63.499999999999986, -255.70000000000005, -84.1, -268.6, -0.7000000000000169, 1.0999999999999865, 63.200000000000195, 20.000000000000014, -50.5, -271.3, 33.50000000000014, 20.000000000000014, -33.0999999999998, 65.00000000000013, 20.000000000000014, 91.09999999999971, 41.60000000000025, 20.000000000000014, 28.700000000000177, 20.000000000000014, -58.9000000000001, 20.000000000000014, 23.60000000000007, 20.000000000000014, 20.000000000000014, 87.49999999999976, 20.000000000000014, 5.900000000000011, 20.000000000000014, 20.000000000000014, -60.400000000000574, 13.699999999999966, 20.000000000000014, 98.29999999999957, 20.000000000000014, 20.000000000000014, 20.000000000000014, -27.999999999999886, 20.000000000000014, 29.000000000000174, 75.49999999999945, -65.80000000000001, 11.29999999999998, 12.199999999999974, 7.399999999999965, 7.399999999999982, 20.000000000000014, 20.000000000000014, 82.69999999999939, 20.000000000000014, 185.60000000000002, -84.70000000000019, 5.299999999999947, -11.499999999999819, 23.600000000000076, 3.1999999999999793, 29.90000000000018, 24.500000000000085, 150.4999999999997, 107.29999999999973, 20.000000000000014, 17.899999999999988, 20.000000000000014, 15.799999999999963, -7.899999999999924, 20.000000000000014, 20.000000000000014, 116.29999999999971, 119.89999999999972, 38.90000000000015, 129.79999999999995, 22.400000000000066, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 34.4000000000002, 44.00000000000019, -11.199999999999852, 29.000000000000163, 29.90000000000018, 79.3999999999995, 29.90000000000018, 20.000000000000014, 20.900000000000013, -43.59999999999982, 130.7, -30.099999999999795, -49.299999999999905, -4.299999999999962, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 102.49999999999994, 134.2999999999996, 20.000000000000014, -25.299999999999876, 52.39999999999996, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -8.7999999999999, 0.7999999999999545, 152.5999999999999, 174.5, 16.399999999999984, 59.0, 20.000000000000014, 116.30000000000001, 14.299999999999967, 20.000000000000014, -10.59999999999985, 49.10000000000023, 14.300000000000166, 138.5, 193.7, 198.2, 164.3, 91.39999999999998, 20.000000000000014, 160.99999999999997, -31.599999999999845, 152.59999999999997, -290.79999999999916, 85.39999999999976, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 30.800000000000196, -45.6999999999998, 180.1999999999999, 164.59999999999997, 20.000000000000014, 20.000000000000014, 163.09999999999988, -64.00000000000091, -30.3999999999998, 29.90000000000018, 117.79999999999998, 114.19999999999999, 15.799999999999962, 20.000000000000014, 15.799999999999962], "policy_predator_policy_reward": [96.0, 0.0, 42.0, 63.0, 105.0, 98.0, 40.0, 30.0, 12.0, 22.0, 106.0, 0.0, 75.0, 166.0, 0.0, 21.0, 95.0, 134.0, 14.0, 0.0, 0.0, 142.0, 115.0, 76.0, 0.0, 10.0, 111.0, 178.0, 116.0, 0.0, 137.0, 168.0, 131.0, 123.0, 54.0, 38.0, 0.0, 175.0, 134.0, 132.0, 61.0, 48.0, 160.0, 0.0, 147.0, 74.0, 0.0, 2.0, 73.0, 0.0, 0.0, 151.0, 135.0, 133.0, 12.0, 12.0, 0.0, 0.0, 181.0, 0.0, 0.0, 0.0, 31.0, 26.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 58.0, 44.0, 3.0, 0.0, 17.0, 13.0, 17.0, 0.0, 0.0, 0.0, 35.0, 11.0, 0.0, 0.0, 0.0, 0.0, 16.0, 45.0, 0.0, 0.0, 0.0, 90.0, 27.0, 5.0, 6.0, 6.0, 0.0, 0.0, 7.0, 0.0, 58.0, 68.0, 15.0, 7.0, 14.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 18.0, 0.0, 0.0, 3.0, 0.0, 0.0, 17.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 32.0, 7.0, 2.0, 4.0, 0.0, 0.0, 26.0, 15.0, 32.0, 0.0, 51.0, 33.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 35.0, 32.0, 4.0, 3.0, 0.0, 0.0, 0.0, 0.0, 10.0, 24.0, 9.0, 3.0, 47.0, 60.0, 14.0, 14.0, 5.0, 2.0, 20.0, 0.0, 18.0, 20.0, 0.0, 0.0, 24.0, 14.0, 0.0, 4.0, 26.0, 29.0, 0.0, 148.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 18.0, 25.0, 6.0, 1.0, 0.0, 0.0, 63.0, 0.0, 6.0, 1.0, 20.0, 11.0, 0.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.681377143654182, "mean_inference_ms": 1.663565594999809, "mean_action_processing_ms": 0.2678569584304581, "mean_env_wait_ms": 0.20107183297890155, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.010631680488586426, "StateBufferConnector_ms": 0.004575610160827637, "ViewRequirementAgentConnector_ms": 0.12929105758666992}, "num_episodes": 27, "episode_return_max": 391.90000000000003, "episode_return_min": -310.0, "episode_return_mean": 56.278999999999925, "episodes_this_iter": 27}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 512000, "num_agent_steps_trained": 512000, "num_env_steps_sampled": 128000, "num_env_steps_trained": 128000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 77.11266717938094, "num_env_steps_trained_throughput_per_sec": 77.11266717938094, "timesteps_total": 128000, "num_env_steps_sampled_lifetime": 128000, "num_agent_steps_sampled_lifetime": 512000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 512000, "timers": {"training_iteration_time_ms": 51744.164, "restore_workers_time_ms": 0.013, "training_step_time_ms": 51744.12, "sample_time_ms": 1389.95, "learn_time_ms": 50338.936, "learn_throughput": 79.461, "synch_weights_time_ms": 11.606}, "counters": {"num_env_steps_sampled": 128000, "num_env_steps_trained": 128000, "num_agent_steps_sampled": 512000, "num_agent_steps_trained": 512000}, "done": false, "training_iteration": 32, "trial_id": "11e70_00000", "date": "2024-08-12_23-34-34", "timestamp": 1723520074, "time_this_iter_s": 51.904165267944336, "time_total_s": 1654.3552746772766, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2b67dc0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1654.3552746772766, "iterations_since_restore": 32, "perf": {"cpu_util_percent": 34.83378378378379, "ram_util_percent": 79.8662162162162}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 8.903201913076733, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.058259905646087, "policy_loss": -0.01052056470092524, "vf_loss": 2.067315820474473, "vf_explained_var": 0.09351043489874986, "kl": 0.009764327511630467, "entropy": 1.3214091111112525, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 61425.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.034658233576981, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.090742213890035, "policy_loss": -0.011402233450786857, "vf_loss": 6.100574049621663, "vf_explained_var": 0.40505732919173265, "kl": 0.010469257385011971, "entropy": 1.302028363533121, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 61425.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 132000, "num_env_steps_trained": 132000, "num_agent_steps_sampled": 528000, "num_agent_steps_trained": 528000}, "env_runners": {"episode_reward_max": 391.90000000000003, "episode_reward_min": -179.5, "episode_reward_mean": 96.65599999999989, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -292.6, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 198.2, "predator_policy": 181.0}, "policy_reward_mean": {"prey_policy": 29.857999999999997, "predator_policy": 18.47}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-109.30000000000021, -15.299999999999926, 52.10000000000003, -179.5, -41.39999999999978, 37.80000000000027, 71.29999999999964, -41.200000000000074, -84.69999999999999, 24.400000000000052, 83.19999999999906, -140.8, 53.50000000000029, 88.89999999999863, 111.09999999999927, 61.60000000000051, 58.70000000000042, 63.10000000000038, 46.600000000000406, 137.499999999999, 42.90000000000036, 40.0000000000003, -0.6999999999998354, 118.29999999999899, 40.0000000000003, 53.000000000000306, 49.000000000000455, 99.69999999999989, 55.50000000000036, 26.800000000000097, 40.0000000000003, 109.69999999999874, 226.89999999999984, 15.799999999999939, 63.80000000000041, 54.40000000000053, 257.79999999999995, 38.90000000000028, 37.80000000000027, 30.100000000000147, 139.29999999999907, 158.79999999999922, 185.19999999999916, 40.0000000000003, 40.0000000000003, 87.39999999999975, 56.80000000000045, 115.29999999999887, 49.90000000000046, 18.299999999999958, 132.59999999999957, 30.400000000000134, 40.0000000000003, 40.0000000000003, 237.79999999999944, 61.700000000000294, 79.40000000000005, 40.0000000000003, 40.0000000000003, 26.000000000000117, 339.09999999999985, 182.39999999999998, 164.29999999999944, 41.30000000000032, 58.50000000000047, 190.7999999999997, 391.90000000000003, 293.7, 184.99999999999932, 175.99999999999935, -57.40000000000036, 40.0000000000003, 40.0000000000003, 40.0000000000003, 50.80000000000048, 177.49999999999926, 191.59999999999934, 183.09999999999926, -31.39999999999955, 154.69999999999962, 160.9999999999994, 37.80000000000027, 103.99999999999947, 169.69999999999905, 278.09999999999985, 68.80000000000011, 187.3999999999993, 69.49999999999996, 320.4000000000001, 149.89999999999964, 47.700000000000074, 347.49999999999994, 149.7999999999995, 202.79999999999927, 201.99999999999926, 274.9, 141.0999999999995, 240.1999999999998, 286.4, 118.49999999999974], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-9.399999999999869, -274.9, 8.6, -289.9, 7.399999999999965, -64.29999999999991, -124.0, -215.50000000000003, 30.20000000000019, -292.6, 15.799999999999963, 20.000000000000014, 25.400000000000098, -27.099999999999994, 63.499999999999986, -255.70000000000005, -84.1, -268.6, -0.7000000000000169, 1.0999999999999865, 63.200000000000195, 20.000000000000014, -50.5, -271.3, 33.50000000000014, 20.000000000000014, -33.0999999999998, 65.00000000000013, 20.000000000000014, 91.09999999999971, 41.60000000000025, 20.000000000000014, 28.700000000000177, 20.000000000000014, -58.9000000000001, 20.000000000000014, 23.60000000000007, 20.000000000000014, 20.000000000000014, 87.49999999999976, 20.000000000000014, 5.900000000000011, 20.000000000000014, 20.000000000000014, -60.400000000000574, 13.699999999999966, 20.000000000000014, 98.29999999999957, 20.000000000000014, 20.000000000000014, 20.000000000000014, -27.999999999999886, 20.000000000000014, 29.000000000000174, 75.49999999999945, -65.80000000000001, 11.29999999999998, 12.199999999999974, 7.399999999999965, 7.399999999999982, 20.000000000000014, 20.000000000000014, 82.69999999999939, 20.000000000000014, 185.60000000000002, -84.70000000000019, 5.299999999999947, -11.499999999999819, 23.600000000000076, 3.1999999999999793, 29.90000000000018, 24.500000000000085, 150.4999999999997, 107.29999999999973, 20.000000000000014, 17.899999999999988, 20.000000000000014, 15.799999999999963, -7.899999999999924, 20.000000000000014, 20.000000000000014, 116.29999999999971, 119.89999999999972, 38.90000000000015, 129.79999999999995, 22.400000000000066, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 34.4000000000002, 44.00000000000019, -11.199999999999852, 29.000000000000163, 29.90000000000018, 79.3999999999995, 29.90000000000018, 20.000000000000014, 20.900000000000013, -43.59999999999982, 130.7, -30.099999999999795, -49.299999999999905, -4.299999999999962, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 102.49999999999994, 134.2999999999996, 20.000000000000014, -25.299999999999876, 52.39999999999996, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -8.7999999999999, 0.7999999999999545, 152.5999999999999, 174.5, 16.399999999999984, 59.0, 20.000000000000014, 116.30000000000001, 14.299999999999967, 20.000000000000014, -10.59999999999985, 49.10000000000023, 14.300000000000166, 138.5, 193.7, 198.2, 164.3, 91.39999999999998, 20.000000000000014, 160.99999999999997, -31.599999999999845, 152.59999999999997, -290.79999999999916, 85.39999999999976, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 30.800000000000196, -45.6999999999998, 180.1999999999999, 164.59999999999997, 20.000000000000014, 20.000000000000014, 163.09999999999988, -64.00000000000091, -30.3999999999998, 29.90000000000018, 117.79999999999998, 114.19999999999999, 15.799999999999962, 20.000000000000014, 15.799999999999962, -55.600000000000335, 104.59999999999988, 147.79999999999976, 17.899999999999977, 175.99999999999994, 76.10000000000001, 48.80000000000021, 20.000000000000014, 133.69999999999996, 31.70000000000021, 20.000000000000014, 6.499999999999999, 133.99999999999994, 163.39999999999998, -0.9999999999999952, 137.90000000000003, 6.499999999999992, -14.799999999999912, 183.79999999999995, 154.70000000000002, 102.79999999999994, 20.000000000000014, 20.000000000000014, 177.79999999999995, 20.000000000000014, 181.99999999999994, 83.90000000000002, 172.99999999999997, 20.000000000000014, 58.1, 87.19999999999997, 137.0, 154.7, 94.69999999999996, 5.299999999999993, 105.19999999999999], "policy_predator_policy_reward": [0.0, 175.0, 134.0, 132.0, 61.0, 48.0, 160.0, 0.0, 147.0, 74.0, 0.0, 2.0, 73.0, 0.0, 0.0, 151.0, 135.0, 133.0, 12.0, 12.0, 0.0, 0.0, 181.0, 0.0, 0.0, 0.0, 31.0, 26.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 58.0, 44.0, 3.0, 0.0, 17.0, 13.0, 17.0, 0.0, 0.0, 0.0, 35.0, 11.0, 0.0, 0.0, 0.0, 0.0, 16.0, 45.0, 0.0, 0.0, 0.0, 90.0, 27.0, 5.0, 6.0, 6.0, 0.0, 0.0, 7.0, 0.0, 58.0, 68.0, 15.0, 7.0, 14.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 18.0, 0.0, 0.0, 3.0, 0.0, 0.0, 17.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 32.0, 7.0, 2.0, 4.0, 0.0, 0.0, 26.0, 15.0, 32.0, 0.0, 51.0, 33.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 35.0, 32.0, 4.0, 3.0, 0.0, 0.0, 0.0, 0.0, 10.0, 24.0, 9.0, 3.0, 47.0, 60.0, 14.0, 14.0, 5.0, 2.0, 20.0, 0.0, 18.0, 20.0, 0.0, 0.0, 24.0, 14.0, 0.0, 4.0, 26.0, 29.0, 0.0, 148.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 18.0, 25.0, 6.0, 1.0, 0.0, 0.0, 63.0, 0.0, 6.0, 1.0, 20.0, 11.0, 0.0, 2.0, 50.0, 5.0, 3.0, 1.0, 3.0, 23.0, 0.0, 0.0, 8.0, 14.0, 8.0, 35.0, 9.0, 14.0, 13.0, 0.0, 33.0, 23.0, 0.0, 9.0, 27.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 18.0, 34.0, 29.0, 15.0, 1.0, 9.0, 28.0, 4.0, 4.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6802052413624906, "mean_inference_ms": 1.659833816396486, "mean_action_processing_ms": 0.26800628840137697, "mean_env_wait_ms": 0.20085583998353707, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006727099418640137, "StateBufferConnector_ms": 0.004340648651123047, "ViewRequirementAgentConnector_ms": 0.13581764698028564}, "num_episodes": 18, "episode_return_max": 391.90000000000003, "episode_return_min": -179.5, "episode_return_mean": 96.65599999999989, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 528000, "num_agent_steps_trained": 528000, "num_env_steps_sampled": 132000, "num_env_steps_trained": 132000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 76.46015086969943, "num_env_steps_trained_throughput_per_sec": 76.46015086969943, "timesteps_total": 132000, "num_env_steps_sampled_lifetime": 132000, "num_agent_steps_sampled_lifetime": 528000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 528000, "timers": {"training_iteration_time_ms": 51914.672, "restore_workers_time_ms": 0.013, "training_step_time_ms": 51914.628, "sample_time_ms": 1387.47, "learn_time_ms": 50510.891, "learn_throughput": 79.191, "synch_weights_time_ms": 11.983}, "counters": {"num_env_steps_sampled": 132000, "num_env_steps_trained": 132000, "num_agent_steps_sampled": 528000, "num_agent_steps_trained": 528000}, "done": false, "training_iteration": 33, "trial_id": "11e70_00000", "date": "2024-08-12_23-35-26", "timestamp": 1723520126, "time_this_iter_s": 52.3496150970459, "time_total_s": 1706.7048897743225, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2b15c10>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1706.7048897743225, "iterations_since_restore": 33, "perf": {"cpu_util_percent": 35.26756756756757, "ram_util_percent": 80.03513513513512}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 7.406283540195889, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.985412778047027, "policy_loss": -0.009867808985075464, "vf_loss": 2.994165521134775, "vf_explained_var": 0.13863159601019803, "kl": 0.007433768511747507, "entropy": 1.323303574355191, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 63315.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.602261108759219, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.106090491158621, "policy_loss": -0.010599033063691523, "vf_loss": 6.115090008639784, "vf_explained_var": 0.4512352162883395, "kl": 0.010663468846067784, "entropy": 1.2954423484978852, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 63315.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 136000, "num_env_steps_trained": 136000, "num_agent_steps_sampled": 544000, "num_agent_steps_trained": 544000}, "env_runners": {"episode_reward_max": 391.90000000000003, "episode_reward_min": -57.40000000000036, "episode_reward_mean": 126.22799999999988, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -290.79999999999916, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 198.2, "predator_policy": 148.0}, "policy_reward_mean": {"prey_policy": 51.073999999999984, "predator_policy": 12.04}, "custom_metrics": {}, "hist_stats": {"episode_reward": [46.600000000000406, 137.499999999999, 42.90000000000036, 40.0000000000003, -0.6999999999998354, 118.29999999999899, 40.0000000000003, 53.000000000000306, 49.000000000000455, 99.69999999999989, 55.50000000000036, 26.800000000000097, 40.0000000000003, 109.69999999999874, 226.89999999999984, 15.799999999999939, 63.80000000000041, 54.40000000000053, 257.79999999999995, 38.90000000000028, 37.80000000000027, 30.100000000000147, 139.29999999999907, 158.79999999999922, 185.19999999999916, 40.0000000000003, 40.0000000000003, 87.39999999999975, 56.80000000000045, 115.29999999999887, 49.90000000000046, 18.299999999999958, 132.59999999999957, 30.400000000000134, 40.0000000000003, 40.0000000000003, 237.79999999999944, 61.700000000000294, 79.40000000000005, 40.0000000000003, 40.0000000000003, 26.000000000000117, 339.09999999999985, 182.39999999999998, 164.29999999999944, 41.30000000000032, 58.50000000000047, 190.7999999999997, 391.90000000000003, 293.7, 184.99999999999932, 175.99999999999935, -57.40000000000036, 40.0000000000003, 40.0000000000003, 40.0000000000003, 50.80000000000048, 177.49999999999926, 191.59999999999934, 183.09999999999926, -31.39999999999955, 154.69999999999962, 160.9999999999994, 37.80000000000027, 103.99999999999947, 169.69999999999905, 278.09999999999985, 68.80000000000011, 187.3999999999993, 69.49999999999996, 320.4000000000001, 149.89999999999964, 47.700000000000074, 347.49999999999994, 149.7999999999995, 202.79999999999927, 201.99999999999926, 274.9, 141.0999999999995, 240.1999999999998, 286.4, 118.49999999999974, 110.19999999999983, 168.9999999999994, 40.0000000000003, 177.29999999999924, 199.79999999999922, 258.1999999999997, 75.9, 89.69999999999999, 180.39999999999927, 134.09999999999965, 40.0000000000003, 174.29999999999933, 298.00000000000006, 267.0999999999999, 190.59999999999994, 239.3999999999997, 40.0000000000003, 366.69999999999993], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [23.60000000000007, 20.000000000000014, 20.000000000000014, 87.49999999999976, 20.000000000000014, 5.900000000000011, 20.000000000000014, 20.000000000000014, -60.400000000000574, 13.699999999999966, 20.000000000000014, 98.29999999999957, 20.000000000000014, 20.000000000000014, 20.000000000000014, -27.999999999999886, 20.000000000000014, 29.000000000000174, 75.49999999999945, -65.80000000000001, 11.29999999999998, 12.199999999999974, 7.399999999999965, 7.399999999999982, 20.000000000000014, 20.000000000000014, 82.69999999999939, 20.000000000000014, 185.60000000000002, -84.70000000000019, 5.299999999999947, -11.499999999999819, 23.600000000000076, 3.1999999999999793, 29.90000000000018, 24.500000000000085, 150.4999999999997, 107.29999999999973, 20.000000000000014, 17.899999999999988, 20.000000000000014, 15.799999999999963, -7.899999999999924, 20.000000000000014, 20.000000000000014, 116.29999999999971, 119.89999999999972, 38.90000000000015, 129.79999999999995, 22.400000000000066, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 34.4000000000002, 44.00000000000019, -11.199999999999852, 29.000000000000163, 29.90000000000018, 79.3999999999995, 29.90000000000018, 20.000000000000014, 20.900000000000013, -43.59999999999982, 130.7, -30.099999999999795, -49.299999999999905, -4.299999999999962, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 102.49999999999994, 134.2999999999996, 20.000000000000014, -25.299999999999876, 52.39999999999996, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -8.7999999999999, 0.7999999999999545, 152.5999999999999, 174.5, 16.399999999999984, 59.0, 20.000000000000014, 116.30000000000001, 14.299999999999967, 20.000000000000014, -10.59999999999985, 49.10000000000023, 14.300000000000166, 138.5, 193.7, 198.2, 164.3, 91.39999999999998, 20.000000000000014, 160.99999999999997, -31.599999999999845, 152.59999999999997, -290.79999999999916, 85.39999999999976, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 30.800000000000196, -45.6999999999998, 180.1999999999999, 164.59999999999997, 20.000000000000014, 20.000000000000014, 163.09999999999988, -64.00000000000091, -30.3999999999998, 29.90000000000018, 117.79999999999998, 114.19999999999999, 15.799999999999962, 20.000000000000014, 15.799999999999962, -55.600000000000335, 104.59999999999988, 147.79999999999976, 17.899999999999977, 175.99999999999994, 76.10000000000001, 48.80000000000021, 20.000000000000014, 133.69999999999996, 31.70000000000021, 20.000000000000014, 6.499999999999999, 133.99999999999994, 163.39999999999998, -0.9999999999999952, 137.90000000000003, 6.499999999999992, -14.799999999999912, 183.79999999999995, 154.70000000000002, 102.79999999999994, 20.000000000000014, 20.000000000000014, 177.79999999999995, 20.000000000000014, 181.99999999999994, 83.90000000000002, 172.99999999999997, 20.000000000000014, 58.1, 87.19999999999997, 137.0, 154.7, 94.69999999999996, 5.299999999999993, 105.19999999999999, 20.000000000000014, 45.20000000000002, 98.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 156.19999999999993, 1.0999999999999617, 20.000000000000014, 177.79999999999993, 88.99999999999997, 162.19999999999996, -30.099999999999987, 20.000000000000014, 16.699999999999875, 20.000000000000014, 20.000000000000014, 142.39999999999998, 20.000000000000014, 112.1, 20.000000000000014, 20.000000000000014, 137.3, 20.000000000000014, 107.89999999999998, 145.1, 111.8, 128.29999999999995, 41.300000000000004, 29.300000000000004, 57.49999999999999, 161.89999999999995, 20.000000000000014, 20.000000000000014, 168.5, 198.2], "policy_predator_policy_reward": [3.0, 0.0, 17.0, 13.0, 17.0, 0.0, 0.0, 0.0, 35.0, 11.0, 0.0, 0.0, 0.0, 0.0, 16.0, 45.0, 0.0, 0.0, 0.0, 90.0, 27.0, 5.0, 6.0, 6.0, 0.0, 0.0, 7.0, 0.0, 58.0, 68.0, 15.0, 7.0, 14.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 18.0, 0.0, 0.0, 3.0, 0.0, 0.0, 17.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 32.0, 7.0, 2.0, 4.0, 0.0, 0.0, 26.0, 15.0, 32.0, 0.0, 51.0, 33.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 35.0, 32.0, 4.0, 3.0, 0.0, 0.0, 0.0, 0.0, 10.0, 24.0, 9.0, 3.0, 47.0, 60.0, 14.0, 14.0, 5.0, 2.0, 20.0, 0.0, 18.0, 20.0, 0.0, 0.0, 24.0, 14.0, 0.0, 4.0, 26.0, 29.0, 0.0, 148.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 18.0, 25.0, 6.0, 1.0, 0.0, 0.0, 63.0, 0.0, 6.0, 1.0, 20.0, 11.0, 0.0, 2.0, 50.0, 5.0, 3.0, 1.0, 3.0, 23.0, 0.0, 0.0, 8.0, 14.0, 8.0, 35.0, 9.0, 14.0, 13.0, 0.0, 33.0, 23.0, 0.0, 9.0, 27.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 18.0, 34.0, 29.0, 15.0, 1.0, 9.0, 28.0, 4.0, 4.0, 25.0, 20.0, 18.0, 33.0, 0.0, 0.0, 10.0, 10.0, 0.0, 2.0, 0.0, 7.0, 59.0, 27.0, 52.0, 1.0, 16.0, 2.0, 0.0, 2.0, 0.0, 0.0, 10.0, 7.0, 25.0, 20.0, 13.0, 14.0, 65.0, 55.0, 3.0, 17.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.679500261278101, "mean_inference_ms": 1.6543334920159265, "mean_action_processing_ms": 0.2681106968119831, "mean_env_wait_ms": 0.20060252618924593, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006826996803283691, "StateBufferConnector_ms": 0.004316806793212891, "ViewRequirementAgentConnector_ms": 0.1296989917755127}, "num_episodes": 18, "episode_return_max": 391.90000000000003, "episode_return_min": -57.40000000000036, "episode_return_mean": 126.22799999999988, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 544000, "num_agent_steps_trained": 544000, "num_env_steps_sampled": 136000, "num_env_steps_trained": 136000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 77.32310657889539, "num_env_steps_trained_throughput_per_sec": 77.32310657889539, "timesteps_total": 136000, "num_env_steps_sampled_lifetime": 136000, "num_agent_steps_sampled_lifetime": 544000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 544000, "timers": {"training_iteration_time_ms": 51815.685, "restore_workers_time_ms": 0.013, "training_step_time_ms": 51815.641, "sample_time_ms": 1383.012, "learn_time_ms": 50416.232, "learn_throughput": 79.34, "synch_weights_time_ms": 12.078}, "counters": {"num_env_steps_sampled": 136000, "num_env_steps_trained": 136000, "num_agent_steps_sampled": 544000, "num_agent_steps_trained": 544000}, "done": false, "training_iteration": 34, "trial_id": "11e70_00000", "date": "2024-08-12_23-36-18", "timestamp": 1723520178, "time_this_iter_s": 51.77617788314819, "time_total_s": 1758.4810676574707, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2b93430>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1758.4810676574707, "iterations_since_restore": 34, "perf": {"cpu_util_percent": 34.82027027027027, "ram_util_percent": 80.12567567567568}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 6.866020640431258, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.703265991286626, "policy_loss": -0.01241745913349506, "vf_loss": 2.7141541941456064, "vf_explained_var": 0.11933098224105028, "kl": 0.010195073038769722, "entropy": 1.3137625534698445, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 65205.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.784864335274571, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.406249728783098, "policy_loss": -0.012474925979902898, "vf_loss": 6.4171998432704385, "vf_explained_var": 0.47486808757302623, "kl": 0.010165328162903019, "entropy": 1.2600837354937557, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 65205.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 140000, "num_env_steps_trained": 140000, "num_agent_steps_sampled": 560000, "num_agent_steps_trained": 560000}, "env_runners": {"episode_reward_max": 391.90000000000003, "episode_reward_min": -57.40000000000036, "episode_reward_mean": 149.89099999999982, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -290.79999999999916, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 198.2, "predator_policy": 148.0}, "policy_reward_mean": {"prey_policy": 62.2655, "predator_policy": 12.68}, "custom_metrics": {}, "hist_stats": {"episode_reward": [257.79999999999995, 38.90000000000028, 37.80000000000027, 30.100000000000147, 139.29999999999907, 158.79999999999922, 185.19999999999916, 40.0000000000003, 40.0000000000003, 87.39999999999975, 56.80000000000045, 115.29999999999887, 49.90000000000046, 18.299999999999958, 132.59999999999957, 30.400000000000134, 40.0000000000003, 40.0000000000003, 237.79999999999944, 61.700000000000294, 79.40000000000005, 40.0000000000003, 40.0000000000003, 26.000000000000117, 339.09999999999985, 182.39999999999998, 164.29999999999944, 41.30000000000032, 58.50000000000047, 190.7999999999997, 391.90000000000003, 293.7, 184.99999999999932, 175.99999999999935, -57.40000000000036, 40.0000000000003, 40.0000000000003, 40.0000000000003, 50.80000000000048, 177.49999999999926, 191.59999999999934, 183.09999999999926, -31.39999999999955, 154.69999999999962, 160.9999999999994, 37.80000000000027, 103.99999999999947, 169.69999999999905, 278.09999999999985, 68.80000000000011, 187.3999999999993, 69.49999999999996, 320.4000000000001, 149.89999999999964, 47.700000000000074, 347.49999999999994, 149.7999999999995, 202.79999999999927, 201.99999999999926, 274.9, 141.0999999999995, 240.1999999999998, 286.4, 118.49999999999974, 110.19999999999983, 168.9999999999994, 40.0000000000003, 177.29999999999924, 199.79999999999922, 258.1999999999997, 75.9, 89.69999999999999, 180.39999999999927, 134.09999999999965, 40.0000000000003, 174.29999999999933, 298.00000000000006, 267.0999999999999, 190.59999999999994, 239.3999999999997, 40.0000000000003, 366.69999999999993, 126.39999999999966, 225.1999999999999, 185.10000000000002, 193.29999999999927, 107.40000000000003, 276.5, 90.79999999999978, 160.3999999999992, 326.09999999999997, 325.9, 188.39999999999932, 183.0999999999992, 206.09999999999994, 349.60000000000036, 153.39999999999932, 40.0000000000003, 139.7999999999992, 308.0], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [150.4999999999997, 107.29999999999973, 20.000000000000014, 17.899999999999988, 20.000000000000014, 15.799999999999963, -7.899999999999924, 20.000000000000014, 20.000000000000014, 116.29999999999971, 119.89999999999972, 38.90000000000015, 129.79999999999995, 22.400000000000066, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 34.4000000000002, 44.00000000000019, -11.199999999999852, 29.000000000000163, 29.90000000000018, 79.3999999999995, 29.90000000000018, 20.000000000000014, 20.900000000000013, -43.59999999999982, 130.7, -30.099999999999795, -49.299999999999905, -4.299999999999962, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 102.49999999999994, 134.2999999999996, 20.000000000000014, -25.299999999999876, 52.39999999999996, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -8.7999999999999, 0.7999999999999545, 152.5999999999999, 174.5, 16.399999999999984, 59.0, 20.000000000000014, 116.30000000000001, 14.299999999999967, 20.000000000000014, -10.59999999999985, 49.10000000000023, 14.300000000000166, 138.5, 193.7, 198.2, 164.3, 91.39999999999998, 20.000000000000014, 160.99999999999997, -31.599999999999845, 152.59999999999997, -290.79999999999916, 85.39999999999976, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 30.800000000000196, -45.6999999999998, 180.1999999999999, 164.59999999999997, 20.000000000000014, 20.000000000000014, 163.09999999999988, -64.00000000000091, -30.3999999999998, 29.90000000000018, 117.79999999999998, 114.19999999999999, 15.799999999999962, 20.000000000000014, 15.799999999999962, -55.600000000000335, 104.59999999999988, 147.79999999999976, 17.899999999999977, 175.99999999999994, 76.10000000000001, 48.80000000000021, 20.000000000000014, 133.69999999999996, 31.70000000000021, 20.000000000000014, 6.499999999999999, 133.99999999999994, 163.39999999999998, -0.9999999999999952, 137.90000000000003, 6.499999999999992, -14.799999999999912, 183.79999999999995, 154.70000000000002, 102.79999999999994, 20.000000000000014, 20.000000000000014, 177.79999999999995, 20.000000000000014, 181.99999999999994, 83.90000000000002, 172.99999999999997, 20.000000000000014, 58.1, 87.19999999999997, 137.0, 154.7, 94.69999999999996, 5.299999999999993, 105.19999999999999, 20.000000000000014, 45.20000000000002, 98.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 156.19999999999993, 1.0999999999999617, 20.000000000000014, 177.79999999999993, 88.99999999999997, 162.19999999999996, -30.099999999999987, 20.000000000000014, 16.699999999999875, 20.000000000000014, 20.000000000000014, 142.39999999999998, 20.000000000000014, 112.1, 20.000000000000014, 20.000000000000014, 137.3, 20.000000000000014, 107.89999999999998, 145.1, 111.8, 128.29999999999995, 41.300000000000004, 29.300000000000004, 57.49999999999999, 161.89999999999995, 20.000000000000014, 20.000000000000014, 168.5, 198.2, 128.89999999999998, -32.49999999999975, 89.89999999999998, 86.30000000000001, 41.900000000000006, 78.2, -29.499999999999815, 183.79999999999998, 77.29999999999998, -73.9, 185.0, 63.5, 17.899999999999988, 14.900000000000006, 20.000000000000014, 121.39999999999988, 197.29999999999998, 96.80000000000001, 192.79999999999995, 109.1, 163.39999999999998, 20.000000000000014, 163.0999999999999, 20.000000000000014, 70.1, 47.000000000000014, 187.39999999999992, 153.19999999999996, 15.799999999999963, 119.59999999999991, 20.000000000000014, 20.000000000000014, 87.79999999999997, 20.000000000000014, 147.8, 150.19999999999996], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 18.0, 0.0, 0.0, 3.0, 0.0, 0.0, 17.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 32.0, 7.0, 2.0, 4.0, 0.0, 0.0, 26.0, 15.0, 32.0, 0.0, 51.0, 33.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 35.0, 32.0, 4.0, 3.0, 0.0, 0.0, 0.0, 0.0, 10.0, 24.0, 9.0, 3.0, 47.0, 60.0, 14.0, 14.0, 5.0, 2.0, 20.0, 0.0, 18.0, 20.0, 0.0, 0.0, 24.0, 14.0, 0.0, 4.0, 26.0, 29.0, 0.0, 148.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 18.0, 25.0, 6.0, 1.0, 0.0, 0.0, 63.0, 0.0, 6.0, 1.0, 20.0, 11.0, 0.0, 2.0, 50.0, 5.0, 3.0, 1.0, 3.0, 23.0, 0.0, 0.0, 8.0, 14.0, 8.0, 35.0, 9.0, 14.0, 13.0, 0.0, 33.0, 23.0, 0.0, 9.0, 27.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 18.0, 34.0, 29.0, 15.0, 1.0, 9.0, 28.0, 4.0, 4.0, 25.0, 20.0, 18.0, 33.0, 0.0, 0.0, 10.0, 10.0, 0.0, 2.0, 0.0, 7.0, 59.0, 27.0, 52.0, 1.0, 16.0, 2.0, 0.0, 2.0, 0.0, 0.0, 10.0, 7.0, 25.0, 20.0, 13.0, 14.0, 65.0, 55.0, 3.0, 17.0, 0.0, 0.0, 0.0, 0.0, 5.0, 25.0, 0.0, 49.0, 40.0, 25.0, 23.0, 16.0, 33.0, 71.0, 28.0, 0.0, 32.0, 26.0, 0.0, 19.0, 0.0, 32.0, 24.0, 0.0, 5.0, 0.0, 0.0, 0.0, 55.0, 34.0, 3.0, 6.0, 16.0, 2.0, 0.0, 0.0, 32.0, 0.0, 0.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6788647915357403, "mean_inference_ms": 1.6497119154632411, "mean_action_processing_ms": 0.26811286330033407, "mean_env_wait_ms": 0.20041505404600612, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0068035125732421875, "StateBufferConnector_ms": 0.004320859909057617, "ViewRequirementAgentConnector_ms": 0.12022435665130615}, "num_episodes": 18, "episode_return_max": 391.90000000000003, "episode_return_min": -57.40000000000036, "episode_return_mean": 149.89099999999982, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 560000, "num_agent_steps_trained": 560000, "num_env_steps_sampled": 140000, "num_env_steps_trained": 140000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 76.75498222381249, "num_env_steps_trained_throughput_per_sec": 76.75498222381249, "timesteps_total": 140000, "num_env_steps_sampled_lifetime": 140000, "num_agent_steps_sampled_lifetime": 560000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 560000, "timers": {"training_iteration_time_ms": 51981.854, "restore_workers_time_ms": 0.013, "training_step_time_ms": 51981.813, "sample_time_ms": 1385.327, "learn_time_ms": 50579.71, "learn_throughput": 79.083, "synch_weights_time_ms": 12.53}, "counters": {"num_env_steps_sampled": 140000, "num_env_steps_trained": 140000, "num_agent_steps_sampled": 560000, "num_agent_steps_trained": 560000}, "done": false, "training_iteration": 35, "trial_id": "11e70_00000", "date": "2024-08-12_23-37-10", "timestamp": 1723520230, "time_this_iter_s": 52.1341278553009, "time_total_s": 1810.6151955127716, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2b96dc0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1810.6151955127716, "iterations_since_restore": 35, "perf": {"cpu_util_percent": 34.54459459459459, "ram_util_percent": 80.71081081081081}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 7.531752513577699, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.6285150721590353, "policy_loss": -0.016966388151591655, "vf_loss": 2.6433674669770335, "vf_explained_var": 0.1226474523228943, "kl": 0.014093297357272766, "entropy": 1.2882611977360237, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 67095.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 6.519924459823225, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.091827094113385, "policy_loss": -0.011211840289758232, "vf_loss": 6.1016694041156265, "vf_explained_var": 0.4780056526421239, "kl": 0.00913028112647139, "entropy": 1.223637530727992, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 67095.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 144000, "num_env_steps_trained": 144000, "num_agent_steps_sampled": 576000, "num_agent_steps_trained": 576000}, "env_runners": {"episode_reward_max": 391.90000000000003, "episode_reward_min": -57.40000000000036, "episode_reward_mean": 166.85199999999978, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -290.79999999999916, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 198.2, "predator_policy": 148.0}, "policy_reward_mean": {"prey_policy": 69.116, "predator_policy": 14.31}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.0000000000003, 26.000000000000117, 339.09999999999985, 182.39999999999998, 164.29999999999944, 41.30000000000032, 58.50000000000047, 190.7999999999997, 391.90000000000003, 293.7, 184.99999999999932, 175.99999999999935, -57.40000000000036, 40.0000000000003, 40.0000000000003, 40.0000000000003, 50.80000000000048, 177.49999999999926, 191.59999999999934, 183.09999999999926, -31.39999999999955, 154.69999999999962, 160.9999999999994, 37.80000000000027, 103.99999999999947, 169.69999999999905, 278.09999999999985, 68.80000000000011, 187.3999999999993, 69.49999999999996, 320.4000000000001, 149.89999999999964, 47.700000000000074, 347.49999999999994, 149.7999999999995, 202.79999999999927, 201.99999999999926, 274.9, 141.0999999999995, 240.1999999999998, 286.4, 118.49999999999974, 110.19999999999983, 168.9999999999994, 40.0000000000003, 177.29999999999924, 199.79999999999922, 258.1999999999997, 75.9, 89.69999999999999, 180.39999999999927, 134.09999999999965, 40.0000000000003, 174.29999999999933, 298.00000000000006, 267.0999999999999, 190.59999999999994, 239.3999999999997, 40.0000000000003, 366.69999999999993, 126.39999999999966, 225.1999999999999, 185.10000000000002, 193.29999999999927, 107.40000000000003, 276.5, 90.79999999999978, 160.3999999999992, 326.09999999999997, 325.9, 188.39999999999932, 183.0999999999992, 206.09999999999994, 349.60000000000036, 153.39999999999932, 40.0000000000003, 139.7999999999992, 308.0, 88.69999999999997, 85.79999999999986, 136.69999999999948, 125.09999999999934, 163.89999999999947, 215.49999999999923, 40.0000000000003, 327.69999999999993, 108.29999999999967, 136.59999999999977, 27.90000000000012, 215.99999999999926, 184.89999999999932, 88.00000000000006, 241.9, 355.00000000000006, 290.3999999999999, 104.00000000000003, 63.40000000000021, 183.09999999999945, 136.99999999999994, 293.70000000000005], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 20.000000000000014, -8.7999999999999, 0.7999999999999545, 152.5999999999999, 174.5, 16.399999999999984, 59.0, 20.000000000000014, 116.30000000000001, 14.299999999999967, 20.000000000000014, -10.59999999999985, 49.10000000000023, 14.300000000000166, 138.5, 193.7, 198.2, 164.3, 91.39999999999998, 20.000000000000014, 160.99999999999997, -31.599999999999845, 152.59999999999997, -290.79999999999916, 85.39999999999976, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 30.800000000000196, -45.6999999999998, 180.1999999999999, 164.59999999999997, 20.000000000000014, 20.000000000000014, 163.09999999999988, -64.00000000000091, -30.3999999999998, 29.90000000000018, 117.79999999999998, 114.19999999999999, 15.799999999999962, 20.000000000000014, 15.799999999999962, -55.600000000000335, 104.59999999999988, 147.79999999999976, 17.899999999999977, 175.99999999999994, 76.10000000000001, 48.80000000000021, 20.000000000000014, 133.69999999999996, 31.70000000000021, 20.000000000000014, 6.499999999999999, 133.99999999999994, 163.39999999999998, -0.9999999999999952, 137.90000000000003, 6.499999999999992, -14.799999999999912, 183.79999999999995, 154.70000000000002, 102.79999999999994, 20.000000000000014, 20.000000000000014, 177.79999999999995, 20.000000000000014, 181.99999999999994, 83.90000000000002, 172.99999999999997, 20.000000000000014, 58.1, 87.19999999999997, 137.0, 154.7, 94.69999999999996, 5.299999999999993, 105.19999999999999, 20.000000000000014, 45.20000000000002, 98.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 156.19999999999993, 1.0999999999999617, 20.000000000000014, 177.79999999999993, 88.99999999999997, 162.19999999999996, -30.099999999999987, 20.000000000000014, 16.699999999999875, 20.000000000000014, 20.000000000000014, 142.39999999999998, 20.000000000000014, 112.1, 20.000000000000014, 20.000000000000014, 137.3, 20.000000000000014, 107.89999999999998, 145.1, 111.8, 128.29999999999995, 41.300000000000004, 29.300000000000004, 57.49999999999999, 161.89999999999995, 20.000000000000014, 20.000000000000014, 168.5, 198.2, 128.89999999999998, -32.49999999999975, 89.89999999999998, 86.30000000000001, 41.900000000000006, 78.2, -29.499999999999815, 183.79999999999998, 77.29999999999998, -73.9, 185.0, 63.5, 17.899999999999988, 14.900000000000006, 20.000000000000014, 121.39999999999988, 197.29999999999998, 96.80000000000001, 192.79999999999995, 109.1, 163.39999999999998, 20.000000000000014, 163.0999999999999, 20.000000000000014, 70.1, 47.000000000000014, 187.39999999999992, 153.19999999999996, 15.799999999999963, 119.59999999999991, 20.000000000000014, 20.000000000000014, 87.79999999999997, 20.000000000000014, 147.8, 150.19999999999996, -13.29999999999999, 20.000000000000014, 33.79999999999998, 20.000000000000014, 82.70000000000002, 20.000000000000014, 58.10000000000002, 20.000000000000014, 20.000000000000014, 119.89999999999998, 20.000000000000014, 195.49999999999997, 20.000000000000014, 20.000000000000014, 125.29999999999995, 178.4, -32.49999999999978, 84.8, 4.100000000000012, 45.50000000000001, -3.099999999999979, 20.000000000000014, 194.0, 20.000000000000014, 20.000000000000014, 164.89999999999992, 20.000000000000014, 64.99999999999997, 53.00000000000001, 140.9, 160.39999999999998, 194.6, 130.99999999999997, 133.39999999999998, 28.69999999999999, -12.699999999999996, 20.000000000000014, 34.39999999999996, 20.000000000000014, 163.1, 92.6, -28.599999999999987, 109.69999999999999, 161.0], "policy_predator_policy_reward": [0.0, 0.0, 10.0, 24.0, 9.0, 3.0, 47.0, 60.0, 14.0, 14.0, 5.0, 2.0, 20.0, 0.0, 18.0, 20.0, 0.0, 0.0, 24.0, 14.0, 0.0, 4.0, 26.0, 29.0, 0.0, 148.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 18.0, 25.0, 6.0, 1.0, 0.0, 0.0, 63.0, 0.0, 6.0, 1.0, 20.0, 11.0, 0.0, 2.0, 50.0, 5.0, 3.0, 1.0, 3.0, 23.0, 0.0, 0.0, 8.0, 14.0, 8.0, 35.0, 9.0, 14.0, 13.0, 0.0, 33.0, 23.0, 0.0, 9.0, 27.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 18.0, 34.0, 29.0, 15.0, 1.0, 9.0, 28.0, 4.0, 4.0, 25.0, 20.0, 18.0, 33.0, 0.0, 0.0, 10.0, 10.0, 0.0, 2.0, 0.0, 7.0, 59.0, 27.0, 52.0, 1.0, 16.0, 2.0, 0.0, 2.0, 0.0, 0.0, 10.0, 7.0, 25.0, 20.0, 13.0, 14.0, 65.0, 55.0, 3.0, 17.0, 0.0, 0.0, 0.0, 0.0, 5.0, 25.0, 0.0, 49.0, 40.0, 25.0, 23.0, 16.0, 33.0, 71.0, 28.0, 0.0, 32.0, 26.0, 0.0, 19.0, 0.0, 32.0, 24.0, 0.0, 5.0, 0.0, 0.0, 0.0, 55.0, 34.0, 3.0, 6.0, 16.0, 2.0, 0.0, 0.0, 32.0, 0.0, 0.0, 10.0, 59.0, 23.0, 17.0, 15.0, 26.0, 8.0, 21.0, 26.0, 24.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.0, 0.0, 24.0, 32.0, 56.0, 31.0, 0.0, 11.0, 2.0, 0.0, 0.0, 0.0, 1.0, 2.0, 48.0, 0.0, 0.0, 0.0, 26.0, 0.0, 11.0, 77.0, 0.0, 9.0, 0.0, 0.0, 73.0, 0.0, 0.0, 23.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6801730281664305, "mean_inference_ms": 1.6490749053663256, "mean_action_processing_ms": 0.26934770745739534, "mean_env_wait_ms": 0.20108420045322817, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005104660987854004, "StateBufferConnector_ms": 0.003905653953552246, "ViewRequirementAgentConnector_ms": 0.11320352554321289}, "num_episodes": 22, "episode_return_max": 391.90000000000003, "episode_return_min": -57.40000000000036, "episode_return_mean": 166.85199999999978, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 576000, "num_agent_steps_trained": 576000, "num_env_steps_sampled": 144000, "num_env_steps_trained": 144000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 75.08373617392554, "num_env_steps_trained_throughput_per_sec": 75.08373617392554, "timesteps_total": 144000, "num_env_steps_sampled_lifetime": 144000, "num_agent_steps_sampled_lifetime": 576000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 576000, "timers": {"training_iteration_time_ms": 52238.261, "restore_workers_time_ms": 0.013, "training_step_time_ms": 52238.22, "sample_time_ms": 1454.603, "learn_time_ms": 50766.179, "learn_throughput": 78.793, "synch_weights_time_ms": 12.915}, "counters": {"num_env_steps_sampled": 144000, "num_env_steps_trained": 144000, "num_agent_steps_sampled": 576000, "num_agent_steps_trained": 576000}, "done": false, "training_iteration": 36, "trial_id": "11e70_00000", "date": "2024-08-12_23-38-04", "timestamp": 1723520284, "time_this_iter_s": 53.32525086402893, "time_total_s": 1863.9404463768005, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3f39af0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1863.9404463768005, "iterations_since_restore": 36, "perf": {"cpu_util_percent": 38.27631578947368, "ram_util_percent": 82.22631578947367}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 6.284601674256502, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.7317685446411213, "policy_loss": -0.007384162160282136, "vf_loss": 3.7375485130088038, "vf_explained_var": 0.023617696131347978, "kl": 0.010694632833266788, "entropy": 1.2822838131082122, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 68985.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 6.1543825611550975, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.699375645067326, "policy_loss": -0.007202179782664177, "vf_loss": 5.70517907344475, "vf_explained_var": 0.19506748520508013, "kl": 0.00932502675252465, "entropy": 1.2162475473666317, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 68985.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 148000, "num_env_steps_trained": 148000, "num_agent_steps_sampled": 592000, "num_agent_steps_trained": 592000}, "env_runners": {"episode_reward_max": 366.69999999999993, "episode_reward_min": -60.60000000000002, "episode_reward_mean": 165.4889999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -630.1, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 198.2, "predator_policy": 512.0}, "policy_reward_mean": {"prey_policy": 65.0195, "predator_policy": 17.725}, "custom_metrics": {}, "hist_stats": {"episode_reward": [37.80000000000027, 103.99999999999947, 169.69999999999905, 278.09999999999985, 68.80000000000011, 187.3999999999993, 69.49999999999996, 320.4000000000001, 149.89999999999964, 47.700000000000074, 347.49999999999994, 149.7999999999995, 202.79999999999927, 201.99999999999926, 274.9, 141.0999999999995, 240.1999999999998, 286.4, 118.49999999999974, 110.19999999999983, 168.9999999999994, 40.0000000000003, 177.29999999999924, 199.79999999999922, 258.1999999999997, 75.9, 89.69999999999999, 180.39999999999927, 134.09999999999965, 40.0000000000003, 174.29999999999933, 298.00000000000006, 267.0999999999999, 190.59999999999994, 239.3999999999997, 40.0000000000003, 366.69999999999993, 126.39999999999966, 225.1999999999999, 185.10000000000002, 193.29999999999927, 107.40000000000003, 276.5, 90.79999999999978, 160.3999999999992, 326.09999999999997, 325.9, 188.39999999999932, 183.0999999999992, 206.09999999999994, 349.60000000000036, 153.39999999999932, 40.0000000000003, 139.7999999999992, 308.0, 88.69999999999997, 85.79999999999986, 136.69999999999948, 125.09999999999934, 163.89999999999947, 215.49999999999923, 40.0000000000003, 327.69999999999993, 108.29999999999967, 136.59999999999977, 27.90000000000012, 215.99999999999926, 184.89999999999932, 88.00000000000006, 241.9, 355.00000000000006, 290.3999999999999, 104.00000000000003, 63.40000000000021, 183.09999999999945, 136.99999999999994, 293.70000000000005, 140.49999999999957, 40.0000000000003, 212.79999999999924, 190.2999999999994, 67.00000000000024, 135.39999999999966, 221.79999999999998, 165.89999999999947, 177.49999999999932, 34.50000000000022, -60.60000000000002, 83.89999999999989, 73.2999999999997, 225.2, 296.8, 233.69999999999985, 121.19999999999996, 211.8999999999993, -48.70000000000085, 45.600000000000165, 143.49999999999926, 132.6999999999998, 58.39999999999999], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 15.799999999999962, -55.600000000000335, 104.59999999999988, 147.79999999999976, 17.899999999999977, 175.99999999999994, 76.10000000000001, 48.80000000000021, 20.000000000000014, 133.69999999999996, 31.70000000000021, 20.000000000000014, 6.499999999999999, 133.99999999999994, 163.39999999999998, -0.9999999999999952, 137.90000000000003, 6.499999999999992, -14.799999999999912, 183.79999999999995, 154.70000000000002, 102.79999999999994, 20.000000000000014, 20.000000000000014, 177.79999999999995, 20.000000000000014, 181.99999999999994, 83.90000000000002, 172.99999999999997, 20.000000000000014, 58.1, 87.19999999999997, 137.0, 154.7, 94.69999999999996, 5.299999999999993, 105.19999999999999, 20.000000000000014, 45.20000000000002, 98.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 156.19999999999993, 1.0999999999999617, 20.000000000000014, 177.79999999999993, 88.99999999999997, 162.19999999999996, -30.099999999999987, 20.000000000000014, 16.699999999999875, 20.000000000000014, 20.000000000000014, 142.39999999999998, 20.000000000000014, 112.1, 20.000000000000014, 20.000000000000014, 137.3, 20.000000000000014, 107.89999999999998, 145.1, 111.8, 128.29999999999995, 41.300000000000004, 29.300000000000004, 57.49999999999999, 161.89999999999995, 20.000000000000014, 20.000000000000014, 168.5, 198.2, 128.89999999999998, -32.49999999999975, 89.89999999999998, 86.30000000000001, 41.900000000000006, 78.2, -29.499999999999815, 183.79999999999998, 77.29999999999998, -73.9, 185.0, 63.5, 17.899999999999988, 14.900000000000006, 20.000000000000014, 121.39999999999988, 197.29999999999998, 96.80000000000001, 192.79999999999995, 109.1, 163.39999999999998, 20.000000000000014, 163.0999999999999, 20.000000000000014, 70.1, 47.000000000000014, 187.39999999999992, 153.19999999999996, 15.799999999999963, 119.59999999999991, 20.000000000000014, 20.000000000000014, 87.79999999999997, 20.000000000000014, 147.8, 150.19999999999996, -13.29999999999999, 20.000000000000014, 33.79999999999998, 20.000000000000014, 82.70000000000002, 20.000000000000014, 58.10000000000002, 20.000000000000014, 20.000000000000014, 119.89999999999998, 20.000000000000014, 195.49999999999997, 20.000000000000014, 20.000000000000014, 125.29999999999995, 178.4, -32.49999999999978, 84.8, 4.100000000000012, 45.50000000000001, -3.099999999999979, 20.000000000000014, 194.0, 20.000000000000014, 20.000000000000014, 164.89999999999992, 20.000000000000014, 64.99999999999997, 53.00000000000001, 140.9, 160.39999999999998, 194.6, 130.99999999999997, 133.39999999999998, 28.69999999999999, -12.699999999999996, 20.000000000000014, 34.39999999999996, 20.000000000000014, 163.1, 92.6, -28.599999999999987, 109.69999999999999, 161.0, 169.7, -89.20000000000083, 20.000000000000014, 20.000000000000014, 20.000000000000014, 192.79999999999995, 20.000000000000014, 170.3, 20.000000000000014, 46.99999999999997, 88.4, 20.000000000000014, 62.6, 99.19999999999999, 131.89999999999998, 20.000000000000014, 20.000000000000014, 138.5, 20.000000000000014, 9.499999999999964, -630.1, -2.499999999999986, 26.90000000000004, 20.000000000000014, -18.69999999999999, 20.000000000000014, 79.4, 93.79999999999998, 151.7, 124.1, 139.3999999999999, 77.29999999999998, 33.799999999999955, 19.400000000000006, 191.9, 20.000000000000014, -45.09999999999976, -34.59999999999975, 20.000000000000014, -30.40000000000002, 20.000000000000014, 87.5, 76.7, 20.000000000000014, 6.200000000000001, -89.79999999999998], "policy_predator_policy_reward": [0.0, 2.0, 50.0, 5.0, 3.0, 1.0, 3.0, 23.0, 0.0, 0.0, 8.0, 14.0, 8.0, 35.0, 9.0, 14.0, 13.0, 0.0, 33.0, 23.0, 0.0, 9.0, 27.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 18.0, 34.0, 29.0, 15.0, 1.0, 9.0, 28.0, 4.0, 4.0, 25.0, 20.0, 18.0, 33.0, 0.0, 0.0, 10.0, 10.0, 0.0, 2.0, 0.0, 7.0, 59.0, 27.0, 52.0, 1.0, 16.0, 2.0, 0.0, 2.0, 0.0, 0.0, 10.0, 7.0, 25.0, 20.0, 13.0, 14.0, 65.0, 55.0, 3.0, 17.0, 0.0, 0.0, 0.0, 0.0, 5.0, 25.0, 0.0, 49.0, 40.0, 25.0, 23.0, 16.0, 33.0, 71.0, 28.0, 0.0, 32.0, 26.0, 0.0, 19.0, 0.0, 32.0, 24.0, 0.0, 5.0, 0.0, 0.0, 0.0, 55.0, 34.0, 3.0, 6.0, 16.0, 2.0, 0.0, 0.0, 32.0, 0.0, 0.0, 10.0, 59.0, 23.0, 17.0, 15.0, 26.0, 8.0, 21.0, 26.0, 24.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.0, 0.0, 24.0, 32.0, 56.0, 31.0, 0.0, 11.0, 2.0, 0.0, 0.0, 0.0, 1.0, 2.0, 48.0, 0.0, 0.0, 0.0, 26.0, 0.0, 11.0, 77.0, 0.0, 9.0, 0.0, 0.0, 73.0, 0.0, 0.0, 23.0, 52.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 14.0, 13.0, 40.0, 20.0, 14.0, 0.0, 15.0, 4.0, 0.0, 5.0, 512.0, 60.0, 35.0, 2.0, 34.0, 38.0, 33.0, 19.0, 3.0, 18.0, 0.0, 17.0, 0.0, 68.0, 0.0, 0.0, 0.0, 31.0, 40.0, 16.0, 36.0, 0.0, 18.0, 18.0, 78.0, 64.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6819902784854304, "mean_inference_ms": 1.6491385011600426, "mean_action_processing_ms": 0.2695998889398255, "mean_env_wait_ms": 0.20147069769039924, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003917098045349121, "StateBufferConnector_ms": 0.0030933618545532227, "ViewRequirementAgentConnector_ms": 0.1083989143371582}, "num_episodes": 23, "episode_return_max": 366.69999999999993, "episode_return_min": -60.60000000000002, "episode_return_mean": 165.4889999999998, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 592000, "num_agent_steps_trained": 592000, "num_env_steps_sampled": 148000, "num_env_steps_trained": 148000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 76.27411756592089, "num_env_steps_trained_throughput_per_sec": 76.27411756592089, "timesteps_total": 148000, "num_env_steps_sampled_lifetime": 148000, "num_agent_steps_sampled_lifetime": 592000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 592000, "timers": {"training_iteration_time_ms": 52403.399, "restore_workers_time_ms": 0.013, "training_step_time_ms": 52403.358, "sample_time_ms": 1466.272, "learn_time_ms": 50920.229, "learn_throughput": 78.554, "synch_weights_time_ms": 13.134}, "counters": {"num_env_steps_sampled": 148000, "num_env_steps_trained": 148000, "num_agent_steps_sampled": 592000, "num_agent_steps_trained": 592000}, "done": false, "training_iteration": 37, "trial_id": "11e70_00000", "date": "2024-08-12_23-38-56", "timestamp": 1723520336, "time_this_iter_s": 52.49139404296875, "time_total_s": 1916.4318404197693, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2b62670>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1916.4318404197693, "iterations_since_restore": 37, "perf": {"cpu_util_percent": 37.645945945945954, "ram_util_percent": 83.10675675675677}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 9.207463085083734, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.4049227674171405, "policy_loss": -0.014225131173485091, "vf_loss": 4.416925214964246, "vf_explained_var": 0.14072679378998973, "kl": 0.014817965800606658, "entropy": 1.2746497642426264, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 70875.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 7.49965733005887, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.382019876550745, "policy_loss": -0.009063781467118552, "vf_loss": 6.390082606562862, "vf_explained_var": 0.1280458551866037, "kl": 0.006673605210516812, "entropy": 1.2263213978242622, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 70875.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 152000, "num_env_steps_trained": 152000, "num_agent_steps_sampled": 608000, "num_agent_steps_trained": 608000}, "env_runners": {"episode_reward_max": 366.69999999999993, "episode_reward_min": -60.60000000000002, "episode_reward_mean": 154.32599999999977, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -630.1, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 198.2, "predator_policy": 512.0}, "policy_reward_mean": {"prey_policy": 56.88799999999999, "predator_policy": 20.275}, "custom_metrics": {}, "hist_stats": {"episode_reward": [118.49999999999974, 110.19999999999983, 168.9999999999994, 40.0000000000003, 177.29999999999924, 199.79999999999922, 258.1999999999997, 75.9, 89.69999999999999, 180.39999999999927, 134.09999999999965, 40.0000000000003, 174.29999999999933, 298.00000000000006, 267.0999999999999, 190.59999999999994, 239.3999999999997, 40.0000000000003, 366.69999999999993, 126.39999999999966, 225.1999999999999, 185.10000000000002, 193.29999999999927, 107.40000000000003, 276.5, 90.79999999999978, 160.3999999999992, 326.09999999999997, 325.9, 188.39999999999932, 183.0999999999992, 206.09999999999994, 349.60000000000036, 153.39999999999932, 40.0000000000003, 139.7999999999992, 308.0, 88.69999999999997, 85.79999999999986, 136.69999999999948, 125.09999999999934, 163.89999999999947, 215.49999999999923, 40.0000000000003, 327.69999999999993, 108.29999999999967, 136.59999999999977, 27.90000000000012, 215.99999999999926, 184.89999999999932, 88.00000000000006, 241.9, 355.00000000000006, 290.3999999999999, 104.00000000000003, 63.40000000000021, 183.09999999999945, 136.99999999999994, 293.70000000000005, 140.49999999999957, 40.0000000000003, 212.79999999999924, 190.2999999999994, 67.00000000000024, 135.39999999999966, 221.79999999999998, 165.89999999999947, 177.49999999999932, 34.50000000000022, -60.60000000000002, 83.89999999999989, 73.2999999999997, 225.2, 296.8, 233.69999999999985, 121.19999999999996, 211.8999999999993, -48.70000000000085, 45.600000000000165, 143.49999999999926, 132.6999999999998, 58.39999999999999, 15.399999999999926, 90.59999999999974, 320.8000000000002, 86.1, 143.5999999999993, 167.2999999999993, 281.5000000000008, 132.9999999999996, 138.79999999999947, 71.29999999999993, 115.69999999999963, 22.000000000000092, 115.60000000000001, 49.20000000000023, 40.0000000000003, 94.9, 161.3999999999994, 114.49999999999997], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [5.299999999999993, 105.19999999999999, 20.000000000000014, 45.20000000000002, 98.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 156.19999999999993, 1.0999999999999617, 20.000000000000014, 177.79999999999993, 88.99999999999997, 162.19999999999996, -30.099999999999987, 20.000000000000014, 16.699999999999875, 20.000000000000014, 20.000000000000014, 142.39999999999998, 20.000000000000014, 112.1, 20.000000000000014, 20.000000000000014, 137.3, 20.000000000000014, 107.89999999999998, 145.1, 111.8, 128.29999999999995, 41.300000000000004, 29.300000000000004, 57.49999999999999, 161.89999999999995, 20.000000000000014, 20.000000000000014, 168.5, 198.2, 128.89999999999998, -32.49999999999975, 89.89999999999998, 86.30000000000001, 41.900000000000006, 78.2, -29.499999999999815, 183.79999999999998, 77.29999999999998, -73.9, 185.0, 63.5, 17.899999999999988, 14.900000000000006, 20.000000000000014, 121.39999999999988, 197.29999999999998, 96.80000000000001, 192.79999999999995, 109.1, 163.39999999999998, 20.000000000000014, 163.0999999999999, 20.000000000000014, 70.1, 47.000000000000014, 187.39999999999992, 153.19999999999996, 15.799999999999963, 119.59999999999991, 20.000000000000014, 20.000000000000014, 87.79999999999997, 20.000000000000014, 147.8, 150.19999999999996, -13.29999999999999, 20.000000000000014, 33.79999999999998, 20.000000000000014, 82.70000000000002, 20.000000000000014, 58.10000000000002, 20.000000000000014, 20.000000000000014, 119.89999999999998, 20.000000000000014, 195.49999999999997, 20.000000000000014, 20.000000000000014, 125.29999999999995, 178.4, -32.49999999999978, 84.8, 4.100000000000012, 45.50000000000001, -3.099999999999979, 20.000000000000014, 194.0, 20.000000000000014, 20.000000000000014, 164.89999999999992, 20.000000000000014, 64.99999999999997, 53.00000000000001, 140.9, 160.39999999999998, 194.6, 130.99999999999997, 133.39999999999998, 28.69999999999999, -12.699999999999996, 20.000000000000014, 34.39999999999996, 20.000000000000014, 163.1, 92.6, -28.599999999999987, 109.69999999999999, 161.0, 169.7, -89.20000000000083, 20.000000000000014, 20.000000000000014, 20.000000000000014, 192.79999999999995, 20.000000000000014, 170.3, 20.000000000000014, 46.99999999999997, 88.4, 20.000000000000014, 62.6, 99.19999999999999, 131.89999999999998, 20.000000000000014, 20.000000000000014, 138.5, 20.000000000000014, 9.499999999999964, -630.1, -2.499999999999986, 26.90000000000004, 20.000000000000014, -18.69999999999999, 20.000000000000014, 79.4, 93.79999999999998, 151.7, 124.1, 139.3999999999999, 77.29999999999998, 33.799999999999955, 19.400000000000006, 191.9, 20.000000000000014, -45.09999999999976, -34.59999999999975, 20.000000000000014, -30.40000000000002, 20.000000000000014, 87.5, 76.7, 20.000000000000014, 6.200000000000001, -89.79999999999998, -48.99999999999999, -13.600000000000072, -0.40000000000000346, 20.000000000000014, 121.1, 178.69999999999996, 14.900000000000006, -53.80000000000001, 130.39999999999984, -17.79999999999974, 131.29999999999998, 20.000000000000014, 125.59999999999975, 131.89999999999998, 74.0, 20.000000000000014, 20.000000000000014, 81.80000000000001, 20.000000000000014, -12.699999999999992, 73.70000000000006, 20.000000000000014, -45.099999999999774, -40.9, 107.9, -94.29999999999998, 20.000000000000014, 12.19999999999996, 20.000000000000014, 20.000000000000014, 28.400000000000006, -8.499999999999993, 146.89999999999992, 9.499999999999966, 51.20000000000001, -30.699999999999996], "policy_predator_policy_reward": [4.0, 4.0, 25.0, 20.0, 18.0, 33.0, 0.0, 0.0, 10.0, 10.0, 0.0, 2.0, 0.0, 7.0, 59.0, 27.0, 52.0, 1.0, 16.0, 2.0, 0.0, 2.0, 0.0, 0.0, 10.0, 7.0, 25.0, 20.0, 13.0, 14.0, 65.0, 55.0, 3.0, 17.0, 0.0, 0.0, 0.0, 0.0, 5.0, 25.0, 0.0, 49.0, 40.0, 25.0, 23.0, 16.0, 33.0, 71.0, 28.0, 0.0, 32.0, 26.0, 0.0, 19.0, 0.0, 32.0, 24.0, 0.0, 5.0, 0.0, 0.0, 0.0, 55.0, 34.0, 3.0, 6.0, 16.0, 2.0, 0.0, 0.0, 32.0, 0.0, 0.0, 10.0, 59.0, 23.0, 17.0, 15.0, 26.0, 8.0, 21.0, 26.0, 24.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.0, 0.0, 24.0, 32.0, 56.0, 31.0, 0.0, 11.0, 2.0, 0.0, 0.0, 0.0, 1.0, 2.0, 48.0, 0.0, 0.0, 0.0, 26.0, 0.0, 11.0, 77.0, 0.0, 9.0, 0.0, 0.0, 73.0, 0.0, 0.0, 23.0, 52.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 14.0, 13.0, 40.0, 20.0, 14.0, 0.0, 15.0, 4.0, 0.0, 5.0, 512.0, 60.0, 35.0, 2.0, 34.0, 38.0, 33.0, 19.0, 3.0, 18.0, 0.0, 17.0, 0.0, 68.0, 0.0, 0.0, 0.0, 31.0, 40.0, 16.0, 36.0, 0.0, 18.0, 18.0, 78.0, 64.0, 31.0, 47.0, 46.0, 25.0, 0.0, 21.0, 52.0, 73.0, 13.0, 18.0, 10.0, 6.0, 5.0, 19.0, 25.0, 14.0, 4.0, 33.0, 33.0, 31.0, 22.0, 0.0, 31.0, 77.0, 23.0, 79.0, 17.0, 0.0, 0.0, 0.0, 75.0, 0.0, 0.0, 5.0, 46.0, 48.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6833121831408981, "mean_inference_ms": 1.6491681470456752, "mean_action_processing_ms": 0.2701751252475044, "mean_env_wait_ms": 0.2018845878622947, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003914237022399902, "StateBufferConnector_ms": 0.0031752586364746094, "ViewRequirementAgentConnector_ms": 0.10603713989257812}, "num_episodes": 18, "episode_return_max": 366.69999999999993, "episode_return_min": -60.60000000000002, "episode_return_mean": 154.32599999999977, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 608000, "num_agent_steps_trained": 608000, "num_env_steps_sampled": 152000, "num_env_steps_trained": 152000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 76.16786079903147, "num_env_steps_trained_throughput_per_sec": 76.16786079903147, "timesteps_total": 152000, "num_env_steps_sampled_lifetime": 152000, "num_agent_steps_sampled_lifetime": 608000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 608000, "timers": {"training_iteration_time_ms": 52401.004, "restore_workers_time_ms": 0.013, "training_step_time_ms": 52400.963, "sample_time_ms": 1313.038, "learn_time_ms": 51070.781, "learn_throughput": 78.323, "synch_weights_time_ms": 13.579}, "counters": {"num_env_steps_sampled": 152000, "num_env_steps_trained": 152000, "num_agent_steps_sampled": 608000, "num_agent_steps_trained": 608000}, "done": false, "training_iteration": 38, "trial_id": "11e70_00000", "date": "2024-08-12_23-39-49", "timestamp": 1723520389, "time_this_iter_s": 52.52934288978577, "time_total_s": 1968.961183309555, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2b02430>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1968.961183309555, "iterations_since_restore": 38, "perf": {"cpu_util_percent": 37.54666666666667, "ram_util_percent": 82.39333333333335}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 8.859639986103804, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.356945865368717, "policy_loss": -0.015410746402654146, "vf_loss": 5.369634285931864, "vf_explained_var": 0.14046782457008564, "kl": 0.01814874883303197, "entropy": 1.2748223287718636, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 72765.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 6.973291199926346, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.773106209184758, "policy_loss": -0.009679492546748074, "vf_loss": 6.781195668568687, "vf_explained_var": -0.04565952880672677, "kl": 0.010600148667893716, "entropy": 1.2454613519724085, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 72765.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 156000, "num_env_steps_trained": 156000, "num_agent_steps_sampled": 624000, "num_agent_steps_trained": 624000}, "env_runners": {"episode_reward_max": 366.69999999999993, "episode_reward_min": -118.90000000000002, "episode_reward_mean": 143.1409999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -630.1, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 198.2, "predator_policy": 512.0}, "policy_reward_mean": {"prey_policy": 47.040499999999994, "predator_policy": 24.53}, "custom_metrics": {}, "hist_stats": {"episode_reward": [366.69999999999993, 126.39999999999966, 225.1999999999999, 185.10000000000002, 193.29999999999927, 107.40000000000003, 276.5, 90.79999999999978, 160.3999999999992, 326.09999999999997, 325.9, 188.39999999999932, 183.0999999999992, 206.09999999999994, 349.60000000000036, 153.39999999999932, 40.0000000000003, 139.7999999999992, 308.0, 88.69999999999997, 85.79999999999986, 136.69999999999948, 125.09999999999934, 163.89999999999947, 215.49999999999923, 40.0000000000003, 327.69999999999993, 108.29999999999967, 136.59999999999977, 27.90000000000012, 215.99999999999926, 184.89999999999932, 88.00000000000006, 241.9, 355.00000000000006, 290.3999999999999, 104.00000000000003, 63.40000000000021, 183.09999999999945, 136.99999999999994, 293.70000000000005, 140.49999999999957, 40.0000000000003, 212.79999999999924, 190.2999999999994, 67.00000000000024, 135.39999999999966, 221.79999999999998, 165.89999999999947, 177.49999999999932, 34.50000000000022, -60.60000000000002, 83.89999999999989, 73.2999999999997, 225.2, 296.8, 233.69999999999985, 121.19999999999996, 211.8999999999993, -48.70000000000085, 45.600000000000165, 143.49999999999926, 132.6999999999998, 58.39999999999999, 15.399999999999926, 90.59999999999974, 320.8000000000002, 86.1, 143.5999999999993, 167.2999999999993, 281.5000000000008, 132.9999999999996, 138.79999999999947, 71.29999999999993, 115.69999999999963, 22.000000000000092, 115.60000000000001, 49.20000000000023, 40.0000000000003, 94.9, 161.3999999999994, 114.49999999999997, -62.5, 104.99999999999991, -118.90000000000002, 8.100000000000025, 148.1999999999992, -16.799999999999883, 121.89999999999996, 15.500000000000021, 156.5, 188.29999999999936, 316.9, 157.60000000000002, 280.4000000000001, -5.80000000000004, 68.3, 148.79999999999998, 73.30000000000013, 99.19999999999999], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [168.5, 198.2, 128.89999999999998, -32.49999999999975, 89.89999999999998, 86.30000000000001, 41.900000000000006, 78.2, -29.499999999999815, 183.79999999999998, 77.29999999999998, -73.9, 185.0, 63.5, 17.899999999999988, 14.900000000000006, 20.000000000000014, 121.39999999999988, 197.29999999999998, 96.80000000000001, 192.79999999999995, 109.1, 163.39999999999998, 20.000000000000014, 163.0999999999999, 20.000000000000014, 70.1, 47.000000000000014, 187.39999999999992, 153.19999999999996, 15.799999999999963, 119.59999999999991, 20.000000000000014, 20.000000000000014, 87.79999999999997, 20.000000000000014, 147.8, 150.19999999999996, -13.29999999999999, 20.000000000000014, 33.79999999999998, 20.000000000000014, 82.70000000000002, 20.000000000000014, 58.10000000000002, 20.000000000000014, 20.000000000000014, 119.89999999999998, 20.000000000000014, 195.49999999999997, 20.000000000000014, 20.000000000000014, 125.29999999999995, 178.4, -32.49999999999978, 84.8, 4.100000000000012, 45.50000000000001, -3.099999999999979, 20.000000000000014, 194.0, 20.000000000000014, 20.000000000000014, 164.89999999999992, 20.000000000000014, 64.99999999999997, 53.00000000000001, 140.9, 160.39999999999998, 194.6, 130.99999999999997, 133.39999999999998, 28.69999999999999, -12.699999999999996, 20.000000000000014, 34.39999999999996, 20.000000000000014, 163.1, 92.6, -28.599999999999987, 109.69999999999999, 161.0, 169.7, -89.20000000000083, 20.000000000000014, 20.000000000000014, 20.000000000000014, 192.79999999999995, 20.000000000000014, 170.3, 20.000000000000014, 46.99999999999997, 88.4, 20.000000000000014, 62.6, 99.19999999999999, 131.89999999999998, 20.000000000000014, 20.000000000000014, 138.5, 20.000000000000014, 9.499999999999964, -630.1, -2.499999999999986, 26.90000000000004, 20.000000000000014, -18.69999999999999, 20.000000000000014, 79.4, 93.79999999999998, 151.7, 124.1, 139.3999999999999, 77.29999999999998, 33.799999999999955, 19.400000000000006, 191.9, 20.000000000000014, -45.09999999999976, -34.59999999999975, 20.000000000000014, -30.40000000000002, 20.000000000000014, 87.5, 76.7, 20.000000000000014, 6.200000000000001, -89.79999999999998, -48.99999999999999, -13.600000000000072, -0.40000000000000346, 20.000000000000014, 121.1, 178.69999999999996, 14.900000000000006, -53.80000000000001, 130.39999999999984, -17.79999999999974, 131.29999999999998, 20.000000000000014, 125.59999999999975, 131.89999999999998, 74.0, 20.000000000000014, 20.000000000000014, 81.80000000000001, 20.000000000000014, -12.699999999999992, 73.70000000000006, 20.000000000000014, -45.099999999999774, -40.9, 107.9, -94.29999999999998, 20.000000000000014, 12.19999999999996, 20.000000000000014, 20.000000000000014, 28.400000000000006, -8.499999999999993, 146.89999999999992, 9.499999999999966, 51.20000000000001, -30.699999999999996, -145.0, -65.5, 32.000000000000014, 14.0, -127.6, -133.3, -40.89999999999979, 20.000000000000014, 102.1999999999999, 20.000000000000014, 20.000000000000014, -182.8, -3.3999999999999932, 41.300000000000004, -95.20000000000002, -25.299999999999997, 77.29999999999998, 12.200000000000003, 27.499999999999993, 141.79999999999998, 137.0, 155.89999999999998, 59.89999999999999, 58.699999999999974, 113.0, 124.39999999999998, 20.000000000000014, -119.8, 20.000000000000014, -30.699999999999996, 46.4, 37.39999999999999, 41.0, -57.70000000000048, 46.099999999999994, -28.900000000000006], "policy_predator_policy_reward": [0.0, 0.0, 5.0, 25.0, 0.0, 49.0, 40.0, 25.0, 23.0, 16.0, 33.0, 71.0, 28.0, 0.0, 32.0, 26.0, 0.0, 19.0, 0.0, 32.0, 24.0, 0.0, 5.0, 0.0, 0.0, 0.0, 55.0, 34.0, 3.0, 6.0, 16.0, 2.0, 0.0, 0.0, 32.0, 0.0, 0.0, 10.0, 59.0, 23.0, 17.0, 15.0, 26.0, 8.0, 21.0, 26.0, 24.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.0, 0.0, 24.0, 32.0, 56.0, 31.0, 0.0, 11.0, 2.0, 0.0, 0.0, 0.0, 1.0, 2.0, 48.0, 0.0, 0.0, 0.0, 26.0, 0.0, 11.0, 77.0, 0.0, 9.0, 0.0, 0.0, 73.0, 0.0, 0.0, 23.0, 52.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 14.0, 13.0, 40.0, 20.0, 14.0, 0.0, 15.0, 4.0, 0.0, 5.0, 512.0, 60.0, 35.0, 2.0, 34.0, 38.0, 33.0, 19.0, 3.0, 18.0, 0.0, 17.0, 0.0, 68.0, 0.0, 0.0, 0.0, 31.0, 40.0, 16.0, 36.0, 0.0, 18.0, 18.0, 78.0, 64.0, 31.0, 47.0, 46.0, 25.0, 0.0, 21.0, 52.0, 73.0, 13.0, 18.0, 10.0, 6.0, 5.0, 19.0, 25.0, 14.0, 4.0, 33.0, 33.0, 31.0, 22.0, 0.0, 31.0, 77.0, 23.0, 79.0, 17.0, 0.0, 0.0, 0.0, 75.0, 0.0, 0.0, 5.0, 46.0, 48.0, 66.0, 82.0, 0.0, 59.0, 82.0, 60.0, 0.0, 29.0, 26.0, 0.0, 35.0, 111.0, 0.0, 84.0, 82.0, 54.0, 39.0, 28.0, 0.0, 19.0, 24.0, 0.0, 39.0, 0.0, 5.0, 38.0, 30.0, 64.0, 22.0, 57.0, 1.0, 64.0, 37.0, 53.0, 0.0, 82.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6848116739735967, "mean_inference_ms": 1.6495108167416646, "mean_action_processing_ms": 0.2708021287541957, "mean_env_wait_ms": 0.20228266639530795, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004189968109130859, "StateBufferConnector_ms": 0.0031834840774536133, "ViewRequirementAgentConnector_ms": 0.10563242435455322}, "num_episodes": 18, "episode_return_max": 366.69999999999993, "episode_return_min": -118.90000000000002, "episode_return_mean": 143.1409999999998, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 624000, "num_agent_steps_trained": 624000, "num_env_steps_sampled": 156000, "num_env_steps_trained": 156000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 74.28069643908628, "num_env_steps_trained_throughput_per_sec": 74.28069643908628, "timesteps_total": 156000, "num_env_steps_sampled_lifetime": 156000, "num_agent_steps_sampled_lifetime": 624000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 624000, "timers": {"training_iteration_time_ms": 52614.548, "restore_workers_time_ms": 0.013, "training_step_time_ms": 52614.508, "sample_time_ms": 1303.836, "learn_time_ms": 51293.452, "learn_throughput": 77.983, "synch_weights_time_ms": 13.725}, "counters": {"num_env_steps_sampled": 156000, "num_env_steps_trained": 156000, "num_agent_steps_sampled": 624000, "num_agent_steps_trained": 624000}, "done": false, "training_iteration": 39, "trial_id": "11e70_00000", "date": "2024-08-12_23-40-43", "timestamp": 1723520443, "time_this_iter_s": 53.8982207775116, "time_total_s": 2022.8594040870667, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3f39670>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2022.8594040870667, "iterations_since_restore": 39, "perf": {"cpu_util_percent": 41.664935064935065, "ram_util_percent": 82.69999999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 8.251548038651704, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.181452002348723, "policy_loss": -0.012688902779802601, "vf_loss": 6.1916977482498, "vf_explained_var": 0.13443278074264525, "kl": 0.016287652211041014, "entropy": 1.214928575419875, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 74655.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 6.117815164661912, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.29979270526341, "policy_loss": -0.010408175793333502, "vf_loss": 7.308812363690169, "vf_explained_var": -0.19078002007550032, "kl": 0.009256813137274684, "entropy": 1.236761036184099, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 74655.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 160000, "num_env_steps_trained": 160000, "num_agent_steps_sampled": 640000, "num_agent_steps_trained": 640000}, "env_runners": {"episode_reward_max": 355.00000000000006, "episode_reward_min": -168.1, "episode_reward_mean": 106.96399999999987, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -630.1, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 195.49999999999997, "predator_policy": 512.0}, "policy_reward_mean": {"prey_policy": 21.076999999999998, "predator_policy": 32.405}, "custom_metrics": {}, "hist_stats": {"episode_reward": [125.09999999999934, 163.89999999999947, 215.49999999999923, 40.0000000000003, 327.69999999999993, 108.29999999999967, 136.59999999999977, 27.90000000000012, 215.99999999999926, 184.89999999999932, 88.00000000000006, 241.9, 355.00000000000006, 290.3999999999999, 104.00000000000003, 63.40000000000021, 183.09999999999945, 136.99999999999994, 293.70000000000005, 140.49999999999957, 40.0000000000003, 212.79999999999924, 190.2999999999994, 67.00000000000024, 135.39999999999966, 221.79999999999998, 165.89999999999947, 177.49999999999932, 34.50000000000022, -60.60000000000002, 83.89999999999989, 73.2999999999997, 225.2, 296.8, 233.69999999999985, 121.19999999999996, 211.8999999999993, -48.70000000000085, 45.600000000000165, 143.49999999999926, 132.6999999999998, 58.39999999999999, 15.399999999999926, 90.59999999999974, 320.8000000000002, 86.1, 143.5999999999993, 167.2999999999993, 281.5000000000008, 132.9999999999996, 138.79999999999947, 71.29999999999993, 115.69999999999963, 22.000000000000092, 115.60000000000001, 49.20000000000023, 40.0000000000003, 94.9, 161.3999999999994, 114.49999999999997, -62.5, 104.99999999999991, -118.90000000000002, 8.100000000000025, 148.1999999999992, -16.799999999999883, 121.89999999999996, 15.500000000000021, 156.5, 188.29999999999936, 316.9, 157.60000000000002, 280.4000000000001, -5.80000000000004, 68.3, 148.79999999999998, 73.30000000000013, 99.19999999999999, -39.79999999999986, -119.79999999999993, 22.400000000000013, 91.69999999999999, 65.60000000000028, -20.69999999999999, 113.89999999999961, -38.39999999999982, 113.6, 40.0000000000003, 82.80000000000001, 126.69999999999993, -4.699999999999994, 169.09999999999994, 32.700000000000216, -8.199999999999898, 38.30000000000026, -96.5, -45.699999999999896, 180.79999999999995, 109.99999999999991, -168.1], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [58.10000000000002, 20.000000000000014, 20.000000000000014, 119.89999999999998, 20.000000000000014, 195.49999999999997, 20.000000000000014, 20.000000000000014, 125.29999999999995, 178.4, -32.49999999999978, 84.8, 4.100000000000012, 45.50000000000001, -3.099999999999979, 20.000000000000014, 194.0, 20.000000000000014, 20.000000000000014, 164.89999999999992, 20.000000000000014, 64.99999999999997, 53.00000000000001, 140.9, 160.39999999999998, 194.6, 130.99999999999997, 133.39999999999998, 28.69999999999999, -12.699999999999996, 20.000000000000014, 34.39999999999996, 20.000000000000014, 163.1, 92.6, -28.599999999999987, 109.69999999999999, 161.0, 169.7, -89.20000000000083, 20.000000000000014, 20.000000000000014, 20.000000000000014, 192.79999999999995, 20.000000000000014, 170.3, 20.000000000000014, 46.99999999999997, 88.4, 20.000000000000014, 62.6, 99.19999999999999, 131.89999999999998, 20.000000000000014, 20.000000000000014, 138.5, 20.000000000000014, 9.499999999999964, -630.1, -2.499999999999986, 26.90000000000004, 20.000000000000014, -18.69999999999999, 20.000000000000014, 79.4, 93.79999999999998, 151.7, 124.1, 139.3999999999999, 77.29999999999998, 33.799999999999955, 19.400000000000006, 191.9, 20.000000000000014, -45.09999999999976, -34.59999999999975, 20.000000000000014, -30.40000000000002, 20.000000000000014, 87.5, 76.7, 20.000000000000014, 6.200000000000001, -89.79999999999998, -48.99999999999999, -13.600000000000072, -0.40000000000000346, 20.000000000000014, 121.1, 178.69999999999996, 14.900000000000006, -53.80000000000001, 130.39999999999984, -17.79999999999974, 131.29999999999998, 20.000000000000014, 125.59999999999975, 131.89999999999998, 74.0, 20.000000000000014, 20.000000000000014, 81.80000000000001, 20.000000000000014, -12.699999999999992, 73.70000000000006, 20.000000000000014, -45.099999999999774, -40.9, 107.9, -94.29999999999998, 20.000000000000014, 12.19999999999996, 20.000000000000014, 20.000000000000014, 28.400000000000006, -8.499999999999993, 146.89999999999992, 9.499999999999966, 51.20000000000001, -30.699999999999996, -145.0, -65.5, 32.000000000000014, 14.0, -127.6, -133.3, -40.89999999999979, 20.000000000000014, 102.1999999999999, 20.000000000000014, 20.000000000000014, -182.8, -3.3999999999999932, 41.300000000000004, -95.20000000000002, -25.299999999999997, 77.29999999999998, 12.200000000000003, 27.499999999999993, 141.79999999999998, 137.0, 155.89999999999998, 59.89999999999999, 58.699999999999974, 113.0, 124.39999999999998, 20.000000000000014, -119.8, 20.000000000000014, -30.699999999999996, 46.4, 37.39999999999999, 41.0, -57.70000000000048, 46.099999999999994, -28.900000000000006, 20.000000000000014, -224.8, -97.30000000000001, -200.5, -13.599999999999783, 20.000000000000014, -57.39999999999999, 34.099999999999994, 20.000000000000014, -24.39999999999999, -147.7, -19.00000000000002, 44.90000000000001, 20.000000000000014, 20.000000000000014, -219.4, 17.3, 26.300000000000004, 20.000000000000014, 20.000000000000014, 15.500000000000005, -33.7, 55.99999999999997, -1.2999999999999972, -156.70000000000002, 20.000000000000014, 10.099999999999994, 94.99999999999997, 20.000000000000014, -91.29999999999998, 20.000000000000014, -182.20000000000005, 20.000000000000014, -108.69999999999999, -133.9, -112.60000000000002, -67.00000000000001, -72.70000000000002, 45.500000000000014, 74.30000000000001, 21.800000000000008, 18.199999999999967, -212.2, -190.9], "policy_predator_policy_reward": [21.0, 26.0, 24.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.0, 0.0, 24.0, 32.0, 56.0, 31.0, 0.0, 11.0, 2.0, 0.0, 0.0, 0.0, 1.0, 2.0, 48.0, 0.0, 0.0, 0.0, 26.0, 0.0, 11.0, 77.0, 0.0, 9.0, 0.0, 0.0, 73.0, 0.0, 0.0, 23.0, 52.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 14.0, 13.0, 40.0, 20.0, 14.0, 0.0, 15.0, 4.0, 0.0, 5.0, 512.0, 60.0, 35.0, 2.0, 34.0, 38.0, 33.0, 19.0, 3.0, 18.0, 0.0, 17.0, 0.0, 68.0, 0.0, 0.0, 0.0, 31.0, 40.0, 16.0, 36.0, 0.0, 18.0, 18.0, 78.0, 64.0, 31.0, 47.0, 46.0, 25.0, 0.0, 21.0, 52.0, 73.0, 13.0, 18.0, 10.0, 6.0, 5.0, 19.0, 25.0, 14.0, 4.0, 33.0, 33.0, 31.0, 22.0, 0.0, 31.0, 77.0, 23.0, 79.0, 17.0, 0.0, 0.0, 0.0, 75.0, 0.0, 0.0, 5.0, 46.0, 48.0, 66.0, 82.0, 0.0, 59.0, 82.0, 60.0, 0.0, 29.0, 26.0, 0.0, 35.0, 111.0, 0.0, 84.0, 82.0, 54.0, 39.0, 28.0, 0.0, 19.0, 24.0, 0.0, 39.0, 0.0, 5.0, 38.0, 30.0, 64.0, 22.0, 57.0, 1.0, 64.0, 37.0, 53.0, 0.0, 82.0, 128.0, 37.0, 71.0, 107.0, 16.0, 0.0, 60.0, 55.0, 0.0, 70.0, 47.0, 99.0, 44.0, 5.0, 78.0, 83.0, 0.0, 70.0, 0.0, 0.0, 59.0, 42.0, 0.0, 72.0, 43.0, 89.0, 0.0, 64.0, 57.0, 47.0, 110.0, 44.0, 56.0, 71.0, 115.0, 35.0, 94.0, 0.0, 61.0, 0.0, 70.0, 0.0, 125.0, 110.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.685480529087541, "mean_inference_ms": 1.6482794571094979, "mean_action_processing_ms": 0.2717324174274112, "mean_env_wait_ms": 0.2024952689584406, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004236817359924316, "StateBufferConnector_ms": 0.0034323930740356445, "ViewRequirementAgentConnector_ms": 0.1059105396270752}, "num_episodes": 22, "episode_return_max": 355.00000000000006, "episode_return_min": -168.1, "episode_return_mean": 106.96399999999987, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 640000, "num_agent_steps_trained": 640000, "num_env_steps_sampled": 160000, "num_env_steps_trained": 160000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 76.56852799819717, "num_env_steps_trained_throughput_per_sec": 76.56852799819717, "timesteps_total": 160000, "num_env_steps_sampled_lifetime": 160000, "num_agent_steps_sampled_lifetime": 640000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 640000, "timers": {"training_iteration_time_ms": 52615.067, "restore_workers_time_ms": 0.013, "training_step_time_ms": 52615.029, "sample_time_ms": 1295.53, "learn_time_ms": 51302.787, "learn_throughput": 77.968, "synch_weights_time_ms": 13.552}, "counters": {"num_env_steps_sampled": 160000, "num_env_steps_trained": 160000, "num_agent_steps_sampled": 640000, "num_agent_steps_trained": 640000}, "done": false, "training_iteration": 40, "trial_id": "11e70_00000", "date": "2024-08-12_23-41-35", "timestamp": 1723520495, "time_this_iter_s": 52.31073594093323, "time_total_s": 2075.170140028, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2b96c10>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2075.170140028, "iterations_since_restore": 40, "perf": {"cpu_util_percent": 37.63108108108108, "ram_util_percent": 82.32702702702701}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 6.460059175541792, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.862739525396357, "policy_loss": -0.012947134183788742, "vf_loss": 6.873616665885562, "vf_explained_var": 0.13736886328490322, "kl": 0.01380003797494475, "entropy": 1.2040842572217265, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 76545.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.7562019079135207, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.173964383110167, "policy_loss": -0.009174337483223074, "vf_loss": 6.181640173140027, "vf_explained_var": -0.5120317175905541, "kl": 0.009990350452474477, "entropy": 1.1708014019582638, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 76545.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 164000, "num_env_steps_trained": 164000, "num_agent_steps_sampled": 656000, "num_agent_steps_trained": 656000}, "env_runners": {"episode_reward_max": 320.8000000000002, "episode_reward_min": -378.19999999999993, "episode_reward_mean": 55.596999999999944, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -630.1, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 191.9, "predator_policy": 512.0}, "policy_reward_mean": {"prey_policy": -18.026500000000002, "predator_policy": 45.825}, "custom_metrics": {}, "hist_stats": {"episode_reward": [67.00000000000024, 135.39999999999966, 221.79999999999998, 165.89999999999947, 177.49999999999932, 34.50000000000022, -60.60000000000002, 83.89999999999989, 73.2999999999997, 225.2, 296.8, 233.69999999999985, 121.19999999999996, 211.8999999999993, -48.70000000000085, 45.600000000000165, 143.49999999999926, 132.6999999999998, 58.39999999999999, 15.399999999999926, 90.59999999999974, 320.8000000000002, 86.1, 143.5999999999993, 167.2999999999993, 281.5000000000008, 132.9999999999996, 138.79999999999947, 71.29999999999993, 115.69999999999963, 22.000000000000092, 115.60000000000001, 49.20000000000023, 40.0000000000003, 94.9, 161.3999999999994, 114.49999999999997, -62.5, 104.99999999999991, -118.90000000000002, 8.100000000000025, 148.1999999999992, -16.799999999999883, 121.89999999999996, 15.500000000000021, 156.5, 188.29999999999936, 316.9, 157.60000000000002, 280.4000000000001, -5.80000000000004, 68.3, 148.79999999999998, 73.30000000000013, 99.19999999999999, -39.79999999999986, -119.79999999999993, 22.400000000000013, 91.69999999999999, 65.60000000000028, -20.69999999999999, 113.89999999999961, -38.39999999999982, 113.6, 40.0000000000003, 82.80000000000001, 126.69999999999993, -4.699999999999994, 169.09999999999994, 32.700000000000216, -8.199999999999898, 38.30000000000026, -96.5, -45.699999999999896, 180.79999999999995, 109.99999999999991, -168.1, -117.70000000000002, 18.200000000000173, -116.00000000000003, -93.80000000000014, -378.19999999999993, 40.0000000000003, -252.10000000000002, 40.0000000000003, -97.89999999999993, 61.30000000000018, -40.299999999999876, -130.8, -107.20000000000002, 48.600000000000115, 42.10000000000028, -20.99999999999995, 45.50000000000018, -1.1999999999998403, -56.99999999999984, 7.200000000000001, 152.59999999999928, -186.6, -106.40000000000015], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 46.99999999999997, 88.4, 20.000000000000014, 62.6, 99.19999999999999, 131.89999999999998, 20.000000000000014, 20.000000000000014, 138.5, 20.000000000000014, 9.499999999999964, -630.1, -2.499999999999986, 26.90000000000004, 20.000000000000014, -18.69999999999999, 20.000000000000014, 79.4, 93.79999999999998, 151.7, 124.1, 139.3999999999999, 77.29999999999998, 33.799999999999955, 19.400000000000006, 191.9, 20.000000000000014, -45.09999999999976, -34.59999999999975, 20.000000000000014, -30.40000000000002, 20.000000000000014, 87.5, 76.7, 20.000000000000014, 6.200000000000001, -89.79999999999998, -48.99999999999999, -13.600000000000072, -0.40000000000000346, 20.000000000000014, 121.1, 178.69999999999996, 14.900000000000006, -53.80000000000001, 130.39999999999984, -17.79999999999974, 131.29999999999998, 20.000000000000014, 125.59999999999975, 131.89999999999998, 74.0, 20.000000000000014, 20.000000000000014, 81.80000000000001, 20.000000000000014, -12.699999999999992, 73.70000000000006, 20.000000000000014, -45.099999999999774, -40.9, 107.9, -94.29999999999998, 20.000000000000014, 12.19999999999996, 20.000000000000014, 20.000000000000014, 28.400000000000006, -8.499999999999993, 146.89999999999992, 9.499999999999966, 51.20000000000001, -30.699999999999996, -145.0, -65.5, 32.000000000000014, 14.0, -127.6, -133.3, -40.89999999999979, 20.000000000000014, 102.1999999999999, 20.000000000000014, 20.000000000000014, -182.8, -3.3999999999999932, 41.300000000000004, -95.20000000000002, -25.299999999999997, 77.29999999999998, 12.200000000000003, 27.499999999999993, 141.79999999999998, 137.0, 155.89999999999998, 59.89999999999999, 58.699999999999974, 113.0, 124.39999999999998, 20.000000000000014, -119.8, 20.000000000000014, -30.699999999999996, 46.4, 37.39999999999999, 41.0, -57.70000000000048, 46.099999999999994, -28.900000000000006, 20.000000000000014, -224.8, -97.30000000000001, -200.5, -13.599999999999783, 20.000000000000014, -57.39999999999999, 34.099999999999994, 20.000000000000014, -24.39999999999999, -147.7, -19.00000000000002, 44.90000000000001, 20.000000000000014, 20.000000000000014, -219.4, 17.3, 26.300000000000004, 20.000000000000014, 20.000000000000014, 15.500000000000005, -33.7, 55.99999999999997, -1.2999999999999972, -156.70000000000002, 20.000000000000014, 10.099999999999994, 94.99999999999997, 20.000000000000014, -91.29999999999998, 20.000000000000014, -182.20000000000005, 20.000000000000014, -108.69999999999999, -133.9, -112.60000000000002, -67.00000000000001, -72.70000000000002, 45.500000000000014, 74.30000000000001, 21.800000000000008, 18.199999999999967, -212.2, -190.9, -161.20000000000002, -179.5, 20.000000000000014, -101.80000000000001, -87.4, -172.60000000000002, -320.8, 20.000000000000014, -355.9, -229.30000000000004, 20.000000000000014, 20.000000000000014, -217.9, -269.2, 20.000000000000014, 20.000000000000014, -148.00000000000003, -67.9, 20.000000000000014, 23.299999999999983, 20.000000000000014, -229.3, -137.8, -163.0, -52.599999999999994, -190.60000000000002, 20.000000000000014, -141.4, -149.80000000000004, 17.899999999999988, 20.000000000000014, -301.00000000000006, -59.49999999999999, 20.000000000000014, 20.000000000000014, -128.2, -211.0, 20.000000000000014, 20.000000000000014, -155.8, 101.59999999999997, 20.000000000000014, -160.29999999999998, -259.3, -312.70000000000005, 5.299999999999965], "policy_predator_policy_reward": [0.0, 0.0, 14.0, 13.0, 40.0, 20.0, 14.0, 0.0, 15.0, 4.0, 0.0, 5.0, 512.0, 60.0, 35.0, 2.0, 34.0, 38.0, 33.0, 19.0, 3.0, 18.0, 0.0, 17.0, 0.0, 68.0, 0.0, 0.0, 0.0, 31.0, 40.0, 16.0, 36.0, 0.0, 18.0, 18.0, 78.0, 64.0, 31.0, 47.0, 46.0, 25.0, 0.0, 21.0, 52.0, 73.0, 13.0, 18.0, 10.0, 6.0, 5.0, 19.0, 25.0, 14.0, 4.0, 33.0, 33.0, 31.0, 22.0, 0.0, 31.0, 77.0, 23.0, 79.0, 17.0, 0.0, 0.0, 0.0, 75.0, 0.0, 0.0, 5.0, 46.0, 48.0, 66.0, 82.0, 0.0, 59.0, 82.0, 60.0, 0.0, 29.0, 26.0, 0.0, 35.0, 111.0, 0.0, 84.0, 82.0, 54.0, 39.0, 28.0, 0.0, 19.0, 24.0, 0.0, 39.0, 0.0, 5.0, 38.0, 30.0, 64.0, 22.0, 57.0, 1.0, 64.0, 37.0, 53.0, 0.0, 82.0, 128.0, 37.0, 71.0, 107.0, 16.0, 0.0, 60.0, 55.0, 0.0, 70.0, 47.0, 99.0, 44.0, 5.0, 78.0, 83.0, 0.0, 70.0, 0.0, 0.0, 59.0, 42.0, 0.0, 72.0, 43.0, 89.0, 0.0, 64.0, 57.0, 47.0, 110.0, 44.0, 56.0, 71.0, 115.0, 35.0, 94.0, 0.0, 61.0, 0.0, 70.0, 0.0, 125.0, 110.0, 114.0, 109.0, 100.0, 0.0, 144.0, 0.0, 156.0, 51.0, 186.0, 21.0, 0.0, 0.0, 159.0, 76.0, 0.0, 0.0, 112.0, 6.0, 13.0, 5.0, 106.0, 63.0, 122.0, 48.0, 136.0, 0.0, 92.0, 78.0, 61.0, 113.0, 153.0, 107.0, 0.0, 85.0, 0.0, 107.0, 134.0, 0.0, 47.0, 96.0, 31.0, 0.0, 163.0, 70.0, 136.0, 65.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6856844353536442, "mean_inference_ms": 1.6422898103145764, "mean_action_processing_ms": 0.271095244049914, "mean_env_wait_ms": 0.202015546758647, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004186391830444336, "StateBufferConnector_ms": 0.0034012794494628906, "ViewRequirementAgentConnector_ms": 0.10513007640838623}, "num_episodes": 23, "episode_return_max": 320.8000000000002, "episode_return_min": -378.19999999999993, "episode_return_mean": 55.596999999999944, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 656000, "num_agent_steps_trained": 656000, "num_env_steps_sampled": 164000, "num_env_steps_trained": 164000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 73.61588064139637, "num_env_steps_trained_throughput_per_sec": 73.61588064139637, "timesteps_total": 164000, "num_env_steps_sampled_lifetime": 164000, "num_agent_steps_sampled_lifetime": 656000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 656000, "timers": {"training_iteration_time_ms": 52669.046, "restore_workers_time_ms": 0.013, "training_step_time_ms": 52669.008, "sample_time_ms": 1294.448, "learn_time_ms": 51358.025, "learn_throughput": 77.885, "synch_weights_time_ms": 13.364}, "counters": {"num_env_steps_sampled": 164000, "num_env_steps_trained": 164000, "num_agent_steps_sampled": 656000, "num_agent_steps_trained": 656000}, "done": false, "training_iteration": 41, "trial_id": "11e70_00000", "date": "2024-08-12_23-42-29", "timestamp": 1723520549, "time_this_iter_s": 54.37961721420288, "time_total_s": 2129.5497572422028, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2b02430>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2129.5497572422028, "iterations_since_restore": 41, "perf": {"cpu_util_percent": 44.65194805194805, "ram_util_percent": 82.43766233766232}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 9.378468221583695, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.977188215558491, "policy_loss": -0.009568164218709898, "vf_loss": 5.9849906853267125, "vf_explained_var": 0.19362296865730688, "kl": 0.0117711688100275, "entropy": 1.1796513463454272, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 78435.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.56280682563151, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.429723696986203, "policy_loss": -0.009249987833635518, "vf_loss": 6.437511049502741, "vf_explained_var": -0.46157817216146557, "kl": 0.009750947196749052, "entropy": 1.1589646604956774, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 78435.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 168000, "num_env_steps_trained": 168000, "num_agent_steps_sampled": 672000, "num_agent_steps_trained": 672000}, "env_runners": {"episode_reward_max": 320.8000000000002, "episode_reward_min": -378.19999999999993, "episode_reward_mean": 19.695999999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -356.4999999999999, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 178.69999999999996, "predator_policy": 186.0}, "policy_reward_mean": {"prey_policy": -42.172, "predator_policy": 52.02}, "custom_metrics": {}, "hist_stats": {"episode_reward": [58.39999999999999, 15.399999999999926, 90.59999999999974, 320.8000000000002, 86.1, 143.5999999999993, 167.2999999999993, 281.5000000000008, 132.9999999999996, 138.79999999999947, 71.29999999999993, 115.69999999999963, 22.000000000000092, 115.60000000000001, 49.20000000000023, 40.0000000000003, 94.9, 161.3999999999994, 114.49999999999997, -62.5, 104.99999999999991, -118.90000000000002, 8.100000000000025, 148.1999999999992, -16.799999999999883, 121.89999999999996, 15.500000000000021, 156.5, 188.29999999999936, 316.9, 157.60000000000002, 280.4000000000001, -5.80000000000004, 68.3, 148.79999999999998, 73.30000000000013, 99.19999999999999, -39.79999999999986, -119.79999999999993, 22.400000000000013, 91.69999999999999, 65.60000000000028, -20.69999999999999, 113.89999999999961, -38.39999999999982, 113.6, 40.0000000000003, 82.80000000000001, 126.69999999999993, -4.699999999999994, 169.09999999999994, 32.700000000000216, -8.199999999999898, 38.30000000000026, -96.5, -45.699999999999896, 180.79999999999995, 109.99999999999991, -168.1, -117.70000000000002, 18.200000000000173, -116.00000000000003, -93.80000000000014, -378.19999999999993, 40.0000000000003, -252.10000000000002, 40.0000000000003, -97.89999999999993, 61.30000000000018, -40.299999999999876, -130.8, -107.20000000000002, 48.600000000000115, 42.10000000000028, -20.99999999999995, 45.50000000000018, -1.1999999999998403, -56.99999999999984, 7.200000000000001, 152.59999999999928, -186.6, -106.40000000000015, 3.1000000000000485, -51.79999999999978, -367.29999999999995, 40.0000000000003, -326.5999999999998, -27.999999999999908, -39.50000000000003, 60.5, -88.00000000000006, -203.99999999999997, -87.70000000000002, -100.50000000000045, -27.20000000000003, -86.70000000000002, -19.99999999999987, -71.89999999999996, 26.100000000000016, 40.0000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [6.200000000000001, -89.79999999999998, -48.99999999999999, -13.600000000000072, -0.40000000000000346, 20.000000000000014, 121.1, 178.69999999999996, 14.900000000000006, -53.80000000000001, 130.39999999999984, -17.79999999999974, 131.29999999999998, 20.000000000000014, 125.59999999999975, 131.89999999999998, 74.0, 20.000000000000014, 20.000000000000014, 81.80000000000001, 20.000000000000014, -12.699999999999992, 73.70000000000006, 20.000000000000014, -45.099999999999774, -40.9, 107.9, -94.29999999999998, 20.000000000000014, 12.19999999999996, 20.000000000000014, 20.000000000000014, 28.400000000000006, -8.499999999999993, 146.89999999999992, 9.499999999999966, 51.20000000000001, -30.699999999999996, -145.0, -65.5, 32.000000000000014, 14.0, -127.6, -133.3, -40.89999999999979, 20.000000000000014, 102.1999999999999, 20.000000000000014, 20.000000000000014, -182.8, -3.3999999999999932, 41.300000000000004, -95.20000000000002, -25.299999999999997, 77.29999999999998, 12.200000000000003, 27.499999999999993, 141.79999999999998, 137.0, 155.89999999999998, 59.89999999999999, 58.699999999999974, 113.0, 124.39999999999998, 20.000000000000014, -119.8, 20.000000000000014, -30.699999999999996, 46.4, 37.39999999999999, 41.0, -57.70000000000048, 46.099999999999994, -28.900000000000006, 20.000000000000014, -224.8, -97.30000000000001, -200.5, -13.599999999999783, 20.000000000000014, -57.39999999999999, 34.099999999999994, 20.000000000000014, -24.39999999999999, -147.7, -19.00000000000002, 44.90000000000001, 20.000000000000014, 20.000000000000014, -219.4, 17.3, 26.300000000000004, 20.000000000000014, 20.000000000000014, 15.500000000000005, -33.7, 55.99999999999997, -1.2999999999999972, -156.70000000000002, 20.000000000000014, 10.099999999999994, 94.99999999999997, 20.000000000000014, -91.29999999999998, 20.000000000000014, -182.20000000000005, 20.000000000000014, -108.69999999999999, -133.9, -112.60000000000002, -67.00000000000001, -72.70000000000002, 45.500000000000014, 74.30000000000001, 21.800000000000008, 18.199999999999967, -212.2, -190.9, -161.20000000000002, -179.5, 20.000000000000014, -101.80000000000001, -87.4, -172.60000000000002, -320.8, 20.000000000000014, -355.9, -229.30000000000004, 20.000000000000014, 20.000000000000014, -217.9, -269.2, 20.000000000000014, 20.000000000000014, -148.00000000000003, -67.9, 20.000000000000014, 23.299999999999983, 20.000000000000014, -229.3, -137.8, -163.0, -52.599999999999994, -190.60000000000002, 20.000000000000014, -141.4, -149.80000000000004, 17.899999999999988, 20.000000000000014, -301.00000000000006, -59.49999999999999, 20.000000000000014, 20.000000000000014, -128.2, -211.0, 20.000000000000014, 20.000000000000014, -155.8, 101.59999999999997, 20.000000000000014, -160.29999999999998, -259.3, -312.70000000000005, 5.299999999999965, -115.89999999999999, 20.000000000000014, -281.8, 20.000000000000014, -273.7, -328.59999999999997, 20.000000000000014, 20.000000000000014, -258.3999999999998, -239.2, 20.000000000000014, -175.0, -25.0, -137.5, -72.1, 44.599999999999994, 11.599999999999971, -301.6, -190.60000000000002, -168.39999999999992, -79.6, -135.1, 20.000000000000014, -356.4999999999999, -73.3, -61.900000000000034, 20.000000000000014, -273.70000000000005, -28.300000000000033, -90.70000000000002, 9.5, -225.4, -64.89999999999999, 20.000000000000014, 20.000000000000014, 20.000000000000014], "policy_predator_policy_reward": [78.0, 64.0, 31.0, 47.0, 46.0, 25.0, 0.0, 21.0, 52.0, 73.0, 13.0, 18.0, 10.0, 6.0, 5.0, 19.0, 25.0, 14.0, 4.0, 33.0, 33.0, 31.0, 22.0, 0.0, 31.0, 77.0, 23.0, 79.0, 17.0, 0.0, 0.0, 0.0, 75.0, 0.0, 0.0, 5.0, 46.0, 48.0, 66.0, 82.0, 0.0, 59.0, 82.0, 60.0, 0.0, 29.0, 26.0, 0.0, 35.0, 111.0, 0.0, 84.0, 82.0, 54.0, 39.0, 28.0, 0.0, 19.0, 24.0, 0.0, 39.0, 0.0, 5.0, 38.0, 30.0, 64.0, 22.0, 57.0, 1.0, 64.0, 37.0, 53.0, 0.0, 82.0, 128.0, 37.0, 71.0, 107.0, 16.0, 0.0, 60.0, 55.0, 0.0, 70.0, 47.0, 99.0, 44.0, 5.0, 78.0, 83.0, 0.0, 70.0, 0.0, 0.0, 59.0, 42.0, 0.0, 72.0, 43.0, 89.0, 0.0, 64.0, 57.0, 47.0, 110.0, 44.0, 56.0, 71.0, 115.0, 35.0, 94.0, 0.0, 61.0, 0.0, 70.0, 0.0, 125.0, 110.0, 114.0, 109.0, 100.0, 0.0, 144.0, 0.0, 156.0, 51.0, 186.0, 21.0, 0.0, 0.0, 159.0, 76.0, 0.0, 0.0, 112.0, 6.0, 13.0, 5.0, 106.0, 63.0, 122.0, 48.0, 136.0, 0.0, 92.0, 78.0, 61.0, 113.0, 153.0, 107.0, 0.0, 85.0, 0.0, 107.0, 134.0, 0.0, 47.0, 96.0, 31.0, 0.0, 163.0, 70.0, 136.0, 65.0, 99.0, 0.0, 68.0, 142.0, 179.0, 56.0, 0.0, 0.0, 165.0, 6.0, 118.0, 9.0, 115.0, 8.0, 0.0, 88.0, 74.0, 128.0, 142.0, 13.0, 125.0, 2.0, 159.0, 77.0, 31.0, 77.0, 157.0, 10.0, 99.0, 0.0, 117.0, 27.0, 35.0, 36.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6842966655808854, "mean_inference_ms": 1.638767619751065, "mean_action_processing_ms": 0.27074583417646275, "mean_env_wait_ms": 0.20198929983309152, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004025578498840332, "StateBufferConnector_ms": 0.0033675432205200195, "ViewRequirementAgentConnector_ms": 0.099587082862854}, "num_episodes": 18, "episode_return_max": 320.8000000000002, "episode_return_min": -378.19999999999993, "episode_return_mean": 19.695999999999998, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 672000, "num_agent_steps_trained": 672000, "num_env_steps_sampled": 168000, "num_env_steps_trained": 168000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 72.6457287920579, "num_env_steps_trained_throughput_per_sec": 72.6457287920579, "timesteps_total": 168000, "num_env_steps_sampled_lifetime": 168000, "num_agent_steps_sampled_lifetime": 672000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 672000, "timers": {"training_iteration_time_ms": 52988.005, "restore_workers_time_ms": 0.013, "training_step_time_ms": 52987.962, "sample_time_ms": 1297.026, "learn_time_ms": 51674.43, "learn_throughput": 77.408, "synch_weights_time_ms": 13.383}, "counters": {"num_env_steps_sampled": 168000, "num_env_steps_trained": 168000, "num_agent_steps_sampled": 672000, "num_agent_steps_trained": 672000}, "done": false, "training_iteration": 42, "trial_id": "11e70_00000", "date": "2024-08-12_23-43-24", "timestamp": 1723520604, "time_this_iter_s": 55.112717151641846, "time_total_s": 2184.6624743938446, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2b96f70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2184.6624743938446, "iterations_since_restore": 42, "perf": {"cpu_util_percent": 44.96455696202532, "ram_util_percent": 83.25822784810126}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 9.735271527653648, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.098658259709676, "policy_loss": -0.008610479372785126, "vf_loss": 5.10572733021287, "vf_explained_var": 0.2381180346958221, "kl": 0.010276129991209956, "entropy": 1.2085553477680873, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 80325.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.69691064143307, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.785844864416375, "policy_loss": -0.01201926131274492, "vf_loss": 5.796253587581493, "vf_explained_var": -0.18979853139352545, "kl": 0.010736822818371183, "entropy": 1.0384645779296835, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 80325.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 172000, "num_env_steps_trained": 172000, "num_agent_steps_sampled": 688000, "num_agent_steps_trained": 688000}, "env_runners": {"episode_reward_max": 373.9000000000001, "episode_reward_min": -378.19999999999993, "episode_reward_mean": -12.373999999999993, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -356.4999999999999, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 197.29999999999998, "predator_policy": 186.0}, "policy_reward_mean": {"prey_policy": -67.28200000000001, "predator_policy": 61.095}, "custom_metrics": {}, "hist_stats": {"episode_reward": [114.49999999999997, -62.5, 104.99999999999991, -118.90000000000002, 8.100000000000025, 148.1999999999992, -16.799999999999883, 121.89999999999996, 15.500000000000021, 156.5, 188.29999999999936, 316.9, 157.60000000000002, 280.4000000000001, -5.80000000000004, 68.3, 148.79999999999998, 73.30000000000013, 99.19999999999999, -39.79999999999986, -119.79999999999993, 22.400000000000013, 91.69999999999999, 65.60000000000028, -20.69999999999999, 113.89999999999961, -38.39999999999982, 113.6, 40.0000000000003, 82.80000000000001, 126.69999999999993, -4.699999999999994, 169.09999999999994, 32.700000000000216, -8.199999999999898, 38.30000000000026, -96.5, -45.699999999999896, 180.79999999999995, 109.99999999999991, -168.1, -117.70000000000002, 18.200000000000173, -116.00000000000003, -93.80000000000014, -378.19999999999993, 40.0000000000003, -252.10000000000002, 40.0000000000003, -97.89999999999993, 61.30000000000018, -40.299999999999876, -130.8, -107.20000000000002, 48.600000000000115, 42.10000000000028, -20.99999999999995, 45.50000000000018, -1.1999999999998403, -56.99999999999984, 7.200000000000001, 152.59999999999928, -186.6, -106.40000000000015, 3.1000000000000485, -51.79999999999978, -367.29999999999995, 40.0000000000003, -326.5999999999998, -27.999999999999908, -39.50000000000003, 60.5, -88.00000000000006, -203.99999999999997, -87.70000000000002, -100.50000000000045, -27.20000000000003, -86.70000000000002, -19.99999999999987, -71.89999999999996, 26.100000000000016, 40.0000000000003, 12.800000000000022, 33.400000000000205, -369.5999999999998, 213.69999999999922, -57.99999999999987, -120.90000000000029, -63.99999999999986, -250.10000000000002, -82.8000000000001, -270.1, 71.5000000000002, 373.9000000000001, -112.80000000000041, -141.69999999999996, -18.499999999999964, -100.10000000000039, -258.1, 40.0000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [51.20000000000001, -30.699999999999996, -145.0, -65.5, 32.000000000000014, 14.0, -127.6, -133.3, -40.89999999999979, 20.000000000000014, 102.1999999999999, 20.000000000000014, 20.000000000000014, -182.8, -3.3999999999999932, 41.300000000000004, -95.20000000000002, -25.299999999999997, 77.29999999999998, 12.200000000000003, 27.499999999999993, 141.79999999999998, 137.0, 155.89999999999998, 59.89999999999999, 58.699999999999974, 113.0, 124.39999999999998, 20.000000000000014, -119.8, 20.000000000000014, -30.699999999999996, 46.4, 37.39999999999999, 41.0, -57.70000000000048, 46.099999999999994, -28.900000000000006, 20.000000000000014, -224.8, -97.30000000000001, -200.5, -13.599999999999783, 20.000000000000014, -57.39999999999999, 34.099999999999994, 20.000000000000014, -24.39999999999999, -147.7, -19.00000000000002, 44.90000000000001, 20.000000000000014, 20.000000000000014, -219.4, 17.3, 26.300000000000004, 20.000000000000014, 20.000000000000014, 15.500000000000005, -33.7, 55.99999999999997, -1.2999999999999972, -156.70000000000002, 20.000000000000014, 10.099999999999994, 94.99999999999997, 20.000000000000014, -91.29999999999998, 20.000000000000014, -182.20000000000005, 20.000000000000014, -108.69999999999999, -133.9, -112.60000000000002, -67.00000000000001, -72.70000000000002, 45.500000000000014, 74.30000000000001, 21.800000000000008, 18.199999999999967, -212.2, -190.9, -161.20000000000002, -179.5, 20.000000000000014, -101.80000000000001, -87.4, -172.60000000000002, -320.8, 20.000000000000014, -355.9, -229.30000000000004, 20.000000000000014, 20.000000000000014, -217.9, -269.2, 20.000000000000014, 20.000000000000014, -148.00000000000003, -67.9, 20.000000000000014, 23.299999999999983, 20.000000000000014, -229.3, -137.8, -163.0, -52.599999999999994, -190.60000000000002, 20.000000000000014, -141.4, -149.80000000000004, 17.899999999999988, 20.000000000000014, -301.00000000000006, -59.49999999999999, 20.000000000000014, 20.000000000000014, -128.2, -211.0, 20.000000000000014, 20.000000000000014, -155.8, 101.59999999999997, 20.000000000000014, -160.29999999999998, -259.3, -312.70000000000005, 5.299999999999965, -115.89999999999999, 20.000000000000014, -281.8, 20.000000000000014, -273.7, -328.59999999999997, 20.000000000000014, 20.000000000000014, -258.3999999999998, -239.2, 20.000000000000014, -175.0, -25.0, -137.5, -72.1, 44.599999999999994, 11.599999999999971, -301.6, -190.60000000000002, -168.39999999999992, -79.6, -135.1, 20.000000000000014, -356.4999999999999, -73.3, -61.900000000000034, 20.000000000000014, -273.70000000000005, -28.300000000000033, -90.70000000000002, 9.5, -225.4, -64.89999999999999, 20.000000000000014, 20.000000000000014, 20.000000000000014, 51.499999999999964, -255.70000000000002, 20.000000000000014, 7.399999999999965, -330.4, -302.1999999999999, 193.7, 20.000000000000014, -289.0, 20.000000000000014, 20.000000000000014, -310.9, 20.000000000000014, -217.00000000000003, -276.4, -228.70000000000002, 20.000000000000014, -353.79999999999995, -258.4, -312.7, 20.000000000000014, 51.499999999999964, 197.29999999999998, 176.6, 20.000000000000014, -338.8, -97.0, -234.7, -332.5, 20.000000000000014, -276.1, 20.000000000000014, -176.5, -220.6, 20.000000000000014, 20.000000000000014], "policy_predator_policy_reward": [46.0, 48.0, 66.0, 82.0, 0.0, 59.0, 82.0, 60.0, 0.0, 29.0, 26.0, 0.0, 35.0, 111.0, 0.0, 84.0, 82.0, 54.0, 39.0, 28.0, 0.0, 19.0, 24.0, 0.0, 39.0, 0.0, 5.0, 38.0, 30.0, 64.0, 22.0, 57.0, 1.0, 64.0, 37.0, 53.0, 0.0, 82.0, 128.0, 37.0, 71.0, 107.0, 16.0, 0.0, 60.0, 55.0, 0.0, 70.0, 47.0, 99.0, 44.0, 5.0, 78.0, 83.0, 0.0, 70.0, 0.0, 0.0, 59.0, 42.0, 0.0, 72.0, 43.0, 89.0, 0.0, 64.0, 57.0, 47.0, 110.0, 44.0, 56.0, 71.0, 115.0, 35.0, 94.0, 0.0, 61.0, 0.0, 70.0, 0.0, 125.0, 110.0, 114.0, 109.0, 100.0, 0.0, 144.0, 0.0, 156.0, 51.0, 186.0, 21.0, 0.0, 0.0, 159.0, 76.0, 0.0, 0.0, 112.0, 6.0, 13.0, 5.0, 106.0, 63.0, 122.0, 48.0, 136.0, 0.0, 92.0, 78.0, 61.0, 113.0, 153.0, 107.0, 0.0, 85.0, 0.0, 107.0, 134.0, 0.0, 47.0, 96.0, 31.0, 0.0, 163.0, 70.0, 136.0, 65.0, 99.0, 0.0, 68.0, 142.0, 179.0, 56.0, 0.0, 0.0, 165.0, 6.0, 118.0, 9.0, 115.0, 8.0, 0.0, 88.0, 74.0, 128.0, 142.0, 13.0, 125.0, 2.0, 159.0, 77.0, 31.0, 77.0, 157.0, 10.0, 99.0, 0.0, 117.0, 27.0, 35.0, 36.0, 0.0, 0.0, 85.0, 132.0, 6.0, 0.0, 98.0, 165.0, 0.0, 0.0, 72.0, 139.0, 0.0, 170.0, 133.0, 0.0, 145.0, 110.0, 149.0, 102.0, 162.0, 139.0, 0.0, 0.0, 0.0, 0.0, 27.0, 179.0, 90.0, 100.0, 158.0, 136.0, 0.0, 156.0, 0.0, 139.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6834972416771639, "mean_inference_ms": 1.6348706069993375, "mean_action_processing_ms": 0.2705091769083042, "mean_env_wait_ms": 0.20180983507047542, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003957390785217285, "StateBufferConnector_ms": 0.0033490657806396484, "ViewRequirementAgentConnector_ms": 0.09837353229522705}, "num_episodes": 18, "episode_return_max": 373.9000000000001, "episode_return_min": -378.19999999999993, "episode_return_mean": -12.373999999999993, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 688000, "num_agent_steps_trained": 688000, "num_env_steps_sampled": 172000, "num_env_steps_trained": 172000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 73.9075520100906, "num_env_steps_trained_throughput_per_sec": 73.9075520100906, "timesteps_total": 172000, "num_env_steps_sampled_lifetime": 172000, "num_agent_steps_sampled_lifetime": 688000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 688000, "timers": {"training_iteration_time_ms": 53168.689, "restore_workers_time_ms": 0.013, "training_step_time_ms": 53168.645, "sample_time_ms": 1300.641, "learn_time_ms": 51851.871, "learn_throughput": 77.143, "synch_weights_time_ms": 13.054}, "counters": {"num_env_steps_sampled": 172000, "num_env_steps_trained": 172000, "num_agent_steps_sampled": 688000, "num_agent_steps_trained": 688000}, "done": false, "training_iteration": 43, "trial_id": "11e70_00000", "date": "2024-08-12_23-44-19", "timestamp": 1723520659, "time_this_iter_s": 54.16507911682129, "time_total_s": 2238.827553510666, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3f39790>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2238.827553510666, "iterations_since_restore": 43, "perf": {"cpu_util_percent": 42.65974025974026, "ram_util_percent": 81.80649350649348}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 8.762666103764186, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.539968499683199, "policy_loss": -0.009876198033314375, "vf_loss": 6.548466431148468, "vf_explained_var": 0.23495733924012965, "kl": 0.009188411340953514, "entropy": 1.1917796172162212, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 82215.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.843507262575564, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.1616873168440724, "policy_loss": -0.011403820317524372, "vf_loss": 6.171809498973625, "vf_explained_var": -0.24248961777914138, "kl": 0.008544313620731128, "entropy": 1.0972866067179927, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 82215.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 176000, "num_env_steps_trained": 176000, "num_agent_steps_sampled": 704000, "num_agent_steps_trained": 704000}, "env_runners": {"episode_reward_max": 373.9000000000001, "episode_reward_min": -421.5999999999997, "episode_reward_mean": -42.358999999999966, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -374.79999999999995, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 197.29999999999998, "predator_policy": 192.0}, "policy_reward_mean": {"prey_policy": -87.01449999999998, "predator_policy": 65.835}, "custom_metrics": {}, "hist_stats": {"episode_reward": [99.19999999999999, -39.79999999999986, -119.79999999999993, 22.400000000000013, 91.69999999999999, 65.60000000000028, -20.69999999999999, 113.89999999999961, -38.39999999999982, 113.6, 40.0000000000003, 82.80000000000001, 126.69999999999993, -4.699999999999994, 169.09999999999994, 32.700000000000216, -8.199999999999898, 38.30000000000026, -96.5, -45.699999999999896, 180.79999999999995, 109.99999999999991, -168.1, -117.70000000000002, 18.200000000000173, -116.00000000000003, -93.80000000000014, -378.19999999999993, 40.0000000000003, -252.10000000000002, 40.0000000000003, -97.89999999999993, 61.30000000000018, -40.299999999999876, -130.8, -107.20000000000002, 48.600000000000115, 42.10000000000028, -20.99999999999995, 45.50000000000018, -1.1999999999998403, -56.99999999999984, 7.200000000000001, 152.59999999999928, -186.6, -106.40000000000015, 3.1000000000000485, -51.79999999999978, -367.29999999999995, 40.0000000000003, -326.5999999999998, -27.999999999999908, -39.50000000000003, 60.5, -88.00000000000006, -203.99999999999997, -87.70000000000002, -100.50000000000045, -27.20000000000003, -86.70000000000002, -19.99999999999987, -71.89999999999996, 26.100000000000016, 40.0000000000003, 12.800000000000022, 33.400000000000205, -369.5999999999998, 213.69999999999922, -57.99999999999987, -120.90000000000029, -63.99999999999986, -250.10000000000002, -82.8000000000001, -270.1, 71.5000000000002, 373.9000000000001, -112.80000000000041, -141.69999999999996, -18.499999999999964, -100.10000000000039, -258.1, 40.0000000000003, 40.0000000000003, -297.4000000000001, 29.000000000000014, -25.699999999999992, 40.0000000000003, -328.4999999999999, -113.40000000000023, -358.79999999999995, 14.69999999999993, -421.5999999999997, -7.999999999999913, 40.0000000000003, 363.10000000000014, -22.299999999999834, 36.70000000000025, 108.99999999999926, -231.1000000000001, -164.9000000000006], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [46.099999999999994, -28.900000000000006, 20.000000000000014, -224.8, -97.30000000000001, -200.5, -13.599999999999783, 20.000000000000014, -57.39999999999999, 34.099999999999994, 20.000000000000014, -24.39999999999999, -147.7, -19.00000000000002, 44.90000000000001, 20.000000000000014, 20.000000000000014, -219.4, 17.3, 26.300000000000004, 20.000000000000014, 20.000000000000014, 15.500000000000005, -33.7, 55.99999999999997, -1.2999999999999972, -156.70000000000002, 20.000000000000014, 10.099999999999994, 94.99999999999997, 20.000000000000014, -91.29999999999998, 20.000000000000014, -182.20000000000005, 20.000000000000014, -108.69999999999999, -133.9, -112.60000000000002, -67.00000000000001, -72.70000000000002, 45.500000000000014, 74.30000000000001, 21.800000000000008, 18.199999999999967, -212.2, -190.9, -161.20000000000002, -179.5, 20.000000000000014, -101.80000000000001, -87.4, -172.60000000000002, -320.8, 20.000000000000014, -355.9, -229.30000000000004, 20.000000000000014, 20.000000000000014, -217.9, -269.2, 20.000000000000014, 20.000000000000014, -148.00000000000003, -67.9, 20.000000000000014, 23.299999999999983, 20.000000000000014, -229.3, -137.8, -163.0, -52.599999999999994, -190.60000000000002, 20.000000000000014, -141.4, -149.80000000000004, 17.899999999999988, 20.000000000000014, -301.00000000000006, -59.49999999999999, 20.000000000000014, 20.000000000000014, -128.2, -211.0, 20.000000000000014, 20.000000000000014, -155.8, 101.59999999999997, 20.000000000000014, -160.29999999999998, -259.3, -312.70000000000005, 5.299999999999965, -115.89999999999999, 20.000000000000014, -281.8, 20.000000000000014, -273.7, -328.59999999999997, 20.000000000000014, 20.000000000000014, -258.3999999999998, -239.2, 20.000000000000014, -175.0, -25.0, -137.5, -72.1, 44.599999999999994, 11.599999999999971, -301.6, -190.60000000000002, -168.39999999999992, -79.6, -135.1, 20.000000000000014, -356.4999999999999, -73.3, -61.900000000000034, 20.000000000000014, -273.70000000000005, -28.300000000000033, -90.70000000000002, 9.5, -225.4, -64.89999999999999, 20.000000000000014, 20.000000000000014, 20.000000000000014, 51.499999999999964, -255.70000000000002, 20.000000000000014, 7.399999999999965, -330.4, -302.1999999999999, 193.7, 20.000000000000014, -289.0, 20.000000000000014, 20.000000000000014, -310.9, 20.000000000000014, -217.00000000000003, -276.4, -228.70000000000002, 20.000000000000014, -353.79999999999995, -258.4, -312.7, 20.000000000000014, 51.499999999999964, 197.29999999999998, 176.6, 20.000000000000014, -338.8, -97.0, -234.7, -332.5, 20.000000000000014, -276.1, 20.000000000000014, -176.5, -220.6, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -286.0, -258.4000000000001, -287.8, 105.79999999999998, -201.70000000000005, 20.000000000000014, 20.000000000000014, 20.000000000000014, -310.0, -266.5, -297.40000000000003, 20.000000000000014, -295.0, -356.79999999999995, 20.000000000000014, -28.299999999999777, -319.5999999999998, -292.0, -259.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 181.99999999999994, 181.1, -160.3, 20.000000000000014, 13.699999999999964, 20.000000000000014, 20.0, 20.000000000000014, -269.20000000000005, -148.90000000000006, -374.79999999999995, 17.899999999999988], "policy_predator_policy_reward": [0.0, 82.0, 128.0, 37.0, 71.0, 107.0, 16.0, 0.0, 60.0, 55.0, 0.0, 70.0, 47.0, 99.0, 44.0, 5.0, 78.0, 83.0, 0.0, 70.0, 0.0, 0.0, 59.0, 42.0, 0.0, 72.0, 43.0, 89.0, 0.0, 64.0, 57.0, 47.0, 110.0, 44.0, 56.0, 71.0, 115.0, 35.0, 94.0, 0.0, 61.0, 0.0, 70.0, 0.0, 125.0, 110.0, 114.0, 109.0, 100.0, 0.0, 144.0, 0.0, 156.0, 51.0, 186.0, 21.0, 0.0, 0.0, 159.0, 76.0, 0.0, 0.0, 112.0, 6.0, 13.0, 5.0, 106.0, 63.0, 122.0, 48.0, 136.0, 0.0, 92.0, 78.0, 61.0, 113.0, 153.0, 107.0, 0.0, 85.0, 0.0, 107.0, 134.0, 0.0, 47.0, 96.0, 31.0, 0.0, 163.0, 70.0, 136.0, 65.0, 99.0, 0.0, 68.0, 142.0, 179.0, 56.0, 0.0, 0.0, 165.0, 6.0, 118.0, 9.0, 115.0, 8.0, 0.0, 88.0, 74.0, 128.0, 142.0, 13.0, 125.0, 2.0, 159.0, 77.0, 31.0, 77.0, 157.0, 10.0, 99.0, 0.0, 117.0, 27.0, 35.0, 36.0, 0.0, 0.0, 85.0, 132.0, 6.0, 0.0, 98.0, 165.0, 0.0, 0.0, 72.0, 139.0, 0.0, 170.0, 133.0, 0.0, 145.0, 110.0, 149.0, 102.0, 162.0, 139.0, 0.0, 0.0, 0.0, 0.0, 27.0, 179.0, 90.0, 100.0, 158.0, 136.0, 0.0, 156.0, 0.0, 139.0, 0.0, 0.0, 0.0, 0.0, 132.0, 115.0, 76.0, 135.0, 49.0, 107.0, 0.0, 0.0, 122.0, 126.0, 2.0, 162.0, 126.0, 167.0, 23.0, 0.0, 0.0, 190.0, 126.0, 105.0, 0.0, 0.0, 0.0, 0.0, 118.0, 0.0, 0.0, 3.0, 19.0, 50.0, 62.0, 125.0, 192.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6830145187171308, "mean_inference_ms": 1.632298007551459, "mean_action_processing_ms": 0.2703587069258766, "mean_env_wait_ms": 0.2017553092153696, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0037131309509277344, "StateBufferConnector_ms": 0.003304600715637207, "ViewRequirementAgentConnector_ms": 0.10476052761077881}, "num_episodes": 18, "episode_return_max": 373.9000000000001, "episode_return_min": -421.5999999999997, "episode_return_mean": -42.358999999999966, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 704000, "num_agent_steps_trained": 704000, "num_env_steps_sampled": 176000, "num_env_steps_trained": 176000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 74.59602826904526, "num_env_steps_trained_throughput_per_sec": 74.59602826904526, "timesteps_total": 176000, "num_env_steps_sampled_lifetime": 176000, "num_agent_steps_sampled_lifetime": 704000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 704000, "timers": {"training_iteration_time_ms": 53357.806, "restore_workers_time_ms": 0.013, "training_step_time_ms": 53357.763, "sample_time_ms": 1320.89, "learn_time_ms": 52020.347, "learn_throughput": 76.893, "synch_weights_time_ms": 12.989}, "counters": {"num_env_steps_sampled": 176000, "num_env_steps_trained": 176000, "num_agent_steps_sampled": 704000, "num_agent_steps_trained": 704000}, "done": false, "training_iteration": 44, "trial_id": "11e70_00000", "date": "2024-08-12_23-45-12", "timestamp": 1723520712, "time_this_iter_s": 53.67284297943115, "time_total_s": 2292.500396490097, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2b679d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2292.500396490097, "iterations_since_restore": 44, "perf": {"cpu_util_percent": 40.51578947368421, "ram_util_percent": 80.80657894736842}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 11.303916132576251, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.974137092771985, "policy_loss": -0.007129070200839095, "vf_loss": 5.9801234727183346, "vf_explained_var": 0.23460298108045385, "kl": 0.0076179408079359015, "entropy": 1.1400776231730425, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 84105.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.3520363704237357, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.683982930486164, "policy_loss": -0.013359672771569676, "vf_loss": 5.696045590203906, "vf_explained_var": -0.21038513808023362, "kl": 0.008646738830487105, "entropy": 1.0837614596836151, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 84105.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 180000, "num_env_steps_trained": 180000, "num_agent_steps_sampled": 720000, "num_agent_steps_trained": 720000}, "env_runners": {"episode_reward_max": 373.9000000000001, "episode_reward_min": -421.5999999999997, "episode_reward_mean": -63.104999999999976, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -374.79999999999995, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 197.29999999999998, "predator_policy": 192.0}, "policy_reward_mean": {"prey_policy": -107.5525, "predator_policy": 76.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-168.1, -117.70000000000002, 18.200000000000173, -116.00000000000003, -93.80000000000014, -378.19999999999993, 40.0000000000003, -252.10000000000002, 40.0000000000003, -97.89999999999993, 61.30000000000018, -40.299999999999876, -130.8, -107.20000000000002, 48.600000000000115, 42.10000000000028, -20.99999999999995, 45.50000000000018, -1.1999999999998403, -56.99999999999984, 7.200000000000001, 152.59999999999928, -186.6, -106.40000000000015, 3.1000000000000485, -51.79999999999978, -367.29999999999995, 40.0000000000003, -326.5999999999998, -27.999999999999908, -39.50000000000003, 60.5, -88.00000000000006, -203.99999999999997, -87.70000000000002, -100.50000000000045, -27.20000000000003, -86.70000000000002, -19.99999999999987, -71.89999999999996, 26.100000000000016, 40.0000000000003, 12.800000000000022, 33.400000000000205, -369.5999999999998, 213.69999999999922, -57.99999999999987, -120.90000000000029, -63.99999999999986, -250.10000000000002, -82.8000000000001, -270.1, 71.5000000000002, 373.9000000000001, -112.80000000000041, -141.69999999999996, -18.499999999999964, -100.10000000000039, -258.1, 40.0000000000003, 40.0000000000003, -297.4000000000001, 29.000000000000014, -25.699999999999992, 40.0000000000003, -328.4999999999999, -113.40000000000023, -358.79999999999995, 14.69999999999993, -421.5999999999997, -7.999999999999913, 40.0000000000003, 363.10000000000014, -22.299999999999834, 36.70000000000025, 108.99999999999926, -231.1000000000001, -164.9000000000006, -57.399999999999835, 16.899999999999945, 0.499999999999976, -28.099999999999902, 161.39999999999998, -118.10000000000022, 140.39999999999995, -41.69999999999983, 150.29999999999959, -378.5, 276.0, -306.2, -40.7999999999998, -128.90000000000038, -20.70000000000003, 40.0000000000003, -281.1999999999996, -27.399999999999814, -96.40000000000018, -92.4, 33.400000000000205, -362.7], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-212.2, -190.9, -161.20000000000002, -179.5, 20.000000000000014, -101.80000000000001, -87.4, -172.60000000000002, -320.8, 20.000000000000014, -355.9, -229.30000000000004, 20.000000000000014, 20.000000000000014, -217.9, -269.2, 20.000000000000014, 20.000000000000014, -148.00000000000003, -67.9, 20.000000000000014, 23.299999999999983, 20.000000000000014, -229.3, -137.8, -163.0, -52.599999999999994, -190.60000000000002, 20.000000000000014, -141.4, -149.80000000000004, 17.899999999999988, 20.000000000000014, -301.00000000000006, -59.49999999999999, 20.000000000000014, 20.000000000000014, -128.2, -211.0, 20.000000000000014, 20.000000000000014, -155.8, 101.59999999999997, 20.000000000000014, -160.29999999999998, -259.3, -312.70000000000005, 5.299999999999965, -115.89999999999999, 20.000000000000014, -281.8, 20.000000000000014, -273.7, -328.59999999999997, 20.000000000000014, 20.000000000000014, -258.3999999999998, -239.2, 20.000000000000014, -175.0, -25.0, -137.5, -72.1, 44.599999999999994, 11.599999999999971, -301.6, -190.60000000000002, -168.39999999999992, -79.6, -135.1, 20.000000000000014, -356.4999999999999, -73.3, -61.900000000000034, 20.000000000000014, -273.70000000000005, -28.300000000000033, -90.70000000000002, 9.5, -225.4, -64.89999999999999, 20.000000000000014, 20.000000000000014, 20.000000000000014, 51.499999999999964, -255.70000000000002, 20.000000000000014, 7.399999999999965, -330.4, -302.1999999999999, 193.7, 20.000000000000014, -289.0, 20.000000000000014, 20.000000000000014, -310.9, 20.000000000000014, -217.00000000000003, -276.4, -228.70000000000002, 20.000000000000014, -353.79999999999995, -258.4, -312.7, 20.000000000000014, 51.499999999999964, 197.29999999999998, 176.6, 20.000000000000014, -338.8, -97.0, -234.7, -332.5, 20.000000000000014, -276.1, 20.000000000000014, -176.5, -220.6, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -286.0, -258.4000000000001, -287.8, 105.79999999999998, -201.70000000000005, 20.000000000000014, 20.000000000000014, 20.000000000000014, -310.0, -266.5, -297.40000000000003, 20.000000000000014, -295.0, -356.79999999999995, 20.000000000000014, -28.299999999999777, -319.5999999999998, -292.0, -259.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 181.99999999999994, 181.1, -160.3, 20.000000000000014, 13.699999999999964, 20.000000000000014, 20.0, 20.000000000000014, -269.20000000000005, -148.90000000000006, -374.79999999999995, 17.899999999999988, -213.40000000000003, 20.000000000000014, -1.0000000000000133, -3.099999999999958, -302.5, 20.000000000000014, -243.10000000000002, 20.000000000000014, 186.2, -266.8, 20.000000000000014, -303.1, -255.4, 165.79999999999995, 20.000000000000014, -351.69999999999993, 20.000000000000014, 128.3, -327.69999999999993, -344.8, 152.89999999999998, 97.10000000000005, -340.6, -334.6, -259.9, 1.0999999999999528, 20.000000000000014, -313.9, -369.7, 20.000000000000014, 20.000000000000014, 20.000000000000014, -293.7999999999996, -291.4, 20.000000000000014, -321.3999999999999, 20.000000000000014, -345.4, 20.000000000000014, -270.40000000000003, 20.000000000000014, 7.399999999999965, -323.8, -316.9], "policy_predator_policy_reward": [125.0, 110.0, 114.0, 109.0, 100.0, 0.0, 144.0, 0.0, 156.0, 51.0, 186.0, 21.0, 0.0, 0.0, 159.0, 76.0, 0.0, 0.0, 112.0, 6.0, 13.0, 5.0, 106.0, 63.0, 122.0, 48.0, 136.0, 0.0, 92.0, 78.0, 61.0, 113.0, 153.0, 107.0, 0.0, 85.0, 0.0, 107.0, 134.0, 0.0, 47.0, 96.0, 31.0, 0.0, 163.0, 70.0, 136.0, 65.0, 99.0, 0.0, 68.0, 142.0, 179.0, 56.0, 0.0, 0.0, 165.0, 6.0, 118.0, 9.0, 115.0, 8.0, 0.0, 88.0, 74.0, 128.0, 142.0, 13.0, 125.0, 2.0, 159.0, 77.0, 31.0, 77.0, 157.0, 10.0, 99.0, 0.0, 117.0, 27.0, 35.0, 36.0, 0.0, 0.0, 85.0, 132.0, 6.0, 0.0, 98.0, 165.0, 0.0, 0.0, 72.0, 139.0, 0.0, 170.0, 133.0, 0.0, 145.0, 110.0, 149.0, 102.0, 162.0, 139.0, 0.0, 0.0, 0.0, 0.0, 27.0, 179.0, 90.0, 100.0, 158.0, 136.0, 0.0, 156.0, 0.0, 139.0, 0.0, 0.0, 0.0, 0.0, 132.0, 115.0, 76.0, 135.0, 49.0, 107.0, 0.0, 0.0, 122.0, 126.0, 2.0, 162.0, 126.0, 167.0, 23.0, 0.0, 0.0, 190.0, 126.0, 105.0, 0.0, 0.0, 0.0, 0.0, 118.0, 0.0, 0.0, 3.0, 19.0, 50.0, 62.0, 125.0, 192.0, 0.0, 136.0, 0.0, 0.0, 21.0, 131.0, 152.0, 107.0, 88.0, 90.0, 152.0, 0.0, 165.0, 82.0, 148.0, 136.0, 154.0, 2.0, 0.0, 126.0, 168.0, 0.0, 26.0, 191.0, 178.0, 72.0, 146.0, 31.0, 134.0, 177.0, 152.0, 0.0, 0.0, 141.0, 163.0, 163.0, 111.0, 171.0, 58.0, 155.0, 3.0, 0.0, 6.0, 152.0, 126.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6849065966206852, "mean_inference_ms": 1.6323842218558355, "mean_action_processing_ms": 0.27060663003412083, "mean_env_wait_ms": 0.202047060366397, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003975391387939453, "StateBufferConnector_ms": 0.0032929182052612305, "ViewRequirementAgentConnector_ms": 0.13716983795166016}, "num_episodes": 22, "episode_return_max": 373.9000000000001, "episode_return_min": -421.5999999999997, "episode_return_mean": -63.104999999999976, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 720000, "num_agent_steps_trained": 720000, "num_env_steps_sampled": 180000, "num_env_steps_trained": 180000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 71.98739289009622, "num_env_steps_trained_throughput_per_sec": 71.98739289009622, "timesteps_total": 180000, "num_env_steps_sampled_lifetime": 180000, "num_agent_steps_sampled_lifetime": 720000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 720000, "timers": {"training_iteration_time_ms": 53702.947, "restore_workers_time_ms": 0.013, "training_step_time_ms": 53702.903, "sample_time_ms": 1363.23, "learn_time_ms": 52320.853, "learn_throughput": 76.451, "synch_weights_time_ms": 14.994}, "counters": {"num_env_steps_sampled": 180000, "num_env_steps_trained": 180000, "num_agent_steps_sampled": 720000, "num_agent_steps_trained": 720000}, "done": false, "training_iteration": 45, "trial_id": "11e70_00000", "date": "2024-08-12_23-46-08", "timestamp": 1723520768, "time_this_iter_s": 55.6485698223114, "time_total_s": 2348.1489663124084, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2b931f0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2348.1489663124084, "iterations_since_restore": 45, "perf": {"cpu_util_percent": 46.42658227848101, "ram_util_percent": 82.87088607594937}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 8.22610214179155, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.041091209492356, "policy_loss": -0.010350800015860133, "vf_loss": 6.050101250189322, "vf_explained_var": 0.28913160972494295, "kl": 0.008938381879833398, "entropy": 1.129245100765632, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 85995.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.3661834304925624, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.256693452502054, "policy_loss": -0.012415460193229139, "vf_loss": 6.267157454970022, "vf_explained_var": -0.16994443406503668, "kl": 0.013009684609301391, "entropy": 1.0413025864217647, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 85995.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 184000, "num_env_steps_trained": 184000, "num_agent_steps_sampled": 736000, "num_agent_steps_trained": 736000}, "env_runners": {"episode_reward_max": 373.9000000000001, "episode_reward_min": -421.5999999999997, "episode_reward_mean": -59.73300000000003, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -394.9, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 199.1, "predator_policy": 198.0}, "policy_reward_mean": {"prey_policy": -107.41149999999998, "predator_policy": 77.545}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-106.40000000000015, 3.1000000000000485, -51.79999999999978, -367.29999999999995, 40.0000000000003, -326.5999999999998, -27.999999999999908, -39.50000000000003, 60.5, -88.00000000000006, -203.99999999999997, -87.70000000000002, -100.50000000000045, -27.20000000000003, -86.70000000000002, -19.99999999999987, -71.89999999999996, 26.100000000000016, 40.0000000000003, 12.800000000000022, 33.400000000000205, -369.5999999999998, 213.69999999999922, -57.99999999999987, -120.90000000000029, -63.99999999999986, -250.10000000000002, -82.8000000000001, -270.1, 71.5000000000002, 373.9000000000001, -112.80000000000041, -141.69999999999996, -18.499999999999964, -100.10000000000039, -258.1, 40.0000000000003, 40.0000000000003, -297.4000000000001, 29.000000000000014, -25.699999999999992, 40.0000000000003, -328.4999999999999, -113.40000000000023, -358.79999999999995, 14.69999999999993, -421.5999999999997, -7.999999999999913, 40.0000000000003, 363.10000000000014, -22.299999999999834, 36.70000000000025, 108.99999999999926, -231.1000000000001, -164.9000000000006, -57.399999999999835, 16.899999999999945, 0.499999999999976, -28.099999999999902, 161.39999999999998, -118.10000000000022, 140.39999999999995, -41.69999999999983, 150.29999999999959, -378.5, 276.0, -306.2, -40.7999999999998, -128.90000000000038, -20.70000000000003, 40.0000000000003, -281.1999999999996, -27.399999999999814, -96.40000000000018, -92.4, 33.400000000000205, -362.7, 40.70000000000009, 163.29999999999953, 40.0000000000003, -224.20000000000078, -51.8999999999998, -270.6, -42.799999999999805, -335.6, 144.9999999999995, 40.0000000000003, 110.6, -5.799999999999976, 40.0000000000003, -307.70000000000016, 121.49999999999932, 160.99999999999937, -283.4000000000001, -286.2, 219.09999999999926, -38.599999999999966, 176.69999999999948, -47.799999999999926, -338.49999999999983], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-312.70000000000005, 5.299999999999965, -115.89999999999999, 20.000000000000014, -281.8, 20.000000000000014, -273.7, -328.59999999999997, 20.000000000000014, 20.000000000000014, -258.3999999999998, -239.2, 20.000000000000014, -175.0, -25.0, -137.5, -72.1, 44.599999999999994, 11.599999999999971, -301.6, -190.60000000000002, -168.39999999999992, -79.6, -135.1, 20.000000000000014, -356.4999999999999, -73.3, -61.900000000000034, 20.000000000000014, -273.70000000000005, -28.300000000000033, -90.70000000000002, 9.5, -225.4, -64.89999999999999, 20.000000000000014, 20.000000000000014, 20.000000000000014, 51.499999999999964, -255.70000000000002, 20.000000000000014, 7.399999999999965, -330.4, -302.1999999999999, 193.7, 20.000000000000014, -289.0, 20.000000000000014, 20.000000000000014, -310.9, 20.000000000000014, -217.00000000000003, -276.4, -228.70000000000002, 20.000000000000014, -353.79999999999995, -258.4, -312.7, 20.000000000000014, 51.499999999999964, 197.29999999999998, 176.6, 20.000000000000014, -338.8, -97.0, -234.7, -332.5, 20.000000000000014, -276.1, 20.000000000000014, -176.5, -220.6, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -286.0, -258.4000000000001, -287.8, 105.79999999999998, -201.70000000000005, 20.000000000000014, 20.000000000000014, 20.000000000000014, -310.0, -266.5, -297.40000000000003, 20.000000000000014, -295.0, -356.79999999999995, 20.000000000000014, -28.299999999999777, -319.5999999999998, -292.0, -259.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 181.99999999999994, 181.1, -160.3, 20.000000000000014, 13.699999999999964, 20.000000000000014, 20.0, 20.000000000000014, -269.20000000000005, -148.90000000000006, -374.79999999999995, 17.899999999999988, -213.40000000000003, 20.000000000000014, -1.0000000000000133, -3.099999999999958, -302.5, 20.000000000000014, -243.10000000000002, 20.000000000000014, 186.2, -266.8, 20.000000000000014, -303.1, -255.4, 165.79999999999995, 20.000000000000014, -351.69999999999993, 20.000000000000014, 128.3, -327.69999999999993, -344.8, 152.89999999999998, 97.10000000000005, -340.6, -334.6, -259.9, 1.0999999999999528, 20.000000000000014, -313.9, -369.7, 20.000000000000014, 20.000000000000014, 20.000000000000014, -293.7999999999996, -291.4, 20.000000000000014, -321.3999999999999, 20.000000000000014, -345.4, 20.000000000000014, -270.40000000000003, 20.000000000000014, 7.399999999999965, -323.8, -316.9, -326.8, 87.49999999999997, 20.000000000000014, 143.3, 20.000000000000014, 20.000000000000014, -394.9, -70.30000000000078, -90.70000000000002, -47.199999999999875, -256.90000000000003, -273.70000000000005, -314.8, 20.000000000000014, -293.8, -218.8, 106.69999999999999, 5.299999999999967, 20.000000000000014, 20.000000000000014, -269.79999999999995, 136.4, -299.5000000000001, 13.699999999999964, 20.000000000000014, 20.000000000000014, -233.80000000000013, -319.90000000000003, 11.599999999999964, 62.900000000000006, 11.599999999999964, 106.4, -301.0, -276.4000000000001, -300.70000000000005, -293.5, 199.1, 20.000000000000014, -115.60000000000001, -130.00000000000003, 142.7, 20.000000000000014, 20.000000000000014, -320.8, -333.6999999999998, -347.8], "policy_predator_policy_reward": [136.0, 65.0, 99.0, 0.0, 68.0, 142.0, 179.0, 56.0, 0.0, 0.0, 165.0, 6.0, 118.0, 9.0, 115.0, 8.0, 0.0, 88.0, 74.0, 128.0, 142.0, 13.0, 125.0, 2.0, 159.0, 77.0, 31.0, 77.0, 157.0, 10.0, 99.0, 0.0, 117.0, 27.0, 35.0, 36.0, 0.0, 0.0, 85.0, 132.0, 6.0, 0.0, 98.0, 165.0, 0.0, 0.0, 72.0, 139.0, 0.0, 170.0, 133.0, 0.0, 145.0, 110.0, 149.0, 102.0, 162.0, 139.0, 0.0, 0.0, 0.0, 0.0, 27.0, 179.0, 90.0, 100.0, 158.0, 136.0, 0.0, 156.0, 0.0, 139.0, 0.0, 0.0, 0.0, 0.0, 132.0, 115.0, 76.0, 135.0, 49.0, 107.0, 0.0, 0.0, 122.0, 126.0, 2.0, 162.0, 126.0, 167.0, 23.0, 0.0, 0.0, 190.0, 126.0, 105.0, 0.0, 0.0, 0.0, 0.0, 118.0, 0.0, 0.0, 3.0, 19.0, 50.0, 62.0, 125.0, 192.0, 0.0, 136.0, 0.0, 0.0, 21.0, 131.0, 152.0, 107.0, 88.0, 90.0, 152.0, 0.0, 165.0, 82.0, 148.0, 136.0, 154.0, 2.0, 0.0, 126.0, 168.0, 0.0, 26.0, 191.0, 178.0, 72.0, 146.0, 31.0, 134.0, 177.0, 152.0, 0.0, 0.0, 141.0, 163.0, 163.0, 111.0, 171.0, 58.0, 155.0, 3.0, 0.0, 6.0, 152.0, 126.0, 128.0, 152.0, 0.0, 0.0, 0.0, 0.0, 198.0, 43.0, 45.0, 41.0, 110.0, 150.0, 93.0, 159.0, 177.0, 0.0, 7.0, 26.0, 0.0, 0.0, 149.0, 95.0, 120.0, 160.0, 0.0, 0.0, 177.0, 69.0, 4.0, 43.0, 34.0, 9.0, 112.0, 182.0, 140.0, 168.0, 0.0, 0.0, 131.0, 76.0, 0.0, 14.0, 146.0, 107.0, 181.0, 162.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.688112939474612, "mean_inference_ms": 1.6365280878984436, "mean_action_processing_ms": 0.27168945529462724, "mean_env_wait_ms": 0.20303409420725074, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00518953800201416, "StateBufferConnector_ms": 0.003452301025390625, "ViewRequirementAgentConnector_ms": 0.15518271923065186}, "num_episodes": 23, "episode_return_max": 373.9000000000001, "episode_return_min": -421.5999999999997, "episode_return_mean": -59.73300000000003, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 736000, "num_agent_steps_trained": 736000, "num_env_steps_sampled": 184000, "num_env_steps_trained": 184000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 72.73950072998701, "num_env_steps_trained_throughput_per_sec": 72.73950072998701, "timesteps_total": 184000, "num_env_steps_sampled_lifetime": 184000, "num_agent_steps_sampled_lifetime": 736000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 736000, "timers": {"training_iteration_time_ms": 53874.637, "restore_workers_time_ms": 0.013, "training_step_time_ms": 53874.592, "sample_time_ms": 1360.3, "learn_time_ms": 52496.048, "learn_throughput": 76.196, "synch_weights_time_ms": 14.658}, "counters": {"num_env_steps_sampled": 184000, "num_env_steps_trained": 184000, "num_agent_steps_sampled": 736000, "num_agent_steps_trained": 736000}, "done": false, "training_iteration": 46, "trial_id": "11e70_00000", "date": "2024-08-12_23-47-03", "timestamp": 1723520823, "time_this_iter_s": 55.050110816955566, "time_total_s": 2403.199077129364, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2b619d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2403.199077129364, "iterations_since_restore": 46, "perf": {"cpu_util_percent": 47.6474358974359, "ram_util_percent": 83.2474358974359}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 8.55368710125565, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.34280758812314, "policy_loss": -0.009671765297932166, "vf_loss": 5.351154551808796, "vf_explained_var": 0.28776015062180776, "kl": 0.008832040579536096, "entropy": 1.138418026260598, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 87885.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.204576378083103, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.960314854616842, "policy_loss": -0.011984840633283571, "vf_loss": 4.970933370993881, "vf_explained_var": -0.16531515966647517, "kl": 0.009108737480950905, "entropy": 0.9945219085330055, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 87885.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 188000, "num_env_steps_trained": 188000, "num_agent_steps_sampled": 752000, "num_agent_steps_trained": 752000}, "env_runners": {"episode_reward_max": 373.9000000000001, "episode_reward_min": -421.5999999999997, "episode_reward_mean": -43.512000000000036, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -394.9, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 198.0}, "policy_reward_mean": {"prey_policy": -99.21100000000003, "predator_policy": 77.455}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.0000000000003, 12.800000000000022, 33.400000000000205, -369.5999999999998, 213.69999999999922, -57.99999999999987, -120.90000000000029, -63.99999999999986, -250.10000000000002, -82.8000000000001, -270.1, 71.5000000000002, 373.9000000000001, -112.80000000000041, -141.69999999999996, -18.499999999999964, -100.10000000000039, -258.1, 40.0000000000003, 40.0000000000003, -297.4000000000001, 29.000000000000014, -25.699999999999992, 40.0000000000003, -328.4999999999999, -113.40000000000023, -358.79999999999995, 14.69999999999993, -421.5999999999997, -7.999999999999913, 40.0000000000003, 363.10000000000014, -22.299999999999834, 36.70000000000025, 108.99999999999926, -231.1000000000001, -164.9000000000006, -57.399999999999835, 16.899999999999945, 0.499999999999976, -28.099999999999902, 161.39999999999998, -118.10000000000022, 140.39999999999995, -41.69999999999983, 150.29999999999959, -378.5, 276.0, -306.2, -40.7999999999998, -128.90000000000038, -20.70000000000003, 40.0000000000003, -281.1999999999996, -27.399999999999814, -96.40000000000018, -92.4, 33.400000000000205, -362.7, 40.70000000000009, 163.29999999999953, 40.0000000000003, -224.20000000000078, -51.8999999999998, -270.6, -42.799999999999805, -335.6, 144.9999999999995, 40.0000000000003, 110.6, -5.799999999999976, 40.0000000000003, -307.70000000000016, 121.49999999999932, 160.99999999999937, -283.4000000000001, -286.2, 219.09999999999926, -38.599999999999966, 176.69999999999948, -47.799999999999926, -338.49999999999983, 1.9999999999999374, 98.29999999999987, -219.90000000000015, 137.09999999999926, 40.0000000000003, -38.09999999999973, 40.0000000000003, 34.50000000000022, -78.80000000000018, -118.40000000000055, -33.89999999999983, -2.7000000000000473, 37.80000000000027, 325.1, 51.40000000000002, -28.3999999999999, -110.50000000000023, 10.700000000000182], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 20.000000000000014, 51.499999999999964, -255.70000000000002, 20.000000000000014, 7.399999999999965, -330.4, -302.1999999999999, 193.7, 20.000000000000014, -289.0, 20.000000000000014, 20.000000000000014, -310.9, 20.000000000000014, -217.00000000000003, -276.4, -228.70000000000002, 20.000000000000014, -353.79999999999995, -258.4, -312.7, 20.000000000000014, 51.499999999999964, 197.29999999999998, 176.6, 20.000000000000014, -338.8, -97.0, -234.7, -332.5, 20.000000000000014, -276.1, 20.000000000000014, -176.5, -220.6, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -286.0, -258.4000000000001, -287.8, 105.79999999999998, -201.70000000000005, 20.000000000000014, 20.000000000000014, 20.000000000000014, -310.0, -266.5, -297.40000000000003, 20.000000000000014, -295.0, -356.79999999999995, 20.000000000000014, -28.299999999999777, -319.5999999999998, -292.0, -259.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 181.99999999999994, 181.1, -160.3, 20.000000000000014, 13.699999999999964, 20.000000000000014, 20.0, 20.000000000000014, -269.20000000000005, -148.90000000000006, -374.79999999999995, 17.899999999999988, -213.40000000000003, 20.000000000000014, -1.0000000000000133, -3.099999999999958, -302.5, 20.000000000000014, -243.10000000000002, 20.000000000000014, 186.2, -266.8, 20.000000000000014, -303.1, -255.4, 165.79999999999995, 20.000000000000014, -351.69999999999993, 20.000000000000014, 128.3, -327.69999999999993, -344.8, 152.89999999999998, 97.10000000000005, -340.6, -334.6, -259.9, 1.0999999999999528, 20.000000000000014, -313.9, -369.7, 20.000000000000014, 20.000000000000014, 20.000000000000014, -293.7999999999996, -291.4, 20.000000000000014, -321.3999999999999, 20.000000000000014, -345.4, 20.000000000000014, -270.40000000000003, 20.000000000000014, 7.399999999999965, -323.8, -316.9, -326.8, 87.49999999999997, 20.000000000000014, 143.3, 20.000000000000014, 20.000000000000014, -394.9, -70.30000000000078, -90.70000000000002, -47.199999999999875, -256.90000000000003, -273.70000000000005, -314.8, 20.000000000000014, -293.8, -218.8, 106.69999999999999, 5.299999999999967, 20.000000000000014, 20.000000000000014, -269.79999999999995, 136.4, -299.5000000000001, 13.699999999999964, 20.000000000000014, 20.000000000000014, -233.80000000000013, -319.90000000000003, 11.599999999999964, 62.900000000000006, 11.599999999999964, 106.4, -301.0, -276.4000000000001, -300.70000000000005, -293.5, 199.1, 20.000000000000014, -115.60000000000001, -130.00000000000003, 142.7, 20.000000000000014, 20.000000000000014, -320.8, -333.6999999999998, -347.8, -274.0, 20.000000000000014, -97.60000000000079, 131.90000000000003, -96.39999999999998, -284.5, 64.1, 20.000000000000014, 20.000000000000014, 20.000000000000014, -383.49999999999994, 7.399999999999968, 20.000000000000014, 20.000000000000014, 9.499999999999966, 20.000000000000014, 20.000000000000014, -272.80000000000007, -300.4000000000001, 20.000000000000014, 1.09999999999996, -199.00000000000009, 20.000000000000014, -309.70000000000005, 20.000000000000014, 15.799999999999963, 155.6, 159.5, -307.6, 200.0, -312.4000000000001, 20.000000000000014, 9.499999999999964, -336.99999999999994, -185.8, -32.49999999999976], "policy_predator_policy_reward": [0.0, 0.0, 85.0, 132.0, 6.0, 0.0, 98.0, 165.0, 0.0, 0.0, 72.0, 139.0, 0.0, 170.0, 133.0, 0.0, 145.0, 110.0, 149.0, 102.0, 162.0, 139.0, 0.0, 0.0, 0.0, 0.0, 27.0, 179.0, 90.0, 100.0, 158.0, 136.0, 0.0, 156.0, 0.0, 139.0, 0.0, 0.0, 0.0, 0.0, 132.0, 115.0, 76.0, 135.0, 49.0, 107.0, 0.0, 0.0, 122.0, 126.0, 2.0, 162.0, 126.0, 167.0, 23.0, 0.0, 0.0, 190.0, 126.0, 105.0, 0.0, 0.0, 0.0, 0.0, 118.0, 0.0, 0.0, 3.0, 19.0, 50.0, 62.0, 125.0, 192.0, 0.0, 136.0, 0.0, 0.0, 21.0, 131.0, 152.0, 107.0, 88.0, 90.0, 152.0, 0.0, 165.0, 82.0, 148.0, 136.0, 154.0, 2.0, 0.0, 126.0, 168.0, 0.0, 26.0, 191.0, 178.0, 72.0, 146.0, 31.0, 134.0, 177.0, 152.0, 0.0, 0.0, 141.0, 163.0, 163.0, 111.0, 171.0, 58.0, 155.0, 3.0, 0.0, 6.0, 152.0, 126.0, 128.0, 152.0, 0.0, 0.0, 0.0, 0.0, 198.0, 43.0, 45.0, 41.0, 110.0, 150.0, 93.0, 159.0, 177.0, 0.0, 7.0, 26.0, 0.0, 0.0, 149.0, 95.0, 120.0, 160.0, 0.0, 0.0, 177.0, 69.0, 4.0, 43.0, 34.0, 9.0, 112.0, 182.0, 140.0, 168.0, 0.0, 0.0, 131.0, 76.0, 0.0, 14.0, 146.0, 107.0, 181.0, 162.0, 123.0, 133.0, 0.0, 64.0, 161.0, 0.0, 21.0, 32.0, 0.0, 0.0, 182.0, 156.0, 0.0, 0.0, 0.0, 5.0, 20.0, 154.0, 0.0, 162.0, 55.0, 109.0, 144.0, 143.0, 2.0, 0.0, 0.0, 10.0, 0.0, 159.0, 141.0, 123.0, 47.0, 170.0, 105.0, 124.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6908522130110897, "mean_inference_ms": 1.6404037709089048, "mean_action_processing_ms": 0.2726241067790562, "mean_env_wait_ms": 0.20386755420591599, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006202220916748047, "StateBufferConnector_ms": 0.003695368766784668, "ViewRequirementAgentConnector_ms": 0.15975475311279297}, "num_episodes": 18, "episode_return_max": 373.9000000000001, "episode_return_min": -421.5999999999997, "episode_return_mean": -43.512000000000036, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 752000, "num_agent_steps_trained": 752000, "num_env_steps_sampled": 188000, "num_env_steps_trained": 188000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 60.29927701784986, "num_env_steps_trained_throughput_per_sec": 60.29927701784986, "timesteps_total": 188000, "num_env_steps_sampled_lifetime": 188000, "num_agent_steps_sampled_lifetime": 752000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 752000, "timers": {"training_iteration_time_ms": 55263.973, "restore_workers_time_ms": 0.014, "training_step_time_ms": 55263.92, "sample_time_ms": 1371.06, "learn_time_ms": 53873.632, "learn_throughput": 74.248, "synch_weights_time_ms": 15.105}, "counters": {"num_env_steps_sampled": 188000, "num_env_steps_trained": 188000, "num_agent_steps_sampled": 752000, "num_agent_steps_trained": 752000}, "done": false, "training_iteration": 47, "trial_id": "11e70_00000", "date": "2024-08-12_23-48-10", "timestamp": 1723520890, "time_this_iter_s": 66.3908429145813, "time_total_s": 2469.5899200439453, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3f8ac10>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2469.5899200439453, "iterations_since_restore": 47, "perf": {"cpu_util_percent": 68.81595744680853, "ram_util_percent": 83.47872340425533}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 9.930765189632536, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.082512713487817, "policy_loss": -0.013612665876588494, "vf_loss": 4.094207447294205, "vf_explained_var": 0.336804836168491, "kl": 0.01278620048086701, "entropy": 1.140040662427428, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 89775.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.51853574624768, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.328330041870238, "policy_loss": -0.013734932327224189, "vf_loss": 5.340348334539504, "vf_explained_var": -0.07300562536905682, "kl": 0.011444170609833113, "entropy": 0.958485636036232, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 89775.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 192000, "num_env_steps_trained": 192000, "num_agent_steps_sampled": 768000, "num_agent_steps_trained": 768000}, "env_runners": {"episode_reward_max": 371.29999999999995, "episode_reward_min": -421.5999999999997, "episode_reward_mean": -25.018000000000058, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -394.9, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 198.0}, "policy_reward_mean": {"prey_policy": -88.15900000000002, "predator_policy": 75.65}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.0000000000003, 40.0000000000003, -297.4000000000001, 29.000000000000014, -25.699999999999992, 40.0000000000003, -328.4999999999999, -113.40000000000023, -358.79999999999995, 14.69999999999993, -421.5999999999997, -7.999999999999913, 40.0000000000003, 363.10000000000014, -22.299999999999834, 36.70000000000025, 108.99999999999926, -231.1000000000001, -164.9000000000006, -57.399999999999835, 16.899999999999945, 0.499999999999976, -28.099999999999902, 161.39999999999998, -118.10000000000022, 140.39999999999995, -41.69999999999983, 150.29999999999959, -378.5, 276.0, -306.2, -40.7999999999998, -128.90000000000038, -20.70000000000003, 40.0000000000003, -281.1999999999996, -27.399999999999814, -96.40000000000018, -92.4, 33.400000000000205, -362.7, 40.70000000000009, 163.29999999999953, 40.0000000000003, -224.20000000000078, -51.8999999999998, -270.6, -42.799999999999805, -335.6, 144.9999999999995, 40.0000000000003, 110.6, -5.799999999999976, 40.0000000000003, -307.70000000000016, 121.49999999999932, 160.99999999999937, -283.4000000000001, -286.2, 219.09999999999926, -38.599999999999966, 176.69999999999948, -47.799999999999926, -338.49999999999983, 1.9999999999999374, 98.29999999999987, -219.90000000000015, 137.09999999999926, 40.0000000000003, -38.09999999999973, 40.0000000000003, 34.50000000000022, -78.80000000000018, -118.40000000000055, -33.89999999999983, -2.7000000000000473, 37.80000000000027, 325.1, 51.40000000000002, -28.3999999999999, -110.50000000000023, 10.700000000000182, -93.10000000000035, 46.60000000000005, 371.29999999999995, -147.5000000000006, 269.49999999999955, 212.79999999999922, -12.29999999999994, -24.899999999999743, 40.0000000000003, -260.2000000000004, -48.59999999999978, 197.99999999999937, 40.0000000000003, -92.30000000000024, 94.89999999999934, 131.39999999999992, 143.1, -120.70000000000056], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -286.0, -258.4000000000001, -287.8, 105.79999999999998, -201.70000000000005, 20.000000000000014, 20.000000000000014, 20.000000000000014, -310.0, -266.5, -297.40000000000003, 20.000000000000014, -295.0, -356.79999999999995, 20.000000000000014, -28.299999999999777, -319.5999999999998, -292.0, -259.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 181.99999999999994, 181.1, -160.3, 20.000000000000014, 13.699999999999964, 20.000000000000014, 20.0, 20.000000000000014, -269.20000000000005, -148.90000000000006, -374.79999999999995, 17.899999999999988, -213.40000000000003, 20.000000000000014, -1.0000000000000133, -3.099999999999958, -302.5, 20.000000000000014, -243.10000000000002, 20.000000000000014, 186.2, -266.8, 20.000000000000014, -303.1, -255.4, 165.79999999999995, 20.000000000000014, -351.69999999999993, 20.000000000000014, 128.3, -327.69999999999993, -344.8, 152.89999999999998, 97.10000000000005, -340.6, -334.6, -259.9, 1.0999999999999528, 20.000000000000014, -313.9, -369.7, 20.000000000000014, 20.000000000000014, 20.000000000000014, -293.7999999999996, -291.4, 20.000000000000014, -321.3999999999999, 20.000000000000014, -345.4, 20.000000000000014, -270.40000000000003, 20.000000000000014, 7.399999999999965, -323.8, -316.9, -326.8, 87.49999999999997, 20.000000000000014, 143.3, 20.000000000000014, 20.000000000000014, -394.9, -70.30000000000078, -90.70000000000002, -47.199999999999875, -256.90000000000003, -273.70000000000005, -314.8, 20.000000000000014, -293.8, -218.8, 106.69999999999999, 5.299999999999967, 20.000000000000014, 20.000000000000014, -269.79999999999995, 136.4, -299.5000000000001, 13.699999999999964, 20.000000000000014, 20.000000000000014, -233.80000000000013, -319.90000000000003, 11.599999999999964, 62.900000000000006, 11.599999999999964, 106.4, -301.0, -276.4000000000001, -300.70000000000005, -293.5, 199.1, 20.000000000000014, -115.60000000000001, -130.00000000000003, 142.7, 20.000000000000014, 20.000000000000014, -320.8, -333.6999999999998, -347.8, -274.0, 20.000000000000014, -97.60000000000079, 131.90000000000003, -96.39999999999998, -284.5, 64.1, 20.000000000000014, 20.000000000000014, 20.000000000000014, -383.49999999999994, 7.399999999999968, 20.000000000000014, 20.000000000000014, 9.499999999999966, 20.000000000000014, 20.000000000000014, -272.80000000000007, -300.4000000000001, 20.000000000000014, 1.09999999999996, -199.00000000000009, 20.000000000000014, -309.70000000000005, 20.000000000000014, 15.799999999999963, 155.6, 159.5, -307.6, 200.0, -312.4000000000001, 20.000000000000014, 9.499999999999964, -336.99999999999994, -185.8, -32.49999999999976, -245.80000000000018, 13.699999999999969, 163.4, -242.8000000000004, 170.0, 191.29999999999998, -315.39999999999986, -3.0999999999999828, 199.1, 70.39999999999996, 20.000000000000014, 192.79999999999995, 15.799999999999962, -198.10000000000005, -394.9, 20.000000000000014, 20.000000000000014, 20.000000000000014, -249.40000000000038, -347.8, -361.6, 20.000000000000014, 20.000000000000014, 167.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, -343.29999999999995, 74.8999999999997, 20.000000000000014, 200.0, -196.60000000000008, -358.29999999999995, 196.39999999999998, 20.000000000000014, -300.69999999999953], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 0.0, 132.0, 115.0, 76.0, 135.0, 49.0, 107.0, 0.0, 0.0, 122.0, 126.0, 2.0, 162.0, 126.0, 167.0, 23.0, 0.0, 0.0, 190.0, 126.0, 105.0, 0.0, 0.0, 0.0, 0.0, 118.0, 0.0, 0.0, 3.0, 19.0, 50.0, 62.0, 125.0, 192.0, 0.0, 136.0, 0.0, 0.0, 21.0, 131.0, 152.0, 107.0, 88.0, 90.0, 152.0, 0.0, 165.0, 82.0, 148.0, 136.0, 154.0, 2.0, 0.0, 126.0, 168.0, 0.0, 26.0, 191.0, 178.0, 72.0, 146.0, 31.0, 134.0, 177.0, 152.0, 0.0, 0.0, 141.0, 163.0, 163.0, 111.0, 171.0, 58.0, 155.0, 3.0, 0.0, 6.0, 152.0, 126.0, 128.0, 152.0, 0.0, 0.0, 0.0, 0.0, 198.0, 43.0, 45.0, 41.0, 110.0, 150.0, 93.0, 159.0, 177.0, 0.0, 7.0, 26.0, 0.0, 0.0, 149.0, 95.0, 120.0, 160.0, 0.0, 0.0, 177.0, 69.0, 4.0, 43.0, 34.0, 9.0, 112.0, 182.0, 140.0, 168.0, 0.0, 0.0, 131.0, 76.0, 0.0, 14.0, 146.0, 107.0, 181.0, 162.0, 123.0, 133.0, 0.0, 64.0, 161.0, 0.0, 21.0, 32.0, 0.0, 0.0, 182.0, 156.0, 0.0, 0.0, 0.0, 5.0, 20.0, 154.0, 0.0, 162.0, 55.0, 109.0, 144.0, 143.0, 2.0, 0.0, 0.0, 10.0, 0.0, 159.0, 141.0, 123.0, 47.0, 170.0, 105.0, 124.0, 3.0, 136.0, 126.0, 0.0, 10.0, 0.0, 0.0, 171.0, 0.0, 0.0, 0.0, 0.0, 64.0, 106.0, 157.0, 193.0, 0.0, 0.0, 173.0, 164.0, 107.0, 186.0, 11.0, 0.0, 0.0, 0.0, 172.0, 59.0, 0.0, 0.0, 128.0, 0.0, 148.0, 157.0, 0.0, 160.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6953476501608992, "mean_inference_ms": 1.6487391146589723, "mean_action_processing_ms": 0.2740428455780963, "mean_env_wait_ms": 0.20523198055819464, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.009795308113098145, "StateBufferConnector_ms": 0.0037668943405151367, "ViewRequirementAgentConnector_ms": 0.16873407363891602}, "num_episodes": 18, "episode_return_max": 371.29999999999995, "episode_return_min": -421.5999999999997, "episode_return_mean": -25.018000000000058, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 768000, "num_agent_steps_trained": 768000, "num_env_steps_sampled": 192000, "num_env_steps_trained": 192000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 63.12259273435842, "num_env_steps_trained_throughput_per_sec": 63.12259273435842, "timesteps_total": 192000, "num_env_steps_sampled_lifetime": 192000, "num_agent_steps_sampled_lifetime": 768000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 768000, "timers": {"training_iteration_time_ms": 56349.289, "restore_workers_time_ms": 0.014, "training_step_time_ms": 56349.237, "sample_time_ms": 1464.249, "learn_time_ms": 54865.773, "learn_throughput": 72.905, "synch_weights_time_ms": 15.028}, "counters": {"num_env_steps_sampled": 192000, "num_env_steps_trained": 192000, "num_agent_steps_sampled": 768000, "num_agent_steps_trained": 768000}, "done": false, "training_iteration": 48, "trial_id": "11e70_00000", "date": "2024-08-12_23-49-13", "timestamp": 1723520953, "time_this_iter_s": 63.407971143722534, "time_total_s": 2532.997891187668, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2b93280>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2532.997891187668, "iterations_since_restore": 48, "perf": {"cpu_util_percent": 68.56333333333332, "ram_util_percent": 83.17333333333333}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 9.85564765576963, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.3953566349372664, "policy_loss": -0.009276955870655242, "vf_loss": 2.4031160425887537, "vf_explained_var": 0.278392846685238, "kl": 0.01011696805219189, "entropy": 1.1802083559137173, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 91665.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.309653502481955, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.589380116563626, "policy_loss": -0.016265179873468778, "vf_loss": 4.604060357840604, "vf_explained_var": 0.033813498985199704, "kl": 0.010566173619633622, "entropy": 0.8962468823743245, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 91665.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 196000, "num_env_steps_trained": 196000, "num_agent_steps_sampled": 784000, "num_agent_steps_trained": 784000}, "env_runners": {"episode_reward_max": 377.7000000000001, "episode_reward_min": -378.5, "episode_reward_mean": 4.629999999999904, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -394.9, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 198.0}, "policy_reward_mean": {"prey_policy": -66.98500000000001, "predator_policy": 69.3}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-28.099999999999902, 161.39999999999998, -118.10000000000022, 140.39999999999995, -41.69999999999983, 150.29999999999959, -378.5, 276.0, -306.2, -40.7999999999998, -128.90000000000038, -20.70000000000003, 40.0000000000003, -281.1999999999996, -27.399999999999814, -96.40000000000018, -92.4, 33.400000000000205, -362.7, 40.70000000000009, 163.29999999999953, 40.0000000000003, -224.20000000000078, -51.8999999999998, -270.6, -42.799999999999805, -335.6, 144.9999999999995, 40.0000000000003, 110.6, -5.799999999999976, 40.0000000000003, -307.70000000000016, 121.49999999999932, 160.99999999999937, -283.4000000000001, -286.2, 219.09999999999926, -38.599999999999966, 176.69999999999948, -47.799999999999926, -338.49999999999983, 1.9999999999999374, 98.29999999999987, -219.90000000000015, 137.09999999999926, 40.0000000000003, -38.09999999999973, 40.0000000000003, 34.50000000000022, -78.80000000000018, -118.40000000000055, -33.89999999999983, -2.7000000000000473, 37.80000000000027, 325.1, 51.40000000000002, -28.3999999999999, -110.50000000000023, 10.700000000000182, -93.10000000000035, 46.60000000000005, 371.29999999999995, -147.5000000000006, 269.49999999999955, 212.79999999999922, -12.29999999999994, -24.899999999999743, 40.0000000000003, -260.2000000000004, -48.59999999999978, 197.99999999999937, 40.0000000000003, -92.30000000000024, 94.89999999999934, 131.39999999999992, 143.1, -120.70000000000056, 40.0000000000003, 219.99999999999926, 127.29999999999976, 142.3999999999996, -0.899999999999987, -64.60000000000011, 161.49999999999955, 58.8, 76.69999999999928, -9.00000000000006, -244.20000000000056, 40.0000000000003, -10.999999999999991, 377.7000000000001, -17.899999999999665, 24.60000000000005, 139.89999999999964, -13.999999999999625, 219.99999999999926, 250.79999999999959, 40.0000000000003, 107.49999999999989], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-243.10000000000002, 20.000000000000014, 186.2, -266.8, 20.000000000000014, -303.1, -255.4, 165.79999999999995, 20.000000000000014, -351.69999999999993, 20.000000000000014, 128.3, -327.69999999999993, -344.8, 152.89999999999998, 97.10000000000005, -340.6, -334.6, -259.9, 1.0999999999999528, 20.000000000000014, -313.9, -369.7, 20.000000000000014, 20.000000000000014, 20.000000000000014, -293.7999999999996, -291.4, 20.000000000000014, -321.3999999999999, 20.000000000000014, -345.4, 20.000000000000014, -270.40000000000003, 20.000000000000014, 7.399999999999965, -323.8, -316.9, -326.8, 87.49999999999997, 20.000000000000014, 143.3, 20.000000000000014, 20.000000000000014, -394.9, -70.30000000000078, -90.70000000000002, -47.199999999999875, -256.90000000000003, -273.70000000000005, -314.8, 20.000000000000014, -293.8, -218.8, 106.69999999999999, 5.299999999999967, 20.000000000000014, 20.000000000000014, -269.79999999999995, 136.4, -299.5000000000001, 13.699999999999964, 20.000000000000014, 20.000000000000014, -233.80000000000013, -319.90000000000003, 11.599999999999964, 62.900000000000006, 11.599999999999964, 106.4, -301.0, -276.4000000000001, -300.70000000000005, -293.5, 199.1, 20.000000000000014, -115.60000000000001, -130.00000000000003, 142.7, 20.000000000000014, 20.000000000000014, -320.8, -333.6999999999998, -347.8, -274.0, 20.000000000000014, -97.60000000000079, 131.90000000000003, -96.39999999999998, -284.5, 64.1, 20.000000000000014, 20.000000000000014, 20.000000000000014, -383.49999999999994, 7.399999999999968, 20.000000000000014, 20.000000000000014, 9.499999999999966, 20.000000000000014, 20.000000000000014, -272.80000000000007, -300.4000000000001, 20.000000000000014, 1.09999999999996, -199.00000000000009, 20.000000000000014, -309.70000000000005, 20.000000000000014, 15.799999999999963, 155.6, 159.5, -307.6, 200.0, -312.4000000000001, 20.000000000000014, 9.499999999999964, -336.99999999999994, -185.8, -32.49999999999976, -245.80000000000018, 13.699999999999969, 163.4, -242.8000000000004, 170.0, 191.29999999999998, -315.39999999999986, -3.0999999999999828, 199.1, 70.39999999999996, 20.000000000000014, 192.79999999999995, 15.799999999999962, -198.10000000000005, -394.9, 20.000000000000014, 20.000000000000014, 20.000000000000014, -249.40000000000038, -347.8, -361.6, 20.000000000000014, 20.000000000000014, 167.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, -343.29999999999995, 74.8999999999997, 20.000000000000014, 200.0, -196.60000000000008, -358.29999999999995, 196.39999999999998, 20.000000000000014, -300.69999999999953, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 107.29999999999998, 103.40000000000006, 20.000000000000014, -112.90000000000009, 20.000000000000014, -326.19999999999936, 11.599999999999964, 20.000000000000014, 141.5, 105.49999999999997, -267.6999999999996, -46.59999999999994, 56.30000000000012, -32.49999999999975, -140.50000000000028, -328.0, -194.20000000000056, 20.000000000000014, 20.000000000000014, -294.9999999999991, 20.000000000000014, 200.0, 169.7, 20.000000000000014, -106.9000000000006, -9.399999999999855, 20.000000000000014, 20.000000000000014, 119.89999999999998, 20.000000000000014, -85.00000000000074, 20.000000000000014, 200.0, 62.299999999999976, 183.5, 20.000000000000014, 20.000000000000014, 87.49999999999997, 20.000000000000014], "policy_predator_policy_reward": [107.0, 88.0, 90.0, 152.0, 0.0, 165.0, 82.0, 148.0, 136.0, 154.0, 2.0, 0.0, 126.0, 168.0, 0.0, 26.0, 191.0, 178.0, 72.0, 146.0, 31.0, 134.0, 177.0, 152.0, 0.0, 0.0, 141.0, 163.0, 163.0, 111.0, 171.0, 58.0, 155.0, 3.0, 0.0, 6.0, 152.0, 126.0, 128.0, 152.0, 0.0, 0.0, 0.0, 0.0, 198.0, 43.0, 45.0, 41.0, 110.0, 150.0, 93.0, 159.0, 177.0, 0.0, 7.0, 26.0, 0.0, 0.0, 149.0, 95.0, 120.0, 160.0, 0.0, 0.0, 177.0, 69.0, 4.0, 43.0, 34.0, 9.0, 112.0, 182.0, 140.0, 168.0, 0.0, 0.0, 131.0, 76.0, 0.0, 14.0, 146.0, 107.0, 181.0, 162.0, 123.0, 133.0, 0.0, 64.0, 161.0, 0.0, 21.0, 32.0, 0.0, 0.0, 182.0, 156.0, 0.0, 0.0, 0.0, 5.0, 20.0, 154.0, 0.0, 162.0, 55.0, 109.0, 144.0, 143.0, 2.0, 0.0, 0.0, 10.0, 0.0, 159.0, 141.0, 123.0, 47.0, 170.0, 105.0, 124.0, 3.0, 136.0, 126.0, 0.0, 10.0, 0.0, 0.0, 171.0, 0.0, 0.0, 0.0, 0.0, 64.0, 106.0, 157.0, 193.0, 0.0, 0.0, 173.0, 164.0, 107.0, 186.0, 11.0, 0.0, 0.0, 0.0, 172.0, 59.0, 0.0, 0.0, 128.0, 0.0, 148.0, 157.0, 0.0, 160.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 19.0, 0.0, 35.0, 57.0, 148.0, 102.0, 0.0, 0.0, 105.0, 116.0, 67.0, 0.0, 96.0, 68.0, 176.0, 102.0, 0.0, 0.0, 139.0, 125.0, 8.0, 0.0, 0.0, 69.0, 0.0, 14.0, 0.0, 0.0, 47.0, 4.0, 0.0, 0.0, 4.0, 1.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7064236496040318, "mean_inference_ms": 1.6697514776500313, "mean_action_processing_ms": 0.27842030224560455, "mean_env_wait_ms": 0.20820468950168464, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.012104153633117676, "StateBufferConnector_ms": 0.004590153694152832, "ViewRequirementAgentConnector_ms": 0.24934077262878418}, "num_episodes": 22, "episode_return_max": 377.7000000000001, "episode_return_min": -378.5, "episode_return_mean": 4.629999999999904, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 784000, "num_agent_steps_trained": 784000, "num_env_steps_sampled": 196000, "num_env_steps_trained": 196000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 63.781199081217366, "num_env_steps_trained_throughput_per_sec": 63.781199081217366, "timesteps_total": 196000, "num_env_steps_sampled_lifetime": 196000, "num_agent_steps_sampled_lifetime": 784000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 784000, "timers": {"training_iteration_time_ms": 57235.751, "restore_workers_time_ms": 0.014, "training_step_time_ms": 57235.697, "sample_time_ms": 1706.229, "learn_time_ms": 55509.242, "learn_throughput": 72.06, "synch_weights_time_ms": 15.967}, "counters": {"num_env_steps_sampled": 196000, "num_env_steps_trained": 196000, "num_agent_steps_sampled": 784000, "num_agent_steps_trained": 784000}, "done": false, "training_iteration": 49, "trial_id": "11e70_00000", "date": "2024-08-12_23-50-16", "timestamp": 1723521016, "time_this_iter_s": 62.757364988327026, "time_total_s": 2595.755256175995, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2b805e0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2595.755256175995, "iterations_since_restore": 49, "perf": {"cpu_util_percent": 65.42111111111112, "ram_util_percent": 83.25}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 8.16090429592385, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.1823925260671233, "policy_loss": -0.009556392102290399, "vf_loss": 1.1903410514511128, "vf_explained_var": 0.23880093990179596, "kl": 0.010719118435521029, "entropy": 1.1541486313734104, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 93555.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.481876343425619, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.500347177439896, "policy_loss": -0.011052443359106306, "vf_loss": 4.5105359352454935, "vf_explained_var": 0.2610761997245607, "kl": 0.005757916989331998, "entropy": 0.8101576612424598, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 93555.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 200000, "num_env_steps_trained": 200000, "num_agent_steps_sampled": 800000, "num_agent_steps_trained": 800000}, "env_runners": {"episode_reward_max": 377.7000000000001, "episode_reward_min": -338.49999999999983, "episode_reward_mean": 43.78199999999989, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -394.9, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 193.0}, "policy_reward_mean": {"prey_policy": -28.909000000000013, "predator_policy": 50.8}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-51.8999999999998, -270.6, -42.799999999999805, -335.6, 144.9999999999995, 40.0000000000003, 110.6, -5.799999999999976, 40.0000000000003, -307.70000000000016, 121.49999999999932, 160.99999999999937, -283.4000000000001, -286.2, 219.09999999999926, -38.599999999999966, 176.69999999999948, -47.799999999999926, -338.49999999999983, 1.9999999999999374, 98.29999999999987, -219.90000000000015, 137.09999999999926, 40.0000000000003, -38.09999999999973, 40.0000000000003, 34.50000000000022, -78.80000000000018, -118.40000000000055, -33.89999999999983, -2.7000000000000473, 37.80000000000027, 325.1, 51.40000000000002, -28.3999999999999, -110.50000000000023, 10.700000000000182, -93.10000000000035, 46.60000000000005, 371.29999999999995, -147.5000000000006, 269.49999999999955, 212.79999999999922, -12.29999999999994, -24.899999999999743, 40.0000000000003, -260.2000000000004, -48.59999999999978, 197.99999999999937, 40.0000000000003, -92.30000000000024, 94.89999999999934, 131.39999999999992, 143.1, -120.70000000000056, 40.0000000000003, 219.99999999999926, 127.29999999999976, 142.3999999999996, -0.899999999999987, -64.60000000000011, 161.49999999999955, 58.8, 76.69999999999928, -9.00000000000006, -244.20000000000056, 40.0000000000003, -10.999999999999991, 377.7000000000001, -17.899999999999665, 24.60000000000005, 139.89999999999964, -13.999999999999625, 219.99999999999926, 250.79999999999959, 40.0000000000003, 107.49999999999989, 23.400000000000045, 217.29999999999927, 353.4, 22.100000000000033, 50.80000000000048, 27.80000000000011, 238.0, 172.29999999999913, 184.59999999999943, 179.49999999999997, 40.0000000000003, 354.1000000000009, 374.79999999999984, -65.60000000000116, 22.400000000000013, 23.100000000000044, 261.7999999999994, 36.70000000000025, 23.50000000000006, 7.999999999999986, 38.90000000000028, 186.5, 40.0000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-90.70000000000002, -47.199999999999875, -256.90000000000003, -273.70000000000005, -314.8, 20.000000000000014, -293.8, -218.8, 106.69999999999999, 5.299999999999967, 20.000000000000014, 20.000000000000014, -269.79999999999995, 136.4, -299.5000000000001, 13.699999999999964, 20.000000000000014, 20.000000000000014, -233.80000000000013, -319.90000000000003, 11.599999999999964, 62.900000000000006, 11.599999999999964, 106.4, -301.0, -276.4000000000001, -300.70000000000005, -293.5, 199.1, 20.000000000000014, -115.60000000000001, -130.00000000000003, 142.7, 20.000000000000014, 20.000000000000014, -320.8, -333.6999999999998, -347.8, -274.0, 20.000000000000014, -97.60000000000079, 131.90000000000003, -96.39999999999998, -284.5, 64.1, 20.000000000000014, 20.000000000000014, 20.000000000000014, -383.49999999999994, 7.399999999999968, 20.000000000000014, 20.000000000000014, 9.499999999999966, 20.000000000000014, 20.000000000000014, -272.80000000000007, -300.4000000000001, 20.000000000000014, 1.09999999999996, -199.00000000000009, 20.000000000000014, -309.70000000000005, 20.000000000000014, 15.799999999999963, 155.6, 159.5, -307.6, 200.0, -312.4000000000001, 20.000000000000014, 9.499999999999964, -336.99999999999994, -185.8, -32.49999999999976, -245.80000000000018, 13.699999999999969, 163.4, -242.8000000000004, 170.0, 191.29999999999998, -315.39999999999986, -3.0999999999999828, 199.1, 70.39999999999996, 20.000000000000014, 192.79999999999995, 15.799999999999962, -198.10000000000005, -394.9, 20.000000000000014, 20.000000000000014, 20.000000000000014, -249.40000000000038, -347.8, -361.6, 20.000000000000014, 20.000000000000014, 167.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, -343.29999999999995, 74.8999999999997, 20.000000000000014, 200.0, -196.60000000000008, -358.29999999999995, 196.39999999999998, 20.000000000000014, -300.69999999999953, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 107.29999999999998, 103.40000000000006, 20.000000000000014, -112.90000000000009, 20.000000000000014, -326.19999999999936, 11.599999999999964, 20.000000000000014, 141.5, 105.49999999999997, -267.6999999999996, -46.59999999999994, 56.30000000000012, -32.49999999999975, -140.50000000000028, -328.0, -194.20000000000056, 20.000000000000014, 20.000000000000014, -294.9999999999991, 20.000000000000014, 200.0, 169.7, 20.000000000000014, -106.9000000000006, -9.399999999999855, 20.000000000000014, 20.000000000000014, 119.89999999999998, 20.000000000000014, -85.00000000000074, 20.000000000000014, 200.0, 62.299999999999976, 183.5, 20.000000000000014, 20.000000000000014, 87.49999999999997, 20.000000000000014, -25.59999999999978, 20.000000000000014, 20.000000000000014, 197.3, 169.3999999999998, 176.0, -61.90000000000067, 20.000000000000014, 20.000000000000014, 30.800000000000196, -13.599999999999783, 25.4000000000001, 83.0, 95.0, 152.2999999999998, 20.000000000000014, 170.0, -9.399999999999855, 115.39999999999998, 64.09999999999998, 20.000000000000014, 20.000000000000014, 200.0, 154.09999999999977, 200.0, 174.79999999999987, -124.90000000000074, -36.699999999999875, -13.599999999999783, 20.000000000000014, -124.90000000000074, 20.000000000000014, 74.59999999999944, 180.2, 20.000000000000014, 13.699999999999966, 20.000000000000014, -11.499999999999883, 20.000000000000014, -118.0, 20.000000000000014, 17.899999999999988, 70.10000000000008, 94.40000000000006, 20.000000000000014, 20.000000000000014], "policy_predator_policy_reward": [45.0, 41.0, 110.0, 150.0, 93.0, 159.0, 177.0, 0.0, 7.0, 26.0, 0.0, 0.0, 149.0, 95.0, 120.0, 160.0, 0.0, 0.0, 177.0, 69.0, 4.0, 43.0, 34.0, 9.0, 112.0, 182.0, 140.0, 168.0, 0.0, 0.0, 131.0, 76.0, 0.0, 14.0, 146.0, 107.0, 181.0, 162.0, 123.0, 133.0, 0.0, 64.0, 161.0, 0.0, 21.0, 32.0, 0.0, 0.0, 182.0, 156.0, 0.0, 0.0, 0.0, 5.0, 20.0, 154.0, 0.0, 162.0, 55.0, 109.0, 144.0, 143.0, 2.0, 0.0, 0.0, 10.0, 0.0, 159.0, 141.0, 123.0, 47.0, 170.0, 105.0, 124.0, 3.0, 136.0, 126.0, 0.0, 10.0, 0.0, 0.0, 171.0, 0.0, 0.0, 0.0, 0.0, 64.0, 106.0, 157.0, 193.0, 0.0, 0.0, 173.0, 164.0, 107.0, 186.0, 11.0, 0.0, 0.0, 0.0, 172.0, 59.0, 0.0, 0.0, 128.0, 0.0, 148.0, 157.0, 0.0, 160.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 19.0, 0.0, 35.0, 57.0, 148.0, 102.0, 0.0, 0.0, 105.0, 116.0, 67.0, 0.0, 96.0, 68.0, 176.0, 102.0, 0.0, 0.0, 139.0, 125.0, 8.0, 0.0, 0.0, 69.0, 0.0, 14.0, 0.0, 0.0, 47.0, 4.0, 0.0, 0.0, 4.0, 1.0, 0.0, 0.0, 0.0, 0.0, 29.0, 0.0, 0.0, 0.0, 0.0, 8.0, 29.0, 35.0, 0.0, 0.0, 0.0, 16.0, 46.0, 14.0, 0.0, 0.0, 14.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 96.0, 0.0, 0.0, 16.0, 59.0, 69.0, 0.0, 7.0, 3.0, 0.0, 15.0, 0.0, 0.0, 106.0, 0.0, 1.0, 22.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7174458501817739, "mean_inference_ms": 1.6913247180762252, "mean_action_processing_ms": 0.28243255992866517, "mean_env_wait_ms": 0.21116006671308804, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01971876621246338, "StateBufferConnector_ms": 0.005751252174377441, "ViewRequirementAgentConnector_ms": 0.23525691032409668}, "num_episodes": 23, "episode_return_max": 377.7000000000001, "episode_return_min": -338.49999999999983, "episode_return_mean": 43.78199999999989, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 800000, "num_agent_steps_trained": 800000, "num_env_steps_sampled": 200000, "num_env_steps_trained": 200000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 64.10854045639886, "num_env_steps_trained_throughput_per_sec": 64.10854045639886, "timesteps_total": 200000, "num_env_steps_sampled_lifetime": 200000, "num_agent_steps_sampled_lifetime": 800000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 800000, "timers": {"training_iteration_time_ms": 58251.091, "restore_workers_time_ms": 0.014, "training_step_time_ms": 58251.037, "sample_time_ms": 1767.686, "learn_time_ms": 56461.591, "learn_throughput": 70.845, "synch_weights_time_ms": 17.69}, "counters": {"num_env_steps_sampled": 200000, "num_env_steps_trained": 200000, "num_agent_steps_sampled": 800000, "num_agent_steps_trained": 800000}, "done": false, "training_iteration": 50, "trial_id": "11e70_00000", "date": "2024-08-12_23-51-18", "timestamp": 1723521078, "time_this_iter_s": 62.46900415420532, "time_total_s": 2658.2242603302, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2b963a0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2658.2242603302, "iterations_since_restore": 50, "perf": {"cpu_util_percent": 66.37272727272727, "ram_util_percent": 83.41250000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 8.395820585318974, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.1540287371823397, "policy_loss": -0.010658434662652552, "vf_loss": 1.1634668959353966, "vf_explained_var": 0.1456433427712274, "kl": 0.008135144958308898, "entropy": 1.1346868547812972, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 95445.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.558929346982764, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.1516512294294974, "policy_loss": -0.00945020222546109, "vf_loss": 3.160049965394237, "vf_explained_var": 0.33059571968815316, "kl": 0.007009834693121264, "entropy": 0.7584783052956616, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 95445.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 204000, "num_env_steps_trained": 204000, "num_agent_steps_sampled": 816000, "num_agent_steps_trained": 816000}, "env_runners": {"episode_reward_max": 377.7000000000001, "episode_reward_min": -338.49999999999983, "episode_reward_mean": 65.47199999999991, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -394.9, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 209.0}, "policy_reward_mean": {"prey_policy": -6.684000000000017, "predator_policy": 39.42}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-338.49999999999983, 1.9999999999999374, 98.29999999999987, -219.90000000000015, 137.09999999999926, 40.0000000000003, -38.09999999999973, 40.0000000000003, 34.50000000000022, -78.80000000000018, -118.40000000000055, -33.89999999999983, -2.7000000000000473, 37.80000000000027, 325.1, 51.40000000000002, -28.3999999999999, -110.50000000000023, 10.700000000000182, -93.10000000000035, 46.60000000000005, 371.29999999999995, -147.5000000000006, 269.49999999999955, 212.79999999999922, -12.29999999999994, -24.899999999999743, 40.0000000000003, -260.2000000000004, -48.59999999999978, 197.99999999999937, 40.0000000000003, -92.30000000000024, 94.89999999999934, 131.39999999999992, 143.1, -120.70000000000056, 40.0000000000003, 219.99999999999926, 127.29999999999976, 142.3999999999996, -0.899999999999987, -64.60000000000011, 161.49999999999955, 58.8, 76.69999999999928, -9.00000000000006, -244.20000000000056, 40.0000000000003, -10.999999999999991, 377.7000000000001, -17.899999999999665, 24.60000000000005, 139.89999999999964, -13.999999999999625, 219.99999999999926, 250.79999999999959, 40.0000000000003, 107.49999999999989, 23.400000000000045, 217.29999999999927, 353.4, 22.100000000000033, 50.80000000000048, 27.80000000000011, 238.0, 172.29999999999913, 184.59999999999943, 179.49999999999997, 40.0000000000003, 354.1000000000009, 374.79999999999984, -65.60000000000116, 22.400000000000013, 23.100000000000044, 261.7999999999994, 36.70000000000025, 23.50000000000006, 7.999999999999986, 38.90000000000028, 186.5, 40.0000000000003, 173.19999999999956, 183.99999999999943, -135.40000000000086, 34.50000000000022, 22.100000000000023, 40.0000000000003, 344.2000000000004, 215.49999999999923, 27.90000000000011, 40.0000000000003, 35.600000000000236, 40.0000000000003, 11.599999999999946, 91.30000000000004, 219.99999999999926, -3.2999999999998373, 162.19999999999953, 9.100000000000184], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-333.6999999999998, -347.8, -274.0, 20.000000000000014, -97.60000000000079, 131.90000000000003, -96.39999999999998, -284.5, 64.1, 20.000000000000014, 20.000000000000014, 20.000000000000014, -383.49999999999994, 7.399999999999968, 20.000000000000014, 20.000000000000014, 9.499999999999966, 20.000000000000014, 20.000000000000014, -272.80000000000007, -300.4000000000001, 20.000000000000014, 1.09999999999996, -199.00000000000009, 20.000000000000014, -309.70000000000005, 20.000000000000014, 15.799999999999963, 155.6, 159.5, -307.6, 200.0, -312.4000000000001, 20.000000000000014, 9.499999999999964, -336.99999999999994, -185.8, -32.49999999999976, -245.80000000000018, 13.699999999999969, 163.4, -242.8000000000004, 170.0, 191.29999999999998, -315.39999999999986, -3.0999999999999828, 199.1, 70.39999999999996, 20.000000000000014, 192.79999999999995, 15.799999999999962, -198.10000000000005, -394.9, 20.000000000000014, 20.000000000000014, 20.000000000000014, -249.40000000000038, -347.8, -361.6, 20.000000000000014, 20.000000000000014, 167.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, -343.29999999999995, 74.8999999999997, 20.000000000000014, 200.0, -196.60000000000008, -358.29999999999995, 196.39999999999998, 20.000000000000014, -300.69999999999953, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 107.29999999999998, 103.40000000000006, 20.000000000000014, -112.90000000000009, 20.000000000000014, -326.19999999999936, 11.599999999999964, 20.000000000000014, 141.5, 105.49999999999997, -267.6999999999996, -46.59999999999994, 56.30000000000012, -32.49999999999975, -140.50000000000028, -328.0, -194.20000000000056, 20.000000000000014, 20.000000000000014, -294.9999999999991, 20.000000000000014, 200.0, 169.7, 20.000000000000014, -106.9000000000006, -9.399999999999855, 20.000000000000014, 20.000000000000014, 119.89999999999998, 20.000000000000014, -85.00000000000074, 20.000000000000014, 200.0, 62.299999999999976, 183.5, 20.000000000000014, 20.000000000000014, 87.49999999999997, 20.000000000000014, -25.59999999999978, 20.000000000000014, 20.000000000000014, 197.3, 169.3999999999998, 176.0, -61.90000000000067, 20.000000000000014, 20.000000000000014, 30.800000000000196, -13.599999999999783, 25.4000000000001, 83.0, 95.0, 152.2999999999998, 20.000000000000014, 170.0, -9.399999999999855, 115.39999999999998, 64.09999999999998, 20.000000000000014, 20.000000000000014, 200.0, 154.09999999999977, 200.0, 174.79999999999987, -124.90000000000074, -36.699999999999875, -13.599999999999783, 20.000000000000014, -124.90000000000074, 20.000000000000014, 74.59999999999944, 180.2, 20.000000000000014, 13.699999999999966, 20.000000000000014, -11.499999999999883, 20.000000000000014, -118.0, 20.000000000000014, 17.899999999999988, 70.10000000000008, 94.40000000000006, 20.000000000000014, 20.000000000000014, 153.20000000000005, 20.000000000000014, 20.000000000000014, 146.0, 20.000000000000014, -364.4000000000001, 20.000000000000014, 9.499999999999964, 20.000000000000014, -28.899999999999764, 20.000000000000014, 20.000000000000014, 184.6999999999999, 159.5, 195.49999999999997, 20.000000000000014, 20.000000000000014, -3.099999999999958, 20.000000000000014, 20.000000000000014, 20.000000000000014, 11.599999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, -51.39999999999988, 20.000000000000014, 71.29999999999997, 200.0, 20.000000000000014, -31.899999999999785, -75.40000000000069, 141.2, 20.000000000000014, 20.000000000000014, -52.900000000000155], "policy_predator_policy_reward": [181.0, 162.0, 123.0, 133.0, 0.0, 64.0, 161.0, 0.0, 21.0, 32.0, 0.0, 0.0, 182.0, 156.0, 0.0, 0.0, 0.0, 5.0, 20.0, 154.0, 0.0, 162.0, 55.0, 109.0, 144.0, 143.0, 2.0, 0.0, 0.0, 10.0, 0.0, 159.0, 141.0, 123.0, 47.0, 170.0, 105.0, 124.0, 3.0, 136.0, 126.0, 0.0, 10.0, 0.0, 0.0, 171.0, 0.0, 0.0, 0.0, 0.0, 64.0, 106.0, 157.0, 193.0, 0.0, 0.0, 173.0, 164.0, 107.0, 186.0, 11.0, 0.0, 0.0, 0.0, 172.0, 59.0, 0.0, 0.0, 128.0, 0.0, 148.0, 157.0, 0.0, 160.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 19.0, 0.0, 35.0, 57.0, 148.0, 102.0, 0.0, 0.0, 105.0, 116.0, 67.0, 0.0, 96.0, 68.0, 176.0, 102.0, 0.0, 0.0, 139.0, 125.0, 8.0, 0.0, 0.0, 69.0, 0.0, 14.0, 0.0, 0.0, 47.0, 4.0, 0.0, 0.0, 4.0, 1.0, 0.0, 0.0, 0.0, 0.0, 29.0, 0.0, 0.0, 0.0, 0.0, 8.0, 29.0, 35.0, 0.0, 0.0, 0.0, 16.0, 46.0, 14.0, 0.0, 0.0, 14.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 96.0, 0.0, 0.0, 16.0, 59.0, 69.0, 0.0, 7.0, 3.0, 0.0, 15.0, 0.0, 0.0, 106.0, 0.0, 1.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 18.0, 0.0, 209.0, 0.0, 5.0, 0.0, 8.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 43.0, 0.0, 0.0, 0.0, 0.0, 0.0, 48.0, 56.0, 1.0, 0.0, 0.0, 42.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7245696854037912, "mean_inference_ms": 1.7087402356948218, "mean_action_processing_ms": 0.28536894875668845, "mean_env_wait_ms": 0.21365093148292347, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.018874406814575195, "StateBufferConnector_ms": 0.0059517621994018555, "ViewRequirementAgentConnector_ms": 0.2280055284500122}, "num_episodes": 18, "episode_return_max": 377.7000000000001, "episode_return_min": -338.49999999999983, "episode_return_mean": 65.47199999999991, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 816000, "num_agent_steps_trained": 816000, "num_env_steps_sampled": 204000, "num_env_steps_trained": 204000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 55.02905274850393, "num_env_steps_trained_throughput_per_sec": 55.02905274850393, "timesteps_total": 204000, "num_env_steps_sampled_lifetime": 204000, "num_agent_steps_sampled_lifetime": 816000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 816000, "timers": {"training_iteration_time_ms": 60086.368, "restore_workers_time_ms": 0.014, "training_step_time_ms": 60086.314, "sample_time_ms": 1816.522, "learn_time_ms": 58247.52, "learn_throughput": 68.672, "synch_weights_time_ms": 18.14}, "counters": {"num_env_steps_sampled": 204000, "num_env_steps_trained": 204000, "num_agent_steps_sampled": 816000, "num_agent_steps_trained": 816000}, "done": false, "training_iteration": 51, "trial_id": "11e70_00000", "date": "2024-08-12_23-52-31", "timestamp": 1723521151, "time_this_iter_s": 72.75641965866089, "time_total_s": 2730.980679988861, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2b80700>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2730.980679988861, "iterations_since_restore": 51, "perf": {"cpu_util_percent": 82.58173076923077, "ram_util_percent": 83.66538461538462}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 7.176995682022559, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.706411342456858, "policy_loss": -0.008660797712333973, "vf_loss": 1.71388765359051, "vf_explained_var": 0.2603031629607791, "kl": 0.007896572482359405, "entropy": 1.1089363625440647, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 97335.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.699694979947711, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.0508602725134955, "policy_loss": -0.0214637773159507, "vf_loss": 4.070662827592678, "vf_explained_var": 0.3400091480010401, "kl": 0.011074796554539006, "entropy": 0.790350053203169, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 97335.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 208000, "num_env_steps_trained": 208000, "num_agent_steps_sampled": 832000, "num_agent_steps_trained": 832000}, "env_runners": {"episode_reward_max": 377.7000000000001, "episode_reward_min": -260.2000000000004, "episode_reward_mean": 79.77299999999988, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -394.9, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 209.0}, "policy_reward_mean": {"prey_policy": 9.07649999999997, "predator_policy": 30.81}, "custom_metrics": {}, "hist_stats": {"episode_reward": [10.700000000000182, -93.10000000000035, 46.60000000000005, 371.29999999999995, -147.5000000000006, 269.49999999999955, 212.79999999999922, -12.29999999999994, -24.899999999999743, 40.0000000000003, -260.2000000000004, -48.59999999999978, 197.99999999999937, 40.0000000000003, -92.30000000000024, 94.89999999999934, 131.39999999999992, 143.1, -120.70000000000056, 40.0000000000003, 219.99999999999926, 127.29999999999976, 142.3999999999996, -0.899999999999987, -64.60000000000011, 161.49999999999955, 58.8, 76.69999999999928, -9.00000000000006, -244.20000000000056, 40.0000000000003, -10.999999999999991, 377.7000000000001, -17.899999999999665, 24.60000000000005, 139.89999999999964, -13.999999999999625, 219.99999999999926, 250.79999999999959, 40.0000000000003, 107.49999999999989, 23.400000000000045, 217.29999999999927, 353.4, 22.100000000000033, 50.80000000000048, 27.80000000000011, 238.0, 172.29999999999913, 184.59999999999943, 179.49999999999997, 40.0000000000003, 354.1000000000009, 374.79999999999984, -65.60000000000116, 22.400000000000013, 23.100000000000044, 261.7999999999994, 36.70000000000025, 23.50000000000006, 7.999999999999986, 38.90000000000028, 186.5, 40.0000000000003, 173.19999999999956, 183.99999999999943, -135.40000000000086, 34.50000000000022, 22.100000000000023, 40.0000000000003, 344.2000000000004, 215.49999999999923, 27.90000000000011, 40.0000000000003, 35.600000000000236, 40.0000000000003, 11.599999999999946, 91.30000000000004, 219.99999999999926, -3.2999999999998373, 162.19999999999953, 9.100000000000184, -214.10000000000073, 40.80000000000013, 62.700000000000045, 219.99999999999926, 40.0000000000003, 136.2999999999997, 170.9999999999995, 215.49999999999923, 40.0000000000003, 31.200000000000166, 183.99999999999955, 193.99999999999937, 47.200000000000415, -119.10000000000079, 108.39999999999921, -9.699999999999655, 38.90000000000028, 40.0000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-185.8, -32.49999999999976, -245.80000000000018, 13.699999999999969, 163.4, -242.8000000000004, 170.0, 191.29999999999998, -315.39999999999986, -3.0999999999999828, 199.1, 70.39999999999996, 20.000000000000014, 192.79999999999995, 15.799999999999962, -198.10000000000005, -394.9, 20.000000000000014, 20.000000000000014, 20.000000000000014, -249.40000000000038, -347.8, -361.6, 20.000000000000014, 20.000000000000014, 167.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, -343.29999999999995, 74.8999999999997, 20.000000000000014, 200.0, -196.60000000000008, -358.29999999999995, 196.39999999999998, 20.000000000000014, -300.69999999999953, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 107.29999999999998, 103.40000000000006, 20.000000000000014, -112.90000000000009, 20.000000000000014, -326.19999999999936, 11.599999999999964, 20.000000000000014, 141.5, 105.49999999999997, -267.6999999999996, -46.59999999999994, 56.30000000000012, -32.49999999999975, -140.50000000000028, -328.0, -194.20000000000056, 20.000000000000014, 20.000000000000014, -294.9999999999991, 20.000000000000014, 200.0, 169.7, 20.000000000000014, -106.9000000000006, -9.399999999999855, 20.000000000000014, 20.000000000000014, 119.89999999999998, 20.000000000000014, -85.00000000000074, 20.000000000000014, 200.0, 62.299999999999976, 183.5, 20.000000000000014, 20.000000000000014, 87.49999999999997, 20.000000000000014, -25.59999999999978, 20.000000000000014, 20.000000000000014, 197.3, 169.3999999999998, 176.0, -61.90000000000067, 20.000000000000014, 20.000000000000014, 30.800000000000196, -13.599999999999783, 25.4000000000001, 83.0, 95.0, 152.2999999999998, 20.000000000000014, 170.0, -9.399999999999855, 115.39999999999998, 64.09999999999998, 20.000000000000014, 20.000000000000014, 200.0, 154.09999999999977, 200.0, 174.79999999999987, -124.90000000000074, -36.699999999999875, -13.599999999999783, 20.000000000000014, -124.90000000000074, 20.000000000000014, 74.59999999999944, 180.2, 20.000000000000014, 13.699999999999966, 20.000000000000014, -11.499999999999883, 20.000000000000014, -118.0, 20.000000000000014, 17.899999999999988, 70.10000000000008, 94.40000000000006, 20.000000000000014, 20.000000000000014, 153.20000000000005, 20.000000000000014, 20.000000000000014, 146.0, 20.000000000000014, -364.4000000000001, 20.000000000000014, 9.499999999999964, 20.000000000000014, -28.899999999999764, 20.000000000000014, 20.000000000000014, 184.6999999999999, 159.5, 195.49999999999997, 20.000000000000014, 20.000000000000014, -3.099999999999958, 20.000000000000014, 20.000000000000014, 20.000000000000014, 11.599999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, -51.39999999999988, 20.000000000000014, 71.29999999999997, 200.0, 20.000000000000014, -31.899999999999785, -75.40000000000069, 141.2, 20.000000000000014, 20.000000000000014, -52.900000000000155, -211.0000000000005, -171.1000000000001, 29.900000000000055, -63.10000000000078, -246.70000000000036, 169.40000000000003, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 116.29999999999998, 20.000000000000014, 101.0, 20.000000000000014, 195.49999999999997, 20.000000000000014, 20.000000000000014, 20.000000000000014, 3.1999999999999615, -146.20000000000044, 189.2, 158.0, 20.000000000000014, 27.20000000000013, 20.000000000000014, -110.80000000000064, -292.29999999999984, 20.000000000000014, 88.39999999999966, -61.600000000000634, -3.099999999999958, 17.899999999999988, 20.000000000000014, 20.000000000000014, 20.000000000000014], "policy_predator_policy_reward": [105.0, 124.0, 3.0, 136.0, 126.0, 0.0, 10.0, 0.0, 0.0, 171.0, 0.0, 0.0, 0.0, 0.0, 64.0, 106.0, 157.0, 193.0, 0.0, 0.0, 173.0, 164.0, 107.0, 186.0, 11.0, 0.0, 0.0, 0.0, 172.0, 59.0, 0.0, 0.0, 128.0, 0.0, 148.0, 157.0, 0.0, 160.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 19.0, 0.0, 35.0, 57.0, 148.0, 102.0, 0.0, 0.0, 105.0, 116.0, 67.0, 0.0, 96.0, 68.0, 176.0, 102.0, 0.0, 0.0, 139.0, 125.0, 8.0, 0.0, 0.0, 69.0, 0.0, 14.0, 0.0, 0.0, 47.0, 4.0, 0.0, 0.0, 4.0, 1.0, 0.0, 0.0, 0.0, 0.0, 29.0, 0.0, 0.0, 0.0, 0.0, 8.0, 29.0, 35.0, 0.0, 0.0, 0.0, 16.0, 46.0, 14.0, 0.0, 0.0, 14.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 96.0, 0.0, 0.0, 16.0, 59.0, 69.0, 0.0, 7.0, 3.0, 0.0, 15.0, 0.0, 0.0, 106.0, 0.0, 1.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 18.0, 0.0, 209.0, 0.0, 5.0, 0.0, 8.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 43.0, 0.0, 0.0, 0.0, 0.0, 0.0, 48.0, 56.0, 1.0, 0.0, 0.0, 42.0, 168.0, 0.0, 39.0, 35.0, 78.0, 62.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 18.0, 32.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 74.0, 67.0, 13.0, 3.0, 0.0, 0.0, 155.0, 129.0, 0.0, 0.0, 44.0, 11.0, 0.0, 1.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7347459737607096, "mean_inference_ms": 1.7330769403566604, "mean_action_processing_ms": 0.28942676762339703, "mean_env_wait_ms": 0.21661273316975926, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.018700480461120605, "StateBufferConnector_ms": 0.005922675132751465, "ViewRequirementAgentConnector_ms": 0.24975204467773438}, "num_episodes": 18, "episode_return_max": 377.7000000000001, "episode_return_min": -260.2000000000004, "episode_return_mean": 79.77299999999988, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 832000, "num_agent_steps_trained": 832000, "num_env_steps_sampled": 208000, "num_env_steps_trained": 208000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 50.67413384629463, "num_env_steps_trained_throughput_per_sec": 50.67413384629463, "timesteps_total": 208000, "num_env_steps_sampled_lifetime": 208000, "num_agent_steps_sampled_lifetime": 832000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 832000, "timers": {"training_iteration_time_ms": 62473.771, "restore_workers_time_ms": 0.015, "training_step_time_ms": 62473.716, "sample_time_ms": 1993.891, "learn_time_ms": 60455.984, "learn_throughput": 66.164, "synch_weights_time_ms": 19.507}, "counters": {"num_env_steps_sampled": 208000, "num_env_steps_trained": 208000, "num_agent_steps_sampled": 832000, "num_agent_steps_trained": 832000}, "done": false, "training_iteration": 52, "trial_id": "11e70_00000", "date": "2024-08-12_23-53-50", "timestamp": 1723521230, "time_this_iter_s": 79.02822399139404, "time_total_s": 2810.008903980255, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2b80430>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2810.008903980255, "iterations_since_restore": 52, "perf": {"cpu_util_percent": 88.88018018018018, "ram_util_percent": 83.73873873873876}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.98006804203861, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.6690692103571362, "policy_loss": -0.004981868670730995, "vf_loss": 0.6732810395005991, "vf_explained_var": 0.157091032985657, "kl": 0.005133609482491483, "entropy": 1.1183219803073419, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 99225.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.518578152366416, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.065555729689422, "policy_loss": -0.007391889162962793, "vf_loss": 5.071912004077245, "vf_explained_var": 0.5119862010239293, "kl": 0.006904129368009096, "entropy": 0.7068836711071156, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 99225.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 212000, "num_env_steps_trained": 212000, "num_agent_steps_sampled": 848000, "num_agent_steps_trained": 848000}, "env_runners": {"episode_reward_max": 377.7000000000001, "episode_reward_min": -244.20000000000056, "episode_reward_mean": 97.97499999999984, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -364.4000000000001, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 209.0}, "policy_reward_mean": {"prey_policy": 28.102499999999964, "predator_policy": 20.885}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-120.70000000000056, 40.0000000000003, 219.99999999999926, 127.29999999999976, 142.3999999999996, -0.899999999999987, -64.60000000000011, 161.49999999999955, 58.8, 76.69999999999928, -9.00000000000006, -244.20000000000056, 40.0000000000003, -10.999999999999991, 377.7000000000001, -17.899999999999665, 24.60000000000005, 139.89999999999964, -13.999999999999625, 219.99999999999926, 250.79999999999959, 40.0000000000003, 107.49999999999989, 23.400000000000045, 217.29999999999927, 353.4, 22.100000000000033, 50.80000000000048, 27.80000000000011, 238.0, 172.29999999999913, 184.59999999999943, 179.49999999999997, 40.0000000000003, 354.1000000000009, 374.79999999999984, -65.60000000000116, 22.400000000000013, 23.100000000000044, 261.7999999999994, 36.70000000000025, 23.50000000000006, 7.999999999999986, 38.90000000000028, 186.5, 40.0000000000003, 173.19999999999956, 183.99999999999943, -135.40000000000086, 34.50000000000022, 22.100000000000023, 40.0000000000003, 344.2000000000004, 215.49999999999923, 27.90000000000011, 40.0000000000003, 35.600000000000236, 40.0000000000003, 11.599999999999946, 91.30000000000004, 219.99999999999926, -3.2999999999998373, 162.19999999999953, 9.100000000000184, -214.10000000000073, 40.80000000000013, 62.700000000000045, 219.99999999999926, 40.0000000000003, 136.2999999999997, 170.9999999999995, 215.49999999999923, 40.0000000000003, 31.200000000000166, 183.99999999999955, 193.99999999999937, 47.200000000000415, -119.10000000000079, 108.39999999999921, -9.699999999999655, 38.90000000000028, 40.0000000000003, 75.10000000000016, 200.19999999999936, 219.99999999999926, 32.300000000000196, 120.09999999999994, -92.00000000000026, 175.79999999999944, 179.59999999999945, 197.99999999999937, -106.10000000000133, 128.7999999999997, 120.999999999999, -22.69999999999957, 355.4, 350.0, 298.0, 192.0999999999994, 274.00000000000006], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, -300.69999999999953, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 107.29999999999998, 103.40000000000006, 20.000000000000014, -112.90000000000009, 20.000000000000014, -326.19999999999936, 11.599999999999964, 20.000000000000014, 141.5, 105.49999999999997, -267.6999999999996, -46.59999999999994, 56.30000000000012, -32.49999999999975, -140.50000000000028, -328.0, -194.20000000000056, 20.000000000000014, 20.000000000000014, -294.9999999999991, 20.000000000000014, 200.0, 169.7, 20.000000000000014, -106.9000000000006, -9.399999999999855, 20.000000000000014, 20.000000000000014, 119.89999999999998, 20.000000000000014, -85.00000000000074, 20.000000000000014, 200.0, 62.299999999999976, 183.5, 20.000000000000014, 20.000000000000014, 87.49999999999997, 20.000000000000014, -25.59999999999978, 20.000000000000014, 20.000000000000014, 197.3, 169.3999999999998, 176.0, -61.90000000000067, 20.000000000000014, 20.000000000000014, 30.800000000000196, -13.599999999999783, 25.4000000000001, 83.0, 95.0, 152.2999999999998, 20.000000000000014, 170.0, -9.399999999999855, 115.39999999999998, 64.09999999999998, 20.000000000000014, 20.000000000000014, 200.0, 154.09999999999977, 200.0, 174.79999999999987, -124.90000000000074, -36.699999999999875, -13.599999999999783, 20.000000000000014, -124.90000000000074, 20.000000000000014, 74.59999999999944, 180.2, 20.000000000000014, 13.699999999999966, 20.000000000000014, -11.499999999999883, 20.000000000000014, -118.0, 20.000000000000014, 17.899999999999988, 70.10000000000008, 94.40000000000006, 20.000000000000014, 20.000000000000014, 153.20000000000005, 20.000000000000014, 20.000000000000014, 146.0, 20.000000000000014, -364.4000000000001, 20.000000000000014, 9.499999999999964, 20.000000000000014, -28.899999999999764, 20.000000000000014, 20.000000000000014, 184.6999999999999, 159.5, 195.49999999999997, 20.000000000000014, 20.000000000000014, -3.099999999999958, 20.000000000000014, 20.000000000000014, 20.000000000000014, 11.599999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, -51.39999999999988, 20.000000000000014, 71.29999999999997, 200.0, 20.000000000000014, -31.899999999999785, -75.40000000000069, 141.2, 20.000000000000014, 20.000000000000014, -52.900000000000155, -211.0000000000005, -171.1000000000001, 29.900000000000055, -63.10000000000078, -246.70000000000036, 169.40000000000003, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 116.29999999999998, 20.000000000000014, 101.0, 20.000000000000014, 195.49999999999997, 20.000000000000014, 20.000000000000014, 20.000000000000014, 3.1999999999999615, -146.20000000000044, 189.2, 158.0, 20.000000000000014, 27.20000000000013, 20.000000000000014, -110.80000000000064, -292.29999999999984, 20.000000000000014, 88.39999999999966, -61.600000000000634, -3.099999999999958, 17.899999999999988, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 55.09999999999996, 180.2, 20.000000000000014, 200.0, 20.000000000000014, 5.2999999999999705, 20.000000000000014, 20.000000000000014, 100.10000000000002, 20.000000000000014, -232.00000000000006, 114.19999999999999, 11.59999999999997, 20.000000000000014, 125.6, 20.000000000000014, 158.0, -71.50000000000068, -118.6000000000007, 68.0, 15.799999999999962, -10.599999999999858, 113.59999999999958, -120.70000000000073, 20.000000000000014, 169.4, 179.0, 170.0, 161.0, 122.0, 161.0, 173.0, 1.0999999999999688, 118.09999999999998, 155.90000000000003], "policy_predator_policy_reward": [0.0, 160.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 19.0, 0.0, 35.0, 57.0, 148.0, 102.0, 0.0, 0.0, 105.0, 116.0, 67.0, 0.0, 96.0, 68.0, 176.0, 102.0, 0.0, 0.0, 139.0, 125.0, 8.0, 0.0, 0.0, 69.0, 0.0, 14.0, 0.0, 0.0, 47.0, 4.0, 0.0, 0.0, 4.0, 1.0, 0.0, 0.0, 0.0, 0.0, 29.0, 0.0, 0.0, 0.0, 0.0, 8.0, 29.0, 35.0, 0.0, 0.0, 0.0, 16.0, 46.0, 14.0, 0.0, 0.0, 14.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 96.0, 0.0, 0.0, 16.0, 59.0, 69.0, 0.0, 7.0, 3.0, 0.0, 15.0, 0.0, 0.0, 106.0, 0.0, 1.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 18.0, 0.0, 209.0, 0.0, 5.0, 0.0, 8.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 43.0, 0.0, 0.0, 0.0, 0.0, 0.0, 48.0, 56.0, 1.0, 0.0, 0.0, 42.0, 168.0, 0.0, 39.0, 35.0, 78.0, 62.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 18.0, 32.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 74.0, 67.0, 13.0, 3.0, 0.0, 0.0, 155.0, 129.0, 0.0, 0.0, 44.0, 11.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 120.0, 26.0, 24.0, 22.0, 12.0, 14.0, 6.0, 72.0, 12.0, 0.0, 45.0, 0.0, 18.0, 20.0, 58.0, 7.0, 0.0, 10.0, 9.0, 0.0, 15.0, 9.0, 9.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7476100222745239, "mean_inference_ms": 1.763772367886493, "mean_action_processing_ms": 0.29482921019714753, "mean_env_wait_ms": 0.22035220170461348, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01580345630645752, "StateBufferConnector_ms": 0.006235957145690918, "ViewRequirementAgentConnector_ms": 0.2990231513977051}, "num_episodes": 18, "episode_return_max": 377.7000000000001, "episode_return_min": -244.20000000000056, "episode_return_mean": 97.97499999999984, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 848000, "num_agent_steps_trained": 848000, "num_env_steps_sampled": 212000, "num_env_steps_trained": 212000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 57.56383279212293, "num_env_steps_trained_throughput_per_sec": 57.56383279212293, "timesteps_total": 212000, "num_env_steps_sampled_lifetime": 212000, "num_agent_steps_sampled_lifetime": 848000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 848000, "timers": {"training_iteration_time_ms": 64010.411, "restore_workers_time_ms": 0.016, "training_step_time_ms": 64010.357, "sample_time_ms": 2266.214, "learn_time_ms": 61720.539, "learn_throughput": 64.808, "synch_weights_time_ms": 19.799}, "counters": {"num_env_steps_sampled": 212000, "num_env_steps_trained": 212000, "num_agent_steps_sampled": 848000, "num_agent_steps_trained": 848000}, "done": false, "training_iteration": 53, "trial_id": "11e70_00000", "date": "2024-08-12_23-55-00", "timestamp": 1723521300, "time_this_iter_s": 69.52196526527405, "time_total_s": 2879.530869245529, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2b93280>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2879.530869245529, "iterations_since_restore": 53, "perf": {"cpu_util_percent": 80.72727272727273, "ram_util_percent": 83.0959595959596}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.431227964288974, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.5468278016284029, "policy_loss": -0.007426145577202083, "vf_loss": 0.5532593279204789, "vf_explained_var": 0.17222168256366063, "kl": 0.00663079337855098, "entropy": 1.07603162640617, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 101115.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 6.067816169741293, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.657877555726066, "policy_loss": -0.00985200092228494, "vf_loss": 4.664674573348313, "vf_explained_var": 0.5278517338964674, "kl": 0.020366540851363357, "entropy": 0.7861276140288701, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 101115.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 216000, "num_env_steps_trained": 216000, "num_agent_steps_sampled": 864000, "num_agent_steps_trained": 864000}, "env_runners": {"episode_reward_max": 374.79999999999984, "episode_reward_min": -214.10000000000073, "episode_reward_mean": 115.23399999999984, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -364.4000000000001, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 209.0}, "policy_reward_mean": {"prey_policy": 43.52699999999995, "predator_policy": 14.09}, "custom_metrics": {}, "hist_stats": {"episode_reward": [107.49999999999989, 23.400000000000045, 217.29999999999927, 353.4, 22.100000000000033, 50.80000000000048, 27.80000000000011, 238.0, 172.29999999999913, 184.59999999999943, 179.49999999999997, 40.0000000000003, 354.1000000000009, 374.79999999999984, -65.60000000000116, 22.400000000000013, 23.100000000000044, 261.7999999999994, 36.70000000000025, 23.50000000000006, 7.999999999999986, 38.90000000000028, 186.5, 40.0000000000003, 173.19999999999956, 183.99999999999943, -135.40000000000086, 34.50000000000022, 22.100000000000023, 40.0000000000003, 344.2000000000004, 215.49999999999923, 27.90000000000011, 40.0000000000003, 35.600000000000236, 40.0000000000003, 11.599999999999946, 91.30000000000004, 219.99999999999926, -3.2999999999998373, 162.19999999999953, 9.100000000000184, -214.10000000000073, 40.80000000000013, 62.700000000000045, 219.99999999999926, 40.0000000000003, 136.2999999999997, 170.9999999999995, 215.49999999999923, 40.0000000000003, 31.200000000000166, 183.99999999999955, 193.99999999999937, 47.200000000000415, -119.10000000000079, 108.39999999999921, -9.699999999999655, 38.90000000000028, 40.0000000000003, 75.10000000000016, 200.19999999999936, 219.99999999999926, 32.300000000000196, 120.09999999999994, -92.00000000000026, 175.79999999999944, 179.59999999999945, 197.99999999999937, -106.10000000000133, 128.7999999999997, 120.999999999999, -22.69999999999957, 355.4, 350.0, 298.0, 192.0999999999994, 274.00000000000006, 40.0000000000003, 161.49999999999955, 40.0000000000003, 189.39999999999924, 198.29999999999936, 121.89999999999972, 219.99999999999926, 40.0000000000003, 336.60000000000025, 206.79999999999933, 40.0000000000003, 210.9999999999993, 208.6999999999993, 132.6999999999997, 166.99999999999955, 40.90000000000031, 188.49999999999918, 7.20000000000001, 84.9, 185.79999999999941, 161.09999999999954, 180.99999999999943], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [87.49999999999997, 20.000000000000014, -25.59999999999978, 20.000000000000014, 20.000000000000014, 197.3, 169.3999999999998, 176.0, -61.90000000000067, 20.000000000000014, 20.000000000000014, 30.800000000000196, -13.599999999999783, 25.4000000000001, 83.0, 95.0, 152.2999999999998, 20.000000000000014, 170.0, -9.399999999999855, 115.39999999999998, 64.09999999999998, 20.000000000000014, 20.000000000000014, 200.0, 154.09999999999977, 200.0, 174.79999999999987, -124.90000000000074, -36.699999999999875, -13.599999999999783, 20.000000000000014, -124.90000000000074, 20.000000000000014, 74.59999999999944, 180.2, 20.000000000000014, 13.699999999999966, 20.000000000000014, -11.499999999999883, 20.000000000000014, -118.0, 20.000000000000014, 17.899999999999988, 70.10000000000008, 94.40000000000006, 20.000000000000014, 20.000000000000014, 153.20000000000005, 20.000000000000014, 20.000000000000014, 146.0, 20.000000000000014, -364.4000000000001, 20.000000000000014, 9.499999999999964, 20.000000000000014, -28.899999999999764, 20.000000000000014, 20.000000000000014, 184.6999999999999, 159.5, 195.49999999999997, 20.000000000000014, 20.000000000000014, -3.099999999999958, 20.000000000000014, 20.000000000000014, 20.000000000000014, 11.599999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, -51.39999999999988, 20.000000000000014, 71.29999999999997, 200.0, 20.000000000000014, -31.899999999999785, -75.40000000000069, 141.2, 20.000000000000014, 20.000000000000014, -52.900000000000155, -211.0000000000005, -171.1000000000001, 29.900000000000055, -63.10000000000078, -246.70000000000036, 169.40000000000003, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 116.29999999999998, 20.000000000000014, 101.0, 20.000000000000014, 195.49999999999997, 20.000000000000014, 20.000000000000014, 20.000000000000014, 3.1999999999999615, -146.20000000000044, 189.2, 158.0, 20.000000000000014, 27.20000000000013, 20.000000000000014, -110.80000000000064, -292.29999999999984, 20.000000000000014, 88.39999999999966, -61.600000000000634, -3.099999999999958, 17.899999999999988, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 55.09999999999996, 180.2, 20.000000000000014, 200.0, 20.000000000000014, 5.2999999999999705, 20.000000000000014, 20.000000000000014, 100.10000000000002, 20.000000000000014, -232.00000000000006, 114.19999999999999, 11.59999999999997, 20.000000000000014, 125.6, 20.000000000000014, 158.0, -71.50000000000068, -118.6000000000007, 68.0, 15.799999999999962, -10.599999999999858, 113.59999999999958, -120.70000000000073, 20.000000000000014, 169.4, 179.0, 170.0, 161.0, 122.0, 161.0, 173.0, 1.0999999999999688, 118.09999999999998, 155.90000000000003, 20.000000000000014, 20.000000000000014, 20.000000000000014, 141.5, 20.000000000000014, 20.000000000000014, 20.000000000000014, 169.3999999999999, 9.499999999999964, 183.8, 141.5, -55.599999999999994, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 166.4, 159.19999999999993, -5.19999999999993, 200.0, 20.000000000000014, 20.000000000000014, 185.0, 20.000000000000014, 5.299999999999965, 196.4, 112.69999999999999, 20.000000000000014, 145.1, -3.099999999999958, 20.000000000000014, 20.900000000000027, 20.000000000000014, 168.49999999999986, 177.5, -343.2999999999995, 59.899999999999984, 20.000000000000014, 20.000000000000014, 165.8, 15.799999999999963, 143.3, 140.0, 20.000000000000014], "policy_predator_policy_reward": [0.0, 0.0, 29.0, 0.0, 0.0, 0.0, 0.0, 8.0, 29.0, 35.0, 0.0, 0.0, 0.0, 16.0, 46.0, 14.0, 0.0, 0.0, 14.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 96.0, 0.0, 0.0, 16.0, 59.0, 69.0, 0.0, 7.0, 3.0, 0.0, 15.0, 0.0, 0.0, 106.0, 0.0, 1.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 18.0, 0.0, 209.0, 0.0, 5.0, 0.0, 8.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 43.0, 0.0, 0.0, 0.0, 0.0, 0.0, 48.0, 56.0, 1.0, 0.0, 0.0, 42.0, 168.0, 0.0, 39.0, 35.0, 78.0, 62.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 18.0, 32.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 74.0, 67.0, 13.0, 3.0, 0.0, 0.0, 155.0, 129.0, 0.0, 0.0, 44.0, 11.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 120.0, 26.0, 24.0, 22.0, 12.0, 14.0, 6.0, 72.0, 12.0, 0.0, 45.0, 0.0, 18.0, 20.0, 58.0, 7.0, 0.0, 10.0, 9.0, 0.0, 15.0, 9.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 36.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 12.0, 0.0, 0.0, 5.0, 1.0, 0.0, 7.0, 0.0, 0.0, 7.0, 18.0, 0.0, 0.0, 0.0, 0.0, 173.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 2.0, 13.0, 8.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7583376464940712, "mean_inference_ms": 1.7919620415592312, "mean_action_processing_ms": 0.2992254635067596, "mean_env_wait_ms": 0.2239705739137641, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.013911247253417969, "StateBufferConnector_ms": 0.0055228471755981445, "ViewRequirementAgentConnector_ms": 0.2488260269165039}, "num_episodes": 22, "episode_return_max": 374.79999999999984, "episode_return_min": -214.10000000000073, "episode_return_mean": 115.23399999999984, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 864000, "num_agent_steps_trained": 864000, "num_env_steps_sampled": 216000, "num_env_steps_trained": 216000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 63.03753204156839, "num_env_steps_trained_throughput_per_sec": 63.03753204156839, "timesteps_total": 216000, "num_env_steps_sampled_lifetime": 216000, "num_agent_steps_sampled_lifetime": 864000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 864000, "timers": {"training_iteration_time_ms": 64993.622, "restore_workers_time_ms": 0.016, "training_step_time_ms": 64993.567, "sample_time_ms": 2313.755, "learn_time_ms": 62656.647, "learn_throughput": 63.84, "synch_weights_time_ms": 19.858}, "counters": {"num_env_steps_sampled": 216000, "num_env_steps_trained": 216000, "num_agent_steps_sampled": 864000, "num_agent_steps_trained": 864000}, "done": false, "training_iteration": 54, "trial_id": "11e70_00000", "date": "2024-08-12_23-56-03", "timestamp": 1723521363, "time_this_iter_s": 63.524980306625366, "time_total_s": 2943.0558495521545, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2b675e0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2943.0558495521545, "iterations_since_restore": 54, "perf": {"cpu_util_percent": 76.66222222222221, "ram_util_percent": 83.47777777777777}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.006932981272854, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.28788590935408753, "policy_loss": -0.008239437722004753, "vf_loss": 0.29491496046379245, "vf_explained_var": 0.29301493647237303, "kl": 0.008069237573850281, "entropy": 1.0795894270851498, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 103005.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 6.349355911451672, "cur_kl_coeff": 0.22500000000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.4998458524229665, "policy_loss": -0.009934370697441476, "vf_loss": 5.507966895582815, "vf_explained_var": 0.7617541269965904, "kl": 0.008059267277593112, "entropy": 0.8916022524631844, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 103005.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 220000, "num_env_steps_trained": 220000, "num_agent_steps_sampled": 880000, "num_agent_steps_trained": 880000}, "env_runners": {"episode_reward_max": 370.5, "episode_reward_min": -214.10000000000073, "episode_reward_mean": 136.50599999999974, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -364.4000000000001, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 209.0}, "policy_reward_mean": {"prey_policy": 56.147999999999975, "predator_policy": 12.105}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.0000000000003, 173.19999999999956, 183.99999999999943, -135.40000000000086, 34.50000000000022, 22.100000000000023, 40.0000000000003, 344.2000000000004, 215.49999999999923, 27.90000000000011, 40.0000000000003, 35.600000000000236, 40.0000000000003, 11.599999999999946, 91.30000000000004, 219.99999999999926, -3.2999999999998373, 162.19999999999953, 9.100000000000184, -214.10000000000073, 40.80000000000013, 62.700000000000045, 219.99999999999926, 40.0000000000003, 136.2999999999997, 170.9999999999995, 215.49999999999923, 40.0000000000003, 31.200000000000166, 183.99999999999955, 193.99999999999937, 47.200000000000415, -119.10000000000079, 108.39999999999921, -9.699999999999655, 38.90000000000028, 40.0000000000003, 75.10000000000016, 200.19999999999936, 219.99999999999926, 32.300000000000196, 120.09999999999994, -92.00000000000026, 175.79999999999944, 179.59999999999945, 197.99999999999937, -106.10000000000133, 128.7999999999997, 120.999999999999, -22.69999999999957, 355.4, 350.0, 298.0, 192.0999999999994, 274.00000000000006, 40.0000000000003, 161.49999999999955, 40.0000000000003, 189.39999999999924, 198.29999999999936, 121.89999999999972, 219.99999999999926, 40.0000000000003, 336.60000000000025, 206.79999999999933, 40.0000000000003, 210.9999999999993, 208.6999999999993, 132.6999999999997, 166.99999999999955, 40.90000000000031, 188.49999999999918, 7.20000000000001, 84.9, 185.79999999999941, 161.09999999999954, 180.99999999999943, 40.0000000000003, 207.39999999999932, 362.9, 328.1, 191.1999999999994, 296.4, 211.4999999999993, 348.1, 154.09999999999886, 40.0000000000003, 209.99999999999932, 195.99999999999937, 171.9999999999995, 341.6, 202.89999999999935, 30.10000000000016, 219.99999999999926, 275.7999999999996, 40.0000000000003, 370.5, 207.1999999999993, 367.1, 195.1999999999994], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 20.000000000000014, 153.20000000000005, 20.000000000000014, 20.000000000000014, 146.0, 20.000000000000014, -364.4000000000001, 20.000000000000014, 9.499999999999964, 20.000000000000014, -28.899999999999764, 20.000000000000014, 20.000000000000014, 184.6999999999999, 159.5, 195.49999999999997, 20.000000000000014, 20.000000000000014, -3.099999999999958, 20.000000000000014, 20.000000000000014, 20.000000000000014, 11.599999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, -51.39999999999988, 20.000000000000014, 71.29999999999997, 200.0, 20.000000000000014, -31.899999999999785, -75.40000000000069, 141.2, 20.000000000000014, 20.000000000000014, -52.900000000000155, -211.0000000000005, -171.1000000000001, 29.900000000000055, -63.10000000000078, -246.70000000000036, 169.40000000000003, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 116.29999999999998, 20.000000000000014, 101.0, 20.000000000000014, 195.49999999999997, 20.000000000000014, 20.000000000000014, 20.000000000000014, 3.1999999999999615, -146.20000000000044, 189.2, 158.0, 20.000000000000014, 27.20000000000013, 20.000000000000014, -110.80000000000064, -292.29999999999984, 20.000000000000014, 88.39999999999966, -61.600000000000634, -3.099999999999958, 17.899999999999988, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 55.09999999999996, 180.2, 20.000000000000014, 200.0, 20.000000000000014, 5.2999999999999705, 20.000000000000014, 20.000000000000014, 100.10000000000002, 20.000000000000014, -232.00000000000006, 114.19999999999999, 11.59999999999997, 20.000000000000014, 125.6, 20.000000000000014, 158.0, -71.50000000000068, -118.6000000000007, 68.0, 15.799999999999962, -10.599999999999858, 113.59999999999958, -120.70000000000073, 20.000000000000014, 169.4, 179.0, 170.0, 161.0, 122.0, 161.0, 173.0, 1.0999999999999688, 118.09999999999998, 155.90000000000003, 20.000000000000014, 20.000000000000014, 20.000000000000014, 141.5, 20.000000000000014, 20.000000000000014, 20.000000000000014, 169.3999999999999, 9.499999999999964, 183.8, 141.5, -55.599999999999994, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 166.4, 159.19999999999993, -5.19999999999993, 200.0, 20.000000000000014, 20.000000000000014, 185.0, 20.000000000000014, 5.299999999999965, 196.4, 112.69999999999999, 20.000000000000014, 145.1, -3.099999999999958, 20.000000000000014, 20.900000000000027, 20.000000000000014, 168.49999999999986, 177.5, -343.2999999999995, 59.899999999999984, 20.000000000000014, 20.000000000000014, 165.8, 15.799999999999963, 143.3, 140.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 187.4, 20.000000000000014, 182.9, 167.0, 163.1, 143.0, 20.000000000000014, 171.2, 142.4, 121.99999999999994, 20.000000000000014, 189.5, 200.0, 127.1, 135.1999999999996, 17.899999999999988, 20.000000000000014, 20.000000000000014, 20.000000000000014, 185.0, 20.000000000000014, 164.0, 128.0, 20.000000000000014, 167.6, 161.0, 20.000000000000014, 182.9, 20.000000000000014, 1.0999999999999652, 200.0, 20.000000000000014, 198.2, 77.59999999999997, 20.000000000000014, 20.000000000000014, 185.0, 177.5, 188.3, 17.899999999999984, 167.0, 181.1, 3.1999999999999615, 176.0], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 0.0, 18.0, 0.0, 209.0, 0.0, 5.0, 0.0, 8.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 43.0, 0.0, 0.0, 0.0, 0.0, 0.0, 48.0, 56.0, 1.0, 0.0, 0.0, 42.0, 168.0, 0.0, 39.0, 35.0, 78.0, 62.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 18.0, 32.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 74.0, 67.0, 13.0, 3.0, 0.0, 0.0, 155.0, 129.0, 0.0, 0.0, 44.0, 11.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 120.0, 26.0, 24.0, 22.0, 12.0, 14.0, 6.0, 72.0, 12.0, 0.0, 45.0, 0.0, 18.0, 20.0, 58.0, 7.0, 0.0, 10.0, 9.0, 0.0, 15.0, 9.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 36.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 12.0, 0.0, 0.0, 5.0, 1.0, 0.0, 7.0, 0.0, 0.0, 7.0, 18.0, 0.0, 0.0, 0.0, 0.0, 173.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 2.0, 13.0, 8.0, 0.0, 0.0, 0.0, 0.0, 2.0, 11.0, 22.0, 0.0, 0.0, 0.0, 16.0, 16.0, 0.0, 2.0, 0.0, 21.0, 1.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 12.0, 7.0, 17.0, 13.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 1.0, 0.0, 12.0, 7.0, 8.0, 8.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7689784597258028, "mean_inference_ms": 1.821018735197124, "mean_action_processing_ms": 0.3035368097632948, "mean_env_wait_ms": 0.22754332243031403, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005934715270996094, "StateBufferConnector_ms": 0.0042994022369384766, "ViewRequirementAgentConnector_ms": 0.25389552116394043}, "num_episodes": 23, "episode_return_max": 370.5, "episode_return_min": -214.10000000000073, "episode_return_mean": 136.50599999999974, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 880000, "num_agent_steps_trained": 880000, "num_env_steps_sampled": 220000, "num_env_steps_trained": 220000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 57.775801672059835, "num_env_steps_trained_throughput_per_sec": 57.775801672059835, "timesteps_total": 220000, "num_env_steps_sampled_lifetime": 220000, "num_agent_steps_sampled_lifetime": 880000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 880000, "timers": {"training_iteration_time_ms": 66360.407, "restore_workers_time_ms": 0.016, "training_step_time_ms": 66360.352, "sample_time_ms": 2319.597, "learn_time_ms": 64015.705, "learn_throughput": 62.485, "synch_weights_time_ms": 20.723}, "counters": {"num_env_steps_sampled": 220000, "num_env_steps_trained": 220000, "num_agent_steps_sampled": 880000, "num_agent_steps_trained": 880000}, "done": false, "training_iteration": 55, "trial_id": "11e70_00000", "date": "2024-08-12_23-57-13", "timestamp": 1723521433, "time_this_iter_s": 69.43885803222656, "time_total_s": 3012.494707584381, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3f8af70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3012.494707584381, "iterations_since_restore": 55, "perf": {"cpu_util_percent": 81.32448979591838, "ram_util_percent": 83.24183673469388}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.356670757828566, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.1577362992933817, "policy_loss": -0.00938688800275996, "vf_loss": 1.165605330467224, "vf_explained_var": 0.06716855915765914, "kl": 0.010119047451467795, "entropy": 1.1036790813087787, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 104895.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 7.330768957276824, "cur_kl_coeff": 0.22500000000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.109525354324825, "policy_loss": -0.00881682016896626, "vf_loss": 6.116405517083627, "vf_explained_var": 0.49553263518545365, "kl": 0.00860731897199837, "entropy": 0.8610674854939577, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 104895.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 224000, "num_env_steps_trained": 224000, "num_agent_steps_sampled": 896000, "num_agent_steps_trained": 896000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -568.4999999999998, "episode_reward_mean": 151.98799999999974, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -411.09999999999997, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 62.95399999999997, "predator_policy": 13.04}, "custom_metrics": {}, "hist_stats": {"episode_reward": [9.100000000000184, -214.10000000000073, 40.80000000000013, 62.700000000000045, 219.99999999999926, 40.0000000000003, 136.2999999999997, 170.9999999999995, 215.49999999999923, 40.0000000000003, 31.200000000000166, 183.99999999999955, 193.99999999999937, 47.200000000000415, -119.10000000000079, 108.39999999999921, -9.699999999999655, 38.90000000000028, 40.0000000000003, 75.10000000000016, 200.19999999999936, 219.99999999999926, 32.300000000000196, 120.09999999999994, -92.00000000000026, 175.79999999999944, 179.59999999999945, 197.99999999999937, -106.10000000000133, 128.7999999999997, 120.999999999999, -22.69999999999957, 355.4, 350.0, 298.0, 192.0999999999994, 274.00000000000006, 40.0000000000003, 161.49999999999955, 40.0000000000003, 189.39999999999924, 198.29999999999936, 121.89999999999972, 219.99999999999926, 40.0000000000003, 336.60000000000025, 206.79999999999933, 40.0000000000003, 210.9999999999993, 208.6999999999993, 132.6999999999997, 166.99999999999955, 40.90000000000031, 188.49999999999918, 7.20000000000001, 84.9, 185.79999999999941, 161.09999999999954, 180.99999999999943, 40.0000000000003, 207.39999999999932, 362.9, 328.1, 191.1999999999994, 296.4, 211.4999999999993, 348.1, 154.09999999999886, 40.0000000000003, 209.99999999999932, 195.99999999999937, 171.9999999999995, 341.6, 202.89999999999935, 30.10000000000016, 219.99999999999926, 275.7999999999996, 40.0000000000003, 370.5, 207.1999999999993, 367.1, 195.1999999999994, 91.09999999999987, 391.00000000000017, 35.600000000000236, 400.0, 182.0999999999994, 400.0, 400.0, 176.79999999999947, 197.99999999999937, 122.90000000000002, 400.0, 176.7999999999995, 218.89999999999927, 40.0000000000003, -568.4999999999998, 182.8999999999994, 40.0000000000003, 203.99999999999935], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, -52.900000000000155, -211.0000000000005, -171.1000000000001, 29.900000000000055, -63.10000000000078, -246.70000000000036, 169.40000000000003, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 116.29999999999998, 20.000000000000014, 101.0, 20.000000000000014, 195.49999999999997, 20.000000000000014, 20.000000000000014, 20.000000000000014, 3.1999999999999615, -146.20000000000044, 189.2, 158.0, 20.000000000000014, 27.20000000000013, 20.000000000000014, -110.80000000000064, -292.29999999999984, 20.000000000000014, 88.39999999999966, -61.600000000000634, -3.099999999999958, 17.899999999999988, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 55.09999999999996, 180.2, 20.000000000000014, 200.0, 20.000000000000014, 5.2999999999999705, 20.000000000000014, 20.000000000000014, 100.10000000000002, 20.000000000000014, -232.00000000000006, 114.19999999999999, 11.59999999999997, 20.000000000000014, 125.6, 20.000000000000014, 158.0, -71.50000000000068, -118.6000000000007, 68.0, 15.799999999999962, -10.599999999999858, 113.59999999999958, -120.70000000000073, 20.000000000000014, 169.4, 179.0, 170.0, 161.0, 122.0, 161.0, 173.0, 1.0999999999999688, 118.09999999999998, 155.90000000000003, 20.000000000000014, 20.000000000000014, 20.000000000000014, 141.5, 20.000000000000014, 20.000000000000014, 20.000000000000014, 169.3999999999999, 9.499999999999964, 183.8, 141.5, -55.599999999999994, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 166.4, 159.19999999999993, -5.19999999999993, 200.0, 20.000000000000014, 20.000000000000014, 185.0, 20.000000000000014, 5.299999999999965, 196.4, 112.69999999999999, 20.000000000000014, 145.1, -3.099999999999958, 20.000000000000014, 20.900000000000027, 20.000000000000014, 168.49999999999986, 177.5, -343.2999999999995, 59.899999999999984, 20.000000000000014, 20.000000000000014, 165.8, 15.799999999999963, 143.3, 140.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 187.4, 20.000000000000014, 182.9, 167.0, 163.1, 143.0, 20.000000000000014, 171.2, 142.4, 121.99999999999994, 20.000000000000014, 189.5, 200.0, 127.1, 135.1999999999996, 17.899999999999988, 20.000000000000014, 20.000000000000014, 20.000000000000014, 185.0, 20.000000000000014, 164.0, 128.0, 20.000000000000014, 167.6, 161.0, 20.000000000000014, 182.9, 20.000000000000014, 1.0999999999999652, 200.0, 20.000000000000014, 198.2, 77.59999999999997, 20.000000000000014, 20.000000000000014, 185.0, 177.5, 188.3, 17.899999999999984, 167.0, 181.1, 3.1999999999999615, 176.0, 82.09999999999997, -0.9999999999999846, 193.69999999999996, 197.3, 20.000000000000014, 11.599999999999964, 200.0, 200.0, 20.000000000000014, 148.09999999999997, 200.0, 200.0, 200.0, 200.0, 20.000000000000014, 156.8, 158.0, 20.000000000000014, 200.0, -411.09999999999997, 200.0, 200.0, 20.000000000000014, 156.8, 200.0, 17.899999999999988, 20.000000000000014, 20.000000000000014, -368.50000000000006, -400.0, 152.90000000000003, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 164.0], "policy_predator_policy_reward": [0.0, 42.0, 168.0, 0.0, 39.0, 35.0, 78.0, 62.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 18.0, 32.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 74.0, 67.0, 13.0, 3.0, 0.0, 0.0, 155.0, 129.0, 0.0, 0.0, 44.0, 11.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 120.0, 26.0, 24.0, 22.0, 12.0, 14.0, 6.0, 72.0, 12.0, 0.0, 45.0, 0.0, 18.0, 20.0, 58.0, 7.0, 0.0, 10.0, 9.0, 0.0, 15.0, 9.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 36.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 12.0, 0.0, 0.0, 5.0, 1.0, 0.0, 7.0, 0.0, 0.0, 7.0, 18.0, 0.0, 0.0, 0.0, 0.0, 173.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 2.0, 13.0, 8.0, 0.0, 0.0, 0.0, 0.0, 2.0, 11.0, 22.0, 0.0, 0.0, 0.0, 16.0, 16.0, 0.0, 2.0, 0.0, 21.0, 1.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 12.0, 7.0, 17.0, 13.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 1.0, 0.0, 12.0, 7.0, 8.0, 8.0, 0.0, 10.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 14.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 11.0, 143.0, 191.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 200.0, 10.0, 0.0, 0.0, 0.0, 8.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.780447707793964, "mean_inference_ms": 1.8546813303452756, "mean_action_processing_ms": 0.3088457920094079, "mean_env_wait_ms": 0.23162992930256937, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005921006202697754, "StateBufferConnector_ms": 0.01046454906463623, "ViewRequirementAgentConnector_ms": 0.2671375274658203}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -568.4999999999998, "episode_return_mean": 151.98799999999974, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 896000, "num_agent_steps_trained": 896000, "num_env_steps_sampled": 224000, "num_env_steps_trained": 224000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 57.65545134174694, "num_env_steps_trained_throughput_per_sec": 57.65545134174694, "timesteps_total": 224000, "num_env_steps_sampled_lifetime": 224000, "num_agent_steps_sampled_lifetime": 896000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 896000, "timers": {"training_iteration_time_ms": 67799.097, "restore_workers_time_ms": 0.015, "training_step_time_ms": 67799.043, "sample_time_ms": 2575.079, "learn_time_ms": 65196.939, "learn_throughput": 61.353, "synch_weights_time_ms": 22.506}, "counters": {"num_env_steps_sampled": 224000, "num_env_steps_trained": 224000, "num_agent_steps_sampled": 896000, "num_agent_steps_trained": 896000}, "done": false, "training_iteration": 56, "trial_id": "11e70_00000", "date": "2024-08-12_23-58-23", "timestamp": 1723521503, "time_this_iter_s": 69.43542504310608, "time_total_s": 3081.930132627487, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3f1daf0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3081.930132627487, "iterations_since_restore": 56, "perf": {"cpu_util_percent": 78.45757575757575, "ram_util_percent": 83.62727272727273}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.563651869032118, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.1585276043131238, "policy_loss": -0.003734541673794704, "vf_loss": 1.1613036057778767, "vf_explained_var": 0.06777670052316453, "kl": 0.006390242661358638, "entropy": 1.1120991906791768, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 106785.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 9.218155946302666, "cur_kl_coeff": 0.22500000000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.999200496219453, "policy_loss": -0.012936034287873006, "vf_loss": 7.008528391015592, "vf_explained_var": 0.46433882855233694, "kl": 0.016036172022211175, "entropy": 0.8904215002501452, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 106785.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 228000, "num_env_steps_trained": 228000, "num_agent_steps_sampled": 912000, "num_agent_steps_trained": 912000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -568.4999999999998, "episode_reward_mean": 180.16599999999977, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -537.8, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 385.0}, "policy_reward_mean": {"prey_policy": 76.50299999999999, "predator_policy": 13.58}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.0000000000003, 75.10000000000016, 200.19999999999936, 219.99999999999926, 32.300000000000196, 120.09999999999994, -92.00000000000026, 175.79999999999944, 179.59999999999945, 197.99999999999937, -106.10000000000133, 128.7999999999997, 120.999999999999, -22.69999999999957, 355.4, 350.0, 298.0, 192.0999999999994, 274.00000000000006, 40.0000000000003, 161.49999999999955, 40.0000000000003, 189.39999999999924, 198.29999999999936, 121.89999999999972, 219.99999999999926, 40.0000000000003, 336.60000000000025, 206.79999999999933, 40.0000000000003, 210.9999999999993, 208.6999999999993, 132.6999999999997, 166.99999999999955, 40.90000000000031, 188.49999999999918, 7.20000000000001, 84.9, 185.79999999999941, 161.09999999999954, 180.99999999999943, 40.0000000000003, 207.39999999999932, 362.9, 328.1, 191.1999999999994, 296.4, 211.4999999999993, 348.1, 154.09999999999886, 40.0000000000003, 209.99999999999932, 195.99999999999937, 171.9999999999995, 341.6, 202.89999999999935, 30.10000000000016, 219.99999999999926, 275.7999999999996, 40.0000000000003, 370.5, 207.1999999999993, 367.1, 195.1999999999994, 91.09999999999987, 391.00000000000017, 35.600000000000236, 400.0, 182.0999999999994, 400.0, 400.0, 176.79999999999947, 197.99999999999937, 122.90000000000002, 400.0, 176.7999999999995, 218.89999999999927, 40.0000000000003, -568.4999999999998, 182.8999999999994, 40.0000000000003, 203.99999999999935, 219.99999999999926, 388.3, 45.0000000000001, -41.0, 338.2, 374.8, 219.99999999999926, 181.49999999999943, 165.5999999999995, 36.9, 341.5, 400.0, 400.0, -165.70000000000059, 368.7, 40.0000000000003, 338.0, 362.20000000000005], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 20.000000000000014, 20.000000000000014, 55.09999999999996, 180.2, 20.000000000000014, 200.0, 20.000000000000014, 5.2999999999999705, 20.000000000000014, 20.000000000000014, 100.10000000000002, 20.000000000000014, -232.00000000000006, 114.19999999999999, 11.59999999999997, 20.000000000000014, 125.6, 20.000000000000014, 158.0, -71.50000000000068, -118.6000000000007, 68.0, 15.799999999999962, -10.599999999999858, 113.59999999999958, -120.70000000000073, 20.000000000000014, 169.4, 179.0, 170.0, 161.0, 122.0, 161.0, 173.0, 1.0999999999999688, 118.09999999999998, 155.90000000000003, 20.000000000000014, 20.000000000000014, 20.000000000000014, 141.5, 20.000000000000014, 20.000000000000014, 20.000000000000014, 169.3999999999999, 9.499999999999964, 183.8, 141.5, -55.599999999999994, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 166.4, 159.19999999999993, -5.19999999999993, 200.0, 20.000000000000014, 20.000000000000014, 185.0, 20.000000000000014, 5.299999999999965, 196.4, 112.69999999999999, 20.000000000000014, 145.1, -3.099999999999958, 20.000000000000014, 20.900000000000027, 20.000000000000014, 168.49999999999986, 177.5, -343.2999999999995, 59.899999999999984, 20.000000000000014, 20.000000000000014, 165.8, 15.799999999999963, 143.3, 140.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 187.4, 20.000000000000014, 182.9, 167.0, 163.1, 143.0, 20.000000000000014, 171.2, 142.4, 121.99999999999994, 20.000000000000014, 189.5, 200.0, 127.1, 135.1999999999996, 17.899999999999988, 20.000000000000014, 20.000000000000014, 20.000000000000014, 185.0, 20.000000000000014, 164.0, 128.0, 20.000000000000014, 167.6, 161.0, 20.000000000000014, 182.9, 20.000000000000014, 1.0999999999999652, 200.0, 20.000000000000014, 198.2, 77.59999999999997, 20.000000000000014, 20.000000000000014, 185.0, 177.5, 188.3, 17.899999999999984, 167.0, 181.1, 3.1999999999999615, 176.0, 82.09999999999997, -0.9999999999999846, 193.69999999999996, 197.3, 20.000000000000014, 11.599999999999964, 200.0, 200.0, 20.000000000000014, 148.09999999999997, 200.0, 200.0, 200.0, 200.0, 20.000000000000014, 156.8, 158.0, 20.000000000000014, 200.0, -411.09999999999997, 200.0, 200.0, 20.000000000000014, 156.8, 200.0, 17.899999999999988, 20.000000000000014, 20.000000000000014, -368.50000000000006, -400.0, 152.90000000000003, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 164.0, 200.0, 20.000000000000014, 193.7, 194.6, 155.90000000000003, -229.90000000000018, -385.3, 128.3, 110.0, 198.2, 200.0, 174.8, 200.0, 20.000000000000014, 20.000000000000014, 153.5, 134.60000000000005, 20.000000000000014, -537.8, 187.7, 196.1, 112.4, 200.0, 200.0, 200.0, 200.0, 20.000000000000014, -372.7, 198.2, 162.5, 20.000000000000014, 20.000000000000014, 185.0, 65.0, 200.0, 162.2], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 120.0, 26.0, 24.0, 22.0, 12.0, 14.0, 6.0, 72.0, 12.0, 0.0, 45.0, 0.0, 18.0, 20.0, 58.0, 7.0, 0.0, 10.0, 9.0, 0.0, 15.0, 9.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 36.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 12.0, 0.0, 0.0, 5.0, 1.0, 0.0, 7.0, 0.0, 0.0, 7.0, 18.0, 0.0, 0.0, 0.0, 0.0, 173.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 2.0, 13.0, 8.0, 0.0, 0.0, 0.0, 0.0, 2.0, 11.0, 22.0, 0.0, 0.0, 0.0, 16.0, 16.0, 0.0, 2.0, 0.0, 21.0, 1.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 12.0, 7.0, 17.0, 13.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 1.0, 0.0, 12.0, 7.0, 8.0, 8.0, 0.0, 10.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 14.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 11.0, 143.0, 191.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 200.0, 10.0, 0.0, 0.0, 0.0, 8.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 119.0, 23.0, 193.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 11.0, 2.0, 385.0, 20.0, 13.0, 0.0, 0.0, 0.0, 0.0, 187.0, 0.0, 8.0, 0.0, 0.0, 0.0, 44.0, 44.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7905309960962856, "mean_inference_ms": 1.8843700706018824, "mean_action_processing_ms": 0.31371565078748653, "mean_env_wait_ms": 0.235399077402033, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.008168935775756836, "StateBufferConnector_ms": 0.012005090713500977, "ViewRequirementAgentConnector_ms": 0.2580442428588867}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -568.4999999999998, "episode_return_mean": 180.16599999999977, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 912000, "num_agent_steps_trained": 912000, "num_env_steps_sampled": 228000, "num_env_steps_trained": 228000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 55.55366446021315, "num_env_steps_trained_throughput_per_sec": 55.55366446021315, "timesteps_total": 228000, "num_env_steps_sampled_lifetime": 228000, "num_agent_steps_sampled_lifetime": 912000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 912000, "timers": {"training_iteration_time_ms": 68365.764, "restore_workers_time_ms": 0.015, "training_step_time_ms": 68365.717, "sample_time_ms": 2673.321, "learn_time_ms": 65665.6, "learn_throughput": 60.915, "synch_weights_time_ms": 22.781}, "counters": {"num_env_steps_sampled": 228000, "num_env_steps_trained": 228000, "num_agent_steps_sampled": 912000, "num_agent_steps_trained": 912000}, "done": false, "training_iteration": 57, "trial_id": "11e70_00000", "date": "2024-08-12_23-59-35", "timestamp": 1723521575, "time_this_iter_s": 72.21908497810364, "time_total_s": 3154.149217605591, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2b960d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3154.149217605591, "iterations_since_restore": 57, "perf": {"cpu_util_percent": 81.54313725490196, "ram_util_percent": 83.27549019607844}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.156084296501502, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.9892887529084291, "policy_loss": -0.006732013726744939, "vf_loss": 0.9947440161512642, "vf_explained_var": 0.221643659267476, "kl": 0.00851166524606104, "entropy": 1.0830834126661695, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 108675.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 11.858490187087387, "cur_kl_coeff": 0.22500000000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.081564453417662, "policy_loss": -0.010369555355621275, "vf_loss": 7.090681273344333, "vf_explained_var": 0.750922356837641, "kl": 0.00556776331347113, "entropy": 0.865000957061374, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 108675.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 232000, "num_env_steps_trained": 232000, "num_agent_steps_sampled": 928000, "num_agent_steps_trained": 928000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -568.4999999999998, "episode_reward_mean": 204.4089999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -537.8, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 385.0}, "policy_reward_mean": {"prey_policy": 87.75450000000001, "predator_policy": 14.45}, "custom_metrics": {}, "hist_stats": {"episode_reward": [189.39999999999924, 198.29999999999936, 121.89999999999972, 219.99999999999926, 40.0000000000003, 336.60000000000025, 206.79999999999933, 40.0000000000003, 210.9999999999993, 208.6999999999993, 132.6999999999997, 166.99999999999955, 40.90000000000031, 188.49999999999918, 7.20000000000001, 84.9, 185.79999999999941, 161.09999999999954, 180.99999999999943, 40.0000000000003, 207.39999999999932, 362.9, 328.1, 191.1999999999994, 296.4, 211.4999999999993, 348.1, 154.09999999999886, 40.0000000000003, 209.99999999999932, 195.99999999999937, 171.9999999999995, 341.6, 202.89999999999935, 30.10000000000016, 219.99999999999926, 275.7999999999996, 40.0000000000003, 370.5, 207.1999999999993, 367.1, 195.1999999999994, 91.09999999999987, 391.00000000000017, 35.600000000000236, 400.0, 182.0999999999994, 400.0, 400.0, 176.79999999999947, 197.99999999999937, 122.90000000000002, 400.0, 176.7999999999995, 218.89999999999927, 40.0000000000003, -568.4999999999998, 182.8999999999994, 40.0000000000003, 203.99999999999935, 219.99999999999926, 388.3, 45.0000000000001, -41.0, 338.2, 374.8, 219.99999999999926, 181.49999999999943, 165.5999999999995, 36.9, 341.5, 400.0, 400.0, -165.70000000000059, 368.7, 40.0000000000003, 338.0, 362.20000000000005, 219.99999999999926, 171.7000000000001, 179.19999999999945, 320.5000000000001, 375.9, 37.80000000000027, -171.00000000000068, 357.8, 380.0, 357.6000000000001, 319.1000000000002, 285.6999999999997, 205.99999999999932, 308.8, 188.79999999999944, 214.50000000000003, 208.0999999999993, 333.6, 400.0, 311.29999999999995, 215.99999999999926, 183.99999999999943], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 169.3999999999999, 9.499999999999964, 183.8, 141.5, -55.599999999999994, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 166.4, 159.19999999999993, -5.19999999999993, 200.0, 20.000000000000014, 20.000000000000014, 185.0, 20.000000000000014, 5.299999999999965, 196.4, 112.69999999999999, 20.000000000000014, 145.1, -3.099999999999958, 20.000000000000014, 20.900000000000027, 20.000000000000014, 168.49999999999986, 177.5, -343.2999999999995, 59.899999999999984, 20.000000000000014, 20.000000000000014, 165.8, 15.799999999999963, 143.3, 140.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 187.4, 20.000000000000014, 182.9, 167.0, 163.1, 143.0, 20.000000000000014, 171.2, 142.4, 121.99999999999994, 20.000000000000014, 189.5, 200.0, 127.1, 135.1999999999996, 17.899999999999988, 20.000000000000014, 20.000000000000014, 20.000000000000014, 185.0, 20.000000000000014, 164.0, 128.0, 20.000000000000014, 167.6, 161.0, 20.000000000000014, 182.9, 20.000000000000014, 1.0999999999999652, 200.0, 20.000000000000014, 198.2, 77.59999999999997, 20.000000000000014, 20.000000000000014, 185.0, 177.5, 188.3, 17.899999999999984, 167.0, 181.1, 3.1999999999999615, 176.0, 82.09999999999997, -0.9999999999999846, 193.69999999999996, 197.3, 20.000000000000014, 11.599999999999964, 200.0, 200.0, 20.000000000000014, 148.09999999999997, 200.0, 200.0, 200.0, 200.0, 20.000000000000014, 156.8, 158.0, 20.000000000000014, 200.0, -411.09999999999997, 200.0, 200.0, 20.000000000000014, 156.8, 200.0, 17.899999999999988, 20.000000000000014, 20.000000000000014, -368.50000000000006, -400.0, 152.90000000000003, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 164.0, 200.0, 20.000000000000014, 193.7, 194.6, 155.90000000000003, -229.90000000000018, -385.3, 128.3, 110.0, 198.2, 200.0, 174.8, 200.0, 20.000000000000014, 20.000000000000014, 153.5, 134.60000000000005, 20.000000000000014, -537.8, 187.7, 196.1, 112.4, 200.0, 200.0, 200.0, 200.0, 20.000000000000014, -372.7, 198.2, 162.5, 20.000000000000014, 20.000000000000014, 185.0, 65.0, 200.0, 162.2, 200.0, 20.000000000000014, 89.29999999999997, 25.399999999999977, 185.0, -38.799999999999855, 167.0, 132.49999999999997, 173.0, 191.9, 20.000000000000014, 15.799999999999963, -463.6, 11.599999999999964, 188.0, 165.8, 200.0, 170.0, 171.2, 172.39999999999998, 197.3, 66.80000000000001, 85.69999999999997, 200.0, 20.000000000000014, 179.0, 146.0, 138.79999999999998, 165.8, 20.000000000000014, 111.50000000000001, 76.99999999999997, 20.000000000000014, 175.1, 127.4, 138.2, 200.0, 200.0, 150.2, 130.1, 198.2, 15.799999999999963, 20.000000000000014, 137.0], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 5.0, 0.0, 36.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 12.0, 0.0, 0.0, 5.0, 1.0, 0.0, 7.0, 0.0, 0.0, 7.0, 18.0, 0.0, 0.0, 0.0, 0.0, 173.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 2.0, 13.0, 8.0, 0.0, 0.0, 0.0, 0.0, 2.0, 11.0, 22.0, 0.0, 0.0, 0.0, 16.0, 16.0, 0.0, 2.0, 0.0, 21.0, 1.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 12.0, 7.0, 17.0, 13.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 1.0, 0.0, 12.0, 7.0, 8.0, 8.0, 0.0, 10.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 14.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 11.0, 143.0, 191.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 200.0, 10.0, 0.0, 0.0, 0.0, 8.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 119.0, 23.0, 193.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 11.0, 2.0, 385.0, 20.0, 13.0, 0.0, 0.0, 0.0, 0.0, 187.0, 0.0, 8.0, 0.0, 0.0, 0.0, 44.0, 44.0, 0.0, 0.0, 0.0, 0.0, 36.0, 21.0, 28.0, 5.0, 0.0, 21.0, 8.0, 3.0, 2.0, 0.0, 4.0, 277.0, 0.0, 4.0, 0.0, 10.0, 14.0, 0.0, 37.0, 18.0, 0.0, 0.0, 7.0, 0.0, 10.0, 14.0, 3.0, 0.0, 5.0, 21.0, 8.0, 5.0, 29.0, 39.0, 0.0, 0.0, 0.0, 31.0, 0.0, 2.0, 9.0, 18.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8131089673063463, "mean_inference_ms": 1.9495327096929953, "mean_action_processing_ms": 0.3233342418372682, "mean_env_wait_ms": 0.24482478713833453, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.008571147918701172, "StateBufferConnector_ms": 0.0573040246963501, "ViewRequirementAgentConnector_ms": 0.38998544216156006}, "num_episodes": 22, "episode_return_max": 400.0, "episode_return_min": -568.4999999999998, "episode_return_mean": 204.4089999999998, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 928000, "num_agent_steps_trained": 928000, "num_env_steps_sampled": 232000, "num_env_steps_trained": 232000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 49.999664279092485, "num_env_steps_trained_throughput_per_sec": 49.999664279092485, "timesteps_total": 232000, "num_env_steps_sampled_lifetime": 232000, "num_agent_steps_sampled_lifetime": 928000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 928000, "timers": {"training_iteration_time_ms": 70028.942, "restore_workers_time_ms": 0.016, "training_step_time_ms": 70028.894, "sample_time_ms": 3450.519, "learn_time_ms": 66550.801, "learn_throughput": 60.104, "synch_weights_time_ms": 22.846}, "counters": {"num_env_steps_sampled": 232000, "num_env_steps_trained": 232000, "num_agent_steps_sampled": 928000, "num_agent_steps_trained": 928000}, "done": false, "training_iteration": 58, "trial_id": "11e70_00000", "date": "2024-08-13_00-00-55", "timestamp": 1723521655, "time_this_iter_s": 80.09084796905518, "time_total_s": 3234.240065574646, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2ae63a0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3234.240065574646, "iterations_since_restore": 58, "perf": {"cpu_util_percent": 83.41946902654867, "ram_util_percent": 83.62300884955752}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.063580871984441, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.4654854358898269, "policy_loss": -0.00834239420737263, "vf_loss": 0.4727183539996899, "vf_explained_var": 0.3291382931527637, "kl": 0.007396507423653123, "entropy": 1.0838824603923414, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 110565.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 16.655892559207935, "cur_kl_coeff": 0.22500000000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.869464164562326, "policy_loss": -0.01081893008286084, "vf_loss": 5.8790080872793045, "vf_explained_var": 0.816574351718186, "kl": 0.005666737101553941, "entropy": 0.7930756808588745, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 110565.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 236000, "num_env_steps_trained": 236000, "num_agent_steps_sampled": 944000, "num_agent_steps_trained": 944000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -568.4999999999998, "episode_reward_mean": 228.3809999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -537.8, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 385.0}, "policy_reward_mean": {"prey_policy": 99.8055, "predator_policy": 14.385}, "custom_metrics": {}, "hist_stats": {"episode_reward": [180.99999999999943, 40.0000000000003, 207.39999999999932, 362.9, 328.1, 191.1999999999994, 296.4, 211.4999999999993, 348.1, 154.09999999999886, 40.0000000000003, 209.99999999999932, 195.99999999999937, 171.9999999999995, 341.6, 202.89999999999935, 30.10000000000016, 219.99999999999926, 275.7999999999996, 40.0000000000003, 370.5, 207.1999999999993, 367.1, 195.1999999999994, 91.09999999999987, 391.00000000000017, 35.600000000000236, 400.0, 182.0999999999994, 400.0, 400.0, 176.79999999999947, 197.99999999999937, 122.90000000000002, 400.0, 176.7999999999995, 218.89999999999927, 40.0000000000003, -568.4999999999998, 182.8999999999994, 40.0000000000003, 203.99999999999935, 219.99999999999926, 388.3, 45.0000000000001, -41.0, 338.2, 374.8, 219.99999999999926, 181.49999999999943, 165.5999999999995, 36.9, 341.5, 400.0, 400.0, -165.70000000000059, 368.7, 40.0000000000003, 338.0, 362.20000000000005, 219.99999999999926, 171.7000000000001, 179.19999999999945, 320.5000000000001, 375.9, 37.80000000000027, -171.00000000000068, 357.8, 380.0, 357.6000000000001, 319.1000000000002, 285.6999999999997, 205.99999999999932, 308.8, 188.79999999999944, 214.50000000000003, 208.0999999999993, 333.6, 400.0, 311.29999999999995, 215.99999999999926, 183.99999999999943, 372.1, 269.8999999999999, 181.99999999999946, 400.0, 343.1, 32.30000000000018, 214.19999999999928, 305.8, 181.99999999999943, 217.99999999999926, 205.99999999999932, 353.7, 392.8, 381.00000000000006, 288.40000000000003, 307.4, 349.1, 340.2], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [140.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 187.4, 20.000000000000014, 182.9, 167.0, 163.1, 143.0, 20.000000000000014, 171.2, 142.4, 121.99999999999994, 20.000000000000014, 189.5, 200.0, 127.1, 135.1999999999996, 17.899999999999988, 20.000000000000014, 20.000000000000014, 20.000000000000014, 185.0, 20.000000000000014, 164.0, 128.0, 20.000000000000014, 167.6, 161.0, 20.000000000000014, 182.9, 20.000000000000014, 1.0999999999999652, 200.0, 20.000000000000014, 198.2, 77.59999999999997, 20.000000000000014, 20.000000000000014, 185.0, 177.5, 188.3, 17.899999999999984, 167.0, 181.1, 3.1999999999999615, 176.0, 82.09999999999997, -0.9999999999999846, 193.69999999999996, 197.3, 20.000000000000014, 11.599999999999964, 200.0, 200.0, 20.000000000000014, 148.09999999999997, 200.0, 200.0, 200.0, 200.0, 20.000000000000014, 156.8, 158.0, 20.000000000000014, 200.0, -411.09999999999997, 200.0, 200.0, 20.000000000000014, 156.8, 200.0, 17.899999999999988, 20.000000000000014, 20.000000000000014, -368.50000000000006, -400.0, 152.90000000000003, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 164.0, 200.0, 20.000000000000014, 193.7, 194.6, 155.90000000000003, -229.90000000000018, -385.3, 128.3, 110.0, 198.2, 200.0, 174.8, 200.0, 20.000000000000014, 20.000000000000014, 153.5, 134.60000000000005, 20.000000000000014, -537.8, 187.7, 196.1, 112.4, 200.0, 200.0, 200.0, 200.0, 20.000000000000014, -372.7, 198.2, 162.5, 20.000000000000014, 20.000000000000014, 185.0, 65.0, 200.0, 162.2, 200.0, 20.000000000000014, 89.29999999999997, 25.399999999999977, 185.0, -38.799999999999855, 167.0, 132.49999999999997, 173.0, 191.9, 20.000000000000014, 15.799999999999963, -463.6, 11.599999999999964, 188.0, 165.8, 200.0, 170.0, 171.2, 172.39999999999998, 197.3, 66.80000000000001, 85.69999999999997, 200.0, 20.000000000000014, 179.0, 146.0, 138.79999999999998, 165.8, 20.000000000000014, 111.50000000000001, 76.99999999999997, 20.000000000000014, 175.1, 127.4, 138.2, 200.0, 200.0, 150.2, 130.1, 198.2, 15.799999999999963, 20.000000000000014, 137.0, 172.1, 200.0, 152.0, 101.89999999999998, 143.0, 20.000000000000014, 200.0, 200.0, 173.0, 151.1, 20.000000000000014, 5.299999999999965, 192.2, 20.000000000000014, 160.7, 115.1, 143.0, 20.000000000000014, 20.000000000000014, 197.0, 179.0, 20.000000000000014, 109.7, 200.0, 200.0, 192.8, 180.5, 195.49999999999997, 182.0, 79.39999999999999, 143.0, 142.39999999999998, 192.8, 122.3, 171.2, 152.0], "policy_predator_policy_reward": [13.0, 8.0, 0.0, 0.0, 0.0, 0.0, 2.0, 11.0, 22.0, 0.0, 0.0, 0.0, 16.0, 16.0, 0.0, 2.0, 0.0, 21.0, 1.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 12.0, 7.0, 17.0, 13.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 1.0, 0.0, 12.0, 7.0, 8.0, 8.0, 0.0, 10.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 14.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 11.0, 143.0, 191.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 200.0, 10.0, 0.0, 0.0, 0.0, 8.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 119.0, 23.0, 193.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 11.0, 2.0, 385.0, 20.0, 13.0, 0.0, 0.0, 0.0, 0.0, 187.0, 0.0, 8.0, 0.0, 0.0, 0.0, 44.0, 44.0, 0.0, 0.0, 0.0, 0.0, 36.0, 21.0, 28.0, 5.0, 0.0, 21.0, 8.0, 3.0, 2.0, 0.0, 4.0, 277.0, 0.0, 4.0, 0.0, 10.0, 14.0, 0.0, 37.0, 18.0, 0.0, 0.0, 7.0, 0.0, 10.0, 14.0, 3.0, 0.0, 5.0, 21.0, 8.0, 5.0, 29.0, 39.0, 0.0, 0.0, 0.0, 31.0, 0.0, 2.0, 9.0, 18.0, 0.0, 0.0, 0.0, 16.0, 0.0, 19.0, 0.0, 0.0, 0.0, 19.0, 7.0, 0.0, 2.0, 0.0, 6.0, 24.0, 4.0, 15.0, 0.0, 1.0, 7.0, 0.0, 17.0, 27.0, 0.0, 0.0, 0.0, 5.0, 27.0, 0.0, 14.0, 8.0, 13.0, 21.0, 15.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8309635565541588, "mean_inference_ms": 2.0010738035550593, "mean_action_processing_ms": 0.3303374458705953, "mean_env_wait_ms": 0.25220610100653323, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.008678793907165527, "StateBufferConnector_ms": 0.057346343994140625, "ViewRequirementAgentConnector_ms": 0.38252735137939453}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -568.4999999999998, "episode_return_mean": 228.3809999999998, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 944000, "num_agent_steps_trained": 944000, "num_env_steps_sampled": 236000, "num_env_steps_trained": 236000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 55.59159981548346, "num_env_steps_trained_throughput_per_sec": 55.59159981548346, "timesteps_total": 236000, "num_env_steps_sampled_lifetime": 236000, "num_agent_steps_sampled_lifetime": 944000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 944000, "timers": {"training_iteration_time_ms": 70952.833, "restore_workers_time_ms": 0.016, "training_step_time_ms": 70952.785, "sample_time_ms": 3268.16, "learn_time_ms": 67657.385, "learn_throughput": 59.121, "synch_weights_time_ms": 22.419}, "counters": {"num_env_steps_sampled": 236000, "num_env_steps_trained": 236000, "num_agent_steps_sampled": 944000, "num_agent_steps_trained": 944000}, "done": false, "training_iteration": 59, "trial_id": "11e70_00000", "date": "2024-08-13_00-02-07", "timestamp": 1723521727, "time_this_iter_s": 72.01767897605896, "time_total_s": 3306.257744550705, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2b96160>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3306.257744550705, "iterations_since_restore": 59, "perf": {"cpu_util_percent": 84.67549019607844, "ram_util_percent": 83.61470588235291}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.9248668186563664, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.3948870977199582, "policy_loss": -0.008063657918609876, "vf_loss": 0.40178164101388086, "vf_explained_var": 0.3494908213930786, "kl": 0.007794094502576942, "entropy": 1.0618655931381953, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 112455.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 19.83389522751803, "cur_kl_coeff": 0.22500000000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.250615207480375, "policy_loss": -0.011771727369595615, "vf_loss": 5.260886919939959, "vf_explained_var": 0.662757517704888, "kl": 0.006666778747564231, "entropy": 0.7305808203876334, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 112455.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 240000, "num_env_steps_trained": 240000, "num_agent_steps_sampled": 960000, "num_agent_steps_trained": 960000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -568.4999999999998, "episode_reward_mean": 243.72099999999983, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -537.8, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 385.0}, "policy_reward_mean": {"prey_policy": 106.87049999999999, "predator_policy": 14.99}, "custom_metrics": {}, "hist_stats": {"episode_reward": [195.1999999999994, 91.09999999999987, 391.00000000000017, 35.600000000000236, 400.0, 182.0999999999994, 400.0, 400.0, 176.79999999999947, 197.99999999999937, 122.90000000000002, 400.0, 176.7999999999995, 218.89999999999927, 40.0000000000003, -568.4999999999998, 182.8999999999994, 40.0000000000003, 203.99999999999935, 219.99999999999926, 388.3, 45.0000000000001, -41.0, 338.2, 374.8, 219.99999999999926, 181.49999999999943, 165.5999999999995, 36.9, 341.5, 400.0, 400.0, -165.70000000000059, 368.7, 40.0000000000003, 338.0, 362.20000000000005, 219.99999999999926, 171.7000000000001, 179.19999999999945, 320.5000000000001, 375.9, 37.80000000000027, -171.00000000000068, 357.8, 380.0, 357.6000000000001, 319.1000000000002, 285.6999999999997, 205.99999999999932, 308.8, 188.79999999999944, 214.50000000000003, 208.0999999999993, 333.6, 400.0, 311.29999999999995, 215.99999999999926, 183.99999999999943, 372.1, 269.8999999999999, 181.99999999999946, 400.0, 343.1, 32.30000000000018, 214.19999999999928, 305.8, 181.99999999999943, 217.99999999999926, 205.99999999999932, 353.7, 392.8, 381.00000000000006, 288.40000000000003, 307.4, 349.1, 340.2, 162.79999999999956, 347.80000000000007, 302.9, 290.1999999999997, 352.3, 350.6, 198.99999999999935, 309.0999999999998, 186.99999999999943, 40.0000000000003, 261.29999999999984, 350.3, 332.5, 353.20000000000005, 212.2999999999993, 365.80000000000007, 364.89999999999986, 219.99999999999926, 282.0, 215.49999999999926, 366.0, 349.4, 312.9999999999999], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [3.1999999999999615, 176.0, 82.09999999999997, -0.9999999999999846, 193.69999999999996, 197.3, 20.000000000000014, 11.599999999999964, 200.0, 200.0, 20.000000000000014, 148.09999999999997, 200.0, 200.0, 200.0, 200.0, 20.000000000000014, 156.8, 158.0, 20.000000000000014, 200.0, -411.09999999999997, 200.0, 200.0, 20.000000000000014, 156.8, 200.0, 17.899999999999988, 20.000000000000014, 20.000000000000014, -368.50000000000006, -400.0, 152.90000000000003, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 164.0, 200.0, 20.000000000000014, 193.7, 194.6, 155.90000000000003, -229.90000000000018, -385.3, 128.3, 110.0, 198.2, 200.0, 174.8, 200.0, 20.000000000000014, 20.000000000000014, 153.5, 134.60000000000005, 20.000000000000014, -537.8, 187.7, 196.1, 112.4, 200.0, 200.0, 200.0, 200.0, 20.000000000000014, -372.7, 198.2, 162.5, 20.000000000000014, 20.000000000000014, 185.0, 65.0, 200.0, 162.2, 200.0, 20.000000000000014, 89.29999999999997, 25.399999999999977, 185.0, -38.799999999999855, 167.0, 132.49999999999997, 173.0, 191.9, 20.000000000000014, 15.799999999999963, -463.6, 11.599999999999964, 188.0, 165.8, 200.0, 170.0, 171.2, 172.39999999999998, 197.3, 66.80000000000001, 85.69999999999997, 200.0, 20.000000000000014, 179.0, 146.0, 138.79999999999998, 165.8, 20.000000000000014, 111.50000000000001, 76.99999999999997, 20.000000000000014, 175.1, 127.4, 138.2, 200.0, 200.0, 150.2, 130.1, 198.2, 15.799999999999963, 20.000000000000014, 137.0, 172.1, 200.0, 152.0, 101.89999999999998, 143.0, 20.000000000000014, 200.0, 200.0, 173.0, 151.1, 20.000000000000014, 5.299999999999965, 192.2, 20.000000000000014, 160.7, 115.1, 143.0, 20.000000000000014, 20.000000000000014, 197.0, 179.0, 20.000000000000014, 109.7, 200.0, 200.0, 192.8, 180.5, 195.49999999999997, 182.0, 79.39999999999999, 143.0, 142.39999999999998, 192.8, 122.3, 171.2, 152.0, 170.3, -32.49999999999984, 200.0, 147.8, 170.0, 101.90000000000003, 196.4, 93.79999999999998, 173.3, 170.0, 166.4, 150.2, 185.0, -0.9999999999999917, 109.09999999999998, 200.0, 149.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 155.3, 91.99999999999997, 189.2, 160.1, 133.1, 151.4, 158.6, 194.6, 5.299999999999965, 200.0, 200.0, 165.8, 166.70000000000002, 198.2, 20.000000000000014, 200.0, 71.0, 155.0, 195.5, 20.000000000000014, 137.0, 194.0, 158.0, 163.4, 191.0, 118.99999999999999], "policy_predator_policy_reward": [8.0, 8.0, 0.0, 10.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 14.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 11.0, 143.0, 191.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 200.0, 10.0, 0.0, 0.0, 0.0, 8.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 119.0, 23.0, 193.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 11.0, 2.0, 385.0, 20.0, 13.0, 0.0, 0.0, 0.0, 0.0, 187.0, 0.0, 8.0, 0.0, 0.0, 0.0, 44.0, 44.0, 0.0, 0.0, 0.0, 0.0, 36.0, 21.0, 28.0, 5.0, 0.0, 21.0, 8.0, 3.0, 2.0, 0.0, 4.0, 277.0, 0.0, 4.0, 0.0, 10.0, 14.0, 0.0, 37.0, 18.0, 0.0, 0.0, 7.0, 0.0, 10.0, 14.0, 3.0, 0.0, 5.0, 21.0, 8.0, 5.0, 29.0, 39.0, 0.0, 0.0, 0.0, 31.0, 0.0, 2.0, 9.0, 18.0, 0.0, 0.0, 0.0, 16.0, 0.0, 19.0, 0.0, 0.0, 0.0, 19.0, 7.0, 0.0, 2.0, 0.0, 6.0, 24.0, 4.0, 15.0, 0.0, 1.0, 7.0, 0.0, 17.0, 27.0, 0.0, 0.0, 0.0, 5.0, 27.0, 0.0, 14.0, 8.0, 13.0, 21.0, 15.0, 2.0, 0.0, 25.0, 0.0, 0.0, 0.0, 31.0, 0.0, 0.0, 9.0, 0.0, 14.0, 20.0, 10.0, 5.0, 0.0, 0.0, 11.0, 7.0, 0.0, 0.0, 0.0, 14.0, 1.0, 0.0, 27.0, 21.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 45.0, 0.0, 0.0, 19.0, 16.0, 14.0, 14.0, 3.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8548461993838954, "mean_inference_ms": 2.0677466801644506, "mean_action_processing_ms": 0.34019181055136344, "mean_env_wait_ms": 0.26153653386815034, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.009929656982421875, "StateBufferConnector_ms": 0.05862903594970703, "ViewRequirementAgentConnector_ms": 0.38265907764434814}, "num_episodes": 23, "episode_return_max": 400.0, "episode_return_min": -568.4999999999998, "episode_return_mean": 243.72099999999983, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 960000, "num_agent_steps_trained": 960000, "num_env_steps_sampled": 240000, "num_env_steps_trained": 240000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 56.25249590623096, "num_env_steps_trained_throughput_per_sec": 56.25249590623096, "timesteps_total": 240000, "num_env_steps_sampled_lifetime": 240000, "num_agent_steps_sampled_lifetime": 960000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 960000, "timers": {"training_iteration_time_ms": 71824.213, "restore_workers_time_ms": 0.017, "training_step_time_ms": 71824.16, "sample_time_ms": 3323.522, "learn_time_ms": 68473.705, "learn_throughput": 58.417, "synch_weights_time_ms": 21.447}, "counters": {"num_env_steps_sampled": 240000, "num_env_steps_trained": 240000, "num_agent_steps_sampled": 960000, "num_agent_steps_trained": 960000}, "done": false, "training_iteration": 60, "trial_id": "11e70_00000", "date": "2024-08-13_00-03-19", "timestamp": 1723521799, "time_this_iter_s": 71.33830189704895, "time_total_s": 3377.596046447754, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3f6f5e0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3377.596046447754, "iterations_since_restore": 60, "perf": {"cpu_util_percent": 81.30882352941177, "ram_util_percent": 83.25196078431371}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.281578150943473, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.5730848483859546, "policy_loss": -0.007559086755410862, "vf_loss": 0.5790092334841137, "vf_explained_var": 0.13238269437557806, "kl": 0.010898018497163509, "entropy": 1.042075435572831, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 114345.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 22.017720993990622, "cur_kl_coeff": 0.22500000000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.8430112325325214, "policy_loss": -0.008850276248687238, "vf_loss": 3.851017673558028, "vf_explained_var": 0.4959539760672857, "kl": 0.0037504072310523113, "entropy": 0.6449119461276543, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 114345.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 244000, "num_env_steps_trained": 244000, "num_agent_steps_sampled": 976000, "num_agent_steps_trained": 976000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -171.00000000000068, "episode_reward_mean": 272.4749999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -537.8, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 385.0}, "policy_reward_mean": {"prey_policy": 123.1575, "predator_policy": 13.08}, "custom_metrics": {}, "hist_stats": {"episode_reward": [203.99999999999935, 219.99999999999926, 388.3, 45.0000000000001, -41.0, 338.2, 374.8, 219.99999999999926, 181.49999999999943, 165.5999999999995, 36.9, 341.5, 400.0, 400.0, -165.70000000000059, 368.7, 40.0000000000003, 338.0, 362.20000000000005, 219.99999999999926, 171.7000000000001, 179.19999999999945, 320.5000000000001, 375.9, 37.80000000000027, -171.00000000000068, 357.8, 380.0, 357.6000000000001, 319.1000000000002, 285.6999999999997, 205.99999999999932, 308.8, 188.79999999999944, 214.50000000000003, 208.0999999999993, 333.6, 400.0, 311.29999999999995, 215.99999999999926, 183.99999999999943, 372.1, 269.8999999999999, 181.99999999999946, 400.0, 343.1, 32.30000000000018, 214.19999999999928, 305.8, 181.99999999999943, 217.99999999999926, 205.99999999999932, 353.7, 392.8, 381.00000000000006, 288.40000000000003, 307.4, 349.1, 340.2, 162.79999999999956, 347.80000000000007, 302.9, 290.1999999999997, 352.3, 350.6, 198.99999999999935, 309.0999999999998, 186.99999999999943, 40.0000000000003, 261.29999999999984, 350.3, 332.5, 353.20000000000005, 212.2999999999993, 365.80000000000007, 364.89999999999986, 219.99999999999926, 282.0, 215.49999999999926, 366.0, 349.4, 312.9999999999999, 388.2, 393.7, 240.7, 205.19999999999996, 323.1, 329.2, 359.0, 372.4, 344.7, 350.1, 329.79999999999995, 338.1, 296.70000000000005, 335.2, 400.0, 385.5, 380.2, 186.3999999999994], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 164.0, 200.0, 20.000000000000014, 193.7, 194.6, 155.90000000000003, -229.90000000000018, -385.3, 128.3, 110.0, 198.2, 200.0, 174.8, 200.0, 20.000000000000014, 20.000000000000014, 153.5, 134.60000000000005, 20.000000000000014, -537.8, 187.7, 196.1, 112.4, 200.0, 200.0, 200.0, 200.0, 20.000000000000014, -372.7, 198.2, 162.5, 20.000000000000014, 20.000000000000014, 185.0, 65.0, 200.0, 162.2, 200.0, 20.000000000000014, 89.29999999999997, 25.399999999999977, 185.0, -38.799999999999855, 167.0, 132.49999999999997, 173.0, 191.9, 20.000000000000014, 15.799999999999963, -463.6, 11.599999999999964, 188.0, 165.8, 200.0, 170.0, 171.2, 172.39999999999998, 197.3, 66.80000000000001, 85.69999999999997, 200.0, 20.000000000000014, 179.0, 146.0, 138.79999999999998, 165.8, 20.000000000000014, 111.50000000000001, 76.99999999999997, 20.000000000000014, 175.1, 127.4, 138.2, 200.0, 200.0, 150.2, 130.1, 198.2, 15.799999999999963, 20.000000000000014, 137.0, 172.1, 200.0, 152.0, 101.89999999999998, 143.0, 20.000000000000014, 200.0, 200.0, 173.0, 151.1, 20.000000000000014, 5.299999999999965, 192.2, 20.000000000000014, 160.7, 115.1, 143.0, 20.000000000000014, 20.000000000000014, 197.0, 179.0, 20.000000000000014, 109.7, 200.0, 200.0, 192.8, 180.5, 195.49999999999997, 182.0, 79.39999999999999, 143.0, 142.39999999999998, 192.8, 122.3, 171.2, 152.0, 170.3, -32.49999999999984, 200.0, 147.8, 170.0, 101.90000000000003, 196.4, 93.79999999999998, 173.3, 170.0, 166.4, 150.2, 185.0, -0.9999999999999917, 109.09999999999998, 200.0, 149.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 155.3, 91.99999999999997, 189.2, 160.1, 133.1, 151.4, 158.6, 194.6, 5.299999999999965, 200.0, 200.0, 165.8, 166.70000000000002, 198.2, 20.000000000000014, 200.0, 71.0, 155.0, 195.5, 20.000000000000014, 137.0, 194.0, 158.0, 163.4, 191.0, 118.99999999999999, 198.2, 185.0, 199.1, 194.6, 143.3, 97.39999999999998, -24.700000000000003, 182.9, 145.7, 154.39999999999998, 175.7, 135.5, 137.0, 200.0, 191.0, 178.4, 166.7, 158.0, 166.1, 173.0, 133.39999999999998, 196.4, 148.1, 161.0, 137.0, 130.7, 135.2, 200.0, 200.0, 200.0, 196.4, 184.1, 192.8, 187.4, 151.4, 20.000000000000014], "policy_predator_policy_reward": [8.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 119.0, 23.0, 193.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 11.0, 2.0, 385.0, 20.0, 13.0, 0.0, 0.0, 0.0, 0.0, 187.0, 0.0, 8.0, 0.0, 0.0, 0.0, 44.0, 44.0, 0.0, 0.0, 0.0, 0.0, 36.0, 21.0, 28.0, 5.0, 0.0, 21.0, 8.0, 3.0, 2.0, 0.0, 4.0, 277.0, 0.0, 4.0, 0.0, 10.0, 14.0, 0.0, 37.0, 18.0, 0.0, 0.0, 7.0, 0.0, 10.0, 14.0, 3.0, 0.0, 5.0, 21.0, 8.0, 5.0, 29.0, 39.0, 0.0, 0.0, 0.0, 31.0, 0.0, 2.0, 9.0, 18.0, 0.0, 0.0, 0.0, 16.0, 0.0, 19.0, 0.0, 0.0, 0.0, 19.0, 7.0, 0.0, 2.0, 0.0, 6.0, 24.0, 4.0, 15.0, 0.0, 1.0, 7.0, 0.0, 17.0, 27.0, 0.0, 0.0, 0.0, 5.0, 27.0, 0.0, 14.0, 8.0, 13.0, 21.0, 15.0, 2.0, 0.0, 25.0, 0.0, 0.0, 0.0, 31.0, 0.0, 0.0, 9.0, 0.0, 14.0, 20.0, 10.0, 5.0, 0.0, 0.0, 11.0, 7.0, 0.0, 0.0, 0.0, 14.0, 1.0, 0.0, 27.0, 21.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 45.0, 0.0, 0.0, 19.0, 16.0, 14.0, 14.0, 3.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 42.0, 5.0, 9.0, 14.0, 17.0, 1.0, 13.0, 9.0, 0.0, 3.0, 7.0, 13.0, 11.0, 0.0, 0.0, 0.0, 8.0, 21.0, 8.0, 21.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 15.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8730014189924009, "mean_inference_ms": 2.1149852973209122, "mean_action_processing_ms": 0.3468189298916757, "mean_env_wait_ms": 0.26862543063153677, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01302182674407959, "StateBufferConnector_ms": 0.06192636489868164, "ViewRequirementAgentConnector_ms": 0.4322240352630615}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -171.00000000000068, "episode_return_mean": 272.4749999999998, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 976000, "num_agent_steps_trained": 976000, "num_env_steps_sampled": 244000, "num_env_steps_trained": 244000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 51.754256371089966, "num_env_steps_trained_throughput_per_sec": 51.754256371089966, "timesteps_total": 244000, "num_env_steps_sampled_lifetime": 244000, "num_agent_steps_sampled_lifetime": 976000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 976000, "timers": {"training_iteration_time_ms": 72284.159, "restore_workers_time_ms": 0.017, "training_step_time_ms": 72284.099, "sample_time_ms": 3520.335, "learn_time_ms": 68735.224, "learn_throughput": 58.194, "synch_weights_time_ms": 22.45}, "counters": {"num_env_steps_sampled": 244000, "num_env_steps_trained": 244000, "num_agent_steps_sampled": 976000, "num_agent_steps_trained": 976000}, "done": false, "training_iteration": 61, "trial_id": "11e70_00000", "date": "2024-08-13_00-04-36", "timestamp": 1723521876, "time_this_iter_s": 77.38920402526855, "time_total_s": 3454.9852504730225, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3f39f70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3454.9852504730225, "iterations_since_restore": 61, "perf": {"cpu_util_percent": 86.60000000000001, "ram_util_percent": 83.4954128440367}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.655309603611628, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.6302060548275236, "policy_loss": -0.00943942485209653, "vf_loss": 0.6382430209605782, "vf_explained_var": 0.19916945396277008, "kl": 0.009349732957347352, "entropy": 1.0069364178117621, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 116235.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 18.140795666452437, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.3177578945639272, "policy_loss": -0.012260814482425018, "vf_loss": 2.328691285312491, "vf_explained_var": 0.7643611261453578, "kl": 0.011799311771290705, "entropy": 0.6819839746548385, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 116235.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 248000, "num_env_steps_trained": 248000, "num_agent_steps_sampled": 992000, "num_agent_steps_trained": 992000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -171.00000000000068, "episode_reward_mean": 283.3249999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -463.6, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 277.0}, "policy_reward_mean": {"prey_policy": 132.8675, "predator_policy": 8.795}, "custom_metrics": {}, "hist_stats": {"episode_reward": [362.20000000000005, 219.99999999999926, 171.7000000000001, 179.19999999999945, 320.5000000000001, 375.9, 37.80000000000027, -171.00000000000068, 357.8, 380.0, 357.6000000000001, 319.1000000000002, 285.6999999999997, 205.99999999999932, 308.8, 188.79999999999944, 214.50000000000003, 208.0999999999993, 333.6, 400.0, 311.29999999999995, 215.99999999999926, 183.99999999999943, 372.1, 269.8999999999999, 181.99999999999946, 400.0, 343.1, 32.30000000000018, 214.19999999999928, 305.8, 181.99999999999943, 217.99999999999926, 205.99999999999932, 353.7, 392.8, 381.00000000000006, 288.40000000000003, 307.4, 349.1, 340.2, 162.79999999999956, 347.80000000000007, 302.9, 290.1999999999997, 352.3, 350.6, 198.99999999999935, 309.0999999999998, 186.99999999999943, 40.0000000000003, 261.29999999999984, 350.3, 332.5, 353.20000000000005, 212.2999999999993, 365.80000000000007, 364.89999999999986, 219.99999999999926, 282.0, 215.49999999999926, 366.0, 349.4, 312.9999999999999, 388.2, 393.7, 240.7, 205.19999999999996, 323.1, 329.2, 359.0, 372.4, 344.7, 350.1, 329.79999999999995, 338.1, 296.70000000000005, 335.2, 400.0, 385.5, 380.2, 186.3999999999994, 350.20000000000005, 93.10000000000002, 106.39999999999989, 324.0, 243.6999999999999, 367.2, 199.99999999999935, 214.3999999999993, 390.0, 181.99999999999946, 277.6, 339.9, 255.8, 377.7, 336.9, 147.19999999999965, 380.8, 353.9], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [200.0, 162.2, 200.0, 20.000000000000014, 89.29999999999997, 25.399999999999977, 185.0, -38.799999999999855, 167.0, 132.49999999999997, 173.0, 191.9, 20.000000000000014, 15.799999999999963, -463.6, 11.599999999999964, 188.0, 165.8, 200.0, 170.0, 171.2, 172.39999999999998, 197.3, 66.80000000000001, 85.69999999999997, 200.0, 20.000000000000014, 179.0, 146.0, 138.79999999999998, 165.8, 20.000000000000014, 111.50000000000001, 76.99999999999997, 20.000000000000014, 175.1, 127.4, 138.2, 200.0, 200.0, 150.2, 130.1, 198.2, 15.799999999999963, 20.000000000000014, 137.0, 172.1, 200.0, 152.0, 101.89999999999998, 143.0, 20.000000000000014, 200.0, 200.0, 173.0, 151.1, 20.000000000000014, 5.299999999999965, 192.2, 20.000000000000014, 160.7, 115.1, 143.0, 20.000000000000014, 20.000000000000014, 197.0, 179.0, 20.000000000000014, 109.7, 200.0, 200.0, 192.8, 180.5, 195.49999999999997, 182.0, 79.39999999999999, 143.0, 142.39999999999998, 192.8, 122.3, 171.2, 152.0, 170.3, -32.49999999999984, 200.0, 147.8, 170.0, 101.90000000000003, 196.4, 93.79999999999998, 173.3, 170.0, 166.4, 150.2, 185.0, -0.9999999999999917, 109.09999999999998, 200.0, 149.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 155.3, 91.99999999999997, 189.2, 160.1, 133.1, 151.4, 158.6, 194.6, 5.299999999999965, 200.0, 200.0, 165.8, 166.70000000000002, 198.2, 20.000000000000014, 200.0, 71.0, 155.0, 195.5, 20.000000000000014, 137.0, 194.0, 158.0, 163.4, 191.0, 118.99999999999999, 198.2, 185.0, 199.1, 194.6, 143.3, 97.39999999999998, -24.700000000000003, 182.9, 145.7, 154.39999999999998, 175.7, 135.5, 137.0, 200.0, 191.0, 178.4, 166.7, 158.0, 166.1, 173.0, 133.39999999999998, 196.4, 148.1, 161.0, 137.0, 130.7, 135.2, 200.0, 200.0, 200.0, 196.4, 184.1, 192.8, 187.4, 151.4, 20.000000000000014, 144.2, 200.0, 20.000000000000014, 73.09999999999997, 85.39999999999998, 20.000000000000014, 200.0, 86.0, 134.3, 88.39999999999998, 177.2, 179.0, 170.0, 20.000000000000014, 17.899999999999988, 195.5, 200.0, 185.0, 20.000000000000014, 143.0, 167.0, 74.6, 149.0, 173.9, 112.69999999999999, 109.1, 174.2, 195.5, 131.0, 182.9, 122.6, 11.599999999999964, 182.0, 192.8, 187.1, 165.8], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 0.0, 36.0, 21.0, 28.0, 5.0, 0.0, 21.0, 8.0, 3.0, 2.0, 0.0, 4.0, 277.0, 0.0, 4.0, 0.0, 10.0, 14.0, 0.0, 37.0, 18.0, 0.0, 0.0, 7.0, 0.0, 10.0, 14.0, 3.0, 0.0, 5.0, 21.0, 8.0, 5.0, 29.0, 39.0, 0.0, 0.0, 0.0, 31.0, 0.0, 2.0, 9.0, 18.0, 0.0, 0.0, 0.0, 16.0, 0.0, 19.0, 0.0, 0.0, 0.0, 19.0, 7.0, 0.0, 2.0, 0.0, 6.0, 24.0, 4.0, 15.0, 0.0, 1.0, 7.0, 0.0, 17.0, 27.0, 0.0, 0.0, 0.0, 5.0, 27.0, 0.0, 14.0, 8.0, 13.0, 21.0, 15.0, 2.0, 0.0, 25.0, 0.0, 0.0, 0.0, 31.0, 0.0, 0.0, 9.0, 0.0, 14.0, 20.0, 10.0, 5.0, 0.0, 0.0, 11.0, 7.0, 0.0, 0.0, 0.0, 14.0, 1.0, 0.0, 27.0, 21.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 45.0, 0.0, 0.0, 19.0, 16.0, 14.0, 14.0, 3.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 42.0, 5.0, 9.0, 14.0, 17.0, 1.0, 13.0, 9.0, 0.0, 3.0, 7.0, 13.0, 11.0, 0.0, 0.0, 0.0, 8.0, 21.0, 8.0, 21.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 15.0, 0.0, 6.0, 0.0, 0.0, 0.0, 1.0, 0.0, 38.0, 0.0, 0.0, 21.0, 7.0, 4.0, 0.0, 10.0, 1.0, 0.0, 0.0, 5.0, 0.0, 19.0, 36.0, 0.0, 0.0, 17.0, 31.0, 3.0, 8.0, 0.0, 0.0, 23.0, 13.0, 0.0, 6.0, 0.0, 1.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8938619847161181, "mean_inference_ms": 2.16750225108513, "mean_action_processing_ms": 0.3542987072739021, "mean_env_wait_ms": 0.2762565821064328, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01055920124053955, "StateBufferConnector_ms": 0.060475826263427734, "ViewRequirementAgentConnector_ms": 0.48160064220428467}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -171.00000000000068, "episode_return_mean": 283.3249999999999, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 992000, "num_agent_steps_trained": 992000, "num_env_steps_sampled": 248000, "num_env_steps_trained": 248000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 48.16160987517026, "num_env_steps_trained_throughput_per_sec": 48.16160987517026, "timesteps_total": 248000, "num_env_steps_sampled_lifetime": 248000, "num_agent_steps_sampled_lifetime": 992000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 992000, "timers": {"training_iteration_time_ms": 72695.953, "restore_workers_time_ms": 0.017, "training_step_time_ms": 72695.896, "sample_time_ms": 3641.637, "learn_time_ms": 69025.476, "learn_throughput": 57.95, "synch_weights_time_ms": 22.015}, "counters": {"num_env_steps_sampled": 248000, "num_env_steps_trained": 248000, "num_agent_steps_sampled": 992000, "num_agent_steps_trained": 992000}, "done": false, "training_iteration": 62, "trial_id": "11e70_00000", "date": "2024-08-13_00-05-59", "timestamp": 1723521959, "time_this_iter_s": 83.1337640285492, "time_total_s": 3538.1190145015717, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3f48c10>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3538.1190145015717, "iterations_since_restore": 62, "perf": {"cpu_util_percent": 87.87627118644068, "ram_util_percent": 83.63559322033896}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.772026843936355, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.8541232381075148, "policy_loss": -0.007033703077052321, "vf_loss": 0.8602731055920086, "vf_explained_var": 0.15943244105924373, "kl": 0.005892231289304906, "entropy": 0.9840943474302847, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 118125.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 16.122168385477924, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.4216511379474053, "policy_loss": -0.012846564232536823, "vf_loss": 2.433620513305462, "vf_explained_var": 0.5643894564222407, "kl": 0.007797212182560084, "entropy": 0.6043222596405675, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 118125.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 252000, "num_env_steps_trained": 252000, "num_agent_steps_sampled": 1008000, "num_agent_steps_trained": 1008000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": 32.30000000000018, "episode_reward_mean": 288.8069999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -46.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 85.0}, "policy_reward_mean": {"prey_policy": 136.7585, "predator_policy": 7.645}, "custom_metrics": {}, "hist_stats": {"episode_reward": [183.99999999999943, 372.1, 269.8999999999999, 181.99999999999946, 400.0, 343.1, 32.30000000000018, 214.19999999999928, 305.8, 181.99999999999943, 217.99999999999926, 205.99999999999932, 353.7, 392.8, 381.00000000000006, 288.40000000000003, 307.4, 349.1, 340.2, 162.79999999999956, 347.80000000000007, 302.9, 290.1999999999997, 352.3, 350.6, 198.99999999999935, 309.0999999999998, 186.99999999999943, 40.0000000000003, 261.29999999999984, 350.3, 332.5, 353.20000000000005, 212.2999999999993, 365.80000000000007, 364.89999999999986, 219.99999999999926, 282.0, 215.49999999999926, 366.0, 349.4, 312.9999999999999, 388.2, 393.7, 240.7, 205.19999999999996, 323.1, 329.2, 359.0, 372.4, 344.7, 350.1, 329.79999999999995, 338.1, 296.70000000000005, 335.2, 400.0, 385.5, 380.2, 186.3999999999994, 350.20000000000005, 93.10000000000002, 106.39999999999989, 324.0, 243.6999999999999, 367.2, 199.99999999999935, 214.3999999999993, 390.0, 181.99999999999946, 277.6, 339.9, 255.8, 377.7, 336.9, 147.19999999999965, 380.8, 353.9, 40.0000000000003, 82.1, 384.7, 329.0, 141.99999999999963, 349.6, 209.1999999999993, 369.40000000000003, 275.1, 194.5999999999994, 346.7, 378.4, 349.00000000000006, 388.0, 380.20000000000005, 386.4, 340.0, 213.9999999999993, 357.4, 219.99999999999926, 193.99999999999937, 202.0], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 137.0, 172.1, 200.0, 152.0, 101.89999999999998, 143.0, 20.000000000000014, 200.0, 200.0, 173.0, 151.1, 20.000000000000014, 5.299999999999965, 192.2, 20.000000000000014, 160.7, 115.1, 143.0, 20.000000000000014, 20.000000000000014, 197.0, 179.0, 20.000000000000014, 109.7, 200.0, 200.0, 192.8, 180.5, 195.49999999999997, 182.0, 79.39999999999999, 143.0, 142.39999999999998, 192.8, 122.3, 171.2, 152.0, 170.3, -32.49999999999984, 200.0, 147.8, 170.0, 101.90000000000003, 196.4, 93.79999999999998, 173.3, 170.0, 166.4, 150.2, 185.0, -0.9999999999999917, 109.09999999999998, 200.0, 149.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 155.3, 91.99999999999997, 189.2, 160.1, 133.1, 151.4, 158.6, 194.6, 5.299999999999965, 200.0, 200.0, 165.8, 166.70000000000002, 198.2, 20.000000000000014, 200.0, 71.0, 155.0, 195.5, 20.000000000000014, 137.0, 194.0, 158.0, 163.4, 191.0, 118.99999999999999, 198.2, 185.0, 199.1, 194.6, 143.3, 97.39999999999998, -24.700000000000003, 182.9, 145.7, 154.39999999999998, 175.7, 135.5, 137.0, 200.0, 191.0, 178.4, 166.7, 158.0, 166.1, 173.0, 133.39999999999998, 196.4, 148.1, 161.0, 137.0, 130.7, 135.2, 200.0, 200.0, 200.0, 196.4, 184.1, 192.8, 187.4, 151.4, 20.000000000000014, 144.2, 200.0, 20.000000000000014, 73.09999999999997, 85.39999999999998, 20.000000000000014, 200.0, 86.0, 134.3, 88.39999999999998, 177.2, 179.0, 170.0, 20.000000000000014, 17.899999999999988, 195.5, 200.0, 185.0, 20.000000000000014, 143.0, 167.0, 74.6, 149.0, 173.9, 112.69999999999999, 109.1, 174.2, 195.5, 131.0, 182.9, 122.6, 11.599999999999964, 182.0, 192.8, 187.1, 165.8, 20.000000000000014, 20.000000000000014, 43.099999999999994, -46.0, 191.0, 193.7, 167.0, 122.0, 20.000000000000014, 83.0, 164.9, 184.7, 189.2, 20.000000000000014, 172.1, 197.3, 48.5, 158.6, 20.000000000000014, 164.6, 171.2, 159.5, 178.4, 200.0, 200.0, 146.0, 200.0, 182.0, 200.0, 180.2, 185.0, 196.4, 158.0, 152.0, 191.0, 20.000000000000014, 173.0, 178.4, 20.000000000000014, 200.0, 158.0, 20.000000000000014, -34.0, 131.0], "policy_predator_policy_reward": [9.0, 18.0, 0.0, 0.0, 0.0, 16.0, 0.0, 19.0, 0.0, 0.0, 0.0, 19.0, 7.0, 0.0, 2.0, 0.0, 6.0, 24.0, 4.0, 15.0, 0.0, 1.0, 7.0, 0.0, 17.0, 27.0, 0.0, 0.0, 0.0, 5.0, 27.0, 0.0, 14.0, 8.0, 13.0, 21.0, 15.0, 2.0, 0.0, 25.0, 0.0, 0.0, 0.0, 31.0, 0.0, 0.0, 9.0, 0.0, 14.0, 20.0, 10.0, 5.0, 0.0, 0.0, 11.0, 7.0, 0.0, 0.0, 0.0, 14.0, 1.0, 0.0, 27.0, 21.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 45.0, 0.0, 0.0, 19.0, 16.0, 14.0, 14.0, 3.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 42.0, 5.0, 9.0, 14.0, 17.0, 1.0, 13.0, 9.0, 0.0, 3.0, 7.0, 13.0, 11.0, 0.0, 0.0, 0.0, 8.0, 21.0, 8.0, 21.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 15.0, 0.0, 6.0, 0.0, 0.0, 0.0, 1.0, 0.0, 38.0, 0.0, 0.0, 21.0, 7.0, 4.0, 0.0, 10.0, 1.0, 0.0, 0.0, 5.0, 0.0, 19.0, 36.0, 0.0, 0.0, 17.0, 31.0, 3.0, 8.0, 0.0, 0.0, 23.0, 13.0, 0.0, 6.0, 0.0, 1.0, 0.0, 0.0, 0.0, 85.0, 0.0, 0.0, 0.0, 14.0, 26.0, 0.0, 39.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.0, 35.0, 0.0, 10.0, 16.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 6.0, 0.0, 0.0, 0.0, 5.0, 5.0, 25.0, 3.0, 0.0, 6.0, 0.0, 0.0, 0.0, 5.0, 11.0, 79.0, 26.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.90927291636781, "mean_inference_ms": 2.205554296981205, "mean_action_processing_ms": 0.3599381607198582, "mean_env_wait_ms": 0.28156787456803045, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.011379241943359375, "StateBufferConnector_ms": 0.01520085334777832, "ViewRequirementAgentConnector_ms": 0.3334615230560303}, "num_episodes": 22, "episode_return_max": 400.0, "episode_return_min": 32.30000000000018, "episode_return_mean": 288.8069999999999, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1008000, "num_agent_steps_trained": 1008000, "num_env_steps_sampled": 252000, "num_env_steps_trained": 252000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 56.023347246548205, "num_env_steps_trained_throughput_per_sec": 56.023347246548205, "timesteps_total": 252000, "num_env_steps_sampled_lifetime": 252000, "num_agent_steps_sampled_lifetime": 1008000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1008000, "timers": {"training_iteration_time_ms": 72887.026, "restore_workers_time_ms": 0.017, "training_step_time_ms": 72886.968, "sample_time_ms": 3724.827, "learn_time_ms": 69133.585, "learn_throughput": 57.859, "synch_weights_time_ms": 21.746}, "counters": {"num_env_steps_sampled": 252000, "num_env_steps_trained": 252000, "num_agent_steps_sampled": 1008000, "num_agent_steps_trained": 1008000}, "done": false, "training_iteration": 63, "trial_id": "11e70_00000", "date": "2024-08-13_00-07-11", "timestamp": 1723522031, "time_this_iter_s": 71.46157479286194, "time_total_s": 3609.5805892944336, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2b93820>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3609.5805892944336, "iterations_since_restore": 63, "perf": {"cpu_util_percent": 81.03069306930692, "ram_util_percent": 83.47029702970298}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.252594512291055, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.4392851633369608, "policy_loss": -0.008068763862841975, "vf_loss": 1.445992463480228, "vf_explained_var": 0.220481240150159, "kl": 0.009076395662687087, "entropy": 0.9914737123976309, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 120015.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 12.694743373911217, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.256861002104623, "policy_loss": -0.013409170508384704, "vf_loss": 3.268912800090023, "vf_explained_var": 0.6453397051997917, "kl": 0.012065526271249927, "entropy": 0.7296854769111311, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 120015.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 256000, "num_env_steps_trained": 256000, "num_agent_steps_sampled": 1024000, "num_agent_steps_trained": 1024000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": 40.0000000000003, "episode_reward_mean": 289.8559999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -46.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 85.0}, "policy_reward_mean": {"prey_policy": 136.928, "predator_policy": 8.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [352.3, 350.6, 198.99999999999935, 309.0999999999998, 186.99999999999943, 40.0000000000003, 261.29999999999984, 350.3, 332.5, 353.20000000000005, 212.2999999999993, 365.80000000000007, 364.89999999999986, 219.99999999999926, 282.0, 215.49999999999926, 366.0, 349.4, 312.9999999999999, 388.2, 393.7, 240.7, 205.19999999999996, 323.1, 329.2, 359.0, 372.4, 344.7, 350.1, 329.79999999999995, 338.1, 296.70000000000005, 335.2, 400.0, 385.5, 380.2, 186.3999999999994, 350.20000000000005, 93.10000000000002, 106.39999999999989, 324.0, 243.6999999999999, 367.2, 199.99999999999935, 214.3999999999993, 390.0, 181.99999999999946, 277.6, 339.9, 255.8, 377.7, 336.9, 147.19999999999965, 380.8, 353.9, 40.0000000000003, 82.1, 384.7, 329.0, 141.99999999999963, 349.6, 209.1999999999993, 369.40000000000003, 275.1, 194.5999999999994, 346.7, 378.4, 349.00000000000006, 388.0, 380.20000000000005, 386.4, 340.0, 213.9999999999993, 357.4, 219.99999999999926, 193.99999999999937, 202.0, 327.1, 219.99999999999926, 325.29999999999995, 104.99999999999989, 236.19999999999936, 316.5, 184.09999999999943, 167.9999999999995, 186.79999999999941, 377.9, 347.0, 361.6, 323.5, 345.5, 245.39999999999972, 339.0, 178.89999999999927, 366.0, 199.6999999999994, 230.39999999999978, 373.70000000000005, 389.2, 383.8], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [173.3, 170.0, 166.4, 150.2, 185.0, -0.9999999999999917, 109.09999999999998, 200.0, 149.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 155.3, 91.99999999999997, 189.2, 160.1, 133.1, 151.4, 158.6, 194.6, 5.299999999999965, 200.0, 200.0, 165.8, 166.70000000000002, 198.2, 20.000000000000014, 200.0, 71.0, 155.0, 195.5, 20.000000000000014, 137.0, 194.0, 158.0, 163.4, 191.0, 118.99999999999999, 198.2, 185.0, 199.1, 194.6, 143.3, 97.39999999999998, -24.700000000000003, 182.9, 145.7, 154.39999999999998, 175.7, 135.5, 137.0, 200.0, 191.0, 178.4, 166.7, 158.0, 166.1, 173.0, 133.39999999999998, 196.4, 148.1, 161.0, 137.0, 130.7, 135.2, 200.0, 200.0, 200.0, 196.4, 184.1, 192.8, 187.4, 151.4, 20.000000000000014, 144.2, 200.0, 20.000000000000014, 73.09999999999997, 85.39999999999998, 20.000000000000014, 200.0, 86.0, 134.3, 88.39999999999998, 177.2, 179.0, 170.0, 20.000000000000014, 17.899999999999988, 195.5, 200.0, 185.0, 20.000000000000014, 143.0, 167.0, 74.6, 149.0, 173.9, 112.69999999999999, 109.1, 174.2, 195.5, 131.0, 182.9, 122.6, 11.599999999999964, 182.0, 192.8, 187.1, 165.8, 20.000000000000014, 20.000000000000014, 43.099999999999994, -46.0, 191.0, 193.7, 167.0, 122.0, 20.000000000000014, 83.0, 164.9, 184.7, 189.2, 20.000000000000014, 172.1, 197.3, 48.5, 158.6, 20.000000000000014, 164.6, 171.2, 159.5, 178.4, 200.0, 200.0, 146.0, 200.0, 182.0, 200.0, 180.2, 185.0, 196.4, 158.0, 152.0, 191.0, 20.000000000000014, 173.0, 178.4, 20.000000000000014, 200.0, 158.0, 20.000000000000014, -34.0, 131.0, 127.1, 164.0, 200.0, 20.000000000000014, 125.29999999999998, 200.0, -13.0, 20.000000000000014, 200.0, 36.19999999999999, 153.5, 134.0, 20.000000000000014, 142.1, 116.0, 20.000000000000014, 170.0, -5.200000000000003, 180.5, 190.4, 152.0, 173.0, 164.0, 185.6, 169.4, 154.1, 195.5, 116.0, 173.0, 55.39999999999997, 122.0, 191.0, 140.0, 17.899999999999984, 149.0, 200.0, 20.000000000000014, 172.7, 70.39999999999996, 140.0, 175.7, 197.0, 189.2, 200.0, 191.9, 191.9], "policy_predator_policy_reward": [9.0, 0.0, 14.0, 20.0, 10.0, 5.0, 0.0, 0.0, 11.0, 7.0, 0.0, 0.0, 0.0, 14.0, 1.0, 0.0, 27.0, 21.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 45.0, 0.0, 0.0, 19.0, 16.0, 14.0, 14.0, 3.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 42.0, 5.0, 9.0, 14.0, 17.0, 1.0, 13.0, 9.0, 0.0, 3.0, 7.0, 13.0, 11.0, 0.0, 0.0, 0.0, 8.0, 21.0, 8.0, 21.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 15.0, 0.0, 6.0, 0.0, 0.0, 0.0, 1.0, 0.0, 38.0, 0.0, 0.0, 21.0, 7.0, 4.0, 0.0, 10.0, 1.0, 0.0, 0.0, 5.0, 0.0, 19.0, 36.0, 0.0, 0.0, 17.0, 31.0, 3.0, 8.0, 0.0, 0.0, 23.0, 13.0, 0.0, 6.0, 0.0, 1.0, 0.0, 0.0, 0.0, 85.0, 0.0, 0.0, 0.0, 14.0, 26.0, 0.0, 39.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.0, 35.0, 0.0, 10.0, 16.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 6.0, 0.0, 0.0, 0.0, 5.0, 5.0, 25.0, 3.0, 0.0, 6.0, 0.0, 0.0, 0.0, 5.0, 11.0, 79.0, 26.0, 19.0, 17.0, 0.0, 0.0, 0.0, 0.0, 61.0, 37.0, 0.0, 0.0, 29.0, 0.0, 16.0, 6.0, 7.0, 25.0, 0.0, 22.0, 0.0, 7.0, 0.0, 22.0, 0.0, 12.0, 0.0, 0.0, 28.0, 6.0, 8.0, 9.0, 26.0, 0.0, 0.0, 21.0, 0.0, 17.0, 0.0, 7.0, 0.0, 20.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.9287126287198282, "mean_inference_ms": 2.253942738947617, "mean_action_processing_ms": 0.36734529304308516, "mean_env_wait_ms": 0.2873878233316243, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01088857650756836, "StateBufferConnector_ms": 0.015262842178344727, "ViewRequirementAgentConnector_ms": 0.3768991231918335}, "num_episodes": 23, "episode_return_max": 400.0, "episode_return_min": 40.0000000000003, "episode_return_mean": 289.8559999999999, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1024000, "num_agent_steps_trained": 1024000, "num_env_steps_sampled": 256000, "num_env_steps_trained": 256000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 53.00625661975312, "num_env_steps_trained_throughput_per_sec": 53.00625661975312, "timesteps_total": 256000, "num_env_steps_sampled_lifetime": 256000, "num_agent_steps_sampled_lifetime": 1024000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1024000, "timers": {"training_iteration_time_ms": 74087.879, "restore_workers_time_ms": 0.017, "training_step_time_ms": 74087.82, "sample_time_ms": 3968.655, "learn_time_ms": 70090.378, "learn_throughput": 57.069, "synch_weights_time_ms": 22.046}, "counters": {"num_env_steps_sampled": 256000, "num_env_steps_trained": 256000, "num_agent_steps_sampled": 1024000, "num_agent_steps_trained": 1024000}, "done": false, "training_iteration": 64, "trial_id": "11e70_00000", "date": "2024-08-13_00-08-27", "timestamp": 1723522107, "time_this_iter_s": 75.59704804420471, "time_total_s": 3685.1776373386383, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2b1d4c0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3685.1776373386383, "iterations_since_restore": 64, "perf": {"cpu_util_percent": 82.2824074074074, "ram_util_percent": 83.44166666666666}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.755917858383643, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.9571917530405458, "policy_loss": -0.005364091708891528, "vf_loss": 1.9615314614520503, "vf_explained_var": 0.07069221384941586, "kl": 0.006829209636693141, "entropy": 0.9929680716108393, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 121905.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 12.874864508298339, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.248836500241012, "policy_loss": -0.009416265839898082, "vf_loss": 3.2573869073832475, "vf_explained_var": 0.6678885089657294, "kl": 0.007696471800210382, "entropy": 0.7040140790914101, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 121905.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 260000, "num_env_steps_trained": 260000, "num_agent_steps_sampled": 1040000, "num_agent_steps_trained": 1040000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": 40.0000000000003, "episode_reward_mean": 285.20099999999985, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -265.8, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 188.0}, "policy_reward_mean": {"prey_policy": 132.62050000000002, "predator_policy": 9.98}, "custom_metrics": {}, "hist_stats": {"episode_reward": [312.9999999999999, 388.2, 393.7, 240.7, 205.19999999999996, 323.1, 329.2, 359.0, 372.4, 344.7, 350.1, 329.79999999999995, 338.1, 296.70000000000005, 335.2, 400.0, 385.5, 380.2, 186.3999999999994, 350.20000000000005, 93.10000000000002, 106.39999999999989, 324.0, 243.6999999999999, 367.2, 199.99999999999935, 214.3999999999993, 390.0, 181.99999999999946, 277.6, 339.9, 255.8, 377.7, 336.9, 147.19999999999965, 380.8, 353.9, 40.0000000000003, 82.1, 384.7, 329.0, 141.99999999999963, 349.6, 209.1999999999993, 369.40000000000003, 275.1, 194.5999999999994, 346.7, 378.4, 349.00000000000006, 388.0, 380.20000000000005, 386.4, 340.0, 213.9999999999993, 357.4, 219.99999999999926, 193.99999999999937, 202.0, 327.1, 219.99999999999926, 325.29999999999995, 104.99999999999989, 236.19999999999936, 316.5, 184.09999999999943, 167.9999999999995, 186.79999999999941, 377.9, 347.0, 361.6, 323.5, 345.5, 245.39999999999972, 339.0, 178.89999999999927, 366.0, 199.6999999999994, 230.39999999999978, 373.70000000000005, 389.2, 383.8, 315.1, 252.4, 384.7, 115.69999999999948, 171.3999999999995, 389.2, 205.49999999999932, 117.3, 216.39999999999927, 40.0000000000003, 347.3, 168.7999999999995, 329.5, 390.0, 182.19999999999982, 307.70000000000005, 341.3, 371.2], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [191.0, 118.99999999999999, 198.2, 185.0, 199.1, 194.6, 143.3, 97.39999999999998, -24.700000000000003, 182.9, 145.7, 154.39999999999998, 175.7, 135.5, 137.0, 200.0, 191.0, 178.4, 166.7, 158.0, 166.1, 173.0, 133.39999999999998, 196.4, 148.1, 161.0, 137.0, 130.7, 135.2, 200.0, 200.0, 200.0, 196.4, 184.1, 192.8, 187.4, 151.4, 20.000000000000014, 144.2, 200.0, 20.000000000000014, 73.09999999999997, 85.39999999999998, 20.000000000000014, 200.0, 86.0, 134.3, 88.39999999999998, 177.2, 179.0, 170.0, 20.000000000000014, 17.899999999999988, 195.5, 200.0, 185.0, 20.000000000000014, 143.0, 167.0, 74.6, 149.0, 173.9, 112.69999999999999, 109.1, 174.2, 195.5, 131.0, 182.9, 122.6, 11.599999999999964, 182.0, 192.8, 187.1, 165.8, 20.000000000000014, 20.000000000000014, 43.099999999999994, -46.0, 191.0, 193.7, 167.0, 122.0, 20.000000000000014, 83.0, 164.9, 184.7, 189.2, 20.000000000000014, 172.1, 197.3, 48.5, 158.6, 20.000000000000014, 164.6, 171.2, 159.5, 178.4, 200.0, 200.0, 146.0, 200.0, 182.0, 200.0, 180.2, 185.0, 196.4, 158.0, 152.0, 191.0, 20.000000000000014, 173.0, 178.4, 20.000000000000014, 200.0, 158.0, 20.000000000000014, -34.0, 131.0, 127.1, 164.0, 200.0, 20.000000000000014, 125.29999999999998, 200.0, -13.0, 20.000000000000014, 200.0, 36.19999999999999, 153.5, 134.0, 20.000000000000014, 142.1, 116.0, 20.000000000000014, 170.0, -5.200000000000003, 180.5, 190.4, 152.0, 173.0, 164.0, 185.6, 169.4, 154.1, 195.5, 116.0, 173.0, 55.39999999999997, 122.0, 191.0, 140.0, 17.899999999999984, 149.0, 200.0, 20.000000000000014, 172.7, 70.39999999999996, 140.0, 175.7, 197.0, 189.2, 200.0, 191.9, 191.9, 167.0, 133.1, 145.4, 53.0, 184.7, 200.0, 20.000000000000014, 64.7, -34.59999999999975, 170.0, 200.0, 189.2, 168.5, 20.000000000000014, -204.09999999999968, 190.4, 20.000000000000014, 196.4, 20.000000000000014, 20.000000000000014, 197.3, 125.0, 144.79999999999998, 20.000000000000014, 172.1, 127.4, 200.0, 185.0, -265.8, 200.0, 89.0, 181.70000000000002, 140.0, 179.3, 185.0, 180.2], "policy_predator_policy_reward": [3.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 42.0, 5.0, 9.0, 14.0, 17.0, 1.0, 13.0, 9.0, 0.0, 3.0, 7.0, 13.0, 11.0, 0.0, 0.0, 0.0, 8.0, 21.0, 8.0, 21.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 15.0, 0.0, 6.0, 0.0, 0.0, 0.0, 1.0, 0.0, 38.0, 0.0, 0.0, 21.0, 7.0, 4.0, 0.0, 10.0, 1.0, 0.0, 0.0, 5.0, 0.0, 19.0, 36.0, 0.0, 0.0, 17.0, 31.0, 3.0, 8.0, 0.0, 0.0, 23.0, 13.0, 0.0, 6.0, 0.0, 1.0, 0.0, 0.0, 0.0, 85.0, 0.0, 0.0, 0.0, 14.0, 26.0, 0.0, 39.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.0, 35.0, 0.0, 10.0, 16.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 6.0, 0.0, 0.0, 0.0, 5.0, 5.0, 25.0, 3.0, 0.0, 6.0, 0.0, 0.0, 0.0, 5.0, 11.0, 79.0, 26.0, 19.0, 17.0, 0.0, 0.0, 0.0, 0.0, 61.0, 37.0, 0.0, 0.0, 29.0, 0.0, 16.0, 6.0, 7.0, 25.0, 0.0, 22.0, 0.0, 7.0, 0.0, 22.0, 0.0, 12.0, 0.0, 0.0, 28.0, 6.0, 8.0, 9.0, 26.0, 0.0, 0.0, 21.0, 0.0, 17.0, 0.0, 7.0, 0.0, 20.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 15.0, 17.0, 37.0, 0.0, 0.0, 0.0, 31.0, 10.0, 26.0, 0.0, 0.0, 9.0, 8.0, 129.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.0, 0.0, 4.0, 23.0, 7.0, 5.0, 0.0, 188.0, 60.0, 0.0, 37.0, 0.0, 22.0, 0.0, 6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.9438981796281024, "mean_inference_ms": 2.294658140548182, "mean_action_processing_ms": 0.37292253927266794, "mean_env_wait_ms": 0.2927248596770999, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.009663820266723633, "StateBufferConnector_ms": 0.015445590019226074, "ViewRequirementAgentConnector_ms": 0.4155569076538086}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": 40.0000000000003, "episode_return_mean": 285.20099999999985, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1040000, "num_agent_steps_trained": 1040000, "num_env_steps_sampled": 260000, "num_env_steps_trained": 260000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 58.44121910721874, "num_env_steps_trained_throughput_per_sec": 58.44121910721874, "timesteps_total": 260000, "num_env_steps_sampled_lifetime": 260000, "num_agent_steps_sampled_lifetime": 1040000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1040000, "timers": {"training_iteration_time_ms": 74009.05, "restore_workers_time_ms": 0.018, "training_step_time_ms": 74008.986, "sample_time_ms": 4103.581, "learn_time_ms": 69880.404, "learn_throughput": 57.241, "synch_weights_time_ms": 19.141}, "counters": {"num_env_steps_sampled": 260000, "num_env_steps_trained": 260000, "num_agent_steps_sampled": 1040000, "num_agent_steps_trained": 1040000}, "done": false, "training_iteration": 65, "trial_id": "11e70_00000", "date": "2024-08-13_00-09-35", "timestamp": 1723522175, "time_this_iter_s": 68.50742173194885, "time_total_s": 3753.685059070587, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3f1d4c0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3753.685059070587, "iterations_since_restore": 65, "perf": {"cpu_util_percent": 80.0721649484536, "ram_util_percent": 83.14329896907218}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.580167393236564, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.8127691259775212, "policy_loss": -0.006298747124574172, "vf_loss": 1.8179463875987543, "vf_explained_var": 0.0829762217544374, "kl": 0.007476563824902555, "entropy": 0.9219239441806046, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 123795.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 11.040240947216276, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.6991310648186495, "policy_loss": -0.00918106664028807, "vf_loss": 3.7076330926683214, "vf_explained_var": 0.21978851279253683, "kl": 0.006035930986735631, "entropy": 0.5947100165659789, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 123795.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 264000, "num_env_steps_trained": 264000, "num_agent_steps_sampled": 1056000, "num_agent_steps_trained": 1056000}, "env_runners": {"episode_reward_max": 390.0, "episode_reward_min": -293.0, "episode_reward_mean": 260.67499999999984, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -311.8, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 188.0}, "policy_reward_mean": {"prey_policy": 116.6725, "predator_policy": 13.665}, "custom_metrics": {}, "hist_stats": {"episode_reward": [186.3999999999994, 350.20000000000005, 93.10000000000002, 106.39999999999989, 324.0, 243.6999999999999, 367.2, 199.99999999999935, 214.3999999999993, 390.0, 181.99999999999946, 277.6, 339.9, 255.8, 377.7, 336.9, 147.19999999999965, 380.8, 353.9, 40.0000000000003, 82.1, 384.7, 329.0, 141.99999999999963, 349.6, 209.1999999999993, 369.40000000000003, 275.1, 194.5999999999994, 346.7, 378.4, 349.00000000000006, 388.0, 380.20000000000005, 386.4, 340.0, 213.9999999999993, 357.4, 219.99999999999926, 193.99999999999937, 202.0, 327.1, 219.99999999999926, 325.29999999999995, 104.99999999999989, 236.19999999999936, 316.5, 184.09999999999943, 167.9999999999995, 186.79999999999941, 377.9, 347.0, 361.6, 323.5, 345.5, 245.39999999999972, 339.0, 178.89999999999927, 366.0, 199.6999999999994, 230.39999999999978, 373.70000000000005, 389.2, 383.8, 315.1, 252.4, 384.7, 115.69999999999948, 171.3999999999995, 389.2, 205.49999999999932, 117.3, 216.39999999999927, 40.0000000000003, 347.3, 168.7999999999995, 329.5, 390.0, 182.19999999999982, 307.70000000000005, 341.3, 371.2, 335.0, 129.2, 380.4, 382.0, 40.0000000000003, -293.0, 175.2, 211.9, 71.1, -30.200000000000003, 176.79999999999947, 306.7, 226.0, 219.99999999999926, 336.0, 370.1, 232.0, 363.0], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [151.4, 20.000000000000014, 144.2, 200.0, 20.000000000000014, 73.09999999999997, 85.39999999999998, 20.000000000000014, 200.0, 86.0, 134.3, 88.39999999999998, 177.2, 179.0, 170.0, 20.000000000000014, 17.899999999999988, 195.5, 200.0, 185.0, 20.000000000000014, 143.0, 167.0, 74.6, 149.0, 173.9, 112.69999999999999, 109.1, 174.2, 195.5, 131.0, 182.9, 122.6, 11.599999999999964, 182.0, 192.8, 187.1, 165.8, 20.000000000000014, 20.000000000000014, 43.099999999999994, -46.0, 191.0, 193.7, 167.0, 122.0, 20.000000000000014, 83.0, 164.9, 184.7, 189.2, 20.000000000000014, 172.1, 197.3, 48.5, 158.6, 20.000000000000014, 164.6, 171.2, 159.5, 178.4, 200.0, 200.0, 146.0, 200.0, 182.0, 200.0, 180.2, 185.0, 196.4, 158.0, 152.0, 191.0, 20.000000000000014, 173.0, 178.4, 20.000000000000014, 200.0, 158.0, 20.000000000000014, -34.0, 131.0, 127.1, 164.0, 200.0, 20.000000000000014, 125.29999999999998, 200.0, -13.0, 20.000000000000014, 200.0, 36.19999999999999, 153.5, 134.0, 20.000000000000014, 142.1, 116.0, 20.000000000000014, 170.0, -5.200000000000003, 180.5, 190.4, 152.0, 173.0, 164.0, 185.6, 169.4, 154.1, 195.5, 116.0, 173.0, 55.39999999999997, 122.0, 191.0, 140.0, 17.899999999999984, 149.0, 200.0, 20.000000000000014, 172.7, 70.39999999999996, 140.0, 175.7, 197.0, 189.2, 200.0, 191.9, 191.9, 167.0, 133.1, 145.4, 53.0, 184.7, 200.0, 20.000000000000014, 64.7, -34.59999999999975, 170.0, 200.0, 189.2, 168.5, 20.000000000000014, -204.09999999999968, 190.4, 20.000000000000014, 196.4, 20.000000000000014, 20.000000000000014, 197.3, 125.0, 144.79999999999998, 20.000000000000014, 172.1, 127.4, 200.0, 185.0, -265.8, 200.0, 89.0, 181.70000000000002, 140.0, 179.3, 185.0, 180.2, 160.4, 164.60000000000002, -50.80000000000001, 80.0, 182.0, 190.4, 182.0, 200.0, 20.000000000000014, 20.000000000000014, -295.0, -163.0, 100.1, 10.100000000000023, 198.2, -76.29999999999998, 53.0, -100.9, -311.8, 104.60000000000001, 20.000000000000014, 156.8, 111.80000000000004, 164.9, 56.0, 101.0, 200.0, 20.000000000000014, 104.0, 200.0, 193.1, 164.0, 68.0, 101.0, 176.0, 176.0], "policy_predator_policy_reward": [15.0, 0.0, 6.0, 0.0, 0.0, 0.0, 1.0, 0.0, 38.0, 0.0, 0.0, 21.0, 7.0, 4.0, 0.0, 10.0, 1.0, 0.0, 0.0, 5.0, 0.0, 19.0, 36.0, 0.0, 0.0, 17.0, 31.0, 3.0, 8.0, 0.0, 0.0, 23.0, 13.0, 0.0, 6.0, 0.0, 1.0, 0.0, 0.0, 0.0, 85.0, 0.0, 0.0, 0.0, 14.0, 26.0, 0.0, 39.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.0, 35.0, 0.0, 10.0, 16.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 6.0, 0.0, 0.0, 0.0, 5.0, 5.0, 25.0, 3.0, 0.0, 6.0, 0.0, 0.0, 0.0, 5.0, 11.0, 79.0, 26.0, 19.0, 17.0, 0.0, 0.0, 0.0, 0.0, 61.0, 37.0, 0.0, 0.0, 29.0, 0.0, 16.0, 6.0, 7.0, 25.0, 0.0, 22.0, 0.0, 7.0, 0.0, 22.0, 0.0, 12.0, 0.0, 0.0, 28.0, 6.0, 8.0, 9.0, 26.0, 0.0, 0.0, 21.0, 0.0, 17.0, 0.0, 7.0, 0.0, 20.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 15.0, 17.0, 37.0, 0.0, 0.0, 0.0, 31.0, 10.0, 26.0, 0.0, 0.0, 9.0, 8.0, 129.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.0, 0.0, 4.0, 23.0, 7.0, 5.0, 0.0, 188.0, 60.0, 0.0, 37.0, 0.0, 22.0, 0.0, 6.0, 10.0, 0.0, 26.0, 74.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 165.0, 0.0, 19.0, 46.0, 0.0, 90.0, 8.0, 111.0, 170.0, 7.0, 0.0, 0.0, 9.0, 21.0, 23.0, 46.0, 0.0, 0.0, 0.0, 32.0, 0.0, 13.0, 55.0, 8.0, 11.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.9671487287899191, "mean_inference_ms": 2.3507485100629997, "mean_action_processing_ms": 0.380993697836302, "mean_env_wait_ms": 0.29913376450399753, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.012613296508789062, "StateBufferConnector_ms": 0.025675177574157715, "ViewRequirementAgentConnector_ms": 0.46889448165893555}, "num_episodes": 18, "episode_return_max": 390.0, "episode_return_min": -293.0, "episode_return_mean": 260.67499999999984, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1056000, "num_agent_steps_trained": 1056000, "num_env_steps_sampled": 264000, "num_env_steps_trained": 264000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 43.93895563561955, "num_env_steps_trained_throughput_per_sec": 43.93895563561955, "timesteps_total": 264000, "num_env_steps_sampled_lifetime": 264000, "num_agent_steps_sampled_lifetime": 1056000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1056000, "timers": {"training_iteration_time_ms": 76174.824, "restore_workers_time_ms": 0.017, "training_step_time_ms": 76174.752, "sample_time_ms": 4491.885, "learn_time_ms": 71658.098, "learn_throughput": 55.821, "synch_weights_time_ms": 18.563}, "counters": {"num_env_steps_sampled": 264000, "num_env_steps_trained": 264000, "num_agent_steps_sampled": 1056000, "num_agent_steps_trained": 1056000}, "done": false, "training_iteration": 66, "trial_id": "11e70_00000", "date": "2024-08-13_00-11-07", "timestamp": 1723522267, "time_this_iter_s": 91.10233902931213, "time_total_s": 3844.7873980998993, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2b06d30>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3844.7873980998993, "iterations_since_restore": 66, "perf": {"cpu_util_percent": 93.86875, "ram_util_percent": 83.65703124999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.871648913432681, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.5960573285975785, "policy_loss": -0.0031817287890358813, "vf_loss": 3.598074659216341, "vf_explained_var": 0.037159787189392814, "kl": 0.0077626859641972855, "entropy": 0.9232691524205384, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 125685.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 9.446255145438764, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.997478830120551, "policy_loss": -0.007126307248990372, "vf_loss": 5.003919972692217, "vf_explained_var": 0.3555186383938663, "kl": 0.006090334535230083, "entropy": 0.6490883997508458, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 125685.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 268000, "num_env_steps_trained": 268000, "num_agent_steps_sampled": 1072000, "num_agent_steps_trained": 1072000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -293.0, "episode_reward_mean": 234.1669999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -311.8, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 188.0}, "policy_reward_mean": {"prey_policy": 98.52850000000002, "predator_policy": 18.555}, "custom_metrics": {}, "hist_stats": {"episode_reward": [329.0, 141.99999999999963, 349.6, 209.1999999999993, 369.40000000000003, 275.1, 194.5999999999994, 346.7, 378.4, 349.00000000000006, 388.0, 380.20000000000005, 386.4, 340.0, 213.9999999999993, 357.4, 219.99999999999926, 193.99999999999937, 202.0, 327.1, 219.99999999999926, 325.29999999999995, 104.99999999999989, 236.19999999999936, 316.5, 184.09999999999943, 167.9999999999995, 186.79999999999941, 377.9, 347.0, 361.6, 323.5, 345.5, 245.39999999999972, 339.0, 178.89999999999927, 366.0, 199.6999999999994, 230.39999999999978, 373.70000000000005, 389.2, 383.8, 315.1, 252.4, 384.7, 115.69999999999948, 171.3999999999995, 389.2, 205.49999999999932, 117.3, 216.39999999999927, 40.0000000000003, 347.3, 168.7999999999995, 329.5, 390.0, 182.19999999999982, 307.70000000000005, 341.3, 371.2, 335.0, 129.2, 380.4, 382.0, 40.0000000000003, -293.0, 175.2, 211.9, 71.1, -30.200000000000003, 176.79999999999947, 306.7, 226.0, 219.99999999999926, 336.0, 370.1, 232.0, 363.0, 219.99999999999926, -11.200000000000003, 116.70000000000003, 400.0, -22.399999999999913, 189.4999999999994, -30.5, -81.10000000000007, -213.89999999999998, 199.0999999999994, 183.39999999999998, 40.0000000000003, 330.70000000000005, 394.6, 268.39999999999986, 16.000000000000057, 146.19999999999956, 167.20000000000005, 117.30000000000013, 393.5, 42.10000000000004, 117.60000000000002], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [167.0, 122.0, 20.000000000000014, 83.0, 164.9, 184.7, 189.2, 20.000000000000014, 172.1, 197.3, 48.5, 158.6, 20.000000000000014, 164.6, 171.2, 159.5, 178.4, 200.0, 200.0, 146.0, 200.0, 182.0, 200.0, 180.2, 185.0, 196.4, 158.0, 152.0, 191.0, 20.000000000000014, 173.0, 178.4, 20.000000000000014, 200.0, 158.0, 20.000000000000014, -34.0, 131.0, 127.1, 164.0, 200.0, 20.000000000000014, 125.29999999999998, 200.0, -13.0, 20.000000000000014, 200.0, 36.19999999999999, 153.5, 134.0, 20.000000000000014, 142.1, 116.0, 20.000000000000014, 170.0, -5.200000000000003, 180.5, 190.4, 152.0, 173.0, 164.0, 185.6, 169.4, 154.1, 195.5, 116.0, 173.0, 55.39999999999997, 122.0, 191.0, 140.0, 17.899999999999984, 149.0, 200.0, 20.000000000000014, 172.7, 70.39999999999996, 140.0, 175.7, 197.0, 189.2, 200.0, 191.9, 191.9, 167.0, 133.1, 145.4, 53.0, 184.7, 200.0, 20.000000000000014, 64.7, -34.59999999999975, 170.0, 200.0, 189.2, 168.5, 20.000000000000014, -204.09999999999968, 190.4, 20.000000000000014, 196.4, 20.000000000000014, 20.000000000000014, 197.3, 125.0, 144.79999999999998, 20.000000000000014, 172.1, 127.4, 200.0, 185.0, -265.8, 200.0, 89.0, 181.70000000000002, 140.0, 179.3, 185.0, 180.2, 160.4, 164.60000000000002, -50.80000000000001, 80.0, 182.0, 190.4, 182.0, 200.0, 20.000000000000014, 20.000000000000014, -295.0, -163.0, 100.1, 10.100000000000023, 198.2, -76.29999999999998, 53.0, -100.9, -311.8, 104.60000000000001, 20.000000000000014, 156.8, 111.80000000000004, 164.9, 56.0, 101.0, 200.0, 20.000000000000014, 104.0, 200.0, 193.1, 164.0, 68.0, 101.0, 176.0, 176.0, 20.000000000000014, 200.0, -17.200000000000003, -103.0, 182.9, -236.20000000000024, 200.0, 200.0, -240.40000000000035, 68.0, 156.5, 20.000000000000014, -118.0, -29.5, -48.10000000000002, -145.0, -154.9, -196.0, 20.000000000000014, 169.1, 94.70000000000005, 34.7, 20.000000000000014, 20.000000000000014, 192.8, 137.89999999999998, 198.2, 196.4, 73.69999999999997, 184.7, -106.0, 20.000000000000014, 20.000000000000014, 90.2, 57.2, 62.0, 23.299999999999983, 11.0, 199.1, 193.4, -8.200000000000003, -33.7, 8.600000000000023, 17.0], "policy_predator_policy_reward": [14.0, 26.0, 0.0, 39.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.0, 35.0, 0.0, 10.0, 16.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 6.0, 0.0, 0.0, 0.0, 5.0, 5.0, 25.0, 3.0, 0.0, 6.0, 0.0, 0.0, 0.0, 5.0, 11.0, 79.0, 26.0, 19.0, 17.0, 0.0, 0.0, 0.0, 0.0, 61.0, 37.0, 0.0, 0.0, 29.0, 0.0, 16.0, 6.0, 7.0, 25.0, 0.0, 22.0, 0.0, 7.0, 0.0, 22.0, 0.0, 12.0, 0.0, 0.0, 28.0, 6.0, 8.0, 9.0, 26.0, 0.0, 0.0, 21.0, 0.0, 17.0, 0.0, 7.0, 0.0, 20.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 15.0, 17.0, 37.0, 0.0, 0.0, 0.0, 31.0, 10.0, 26.0, 0.0, 0.0, 9.0, 8.0, 129.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.0, 0.0, 4.0, 23.0, 7.0, 5.0, 0.0, 188.0, 60.0, 0.0, 37.0, 0.0, 22.0, 0.0, 6.0, 10.0, 0.0, 26.0, 74.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 165.0, 0.0, 19.0, 46.0, 0.0, 90.0, 8.0, 111.0, 170.0, 7.0, 0.0, 0.0, 9.0, 21.0, 23.0, 46.0, 0.0, 0.0, 0.0, 32.0, 0.0, 13.0, 55.0, 8.0, 11.0, 0.0, 0.0, 0.0, 0.0, 109.0, 122.0, 48.0, 0.0, 0.0, 124.0, 26.0, 0.0, 13.0, 26.0, 91.0, 0.0, 112.0, 4.0, 133.0, 0.0, 10.0, 13.0, 41.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 102.0, 22.0, 14.0, 0.0, 48.0, 83.0, 0.0, 0.0, 1.0, 0.0, 84.0, 28.0, 64.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.9925371347546327, "mean_inference_ms": 2.4131393167165056, "mean_action_processing_ms": 0.3902063961369099, "mean_env_wait_ms": 0.30651461023481463, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.009842514991760254, "StateBufferConnector_ms": 0.021155834197998047, "ViewRequirementAgentConnector_ms": 0.399135947227478}, "num_episodes": 22, "episode_return_max": 400.0, "episode_return_min": -293.0, "episode_return_mean": 234.1669999999998, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1072000, "num_agent_steps_trained": 1072000, "num_env_steps_sampled": 268000, "num_env_steps_trained": 268000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 53.484652901249554, "num_env_steps_trained_throughput_per_sec": 53.484652901249554, "timesteps_total": 268000, "num_env_steps_sampled_lifetime": 268000, "num_agent_steps_sampled_lifetime": 1072000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1072000, "timers": {"training_iteration_time_ms": 76453.359, "restore_workers_time_ms": 0.017, "training_step_time_ms": 76453.287, "sample_time_ms": 4621.956, "learn_time_ms": 71803.763, "learn_throughput": 55.707, "synch_weights_time_ms": 21.317}, "counters": {"num_env_steps_sampled": 268000, "num_env_steps_trained": 268000, "num_agent_steps_sampled": 1072000, "num_agent_steps_trained": 1072000}, "done": false, "training_iteration": 67, "trial_id": "11e70_00000", "date": "2024-08-13_00-12-22", "timestamp": 1723522342, "time_this_iter_s": 75.0112841129303, "time_total_s": 3919.7986822128296, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2b93430>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3919.7986822128296, "iterations_since_restore": 67, "perf": {"cpu_util_percent": 88.99532710280374, "ram_util_percent": 83.4747663551402}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.183640612370123, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.899156992019169, "policy_loss": -0.003628177466684036, "vf_loss": 4.901862479391552, "vf_explained_var": 0.04718410404270919, "kl": 0.006151284937066271, "entropy": 0.8823887195536699, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 127575.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 6.097516214532196, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.725829201148301, "policy_loss": -0.007117214141581109, "vf_loss": 7.732160578581391, "vf_explained_var": 0.15689045335880664, "kl": 0.0069851732180961495, "entropy": 0.6344045372551711, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 127575.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 272000, "num_env_steps_trained": 272000, "num_agent_steps_sampled": 1088000, "num_agent_steps_trained": 1088000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -293.0, "episode_reward_mean": 197.29499999999985, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -888.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 749.0}, "policy_reward_mean": {"prey_policy": 67.3525, "predator_policy": 31.295}, "custom_metrics": {}, "hist_stats": {"episode_reward": [202.0, 327.1, 219.99999999999926, 325.29999999999995, 104.99999999999989, 236.19999999999936, 316.5, 184.09999999999943, 167.9999999999995, 186.79999999999941, 377.9, 347.0, 361.6, 323.5, 345.5, 245.39999999999972, 339.0, 178.89999999999927, 366.0, 199.6999999999994, 230.39999999999978, 373.70000000000005, 389.2, 383.8, 315.1, 252.4, 384.7, 115.69999999999948, 171.3999999999995, 389.2, 205.49999999999932, 117.3, 216.39999999999927, 40.0000000000003, 347.3, 168.7999999999995, 329.5, 390.0, 182.19999999999982, 307.70000000000005, 341.3, 371.2, 335.0, 129.2, 380.4, 382.0, 40.0000000000003, -293.0, 175.2, 211.9, 71.1, -30.200000000000003, 176.79999999999947, 306.7, 226.0, 219.99999999999926, 336.0, 370.1, 232.0, 363.0, 219.99999999999926, -11.200000000000003, 116.70000000000003, 400.0, -22.399999999999913, 189.4999999999994, -30.5, -81.10000000000007, -213.89999999999998, 199.0999999999994, 183.39999999999998, 40.0000000000003, 330.70000000000005, 394.6, 268.39999999999986, 16.000000000000057, 146.19999999999956, 167.20000000000005, 117.30000000000013, 393.5, 42.10000000000004, 117.60000000000002, 104.30000000000001, -61.599999999999966, 193.6, 19.899999999999665, 218.2, -92.0, 86.3, 69.4, -5.099999999999863, 255.0, 246.10000000000002, -31.0, 357.5, 81.0, 139.0, -92.00000000000009, -38.89999999999985, 286.1], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-34.0, 131.0, 127.1, 164.0, 200.0, 20.000000000000014, 125.29999999999998, 200.0, -13.0, 20.000000000000014, 200.0, 36.19999999999999, 153.5, 134.0, 20.000000000000014, 142.1, 116.0, 20.000000000000014, 170.0, -5.200000000000003, 180.5, 190.4, 152.0, 173.0, 164.0, 185.6, 169.4, 154.1, 195.5, 116.0, 173.0, 55.39999999999997, 122.0, 191.0, 140.0, 17.899999999999984, 149.0, 200.0, 20.000000000000014, 172.7, 70.39999999999996, 140.0, 175.7, 197.0, 189.2, 200.0, 191.9, 191.9, 167.0, 133.1, 145.4, 53.0, 184.7, 200.0, 20.000000000000014, 64.7, -34.59999999999975, 170.0, 200.0, 189.2, 168.5, 20.000000000000014, -204.09999999999968, 190.4, 20.000000000000014, 196.4, 20.000000000000014, 20.000000000000014, 197.3, 125.0, 144.79999999999998, 20.000000000000014, 172.1, 127.4, 200.0, 185.0, -265.8, 200.0, 89.0, 181.70000000000002, 140.0, 179.3, 185.0, 180.2, 160.4, 164.60000000000002, -50.80000000000001, 80.0, 182.0, 190.4, 182.0, 200.0, 20.000000000000014, 20.000000000000014, -295.0, -163.0, 100.1, 10.100000000000023, 198.2, -76.29999999999998, 53.0, -100.9, -311.8, 104.60000000000001, 20.000000000000014, 156.8, 111.80000000000004, 164.9, 56.0, 101.0, 200.0, 20.000000000000014, 104.0, 200.0, 193.1, 164.0, 68.0, 101.0, 176.0, 176.0, 20.000000000000014, 200.0, -17.200000000000003, -103.0, 182.9, -236.20000000000024, 200.0, 200.0, -240.40000000000035, 68.0, 156.5, 20.000000000000014, -118.0, -29.5, -48.10000000000002, -145.0, -154.9, -196.0, 20.000000000000014, 169.1, 94.70000000000005, 34.7, 20.000000000000014, 20.000000000000014, 192.8, 137.89999999999998, 198.2, 196.4, 73.69999999999997, 184.7, -106.0, 20.000000000000014, 20.000000000000014, 90.2, 57.2, 62.0, 23.299999999999983, 11.0, 199.1, 193.4, -8.200000000000003, -33.7, 8.600000000000023, 17.0, 48.8, -41.5, -44.19999999999994, -144.4, 155.3, -42.69999999999999, -85.00000000000003, 47.900000000000006, 83.0, 96.19999999999999, -247.0, -10.0, 47.0, -39.7, -12.699999999999996, -22.900000000000006, 20.000000000000014, -75.10000000000004, 47.0, 149.0, 104.0, 97.1, -888.0, 62.0, 170.0, 177.5, -36.1, 28.099999999999994, 181.7, -721.7, -268.0, 20.000000000000014, 20.000000000000014, -187.9, 106.1, 152.0], "policy_predator_policy_reward": [79.0, 26.0, 19.0, 17.0, 0.0, 0.0, 0.0, 0.0, 61.0, 37.0, 0.0, 0.0, 29.0, 0.0, 16.0, 6.0, 7.0, 25.0, 0.0, 22.0, 0.0, 7.0, 0.0, 22.0, 0.0, 12.0, 0.0, 0.0, 28.0, 6.0, 8.0, 9.0, 26.0, 0.0, 0.0, 21.0, 0.0, 17.0, 0.0, 7.0, 0.0, 20.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 15.0, 17.0, 37.0, 0.0, 0.0, 0.0, 31.0, 10.0, 26.0, 0.0, 0.0, 9.0, 8.0, 129.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.0, 0.0, 4.0, 23.0, 7.0, 5.0, 0.0, 188.0, 60.0, 0.0, 37.0, 0.0, 22.0, 0.0, 6.0, 10.0, 0.0, 26.0, 74.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 165.0, 0.0, 19.0, 46.0, 0.0, 90.0, 8.0, 111.0, 170.0, 7.0, 0.0, 0.0, 9.0, 21.0, 23.0, 46.0, 0.0, 0.0, 0.0, 32.0, 0.0, 13.0, 55.0, 8.0, 11.0, 0.0, 0.0, 0.0, 0.0, 109.0, 122.0, 48.0, 0.0, 0.0, 124.0, 26.0, 0.0, 13.0, 26.0, 91.0, 0.0, 112.0, 4.0, 133.0, 0.0, 10.0, 13.0, 41.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 102.0, 22.0, 14.0, 0.0, 48.0, 83.0, 0.0, 0.0, 1.0, 0.0, 84.0, 28.0, 64.0, 62.0, 35.0, 113.0, 14.0, 81.0, 0.0, 0.0, 57.0, 0.0, 39.0, 88.0, 77.0, 0.0, 79.0, 40.0, 65.0, 18.0, 32.0, 0.0, 59.0, 16.0, 29.0, 749.0, 46.0, 0.0, 10.0, 0.0, 89.0, 675.0, 4.0, 0.0, 156.0, 5.0, 124.0, 0.0, 28.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.009435746692753, "mean_inference_ms": 2.4598820459470208, "mean_action_processing_ms": 0.39656359035580735, "mean_env_wait_ms": 0.31123769503761656, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.025130033493041992, "StateBufferConnector_ms": 0.021220803260803223, "ViewRequirementAgentConnector_ms": 0.40625786781311035}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -293.0, "episode_return_mean": 197.29499999999985, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1088000, "num_agent_steps_trained": 1088000, "num_env_steps_sampled": 272000, "num_env_steps_trained": 272000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 56.676681692837484, "num_env_steps_trained_throughput_per_sec": 56.676681692837484, "timesteps_total": 272000, "num_env_steps_sampled_lifetime": 272000, "num_agent_steps_sampled_lifetime": 1088000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1088000, "timers": {"training_iteration_time_ms": 75510.882, "restore_workers_time_ms": 0.018, "training_step_time_ms": 75510.81, "sample_time_ms": 3943.005, "learn_time_ms": 71538.88, "learn_throughput": 55.914, "synch_weights_time_ms": 23.117}, "counters": {"num_env_steps_sampled": 272000, "num_env_steps_trained": 272000, "num_agent_steps_sampled": 1088000, "num_agent_steps_trained": 1088000}, "done": false, "training_iteration": 68, "trial_id": "11e70_00000", "date": "2024-08-13_00-13-33", "timestamp": 1723522413, "time_this_iter_s": 70.77220296859741, "time_total_s": 3990.570885181427, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b4a09d30>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3990.570885181427, "iterations_since_restore": 68, "perf": {"cpu_util_percent": 87.441, "ram_util_percent": 83.47200000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.789783351825028, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.438307041087478, "policy_loss": -0.008043982031158905, "vf_loss": 5.4450129400485405, "vf_explained_var": 0.14595893019090886, "kl": 0.008920606905771586, "entropy": 0.8932544007818535, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 129465.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 7.2041884221097146, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.2533121492496875, "policy_loss": -0.008847087116236921, "vf_loss": 7.261331670751017, "vf_explained_var": -0.2220493942656845, "kl": 0.00735620552007387, "entropy": 0.6413976679403315, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 129465.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 276000, "num_env_steps_trained": 276000, "num_agent_steps_sampled": 1104000, "num_agent_steps_trained": 1104000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -399.0, "episode_reward_mean": 130.22899999999993, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -888.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 749.0}, "policy_reward_mean": {"prey_policy": 24.239499999999992, "predator_policy": 40.875}, "custom_metrics": {}, "hist_stats": {"episode_reward": [383.8, 315.1, 252.4, 384.7, 115.69999999999948, 171.3999999999995, 389.2, 205.49999999999932, 117.3, 216.39999999999927, 40.0000000000003, 347.3, 168.7999999999995, 329.5, 390.0, 182.19999999999982, 307.70000000000005, 341.3, 371.2, 335.0, 129.2, 380.4, 382.0, 40.0000000000003, -293.0, 175.2, 211.9, 71.1, -30.200000000000003, 176.79999999999947, 306.7, 226.0, 219.99999999999926, 336.0, 370.1, 232.0, 363.0, 219.99999999999926, -11.200000000000003, 116.70000000000003, 400.0, -22.399999999999913, 189.4999999999994, -30.5, -81.10000000000007, -213.89999999999998, 199.0999999999994, 183.39999999999998, 40.0000000000003, 330.70000000000005, 394.6, 268.39999999999986, 16.000000000000057, 146.19999999999956, 167.20000000000005, 117.30000000000013, 393.5, 42.10000000000004, 117.60000000000002, 104.30000000000001, -61.599999999999966, 193.6, 19.899999999999665, 218.2, -92.0, 86.3, 69.4, -5.099999999999863, 255.0, 246.10000000000002, -31.0, 357.5, 81.0, 139.0, -92.00000000000009, -38.89999999999985, 286.1, -123.89999999999992, 40.0000000000003, -8.099999999999994, -51.400000000000006, -56.99999999999991, 152.0, 261.6, -399.0, -51.3999999999999, 96.49999999999932, 47.70000000000018, -152.50000000000048, 22.00000000000015, 3.8000000000002156, 39.0, 345.1, -252.0, 263.39999999999964, -107.0, -178.0, 27.0, -230.9, -44.7], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [191.9, 191.9, 167.0, 133.1, 145.4, 53.0, 184.7, 200.0, 20.000000000000014, 64.7, -34.59999999999975, 170.0, 200.0, 189.2, 168.5, 20.000000000000014, -204.09999999999968, 190.4, 20.000000000000014, 196.4, 20.000000000000014, 20.000000000000014, 197.3, 125.0, 144.79999999999998, 20.000000000000014, 172.1, 127.4, 200.0, 185.0, -265.8, 200.0, 89.0, 181.70000000000002, 140.0, 179.3, 185.0, 180.2, 160.4, 164.60000000000002, -50.80000000000001, 80.0, 182.0, 190.4, 182.0, 200.0, 20.000000000000014, 20.000000000000014, -295.0, -163.0, 100.1, 10.100000000000023, 198.2, -76.29999999999998, 53.0, -100.9, -311.8, 104.60000000000001, 20.000000000000014, 156.8, 111.80000000000004, 164.9, 56.0, 101.0, 200.0, 20.000000000000014, 104.0, 200.0, 193.1, 164.0, 68.0, 101.0, 176.0, 176.0, 20.000000000000014, 200.0, -17.200000000000003, -103.0, 182.9, -236.20000000000024, 200.0, 200.0, -240.40000000000035, 68.0, 156.5, 20.000000000000014, -118.0, -29.5, -48.10000000000002, -145.0, -154.9, -196.0, 20.000000000000014, 169.1, 94.70000000000005, 34.7, 20.000000000000014, 20.000000000000014, 192.8, 137.89999999999998, 198.2, 196.4, 73.69999999999997, 184.7, -106.0, 20.000000000000014, 20.000000000000014, 90.2, 57.2, 62.0, 23.299999999999983, 11.0, 199.1, 193.4, -8.200000000000003, -33.7, 8.600000000000023, 17.0, 48.8, -41.5, -44.19999999999994, -144.4, 155.3, -42.69999999999999, -85.00000000000003, 47.900000000000006, 83.0, 96.19999999999999, -247.0, -10.0, 47.0, -39.7, -12.699999999999996, -22.900000000000006, 20.000000000000014, -75.10000000000004, 47.0, 149.0, 104.0, 97.1, -888.0, 62.0, 170.0, 177.5, -36.1, 28.099999999999994, 181.7, -721.7, -268.0, 20.000000000000014, 20.000000000000014, -187.9, 106.1, 152.0, -107.2, -126.70000000000002, 20.000000000000014, 20.000000000000014, -100.0, -12.099999999999994, -22.599999999999994, -146.8, 20.000000000000014, -217.0, 59.0, 14.0, 102.5, 109.1, -280.3, -288.7, -183.4, 20.000000000000014, 20.000000000000014, 21.5, 20.000000000000014, -55.3, -347.5, 20.000000000000014, -97.0, 20.000000000000014, 20.000000000000014, -53.20000000000004, -40.0, -28.0, 193.7, 151.4, -190.0, -205.0, 76.39999999999998, 179.0, -331.0, 41.0, -232.0, -127.0, -211.0, 101.0, -256.9, -139.0, -48.7, -184.0], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 15.0, 17.0, 37.0, 0.0, 0.0, 0.0, 31.0, 10.0, 26.0, 0.0, 0.0, 9.0, 8.0, 129.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.0, 0.0, 4.0, 23.0, 7.0, 5.0, 0.0, 188.0, 60.0, 0.0, 37.0, 0.0, 22.0, 0.0, 6.0, 10.0, 0.0, 26.0, 74.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 165.0, 0.0, 19.0, 46.0, 0.0, 90.0, 8.0, 111.0, 170.0, 7.0, 0.0, 0.0, 9.0, 21.0, 23.0, 46.0, 0.0, 0.0, 0.0, 32.0, 0.0, 13.0, 55.0, 8.0, 11.0, 0.0, 0.0, 0.0, 0.0, 109.0, 122.0, 48.0, 0.0, 0.0, 124.0, 26.0, 0.0, 13.0, 26.0, 91.0, 0.0, 112.0, 4.0, 133.0, 0.0, 10.0, 13.0, 41.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 102.0, 22.0, 14.0, 0.0, 48.0, 83.0, 0.0, 0.0, 1.0, 0.0, 84.0, 28.0, 64.0, 62.0, 35.0, 113.0, 14.0, 81.0, 0.0, 0.0, 57.0, 0.0, 39.0, 88.0, 77.0, 0.0, 79.0, 40.0, 65.0, 18.0, 32.0, 0.0, 59.0, 16.0, 29.0, 749.0, 46.0, 0.0, 10.0, 0.0, 89.0, 675.0, 4.0, 0.0, 156.0, 5.0, 124.0, 0.0, 28.0, 30.0, 80.0, 0.0, 0.0, 0.0, 104.0, 47.0, 71.0, 31.0, 109.0, 51.0, 28.0, 0.0, 50.0, 169.0, 1.0, 106.0, 6.0, 55.0, 0.0, 46.0, 37.0, 175.0, 0.0, 0.0, 99.0, 37.0, 0.0, 107.0, 0.0, 0.0, 0.0, 77.0, 66.0, 8.0, 0.0, 7.0, 176.0, 85.0, 96.0, 0.0, 137.0, 158.0, 7.0, 103.0, 85.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0338845649787545, "mean_inference_ms": 2.517688852523562, "mean_action_processing_ms": 0.4055995560459027, "mean_env_wait_ms": 0.31828321584681574, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.03304028511047363, "StateBufferConnector_ms": 0.0211946964263916, "ViewRequirementAgentConnector_ms": 0.3860898017883301}, "num_episodes": 23, "episode_return_max": 400.0, "episode_return_min": -399.0, "episode_return_mean": 130.22899999999993, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1104000, "num_agent_steps_trained": 1104000, "num_env_steps_sampled": 276000, "num_env_steps_trained": 276000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 56.15413028209033, "num_env_steps_trained_throughput_per_sec": 56.15413028209033, "timesteps_total": 276000, "num_env_steps_sampled_lifetime": 276000, "num_agent_steps_sampled_lifetime": 1104000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1104000, "timers": {"training_iteration_time_ms": 75438.802, "restore_workers_time_ms": 0.017, "training_step_time_ms": 75438.73, "sample_time_ms": 4243.971, "learn_time_ms": 71164.485, "learn_throughput": 56.208, "synch_weights_time_ms": 24.46}, "counters": {"num_env_steps_sampled": 276000, "num_env_steps_trained": 276000, "num_agent_steps_sampled": 1104000, "num_agent_steps_trained": 1104000}, "done": false, "training_iteration": 69, "trial_id": "11e70_00000", "date": "2024-08-13_00-14-44", "timestamp": 1723522484, "time_this_iter_s": 71.39178991317749, "time_total_s": 4061.9626750946045, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3f48d30>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 4061.9626750946045, "iterations_since_restore": 69, "perf": {"cpu_util_percent": 87.4049504950495, "ram_util_percent": 83.53663366336633}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 6.2488232880042345, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.012100406550856, "policy_loss": -0.005725676025801077, "vf_loss": 5.016428244933881, "vf_explained_var": 0.05455046050132267, "kl": 0.009318905983069581, "entropy": 0.9124527133015728, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 131355.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 9.712402814405936, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.179141533311713, "policy_loss": -0.010068178706477204, "vf_loss": 7.188360203132428, "vf_explained_var": 0.14863825967072178, "kl": 0.007551129882109412, "entropy": 0.6779492800828641, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 131355.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 280000, "num_env_steps_trained": 280000, "num_agent_steps_sampled": 1120000, "num_agent_steps_trained": 1120000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -399.0, "episode_reward_mean": 71.11299999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -888.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 749.0}, "policy_reward_mean": {"prey_policy": -16.403500000000005, "predator_policy": 51.96}, "custom_metrics": {}, "hist_stats": {"episode_reward": [371.2, 335.0, 129.2, 380.4, 382.0, 40.0000000000003, -293.0, 175.2, 211.9, 71.1, -30.200000000000003, 176.79999999999947, 306.7, 226.0, 219.99999999999926, 336.0, 370.1, 232.0, 363.0, 219.99999999999926, -11.200000000000003, 116.70000000000003, 400.0, -22.399999999999913, 189.4999999999994, -30.5, -81.10000000000007, -213.89999999999998, 199.0999999999994, 183.39999999999998, 40.0000000000003, 330.70000000000005, 394.6, 268.39999999999986, 16.000000000000057, 146.19999999999956, 167.20000000000005, 117.30000000000013, 393.5, 42.10000000000004, 117.60000000000002, 104.30000000000001, -61.599999999999966, 193.6, 19.899999999999665, 218.2, -92.0, 86.3, 69.4, -5.099999999999863, 255.0, 246.10000000000002, -31.0, 357.5, 81.0, 139.0, -92.00000000000009, -38.89999999999985, 286.1, -123.89999999999992, 40.0000000000003, -8.099999999999994, -51.400000000000006, -56.99999999999991, 152.0, 261.6, -399.0, -51.3999999999999, 96.49999999999932, 47.70000000000018, -152.50000000000048, 22.00000000000015, 3.8000000000002156, 39.0, 345.1, -252.0, 263.39999999999964, -107.0, -178.0, 27.0, -230.9, -44.7, -223.6, -25.5, 29.700000000000003, 40.0000000000003, -307.6, -208.90000000000003, 0.5000000000001029, 400.0, -227.19999999999996, 222.69999999999993, -167.8, -319.6, -63.599999999999795, -370.0, -1.0000000000000568, -262.7, -120.99999999999989, 352.3], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [185.0, 180.2, 160.4, 164.60000000000002, -50.80000000000001, 80.0, 182.0, 190.4, 182.0, 200.0, 20.000000000000014, 20.000000000000014, -295.0, -163.0, 100.1, 10.100000000000023, 198.2, -76.29999999999998, 53.0, -100.9, -311.8, 104.60000000000001, 20.000000000000014, 156.8, 111.80000000000004, 164.9, 56.0, 101.0, 200.0, 20.000000000000014, 104.0, 200.0, 193.1, 164.0, 68.0, 101.0, 176.0, 176.0, 20.000000000000014, 200.0, -17.200000000000003, -103.0, 182.9, -236.20000000000024, 200.0, 200.0, -240.40000000000035, 68.0, 156.5, 20.000000000000014, -118.0, -29.5, -48.10000000000002, -145.0, -154.9, -196.0, 20.000000000000014, 169.1, 94.70000000000005, 34.7, 20.000000000000014, 20.000000000000014, 192.8, 137.89999999999998, 198.2, 196.4, 73.69999999999997, 184.7, -106.0, 20.000000000000014, 20.000000000000014, 90.2, 57.2, 62.0, 23.299999999999983, 11.0, 199.1, 193.4, -8.200000000000003, -33.7, 8.600000000000023, 17.0, 48.8, -41.5, -44.19999999999994, -144.4, 155.3, -42.69999999999999, -85.00000000000003, 47.900000000000006, 83.0, 96.19999999999999, -247.0, -10.0, 47.0, -39.7, -12.699999999999996, -22.900000000000006, 20.000000000000014, -75.10000000000004, 47.0, 149.0, 104.0, 97.1, -888.0, 62.0, 170.0, 177.5, -36.1, 28.099999999999994, 181.7, -721.7, -268.0, 20.000000000000014, 20.000000000000014, -187.9, 106.1, 152.0, -107.2, -126.70000000000002, 20.000000000000014, 20.000000000000014, -100.0, -12.099999999999994, -22.599999999999994, -146.8, 20.000000000000014, -217.0, 59.0, 14.0, 102.5, 109.1, -280.3, -288.7, -183.4, 20.000000000000014, 20.000000000000014, 21.5, 20.000000000000014, -55.3, -347.5, 20.000000000000014, -97.0, 20.000000000000014, 20.000000000000014, -53.20000000000004, -40.0, -28.0, 193.7, 151.4, -190.0, -205.0, 76.39999999999998, 179.0, -331.0, 41.0, -232.0, -127.0, -211.0, 101.0, -256.9, -139.0, -48.7, -184.0, -223.0, -169.6, -175.0, 15.499999999999998, -112.3, 35.0, 20.000000000000014, 20.000000000000014, -220.6, -241.0, -46.89999999999999, -367.0, 20.000000000000014, -140.49999999999997, 200.0, 200.0, -379.0, -80.2, 196.4, -537.6999999999999, -115.30000000000001, -359.5, -293.8, -206.8, 20.000000000000014, -223.6, -277.0, -283.0, -61.000000000000014, -31.0, -187.0, -204.7, -43.00000000000004, -226.0, 164.9, 187.4], "policy_predator_policy_reward": [0.0, 6.0, 10.0, 0.0, 26.0, 74.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 165.0, 0.0, 19.0, 46.0, 0.0, 90.0, 8.0, 111.0, 170.0, 7.0, 0.0, 0.0, 9.0, 21.0, 23.0, 46.0, 0.0, 0.0, 0.0, 32.0, 0.0, 13.0, 55.0, 8.0, 11.0, 0.0, 0.0, 0.0, 0.0, 109.0, 122.0, 48.0, 0.0, 0.0, 124.0, 26.0, 0.0, 13.0, 26.0, 91.0, 0.0, 112.0, 4.0, 133.0, 0.0, 10.0, 13.0, 41.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 102.0, 22.0, 14.0, 0.0, 48.0, 83.0, 0.0, 0.0, 1.0, 0.0, 84.0, 28.0, 64.0, 62.0, 35.0, 113.0, 14.0, 81.0, 0.0, 0.0, 57.0, 0.0, 39.0, 88.0, 77.0, 0.0, 79.0, 40.0, 65.0, 18.0, 32.0, 0.0, 59.0, 16.0, 29.0, 749.0, 46.0, 0.0, 10.0, 0.0, 89.0, 675.0, 4.0, 0.0, 156.0, 5.0, 124.0, 0.0, 28.0, 30.0, 80.0, 0.0, 0.0, 0.0, 104.0, 47.0, 71.0, 31.0, 109.0, 51.0, 28.0, 0.0, 50.0, 169.0, 1.0, 106.0, 6.0, 55.0, 0.0, 46.0, 37.0, 175.0, 0.0, 0.0, 99.0, 37.0, 0.0, 107.0, 0.0, 0.0, 0.0, 77.0, 66.0, 8.0, 0.0, 7.0, 176.0, 85.0, 96.0, 0.0, 137.0, 158.0, 7.0, 103.0, 85.0, 66.0, 103.0, 0.0, 134.0, 48.0, 59.0, 0.0, 0.0, 0.0, 154.0, 189.0, 16.0, 88.0, 33.0, 0.0, 0.0, 90.0, 142.0, 352.0, 212.0, 182.0, 125.0, 181.0, 0.0, 140.0, 0.0, 128.0, 62.0, 20.0, 71.0, 0.0, 129.0, 148.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0541528236391133, "mean_inference_ms": 2.569632950534233, "mean_action_processing_ms": 0.41338151006479507, "mean_env_wait_ms": 0.3246832921476053, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.03943228721618652, "StateBufferConnector_ms": 0.023354291915893555, "ViewRequirementAgentConnector_ms": 0.3922727108001709}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -399.0, "episode_return_mean": 71.11299999999999, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1120000, "num_agent_steps_trained": 1120000, "num_env_steps_sampled": 280000, "num_env_steps_trained": 280000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 54.3070087460284, "num_env_steps_trained_throughput_per_sec": 54.3070087460284, "timesteps_total": 280000, "num_env_steps_sampled_lifetime": 280000, "num_agent_steps_sampled_lifetime": 1120000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1120000, "timers": {"training_iteration_time_ms": 75693.536, "restore_workers_time_ms": 0.017, "training_step_time_ms": 75693.468, "sample_time_ms": 4529.981, "learn_time_ms": 71132.57, "learn_throughput": 56.233, "synch_weights_time_ms": 25.387}, "counters": {"num_env_steps_sampled": 280000, "num_env_steps_trained": 280000, "num_agent_steps_sampled": 1120000, "num_agent_steps_trained": 1120000}, "done": false, "training_iteration": 70, "trial_id": "11e70_00000", "date": "2024-08-13_00-15-58", "timestamp": 1723522558, "time_this_iter_s": 73.7157769203186, "time_total_s": 4135.678452014923, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2b67700>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 4135.678452014923, "iterations_since_restore": 70, "perf": {"cpu_util_percent": 88.03076923076924, "ram_util_percent": 83.40096153846154}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 8.58273089827684, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.291845578995962, "policy_loss": -0.011590389680196211, "vf_loss": 6.299694736672457, "vf_explained_var": 0.2203332970697413, "kl": 0.024941487250041628, "entropy": 0.9809041949491653, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 133245.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.501446027888192, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.722306927423628, "policy_loss": -0.009314461482846469, "vf_loss": 7.730688832045863, "vf_explained_var": -0.026582117843880225, "kl": 0.00828941668984678, "entropy": 0.7365272870454839, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 133245.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 284000, "num_env_steps_trained": 284000, "num_agent_steps_sampled": 1136000, "num_agent_steps_trained": 1136000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -461.4, "episode_reward_mean": 9.866999999999985, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -888.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 749.0}, "policy_reward_mean": {"prey_policy": -61.711500000000015, "predator_policy": 66.645}, "custom_metrics": {}, "hist_stats": {"episode_reward": [363.0, 219.99999999999926, -11.200000000000003, 116.70000000000003, 400.0, -22.399999999999913, 189.4999999999994, -30.5, -81.10000000000007, -213.89999999999998, 199.0999999999994, 183.39999999999998, 40.0000000000003, 330.70000000000005, 394.6, 268.39999999999986, 16.000000000000057, 146.19999999999956, 167.20000000000005, 117.30000000000013, 393.5, 42.10000000000004, 117.60000000000002, 104.30000000000001, -61.599999999999966, 193.6, 19.899999999999665, 218.2, -92.0, 86.3, 69.4, -5.099999999999863, 255.0, 246.10000000000002, -31.0, 357.5, 81.0, 139.0, -92.00000000000009, -38.89999999999985, 286.1, -123.89999999999992, 40.0000000000003, -8.099999999999994, -51.400000000000006, -56.99999999999991, 152.0, 261.6, -399.0, -51.3999999999999, 96.49999999999932, 47.70000000000018, -152.50000000000048, 22.00000000000015, 3.8000000000002156, 39.0, 345.1, -252.0, 263.39999999999964, -107.0, -178.0, 27.0, -230.9, -44.7, -223.6, -25.5, 29.700000000000003, 40.0000000000003, -307.6, -208.90000000000003, 0.5000000000001029, 400.0, -227.19999999999996, 222.69999999999993, -167.8, -319.6, -63.599999999999795, -370.0, -1.0000000000000568, -262.7, -120.99999999999989, 352.3, 392.8, -121.0, -123.4, -292.40000000000003, -77.8, -406.0, 112.49999999999994, -28.999999999999936, -6.599999999999945, 400.0, -461.4, -81.7, -371.6, -83.19999999999996, -364.4, -231.39999999999992, -322.0, -417.6], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [176.0, 176.0, 20.000000000000014, 200.0, -17.200000000000003, -103.0, 182.9, -236.20000000000024, 200.0, 200.0, -240.40000000000035, 68.0, 156.5, 20.000000000000014, -118.0, -29.5, -48.10000000000002, -145.0, -154.9, -196.0, 20.000000000000014, 169.1, 94.70000000000005, 34.7, 20.000000000000014, 20.000000000000014, 192.8, 137.89999999999998, 198.2, 196.4, 73.69999999999997, 184.7, -106.0, 20.000000000000014, 20.000000000000014, 90.2, 57.2, 62.0, 23.299999999999983, 11.0, 199.1, 193.4, -8.200000000000003, -33.7, 8.600000000000023, 17.0, 48.8, -41.5, -44.19999999999994, -144.4, 155.3, -42.69999999999999, -85.00000000000003, 47.900000000000006, 83.0, 96.19999999999999, -247.0, -10.0, 47.0, -39.7, -12.699999999999996, -22.900000000000006, 20.000000000000014, -75.10000000000004, 47.0, 149.0, 104.0, 97.1, -888.0, 62.0, 170.0, 177.5, -36.1, 28.099999999999994, 181.7, -721.7, -268.0, 20.000000000000014, 20.000000000000014, -187.9, 106.1, 152.0, -107.2, -126.70000000000002, 20.000000000000014, 20.000000000000014, -100.0, -12.099999999999994, -22.599999999999994, -146.8, 20.000000000000014, -217.0, 59.0, 14.0, 102.5, 109.1, -280.3, -288.7, -183.4, 20.000000000000014, 20.000000000000014, 21.5, 20.000000000000014, -55.3, -347.5, 20.000000000000014, -97.0, 20.000000000000014, 20.000000000000014, -53.20000000000004, -40.0, -28.0, 193.7, 151.4, -190.0, -205.0, 76.39999999999998, 179.0, -331.0, 41.0, -232.0, -127.0, -211.0, 101.0, -256.9, -139.0, -48.7, -184.0, -223.0, -169.6, -175.0, 15.499999999999998, -112.3, 35.0, 20.000000000000014, 20.000000000000014, -220.6, -241.0, -46.89999999999999, -367.0, 20.000000000000014, -140.49999999999997, 200.0, 200.0, -379.0, -80.2, 196.4, -537.6999999999999, -115.30000000000001, -359.5, -293.8, -206.8, 20.000000000000014, -223.6, -277.0, -283.0, -61.000000000000014, -31.0, -187.0, -204.7, -43.00000000000004, -226.0, 164.9, 187.4, 200.0, 192.8, -271.0, -10.0, -102.4, -151.0, -244.0, -360.4, 0.4999999999999858, -226.3, -280.0, -298.0, -729.4999999999997, 200.0, -280.0, 20.000000000000014, 20.000000000000014, -163.60000000000002, 200.0, 200.0, -362.8, -292.6, -49.0, -147.7, -273.7, -280.9, -347.2, 20.000000000000014, -325.0, -312.4, -228.4, -301.0, -280.0, -397.0, -340.9, -366.7], "policy_predator_policy_reward": [11.0, 0.0, 0.0, 0.0, 0.0, 109.0, 122.0, 48.0, 0.0, 0.0, 124.0, 26.0, 0.0, 13.0, 26.0, 91.0, 0.0, 112.0, 4.0, 133.0, 0.0, 10.0, 13.0, 41.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 102.0, 22.0, 14.0, 0.0, 48.0, 83.0, 0.0, 0.0, 1.0, 0.0, 84.0, 28.0, 64.0, 62.0, 35.0, 113.0, 14.0, 81.0, 0.0, 0.0, 57.0, 0.0, 39.0, 88.0, 77.0, 0.0, 79.0, 40.0, 65.0, 18.0, 32.0, 0.0, 59.0, 16.0, 29.0, 749.0, 46.0, 0.0, 10.0, 0.0, 89.0, 675.0, 4.0, 0.0, 156.0, 5.0, 124.0, 0.0, 28.0, 30.0, 80.0, 0.0, 0.0, 0.0, 104.0, 47.0, 71.0, 31.0, 109.0, 51.0, 28.0, 0.0, 50.0, 169.0, 1.0, 106.0, 6.0, 55.0, 0.0, 46.0, 37.0, 175.0, 0.0, 0.0, 99.0, 37.0, 0.0, 107.0, 0.0, 0.0, 0.0, 77.0, 66.0, 8.0, 0.0, 7.0, 176.0, 85.0, 96.0, 0.0, 137.0, 158.0, 7.0, 103.0, 85.0, 66.0, 103.0, 0.0, 134.0, 48.0, 59.0, 0.0, 0.0, 0.0, 154.0, 189.0, 16.0, 88.0, 33.0, 0.0, 0.0, 90.0, 142.0, 352.0, 212.0, 182.0, 125.0, 181.0, 0.0, 140.0, 0.0, 128.0, 62.0, 20.0, 71.0, 0.0, 129.0, 148.0, 0.0, 0.0, 0.0, 0.0, 0.0, 160.0, 0.0, 0.0, 130.0, 146.0, 166.0, 0.0, 148.0, 172.0, 0.0, 11.0, 631.0, 109.0, 122.0, 59.0, 78.0, 0.0, 0.0, 0.0, 194.0, 0.0, 115.0, 183.0, 0.0, 106.0, 138.0, 172.0, 101.0, 132.0, 166.0, 156.0, 199.0, 137.0, 153.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.066335985655238, "mean_inference_ms": 2.602005859672081, "mean_action_processing_ms": 0.4185671881674795, "mean_env_wait_ms": 0.3290762959305294, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.042069435119628906, "StateBufferConnector_ms": 0.01154792308807373, "ViewRequirementAgentConnector_ms": 0.3328324556350708}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -461.4, "episode_return_mean": 9.866999999999985, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1136000, "num_agent_steps_trained": 1136000, "num_env_steps_sampled": 284000, "num_env_steps_trained": 284000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 57.57673556720962, "num_env_steps_trained_throughput_per_sec": 57.57673556720962, "timesteps_total": 284000, "num_env_steps_sampled_lifetime": 284000, "num_agent_steps_sampled_lifetime": 1136000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1136000, "timers": {"training_iteration_time_ms": 74911.953, "restore_workers_time_ms": 0.017, "training_step_time_ms": 74911.892, "sample_time_ms": 4462.943, "learn_time_ms": 70419.204, "learn_throughput": 56.803, "synch_weights_time_ms": 24.734}, "counters": {"num_env_steps_sampled": 284000, "num_env_steps_trained": 284000, "num_agent_steps_sampled": 1136000, "num_agent_steps_trained": 1136000}, "done": false, "training_iteration": 71, "trial_id": "11e70_00000", "date": "2024-08-13_00-17-08", "timestamp": 1723522628, "time_this_iter_s": 69.54414916038513, "time_total_s": 4205.222601175308, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3f8a4c0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 4205.222601175308, "iterations_since_restore": 71, "perf": {"cpu_util_percent": 87.03333333333333, "ram_util_percent": 83.01313131313132}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 11.797489401903102, "cur_kl_coeff": 0.22500000000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.557186452673856, "policy_loss": -0.009830723664718408, "vf_loss": 7.565120541103303, "vf_explained_var": 0.1930961549282074, "kl": 0.008429549548000041, "entropy": 0.9548194004114343, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 135135.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 6.084467971009552, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.871421159007562, "policy_loss": -0.011040319324342938, "vf_loss": 6.881413574824258, "vf_explained_var": -0.2710349961563393, "kl": 0.009314789698023152, "entropy": 0.822273985860209, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 135135.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 288000, "num_env_steps_trained": 288000, "num_agent_steps_sampled": 1152000, "num_agent_steps_trained": 1152000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -461.4, "episode_reward_mean": -50.605999999999995, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -888.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 749.0}, "policy_reward_mean": {"prey_policy": -107.68299999999999, "predator_policy": 82.38}, "custom_metrics": {}, "hist_stats": {"episode_reward": [117.60000000000002, 104.30000000000001, -61.599999999999966, 193.6, 19.899999999999665, 218.2, -92.0, 86.3, 69.4, -5.099999999999863, 255.0, 246.10000000000002, -31.0, 357.5, 81.0, 139.0, -92.00000000000009, -38.89999999999985, 286.1, -123.89999999999992, 40.0000000000003, -8.099999999999994, -51.400000000000006, -56.99999999999991, 152.0, 261.6, -399.0, -51.3999999999999, 96.49999999999932, 47.70000000000018, -152.50000000000048, 22.00000000000015, 3.8000000000002156, 39.0, 345.1, -252.0, 263.39999999999964, -107.0, -178.0, 27.0, -230.9, -44.7, -223.6, -25.5, 29.700000000000003, 40.0000000000003, -307.6, -208.90000000000003, 0.5000000000001029, 400.0, -227.19999999999996, 222.69999999999993, -167.8, -319.6, -63.599999999999795, -370.0, -1.0000000000000568, -262.7, -120.99999999999989, 352.3, 392.8, -121.0, -123.4, -292.40000000000003, -77.8, -406.0, 112.49999999999994, -28.999999999999936, -6.599999999999945, 400.0, -461.4, -81.7, -371.6, -83.19999999999996, -364.4, -231.39999999999992, -322.0, -417.6, 384.7, -342.5, -440.6, -251.79999999999995, 386.5, 40.0, -344.2, -53.49999999999985, -333.90000000000003, -383.5999999999999, -88.09999999999994, -26.199999999999825, -104.00000000000014, 74.80000000000001, -357.8, -212.50000000000003, -43.99999999999983, -29.59999999999983, -361.4, -101.00000000000043, -118.00000000000051, -112.00000000000031], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [8.600000000000023, 17.0, 48.8, -41.5, -44.19999999999994, -144.4, 155.3, -42.69999999999999, -85.00000000000003, 47.900000000000006, 83.0, 96.19999999999999, -247.0, -10.0, 47.0, -39.7, -12.699999999999996, -22.900000000000006, 20.000000000000014, -75.10000000000004, 47.0, 149.0, 104.0, 97.1, -888.0, 62.0, 170.0, 177.5, -36.1, 28.099999999999994, 181.7, -721.7, -268.0, 20.000000000000014, 20.000000000000014, -187.9, 106.1, 152.0, -107.2, -126.70000000000002, 20.000000000000014, 20.000000000000014, -100.0, -12.099999999999994, -22.599999999999994, -146.8, 20.000000000000014, -217.0, 59.0, 14.0, 102.5, 109.1, -280.3, -288.7, -183.4, 20.000000000000014, 20.000000000000014, 21.5, 20.000000000000014, -55.3, -347.5, 20.000000000000014, -97.0, 20.000000000000014, 20.000000000000014, -53.20000000000004, -40.0, -28.0, 193.7, 151.4, -190.0, -205.0, 76.39999999999998, 179.0, -331.0, 41.0, -232.0, -127.0, -211.0, 101.0, -256.9, -139.0, -48.7, -184.0, -223.0, -169.6, -175.0, 15.499999999999998, -112.3, 35.0, 20.000000000000014, 20.000000000000014, -220.6, -241.0, -46.89999999999999, -367.0, 20.000000000000014, -140.49999999999997, 200.0, 200.0, -379.0, -80.2, 196.4, -537.6999999999999, -115.30000000000001, -359.5, -293.8, -206.8, 20.000000000000014, -223.6, -277.0, -283.0, -61.000000000000014, -31.0, -187.0, -204.7, -43.00000000000004, -226.0, 164.9, 187.4, 200.0, 192.8, -271.0, -10.0, -102.4, -151.0, -244.0, -360.4, 0.4999999999999858, -226.3, -280.0, -298.0, -729.4999999999997, 200.0, -280.0, 20.000000000000014, 20.000000000000014, -163.60000000000002, 200.0, 200.0, -362.8, -292.6, -49.0, -147.7, -273.7, -280.9, -347.2, 20.000000000000014, -325.0, -312.4, -228.4, -301.0, -280.0, -397.0, -340.9, -366.7, 190.1, 194.6, -379.0, -329.5, -328.9, -324.7, -247.0, -161.8, 188.3, 198.2, 50.599999999999994, -115.6, -187.60000000000002, -319.6, -323.2, 13.699999999999964, -288.40000000000003, -248.5, -304.0, -247.60000000000002, -320.2, -79.9, 7.399999999999965, -277.6, 20.000000000000014, -286.0, 198.2, -293.40000000000015, -319.0, -362.8, -191.8, -363.7, -241.0, 20.000000000000014, -283.6, 20.000000000000014, -294.4, -271.0, -379.0, 20.000000000000014, -252.39999999999998, -34.59999999999975, 20.000000000000014, -298.0], "policy_predator_policy_reward": [28.0, 64.0, 62.0, 35.0, 113.0, 14.0, 81.0, 0.0, 0.0, 57.0, 0.0, 39.0, 88.0, 77.0, 0.0, 79.0, 40.0, 65.0, 18.0, 32.0, 0.0, 59.0, 16.0, 29.0, 749.0, 46.0, 0.0, 10.0, 0.0, 89.0, 675.0, 4.0, 0.0, 156.0, 5.0, 124.0, 0.0, 28.0, 30.0, 80.0, 0.0, 0.0, 0.0, 104.0, 47.0, 71.0, 31.0, 109.0, 51.0, 28.0, 0.0, 50.0, 169.0, 1.0, 106.0, 6.0, 55.0, 0.0, 46.0, 37.0, 175.0, 0.0, 0.0, 99.0, 37.0, 0.0, 107.0, 0.0, 0.0, 0.0, 77.0, 66.0, 8.0, 0.0, 7.0, 176.0, 85.0, 96.0, 0.0, 137.0, 158.0, 7.0, 103.0, 85.0, 66.0, 103.0, 0.0, 134.0, 48.0, 59.0, 0.0, 0.0, 0.0, 154.0, 189.0, 16.0, 88.0, 33.0, 0.0, 0.0, 90.0, 142.0, 352.0, 212.0, 182.0, 125.0, 181.0, 0.0, 140.0, 0.0, 128.0, 62.0, 20.0, 71.0, 0.0, 129.0, 148.0, 0.0, 0.0, 0.0, 0.0, 0.0, 160.0, 0.0, 0.0, 130.0, 146.0, 166.0, 0.0, 148.0, 172.0, 0.0, 11.0, 631.0, 109.0, 122.0, 59.0, 78.0, 0.0, 0.0, 0.0, 194.0, 0.0, 115.0, 183.0, 0.0, 106.0, 138.0, 172.0, 101.0, 132.0, 166.0, 156.0, 199.0, 137.0, 153.0, 0.0, 0.0, 194.0, 172.0, 39.0, 174.0, 157.0, 0.0, 0.0, 0.0, 105.0, 0.0, 163.0, 0.0, 107.0, 149.0, 27.0, 176.0, 0.0, 168.0, 148.0, 164.0, 147.0, 97.0, 162.0, 0.0, 170.0, 0.0, 141.0, 183.0, 157.0, 186.0, 64.0, 113.0, 109.0, 125.0, 125.0, 79.0, 67.0, 191.0, 26.0, 143.0, 166.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0786078381287114, "mean_inference_ms": 2.636611953264017, "mean_action_processing_ms": 0.42414236822868157, "mean_env_wait_ms": 0.33378599951722415, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.04737722873687744, "StateBufferConnector_ms": 0.017240405082702637, "ViewRequirementAgentConnector_ms": 0.31937527656555176}, "num_episodes": 22, "episode_return_max": 400.0, "episode_return_min": -461.4, "episode_return_mean": -50.605999999999995, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1152000, "num_agent_steps_trained": 1152000, "num_env_steps_sampled": 288000, "num_env_steps_trained": 288000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 63.10688699419538, "num_env_steps_trained_throughput_per_sec": 63.10688699419538, "timesteps_total": 288000, "num_env_steps_sampled_lifetime": 288000, "num_agent_steps_sampled_lifetime": 1152000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1152000, "timers": {"training_iteration_time_ms": 72945.035, "restore_workers_time_ms": 0.017, "training_step_time_ms": 72944.974, "sample_time_ms": 4326.736, "learn_time_ms": 68589.168, "learn_throughput": 58.318, "synch_weights_time_ms": 25.034}, "counters": {"num_env_steps_sampled": 288000, "num_env_steps_trained": 288000, "num_agent_steps_sampled": 1152000, "num_agent_steps_trained": 1152000}, "done": false, "training_iteration": 72, "trial_id": "11e70_00000", "date": "2024-08-13_00-18-11", "timestamp": 1723522691, "time_this_iter_s": 63.4835410118103, "time_total_s": 4268.7061421871185, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3f560d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 4268.7061421871185, "iterations_since_restore": 72, "perf": {"cpu_util_percent": 75.52111111111111, "ram_util_percent": 82.60777777777777}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 13.121533684629611, "cur_kl_coeff": 0.22500000000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.210339797236932, "policy_loss": -0.0068396378005485215, "vf_loss": 7.21571141777846, "vf_explained_var": 0.2490734063128315, "kl": 0.006524581715173754, "entropy": 0.9350801074631, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 137025.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 6.1349130663291485, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.556721253369851, "policy_loss": -0.00884521825389355, "vf_loss": 7.564756499144135, "vf_explained_var": -0.1613418044867339, "kl": 0.007199862521269886, "entropy": 0.7935831944778483, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 137025.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 292000, "num_env_steps_trained": 292000, "num_agent_steps_sampled": 1168000, "num_agent_steps_trained": 1168000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -498.5, "episode_reward_mean": -109.98700000000001, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -729.4999999999997, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 631.0}, "policy_reward_mean": {"prey_policy": -147.9185, "predator_policy": 92.925}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-56.99999999999991, 152.0, 261.6, -399.0, -51.3999999999999, 96.49999999999932, 47.70000000000018, -152.50000000000048, 22.00000000000015, 3.8000000000002156, 39.0, 345.1, -252.0, 263.39999999999964, -107.0, -178.0, 27.0, -230.9, -44.7, -223.6, -25.5, 29.700000000000003, 40.0000000000003, -307.6, -208.90000000000003, 0.5000000000001029, 400.0, -227.19999999999996, 222.69999999999993, -167.8, -319.6, -63.599999999999795, -370.0, -1.0000000000000568, -262.7, -120.99999999999989, 352.3, 392.8, -121.0, -123.4, -292.40000000000003, -77.8, -406.0, 112.49999999999994, -28.999999999999936, -6.599999999999945, 400.0, -461.4, -81.7, -371.6, -83.19999999999996, -364.4, -231.39999999999992, -322.0, -417.6, 384.7, -342.5, -440.6, -251.79999999999995, 386.5, 40.0, -344.2, -53.49999999999985, -333.90000000000003, -383.5999999999999, -88.09999999999994, -26.199999999999825, -104.00000000000014, 74.80000000000001, -357.8, -212.50000000000003, -43.99999999999983, -29.59999999999983, -361.4, -101.00000000000043, -118.00000000000051, -112.00000000000031, 40.0000000000003, -82.4, -70.79999999999998, -345.7, -379.5, -53.99999999999978, 340.6, -160.10000000000005, -12.999999999999979, -314.29999999999995, 6.999999999999771, -179.9, -460.5, -351.9, -121.60000000000025, -484.5, -339.5, -308.09999999999997, -488.4, -498.5, -27.999999999999794, -289.1, 354.1], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, -217.0, 59.0, 14.0, 102.5, 109.1, -280.3, -288.7, -183.4, 20.000000000000014, 20.000000000000014, 21.5, 20.000000000000014, -55.3, -347.5, 20.000000000000014, -97.0, 20.000000000000014, 20.000000000000014, -53.20000000000004, -40.0, -28.0, 193.7, 151.4, -190.0, -205.0, 76.39999999999998, 179.0, -331.0, 41.0, -232.0, -127.0, -211.0, 101.0, -256.9, -139.0, -48.7, -184.0, -223.0, -169.6, -175.0, 15.499999999999998, -112.3, 35.0, 20.000000000000014, 20.000000000000014, -220.6, -241.0, -46.89999999999999, -367.0, 20.000000000000014, -140.49999999999997, 200.0, 200.0, -379.0, -80.2, 196.4, -537.6999999999999, -115.30000000000001, -359.5, -293.8, -206.8, 20.000000000000014, -223.6, -277.0, -283.0, -61.000000000000014, -31.0, -187.0, -204.7, -43.00000000000004, -226.0, 164.9, 187.4, 200.0, 192.8, -271.0, -10.0, -102.4, -151.0, -244.0, -360.4, 0.4999999999999858, -226.3, -280.0, -298.0, -729.4999999999997, 200.0, -280.0, 20.000000000000014, 20.000000000000014, -163.60000000000002, 200.0, 200.0, -362.8, -292.6, -49.0, -147.7, -273.7, -280.9, -347.2, 20.000000000000014, -325.0, -312.4, -228.4, -301.0, -280.0, -397.0, -340.9, -366.7, 190.1, 194.6, -379.0, -329.5, -328.9, -324.7, -247.0, -161.8, 188.3, 198.2, 50.599999999999994, -115.6, -187.60000000000002, -319.6, -323.2, 13.699999999999964, -288.40000000000003, -248.5, -304.0, -247.60000000000002, -320.2, -79.9, 7.399999999999965, -277.6, 20.000000000000014, -286.0, 198.2, -293.40000000000015, -319.0, -362.8, -191.8, -363.7, -241.0, 20.000000000000014, -283.6, 20.000000000000014, -294.4, -271.0, -379.0, 20.000000000000014, -252.39999999999998, -34.59999999999975, 20.000000000000014, -298.0, 20.000000000000014, 20.000000000000014, -325.0, -66.40000000000003, 20.000000000000014, -275.8, -324.7, -376.0, -367.9, -352.6, -373.0, 20.000000000000014, 146.0, 194.6, -325.9, -146.20000000000005, 20.000000000000014, -286.0, -382.0, -262.3, -127.0, 20.000000000000014, -332.10000000000025, -176.8, -350.5, -298.0, -388.0, -343.9, 20.000000000000014, -310.6, -365.8, -306.7, -322.3, -317.2, -286.29999999999995, -320.8, -350.5, -337.9, -302.5, -400.0, -340.0, 20.000000000000014, -257.5, -307.6, 154.1, 200.0], "policy_predator_policy_reward": [31.0, 109.0, 51.0, 28.0, 0.0, 50.0, 169.0, 1.0, 106.0, 6.0, 55.0, 0.0, 46.0, 37.0, 175.0, 0.0, 0.0, 99.0, 37.0, 0.0, 107.0, 0.0, 0.0, 0.0, 77.0, 66.0, 8.0, 0.0, 7.0, 176.0, 85.0, 96.0, 0.0, 137.0, 158.0, 7.0, 103.0, 85.0, 66.0, 103.0, 0.0, 134.0, 48.0, 59.0, 0.0, 0.0, 0.0, 154.0, 189.0, 16.0, 88.0, 33.0, 0.0, 0.0, 90.0, 142.0, 352.0, 212.0, 182.0, 125.0, 181.0, 0.0, 140.0, 0.0, 128.0, 62.0, 20.0, 71.0, 0.0, 129.0, 148.0, 0.0, 0.0, 0.0, 0.0, 0.0, 160.0, 0.0, 0.0, 130.0, 146.0, 166.0, 0.0, 148.0, 172.0, 0.0, 11.0, 631.0, 109.0, 122.0, 59.0, 78.0, 0.0, 0.0, 0.0, 194.0, 0.0, 115.0, 183.0, 0.0, 106.0, 138.0, 172.0, 101.0, 132.0, 166.0, 156.0, 199.0, 137.0, 153.0, 0.0, 0.0, 194.0, 172.0, 39.0, 174.0, 157.0, 0.0, 0.0, 0.0, 105.0, 0.0, 163.0, 0.0, 107.0, 149.0, 27.0, 176.0, 0.0, 168.0, 148.0, 164.0, 147.0, 97.0, 162.0, 0.0, 170.0, 0.0, 141.0, 183.0, 157.0, 186.0, 64.0, 113.0, 109.0, 125.0, 125.0, 79.0, 67.0, 191.0, 26.0, 143.0, 166.0, 0.0, 0.0, 0.0, 149.0, 160.0, 88.0, 97.0, 189.0, 166.0, 151.0, 190.0, 120.0, 179.0, 0.0, 0.0, 169.0, 143.0, 111.0, 142.0, 137.0, 193.0, 14.0, 100.0, 204.0, 125.0, 188.0, 0.0, 196.0, 184.0, 0.0, 169.0, 188.0, 0.0, 156.0, 144.0, 161.0, 138.0, 0.0, 200.0, 4.0, 200.0, 173.0, 119.0, 161.0, 115.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0913500730634986, "mean_inference_ms": 2.6645987904935216, "mean_action_processing_ms": 0.4291161404382187, "mean_env_wait_ms": 0.33714848871285336, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.035996198654174805, "StateBufferConnector_ms": 0.017174482345581055, "ViewRequirementAgentConnector_ms": 0.2964566946029663}, "num_episodes": 23, "episode_return_max": 400.0, "episode_return_min": -498.5, "episode_return_mean": -109.98700000000001, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1168000, "num_agent_steps_trained": 1168000, "num_env_steps_sampled": 292000, "num_env_steps_trained": 292000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 56.4834157541123, "num_env_steps_trained_throughput_per_sec": 56.4834157541123, "timesteps_total": 292000, "num_env_steps_sampled_lifetime": 292000, "num_agent_steps_sampled_lifetime": 1168000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1168000, "timers": {"training_iteration_time_ms": 72886.88, "restore_workers_time_ms": 0.016, "training_step_time_ms": 72886.82, "sample_time_ms": 4066.389, "learn_time_ms": 68789.807, "learn_throughput": 58.148, "synch_weights_time_ms": 26.515}, "counters": {"num_env_steps_sampled": 292000, "num_env_steps_trained": 292000, "num_agent_steps_sampled": 1168000, "num_agent_steps_trained": 1168000}, "done": false, "training_iteration": 73, "trial_id": "11e70_00000", "date": "2024-08-13_00-19-22", "timestamp": 1723522762, "time_this_iter_s": 70.88155388832092, "time_total_s": 4339.587696075439, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3f561f0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 4339.587696075439, "iterations_since_restore": 73, "perf": {"cpu_util_percent": 80.771, "ram_util_percent": 83.204}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 13.196388714654105, "cur_kl_coeff": 0.22500000000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.506851361289858, "policy_loss": -0.006740371883315867, "vf_loss": 8.512352021535238, "vf_explained_var": 0.1744641465800149, "kl": 0.005509738294980892, "entropy": 0.8911520958892882, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 138915.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.251435904338877, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.557006269787985, "policy_loss": -0.015227548970234773, "vf_loss": 8.570687801371175, "vf_explained_var": -0.5259202378136771, "kl": 0.01374257593929238, "entropy": 0.8514261081420555, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 138915.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 296000, "num_env_steps_trained": 296000, "num_agent_steps_sampled": 1184000, "num_agent_steps_trained": 1184000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -523.3, "episode_reward_mean": -147.77599999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -729.4999999999997, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 631.0}, "policy_reward_mean": {"prey_policy": -181.43300000000002, "predator_policy": 107.545}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-44.7, -223.6, -25.5, 29.700000000000003, 40.0000000000003, -307.6, -208.90000000000003, 0.5000000000001029, 400.0, -227.19999999999996, 222.69999999999993, -167.8, -319.6, -63.599999999999795, -370.0, -1.0000000000000568, -262.7, -120.99999999999989, 352.3, 392.8, -121.0, -123.4, -292.40000000000003, -77.8, -406.0, 112.49999999999994, -28.999999999999936, -6.599999999999945, 400.0, -461.4, -81.7, -371.6, -83.19999999999996, -364.4, -231.39999999999992, -322.0, -417.6, 384.7, -342.5, -440.6, -251.79999999999995, 386.5, 40.0, -344.2, -53.49999999999985, -333.90000000000003, -383.5999999999999, -88.09999999999994, -26.199999999999825, -104.00000000000014, 74.80000000000001, -357.8, -212.50000000000003, -43.99999999999983, -29.59999999999983, -361.4, -101.00000000000043, -118.00000000000051, -112.00000000000031, 40.0000000000003, -82.4, -70.79999999999998, -345.7, -379.5, -53.99999999999978, 340.6, -160.10000000000005, -12.999999999999979, -314.29999999999995, 6.999999999999771, -179.9, -460.5, -351.9, -121.60000000000025, -484.5, -339.5, -308.09999999999997, -488.4, -498.5, -27.999999999999794, -289.1, 354.1, -44.99999999999988, -76.89999999999998, -23.999999999999922, -293.79999999999995, -82.70000000000002, -273.00000000000006, -368.9, -73.5, -109.39999999999996, -22.99999999999976, -367.9, -155.69999999999996, -523.3, -398.70000000000005, -146.1, -380.0, -268.9000000000001, -337.8], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-48.7, -184.0, -223.0, -169.6, -175.0, 15.499999999999998, -112.3, 35.0, 20.000000000000014, 20.000000000000014, -220.6, -241.0, -46.89999999999999, -367.0, 20.000000000000014, -140.49999999999997, 200.0, 200.0, -379.0, -80.2, 196.4, -537.6999999999999, -115.30000000000001, -359.5, -293.8, -206.8, 20.000000000000014, -223.6, -277.0, -283.0, -61.000000000000014, -31.0, -187.0, -204.7, -43.00000000000004, -226.0, 164.9, 187.4, 200.0, 192.8, -271.0, -10.0, -102.4, -151.0, -244.0, -360.4, 0.4999999999999858, -226.3, -280.0, -298.0, -729.4999999999997, 200.0, -280.0, 20.000000000000014, 20.000000000000014, -163.60000000000002, 200.0, 200.0, -362.8, -292.6, -49.0, -147.7, -273.7, -280.9, -347.2, 20.000000000000014, -325.0, -312.4, -228.4, -301.0, -280.0, -397.0, -340.9, -366.7, 190.1, 194.6, -379.0, -329.5, -328.9, -324.7, -247.0, -161.8, 188.3, 198.2, 50.599999999999994, -115.6, -187.60000000000002, -319.6, -323.2, 13.699999999999964, -288.40000000000003, -248.5, -304.0, -247.60000000000002, -320.2, -79.9, 7.399999999999965, -277.6, 20.000000000000014, -286.0, 198.2, -293.40000000000015, -319.0, -362.8, -191.8, -363.7, -241.0, 20.000000000000014, -283.6, 20.000000000000014, -294.4, -271.0, -379.0, 20.000000000000014, -252.39999999999998, -34.59999999999975, 20.000000000000014, -298.0, 20.000000000000014, 20.000000000000014, -325.0, -66.40000000000003, 20.000000000000014, -275.8, -324.7, -376.0, -367.9, -352.6, -373.0, 20.000000000000014, 146.0, 194.6, -325.9, -146.20000000000005, 20.000000000000014, -286.0, -382.0, -262.3, -127.0, 20.000000000000014, -332.10000000000025, -176.8, -350.5, -298.0, -388.0, -343.9, 20.000000000000014, -310.6, -365.8, -306.7, -322.3, -317.2, -286.29999999999995, -320.8, -350.5, -337.9, -302.5, -400.0, -340.0, 20.000000000000014, -257.5, -307.6, 154.1, 200.0, -385.0, 20.000000000000014, 20.000000000000014, -349.9, -346.0, 20.000000000000014, -283.0, -281.8, -202.9, -41.80000000000001, -319.9, -348.1, -375.1, -377.8, -61.0, -155.5, -271.0, -9.400000000000006, 20.000000000000014, -400.0, -331.9, -343.0, -312.7, -85.00000000000003, -345.7, -370.5999999999999, -309.70000000000005, -262.0, -191.8, -181.3, -376.0, -385.0, -315.40000000000003, -200.50000000000003, -289.9, -367.9], "policy_predator_policy_reward": [103.0, 85.0, 66.0, 103.0, 0.0, 134.0, 48.0, 59.0, 0.0, 0.0, 0.0, 154.0, 189.0, 16.0, 88.0, 33.0, 0.0, 0.0, 90.0, 142.0, 352.0, 212.0, 182.0, 125.0, 181.0, 0.0, 140.0, 0.0, 128.0, 62.0, 20.0, 71.0, 0.0, 129.0, 148.0, 0.0, 0.0, 0.0, 0.0, 0.0, 160.0, 0.0, 0.0, 130.0, 146.0, 166.0, 0.0, 148.0, 172.0, 0.0, 11.0, 631.0, 109.0, 122.0, 59.0, 78.0, 0.0, 0.0, 0.0, 194.0, 0.0, 115.0, 183.0, 0.0, 106.0, 138.0, 172.0, 101.0, 132.0, 166.0, 156.0, 199.0, 137.0, 153.0, 0.0, 0.0, 194.0, 172.0, 39.0, 174.0, 157.0, 0.0, 0.0, 0.0, 105.0, 0.0, 163.0, 0.0, 107.0, 149.0, 27.0, 176.0, 0.0, 168.0, 148.0, 164.0, 147.0, 97.0, 162.0, 0.0, 170.0, 0.0, 141.0, 183.0, 157.0, 186.0, 64.0, 113.0, 109.0, 125.0, 125.0, 79.0, 67.0, 191.0, 26.0, 143.0, 166.0, 0.0, 0.0, 0.0, 149.0, 160.0, 88.0, 97.0, 189.0, 166.0, 151.0, 190.0, 120.0, 179.0, 0.0, 0.0, 169.0, 143.0, 111.0, 142.0, 137.0, 193.0, 14.0, 100.0, 204.0, 125.0, 188.0, 0.0, 196.0, 184.0, 0.0, 169.0, 188.0, 0.0, 156.0, 144.0, 161.0, 138.0, 0.0, 200.0, 4.0, 200.0, 173.0, 119.0, 161.0, 115.0, 0.0, 0.0, 181.0, 139.0, 113.0, 140.0, 154.0, 148.0, 133.0, 138.0, 137.0, 25.0, 173.0, 222.0, 191.0, 193.0, 143.0, 0.0, 157.0, 14.0, 192.0, 165.0, 129.0, 178.0, 171.0, 71.0, 193.0, 0.0, 0.0, 173.0, 130.0, 97.0, 188.0, 193.0, 84.0, 163.0, 121.0, 199.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0959444469832829, "mean_inference_ms": 2.680643971752032, "mean_action_processing_ms": 0.43119815021134916, "mean_env_wait_ms": 0.33937257356663125, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.028077006340026855, "StateBufferConnector_ms": 0.01708090305328369, "ViewRequirementAgentConnector_ms": 0.26076292991638184}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -523.3, "episode_return_mean": -147.77599999999998, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1184000, "num_agent_steps_trained": 1184000, "num_env_steps_sampled": 296000, "num_env_steps_trained": 296000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 46.478959155771236, "num_env_steps_trained_throughput_per_sec": 46.478959155771236, "timesteps_total": 296000, "num_env_steps_sampled_lifetime": 296000, "num_agent_steps_sampled_lifetime": 1184000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1184000, "timers": {"training_iteration_time_ms": 73946.646, "restore_workers_time_ms": 0.016, "training_step_time_ms": 73946.585, "sample_time_ms": 3846.71, "learn_time_ms": 70064.318, "learn_throughput": 57.09, "synch_weights_time_ms": 31.041}, "counters": {"num_env_steps_sampled": 296000, "num_env_steps_trained": 296000, "num_agent_steps_sampled": 1184000, "num_agent_steps_trained": 1184000}, "done": false, "training_iteration": 74, "trial_id": "11e70_00000", "date": "2024-08-13_00-20-48", "timestamp": 1723522848, "time_this_iter_s": 86.27864694595337, "time_total_s": 4425.866343021393, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3f1d940>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 4425.866343021393, "iterations_since_restore": 74, "perf": {"cpu_util_percent": 90.4844262295082, "ram_util_percent": 83.77540983606556}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 11.310982314240995, "cur_kl_coeff": 0.22500000000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.949500648054497, "policy_loss": -0.005647121564972968, "vf_loss": 7.953666913824738, "vf_explained_var": 0.24448200615625532, "kl": 0.006581565524243504, "entropy": 0.932589847574789, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 140805.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.972066436810469, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.079285794465, "policy_loss": -0.007608959630129258, "vf_loss": 8.086021565129517, "vf_explained_var": -0.35630244205868433, "kl": 0.007761359579662465, "entropy": 0.8896250312921231, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 140805.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 300000, "num_env_steps_trained": 300000, "num_agent_steps_sampled": 1200000, "num_agent_steps_trained": 1200000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -523.3, "episode_reward_mean": -162.635, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -729.4999999999997, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 631.0}, "policy_reward_mean": {"prey_policy": -198.0275, "predator_policy": 116.71}, "custom_metrics": {}, "hist_stats": {"episode_reward": [352.3, 392.8, -121.0, -123.4, -292.40000000000003, -77.8, -406.0, 112.49999999999994, -28.999999999999936, -6.599999999999945, 400.0, -461.4, -81.7, -371.6, -83.19999999999996, -364.4, -231.39999999999992, -322.0, -417.6, 384.7, -342.5, -440.6, -251.79999999999995, 386.5, 40.0, -344.2, -53.49999999999985, -333.90000000000003, -383.5999999999999, -88.09999999999994, -26.199999999999825, -104.00000000000014, 74.80000000000001, -357.8, -212.50000000000003, -43.99999999999983, -29.59999999999983, -361.4, -101.00000000000043, -118.00000000000051, -112.00000000000031, 40.0000000000003, -82.4, -70.79999999999998, -345.7, -379.5, -53.99999999999978, 340.6, -160.10000000000005, -12.999999999999979, -314.29999999999995, 6.999999999999771, -179.9, -460.5, -351.9, -121.60000000000025, -484.5, -339.5, -308.09999999999997, -488.4, -498.5, -27.999999999999794, -289.1, 354.1, -44.99999999999988, -76.89999999999998, -23.999999999999922, -293.79999999999995, -82.70000000000002, -273.00000000000006, -368.9, -73.5, -109.39999999999996, -22.99999999999976, -367.9, -155.69999999999996, -523.3, -398.70000000000005, -146.1, -380.0, -268.9000000000001, -337.8, 9.399999999999984, -387.69999999999993, -123.7999999999999, -305.8, -109.6000000000002, -57.89999999999977, -258.0, -208.8, -191.09999999999988, -109.39999999999979, -275.2, -209.8, 23.50000000000025, -101.09999999999985, -74.00000000000011, -39.99999999999982, -341.29999999999995, -375.6], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [164.9, 187.4, 200.0, 192.8, -271.0, -10.0, -102.4, -151.0, -244.0, -360.4, 0.4999999999999858, -226.3, -280.0, -298.0, -729.4999999999997, 200.0, -280.0, 20.000000000000014, 20.000000000000014, -163.60000000000002, 200.0, 200.0, -362.8, -292.6, -49.0, -147.7, -273.7, -280.9, -347.2, 20.000000000000014, -325.0, -312.4, -228.4, -301.0, -280.0, -397.0, -340.9, -366.7, 190.1, 194.6, -379.0, -329.5, -328.9, -324.7, -247.0, -161.8, 188.3, 198.2, 50.599999999999994, -115.6, -187.60000000000002, -319.6, -323.2, 13.699999999999964, -288.40000000000003, -248.5, -304.0, -247.60000000000002, -320.2, -79.9, 7.399999999999965, -277.6, 20.000000000000014, -286.0, 198.2, -293.40000000000015, -319.0, -362.8, -191.8, -363.7, -241.0, 20.000000000000014, -283.6, 20.000000000000014, -294.4, -271.0, -379.0, 20.000000000000014, -252.39999999999998, -34.59999999999975, 20.000000000000014, -298.0, 20.000000000000014, 20.000000000000014, -325.0, -66.40000000000003, 20.000000000000014, -275.8, -324.7, -376.0, -367.9, -352.6, -373.0, 20.000000000000014, 146.0, 194.6, -325.9, -146.20000000000005, 20.000000000000014, -286.0, -382.0, -262.3, -127.0, 20.000000000000014, -332.10000000000025, -176.8, -350.5, -298.0, -388.0, -343.9, 20.000000000000014, -310.6, -365.8, -306.7, -322.3, -317.2, -286.29999999999995, -320.8, -350.5, -337.9, -302.5, -400.0, -340.0, 20.000000000000014, -257.5, -307.6, 154.1, 200.0, -385.0, 20.000000000000014, 20.000000000000014, -349.9, -346.0, 20.000000000000014, -283.0, -281.8, -202.9, -41.80000000000001, -319.9, -348.1, -375.1, -377.8, -61.0, -155.5, -271.0, -9.400000000000006, 20.000000000000014, -400.0, -331.9, -343.0, -312.7, -85.00000000000003, -345.7, -370.5999999999999, -309.70000000000005, -262.0, -191.8, -181.3, -376.0, -385.0, -315.40000000000003, -200.50000000000003, -289.9, -367.9, -307.6, 20.000000000000014, -205.3, -366.4, -382.6, -68.20000000000003, -197.8, -325.0, -268.0, -13.599999999999783, 20.000000000000014, -355.9, -76.0, -373.0, -353.79999999999995, -193.0, -400.0, -156.10000000000002, -400.0, -51.400000000000034, -323.2, -313.0, -259.3, -242.50000000000003, 9.499999999999964, -268.0, -364.0, -12.100000000000037, -400.0, 20.000000000000014, -190.0, 20.000000000000014, -194.8, -320.5, -379.0, -358.6], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 0.0, 160.0, 0.0, 0.0, 130.0, 146.0, 166.0, 0.0, 148.0, 172.0, 0.0, 11.0, 631.0, 109.0, 122.0, 59.0, 78.0, 0.0, 0.0, 0.0, 194.0, 0.0, 115.0, 183.0, 0.0, 106.0, 138.0, 172.0, 101.0, 132.0, 166.0, 156.0, 199.0, 137.0, 153.0, 0.0, 0.0, 194.0, 172.0, 39.0, 174.0, 157.0, 0.0, 0.0, 0.0, 105.0, 0.0, 163.0, 0.0, 107.0, 149.0, 27.0, 176.0, 0.0, 168.0, 148.0, 164.0, 147.0, 97.0, 162.0, 0.0, 170.0, 0.0, 141.0, 183.0, 157.0, 186.0, 64.0, 113.0, 109.0, 125.0, 125.0, 79.0, 67.0, 191.0, 26.0, 143.0, 166.0, 0.0, 0.0, 0.0, 149.0, 160.0, 88.0, 97.0, 189.0, 166.0, 151.0, 190.0, 120.0, 179.0, 0.0, 0.0, 169.0, 143.0, 111.0, 142.0, 137.0, 193.0, 14.0, 100.0, 204.0, 125.0, 188.0, 0.0, 196.0, 184.0, 0.0, 169.0, 188.0, 0.0, 156.0, 144.0, 161.0, 138.0, 0.0, 200.0, 4.0, 200.0, 173.0, 119.0, 161.0, 115.0, 0.0, 0.0, 181.0, 139.0, 113.0, 140.0, 154.0, 148.0, 133.0, 138.0, 137.0, 25.0, 173.0, 222.0, 191.0, 193.0, 143.0, 0.0, 157.0, 14.0, 192.0, 165.0, 129.0, 178.0, 171.0, 71.0, 193.0, 0.0, 0.0, 173.0, 130.0, 97.0, 188.0, 193.0, 84.0, 163.0, 121.0, 199.0, 155.0, 142.0, 184.0, 0.0, 150.0, 177.0, 175.0, 42.0, 172.0, 0.0, 155.0, 123.0, 0.0, 191.0, 181.0, 157.0, 198.0, 167.0, 200.0, 142.0, 169.0, 192.0, 152.0, 140.0, 121.0, 161.0, 100.0, 175.0, 106.0, 200.0, 0.0, 130.0, 0.0, 174.0, 182.0, 180.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0998794348049552, "mean_inference_ms": 2.6905095788716547, "mean_action_processing_ms": 0.43266448302643007, "mean_env_wait_ms": 0.34041418946050916, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.021827101707458496, "StateBufferConnector_ms": 0.013271093368530273, "ViewRequirementAgentConnector_ms": 0.24110400676727295}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -523.3, "episode_return_mean": -162.635, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1200000, "num_agent_steps_trained": 1200000, "num_env_steps_sampled": 300000, "num_env_steps_trained": 300000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 51.70177433477765, "num_env_steps_trained_throughput_per_sec": 51.70177433477765, "timesteps_total": 300000, "num_env_steps_sampled_lifetime": 300000, "num_agent_steps_sampled_lifetime": 1200000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1200000, "timers": {"training_iteration_time_ms": 74838.843, "restore_workers_time_ms": 0.041, "training_step_time_ms": 74838.755, "sample_time_ms": 3884.982, "learn_time_ms": 70918.203, "learn_throughput": 56.403, "synch_weights_time_ms": 31.36}, "counters": {"num_env_steps_sampled": 300000, "num_env_steps_trained": 300000, "num_agent_steps_sampled": 1200000, "num_agent_steps_trained": 1200000}, "done": false, "training_iteration": 75, "trial_id": "11e70_00000", "date": "2024-08-13_00-22-06", "timestamp": 1723522926, "time_this_iter_s": 77.38627886772156, "time_total_s": 4503.252621889114, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3f1daf0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 4503.252621889114, "iterations_since_restore": 75, "perf": {"cpu_util_percent": 87.96272727272729, "ram_util_percent": 83.26272727272729}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 18.827851835129753, "cur_kl_coeff": 0.22500000000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.526111322735983, "policy_loss": -0.007500684387592609, "vf_loss": 7.531876816320672, "vf_explained_var": 0.31078840894673865, "kl": 0.007712000812670598, "entropy": 0.933340477407294, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 142695.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 7.431829791283481, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.089308992517058, "policy_loss": -0.009711972824864523, "vf_loss": 7.097795493262154, "vf_explained_var": -0.39817857344945273, "kl": 0.010893052496240637, "entropy": 0.9513679599635816, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 142695.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 304000, "num_env_steps_trained": 304000, "num_agent_steps_sampled": 1216000, "num_agent_steps_trained": 1216000}, "env_runners": {"episode_reward_max": 386.5, "episode_reward_min": -523.3, "episode_reward_mean": -153.46099999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 222.0}, "policy_reward_mean": {"prey_policy": -191.35050000000004, "predator_policy": 114.62}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-251.79999999999995, 386.5, 40.0, -344.2, -53.49999999999985, -333.90000000000003, -383.5999999999999, -88.09999999999994, -26.199999999999825, -104.00000000000014, 74.80000000000001, -357.8, -212.50000000000003, -43.99999999999983, -29.59999999999983, -361.4, -101.00000000000043, -118.00000000000051, -112.00000000000031, 40.0000000000003, -82.4, -70.79999999999998, -345.7, -379.5, -53.99999999999978, 340.6, -160.10000000000005, -12.999999999999979, -314.29999999999995, 6.999999999999771, -179.9, -460.5, -351.9, -121.60000000000025, -484.5, -339.5, -308.09999999999997, -488.4, -498.5, -27.999999999999794, -289.1, 354.1, -44.99999999999988, -76.89999999999998, -23.999999999999922, -293.79999999999995, -82.70000000000002, -273.00000000000006, -368.9, -73.5, -109.39999999999996, -22.99999999999976, -367.9, -155.69999999999996, -523.3, -398.70000000000005, -146.1, -380.0, -268.9000000000001, -337.8, 9.399999999999984, -387.69999999999993, -123.7999999999999, -305.8, -109.6000000000002, -57.89999999999977, -258.0, -208.8, -191.09999999999988, -109.39999999999979, -275.2, -209.8, 23.50000000000025, -101.09999999999985, -74.00000000000011, -39.99999999999982, -341.29999999999995, -375.6, -508.2, 120.19999999999959, 64.80000000000022, -11.599999999999966, 12.800000000000255, 13.000000000000078, 31.000000000000256, 40.0000000000003, -214.8, -226.99999999999991, -42.099999999999916, 62.000000000000206, -179.60000000000002, -200.5, 105.09999999999926, 38.90000000000028, -318.6, -65.40000000000025, 264.89999999999975, -27.999999999999794, -189.89999999999998, -379.9], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-247.0, -161.8, 188.3, 198.2, 50.599999999999994, -115.6, -187.60000000000002, -319.6, -323.2, 13.699999999999964, -288.40000000000003, -248.5, -304.0, -247.60000000000002, -320.2, -79.9, 7.399999999999965, -277.6, 20.000000000000014, -286.0, 198.2, -293.40000000000015, -319.0, -362.8, -191.8, -363.7, -241.0, 20.000000000000014, -283.6, 20.000000000000014, -294.4, -271.0, -379.0, 20.000000000000014, -252.39999999999998, -34.59999999999975, 20.000000000000014, -298.0, 20.000000000000014, 20.000000000000014, -325.0, -66.40000000000003, 20.000000000000014, -275.8, -324.7, -376.0, -367.9, -352.6, -373.0, 20.000000000000014, 146.0, 194.6, -325.9, -146.20000000000005, 20.000000000000014, -286.0, -382.0, -262.3, -127.0, 20.000000000000014, -332.10000000000025, -176.8, -350.5, -298.0, -388.0, -343.9, 20.000000000000014, -310.6, -365.8, -306.7, -322.3, -317.2, -286.29999999999995, -320.8, -350.5, -337.9, -302.5, -400.0, -340.0, 20.000000000000014, -257.5, -307.6, 154.1, 200.0, -385.0, 20.000000000000014, 20.000000000000014, -349.9, -346.0, 20.000000000000014, -283.0, -281.8, -202.9, -41.80000000000001, -319.9, -348.1, -375.1, -377.8, -61.0, -155.5, -271.0, -9.400000000000006, 20.000000000000014, -400.0, -331.9, -343.0, -312.7, -85.00000000000003, -345.7, -370.5999999999999, -309.70000000000005, -262.0, -191.8, -181.3, -376.0, -385.0, -315.40000000000003, -200.50000000000003, -289.9, -367.9, -307.6, 20.000000000000014, -205.3, -366.4, -382.6, -68.20000000000003, -197.8, -325.0, -268.0, -13.599999999999783, 20.000000000000014, -355.9, -76.0, -373.0, -353.79999999999995, -193.0, -400.0, -156.10000000000002, -400.0, -51.400000000000034, -323.2, -313.0, -259.3, -242.50000000000003, 9.499999999999964, -268.0, -364.0, -12.100000000000037, -400.0, 20.000000000000014, -190.0, 20.000000000000014, -194.8, -320.5, -379.0, -358.6, -322.3, -382.9, -66.1000000000002, 119.3, 20.000000000000014, 36.79999999999997, -109.60000000000002, -43.00000000000002, -206.20000000000005, 20.000000000000014, -106.0, 20.000000000000014, 20.000000000000014, -295.0, 20.000000000000014, 20.000000000000014, -197.8, -253.0, -147.4, -223.60000000000002, -360.0999999999999, -63.99999999999977, -145.0, 20.000000000000014, -205.3, -301.3, -356.5, -193.0, 20.000000000000014, 28.099999999999994, 17.899999999999988, 20.000000000000014, -298.6, -325.0, -345.4, 20.000000000000014, 173.3, 86.59999999999997, -349.0, 20.000000000000014, -244.6, -247.3, -304.3, -247.6], "policy_predator_policy_reward": [157.0, 0.0, 0.0, 0.0, 105.0, 0.0, 163.0, 0.0, 107.0, 149.0, 27.0, 176.0, 0.0, 168.0, 148.0, 164.0, 147.0, 97.0, 162.0, 0.0, 170.0, 0.0, 141.0, 183.0, 157.0, 186.0, 64.0, 113.0, 109.0, 125.0, 125.0, 79.0, 67.0, 191.0, 26.0, 143.0, 166.0, 0.0, 0.0, 0.0, 149.0, 160.0, 88.0, 97.0, 189.0, 166.0, 151.0, 190.0, 120.0, 179.0, 0.0, 0.0, 169.0, 143.0, 111.0, 142.0, 137.0, 193.0, 14.0, 100.0, 204.0, 125.0, 188.0, 0.0, 196.0, 184.0, 0.0, 169.0, 188.0, 0.0, 156.0, 144.0, 161.0, 138.0, 0.0, 200.0, 4.0, 200.0, 173.0, 119.0, 161.0, 115.0, 0.0, 0.0, 181.0, 139.0, 113.0, 140.0, 154.0, 148.0, 133.0, 138.0, 137.0, 25.0, 173.0, 222.0, 191.0, 193.0, 143.0, 0.0, 157.0, 14.0, 192.0, 165.0, 129.0, 178.0, 171.0, 71.0, 193.0, 0.0, 0.0, 173.0, 130.0, 97.0, 188.0, 193.0, 84.0, 163.0, 121.0, 199.0, 155.0, 142.0, 184.0, 0.0, 150.0, 177.0, 175.0, 42.0, 172.0, 0.0, 155.0, 123.0, 0.0, 191.0, 181.0, 157.0, 198.0, 167.0, 200.0, 142.0, 169.0, 192.0, 152.0, 140.0, 121.0, 161.0, 100.0, 175.0, 106.0, 200.0, 0.0, 130.0, 0.0, 174.0, 182.0, 180.0, 197.0, 0.0, 26.0, 41.0, 4.0, 4.0, 69.0, 72.0, 68.0, 131.0, 99.0, 0.0, 143.0, 163.0, 0.0, 0.0, 104.0, 132.0, 0.0, 144.0, 198.0, 184.0, 89.0, 98.0, 172.0, 155.0, 163.0, 186.0, 0.0, 57.0, 0.0, 1.0, 153.0, 152.0, 163.0, 97.0, 0.0, 5.0, 183.0, 118.0, 158.0, 144.0, 172.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1018984049126974, "mean_inference_ms": 2.697165936009566, "mean_action_processing_ms": 0.4333787944944946, "mean_env_wait_ms": 0.34118906765072554, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01662909984588623, "StateBufferConnector_ms": 0.01356208324432373, "ViewRequirementAgentConnector_ms": 0.25546717643737793}, "num_episodes": 22, "episode_return_max": 386.5, "episode_return_min": -523.3, "episode_return_mean": -153.46099999999998, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1216000, "num_agent_steps_trained": 1216000, "num_env_steps_sampled": 304000, "num_env_steps_trained": 304000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 63.973003335975484, "num_env_steps_trained_throughput_per_sec": 63.973003335975484, "timesteps_total": 304000, "num_env_steps_sampled_lifetime": 304000, "num_agent_steps_sampled_lifetime": 1216000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1216000, "timers": {"training_iteration_time_ms": 71987.941, "restore_workers_time_ms": 0.041, "training_step_time_ms": 71987.861, "sample_time_ms": 3215.885, "learn_time_ms": 68736.142, "learn_throughput": 58.194, "synch_weights_time_ms": 32.121}, "counters": {"num_env_steps_sampled": 304000, "num_env_steps_trained": 304000, "num_agent_steps_sampled": 1216000, "num_agent_steps_trained": 1216000}, "done": false, "training_iteration": 76, "trial_id": "11e70_00000", "date": "2024-08-13_00-23-08", "timestamp": 1723522988, "time_this_iter_s": 62.61293077468872, "time_total_s": 4565.865552663803, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b4a09700>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 4565.865552663803, "iterations_since_restore": 76, "perf": {"cpu_util_percent": 69.02696629213484, "ram_util_percent": 81.75617977528088}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 15.177556198236173, "cur_kl_coeff": 0.22500000000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.875094711212885, "policy_loss": -0.00588918827035558, "vf_loss": 7.879784325695542, "vf_explained_var": 0.3099492948522013, "kl": 0.005331478074120039, "entropy": 0.9150470412597455, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 144585.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 8.172921503094768, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.981436587893774, "policy_loss": -0.01425402549590679, "vf_loss": 7.994115347584719, "vf_explained_var": -0.12185365062542063, "kl": 0.014002176263304161, "entropy": 0.8923584342002868, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 144585.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 308000, "num_env_steps_trained": 308000, "num_agent_steps_sampled": 1232000, "num_agent_steps_trained": 1232000}, "env_runners": {"episode_reward_max": 354.1, "episode_reward_min": -523.3, "episode_reward_mean": -145.975, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 222.0}, "policy_reward_mean": {"prey_policy": -192.7325, "predator_policy": 119.745}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-112.00000000000031, 40.0000000000003, -82.4, -70.79999999999998, -345.7, -379.5, -53.99999999999978, 340.6, -160.10000000000005, -12.999999999999979, -314.29999999999995, 6.999999999999771, -179.9, -460.5, -351.9, -121.60000000000025, -484.5, -339.5, -308.09999999999997, -488.4, -498.5, -27.999999999999794, -289.1, 354.1, -44.99999999999988, -76.89999999999998, -23.999999999999922, -293.79999999999995, -82.70000000000002, -273.00000000000006, -368.9, -73.5, -109.39999999999996, -22.99999999999976, -367.9, -155.69999999999996, -523.3, -398.70000000000005, -146.1, -380.0, -268.9000000000001, -337.8, 9.399999999999984, -387.69999999999993, -123.7999999999999, -305.8, -109.6000000000002, -57.89999999999977, -258.0, -208.8, -191.09999999999988, -109.39999999999979, -275.2, -209.8, 23.50000000000025, -101.09999999999985, -74.00000000000011, -39.99999999999982, -341.29999999999995, -375.6, -508.2, 120.19999999999959, 64.80000000000022, -11.599999999999966, 12.800000000000255, 13.000000000000078, 31.000000000000256, 40.0000000000003, -214.8, -226.99999999999991, -42.099999999999916, 62.000000000000206, -179.60000000000002, -200.5, 105.09999999999926, 38.90000000000028, -318.6, -65.40000000000025, 264.89999999999975, -27.999999999999794, -189.89999999999998, -379.9, -352.9, -6.6000000000000245, -180.0, -11.100000000000053, -202.5, -41.1, -13.0, -18.59999999999983, 28.700000000000003, -23.80000000000004, -269.4, -47.0, -67.3, -73.59999999999982, -9.100000000000058, 99.6, -213.30000000000004, -158.70000000000053], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, -298.0, 20.000000000000014, 20.000000000000014, -325.0, -66.40000000000003, 20.000000000000014, -275.8, -324.7, -376.0, -367.9, -352.6, -373.0, 20.000000000000014, 146.0, 194.6, -325.9, -146.20000000000005, 20.000000000000014, -286.0, -382.0, -262.3, -127.0, 20.000000000000014, -332.10000000000025, -176.8, -350.5, -298.0, -388.0, -343.9, 20.000000000000014, -310.6, -365.8, -306.7, -322.3, -317.2, -286.29999999999995, -320.8, -350.5, -337.9, -302.5, -400.0, -340.0, 20.000000000000014, -257.5, -307.6, 154.1, 200.0, -385.0, 20.000000000000014, 20.000000000000014, -349.9, -346.0, 20.000000000000014, -283.0, -281.8, -202.9, -41.80000000000001, -319.9, -348.1, -375.1, -377.8, -61.0, -155.5, -271.0, -9.400000000000006, 20.000000000000014, -400.0, -331.9, -343.0, -312.7, -85.00000000000003, -345.7, -370.5999999999999, -309.70000000000005, -262.0, -191.8, -181.3, -376.0, -385.0, -315.40000000000003, -200.50000000000003, -289.9, -367.9, -307.6, 20.000000000000014, -205.3, -366.4, -382.6, -68.20000000000003, -197.8, -325.0, -268.0, -13.599999999999783, 20.000000000000014, -355.9, -76.0, -373.0, -353.79999999999995, -193.0, -400.0, -156.10000000000002, -400.0, -51.400000000000034, -323.2, -313.0, -259.3, -242.50000000000003, 9.499999999999964, -268.0, -364.0, -12.100000000000037, -400.0, 20.000000000000014, -190.0, 20.000000000000014, -194.8, -320.5, -379.0, -358.6, -322.3, -382.9, -66.1000000000002, 119.3, 20.000000000000014, 36.79999999999997, -109.60000000000002, -43.00000000000002, -206.20000000000005, 20.000000000000014, -106.0, 20.000000000000014, 20.000000000000014, -295.0, 20.000000000000014, 20.000000000000014, -197.8, -253.0, -147.4, -223.60000000000002, -360.0999999999999, -63.99999999999977, -145.0, 20.000000000000014, -205.3, -301.3, -356.5, -193.0, 20.000000000000014, 28.099999999999994, 17.899999999999988, 20.000000000000014, -298.6, -325.0, -345.4, 20.000000000000014, 173.3, 86.59999999999997, -349.0, 20.000000000000014, -244.6, -247.3, -304.3, -247.6, -353.5, -348.4, 20.000000000000014, -328.6, -400.0, 20.0, -355.9, 15.799999999999963, -366.7, -200.8, -303.1, 95.0, -271.0, -79.0, 20.000000000000014, -271.6, 34.699999999999996, -355.0, -183.4, -93.40000000000002, -363.4, -106.0, -301.0, 83.0, -327.4, 79.1, -338.8, -38.80000000000004, -279.10000000000014, 20.000000000000014, -215.5, 61.1, -207.4, -247.9, 20.000000000000014, -366.7], "policy_predator_policy_reward": [166.0, 0.0, 0.0, 0.0, 149.0, 160.0, 88.0, 97.0, 189.0, 166.0, 151.0, 190.0, 120.0, 179.0, 0.0, 0.0, 169.0, 143.0, 111.0, 142.0, 137.0, 193.0, 14.0, 100.0, 204.0, 125.0, 188.0, 0.0, 196.0, 184.0, 0.0, 169.0, 188.0, 0.0, 156.0, 144.0, 161.0, 138.0, 0.0, 200.0, 4.0, 200.0, 173.0, 119.0, 161.0, 115.0, 0.0, 0.0, 181.0, 139.0, 113.0, 140.0, 154.0, 148.0, 133.0, 138.0, 137.0, 25.0, 173.0, 222.0, 191.0, 193.0, 143.0, 0.0, 157.0, 14.0, 192.0, 165.0, 129.0, 178.0, 171.0, 71.0, 193.0, 0.0, 0.0, 173.0, 130.0, 97.0, 188.0, 193.0, 84.0, 163.0, 121.0, 199.0, 155.0, 142.0, 184.0, 0.0, 150.0, 177.0, 175.0, 42.0, 172.0, 0.0, 155.0, 123.0, 0.0, 191.0, 181.0, 157.0, 198.0, 167.0, 200.0, 142.0, 169.0, 192.0, 152.0, 140.0, 121.0, 161.0, 100.0, 175.0, 106.0, 200.0, 0.0, 130.0, 0.0, 174.0, 182.0, 180.0, 197.0, 0.0, 26.0, 41.0, 4.0, 4.0, 69.0, 72.0, 68.0, 131.0, 99.0, 0.0, 143.0, 163.0, 0.0, 0.0, 104.0, 132.0, 0.0, 144.0, 198.0, 184.0, 89.0, 98.0, 172.0, 155.0, 163.0, 186.0, 0.0, 57.0, 0.0, 1.0, 153.0, 152.0, 163.0, 97.0, 0.0, 5.0, 183.0, 118.0, 158.0, 144.0, 172.0, 0.0, 184.0, 165.0, 149.0, 153.0, 0.0, 200.0, 176.0, 153.0, 186.0, 179.0, 0.0, 167.0, 181.0, 156.0, 133.0, 100.0, 160.0, 189.0, 127.0, 126.0, 200.0, 0.0, 171.0, 0.0, 0.0, 181.0, 133.0, 171.0, 102.0, 148.0, 146.0, 108.0, 91.0, 151.0, 188.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1028401904160037, "mean_inference_ms": 2.698714789351351, "mean_action_processing_ms": 0.4334636312760145, "mean_env_wait_ms": 0.3412449371324112, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.009711146354675293, "StateBufferConnector_ms": 0.005362153053283691, "ViewRequirementAgentConnector_ms": 0.21468019485473633}, "num_episodes": 18, "episode_return_max": 354.1, "episode_return_min": -523.3, "episode_return_mean": -145.975, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1232000, "num_agent_steps_trained": 1232000, "num_env_steps_sampled": 308000, "num_env_steps_trained": 308000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 64.11403681664382, "num_env_steps_trained_throughput_per_sec": 64.11403681664382, "timesteps_total": 308000, "num_env_steps_sampled_lifetime": 308000, "num_agent_steps_sampled_lifetime": 1232000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1232000, "timers": {"training_iteration_time_ms": 70748.044, "restore_workers_time_ms": 0.041, "training_step_time_ms": 70747.962, "sample_time_ms": 3027.556, "learn_time_ms": 67688.044, "learn_throughput": 59.095, "synch_weights_time_ms": 28.69}, "counters": {"num_env_steps_sampled": 308000, "num_env_steps_trained": 308000, "num_agent_steps_sampled": 1232000, "num_agent_steps_trained": 1232000}, "done": false, "training_iteration": 77, "trial_id": "11e70_00000", "date": "2024-08-13_00-24-11", "timestamp": 1723523051, "time_this_iter_s": 62.432080030441284, "time_total_s": 4628.297632694244, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2b06ca0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 4628.297632694244, "iterations_since_restore": 77, "perf": {"cpu_util_percent": 70.88202247191012, "ram_util_percent": 82.22808988764046}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 16.73671883578023, "cur_kl_coeff": 0.22500000000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.178563500207568, "policy_loss": -0.007201141678782367, "vf_loss": 7.184408523922875, "vf_explained_var": 0.40668584638171723, "kl": 0.006027185646716707, "entropy": 0.8900989701508214, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 146475.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 9.218362634522574, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.912890532660106, "policy_loss": -0.011109389448242765, "vf_loss": 7.922791670239161, "vf_explained_var": 0.01652279294357098, "kl": 0.010739872558579626, "entropy": 0.9372003441765195, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 146475.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 312000, "num_env_steps_trained": 312000, "num_agent_steps_sampled": 1248000, "num_agent_steps_trained": 1248000}, "env_runners": {"episode_reward_max": 354.1, "episode_reward_min": -523.3, "episode_reward_mean": -103.48299999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 222.0}, "policy_reward_mean": {"prey_policy": -168.59650000000002, "predator_policy": 116.855}, "custom_metrics": {}, "hist_stats": {"episode_reward": [354.1, -44.99999999999988, -76.89999999999998, -23.999999999999922, -293.79999999999995, -82.70000000000002, -273.00000000000006, -368.9, -73.5, -109.39999999999996, -22.99999999999976, -367.9, -155.69999999999996, -523.3, -398.70000000000005, -146.1, -380.0, -268.9000000000001, -337.8, 9.399999999999984, -387.69999999999993, -123.7999999999999, -305.8, -109.6000000000002, -57.89999999999977, -258.0, -208.8, -191.09999999999988, -109.39999999999979, -275.2, -209.8, 23.50000000000025, -101.09999999999985, -74.00000000000011, -39.99999999999982, -341.29999999999995, -375.6, -508.2, 120.19999999999959, 64.80000000000022, -11.599999999999966, 12.800000000000255, 13.000000000000078, 31.000000000000256, 40.0000000000003, -214.8, -226.99999999999991, -42.099999999999916, 62.000000000000206, -179.60000000000002, -200.5, 105.09999999999926, 38.90000000000028, -318.6, -65.40000000000025, 264.89999999999975, -27.999999999999794, -189.89999999999998, -379.9, -352.9, -6.6000000000000245, -180.0, -11.100000000000053, -202.5, -41.1, -13.0, -18.59999999999983, 28.700000000000003, -23.80000000000004, -269.4, -47.0, -67.3, -73.59999999999982, -9.100000000000058, 99.6, -213.30000000000004, -158.70000000000053, 70.89999999999996, -143.1, -193.6, -337.0, -285.1, 74.40000000000006, -19.9, 98.5, 73.4, 158.79999999999956, -143.20000000000047, -44.400000000000006, -26.799999999999827, 57.099999999999994, -54.3, 42.099999999999994, 40.0000000000003, 71.10000000000002, 163.6999999999997, 150.0, 21.999999999999954, -194.4, -25.200000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [154.1, 200.0, -385.0, 20.000000000000014, 20.000000000000014, -349.9, -346.0, 20.000000000000014, -283.0, -281.8, -202.9, -41.80000000000001, -319.9, -348.1, -375.1, -377.8, -61.0, -155.5, -271.0, -9.400000000000006, 20.000000000000014, -400.0, -331.9, -343.0, -312.7, -85.00000000000003, -345.7, -370.5999999999999, -309.70000000000005, -262.0, -191.8, -181.3, -376.0, -385.0, -315.40000000000003, -200.50000000000003, -289.9, -367.9, -307.6, 20.000000000000014, -205.3, -366.4, -382.6, -68.20000000000003, -197.8, -325.0, -268.0, -13.599999999999783, 20.000000000000014, -355.9, -76.0, -373.0, -353.79999999999995, -193.0, -400.0, -156.10000000000002, -400.0, -51.400000000000034, -323.2, -313.0, -259.3, -242.50000000000003, 9.499999999999964, -268.0, -364.0, -12.100000000000037, -400.0, 20.000000000000014, -190.0, 20.000000000000014, -194.8, -320.5, -379.0, -358.6, -322.3, -382.9, -66.1000000000002, 119.3, 20.000000000000014, 36.79999999999997, -109.60000000000002, -43.00000000000002, -206.20000000000005, 20.000000000000014, -106.0, 20.000000000000014, 20.000000000000014, -295.0, 20.000000000000014, 20.000000000000014, -197.8, -253.0, -147.4, -223.60000000000002, -360.0999999999999, -63.99999999999977, -145.0, 20.000000000000014, -205.3, -301.3, -356.5, -193.0, 20.000000000000014, 28.099999999999994, 17.899999999999988, 20.000000000000014, -298.6, -325.0, -345.4, 20.000000000000014, 173.3, 86.59999999999997, -349.0, 20.000000000000014, -244.6, -247.3, -304.3, -247.6, -353.5, -348.4, 20.000000000000014, -328.6, -400.0, 20.0, -355.9, 15.799999999999963, -366.7, -200.8, -303.1, 95.0, -271.0, -79.0, 20.000000000000014, -271.6, 34.699999999999996, -355.0, -183.4, -93.40000000000002, -363.4, -106.0, -301.0, 83.0, -327.4, 79.1, -338.8, -38.80000000000004, -279.10000000000014, 20.000000000000014, -215.5, 61.1, -207.4, -247.9, 20.000000000000014, -366.7, -76.0, -81.10000000000002, -168.7, -327.4, -82.6, -271.0, -313.6, -336.4, -307.3, -302.8, 47.0, -265.6, -193.0, -106.9, -25.0, -2.5, 137.89999999999998, -158.5, 20.000000000000014, 120.8, 20.000000000000014, -341.2, -43.599999999999994, -347.8, -221.8, 20.000000000000014, -373.9, 53.0, 134.0, -379.3, -205.9, 113.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, -175.9, 116.0, -43.300000000000026, 122.0, -250.0, 20.000000000000014, -190.0, -266.8, -277.6, 49.7, -253.9], "policy_predator_policy_reward": [0.0, 0.0, 181.0, 139.0, 113.0, 140.0, 154.0, 148.0, 133.0, 138.0, 137.0, 25.0, 173.0, 222.0, 191.0, 193.0, 143.0, 0.0, 157.0, 14.0, 192.0, 165.0, 129.0, 178.0, 171.0, 71.0, 193.0, 0.0, 0.0, 173.0, 130.0, 97.0, 188.0, 193.0, 84.0, 163.0, 121.0, 199.0, 155.0, 142.0, 184.0, 0.0, 150.0, 177.0, 175.0, 42.0, 172.0, 0.0, 155.0, 123.0, 0.0, 191.0, 181.0, 157.0, 198.0, 167.0, 200.0, 142.0, 169.0, 192.0, 152.0, 140.0, 121.0, 161.0, 100.0, 175.0, 106.0, 200.0, 0.0, 130.0, 0.0, 174.0, 182.0, 180.0, 197.0, 0.0, 26.0, 41.0, 4.0, 4.0, 69.0, 72.0, 68.0, 131.0, 99.0, 0.0, 143.0, 163.0, 0.0, 0.0, 104.0, 132.0, 0.0, 144.0, 198.0, 184.0, 89.0, 98.0, 172.0, 155.0, 163.0, 186.0, 0.0, 57.0, 0.0, 1.0, 153.0, 152.0, 163.0, 97.0, 0.0, 5.0, 183.0, 118.0, 158.0, 144.0, 172.0, 0.0, 184.0, 165.0, 149.0, 153.0, 0.0, 200.0, 176.0, 153.0, 186.0, 179.0, 0.0, 167.0, 181.0, 156.0, 133.0, 100.0, 160.0, 189.0, 127.0, 126.0, 200.0, 0.0, 171.0, 0.0, 0.0, 181.0, 133.0, 171.0, 102.0, 148.0, 146.0, 108.0, 91.0, 151.0, 188.0, 0.0, 106.0, 122.0, 177.0, 176.0, 157.0, 3.0, 129.0, 184.0, 169.0, 156.0, 163.0, 130.0, 137.0, 143.0, 126.0, 0.0, 91.0, 3.0, 0.0, 18.0, 178.0, 0.0, 177.0, 170.0, 47.0, 128.0, 182.0, 196.0, 0.0, 191.0, 0.0, 135.0, 0.0, 0.0, 107.0, 120.0, 45.0, 46.0, 142.0, 136.0, 97.0, 95.0, 181.0, 169.0, 0.0, 179.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1030091772609691, "mean_inference_ms": 2.699940314894419, "mean_action_processing_ms": 0.4334453356180213, "mean_env_wait_ms": 0.3415545900079643, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004618167877197266, "StateBufferConnector_ms": 0.005400300025939941, "ViewRequirementAgentConnector_ms": 0.21382081508636475}, "num_episodes": 23, "episode_return_max": 354.1, "episode_return_min": -523.3, "episode_return_mean": -103.48299999999999, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1248000, "num_agent_steps_trained": 1248000, "num_env_steps_sampled": 312000, "num_env_steps_trained": 312000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 63.69950350185192, "num_env_steps_trained_throughput_per_sec": 63.69950350185192, "timesteps_total": 312000, "num_env_steps_sampled_lifetime": 312000, "num_agent_steps_sampled_lifetime": 1248000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1248000, "timers": {"training_iteration_time_ms": 69969.951, "restore_workers_time_ms": 0.04, "training_step_time_ms": 69969.871, "sample_time_ms": 2904.741, "learn_time_ms": 67033.875, "learn_throughput": 59.671, "synch_weights_time_ms": 27.391}, "counters": {"num_env_steps_sampled": 312000, "num_env_steps_trained": 312000, "num_agent_steps_sampled": 1248000, "num_agent_steps_trained": 1248000}, "done": false, "training_iteration": 78, "trial_id": "11e70_00000", "date": "2024-08-13_00-25-14", "timestamp": 1723523114, "time_this_iter_s": 62.872156858444214, "time_total_s": 4691.169789552689, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3f39f70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 4691.169789552689, "iterations_since_restore": 78, "perf": {"cpu_util_percent": 67.64269662921349, "ram_util_percent": 83.42359550561798}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 18.908195776661866, "cur_kl_coeff": 0.22500000000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.321929424528092, "policy_loss": -0.008940717328103288, "vf_loss": 6.3290837323224105, "vf_explained_var": 0.320143189348241, "kl": 0.007939566191441887, "entropy": 0.9188708841169952, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 148365.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 11.4107474903581, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.948695391952676, "policy_loss": -0.0246058140553672, "vf_loss": 6.970288151534146, "vf_explained_var": 0.16596313497376822, "kl": 0.02678278182501171, "entropy": 0.9650862286961268, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 148365.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 316000, "num_env_steps_trained": 316000, "num_agent_steps_sampled": 1264000, "num_agent_steps_trained": 1264000}, "env_runners": {"episode_reward_max": 264.89999999999975, "episode_reward_min": -508.2, "episode_reward_mean": -59.964000000000034, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 188.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -138.202, "predator_policy": 108.22}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-337.8, 9.399999999999984, -387.69999999999993, -123.7999999999999, -305.8, -109.6000000000002, -57.89999999999977, -258.0, -208.8, -191.09999999999988, -109.39999999999979, -275.2, -209.8, 23.50000000000025, -101.09999999999985, -74.00000000000011, -39.99999999999982, -341.29999999999995, -375.6, -508.2, 120.19999999999959, 64.80000000000022, -11.599999999999966, 12.800000000000255, 13.000000000000078, 31.000000000000256, 40.0000000000003, -214.8, -226.99999999999991, -42.099999999999916, 62.000000000000206, -179.60000000000002, -200.5, 105.09999999999926, 38.90000000000028, -318.6, -65.40000000000025, 264.89999999999975, -27.999999999999794, -189.89999999999998, -379.9, -352.9, -6.6000000000000245, -180.0, -11.100000000000053, -202.5, -41.1, -13.0, -18.59999999999983, 28.700000000000003, -23.80000000000004, -269.4, -47.0, -67.3, -73.59999999999982, -9.100000000000058, 99.6, -213.30000000000004, -158.70000000000053, 70.89999999999996, -143.1, -193.6, -337.0, -285.1, 74.40000000000006, -19.9, 98.5, 73.4, 158.79999999999956, -143.20000000000047, -44.400000000000006, -26.799999999999827, 57.099999999999994, -54.3, 42.099999999999994, 40.0000000000003, 71.10000000000002, 163.6999999999997, 150.0, 21.999999999999954, -194.4, -25.200000000000003, 211.99999999999926, 197.99999999999926, -132.50000000000048, 127.1, -311.69999999999993, -15.599999999999994, 120.1, 189.99999999999926, 39.00000000000004, 191.9999999999994, 194.0, 149.9999999999996, -247.70000000000005, 152.9, -11.999999999999842, 236.1, -46.0000000000002, 49.50000000000019], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-289.9, -367.9, -307.6, 20.000000000000014, -205.3, -366.4, -382.6, -68.20000000000003, -197.8, -325.0, -268.0, -13.599999999999783, 20.000000000000014, -355.9, -76.0, -373.0, -353.79999999999995, -193.0, -400.0, -156.10000000000002, -400.0, -51.400000000000034, -323.2, -313.0, -259.3, -242.50000000000003, 9.499999999999964, -268.0, -364.0, -12.100000000000037, -400.0, 20.000000000000014, -190.0, 20.000000000000014, -194.8, -320.5, -379.0, -358.6, -322.3, -382.9, -66.1000000000002, 119.3, 20.000000000000014, 36.79999999999997, -109.60000000000002, -43.00000000000002, -206.20000000000005, 20.000000000000014, -106.0, 20.000000000000014, 20.000000000000014, -295.0, 20.000000000000014, 20.000000000000014, -197.8, -253.0, -147.4, -223.60000000000002, -360.0999999999999, -63.99999999999977, -145.0, 20.000000000000014, -205.3, -301.3, -356.5, -193.0, 20.000000000000014, 28.099999999999994, 17.899999999999988, 20.000000000000014, -298.6, -325.0, -345.4, 20.000000000000014, 173.3, 86.59999999999997, -349.0, 20.000000000000014, -244.6, -247.3, -304.3, -247.6, -353.5, -348.4, 20.000000000000014, -328.6, -400.0, 20.0, -355.9, 15.799999999999963, -366.7, -200.8, -303.1, 95.0, -271.0, -79.0, 20.000000000000014, -271.6, 34.699999999999996, -355.0, -183.4, -93.40000000000002, -363.4, -106.0, -301.0, 83.0, -327.4, 79.1, -338.8, -38.80000000000004, -279.10000000000014, 20.000000000000014, -215.5, 61.1, -207.4, -247.9, 20.000000000000014, -366.7, -76.0, -81.10000000000002, -168.7, -327.4, -82.6, -271.0, -313.6, -336.4, -307.3, -302.8, 47.0, -265.6, -193.0, -106.9, -25.0, -2.5, 137.89999999999998, -158.5, 20.000000000000014, 120.8, 20.000000000000014, -341.2, -43.599999999999994, -347.8, -221.8, 20.000000000000014, -373.9, 53.0, 134.0, -379.3, -205.9, 113.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, -175.9, 116.0, -43.300000000000026, 122.0, -250.0, 20.000000000000014, -190.0, -266.8, -277.6, 49.7, -253.9, 188.0, 20.000000000000014, 167.0, 20.000000000000014, 20.000000000000014, -326.5, 124.1, -115.0, -329.79999999999995, -346.9, -124.3, -181.3, -67.9, -28.0, 20.000000000000014, 155.0, 20.000000000000014, -166.0, 20.000000000000014, 158.0, 128.0, -82.0, 20.000000000000014, 74.0, -290.7999999999999, -256.9, -194.5, 94.4, -274.0, 20.000000000000014, 139.1, -73.0, 20.000000000000014, -181.0, 7.399999999999999, -82.90000000000086], "policy_predator_policy_reward": [121.0, 199.0, 155.0, 142.0, 184.0, 0.0, 150.0, 177.0, 175.0, 42.0, 172.0, 0.0, 155.0, 123.0, 0.0, 191.0, 181.0, 157.0, 198.0, 167.0, 200.0, 142.0, 169.0, 192.0, 152.0, 140.0, 121.0, 161.0, 100.0, 175.0, 106.0, 200.0, 0.0, 130.0, 0.0, 174.0, 182.0, 180.0, 197.0, 0.0, 26.0, 41.0, 4.0, 4.0, 69.0, 72.0, 68.0, 131.0, 99.0, 0.0, 143.0, 163.0, 0.0, 0.0, 104.0, 132.0, 0.0, 144.0, 198.0, 184.0, 89.0, 98.0, 172.0, 155.0, 163.0, 186.0, 0.0, 57.0, 0.0, 1.0, 153.0, 152.0, 163.0, 97.0, 0.0, 5.0, 183.0, 118.0, 158.0, 144.0, 172.0, 0.0, 184.0, 165.0, 149.0, 153.0, 0.0, 200.0, 176.0, 153.0, 186.0, 179.0, 0.0, 167.0, 181.0, 156.0, 133.0, 100.0, 160.0, 189.0, 127.0, 126.0, 200.0, 0.0, 171.0, 0.0, 0.0, 181.0, 133.0, 171.0, 102.0, 148.0, 146.0, 108.0, 91.0, 151.0, 188.0, 0.0, 106.0, 122.0, 177.0, 176.0, 157.0, 3.0, 129.0, 184.0, 169.0, 156.0, 163.0, 130.0, 137.0, 143.0, 126.0, 0.0, 91.0, 3.0, 0.0, 18.0, 178.0, 0.0, 177.0, 170.0, 47.0, 128.0, 182.0, 196.0, 0.0, 191.0, 0.0, 135.0, 0.0, 0.0, 107.0, 120.0, 45.0, 46.0, 142.0, 136.0, 97.0, 95.0, 181.0, 169.0, 0.0, 179.0, 0.0, 4.0, 11.0, 0.0, 0.0, 174.0, 118.0, 0.0, 194.0, 171.0, 137.0, 153.0, 131.0, 85.0, 0.0, 15.0, 75.0, 110.0, 2.0, 12.0, 61.0, 87.0, 35.0, 21.0, 144.0, 156.0, 130.0, 123.0, 102.0, 140.0, 74.0, 96.0, 115.0, 0.0, 75.0, 50.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1033988620261739, "mean_inference_ms": 2.7010077521324805, "mean_action_processing_ms": 0.4334625045028035, "mean_env_wait_ms": 0.34177258430083085, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004781961441040039, "StateBufferConnector_ms": 0.005374908447265625, "ViewRequirementAgentConnector_ms": 0.213212251663208}, "num_episodes": 18, "episode_return_max": 264.89999999999975, "episode_return_min": -508.2, "episode_return_mean": -59.964000000000034, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1264000, "num_agent_steps_trained": 1264000, "num_env_steps_sampled": 316000, "num_env_steps_trained": 316000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 59.784387639843715, "num_env_steps_trained_throughput_per_sec": 59.784387639843715, "timesteps_total": 316000, "num_env_steps_sampled_lifetime": 316000, "num_agent_steps_sampled_lifetime": 1264000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1264000, "timers": {"training_iteration_time_ms": 69537.41, "restore_workers_time_ms": 0.041, "training_step_time_ms": 69537.329, "sample_time_ms": 2645.145, "learn_time_ms": 66862.731, "learn_throughput": 59.824, "synch_weights_time_ms": 25.786}, "counters": {"num_env_steps_sampled": 316000, "num_env_steps_trained": 316000, "num_agent_steps_sampled": 1264000, "num_agent_steps_trained": 1264000}, "done": false, "training_iteration": 79, "trial_id": "11e70_00000", "date": "2024-08-13_00-26-21", "timestamp": 1723523181, "time_this_iter_s": 66.9786970615387, "time_total_s": 4758.148486614227, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2b06550>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 4758.148486614227, "iterations_since_restore": 79, "perf": {"cpu_util_percent": 75.81052631578949, "ram_util_percent": 80.34105263157895}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 17.8786401953016, "cur_kl_coeff": 0.22500000000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.6164563676036856, "policy_loss": -0.007794311547297097, "vf_loss": 3.6227561288409764, "vf_explained_var": 0.2097888415137296, "kl": 0.006642436769861844, "entropy": 0.9460887921234918, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 150255.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 12.998238926211362, "cur_kl_coeff": 0.16875, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.2333753532833525, "policy_loss": -0.015179096407961673, "vf_loss": 6.247280115803713, "vf_explained_var": 0.5342506928418679, "kl": 0.0075515479893004805, "entropy": 0.9867062627638459, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 150255.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 320000, "num_env_steps_trained": 320000, "num_agent_steps_sampled": 1280000, "num_agent_steps_trained": 1280000}, "env_runners": {"episode_reward_max": 381.4, "episode_reward_min": -379.9, "episode_reward_mean": 18.646999999999927, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 197.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -80.7115, "predator_policy": 90.035}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-11.599999999999966, 12.800000000000255, 13.000000000000078, 31.000000000000256, 40.0000000000003, -214.8, -226.99999999999991, -42.099999999999916, 62.000000000000206, -179.60000000000002, -200.5, 105.09999999999926, 38.90000000000028, -318.6, -65.40000000000025, 264.89999999999975, -27.999999999999794, -189.89999999999998, -379.9, -352.9, -6.6000000000000245, -180.0, -11.100000000000053, -202.5, -41.1, -13.0, -18.59999999999983, 28.700000000000003, -23.80000000000004, -269.4, -47.0, -67.3, -73.59999999999982, -9.100000000000058, 99.6, -213.30000000000004, -158.70000000000053, 70.89999999999996, -143.1, -193.6, -337.0, -285.1, 74.40000000000006, -19.9, 98.5, 73.4, 158.79999999999956, -143.20000000000047, -44.400000000000006, -26.799999999999827, 57.099999999999994, -54.3, 42.099999999999994, 40.0000000000003, 71.10000000000002, 163.6999999999997, 150.0, 21.999999999999954, -194.4, -25.200000000000003, 211.99999999999926, 197.99999999999926, -132.50000000000048, 127.1, -311.69999999999993, -15.599999999999994, 120.1, 189.99999999999926, 39.00000000000004, 191.9999999999994, 194.0, 149.9999999999996, -247.70000000000005, 152.9, -11.999999999999842, 236.1, -46.0000000000002, 49.50000000000019, 235.3, 168.9, 195.99999999999937, 191.99999999999937, 287.29999999999995, 220.1, 71.30000000000015, 56.6, 182.9999999999995, 221.0, 213.2999999999993, 212.6, 144.4, 209.99999999999926, 85.39999999999999, 348.0, 381.4, 40.0000000000003, 113.99999999999982, 186.0, 188.1, 109.19999999999985], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-109.60000000000002, -43.00000000000002, -206.20000000000005, 20.000000000000014, -106.0, 20.000000000000014, 20.000000000000014, -295.0, 20.000000000000014, 20.000000000000014, -197.8, -253.0, -147.4, -223.60000000000002, -360.0999999999999, -63.99999999999977, -145.0, 20.000000000000014, -205.3, -301.3, -356.5, -193.0, 20.000000000000014, 28.099999999999994, 17.899999999999988, 20.000000000000014, -298.6, -325.0, -345.4, 20.000000000000014, 173.3, 86.59999999999997, -349.0, 20.000000000000014, -244.6, -247.3, -304.3, -247.6, -353.5, -348.4, 20.000000000000014, -328.6, -400.0, 20.0, -355.9, 15.799999999999963, -366.7, -200.8, -303.1, 95.0, -271.0, -79.0, 20.000000000000014, -271.6, 34.699999999999996, -355.0, -183.4, -93.40000000000002, -363.4, -106.0, -301.0, 83.0, -327.4, 79.1, -338.8, -38.80000000000004, -279.10000000000014, 20.000000000000014, -215.5, 61.1, -207.4, -247.9, 20.000000000000014, -366.7, -76.0, -81.10000000000002, -168.7, -327.4, -82.6, -271.0, -313.6, -336.4, -307.3, -302.8, 47.0, -265.6, -193.0, -106.9, -25.0, -2.5, 137.89999999999998, -158.5, 20.000000000000014, 120.8, 20.000000000000014, -341.2, -43.599999999999994, -347.8, -221.8, 20.000000000000014, -373.9, 53.0, 134.0, -379.3, -205.9, 113.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, -175.9, 116.0, -43.300000000000026, 122.0, -250.0, 20.000000000000014, -190.0, -266.8, -277.6, 49.7, -253.9, 188.0, 20.000000000000014, 167.0, 20.000000000000014, 20.000000000000014, -326.5, 124.1, -115.0, -329.79999999999995, -346.9, -124.3, -181.3, -67.9, -28.0, 20.000000000000014, 155.0, 20.000000000000014, -166.0, 20.000000000000014, 158.0, 128.0, -82.0, 20.000000000000014, 74.0, -290.7999999999999, -256.9, -194.5, 94.4, -274.0, 20.000000000000014, 139.1, -73.0, 20.000000000000014, -181.0, 7.399999999999999, -82.90000000000086, 68.3, 83.0, -73.0, 119.9, 146.0, 20.000000000000014, 20.000000000000014, 152.0, 167.6, 109.69999999999999, 124.4, 4.700000000000003, 20.000000000000014, -42.69999999999999, -7.600000000000023, -146.8, 20.000000000000014, 116.0, -214.0, 161.0, 20.000000000000014, 191.3, 29.599999999999994, 92.0, -19.599999999999994, -49.0, 185.0, 20.000000000000014, -103.9, -0.7000000000000313, 179.0, 143.0, 197.0, 169.4, 20.000000000000014, 20.000000000000014, 17.0, 20.000000000000014, 14.0, 68.0, 173.0, -76.9, -53.500000000000135, 112.7], "policy_predator_policy_reward": [69.0, 72.0, 68.0, 131.0, 99.0, 0.0, 143.0, 163.0, 0.0, 0.0, 104.0, 132.0, 0.0, 144.0, 198.0, 184.0, 89.0, 98.0, 172.0, 155.0, 163.0, 186.0, 0.0, 57.0, 0.0, 1.0, 153.0, 152.0, 163.0, 97.0, 0.0, 5.0, 183.0, 118.0, 158.0, 144.0, 172.0, 0.0, 184.0, 165.0, 149.0, 153.0, 0.0, 200.0, 176.0, 153.0, 186.0, 179.0, 0.0, 167.0, 181.0, 156.0, 133.0, 100.0, 160.0, 189.0, 127.0, 126.0, 200.0, 0.0, 171.0, 0.0, 0.0, 181.0, 133.0, 171.0, 102.0, 148.0, 146.0, 108.0, 91.0, 151.0, 188.0, 0.0, 106.0, 122.0, 177.0, 176.0, 157.0, 3.0, 129.0, 184.0, 169.0, 156.0, 163.0, 130.0, 137.0, 143.0, 126.0, 0.0, 91.0, 3.0, 0.0, 18.0, 178.0, 0.0, 177.0, 170.0, 47.0, 128.0, 182.0, 196.0, 0.0, 191.0, 0.0, 135.0, 0.0, 0.0, 107.0, 120.0, 45.0, 46.0, 142.0, 136.0, 97.0, 95.0, 181.0, 169.0, 0.0, 179.0, 0.0, 4.0, 11.0, 0.0, 0.0, 174.0, 118.0, 0.0, 194.0, 171.0, 137.0, 153.0, 131.0, 85.0, 0.0, 15.0, 75.0, 110.0, 2.0, 12.0, 61.0, 87.0, 35.0, 21.0, 144.0, 156.0, 130.0, 123.0, 102.0, 140.0, 74.0, 96.0, 115.0, 0.0, 75.0, 50.0, 56.0, 28.0, 54.0, 68.0, 12.0, 18.0, 14.0, 6.0, 0.0, 10.0, 73.0, 18.0, 47.0, 47.0, 117.0, 94.0, 24.0, 23.0, 132.0, 142.0, 2.0, 0.0, 40.0, 51.0, 121.0, 92.0, 0.0, 5.0, 83.0, 107.0, 26.0, 0.0, 9.0, 6.0, 0.0, 0.0, 18.0, 59.0, 51.0, 53.0, 88.0, 4.0, 35.0, 15.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1015854026076684, "mean_inference_ms": 2.6948861565665108, "mean_action_processing_ms": 0.43267462055043765, "mean_env_wait_ms": 0.3411683755277653, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004587292671203613, "StateBufferConnector_ms": 0.005355715751647949, "ViewRequirementAgentConnector_ms": 0.16976726055145264}, "num_episodes": 22, "episode_return_max": 381.4, "episode_return_min": -379.9, "episode_return_mean": 18.646999999999927, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1280000, "num_agent_steps_trained": 1280000, "num_env_steps_sampled": 320000, "num_env_steps_trained": 320000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 58.08326240812169, "num_env_steps_trained_throughput_per_sec": 58.08326240812169, "timesteps_total": 320000, "num_env_steps_sampled_lifetime": 320000, "num_agent_steps_sampled_lifetime": 1280000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1280000, "timers": {"training_iteration_time_ms": 69058.543, "restore_workers_time_ms": 0.042, "training_step_time_ms": 69058.461, "sample_time_ms": 2272.918, "learn_time_ms": 66756.24, "learn_throughput": 59.919, "synch_weights_time_ms": 25.24}, "counters": {"num_env_steps_sampled": 320000, "num_env_steps_trained": 320000, "num_agent_steps_sampled": 1280000, "num_agent_steps_trained": 1280000}, "done": false, "training_iteration": 80, "trial_id": "11e70_00000", "date": "2024-08-13_00-27-30", "timestamp": 1723523250, "time_this_iter_s": 68.8929750919342, "time_total_s": 4827.0414617061615, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2b06ca0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 4827.0414617061615, "iterations_since_restore": 80, "perf": {"cpu_util_percent": 73.3969387755102, "ram_util_percent": 79.91530612244898}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 17.491522347990166, "cur_kl_coeff": 0.22500000000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.543907611206095, "policy_loss": -0.010155516212668131, "vf_loss": 3.5523731693388925, "vf_explained_var": 0.1293959920683866, "kl": 0.007510901914938777, "entropy": 0.8867338324034656, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 152145.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 15.017603612955286, "cur_kl_coeff": 0.16875, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.991582510206435, "policy_loss": -0.013006068931931935, "vf_loss": 6.00268251050717, "vf_explained_var": 0.7010476965437491, "kl": 0.011295228252860608, "entropy": 1.0048279886523253, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 152145.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 324000, "num_env_steps_trained": 324000, "num_agent_steps_sampled": 1296000, "num_agent_steps_trained": 1296000}, "env_runners": {"episode_reward_max": 381.4, "episode_reward_min": -379.9, "episode_reward_mean": 57.1219999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 197.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -47.83900000000001, "predator_policy": 76.4}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-379.9, -352.9, -6.6000000000000245, -180.0, -11.100000000000053, -202.5, -41.1, -13.0, -18.59999999999983, 28.700000000000003, -23.80000000000004, -269.4, -47.0, -67.3, -73.59999999999982, -9.100000000000058, 99.6, -213.30000000000004, -158.70000000000053, 70.89999999999996, -143.1, -193.6, -337.0, -285.1, 74.40000000000006, -19.9, 98.5, 73.4, 158.79999999999956, -143.20000000000047, -44.400000000000006, -26.799999999999827, 57.099999999999994, -54.3, 42.099999999999994, 40.0000000000003, 71.10000000000002, 163.6999999999997, 150.0, 21.999999999999954, -194.4, -25.200000000000003, 211.99999999999926, 197.99999999999926, -132.50000000000048, 127.1, -311.69999999999993, -15.599999999999994, 120.1, 189.99999999999926, 39.00000000000004, 191.9999999999994, 194.0, 149.9999999999996, -247.70000000000005, 152.9, -11.999999999999842, 236.1, -46.0000000000002, 49.50000000000019, 235.3, 168.9, 195.99999999999937, 191.99999999999937, 287.29999999999995, 220.1, 71.30000000000015, 56.6, 182.9999999999995, 221.0, 213.2999999999993, 212.6, 144.4, 209.99999999999926, 85.39999999999999, 348.0, 381.4, 40.0000000000003, 113.99999999999982, 186.0, 188.1, 109.19999999999985, 341.0, 200.0999999999993, 87.80000000000007, 40.0000000000003, 168.99999999999946, 242.0, 147.3999999999995, 267.30000000000007, 106.69999999999989, 267.7, 283.4, 155.99999999999957, 40.0000000000003, 152.2, 31.200000000000166, 217.79999999999967, 30.100000000000147, 157.99999999999943], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-304.3, -247.6, -353.5, -348.4, 20.000000000000014, -328.6, -400.0, 20.0, -355.9, 15.799999999999963, -366.7, -200.8, -303.1, 95.0, -271.0, -79.0, 20.000000000000014, -271.6, 34.699999999999996, -355.0, -183.4, -93.40000000000002, -363.4, -106.0, -301.0, 83.0, -327.4, 79.1, -338.8, -38.80000000000004, -279.10000000000014, 20.000000000000014, -215.5, 61.1, -207.4, -247.9, 20.000000000000014, -366.7, -76.0, -81.10000000000002, -168.7, -327.4, -82.6, -271.0, -313.6, -336.4, -307.3, -302.8, 47.0, -265.6, -193.0, -106.9, -25.0, -2.5, 137.89999999999998, -158.5, 20.000000000000014, 120.8, 20.000000000000014, -341.2, -43.599999999999994, -347.8, -221.8, 20.000000000000014, -373.9, 53.0, 134.0, -379.3, -205.9, 113.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, -175.9, 116.0, -43.300000000000026, 122.0, -250.0, 20.000000000000014, -190.0, -266.8, -277.6, 49.7, -253.9, 188.0, 20.000000000000014, 167.0, 20.000000000000014, 20.000000000000014, -326.5, 124.1, -115.0, -329.79999999999995, -346.9, -124.3, -181.3, -67.9, -28.0, 20.000000000000014, 155.0, 20.000000000000014, -166.0, 20.000000000000014, 158.0, 128.0, -82.0, 20.000000000000014, 74.0, -290.7999999999999, -256.9, -194.5, 94.4, -274.0, 20.000000000000014, 139.1, -73.0, 20.000000000000014, -181.0, 7.399999999999999, -82.90000000000086, 68.3, 83.0, -73.0, 119.9, 146.0, 20.000000000000014, 20.000000000000014, 152.0, 167.6, 109.69999999999999, 124.4, 4.700000000000003, 20.000000000000014, -42.69999999999999, -7.600000000000023, -146.8, 20.000000000000014, 116.0, -214.0, 161.0, 20.000000000000014, 191.3, 29.599999999999994, 92.0, -19.599999999999994, -49.0, 185.0, 20.000000000000014, -103.9, -0.7000000000000313, 179.0, 143.0, 197.0, 169.4, 20.000000000000014, 20.000000000000014, 17.0, 20.000000000000014, 14.0, 68.0, 173.0, -76.9, -53.500000000000135, 112.7, 128.0, 161.0, 169.1, 20.000000000000014, -43.00000000000003, -2.200000000000003, 20.000000000000014, 20.000000000000014, 122.0, 20.000000000000014, 104.0, 50.0, 20.000000000000014, 82.4, 71.30000000000001, 152.0, -34.3, 20.000000000000014, 70.7, 146.0, 116.0, 127.4, 101.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, -20.799999999999997, 32.0, 3.1999999999999615, 20.000000000000014, 136.1, 49.69999999999996, 1.0999999999999865, 20.000000000000014, 101.0, 20.000000000000014], "policy_predator_policy_reward": [172.0, 0.0, 184.0, 165.0, 149.0, 153.0, 0.0, 200.0, 176.0, 153.0, 186.0, 179.0, 0.0, 167.0, 181.0, 156.0, 133.0, 100.0, 160.0, 189.0, 127.0, 126.0, 200.0, 0.0, 171.0, 0.0, 0.0, 181.0, 133.0, 171.0, 102.0, 148.0, 146.0, 108.0, 91.0, 151.0, 188.0, 0.0, 106.0, 122.0, 177.0, 176.0, 157.0, 3.0, 129.0, 184.0, 169.0, 156.0, 163.0, 130.0, 137.0, 143.0, 126.0, 0.0, 91.0, 3.0, 0.0, 18.0, 178.0, 0.0, 177.0, 170.0, 47.0, 128.0, 182.0, 196.0, 0.0, 191.0, 0.0, 135.0, 0.0, 0.0, 107.0, 120.0, 45.0, 46.0, 142.0, 136.0, 97.0, 95.0, 181.0, 169.0, 0.0, 179.0, 0.0, 4.0, 11.0, 0.0, 0.0, 174.0, 118.0, 0.0, 194.0, 171.0, 137.0, 153.0, 131.0, 85.0, 0.0, 15.0, 75.0, 110.0, 2.0, 12.0, 61.0, 87.0, 35.0, 21.0, 144.0, 156.0, 130.0, 123.0, 102.0, 140.0, 74.0, 96.0, 115.0, 0.0, 75.0, 50.0, 56.0, 28.0, 54.0, 68.0, 12.0, 18.0, 14.0, 6.0, 0.0, 10.0, 73.0, 18.0, 47.0, 47.0, 117.0, 94.0, 24.0, 23.0, 132.0, 142.0, 2.0, 0.0, 40.0, 51.0, 121.0, 92.0, 0.0, 5.0, 83.0, 107.0, 26.0, 0.0, 9.0, 6.0, 0.0, 0.0, 18.0, 59.0, 51.0, 53.0, 88.0, 4.0, 35.0, 15.0, 19.0, 33.0, 9.0, 2.0, 59.0, 74.0, 0.0, 0.0, 4.0, 23.0, 35.0, 53.0, 14.0, 31.0, 23.0, 21.0, 63.0, 58.0, 0.0, 51.0, 25.0, 15.0, 32.0, 3.0, 0.0, 0.0, 87.0, 54.0, 8.0, 0.0, 20.0, 12.0, 9.0, 0.0, 23.0, 14.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1000266222499426, "mean_inference_ms": 2.6890431857892967, "mean_action_processing_ms": 0.4320330129416371, "mean_env_wait_ms": 0.340507927733748, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00655972957611084, "StateBufferConnector_ms": 0.006064295768737793, "ViewRequirementAgentConnector_ms": 0.16803550720214844}, "num_episodes": 18, "episode_return_max": 381.4, "episode_return_min": -379.9, "episode_return_mean": 57.1219999999999, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1296000, "num_agent_steps_trained": 1296000, "num_env_steps_sampled": 324000, "num_env_steps_trained": 324000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 62.60045603007407, "num_env_steps_trained_throughput_per_sec": 62.60045603007407, "timesteps_total": 324000, "num_env_steps_sampled_lifetime": 324000, "num_agent_steps_sampled_lifetime": 1296000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1296000, "timers": {"training_iteration_time_ms": 68501.023, "restore_workers_time_ms": 0.042, "training_step_time_ms": 68500.94, "sample_time_ms": 2133.569, "learn_time_ms": 66337.139, "learn_throughput": 60.298, "synch_weights_time_ms": 25.949}, "counters": {"num_env_steps_sampled": 324000, "num_env_steps_trained": 324000, "num_agent_steps_sampled": 1296000, "num_agent_steps_trained": 1296000}, "done": false, "training_iteration": 81, "trial_id": "11e70_00000", "date": "2024-08-13_00-28-34", "timestamp": 1723523314, "time_this_iter_s": 63.9267692565918, "time_total_s": 4890.968230962753, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3f8aee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 4890.968230962753, "iterations_since_restore": 81, "perf": {"cpu_util_percent": 66.62087912087912, "ram_util_percent": 83.52857142857142}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 15.828759357159731, "cur_kl_coeff": 0.22500000000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.05143994856133, "policy_loss": -0.008027945947340596, "vf_loss": 3.057953640897438, "vf_explained_var": 0.3367437265852772, "kl": 0.0067300406433026755, "entropy": 0.9292543329889812, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 154035.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 15.903054399843569, "cur_kl_coeff": 0.16875, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.591255713644482, "policy_loss": -0.01622336687576814, "vf_loss": 5.605191276186988, "vf_explained_var": 0.6328930581057514, "kl": 0.013557432256031827, "entropy": 1.0048395158437193, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 154035.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 328000, "num_env_steps_trained": 328000, "num_agent_steps_sampled": 1312000, "num_agent_steps_trained": 1312000}, "env_runners": {"episode_reward_max": 381.4, "episode_reward_min": -311.69999999999993, "episode_reward_mean": 119.15299999999986, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -379.3, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 197.0, "predator_policy": 196.0}, "policy_reward_mean": {"prey_policy": 6.246499999999997, "predator_policy": 53.33}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-285.1, 74.40000000000006, -19.9, 98.5, 73.4, 158.79999999999956, -143.20000000000047, -44.400000000000006, -26.799999999999827, 57.099999999999994, -54.3, 42.099999999999994, 40.0000000000003, 71.10000000000002, 163.6999999999997, 150.0, 21.999999999999954, -194.4, -25.200000000000003, 211.99999999999926, 197.99999999999926, -132.50000000000048, 127.1, -311.69999999999993, -15.599999999999994, 120.1, 189.99999999999926, 39.00000000000004, 191.9999999999994, 194.0, 149.9999999999996, -247.70000000000005, 152.9, -11.999999999999842, 236.1, -46.0000000000002, 49.50000000000019, 235.3, 168.9, 195.99999999999937, 191.99999999999937, 287.29999999999995, 220.1, 71.30000000000015, 56.6, 182.9999999999995, 221.0, 213.2999999999993, 212.6, 144.4, 209.99999999999926, 85.39999999999999, 348.0, 381.4, 40.0000000000003, 113.99999999999982, 186.0, 188.1, 109.19999999999985, 341.0, 200.0999999999993, 87.80000000000007, 40.0000000000003, 168.99999999999946, 242.0, 147.3999999999995, 267.30000000000007, 106.69999999999989, 267.7, 283.4, 155.99999999999957, 40.0000000000003, 152.2, 31.200000000000166, 217.79999999999967, 30.100000000000147, 157.99999999999943, 136.8999999999997, 309.2, 195.0, 40.0000000000003, 179.99999999999937, 127.70000000000016, 195.99999999999937, -114.00000000000081, 293.0, 247.0, 40.0000000000003, 274.9, 12.50000000000003, 235.5999999999996, 154.9, 2.5000000000000573, 206.8, 175.99999999999952, 124.5, 199.9, 197.99999999999937, 139.3999999999996, 284.9], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-307.3, -302.8, 47.0, -265.6, -193.0, -106.9, -25.0, -2.5, 137.89999999999998, -158.5, 20.000000000000014, 120.8, 20.000000000000014, -341.2, -43.599999999999994, -347.8, -221.8, 20.000000000000014, -373.9, 53.0, 134.0, -379.3, -205.9, 113.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, -175.9, 116.0, -43.300000000000026, 122.0, -250.0, 20.000000000000014, -190.0, -266.8, -277.6, 49.7, -253.9, 188.0, 20.000000000000014, 167.0, 20.000000000000014, 20.000000000000014, -326.5, 124.1, -115.0, -329.79999999999995, -346.9, -124.3, -181.3, -67.9, -28.0, 20.000000000000014, 155.0, 20.000000000000014, -166.0, 20.000000000000014, 158.0, 128.0, -82.0, 20.000000000000014, 74.0, -290.7999999999999, -256.9, -194.5, 94.4, -274.0, 20.000000000000014, 139.1, -73.0, 20.000000000000014, -181.0, 7.399999999999999, -82.90000000000086, 68.3, 83.0, -73.0, 119.9, 146.0, 20.000000000000014, 20.000000000000014, 152.0, 167.6, 109.69999999999999, 124.4, 4.700000000000003, 20.000000000000014, -42.69999999999999, -7.600000000000023, -146.8, 20.000000000000014, 116.0, -214.0, 161.0, 20.000000000000014, 191.3, 29.599999999999994, 92.0, -19.599999999999994, -49.0, 185.0, 20.000000000000014, -103.9, -0.7000000000000313, 179.0, 143.0, 197.0, 169.4, 20.000000000000014, 20.000000000000014, 17.0, 20.000000000000014, 14.0, 68.0, 173.0, -76.9, -53.500000000000135, 112.7, 128.0, 161.0, 169.1, 20.000000000000014, -43.00000000000003, -2.200000000000003, 20.000000000000014, 20.000000000000014, 122.0, 20.000000000000014, 104.0, 50.0, 20.000000000000014, 82.4, 71.30000000000001, 152.0, -34.3, 20.000000000000014, 70.7, 146.0, 116.0, 127.4, 101.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, -20.799999999999997, 32.0, 3.1999999999999615, 20.000000000000014, 136.1, 49.69999999999996, 1.0999999999999865, 20.000000000000014, 101.0, 20.000000000000014, -24.09999999999979, 110.0, 158.0, 105.2, 84.8, 12.200000000000003, 20.000000000000014, 20.000000000000014, 140.0, 20.000000000000014, 53.900000000000134, 45.800000000000054, 20.000000000000014, 152.0, -274.00000000000017, 20.000000000000014, 119.0, 119.0, 95.0, 104.0, 20.000000000000014, 20.000000000000014, 110.0, 101.9, 20.000000000000014, -32.49999999999975, 55.99999999999996, 176.6, 2.9000000000000057, 71.0, 47.0, -200.50000000000026, 33.8, 98.0, 20.000000000000014, 131.0, 44.0, -35.5, 137.0, -27.099999999999994, 167.0, 20.000000000000014, 122.0, -34.59999999999975, 122.0, 83.9], "policy_predator_policy_reward": [169.0, 156.0, 163.0, 130.0, 137.0, 143.0, 126.0, 0.0, 91.0, 3.0, 0.0, 18.0, 178.0, 0.0, 177.0, 170.0, 47.0, 128.0, 182.0, 196.0, 0.0, 191.0, 0.0, 135.0, 0.0, 0.0, 107.0, 120.0, 45.0, 46.0, 142.0, 136.0, 97.0, 95.0, 181.0, 169.0, 0.0, 179.0, 0.0, 4.0, 11.0, 0.0, 0.0, 174.0, 118.0, 0.0, 194.0, 171.0, 137.0, 153.0, 131.0, 85.0, 0.0, 15.0, 75.0, 110.0, 2.0, 12.0, 61.0, 87.0, 35.0, 21.0, 144.0, 156.0, 130.0, 123.0, 102.0, 140.0, 74.0, 96.0, 115.0, 0.0, 75.0, 50.0, 56.0, 28.0, 54.0, 68.0, 12.0, 18.0, 14.0, 6.0, 0.0, 10.0, 73.0, 18.0, 47.0, 47.0, 117.0, 94.0, 24.0, 23.0, 132.0, 142.0, 2.0, 0.0, 40.0, 51.0, 121.0, 92.0, 0.0, 5.0, 83.0, 107.0, 26.0, 0.0, 9.0, 6.0, 0.0, 0.0, 18.0, 59.0, 51.0, 53.0, 88.0, 4.0, 35.0, 15.0, 19.0, 33.0, 9.0, 2.0, 59.0, 74.0, 0.0, 0.0, 4.0, 23.0, 35.0, 53.0, 14.0, 31.0, 23.0, 21.0, 63.0, 58.0, 0.0, 51.0, 25.0, 15.0, 32.0, 3.0, 0.0, 0.0, 87.0, 54.0, 8.0, 0.0, 20.0, 12.0, 9.0, 0.0, 23.0, 14.0, 21.0, 30.0, 34.0, 12.0, 39.0, 59.0, 0.0, 0.0, 10.0, 10.0, 10.0, 18.0, 16.0, 8.0, 0.0, 140.0, 37.0, 18.0, 4.0, 44.0, 0.0, 0.0, 29.0, 34.0, 0.0, 25.0, 0.0, 3.0, 42.0, 39.0, 105.0, 51.0, 51.0, 24.0, 16.0, 9.0, 63.0, 53.0, 26.0, 64.0, 4.0, 7.0, 26.0, 26.0, 40.0, 39.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1012411529997492, "mean_inference_ms": 2.6838780905040234, "mean_action_processing_ms": 0.43181616107256543, "mean_env_wait_ms": 0.33984805407875285, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006824016571044922, "StateBufferConnector_ms": 0.006013274192810059, "ViewRequirementAgentConnector_ms": 0.1731933355331421}, "num_episodes": 23, "episode_return_max": 381.4, "episode_return_min": -311.69999999999993, "episode_return_mean": 119.15299999999986, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1312000, "num_agent_steps_trained": 1312000, "num_env_steps_sampled": 328000, "num_env_steps_trained": 328000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 63.81755260299553, "num_env_steps_trained_throughput_per_sec": 63.81755260299553, "timesteps_total": 328000, "num_env_steps_sampled_lifetime": 328000, "num_agent_steps_sampled_lifetime": 1312000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1312000, "timers": {"training_iteration_time_ms": 68430.439, "restore_workers_time_ms": 0.043, "training_step_time_ms": 68430.356, "sample_time_ms": 2122.949, "learn_time_ms": 66277.271, "learn_throughput": 60.353, "synch_weights_time_ms": 25.684}, "counters": {"num_env_steps_sampled": 328000, "num_env_steps_trained": 328000, "num_agent_steps_sampled": 1312000, "num_agent_steps_trained": 1312000}, "done": false, "training_iteration": 82, "trial_id": "11e70_00000", "date": "2024-08-13_00-29-37", "timestamp": 1723523377, "time_this_iter_s": 62.713027238845825, "time_total_s": 4953.681258201599, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b4a5c820>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 4953.681258201599, "iterations_since_restore": 82, "perf": {"cpu_util_percent": 65.87752808988765, "ram_util_percent": 82.85842696629213}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 13.203104997942688, "cur_kl_coeff": 0.22500000000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.022946758308108, "policy_loss": -0.0089689760847096, "vf_loss": 3.030220125213502, "vf_explained_var": 0.13679909315058794, "kl": 0.007536045612298482, "entropy": 0.8629744748274485, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 155925.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 20.680262106562417, "cur_kl_coeff": 0.16875, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.36209263057305, "policy_loss": -0.009966290814718282, "vf_loss": 5.370589754190394, "vf_explained_var": 0.6823582849805317, "kl": 0.008706098098272063, "entropy": 0.9448737117663893, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 155925.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 332000, "num_env_steps_trained": 332000, "num_agent_steps_sampled": 1328000, "num_agent_steps_trained": 1328000}, "env_runners": {"episode_reward_max": 381.4, "episode_reward_min": -311.69999999999993, "episode_reward_mean": 155.31899999999985, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -346.9, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 197.0, "predator_policy": 194.0}, "policy_reward_mean": {"prey_policy": 39.2645, "predator_policy": 38.395}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-25.200000000000003, 211.99999999999926, 197.99999999999926, -132.50000000000048, 127.1, -311.69999999999993, -15.599999999999994, 120.1, 189.99999999999926, 39.00000000000004, 191.9999999999994, 194.0, 149.9999999999996, -247.70000000000005, 152.9, -11.999999999999842, 236.1, -46.0000000000002, 49.50000000000019, 235.3, 168.9, 195.99999999999937, 191.99999999999937, 287.29999999999995, 220.1, 71.30000000000015, 56.6, 182.9999999999995, 221.0, 213.2999999999993, 212.6, 144.4, 209.99999999999926, 85.39999999999999, 348.0, 381.4, 40.0000000000003, 113.99999999999982, 186.0, 188.1, 109.19999999999985, 341.0, 200.0999999999993, 87.80000000000007, 40.0000000000003, 168.99999999999946, 242.0, 147.3999999999995, 267.30000000000007, 106.69999999999989, 267.7, 283.4, 155.99999999999957, 40.0000000000003, 152.2, 31.200000000000166, 217.79999999999967, 30.100000000000147, 157.99999999999943, 136.8999999999997, 309.2, 195.0, 40.0000000000003, 179.99999999999937, 127.70000000000016, 195.99999999999937, -114.00000000000081, 293.0, 247.0, 40.0000000000003, 274.9, 12.50000000000003, 235.5999999999996, 154.9, 2.5000000000000573, 206.8, 175.99999999999952, 124.5, 199.9, 197.99999999999937, 139.3999999999996, 284.9, 40.0000000000003, 270.4, 148.0999999999996, 149.7999999999996, 374.0, 318.2, 199.59999999999937, 300.6, 193.29999999999987, 169.39999999999952, 307.0, 113.59999999999985, 281.70000000000005, 154.19999999999965, 286.4, 226.19999999999962, 216.6, 50.50000000000011], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [49.7, -253.9, 188.0, 20.000000000000014, 167.0, 20.000000000000014, 20.000000000000014, -326.5, 124.1, -115.0, -329.79999999999995, -346.9, -124.3, -181.3, -67.9, -28.0, 20.000000000000014, 155.0, 20.000000000000014, -166.0, 20.000000000000014, 158.0, 128.0, -82.0, 20.000000000000014, 74.0, -290.7999999999999, -256.9, -194.5, 94.4, -274.0, 20.000000000000014, 139.1, -73.0, 20.000000000000014, -181.0, 7.399999999999999, -82.90000000000086, 68.3, 83.0, -73.0, 119.9, 146.0, 20.000000000000014, 20.000000000000014, 152.0, 167.6, 109.69999999999999, 124.4, 4.700000000000003, 20.000000000000014, -42.69999999999999, -7.600000000000023, -146.8, 20.000000000000014, 116.0, -214.0, 161.0, 20.000000000000014, 191.3, 29.599999999999994, 92.0, -19.599999999999994, -49.0, 185.0, 20.000000000000014, -103.9, -0.7000000000000313, 179.0, 143.0, 197.0, 169.4, 20.000000000000014, 20.000000000000014, 17.0, 20.000000000000014, 14.0, 68.0, 173.0, -76.9, -53.500000000000135, 112.7, 128.0, 161.0, 169.1, 20.000000000000014, -43.00000000000003, -2.200000000000003, 20.000000000000014, 20.000000000000014, 122.0, 20.000000000000014, 104.0, 50.0, 20.000000000000014, 82.4, 71.30000000000001, 152.0, -34.3, 20.000000000000014, 70.7, 146.0, 116.0, 127.4, 101.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, -20.799999999999997, 32.0, 3.1999999999999615, 20.000000000000014, 136.1, 49.69999999999996, 1.0999999999999865, 20.000000000000014, 101.0, 20.000000000000014, -24.09999999999979, 110.0, 158.0, 105.2, 84.8, 12.200000000000003, 20.000000000000014, 20.000000000000014, 140.0, 20.000000000000014, 53.900000000000134, 45.800000000000054, 20.000000000000014, 152.0, -274.00000000000017, 20.000000000000014, 119.0, 119.0, 95.0, 104.0, 20.000000000000014, 20.000000000000014, 110.0, 101.9, 20.000000000000014, -32.49999999999975, 55.99999999999996, 176.6, 2.9000000000000057, 71.0, 47.0, -200.50000000000026, 33.8, 98.0, 20.000000000000014, 131.0, 44.0, -35.5, 137.0, -27.099999999999994, 167.0, 20.000000000000014, 122.0, -34.59999999999975, 122.0, 83.9, 20.000000000000014, 20.000000000000014, 114.5, 98.89999999999999, 85.1, 20.000000000000014, 90.8, 20.000000000000014, 176.0, 188.0, 157.1, 139.1, 20.000000000000014, 176.6, 98.6, 143.0, 11.300000000000175, 134.0, 20.900000000000013, 96.5, 80.0, 158.0, 92.59999999999997, 20.000000000000014, 160.7, 100.99999999999999, 20.000000000000014, 102.2, 130.4, 101.0, 158.0, 54.19999999999996, -16.0, 107.6, -11.500000000000028, 20.000000000000014], "policy_predator_policy_reward": [0.0, 179.0, 0.0, 4.0, 11.0, 0.0, 0.0, 174.0, 118.0, 0.0, 194.0, 171.0, 137.0, 153.0, 131.0, 85.0, 0.0, 15.0, 75.0, 110.0, 2.0, 12.0, 61.0, 87.0, 35.0, 21.0, 144.0, 156.0, 130.0, 123.0, 102.0, 140.0, 74.0, 96.0, 115.0, 0.0, 75.0, 50.0, 56.0, 28.0, 54.0, 68.0, 12.0, 18.0, 14.0, 6.0, 0.0, 10.0, 73.0, 18.0, 47.0, 47.0, 117.0, 94.0, 24.0, 23.0, 132.0, 142.0, 2.0, 0.0, 40.0, 51.0, 121.0, 92.0, 0.0, 5.0, 83.0, 107.0, 26.0, 0.0, 9.0, 6.0, 0.0, 0.0, 18.0, 59.0, 51.0, 53.0, 88.0, 4.0, 35.0, 15.0, 19.0, 33.0, 9.0, 2.0, 59.0, 74.0, 0.0, 0.0, 4.0, 23.0, 35.0, 53.0, 14.0, 31.0, 23.0, 21.0, 63.0, 58.0, 0.0, 51.0, 25.0, 15.0, 32.0, 3.0, 0.0, 0.0, 87.0, 54.0, 8.0, 0.0, 20.0, 12.0, 9.0, 0.0, 23.0, 14.0, 21.0, 30.0, 34.0, 12.0, 39.0, 59.0, 0.0, 0.0, 10.0, 10.0, 10.0, 18.0, 16.0, 8.0, 0.0, 140.0, 37.0, 18.0, 4.0, 44.0, 0.0, 0.0, 29.0, 34.0, 0.0, 25.0, 0.0, 3.0, 42.0, 39.0, 105.0, 51.0, 51.0, 24.0, 16.0, 9.0, 63.0, 53.0, 26.0, 64.0, 4.0, 7.0, 26.0, 26.0, 40.0, 39.0, 0.0, 0.0, 15.0, 42.0, 32.0, 11.0, 29.0, 10.0, 8.0, 2.0, 0.0, 22.0, 3.0, 0.0, 33.0, 26.0, 40.0, 8.0, 24.0, 28.0, 38.0, 31.0, 1.0, 0.0, 0.0, 20.0, 29.0, 3.0, 30.0, 25.0, 4.0, 10.0, 63.0, 62.0, 0.0, 42.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0989119785809967, "mean_inference_ms": 2.6808094175100314, "mean_action_processing_ms": 0.43131883568117635, "mean_env_wait_ms": 0.3397502542461129, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00643002986907959, "StateBufferConnector_ms": 0.00600886344909668, "ViewRequirementAgentConnector_ms": 0.15793085098266602}, "num_episodes": 18, "episode_return_max": 381.4, "episode_return_min": -311.69999999999993, "episode_return_mean": 155.31899999999985, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1328000, "num_agent_steps_trained": 1328000, "num_env_steps_sampled": 332000, "num_env_steps_trained": 332000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 77.41396017681883, "num_env_steps_trained_throughput_per_sec": 77.41396017681883, "timesteps_total": 332000, "num_env_steps_sampled_lifetime": 332000, "num_agent_steps_sampled_lifetime": 1328000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1328000, "timers": {"training_iteration_time_ms": 66515.741, "restore_workers_time_ms": 0.043, "training_step_time_ms": 66515.658, "sample_time_ms": 2062.54, "learn_time_ms": 64423.98, "learn_throughput": 62.089, "synch_weights_time_ms": 24.859}, "counters": {"num_env_steps_sampled": 332000, "num_env_steps_trained": 332000, "num_agent_steps_sampled": 1328000, "num_agent_steps_trained": 1328000}, "done": false, "training_iteration": 83, "trial_id": "11e70_00000", "date": "2024-08-13_00-30-28", "timestamp": 1723523428, "time_this_iter_s": 51.73561191558838, "time_total_s": 5005.4168701171875, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3f489d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 5005.4168701171875, "iterations_since_restore": 83, "perf": {"cpu_util_percent": 47.34109589041097, "ram_util_percent": 78.61780821917807}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 11.259779649562937, "cur_kl_coeff": 0.22500000000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.0411766848236166, "policy_loss": -0.00878039600904144, "vf_loss": 3.0485601534288396, "vf_explained_var": 0.1649870633763611, "kl": 0.006208561690446533, "entropy": 0.8669966124668324, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 157815.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 17.577684447626588, "cur_kl_coeff": 0.16875, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.87203276409674, "policy_loss": -0.013223083040100479, "vf_loss": 4.8839783874138325, "vf_explained_var": 0.7575913844915925, "kl": 0.007570098200298544, "entropy": 0.983161156865024, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 157815.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 336000, "num_env_steps_trained": 336000, "num_agent_steps_sampled": 1344000, "num_agent_steps_trained": 1344000}, "env_runners": {"episode_reward_max": 381.4, "episode_reward_min": -114.00000000000081, "episode_reward_mean": 184.48199999999986, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -274.00000000000017, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 197.0, "predator_policy": 142.0}, "policy_reward_mean": {"prey_policy": 64.601, "predator_policy": 27.64}, "custom_metrics": {}, "hist_stats": {"episode_reward": [49.50000000000019, 235.3, 168.9, 195.99999999999937, 191.99999999999937, 287.29999999999995, 220.1, 71.30000000000015, 56.6, 182.9999999999995, 221.0, 213.2999999999993, 212.6, 144.4, 209.99999999999926, 85.39999999999999, 348.0, 381.4, 40.0000000000003, 113.99999999999982, 186.0, 188.1, 109.19999999999985, 341.0, 200.0999999999993, 87.80000000000007, 40.0000000000003, 168.99999999999946, 242.0, 147.3999999999995, 267.30000000000007, 106.69999999999989, 267.7, 283.4, 155.99999999999957, 40.0000000000003, 152.2, 31.200000000000166, 217.79999999999967, 30.100000000000147, 157.99999999999943, 136.8999999999997, 309.2, 195.0, 40.0000000000003, 179.99999999999937, 127.70000000000016, 195.99999999999937, -114.00000000000081, 293.0, 247.0, 40.0000000000003, 274.9, 12.50000000000003, 235.5999999999996, 154.9, 2.5000000000000573, 206.8, 175.99999999999952, 124.5, 199.9, 197.99999999999937, 139.3999999999996, 284.9, 40.0000000000003, 270.4, 148.0999999999996, 149.7999999999996, 374.0, 318.2, 199.59999999999937, 300.6, 193.29999999999987, 169.39999999999952, 307.0, 113.59999999999985, 281.70000000000005, 154.19999999999965, 286.4, 226.19999999999962, 216.6, 50.50000000000011, 343.6, 151.99999999999963, 175.2, 219.2, 172.99999999999946, 199.99999999999935, 308.2, 304.2, 251.90000000000006, 158.49999999999957, 281.7, 124.6999999999997, 195.99999999999926, 143.89999999999964, 190.99999999999932, 109.29999999999976, 251.89999999999998, 352.5], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [7.399999999999999, -82.90000000000086, 68.3, 83.0, -73.0, 119.9, 146.0, 20.000000000000014, 20.000000000000014, 152.0, 167.6, 109.69999999999999, 124.4, 4.700000000000003, 20.000000000000014, -42.69999999999999, -7.600000000000023, -146.8, 20.000000000000014, 116.0, -214.0, 161.0, 20.000000000000014, 191.3, 29.599999999999994, 92.0, -19.599999999999994, -49.0, 185.0, 20.000000000000014, -103.9, -0.7000000000000313, 179.0, 143.0, 197.0, 169.4, 20.000000000000014, 20.000000000000014, 17.0, 20.000000000000014, 14.0, 68.0, 173.0, -76.9, -53.500000000000135, 112.7, 128.0, 161.0, 169.1, 20.000000000000014, -43.00000000000003, -2.200000000000003, 20.000000000000014, 20.000000000000014, 122.0, 20.000000000000014, 104.0, 50.0, 20.000000000000014, 82.4, 71.30000000000001, 152.0, -34.3, 20.000000000000014, 70.7, 146.0, 116.0, 127.4, 101.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, -20.799999999999997, 32.0, 3.1999999999999615, 20.000000000000014, 136.1, 49.69999999999996, 1.0999999999999865, 20.000000000000014, 101.0, 20.000000000000014, -24.09999999999979, 110.0, 158.0, 105.2, 84.8, 12.200000000000003, 20.000000000000014, 20.000000000000014, 140.0, 20.000000000000014, 53.900000000000134, 45.800000000000054, 20.000000000000014, 152.0, -274.00000000000017, 20.000000000000014, 119.0, 119.0, 95.0, 104.0, 20.000000000000014, 20.000000000000014, 110.0, 101.9, 20.000000000000014, -32.49999999999975, 55.99999999999996, 176.6, 2.9000000000000057, 71.0, 47.0, -200.50000000000026, 33.8, 98.0, 20.000000000000014, 131.0, 44.0, -35.5, 137.0, -27.099999999999994, 167.0, 20.000000000000014, 122.0, -34.59999999999975, 122.0, 83.9, 20.000000000000014, 20.000000000000014, 114.5, 98.89999999999999, 85.1, 20.000000000000014, 90.8, 20.000000000000014, 176.0, 188.0, 157.1, 139.1, 20.000000000000014, 176.6, 98.6, 143.0, 11.300000000000175, 134.0, 20.900000000000013, 96.5, 80.0, 158.0, 92.59999999999997, 20.000000000000014, 160.7, 100.99999999999999, 20.000000000000014, 102.2, 130.4, 101.0, 158.0, 54.19999999999996, -16.0, 107.6, -11.500000000000028, 20.000000000000014, 158.0, 164.6, 20.000000000000014, 98.0, 73.69999999999999, 12.499999999999993, 155.0, -26.799999999999997, 128.0, 20.000000000000014, 20.000000000000014, 170.0, 139.7, 150.5, 111.8, 139.4, 101.0, 98.89999999999998, 9.499999999999964, 101.0, 173.0, 88.69999999999999, 105.19999999999999, -11.499999999999819, 164.0, 20.000000000000014, 80.0, -3.099999999999958, 155.0, 20.000000000000014, 13.699999999999964, 56.599999999999994, 98.0, 92.89999999999999, 171.5, 164.0], "policy_predator_policy_reward": [75.0, 50.0, 56.0, 28.0, 54.0, 68.0, 12.0, 18.0, 14.0, 6.0, 0.0, 10.0, 73.0, 18.0, 47.0, 47.0, 117.0, 94.0, 24.0, 23.0, 132.0, 142.0, 2.0, 0.0, 40.0, 51.0, 121.0, 92.0, 0.0, 5.0, 83.0, 107.0, 26.0, 0.0, 9.0, 6.0, 0.0, 0.0, 18.0, 59.0, 51.0, 53.0, 88.0, 4.0, 35.0, 15.0, 19.0, 33.0, 9.0, 2.0, 59.0, 74.0, 0.0, 0.0, 4.0, 23.0, 35.0, 53.0, 14.0, 31.0, 23.0, 21.0, 63.0, 58.0, 0.0, 51.0, 25.0, 15.0, 32.0, 3.0, 0.0, 0.0, 87.0, 54.0, 8.0, 0.0, 20.0, 12.0, 9.0, 0.0, 23.0, 14.0, 21.0, 30.0, 34.0, 12.0, 39.0, 59.0, 0.0, 0.0, 10.0, 10.0, 10.0, 18.0, 16.0, 8.0, 0.0, 140.0, 37.0, 18.0, 4.0, 44.0, 0.0, 0.0, 29.0, 34.0, 0.0, 25.0, 0.0, 3.0, 42.0, 39.0, 105.0, 51.0, 51.0, 24.0, 16.0, 9.0, 63.0, 53.0, 26.0, 64.0, 4.0, 7.0, 26.0, 26.0, 40.0, 39.0, 0.0, 0.0, 15.0, 42.0, 32.0, 11.0, 29.0, 10.0, 8.0, 2.0, 0.0, 22.0, 3.0, 0.0, 33.0, 26.0, 40.0, 8.0, 24.0, 28.0, 38.0, 31.0, 1.0, 0.0, 0.0, 20.0, 29.0, 3.0, 30.0, 25.0, 4.0, 10.0, 63.0, 62.0, 0.0, 42.0, 15.0, 6.0, 11.0, 23.0, 38.0, 51.0, 71.0, 20.0, 10.0, 15.0, 0.0, 10.0, 0.0, 18.0, 27.0, 26.0, 25.0, 27.0, 29.0, 19.0, 20.0, 0.0, 16.0, 15.0, 0.0, 12.0, 36.0, 31.0, 13.0, 3.0, 24.0, 15.0, 28.0, 33.0, 17.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0980065172688136, "mean_inference_ms": 2.6768535542597953, "mean_action_processing_ms": 0.4310436973487613, "mean_env_wait_ms": 0.339418353804292, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00973057746887207, "StateBufferConnector_ms": 0.006034374237060547, "ViewRequirementAgentConnector_ms": 0.16222214698791504}, "num_episodes": 18, "episode_return_max": 381.4, "episode_return_min": -114.00000000000081, "episode_return_mean": 184.48199999999986, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1344000, "num_agent_steps_trained": 1344000, "num_env_steps_sampled": 336000, "num_env_steps_trained": 336000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 71.9779299811127, "num_env_steps_trained_throughput_per_sec": 71.9779299811127, "timesteps_total": 336000, "num_env_steps_sampled_lifetime": 336000, "num_agent_steps_sampled_lifetime": 1344000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1344000, "timers": {"training_iteration_time_ms": 63466.954, "restore_workers_time_ms": 0.043, "training_step_time_ms": 63466.873, "sample_time_ms": 2070.264, "learn_time_ms": 61373.032, "learn_throughput": 65.175, "synch_weights_time_ms": 19.716}, "counters": {"num_env_steps_sampled": 336000, "num_env_steps_trained": 336000, "num_agent_steps_sampled": 1344000, "num_agent_steps_trained": 1344000}, "done": false, "training_iteration": 84, "trial_id": "11e70_00000", "date": "2024-08-13_00-31-24", "timestamp": 1723523484, "time_this_iter_s": 55.66907095909119, "time_total_s": 5061.085941076279, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b4a5c790>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 5061.085941076279, "iterations_since_restore": 84, "perf": {"cpu_util_percent": 52.11139240506329, "ram_util_percent": 79.33037974683543}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 10.52857909189961, "cur_kl_coeff": 0.22500000000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.4009731480053493, "policy_loss": -0.006592053986676826, "vf_loss": 2.4062390302854872, "vf_explained_var": 0.18821133766224776, "kl": 0.00589414893819383, "entropy": 0.8387044858049464, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 159705.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 17.015826585179283, "cur_kl_coeff": 0.16875, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.782198448408217, "policy_loss": -0.011435845424236346, "vf_loss": 4.791744330572704, "vf_explained_var": 0.7317011413435457, "kl": 0.011199794197252082, "entropy": 0.974134089864751, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 159705.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 340000, "num_env_steps_trained": 340000, "num_agent_steps_sampled": 1360000, "num_agent_steps_trained": 1360000}, "env_runners": {"episode_reward_max": 374.0, "episode_reward_min": -114.00000000000081, "episode_reward_mean": 190.09299999999985, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -274.00000000000017, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 140.0}, "policy_reward_mean": {"prey_policy": 72.3815, "predator_policy": 22.665}, "custom_metrics": {}, "hist_stats": {"episode_reward": [109.19999999999985, 341.0, 200.0999999999993, 87.80000000000007, 40.0000000000003, 168.99999999999946, 242.0, 147.3999999999995, 267.30000000000007, 106.69999999999989, 267.7, 283.4, 155.99999999999957, 40.0000000000003, 152.2, 31.200000000000166, 217.79999999999967, 30.100000000000147, 157.99999999999943, 136.8999999999997, 309.2, 195.0, 40.0000000000003, 179.99999999999937, 127.70000000000016, 195.99999999999937, -114.00000000000081, 293.0, 247.0, 40.0000000000003, 274.9, 12.50000000000003, 235.5999999999996, 154.9, 2.5000000000000573, 206.8, 175.99999999999952, 124.5, 199.9, 197.99999999999937, 139.3999999999996, 284.9, 40.0000000000003, 270.4, 148.0999999999996, 149.7999999999996, 374.0, 318.2, 199.59999999999937, 300.6, 193.29999999999987, 169.39999999999952, 307.0, 113.59999999999985, 281.70000000000005, 154.19999999999965, 286.4, 226.19999999999962, 216.6, 50.50000000000011, 343.6, 151.99999999999963, 175.2, 219.2, 172.99999999999946, 199.99999999999935, 308.2, 304.2, 251.90000000000006, 158.49999999999957, 281.7, 124.6999999999997, 195.99999999999926, 143.89999999999964, 190.99999999999932, 109.29999999999976, 251.89999999999998, 352.5, 163.99999999999955, 119.09999999999977, 228.3, 190.70000000000005, 292.1, 139.99999999999972, 368.0, 152.5999999999996, 207.60000000000002, 195.4999999999994, 179.99999999999946, 160.4000000000001, 257.5, 208.90000000000003, 219.99999999999926, 207.09999999999948, 271.1, 40.0000000000003, 159.3, 356.0, 144.99999999999966, 302.1], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-53.500000000000135, 112.7, 128.0, 161.0, 169.1, 20.000000000000014, -43.00000000000003, -2.200000000000003, 20.000000000000014, 20.000000000000014, 122.0, 20.000000000000014, 104.0, 50.0, 20.000000000000014, 82.4, 71.30000000000001, 152.0, -34.3, 20.000000000000014, 70.7, 146.0, 116.0, 127.4, 101.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, -20.799999999999997, 32.0, 3.1999999999999615, 20.000000000000014, 136.1, 49.69999999999996, 1.0999999999999865, 20.000000000000014, 101.0, 20.000000000000014, -24.09999999999979, 110.0, 158.0, 105.2, 84.8, 12.200000000000003, 20.000000000000014, 20.000000000000014, 140.0, 20.000000000000014, 53.900000000000134, 45.800000000000054, 20.000000000000014, 152.0, -274.00000000000017, 20.000000000000014, 119.0, 119.0, 95.0, 104.0, 20.000000000000014, 20.000000000000014, 110.0, 101.9, 20.000000000000014, -32.49999999999975, 55.99999999999996, 176.6, 2.9000000000000057, 71.0, 47.0, -200.50000000000026, 33.8, 98.0, 20.000000000000014, 131.0, 44.0, -35.5, 137.0, -27.099999999999994, 167.0, 20.000000000000014, 122.0, -34.59999999999975, 122.0, 83.9, 20.000000000000014, 20.000000000000014, 114.5, 98.89999999999999, 85.1, 20.000000000000014, 90.8, 20.000000000000014, 176.0, 188.0, 157.1, 139.1, 20.000000000000014, 176.6, 98.6, 143.0, 11.300000000000175, 134.0, 20.900000000000013, 96.5, 80.0, 158.0, 92.59999999999997, 20.000000000000014, 160.7, 100.99999999999999, 20.000000000000014, 102.2, 130.4, 101.0, 158.0, 54.19999999999996, -16.0, 107.6, -11.500000000000028, 20.000000000000014, 158.0, 164.6, 20.000000000000014, 98.0, 73.69999999999999, 12.499999999999993, 155.0, -26.799999999999997, 128.0, 20.000000000000014, 20.000000000000014, 170.0, 139.7, 150.5, 111.8, 139.4, 101.0, 98.89999999999998, 9.499999999999964, 101.0, 173.0, 88.69999999999999, 105.19999999999999, -11.499999999999819, 164.0, 20.000000000000014, 80.0, -3.099999999999958, 155.0, 20.000000000000014, 13.699999999999964, 56.599999999999994, 98.0, 92.89999999999999, 171.5, 164.0, 116.0, 20.000000000000014, 85.10000000000008, 20.000000000000014, 39.8, 126.5, 35.599999999999994, 67.1, 92.0, 142.1, 20.000000000000014, 74.0, 158.0, 185.0, -9.399999999999855, 122.0, 50.0, 98.6, 20.000000000000014, 165.5, 20.000000000000014, 140.0, 61.39999999999998, 5.0, 117.5, 77.0, -24.10000000000001, 164.0, 200.0, 20.000000000000014, 37.09999999999999, 155.0, 135.2, 95.9, 20.000000000000014, 20.000000000000014, 39.5, 36.8, 155.0, 164.0, 86.0, 20.000000000000014, 118.1, 146.0], "policy_predator_policy_reward": [35.0, 15.0, 19.0, 33.0, 9.0, 2.0, 59.0, 74.0, 0.0, 0.0, 4.0, 23.0, 35.0, 53.0, 14.0, 31.0, 23.0, 21.0, 63.0, 58.0, 0.0, 51.0, 25.0, 15.0, 32.0, 3.0, 0.0, 0.0, 87.0, 54.0, 8.0, 0.0, 20.0, 12.0, 9.0, 0.0, 23.0, 14.0, 21.0, 30.0, 34.0, 12.0, 39.0, 59.0, 0.0, 0.0, 10.0, 10.0, 10.0, 18.0, 16.0, 8.0, 0.0, 140.0, 37.0, 18.0, 4.0, 44.0, 0.0, 0.0, 29.0, 34.0, 0.0, 25.0, 0.0, 3.0, 42.0, 39.0, 105.0, 51.0, 51.0, 24.0, 16.0, 9.0, 63.0, 53.0, 26.0, 64.0, 4.0, 7.0, 26.0, 26.0, 40.0, 39.0, 0.0, 0.0, 15.0, 42.0, 32.0, 11.0, 29.0, 10.0, 8.0, 2.0, 0.0, 22.0, 3.0, 0.0, 33.0, 26.0, 40.0, 8.0, 24.0, 28.0, 38.0, 31.0, 1.0, 0.0, 0.0, 20.0, 29.0, 3.0, 30.0, 25.0, 4.0, 10.0, 63.0, 62.0, 0.0, 42.0, 15.0, 6.0, 11.0, 23.0, 38.0, 51.0, 71.0, 20.0, 10.0, 15.0, 0.0, 10.0, 0.0, 18.0, 27.0, 26.0, 25.0, 27.0, 29.0, 19.0, 20.0, 0.0, 16.0, 15.0, 0.0, 12.0, 36.0, 31.0, 13.0, 3.0, 24.0, 15.0, 28.0, 33.0, 17.0, 0.0, 2.0, 26.0, 2.0, 12.0, 3.0, 59.0, 30.0, 58.0, 41.0, 17.0, 23.0, 23.0, 10.0, 15.0, 40.0, 0.0, 36.0, 23.0, 10.0, 0.0, 20.0, 0.0, 32.0, 62.0, 32.0, 31.0, 0.0, 69.0, 0.0, 0.0, 2.0, 13.0, 40.0, 0.0, 0.0, 0.0, 53.0, 30.0, 16.0, 21.0, 37.0, 2.0, 21.0, 17.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0969745547384473, "mean_inference_ms": 2.6720058364003525, "mean_action_processing_ms": 0.43064973234983583, "mean_env_wait_ms": 0.33901871647839754, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.009775161743164062, "StateBufferConnector_ms": 0.006158113479614258, "ViewRequirementAgentConnector_ms": 0.16802799701690674}, "num_episodes": 22, "episode_return_max": 374.0, "episode_return_min": -114.00000000000081, "episode_return_mean": 190.09299999999985, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1360000, "num_agent_steps_trained": 1360000, "num_env_steps_sampled": 340000, "num_env_steps_trained": 340000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 67.3117091818537, "num_env_steps_trained_throughput_per_sec": 67.3117091818537, "timesteps_total": 340000, "num_env_steps_sampled_lifetime": 340000, "num_agent_steps_sampled_lifetime": 1360000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1360000, "timers": {"training_iteration_time_ms": 61672.775, "restore_workers_time_ms": 0.017, "training_step_time_ms": 61672.727, "sample_time_ms": 1861.988, "learn_time_ms": 59787.178, "learn_throughput": 66.904, "synch_weights_time_ms": 19.787}, "counters": {"num_env_steps_sampled": 340000, "num_env_steps_trained": 340000, "num_agent_steps_sampled": 1360000, "num_agent_steps_trained": 1360000}, "done": false, "training_iteration": 85, "trial_id": "11e70_00000", "date": "2024-08-13_00-32-24", "timestamp": 1723523544, "time_this_iter_s": 59.51838707923889, "time_total_s": 5120.604328155518, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b4a5c670>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 5120.604328155518, "iterations_since_restore": 85, "perf": {"cpu_util_percent": 60.48352941176471, "ram_util_percent": 78.71058823529414}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 10.468536453398448, "cur_kl_coeff": 0.22500000000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.635308030421141, "policy_loss": -0.010748260306864583, "vf_loss": 3.6440814276851676, "vf_explained_var": 0.2118053761424211, "kl": 0.008777131198264409, "entropy": 0.91711504730598, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 161595.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 14.289582317783719, "cur_kl_coeff": 0.16875, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.861260606624462, "policy_loss": -0.012259758383814226, "vf_loss": 5.872091120260733, "vf_explained_var": 0.47618220505260284, "kl": 0.00846947705890532, "entropy": 0.954968388149978, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 161595.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 344000, "num_env_steps_trained": 344000, "num_agent_steps_sampled": 1376000, "num_agent_steps_trained": 1376000}, "env_runners": {"episode_reward_max": 399.1, "episode_reward_min": -114.00000000000081, "episode_reward_mean": 196.09999999999982, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -274.00000000000017, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 141.0}, "policy_reward_mean": {"prey_policy": 76.14500000000001, "predator_policy": 21.905}, "custom_metrics": {}, "hist_stats": {"episode_reward": [157.99999999999943, 136.8999999999997, 309.2, 195.0, 40.0000000000003, 179.99999999999937, 127.70000000000016, 195.99999999999937, -114.00000000000081, 293.0, 247.0, 40.0000000000003, 274.9, 12.50000000000003, 235.5999999999996, 154.9, 2.5000000000000573, 206.8, 175.99999999999952, 124.5, 199.9, 197.99999999999937, 139.3999999999996, 284.9, 40.0000000000003, 270.4, 148.0999999999996, 149.7999999999996, 374.0, 318.2, 199.59999999999937, 300.6, 193.29999999999987, 169.39999999999952, 307.0, 113.59999999999985, 281.70000000000005, 154.19999999999965, 286.4, 226.19999999999962, 216.6, 50.50000000000011, 343.6, 151.99999999999963, 175.2, 219.2, 172.99999999999946, 199.99999999999935, 308.2, 304.2, 251.90000000000006, 158.49999999999957, 281.7, 124.6999999999997, 195.99999999999926, 143.89999999999964, 190.99999999999932, 109.29999999999976, 251.89999999999998, 352.5, 163.99999999999955, 119.09999999999977, 228.3, 190.70000000000005, 292.1, 139.99999999999972, 368.0, 152.5999999999996, 207.60000000000002, 195.4999999999994, 179.99999999999946, 160.4000000000001, 257.5, 208.90000000000003, 219.99999999999926, 207.09999999999948, 271.1, 40.0000000000003, 159.3, 356.0, 144.99999999999966, 302.1, 165.59999999999954, 225.40000000000003, 214.99999999999977, 286.0, 187.09999999999945, 250.6, 267.4, 144.09999999999957, 40.0000000000003, 243.1, 269.49999999999966, 40.0000000000003, 282.3, 229.4000000000001, 214.2, 399.1, 40.0000000000003, -9.200000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [101.0, 20.000000000000014, -24.09999999999979, 110.0, 158.0, 105.2, 84.8, 12.200000000000003, 20.000000000000014, 20.000000000000014, 140.0, 20.000000000000014, 53.900000000000134, 45.800000000000054, 20.000000000000014, 152.0, -274.00000000000017, 20.000000000000014, 119.0, 119.0, 95.0, 104.0, 20.000000000000014, 20.000000000000014, 110.0, 101.9, 20.000000000000014, -32.49999999999975, 55.99999999999996, 176.6, 2.9000000000000057, 71.0, 47.0, -200.50000000000026, 33.8, 98.0, 20.000000000000014, 131.0, 44.0, -35.5, 137.0, -27.099999999999994, 167.0, 20.000000000000014, 122.0, -34.59999999999975, 122.0, 83.9, 20.000000000000014, 20.000000000000014, 114.5, 98.89999999999999, 85.1, 20.000000000000014, 90.8, 20.000000000000014, 176.0, 188.0, 157.1, 139.1, 20.000000000000014, 176.6, 98.6, 143.0, 11.300000000000175, 134.0, 20.900000000000013, 96.5, 80.0, 158.0, 92.59999999999997, 20.000000000000014, 160.7, 100.99999999999999, 20.000000000000014, 102.2, 130.4, 101.0, 158.0, 54.19999999999996, -16.0, 107.6, -11.500000000000028, 20.000000000000014, 158.0, 164.6, 20.000000000000014, 98.0, 73.69999999999999, 12.499999999999993, 155.0, -26.799999999999997, 128.0, 20.000000000000014, 20.000000000000014, 170.0, 139.7, 150.5, 111.8, 139.4, 101.0, 98.89999999999998, 9.499999999999964, 101.0, 173.0, 88.69999999999999, 105.19999999999999, -11.499999999999819, 164.0, 20.000000000000014, 80.0, -3.099999999999958, 155.0, 20.000000000000014, 13.699999999999964, 56.599999999999994, 98.0, 92.89999999999999, 171.5, 164.0, 116.0, 20.000000000000014, 85.10000000000008, 20.000000000000014, 39.8, 126.5, 35.599999999999994, 67.1, 92.0, 142.1, 20.000000000000014, 74.0, 158.0, 185.0, -9.399999999999855, 122.0, 50.0, 98.6, 20.000000000000014, 165.5, 20.000000000000014, 140.0, 61.39999999999998, 5.0, 117.5, 77.0, -24.10000000000001, 164.0, 200.0, 20.000000000000014, 37.09999999999999, 155.0, 135.2, 95.9, 20.000000000000014, 20.000000000000014, 39.5, 36.8, 155.0, 164.0, 86.0, 20.000000000000014, 118.1, 146.0, 125.0, 11.599999999999964, 100.4, 74.0, 138.8, 51.19999999999997, 150.2, 96.8, 20.000000000000014, 151.1, 68.6, 113.0, 79.4, 137.0, 20.000000000000014, 82.1, 20.000000000000014, 20.000000000000014, -10.899999999999999, 182.0, 76.69999999999996, 192.8, 20.000000000000014, 20.000000000000014, 122.3, 119.0, 108.8, 95.59999999999997, 79.1, 43.099999999999994, 199.1, 200.0, 20.000000000000014, 20.000000000000014, -22.0, -170.20000000000002], "policy_predator_policy_reward": [23.0, 14.0, 21.0, 30.0, 34.0, 12.0, 39.0, 59.0, 0.0, 0.0, 10.0, 10.0, 10.0, 18.0, 16.0, 8.0, 0.0, 140.0, 37.0, 18.0, 4.0, 44.0, 0.0, 0.0, 29.0, 34.0, 0.0, 25.0, 0.0, 3.0, 42.0, 39.0, 105.0, 51.0, 51.0, 24.0, 16.0, 9.0, 63.0, 53.0, 26.0, 64.0, 4.0, 7.0, 26.0, 26.0, 40.0, 39.0, 0.0, 0.0, 15.0, 42.0, 32.0, 11.0, 29.0, 10.0, 8.0, 2.0, 0.0, 22.0, 3.0, 0.0, 33.0, 26.0, 40.0, 8.0, 24.0, 28.0, 38.0, 31.0, 1.0, 0.0, 0.0, 20.0, 29.0, 3.0, 30.0, 25.0, 4.0, 10.0, 63.0, 62.0, 0.0, 42.0, 15.0, 6.0, 11.0, 23.0, 38.0, 51.0, 71.0, 20.0, 10.0, 15.0, 0.0, 10.0, 0.0, 18.0, 27.0, 26.0, 25.0, 27.0, 29.0, 19.0, 20.0, 0.0, 16.0, 15.0, 0.0, 12.0, 36.0, 31.0, 13.0, 3.0, 24.0, 15.0, 28.0, 33.0, 17.0, 0.0, 2.0, 26.0, 2.0, 12.0, 3.0, 59.0, 30.0, 58.0, 41.0, 17.0, 23.0, 23.0, 10.0, 15.0, 40.0, 0.0, 36.0, 23.0, 10.0, 0.0, 20.0, 0.0, 32.0, 62.0, 32.0, 31.0, 0.0, 69.0, 0.0, 0.0, 2.0, 13.0, 40.0, 0.0, 0.0, 0.0, 53.0, 30.0, 16.0, 21.0, 37.0, 2.0, 21.0, 17.0, 4.0, 25.0, 40.0, 11.0, 0.0, 25.0, 0.0, 39.0, 0.0, 16.0, 42.0, 27.0, 51.0, 0.0, 29.0, 13.0, 0.0, 0.0, 40.0, 32.0, 0.0, 0.0, 0.0, 0.0, 20.0, 21.0, 0.0, 25.0, 42.0, 50.0, 0.0, 0.0, 0.0, 0.0, 42.0, 141.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0962433948767725, "mean_inference_ms": 2.6689026355045558, "mean_action_processing_ms": 0.43047562902580155, "mean_env_wait_ms": 0.33873932485130814, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007729172706604004, "StateBufferConnector_ms": 0.004491209983825684, "ViewRequirementAgentConnector_ms": 0.1631394624710083}, "num_episodes": 18, "episode_return_max": 399.1, "episode_return_min": -114.00000000000081, "episode_return_mean": 196.09999999999982, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1376000, "num_agent_steps_trained": 1376000, "num_env_steps_sampled": 344000, "num_env_steps_trained": 344000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 70.96111350591741, "num_env_steps_trained_throughput_per_sec": 70.96111350591741, "timesteps_total": 344000, "num_env_steps_sampled_lifetime": 344000, "num_agent_steps_sampled_lifetime": 1376000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1376000, "timers": {"training_iteration_time_ms": 61057.027, "restore_workers_time_ms": 0.017, "training_step_time_ms": 61056.979, "sample_time_ms": 1883.93, "learn_time_ms": 59149.73, "learn_throughput": 67.625, "synch_weights_time_ms": 19.536}, "counters": {"num_env_steps_sampled": 344000, "num_env_steps_trained": 344000, "num_agent_steps_sampled": 1376000, "num_agent_steps_trained": 1376000}, "done": false, "training_iteration": 86, "trial_id": "11e70_00000", "date": "2024-08-13_00-33-20", "timestamp": 1723523600, "time_this_iter_s": 56.413820028305054, "time_total_s": 5177.018148183823, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2b67d30>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 5177.018148183823, "iterations_since_restore": 86, "perf": {"cpu_util_percent": 52.9825, "ram_util_percent": 77.66875}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 9.533947286656295, "cur_kl_coeff": 0.22500000000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.6354488761336716, "policy_loss": -0.00899738676072389, "vf_loss": 3.6429060085740668, "vf_explained_var": 0.16819730464112823, "kl": 0.006845634421176602, "entropy": 0.8122019479199062, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 163485.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 11.526245370743768, "cur_kl_coeff": 0.16875, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.527433850273254, "policy_loss": -0.00883830136449505, "vf_loss": 5.535254723685128, "vf_explained_var": 0.22925260445428272, "kl": 0.006029235175623848, "entropy": 0.908805841901315, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 163485.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 348000, "num_env_steps_trained": 348000, "num_agent_steps_sampled": 1392000, "num_agent_steps_trained": 1392000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -106.50000000000142, "episode_reward_mean": 191.49599999999987, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -170.20000000000002, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 141.0}, "policy_reward_mean": {"prey_policy": 73.343, "predator_policy": 22.405}, "custom_metrics": {}, "hist_stats": {"episode_reward": [284.9, 40.0000000000003, 270.4, 148.0999999999996, 149.7999999999996, 374.0, 318.2, 199.59999999999937, 300.6, 193.29999999999987, 169.39999999999952, 307.0, 113.59999999999985, 281.70000000000005, 154.19999999999965, 286.4, 226.19999999999962, 216.6, 50.50000000000011, 343.6, 151.99999999999963, 175.2, 219.2, 172.99999999999946, 199.99999999999935, 308.2, 304.2, 251.90000000000006, 158.49999999999957, 281.7, 124.6999999999997, 195.99999999999926, 143.89999999999964, 190.99999999999932, 109.29999999999976, 251.89999999999998, 352.5, 163.99999999999955, 119.09999999999977, 228.3, 190.70000000000005, 292.1, 139.99999999999972, 368.0, 152.5999999999996, 207.60000000000002, 195.4999999999994, 179.99999999999946, 160.4000000000001, 257.5, 208.90000000000003, 219.99999999999926, 207.09999999999948, 271.1, 40.0000000000003, 159.3, 356.0, 144.99999999999966, 302.1, 165.59999999999954, 225.40000000000003, 214.99999999999977, 286.0, 187.09999999999945, 250.6, 267.4, 144.09999999999957, 40.0000000000003, 243.1, 269.49999999999966, 40.0000000000003, 282.3, 229.4000000000001, 214.2, 399.1, 40.0000000000003, -9.200000000000003, 69.50000000000006, 210.1, -106.50000000000142, 81.09999999999977, 40.0000000000003, 193.30000000000004, 33.00000000000003, 182.99999999999943, 400.0, 223.0, 99.0, 85.1, 355.00000000000006, 109.79999999999978, 190.3, 122.79999999999973, 162.3999999999995, 187.2, 10.300000000000104, 40.0000000000003, 157.29999999999956, 165.6999999999995, 62.0], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [122.0, 83.9, 20.000000000000014, 20.000000000000014, 114.5, 98.89999999999999, 85.1, 20.000000000000014, 90.8, 20.000000000000014, 176.0, 188.0, 157.1, 139.1, 20.000000000000014, 176.6, 98.6, 143.0, 11.300000000000175, 134.0, 20.900000000000013, 96.5, 80.0, 158.0, 92.59999999999997, 20.000000000000014, 160.7, 100.99999999999999, 20.000000000000014, 102.2, 130.4, 101.0, 158.0, 54.19999999999996, -16.0, 107.6, -11.500000000000028, 20.000000000000014, 158.0, 164.6, 20.000000000000014, 98.0, 73.69999999999999, 12.499999999999993, 155.0, -26.799999999999997, 128.0, 20.000000000000014, 20.000000000000014, 170.0, 139.7, 150.5, 111.8, 139.4, 101.0, 98.89999999999998, 9.499999999999964, 101.0, 173.0, 88.69999999999999, 105.19999999999999, -11.499999999999819, 164.0, 20.000000000000014, 80.0, -3.099999999999958, 155.0, 20.000000000000014, 13.699999999999964, 56.599999999999994, 98.0, 92.89999999999999, 171.5, 164.0, 116.0, 20.000000000000014, 85.10000000000008, 20.000000000000014, 39.8, 126.5, 35.599999999999994, 67.1, 92.0, 142.1, 20.000000000000014, 74.0, 158.0, 185.0, -9.399999999999855, 122.0, 50.0, 98.6, 20.000000000000014, 165.5, 20.000000000000014, 140.0, 61.39999999999998, 5.0, 117.5, 77.0, -24.10000000000001, 164.0, 200.0, 20.000000000000014, 37.09999999999999, 155.0, 135.2, 95.9, 20.000000000000014, 20.000000000000014, 39.5, 36.8, 155.0, 164.0, 86.0, 20.000000000000014, 118.1, 146.0, 125.0, 11.599999999999964, 100.4, 74.0, 138.8, 51.19999999999997, 150.2, 96.8, 20.000000000000014, 151.1, 68.6, 113.0, 79.4, 137.0, 20.000000000000014, 82.1, 20.000000000000014, 20.000000000000014, -10.899999999999999, 182.0, 76.69999999999996, 192.8, 20.000000000000014, 20.000000000000014, 122.3, 119.0, 108.8, 95.59999999999997, 79.1, 43.099999999999994, 199.1, 200.0, 20.000000000000014, 20.000000000000014, -22.0, -170.20000000000002, 20.000000000000014, -23.5, 74.0, 58.1, -45.099999999999824, -135.40000000000072, 14.0, -13.90000000000003, 20.000000000000014, 20.000000000000014, 38.599999999999994, 97.69999999999999, 20.000000000000014, -85.0, 137.0, 20.000000000000014, 200.0, 200.0, 68.0, 53.0, 17.0, -22.0, 32.0, -52.900000000000006, 155.0, 200.0, 20.000000000000014, 78.79999999999998, 41.0, 74.3, 74.00000000000006, 15.799999999999963, 115.4, 20.000000000000014, -31.0, 105.2, -44.499999999999794, -68.2, 20.000000000000014, 20.000000000000014, -5.199999999999934, 132.5, 20.000000000000014, 121.7, -106.6, 59.599999999999994], "policy_predator_policy_reward": [40.0, 39.0, 0.0, 0.0, 15.0, 42.0, 32.0, 11.0, 29.0, 10.0, 8.0, 2.0, 0.0, 22.0, 3.0, 0.0, 33.0, 26.0, 40.0, 8.0, 24.0, 28.0, 38.0, 31.0, 1.0, 0.0, 0.0, 20.0, 29.0, 3.0, 30.0, 25.0, 4.0, 10.0, 63.0, 62.0, 0.0, 42.0, 15.0, 6.0, 11.0, 23.0, 38.0, 51.0, 71.0, 20.0, 10.0, 15.0, 0.0, 10.0, 0.0, 18.0, 27.0, 26.0, 25.0, 27.0, 29.0, 19.0, 20.0, 0.0, 16.0, 15.0, 0.0, 12.0, 36.0, 31.0, 13.0, 3.0, 24.0, 15.0, 28.0, 33.0, 17.0, 0.0, 2.0, 26.0, 2.0, 12.0, 3.0, 59.0, 30.0, 58.0, 41.0, 17.0, 23.0, 23.0, 10.0, 15.0, 40.0, 0.0, 36.0, 23.0, 10.0, 0.0, 20.0, 0.0, 32.0, 62.0, 32.0, 31.0, 0.0, 69.0, 0.0, 0.0, 2.0, 13.0, 40.0, 0.0, 0.0, 0.0, 53.0, 30.0, 16.0, 21.0, 37.0, 2.0, 21.0, 17.0, 4.0, 25.0, 40.0, 11.0, 0.0, 25.0, 0.0, 39.0, 0.0, 16.0, 42.0, 27.0, 51.0, 0.0, 29.0, 13.0, 0.0, 0.0, 40.0, 32.0, 0.0, 0.0, 0.0, 0.0, 20.0, 21.0, 0.0, 25.0, 42.0, 50.0, 0.0, 0.0, 0.0, 0.0, 42.0, 141.0, 62.0, 11.0, 6.0, 72.0, 74.0, 0.0, 76.0, 5.0, 0.0, 0.0, 57.0, 0.0, 5.0, 93.0, 16.0, 10.0, 0.0, 0.0, 38.0, 64.0, 72.0, 32.0, 73.0, 33.0, 0.0, 0.0, 11.0, 0.0, 37.0, 38.0, 25.0, 8.0, 18.0, 9.0, 46.0, 67.0, 58.0, 65.0, 0.0, 0.0, 0.0, 30.0, 24.0, 0.0, 59.0, 50.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0938748512056198, "mean_inference_ms": 2.6634266506900337, "mean_action_processing_ms": 0.4299042874481281, "mean_env_wait_ms": 0.338101575780381, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.015428423881530762, "StateBufferConnector_ms": 0.00409245491027832, "ViewRequirementAgentConnector_ms": 0.18442392349243164}, "num_episodes": 23, "episode_return_max": 400.0, "episode_return_min": -106.50000000000142, "episode_return_mean": 191.49599999999987, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1392000, "num_agent_steps_trained": 1392000, "num_env_steps_sampled": 348000, "num_env_steps_trained": 348000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 68.28851421190765, "num_env_steps_trained_throughput_per_sec": 68.28851421190765, "timesteps_total": 348000, "num_env_steps_sampled_lifetime": 348000, "num_agent_steps_sampled_lifetime": 1392000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1392000, "timers": {"training_iteration_time_ms": 60675.644, "restore_workers_time_ms": 0.017, "training_step_time_ms": 60675.597, "sample_time_ms": 1902.164, "learn_time_ms": 58746.739, "learn_throughput": 68.089, "synch_weights_time_ms": 20.481}, "counters": {"num_env_steps_sampled": 348000, "num_env_steps_trained": 348000, "num_agent_steps_sampled": 1392000, "num_agent_steps_trained": 1392000}, "done": false, "training_iteration": 87, "trial_id": "11e70_00000", "date": "2024-08-13_00-34-19", "timestamp": 1723523659, "time_this_iter_s": 58.7157301902771, "time_total_s": 5235.7338783741, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3f560d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 5235.7338783741, "iterations_since_restore": 87, "perf": {"cpu_util_percent": 55.51927710843374, "ram_util_percent": 81.39638554216867}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 10.41647066994319, "cur_kl_coeff": 0.22500000000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.1748929021219725, "policy_loss": -0.009357000156872408, "vf_loss": 6.182614630239981, "vf_explained_var": 0.16134728984857993, "kl": 0.00726774434914949, "entropy": 0.8354067943083546, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 165375.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 9.771747239304599, "cur_kl_coeff": 0.16875, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.223477591156329, "policy_loss": -0.011884790842997886, "vf_loss": 7.234084655368139, "vf_explained_var": -0.10310483171195581, "kl": 0.0075716174783865995, "entropy": 0.9155890772582362, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 165375.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 352000, "num_env_steps_trained": 352000, "num_agent_steps_sampled": 1408000, "num_agent_steps_trained": 1408000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -141.4, "episode_reward_mean": 165.18799999999985, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -240.70000000000005, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 141.0}, "policy_reward_mean": {"prey_policy": 54.659, "predator_policy": 27.935}, "custom_metrics": {}, "hist_stats": {"episode_reward": [50.50000000000011, 343.6, 151.99999999999963, 175.2, 219.2, 172.99999999999946, 199.99999999999935, 308.2, 304.2, 251.90000000000006, 158.49999999999957, 281.7, 124.6999999999997, 195.99999999999926, 143.89999999999964, 190.99999999999932, 109.29999999999976, 251.89999999999998, 352.5, 163.99999999999955, 119.09999999999977, 228.3, 190.70000000000005, 292.1, 139.99999999999972, 368.0, 152.5999999999996, 207.60000000000002, 195.4999999999994, 179.99999999999946, 160.4000000000001, 257.5, 208.90000000000003, 219.99999999999926, 207.09999999999948, 271.1, 40.0000000000003, 159.3, 356.0, 144.99999999999966, 302.1, 165.59999999999954, 225.40000000000003, 214.99999999999977, 286.0, 187.09999999999945, 250.6, 267.4, 144.09999999999957, 40.0000000000003, 243.1, 269.49999999999966, 40.0000000000003, 282.3, 229.4000000000001, 214.2, 399.1, 40.0000000000003, -9.200000000000003, 69.50000000000006, 210.1, -106.50000000000142, 81.09999999999977, 40.0000000000003, 193.30000000000004, 33.00000000000003, 182.99999999999943, 400.0, 223.0, 99.0, 85.1, 355.00000000000006, 109.79999999999978, 190.3, 122.79999999999973, 162.3999999999995, 187.2, 10.300000000000104, 40.0000000000003, 157.29999999999956, 165.6999999999995, 62.0, 142.10000000000002, 183.99999999999926, 173.79999999999947, -141.4, 121.69999999999979, 212.90000000000003, 63.0, -12.5, 11.300000000000075, -40.099999999999994, 162.99999999999935, -41.0, 327.1, 322.0, -57.8, -41.8, 85.60000000000011, -68.69999999999996], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-11.500000000000028, 20.000000000000014, 158.0, 164.6, 20.000000000000014, 98.0, 73.69999999999999, 12.499999999999993, 155.0, -26.799999999999997, 128.0, 20.000000000000014, 20.000000000000014, 170.0, 139.7, 150.5, 111.8, 139.4, 101.0, 98.89999999999998, 9.499999999999964, 101.0, 173.0, 88.69999999999999, 105.19999999999999, -11.499999999999819, 164.0, 20.000000000000014, 80.0, -3.099999999999958, 155.0, 20.000000000000014, 13.699999999999964, 56.599999999999994, 98.0, 92.89999999999999, 171.5, 164.0, 116.0, 20.000000000000014, 85.10000000000008, 20.000000000000014, 39.8, 126.5, 35.599999999999994, 67.1, 92.0, 142.1, 20.000000000000014, 74.0, 158.0, 185.0, -9.399999999999855, 122.0, 50.0, 98.6, 20.000000000000014, 165.5, 20.000000000000014, 140.0, 61.39999999999998, 5.0, 117.5, 77.0, -24.10000000000001, 164.0, 200.0, 20.000000000000014, 37.09999999999999, 155.0, 135.2, 95.9, 20.000000000000014, 20.000000000000014, 39.5, 36.8, 155.0, 164.0, 86.0, 20.000000000000014, 118.1, 146.0, 125.0, 11.599999999999964, 100.4, 74.0, 138.8, 51.19999999999997, 150.2, 96.8, 20.000000000000014, 151.1, 68.6, 113.0, 79.4, 137.0, 20.000000000000014, 82.1, 20.000000000000014, 20.000000000000014, -10.899999999999999, 182.0, 76.69999999999996, 192.8, 20.000000000000014, 20.000000000000014, 122.3, 119.0, 108.8, 95.59999999999997, 79.1, 43.099999999999994, 199.1, 200.0, 20.000000000000014, 20.000000000000014, -22.0, -170.20000000000002, 20.000000000000014, -23.5, 74.0, 58.1, -45.099999999999824, -135.40000000000072, 14.0, -13.90000000000003, 20.000000000000014, 20.000000000000014, 38.599999999999994, 97.69999999999999, 20.000000000000014, -85.0, 137.0, 20.000000000000014, 200.0, 200.0, 68.0, 53.0, 17.0, -22.0, 32.0, -52.900000000000006, 155.0, 200.0, 20.000000000000014, 78.79999999999998, 41.0, 74.3, 74.00000000000006, 15.799999999999963, 115.4, 20.000000000000014, -31.0, 105.2, -44.499999999999794, -68.2, 20.000000000000014, 20.000000000000014, -5.199999999999934, 132.5, 20.000000000000014, 121.7, -106.6, 59.599999999999994, 62.0, 7.099999999999994, 146.0, 20.000000000000014, 20.000000000000014, 141.8, -131.2, -182.2, 52.099999999999994, 11.600000000000009, 152.0, 8.899999999999984, -10.0, -52.0, -91.0, -95.5, -123.70000000000005, 20.000000000000014, -4.600000000000001, -209.5, 107.0, 20.000000000000014, -85.0, -79.0, 139.1, 152.0, 110.0, 179.0, -56.8, -139.0, -95.80000000000001, -166.0, -65.80000000000001, 28.39999999999999, -240.70000000000005, 20.000000000000014], "policy_predator_policy_reward": [0.0, 42.0, 15.0, 6.0, 11.0, 23.0, 38.0, 51.0, 71.0, 20.0, 10.0, 15.0, 0.0, 10.0, 0.0, 18.0, 27.0, 26.0, 25.0, 27.0, 29.0, 19.0, 20.0, 0.0, 16.0, 15.0, 0.0, 12.0, 36.0, 31.0, 13.0, 3.0, 24.0, 15.0, 28.0, 33.0, 17.0, 0.0, 2.0, 26.0, 2.0, 12.0, 3.0, 59.0, 30.0, 58.0, 41.0, 17.0, 23.0, 23.0, 10.0, 15.0, 40.0, 0.0, 36.0, 23.0, 10.0, 0.0, 20.0, 0.0, 32.0, 62.0, 32.0, 31.0, 0.0, 69.0, 0.0, 0.0, 2.0, 13.0, 40.0, 0.0, 0.0, 0.0, 53.0, 30.0, 16.0, 21.0, 37.0, 2.0, 21.0, 17.0, 4.0, 25.0, 40.0, 11.0, 0.0, 25.0, 0.0, 39.0, 0.0, 16.0, 42.0, 27.0, 51.0, 0.0, 29.0, 13.0, 0.0, 0.0, 40.0, 32.0, 0.0, 0.0, 0.0, 0.0, 20.0, 21.0, 0.0, 25.0, 42.0, 50.0, 0.0, 0.0, 0.0, 0.0, 42.0, 141.0, 62.0, 11.0, 6.0, 72.0, 74.0, 0.0, 76.0, 5.0, 0.0, 0.0, 57.0, 0.0, 5.0, 93.0, 16.0, 10.0, 0.0, 0.0, 38.0, 64.0, 72.0, 32.0, 73.0, 33.0, 0.0, 0.0, 11.0, 0.0, 37.0, 38.0, 25.0, 8.0, 18.0, 9.0, 46.0, 67.0, 58.0, 65.0, 0.0, 0.0, 0.0, 30.0, 24.0, 0.0, 59.0, 50.0, 58.0, 15.0, 18.0, 0.0, 8.0, 4.0, 65.0, 107.0, 34.0, 24.0, 0.0, 52.0, 91.0, 34.0, 66.0, 108.0, 36.0, 79.0, 101.0, 73.0, 15.0, 21.0, 81.0, 42.0, 22.0, 14.0, 17.0, 16.0, 21.0, 117.0, 116.0, 104.0, 50.0, 73.0, 18.0, 134.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0930065228135073, "mean_inference_ms": 2.6633762769854017, "mean_action_processing_ms": 0.43031118096536486, "mean_env_wait_ms": 0.33813772936811565, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01584494113922119, "StateBufferConnector_ms": 0.004047751426696777, "ViewRequirementAgentConnector_ms": 0.1988922357559204}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -141.4, "episode_return_mean": 165.18799999999985, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1408000, "num_agent_steps_trained": 1408000, "num_env_steps_sampled": 352000, "num_env_steps_trained": 352000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 55.17724949310234, "num_env_steps_trained_throughput_per_sec": 55.17724949310234, "timesteps_total": 352000, "num_env_steps_sampled_lifetime": 352000, "num_agent_steps_sampled_lifetime": 1408000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1408000, "timers": {"training_iteration_time_ms": 61645.525, "restore_workers_time_ms": 0.018, "training_step_time_ms": 61645.477, "sample_time_ms": 2016.665, "learn_time_ms": 59601.996, "learn_throughput": 67.112, "synch_weights_time_ms": 20.445}, "counters": {"num_env_steps_sampled": 352000, "num_env_steps_trained": 352000, "num_agent_steps_sampled": 1408000, "num_agent_steps_trained": 1408000}, "done": false, "training_iteration": 88, "trial_id": "11e70_00000", "date": "2024-08-13_00-35-32", "timestamp": 1723523732, "time_this_iter_s": 72.55336308479309, "time_total_s": 5308.287241458893, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b4a76b80>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 5308.287241458893, "iterations_since_restore": 88, "perf": {"cpu_util_percent": 74.50873786407767, "ram_util_percent": 79.44466019417474}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 12.566024656018252, "cur_kl_coeff": 0.22500000000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.476704605294283, "policy_loss": -0.009220147173649695, "vf_loss": 5.483902341600448, "vf_explained_var": 0.10173279595753504, "kl": 0.008988524659479188, "entropy": 0.8832735225006386, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 167265.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 12.361234294359015, "cur_kl_coeff": 0.16875, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.965176428436602, "policy_loss": -0.008205404182373689, "vf_loss": 5.972232160870991, "vf_explained_var": 0.20914865038382313, "kl": 0.006812834785803177, "entropy": 0.8970199864692789, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 167265.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 356000, "num_env_steps_trained": 356000, "num_agent_steps_sampled": 1424000, "num_agent_steps_trained": 1424000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -175.89999999999998, "episode_reward_mean": 140.9039999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -395.8, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 198.0}, "policy_reward_mean": {"prey_policy": 37.217000000000006, "predator_policy": 33.235}, "custom_metrics": {}, "hist_stats": {"episode_reward": [190.70000000000005, 292.1, 139.99999999999972, 368.0, 152.5999999999996, 207.60000000000002, 195.4999999999994, 179.99999999999946, 160.4000000000001, 257.5, 208.90000000000003, 219.99999999999926, 207.09999999999948, 271.1, 40.0000000000003, 159.3, 356.0, 144.99999999999966, 302.1, 165.59999999999954, 225.40000000000003, 214.99999999999977, 286.0, 187.09999999999945, 250.6, 267.4, 144.09999999999957, 40.0000000000003, 243.1, 269.49999999999966, 40.0000000000003, 282.3, 229.4000000000001, 214.2, 399.1, 40.0000000000003, -9.200000000000003, 69.50000000000006, 210.1, -106.50000000000142, 81.09999999999977, 40.0000000000003, 193.30000000000004, 33.00000000000003, 182.99999999999943, 400.0, 223.0, 99.0, 85.1, 355.00000000000006, 109.79999999999978, 190.3, 122.79999999999973, 162.3999999999995, 187.2, 10.300000000000104, 40.0000000000003, 157.29999999999956, 165.6999999999995, 62.0, 142.10000000000002, 183.99999999999926, 173.79999999999947, -141.4, 121.69999999999979, 212.90000000000003, 63.0, -12.5, 11.300000000000075, -40.099999999999994, 162.99999999999935, -41.0, 327.1, 322.0, -57.8, -41.8, 85.60000000000011, -68.69999999999996, 134.2000000000001, 146.1, -175.89999999999998, 90.49999999999982, 256.9, 126.49999999999977, 264.0, 38.90000000000028, 2.200000000000003, -7.399999999999908, 3.0000000000000755, 45.99999999999967, 10.099999999999973, 93.39999999999986, -17.300000000000033, 109.29999999999967, 172.6, 23.00000000000007, 247.0, 300.2, 60.500000000000206, 146.50000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [35.599999999999994, 67.1, 92.0, 142.1, 20.000000000000014, 74.0, 158.0, 185.0, -9.399999999999855, 122.0, 50.0, 98.6, 20.000000000000014, 165.5, 20.000000000000014, 140.0, 61.39999999999998, 5.0, 117.5, 77.0, -24.10000000000001, 164.0, 200.0, 20.000000000000014, 37.09999999999999, 155.0, 135.2, 95.9, 20.000000000000014, 20.000000000000014, 39.5, 36.8, 155.0, 164.0, 86.0, 20.000000000000014, 118.1, 146.0, 125.0, 11.599999999999964, 100.4, 74.0, 138.8, 51.19999999999997, 150.2, 96.8, 20.000000000000014, 151.1, 68.6, 113.0, 79.4, 137.0, 20.000000000000014, 82.1, 20.000000000000014, 20.000000000000014, -10.899999999999999, 182.0, 76.69999999999996, 192.8, 20.000000000000014, 20.000000000000014, 122.3, 119.0, 108.8, 95.59999999999997, 79.1, 43.099999999999994, 199.1, 200.0, 20.000000000000014, 20.000000000000014, -22.0, -170.20000000000002, 20.000000000000014, -23.5, 74.0, 58.1, -45.099999999999824, -135.40000000000072, 14.0, -13.90000000000003, 20.000000000000014, 20.000000000000014, 38.599999999999994, 97.69999999999999, 20.000000000000014, -85.0, 137.0, 20.000000000000014, 200.0, 200.0, 68.0, 53.0, 17.0, -22.0, 32.0, -52.900000000000006, 155.0, 200.0, 20.000000000000014, 78.79999999999998, 41.0, 74.3, 74.00000000000006, 15.799999999999963, 115.4, 20.000000000000014, -31.0, 105.2, -44.499999999999794, -68.2, 20.000000000000014, 20.000000000000014, -5.199999999999934, 132.5, 20.000000000000014, 121.7, -106.6, 59.599999999999994, 62.0, 7.099999999999994, 146.0, 20.000000000000014, 20.000000000000014, 141.8, -131.2, -182.2, 52.099999999999994, 11.600000000000009, 152.0, 8.899999999999984, -10.0, -52.0, -91.0, -95.5, -123.70000000000005, 20.000000000000014, -4.600000000000001, -209.5, 107.0, 20.000000000000014, -85.0, -79.0, 139.1, 152.0, 110.0, 179.0, -56.8, -139.0, -95.80000000000001, -166.0, -65.80000000000001, 28.39999999999999, -240.70000000000005, 20.000000000000014, 91.99999999999997, -26.799999999999997, -0.10000000000000142, 72.2, -395.8, -54.099999999999994, 20.000000000000014, 0.5, 83.9, 125.0, 60.5, 20.000000000000014, 113.0, 113.0, 17.899999999999988, 20.000000000000014, -73.0, -38.8, -32.499999999999766, -112.9, -130.0, 20.000000000000014, 20.000000000000014, -61.0, 20.000000000000014, -139.89999999999998, 20.000000000000014, 61.40000000000006, -240.40000000000003, 49.099999999999994, 35.3, 20.000000000000014, 83.0, 20.6, -97.0, 20.000000000000014, 74.0, 119.0, 174.2, 89.0, -65.5, 20.000000000000014, 29.0, 15.5], "policy_predator_policy_reward": [30.0, 58.0, 41.0, 17.0, 23.0, 23.0, 10.0, 15.0, 40.0, 0.0, 36.0, 23.0, 10.0, 0.0, 20.0, 0.0, 32.0, 62.0, 32.0, 31.0, 0.0, 69.0, 0.0, 0.0, 2.0, 13.0, 40.0, 0.0, 0.0, 0.0, 53.0, 30.0, 16.0, 21.0, 37.0, 2.0, 21.0, 17.0, 4.0, 25.0, 40.0, 11.0, 0.0, 25.0, 0.0, 39.0, 0.0, 16.0, 42.0, 27.0, 51.0, 0.0, 29.0, 13.0, 0.0, 0.0, 40.0, 32.0, 0.0, 0.0, 0.0, 0.0, 20.0, 21.0, 0.0, 25.0, 42.0, 50.0, 0.0, 0.0, 0.0, 0.0, 42.0, 141.0, 62.0, 11.0, 6.0, 72.0, 74.0, 0.0, 76.0, 5.0, 0.0, 0.0, 57.0, 0.0, 5.0, 93.0, 16.0, 10.0, 0.0, 0.0, 38.0, 64.0, 72.0, 32.0, 73.0, 33.0, 0.0, 0.0, 11.0, 0.0, 37.0, 38.0, 25.0, 8.0, 18.0, 9.0, 46.0, 67.0, 58.0, 65.0, 0.0, 0.0, 0.0, 30.0, 24.0, 0.0, 59.0, 50.0, 58.0, 15.0, 18.0, 0.0, 8.0, 4.0, 65.0, 107.0, 34.0, 24.0, 0.0, 52.0, 91.0, 34.0, 66.0, 108.0, 36.0, 79.0, 101.0, 73.0, 15.0, 21.0, 81.0, 42.0, 22.0, 14.0, 17.0, 16.0, 21.0, 117.0, 116.0, 104.0, 50.0, 73.0, 18.0, 134.0, 0.0, 69.0, 50.0, 24.0, 198.0, 76.0, 30.0, 40.0, 0.0, 48.0, 20.0, 26.0, 3.0, 35.0, 1.0, 0.0, 81.0, 33.0, 64.0, 74.0, 82.0, 31.0, 0.0, 87.0, 94.0, 36.0, 0.0, 12.0, 124.0, 50.0, 54.0, 0.0, 24.0, 45.0, 1.0, 99.0, 54.0, 0.0, 0.0, 37.0, 82.0, 24.0, 20.0, 82.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0914594377857199, "mean_inference_ms": 2.6625090198886947, "mean_action_processing_ms": 0.43056086554590023, "mean_env_wait_ms": 0.3381630814527267, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.012464404106140137, "StateBufferConnector_ms": 0.0038832426071166992, "ViewRequirementAgentConnector_ms": 0.19910311698913574}, "num_episodes": 22, "episode_return_max": 400.0, "episode_return_min": -175.89999999999998, "episode_return_mean": 140.9039999999999, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1424000, "num_agent_steps_trained": 1424000, "num_env_steps_sampled": 356000, "num_env_steps_trained": 356000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 71.3236491742805, "num_env_steps_trained_throughput_per_sec": 71.3236491742805, "timesteps_total": 356000, "num_env_steps_sampled_lifetime": 356000, "num_agent_steps_sampled_lifetime": 1424000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1424000, "timers": {"training_iteration_time_ms": 60563.053, "restore_workers_time_ms": 0.017, "training_step_time_ms": 60563.005, "sample_time_ms": 1971.333, "learn_time_ms": 58563.503, "learn_throughput": 68.302, "synch_weights_time_ms": 21.682}, "counters": {"num_env_steps_sampled": 356000, "num_env_steps_trained": 356000, "num_agent_steps_sampled": 1424000, "num_agent_steps_trained": 1424000}, "done": false, "training_iteration": 89, "trial_id": "11e70_00000", "date": "2024-08-13_00-36-28", "timestamp": 1723523788, "time_this_iter_s": 56.12752413749695, "time_total_s": 5364.41476559639, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2b061f0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 5364.41476559639, "iterations_since_restore": 89, "perf": {"cpu_util_percent": 50.660000000000004, "ram_util_percent": 75.48875}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 9.372888002572235, "cur_kl_coeff": 0.22500000000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.1389840933380935, "policy_loss": -0.008307240006548387, "vf_loss": 6.145750390663348, "vf_explained_var": 0.13270247729997786, "kl": 0.006848643186029902, "entropy": 0.85877589772618, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 169155.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 9.001247071652186, "cur_kl_coeff": 0.16875, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.661463450376319, "policy_loss": -0.009370707511093724, "vf_loss": 6.669380295465863, "vf_explained_var": -0.4272274466418715, "kl": 0.008615451340817695, "entropy": 0.9103274175414333, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 169155.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 360000, "num_env_steps_trained": 360000, "num_agent_steps_sampled": 1440000, "num_agent_steps_trained": 1440000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -178.6, "episode_reward_mean": 102.13699999999993, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -395.8, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 198.0}, "policy_reward_mean": {"prey_policy": 10.743499999999994, "predator_policy": 40.325}, "custom_metrics": {}, "hist_stats": {"episode_reward": [302.1, 165.59999999999954, 225.40000000000003, 214.99999999999977, 286.0, 187.09999999999945, 250.6, 267.4, 144.09999999999957, 40.0000000000003, 243.1, 269.49999999999966, 40.0000000000003, 282.3, 229.4000000000001, 214.2, 399.1, 40.0000000000003, -9.200000000000003, 69.50000000000006, 210.1, -106.50000000000142, 81.09999999999977, 40.0000000000003, 193.30000000000004, 33.00000000000003, 182.99999999999943, 400.0, 223.0, 99.0, 85.1, 355.00000000000006, 109.79999999999978, 190.3, 122.79999999999973, 162.3999999999995, 187.2, 10.300000000000104, 40.0000000000003, 157.29999999999956, 165.6999999999995, 62.0, 142.10000000000002, 183.99999999999926, 173.79999999999947, -141.4, 121.69999999999979, 212.90000000000003, 63.0, -12.5, 11.300000000000075, -40.099999999999994, 162.99999999999935, -41.0, 327.1, 322.0, -57.8, -41.8, 85.60000000000011, -68.69999999999996, 134.2000000000001, 146.1, -175.89999999999998, 90.49999999999982, 256.9, 126.49999999999977, 264.0, 38.90000000000028, 2.200000000000003, -7.399999999999908, 3.0000000000000755, 45.99999999999967, 10.099999999999973, 93.39999999999986, -17.300000000000033, 109.29999999999967, 172.6, 23.00000000000007, 247.0, 300.2, 60.500000000000206, 146.50000000000003, -53.099999999999966, 1.500000000000229, 6.499999999999953, -68.50000000000117, 99.99999999999964, 87.80000000000011, -156.99999999999994, 41.30000000000018, -6.8999999999998, -59.999999999999794, 2.7000000000000384, 106.2999999999997, 17.000000000000217, -178.6, 1.8000000000000702, 13.600000000000012, 106.0, -85.3], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [118.1, 146.0, 125.0, 11.599999999999964, 100.4, 74.0, 138.8, 51.19999999999997, 150.2, 96.8, 20.000000000000014, 151.1, 68.6, 113.0, 79.4, 137.0, 20.000000000000014, 82.1, 20.000000000000014, 20.000000000000014, -10.899999999999999, 182.0, 76.69999999999996, 192.8, 20.000000000000014, 20.000000000000014, 122.3, 119.0, 108.8, 95.59999999999997, 79.1, 43.099999999999994, 199.1, 200.0, 20.000000000000014, 20.000000000000014, -22.0, -170.20000000000002, 20.000000000000014, -23.5, 74.0, 58.1, -45.099999999999824, -135.40000000000072, 14.0, -13.90000000000003, 20.000000000000014, 20.000000000000014, 38.599999999999994, 97.69999999999999, 20.000000000000014, -85.0, 137.0, 20.000000000000014, 200.0, 200.0, 68.0, 53.0, 17.0, -22.0, 32.0, -52.900000000000006, 155.0, 200.0, 20.000000000000014, 78.79999999999998, 41.0, 74.3, 74.00000000000006, 15.799999999999963, 115.4, 20.000000000000014, -31.0, 105.2, -44.499999999999794, -68.2, 20.000000000000014, 20.000000000000014, -5.199999999999934, 132.5, 20.000000000000014, 121.7, -106.6, 59.599999999999994, 62.0, 7.099999999999994, 146.0, 20.000000000000014, 20.000000000000014, 141.8, -131.2, -182.2, 52.099999999999994, 11.600000000000009, 152.0, 8.899999999999984, -10.0, -52.0, -91.0, -95.5, -123.70000000000005, 20.000000000000014, -4.600000000000001, -209.5, 107.0, 20.000000000000014, -85.0, -79.0, 139.1, 152.0, 110.0, 179.0, -56.8, -139.0, -95.80000000000001, -166.0, -65.80000000000001, 28.39999999999999, -240.70000000000005, 20.000000000000014, 91.99999999999997, -26.799999999999997, -0.10000000000000142, 72.2, -395.8, -54.099999999999994, 20.000000000000014, 0.5, 83.9, 125.0, 60.5, 20.000000000000014, 113.0, 113.0, 17.899999999999988, 20.000000000000014, -73.0, -38.8, -32.499999999999766, -112.9, -130.0, 20.000000000000014, 20.000000000000014, -61.0, 20.000000000000014, -139.89999999999998, 20.000000000000014, 61.40000000000006, -240.40000000000003, 49.099999999999994, 35.3, 20.000000000000014, 83.0, 20.6, -97.0, 20.000000000000014, 74.0, 119.0, 174.2, 89.0, -65.5, 20.000000000000014, 29.0, 15.5, -39.099999999999994, -178.0, -3.099999999999965, -9.399999999999862, -230.5, 20.000000000000014, -124.90000000000057, -55.59999999999985, 20.000000000000014, 20.0, -47.2, 31.99999999999998, -148.0, -139.0, 20.000000000000014, -66.7, -139.9, 20.000000000000014, -229.0, 20.000000000000014, -277.6, 50.3, 65.89999999999999, 7.399999999999965, 20.000000000000014, -118.0, -127.0, -220.6, 13.69999999999997, -121.9, 20.000000000000014, -30.39999999999975, -25.0, 14.0, -142.0, -199.3], "policy_predator_policy_reward": [21.0, 17.0, 4.0, 25.0, 40.0, 11.0, 0.0, 25.0, 0.0, 39.0, 0.0, 16.0, 42.0, 27.0, 51.0, 0.0, 29.0, 13.0, 0.0, 0.0, 40.0, 32.0, 0.0, 0.0, 0.0, 0.0, 20.0, 21.0, 0.0, 25.0, 42.0, 50.0, 0.0, 0.0, 0.0, 0.0, 42.0, 141.0, 62.0, 11.0, 6.0, 72.0, 74.0, 0.0, 76.0, 5.0, 0.0, 0.0, 57.0, 0.0, 5.0, 93.0, 16.0, 10.0, 0.0, 0.0, 38.0, 64.0, 72.0, 32.0, 73.0, 33.0, 0.0, 0.0, 11.0, 0.0, 37.0, 38.0, 25.0, 8.0, 18.0, 9.0, 46.0, 67.0, 58.0, 65.0, 0.0, 0.0, 0.0, 30.0, 24.0, 0.0, 59.0, 50.0, 58.0, 15.0, 18.0, 0.0, 8.0, 4.0, 65.0, 107.0, 34.0, 24.0, 0.0, 52.0, 91.0, 34.0, 66.0, 108.0, 36.0, 79.0, 101.0, 73.0, 15.0, 21.0, 81.0, 42.0, 22.0, 14.0, 17.0, 16.0, 21.0, 117.0, 116.0, 104.0, 50.0, 73.0, 18.0, 134.0, 0.0, 69.0, 50.0, 24.0, 198.0, 76.0, 30.0, 40.0, 0.0, 48.0, 20.0, 26.0, 3.0, 35.0, 1.0, 0.0, 81.0, 33.0, 64.0, 74.0, 82.0, 31.0, 0.0, 87.0, 94.0, 36.0, 0.0, 12.0, 124.0, 50.0, 54.0, 0.0, 24.0, 45.0, 1.0, 99.0, 54.0, 0.0, 0.0, 37.0, 82.0, 24.0, 20.0, 82.0, 127.0, 37.0, 0.0, 14.0, 107.0, 110.0, 47.0, 65.0, 0.0, 60.0, 52.0, 51.0, 105.0, 25.0, 86.0, 2.0, 0.0, 113.0, 103.0, 46.0, 82.0, 148.0, 33.0, 0.0, 50.0, 65.0, 102.0, 67.0, 10.0, 100.0, 24.0, 0.0, 28.0, 89.0, 129.0, 127.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0912033946704585, "mean_inference_ms": 2.6631147164313353, "mean_action_processing_ms": 0.43094191555445577, "mean_env_wait_ms": 0.33820868149910976, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.013277530670166016, "StateBufferConnector_ms": 0.004105925559997559, "ViewRequirementAgentConnector_ms": 0.20469772815704346}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -178.6, "episode_return_mean": 102.13699999999993, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1440000, "num_agent_steps_trained": 1440000, "num_env_steps_sampled": 360000, "num_env_steps_trained": 360000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 75.876393054121, "num_env_steps_trained_throughput_per_sec": 75.876393054121, "timesteps_total": 360000, "num_env_steps_sampled_lifetime": 360000, "num_agent_steps_sampled_lifetime": 1440000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1440000, "timers": {"training_iteration_time_ms": 58948.12, "restore_workers_time_ms": 0.016, "training_step_time_ms": 58948.069, "sample_time_ms": 2047.252, "learn_time_ms": 56872.245, "learn_throughput": 70.333, "synch_weights_time_ms": 22.213}, "counters": {"num_env_steps_sampled": 360000, "num_env_steps_trained": 360000, "num_agent_steps_sampled": 1440000, "num_agent_steps_trained": 1440000}, "done": false, "training_iteration": 90, "trial_id": "11e70_00000", "date": "2024-08-13_00-37-21", "timestamp": 1723523841, "time_this_iter_s": 52.77788209915161, "time_total_s": 5417.192647695541, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2b06790>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 5417.192647695541, "iterations_since_restore": 90, "perf": {"cpu_util_percent": 33.641333333333336, "ram_util_percent": 78.84933333333335}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 8.661108790503608, "cur_kl_coeff": 0.22500000000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.340557941305574, "policy_loss": -0.007970006476900486, "vf_loss": 7.347048511706963, "vf_explained_var": 0.10915682243291663, "kl": 0.006575306684035273, "entropy": 0.8147952576162953, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 171045.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 9.040500353631518, "cur_kl_coeff": 0.16875, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.734790362504424, "policy_loss": -0.010117305883713974, "vf_loss": 6.74307123769528, "vf_explained_var": -0.49242703517278036, "kl": 0.010882556309722435, "entropy": 0.9809294044656097, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 171045.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 364000, "num_env_steps_trained": 364000, "num_agent_steps_sampled": 1456000, "num_agent_steps_trained": 1456000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -242.29999999999995, "episode_reward_mean": 61.449999999999946, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -395.8, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 198.0}, "policy_reward_mean": {"prey_policy": -20.124999999999996, "predator_policy": 50.85}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.0000000000003, 193.30000000000004, 33.00000000000003, 182.99999999999943, 400.0, 223.0, 99.0, 85.1, 355.00000000000006, 109.79999999999978, 190.3, 122.79999999999973, 162.3999999999995, 187.2, 10.300000000000104, 40.0000000000003, 157.29999999999956, 165.6999999999995, 62.0, 142.10000000000002, 183.99999999999926, 173.79999999999947, -141.4, 121.69999999999979, 212.90000000000003, 63.0, -12.5, 11.300000000000075, -40.099999999999994, 162.99999999999935, -41.0, 327.1, 322.0, -57.8, -41.8, 85.60000000000011, -68.69999999999996, 134.2000000000001, 146.1, -175.89999999999998, 90.49999999999982, 256.9, 126.49999999999977, 264.0, 38.90000000000028, 2.200000000000003, -7.399999999999908, 3.0000000000000755, 45.99999999999967, 10.099999999999973, 93.39999999999986, -17.300000000000033, 109.29999999999967, 172.6, 23.00000000000007, 247.0, 300.2, 60.500000000000206, 146.50000000000003, -53.099999999999966, 1.500000000000229, 6.499999999999953, -68.50000000000117, 99.99999999999964, 87.80000000000011, -156.99999999999994, 41.30000000000018, -6.8999999999998, -59.999999999999794, 2.7000000000000384, 106.2999999999997, 17.000000000000217, -178.6, 1.8000000000000702, 13.600000000000012, 106.0, -85.3, 76.00000000000009, -74.8, -57.29999999999987, -116.70000000000057, 147.1999999999993, 222.09999999999997, -65.49999999999991, 139.1, 47.10000000000001, 5.500000000000101, -134.69999999999993, 44.79999999999998, 49.00000000000014, 18.000000000000163, -239.9, -178.4, -43.0, 113.5, 72.3999999999996, -242.29999999999995, 295.2, -135.1, 35.0], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 20.000000000000014, 38.599999999999994, 97.69999999999999, 20.000000000000014, -85.0, 137.0, 20.000000000000014, 200.0, 200.0, 68.0, 53.0, 17.0, -22.0, 32.0, -52.900000000000006, 155.0, 200.0, 20.000000000000014, 78.79999999999998, 41.0, 74.3, 74.00000000000006, 15.799999999999963, 115.4, 20.000000000000014, -31.0, 105.2, -44.499999999999794, -68.2, 20.000000000000014, 20.000000000000014, -5.199999999999934, 132.5, 20.000000000000014, 121.7, -106.6, 59.599999999999994, 62.0, 7.099999999999994, 146.0, 20.000000000000014, 20.000000000000014, 141.8, -131.2, -182.2, 52.099999999999994, 11.600000000000009, 152.0, 8.899999999999984, -10.0, -52.0, -91.0, -95.5, -123.70000000000005, 20.000000000000014, -4.600000000000001, -209.5, 107.0, 20.000000000000014, -85.0, -79.0, 139.1, 152.0, 110.0, 179.0, -56.8, -139.0, -95.80000000000001, -166.0, -65.80000000000001, 28.39999999999999, -240.70000000000005, 20.000000000000014, 91.99999999999997, -26.799999999999997, -0.10000000000000142, 72.2, -395.8, -54.099999999999994, 20.000000000000014, 0.5, 83.9, 125.0, 60.5, 20.000000000000014, 113.0, 113.0, 17.899999999999988, 20.000000000000014, -73.0, -38.8, -32.499999999999766, -112.9, -130.0, 20.000000000000014, 20.000000000000014, -61.0, 20.000000000000014, -139.89999999999998, 20.000000000000014, 61.40000000000006, -240.40000000000003, 49.099999999999994, 35.3, 20.000000000000014, 83.0, 20.6, -97.0, 20.000000000000014, 74.0, 119.0, 174.2, 89.0, -65.5, 20.000000000000014, 29.0, 15.5, -39.099999999999994, -178.0, -3.099999999999965, -9.399999999999862, -230.5, 20.000000000000014, -124.90000000000057, -55.59999999999985, 20.000000000000014, 20.0, -47.2, 31.99999999999998, -148.0, -139.0, 20.000000000000014, -66.7, -139.9, 20.000000000000014, -229.0, 20.000000000000014, -277.6, 50.3, 65.89999999999999, 7.399999999999965, 20.000000000000014, -118.0, -127.0, -220.6, 13.69999999999997, -121.9, 20.000000000000014, -30.39999999999975, -25.0, 14.0, -142.0, -199.3, -16.0, 20.000000000000014, -161.20000000000002, -178.6, 20.000000000000014, -214.3, -381.7, 20.000000000000014, 1.0999999999999688, 106.1, 123.80000000000001, 41.3, -272.5, 20.000000000000014, 62.0, -10.899999999999999, -58.600000000000016, -106.3, -74.50000000000003, 20.000000000000014, -51.70000000000003, -250.0, 8.0, -71.2, 20.000000000000014, -52.0, 20.000000000000014, -172.0, -262.9, -178.0, -145.0, -165.4, 20.000000000000014, -286.0, 69.2, -27.700000000000003, 20.000000000000014, -19.6, -214.3, -199.0, 104.0, 147.2, -194.8, -157.3, 20.000000000000014, -148.0], "policy_predator_policy_reward": [0.0, 0.0, 57.0, 0.0, 5.0, 93.0, 16.0, 10.0, 0.0, 0.0, 38.0, 64.0, 72.0, 32.0, 73.0, 33.0, 0.0, 0.0, 11.0, 0.0, 37.0, 38.0, 25.0, 8.0, 18.0, 9.0, 46.0, 67.0, 58.0, 65.0, 0.0, 0.0, 0.0, 30.0, 24.0, 0.0, 59.0, 50.0, 58.0, 15.0, 18.0, 0.0, 8.0, 4.0, 65.0, 107.0, 34.0, 24.0, 0.0, 52.0, 91.0, 34.0, 66.0, 108.0, 36.0, 79.0, 101.0, 73.0, 15.0, 21.0, 81.0, 42.0, 22.0, 14.0, 17.0, 16.0, 21.0, 117.0, 116.0, 104.0, 50.0, 73.0, 18.0, 134.0, 0.0, 69.0, 50.0, 24.0, 198.0, 76.0, 30.0, 40.0, 0.0, 48.0, 20.0, 26.0, 3.0, 35.0, 1.0, 0.0, 81.0, 33.0, 64.0, 74.0, 82.0, 31.0, 0.0, 87.0, 94.0, 36.0, 0.0, 12.0, 124.0, 50.0, 54.0, 0.0, 24.0, 45.0, 1.0, 99.0, 54.0, 0.0, 0.0, 37.0, 82.0, 24.0, 20.0, 82.0, 127.0, 37.0, 0.0, 14.0, 107.0, 110.0, 47.0, 65.0, 0.0, 60.0, 52.0, 51.0, 105.0, 25.0, 86.0, 2.0, 0.0, 113.0, 103.0, 46.0, 82.0, 148.0, 33.0, 0.0, 50.0, 65.0, 102.0, 67.0, 10.0, 100.0, 24.0, 0.0, 28.0, 89.0, 129.0, 127.0, 0.0, 72.0, 167.0, 98.0, 90.0, 47.0, 69.0, 176.0, 40.0, 0.0, 0.0, 57.0, 123.0, 64.0, 88.0, 0.0, 105.0, 107.0, 13.0, 47.0, 71.0, 96.0, 84.0, 24.0, 32.0, 49.0, 110.0, 60.0, 106.0, 95.0, 7.0, 125.0, 119.0, 104.0, 72.0, 0.0, 0.0, 72.0, 107.0, 64.0, 44.0, 0.0, 97.0, 120.0, 74.0, 89.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0923653695390616, "mean_inference_ms": 2.66409255399452, "mean_action_processing_ms": 0.4317656925730285, "mean_env_wait_ms": 0.33818751866618113, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.014905691146850586, "StateBufferConnector_ms": 0.007195591926574707, "ViewRequirementAgentConnector_ms": 0.19219183921813965}, "num_episodes": 23, "episode_return_max": 400.0, "episode_return_min": -242.29999999999995, "episode_return_mean": 61.449999999999946, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1456000, "num_agent_steps_trained": 1456000, "num_env_steps_sampled": 364000, "num_env_steps_trained": 364000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 57.98211257058204, "num_env_steps_trained_throughput_per_sec": 57.98211257058204, "timesteps_total": 364000, "num_env_steps_sampled_lifetime": 364000, "num_agent_steps_sampled_lifetime": 1456000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1456000, "timers": {"training_iteration_time_ms": 59457.069, "restore_workers_time_ms": 0.016, "training_step_time_ms": 59457.019, "sample_time_ms": 2083.337, "learn_time_ms": 57346.565, "learn_throughput": 69.751, "synch_weights_time_ms": 21.183}, "counters": {"num_env_steps_sampled": 364000, "num_env_steps_trained": 364000, "num_agent_steps_sampled": 1456000, "num_agent_steps_trained": 1456000}, "done": false, "training_iteration": 91, "trial_id": "11e70_00000", "date": "2024-08-13_00-38-30", "timestamp": 1723523910, "time_this_iter_s": 69.01569366455078, "time_total_s": 5486.208341360092, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b4a769d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 5486.208341360092, "iterations_since_restore": 91, "perf": {"cpu_util_percent": 61.68469387755103, "ram_util_percent": 80.02142857142857}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 9.02824308172105, "cur_kl_coeff": 0.22500000000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.08454448760502, "policy_loss": -0.008309563615965465, "vf_loss": 7.091463374839258, "vf_explained_var": 0.1499743538874167, "kl": 0.0061808010370277226, "entropy": 0.8019142728318613, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 172935.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 10.098684010051546, "cur_kl_coeff": 0.16875, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.750239207504919, "policy_loss": -0.010621126976588534, "vf_loss": 6.759308243302441, "vf_explained_var": -0.7337529659901977, "kl": 0.009197449224393753, "entropy": 0.9420455713436087, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 172935.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 368000, "num_env_steps_trained": 368000, "num_agent_steps_sampled": 1472000, "num_agent_steps_trained": 1472000}, "env_runners": {"episode_reward_max": 327.1, "episode_reward_min": -374.7, "episode_reward_mean": 15.331999999999976, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -395.8, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 179.0, "predator_policy": 198.0}, "policy_reward_mean": {"prey_policy": -54.483999999999995, "predator_policy": 62.15}, "custom_metrics": {}, "hist_stats": {"episode_reward": [62.0, 142.10000000000002, 183.99999999999926, 173.79999999999947, -141.4, 121.69999999999979, 212.90000000000003, 63.0, -12.5, 11.300000000000075, -40.099999999999994, 162.99999999999935, -41.0, 327.1, 322.0, -57.8, -41.8, 85.60000000000011, -68.69999999999996, 134.2000000000001, 146.1, -175.89999999999998, 90.49999999999982, 256.9, 126.49999999999977, 264.0, 38.90000000000028, 2.200000000000003, -7.399999999999908, 3.0000000000000755, 45.99999999999967, 10.099999999999973, 93.39999999999986, -17.300000000000033, 109.29999999999967, 172.6, 23.00000000000007, 247.0, 300.2, 60.500000000000206, 146.50000000000003, -53.099999999999966, 1.500000000000229, 6.499999999999953, -68.50000000000117, 99.99999999999964, 87.80000000000011, -156.99999999999994, 41.30000000000018, -6.8999999999998, -59.999999999999794, 2.7000000000000384, 106.2999999999997, 17.000000000000217, -178.6, 1.8000000000000702, 13.600000000000012, 106.0, -85.3, 76.00000000000009, -74.8, -57.29999999999987, -116.70000000000057, 147.1999999999993, 222.09999999999997, -65.49999999999991, 139.1, 47.10000000000001, 5.500000000000101, -134.69999999999993, 44.79999999999998, 49.00000000000014, 18.000000000000163, -239.9, -178.4, -43.0, 113.5, 72.3999999999996, -242.29999999999995, 295.2, -135.1, 35.0, -47.39999999999989, -42.4, -282.7, 37.80000000000027, -126.0, -86.00000000000023, -286.5, -37.99999999999986, 40.0000000000003, -347.9, -239.0, -161.8, 13.100000000000124, -374.7, 177.7, 40.0000000000003, -70.00000000000003, -60.799999999999955], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-106.6, 59.599999999999994, 62.0, 7.099999999999994, 146.0, 20.000000000000014, 20.000000000000014, 141.8, -131.2, -182.2, 52.099999999999994, 11.600000000000009, 152.0, 8.899999999999984, -10.0, -52.0, -91.0, -95.5, -123.70000000000005, 20.000000000000014, -4.600000000000001, -209.5, 107.0, 20.000000000000014, -85.0, -79.0, 139.1, 152.0, 110.0, 179.0, -56.8, -139.0, -95.80000000000001, -166.0, -65.80000000000001, 28.39999999999999, -240.70000000000005, 20.000000000000014, 91.99999999999997, -26.799999999999997, -0.10000000000000142, 72.2, -395.8, -54.099999999999994, 20.000000000000014, 0.5, 83.9, 125.0, 60.5, 20.000000000000014, 113.0, 113.0, 17.899999999999988, 20.000000000000014, -73.0, -38.8, -32.499999999999766, -112.9, -130.0, 20.000000000000014, 20.000000000000014, -61.0, 20.000000000000014, -139.89999999999998, 20.000000000000014, 61.40000000000006, -240.40000000000003, 49.099999999999994, 35.3, 20.000000000000014, 83.0, 20.6, -97.0, 20.000000000000014, 74.0, 119.0, 174.2, 89.0, -65.5, 20.000000000000014, 29.0, 15.5, -39.099999999999994, -178.0, -3.099999999999965, -9.399999999999862, -230.5, 20.000000000000014, -124.90000000000057, -55.59999999999985, 20.000000000000014, 20.0, -47.2, 31.99999999999998, -148.0, -139.0, 20.000000000000014, -66.7, -139.9, 20.000000000000014, -229.0, 20.000000000000014, -277.6, 50.3, 65.89999999999999, 7.399999999999965, 20.000000000000014, -118.0, -127.0, -220.6, 13.69999999999997, -121.9, 20.000000000000014, -30.39999999999975, -25.0, 14.0, -142.0, -199.3, -16.0, 20.000000000000014, -161.20000000000002, -178.6, 20.000000000000014, -214.3, -381.7, 20.000000000000014, 1.0999999999999688, 106.1, 123.80000000000001, 41.3, -272.5, 20.000000000000014, 62.0, -10.899999999999999, -58.600000000000016, -106.3, -74.50000000000003, 20.000000000000014, -51.70000000000003, -250.0, 8.0, -71.2, 20.000000000000014, -52.0, 20.000000000000014, -172.0, -262.9, -178.0, -145.0, -165.4, 20.000000000000014, -286.0, 69.2, -27.700000000000003, 20.000000000000014, -19.6, -214.3, -199.0, 104.0, 147.2, -194.8, -157.3, 20.000000000000014, -148.0, -190.0, -9.399999999999855, -5.5, -298.9, -256.0, -255.7, 20.000000000000014, 15.799999999999963, -178.0, -136.0, -376.0, 20.000000000000014, -331.9, -226.6, 20.000000000000014, -328.0, 20.000000000000014, 20.000000000000014, -310.0, -319.9, -187.0, -250.0, -132.7, -267.1, 20.000000000000014, -109.9, -292.0, -339.7, 61.69999999999999, 71.0, 20.000000000000014, 20.000000000000014, -310.9, -9.1, -85.00000000000003, -146.8], "policy_predator_policy_reward": [59.0, 50.0, 58.0, 15.0, 18.0, 0.0, 8.0, 4.0, 65.0, 107.0, 34.0, 24.0, 0.0, 52.0, 91.0, 34.0, 66.0, 108.0, 36.0, 79.0, 101.0, 73.0, 15.0, 21.0, 81.0, 42.0, 22.0, 14.0, 17.0, 16.0, 21.0, 117.0, 116.0, 104.0, 50.0, 73.0, 18.0, 134.0, 0.0, 69.0, 50.0, 24.0, 198.0, 76.0, 30.0, 40.0, 0.0, 48.0, 20.0, 26.0, 3.0, 35.0, 1.0, 0.0, 81.0, 33.0, 64.0, 74.0, 82.0, 31.0, 0.0, 87.0, 94.0, 36.0, 0.0, 12.0, 124.0, 50.0, 54.0, 0.0, 24.0, 45.0, 1.0, 99.0, 54.0, 0.0, 0.0, 37.0, 82.0, 24.0, 20.0, 82.0, 127.0, 37.0, 0.0, 14.0, 107.0, 110.0, 47.0, 65.0, 0.0, 60.0, 52.0, 51.0, 105.0, 25.0, 86.0, 2.0, 0.0, 113.0, 103.0, 46.0, 82.0, 148.0, 33.0, 0.0, 50.0, 65.0, 102.0, 67.0, 10.0, 100.0, 24.0, 0.0, 28.0, 89.0, 129.0, 127.0, 0.0, 72.0, 167.0, 98.0, 90.0, 47.0, 69.0, 176.0, 40.0, 0.0, 0.0, 57.0, 123.0, 64.0, 88.0, 0.0, 105.0, 107.0, 13.0, 47.0, 71.0, 96.0, 84.0, 24.0, 32.0, 49.0, 110.0, 60.0, 106.0, 95.0, 7.0, 125.0, 119.0, 104.0, 72.0, 0.0, 0.0, 72.0, 107.0, 64.0, 44.0, 0.0, 97.0, 120.0, 74.0, 89.0, 63.0, 89.0, 130.0, 132.0, 117.0, 112.0, 0.0, 2.0, 86.0, 102.0, 118.0, 152.0, 127.0, 145.0, 131.0, 139.0, 0.0, 0.0, 172.0, 110.0, 159.0, 39.0, 147.0, 91.0, 71.0, 32.0, 138.0, 119.0, 0.0, 45.0, 0.0, 0.0, 140.0, 110.0, 97.0, 74.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0907006879453545, "mean_inference_ms": 2.665019358837689, "mean_action_processing_ms": 0.431750156004359, "mean_env_wait_ms": 0.3386363736160392, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007652759552001953, "StateBufferConnector_ms": 0.007262706756591797, "ViewRequirementAgentConnector_ms": 0.1729755401611328}, "num_episodes": 18, "episode_return_max": 327.1, "episode_return_min": -374.7, "episode_return_mean": 15.331999999999976, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1472000, "num_agent_steps_trained": 1472000, "num_env_steps_sampled": 368000, "num_env_steps_trained": 368000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 70.97405991791, "num_env_steps_trained_throughput_per_sec": 70.97405991791, "timesteps_total": 368000, "num_env_steps_sampled_lifetime": 368000, "num_agent_steps_sampled_lifetime": 1472000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1472000, "timers": {"training_iteration_time_ms": 58825.063, "restore_workers_time_ms": 0.015, "training_step_time_ms": 58824.999, "sample_time_ms": 1959.406, "learn_time_ms": 56839.111, "learn_throughput": 70.374, "synch_weights_time_ms": 20.522}, "counters": {"num_env_steps_sampled": 368000, "num_env_steps_trained": 368000, "num_agent_steps_sampled": 1472000, "num_agent_steps_trained": 1472000}, "done": false, "training_iteration": 92, "trial_id": "11e70_00000", "date": "2024-08-13_00-39-26", "timestamp": 1723523966, "time_this_iter_s": 56.41585993766785, "time_total_s": 5542.62420129776, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2b060d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 5542.62420129776, "iterations_since_restore": 92, "perf": {"cpu_util_percent": 43.396249999999995, "ram_util_percent": 78.39}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 10.342814892877346, "cur_kl_coeff": 0.22500000000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.332951552022702, "policy_loss": -0.010207146147719372, "vf_loss": 7.341636513402222, "vf_explained_var": 0.0993026712584117, "kl": 0.00676529694803276, "entropy": 0.8120924886572298, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 174825.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 9.012818970125188, "cur_kl_coeff": 0.16875, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.2166766234806605, "policy_loss": -0.008886613091207527, "vf_loss": 6.224115755192186, "vf_explained_var": -0.6771345628001703, "kl": 0.008577596990688946, "entropy": 0.9496730454068966, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 174825.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 372000, "num_env_steps_trained": 372000, "num_agent_steps_sampled": 1488000, "num_agent_steps_trained": 1488000}, "env_runners": {"episode_reward_max": 300.2, "episode_reward_min": -374.7, "episode_reward_mean": -8.553, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -395.8, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 174.2, "predator_policy": 198.0}, "policy_reward_mean": {"prey_policy": -74.2615, "predator_policy": 69.985}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-68.69999999999996, 134.2000000000001, 146.1, -175.89999999999998, 90.49999999999982, 256.9, 126.49999999999977, 264.0, 38.90000000000028, 2.200000000000003, -7.399999999999908, 3.0000000000000755, 45.99999999999967, 10.099999999999973, 93.39999999999986, -17.300000000000033, 109.29999999999967, 172.6, 23.00000000000007, 247.0, 300.2, 60.500000000000206, 146.50000000000003, -53.099999999999966, 1.500000000000229, 6.499999999999953, -68.50000000000117, 99.99999999999964, 87.80000000000011, -156.99999999999994, 41.30000000000018, -6.8999999999998, -59.999999999999794, 2.7000000000000384, 106.2999999999997, 17.000000000000217, -178.6, 1.8000000000000702, 13.600000000000012, 106.0, -85.3, 76.00000000000009, -74.8, -57.29999999999987, -116.70000000000057, 147.1999999999993, 222.09999999999997, -65.49999999999991, 139.1, 47.10000000000001, 5.500000000000101, -134.69999999999993, 44.79999999999998, 49.00000000000014, 18.000000000000163, -239.9, -178.4, -43.0, 113.5, 72.3999999999996, -242.29999999999995, 295.2, -135.1, 35.0, -47.39999999999989, -42.4, -282.7, 37.80000000000027, -126.0, -86.00000000000023, -286.5, -37.99999999999986, 40.0000000000003, -347.9, -239.0, -161.8, 13.100000000000124, -374.7, 177.7, 40.0000000000003, -70.00000000000003, -60.799999999999955, -239.39999999999998, 68.09999999999985, -58.999999999999844, -107.90000000000005, -288.7, 34.5, -35.899999999999906, 31.800000000000004, 162.39999999999947, -17.299999999999937, 34.50000000000022, 48.500000000000256, -17.399999999999906, -36.99999999999992, -218.9, -180.4, 0.5000000000000727, -32.99999999999982], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-240.70000000000005, 20.000000000000014, 91.99999999999997, -26.799999999999997, -0.10000000000000142, 72.2, -395.8, -54.099999999999994, 20.000000000000014, 0.5, 83.9, 125.0, 60.5, 20.000000000000014, 113.0, 113.0, 17.899999999999988, 20.000000000000014, -73.0, -38.8, -32.499999999999766, -112.9, -130.0, 20.000000000000014, 20.000000000000014, -61.0, 20.000000000000014, -139.89999999999998, 20.000000000000014, 61.40000000000006, -240.40000000000003, 49.099999999999994, 35.3, 20.000000000000014, 83.0, 20.6, -97.0, 20.000000000000014, 74.0, 119.0, 174.2, 89.0, -65.5, 20.000000000000014, 29.0, 15.5, -39.099999999999994, -178.0, -3.099999999999965, -9.399999999999862, -230.5, 20.000000000000014, -124.90000000000057, -55.59999999999985, 20.000000000000014, 20.0, -47.2, 31.99999999999998, -148.0, -139.0, 20.000000000000014, -66.7, -139.9, 20.000000000000014, -229.0, 20.000000000000014, -277.6, 50.3, 65.89999999999999, 7.399999999999965, 20.000000000000014, -118.0, -127.0, -220.6, 13.69999999999997, -121.9, 20.000000000000014, -30.39999999999975, -25.0, 14.0, -142.0, -199.3, -16.0, 20.000000000000014, -161.20000000000002, -178.6, 20.000000000000014, -214.3, -381.7, 20.000000000000014, 1.0999999999999688, 106.1, 123.80000000000001, 41.3, -272.5, 20.000000000000014, 62.0, -10.899999999999999, -58.600000000000016, -106.3, -74.50000000000003, 20.000000000000014, -51.70000000000003, -250.0, 8.0, -71.2, 20.000000000000014, -52.0, 20.000000000000014, -172.0, -262.9, -178.0, -145.0, -165.4, 20.000000000000014, -286.0, 69.2, -27.700000000000003, 20.000000000000014, -19.6, -214.3, -199.0, 104.0, 147.2, -194.8, -157.3, 20.000000000000014, -148.0, -190.0, -9.399999999999855, -5.5, -298.9, -256.0, -255.7, 20.000000000000014, 15.799999999999963, -178.0, -136.0, -376.0, 20.000000000000014, -331.9, -226.6, 20.000000000000014, -328.0, 20.000000000000014, 20.000000000000014, -310.0, -319.9, -187.0, -250.0, -132.7, -267.1, 20.000000000000014, -109.9, -292.0, -339.7, 61.69999999999999, 71.0, 20.000000000000014, 20.000000000000014, -310.9, -9.1, -85.00000000000003, -146.8, -265.0, -252.4, -181.9, 20.000000000000014, -292.0, 20.000000000000014, -115.90000000000003, -271.0, -221.8, -331.9, -5.800000000000001, -87.7, -124.90000000000015, 20.000000000000014, 90.49999999999997, -315.7, 20.000000000000014, 142.39999999999998, -146.8, 9.499999999999964, 9.499999999999964, 20.000000000000014, -200.5, 20.000000000000014, -174.40000000000003, 20.000000000000014, 20.000000000000014, -214.0, -394.9, -184.0, -160.9, -284.5, -146.5, 20.000000000000014, 20.000000000000014, -292.0], "policy_predator_policy_reward": [18.0, 134.0, 0.0, 69.0, 50.0, 24.0, 198.0, 76.0, 30.0, 40.0, 0.0, 48.0, 20.0, 26.0, 3.0, 35.0, 1.0, 0.0, 81.0, 33.0, 64.0, 74.0, 82.0, 31.0, 0.0, 87.0, 94.0, 36.0, 0.0, 12.0, 124.0, 50.0, 54.0, 0.0, 24.0, 45.0, 1.0, 99.0, 54.0, 0.0, 0.0, 37.0, 82.0, 24.0, 20.0, 82.0, 127.0, 37.0, 0.0, 14.0, 107.0, 110.0, 47.0, 65.0, 0.0, 60.0, 52.0, 51.0, 105.0, 25.0, 86.0, 2.0, 0.0, 113.0, 103.0, 46.0, 82.0, 148.0, 33.0, 0.0, 50.0, 65.0, 102.0, 67.0, 10.0, 100.0, 24.0, 0.0, 28.0, 89.0, 129.0, 127.0, 0.0, 72.0, 167.0, 98.0, 90.0, 47.0, 69.0, 176.0, 40.0, 0.0, 0.0, 57.0, 123.0, 64.0, 88.0, 0.0, 105.0, 107.0, 13.0, 47.0, 71.0, 96.0, 84.0, 24.0, 32.0, 49.0, 110.0, 60.0, 106.0, 95.0, 7.0, 125.0, 119.0, 104.0, 72.0, 0.0, 0.0, 72.0, 107.0, 64.0, 44.0, 0.0, 97.0, 120.0, 74.0, 89.0, 63.0, 89.0, 130.0, 132.0, 117.0, 112.0, 0.0, 2.0, 86.0, 102.0, 118.0, 152.0, 127.0, 145.0, 131.0, 139.0, 0.0, 0.0, 172.0, 110.0, 159.0, 39.0, 147.0, 91.0, 71.0, 32.0, 138.0, 119.0, 0.0, 45.0, 0.0, 0.0, 140.0, 110.0, 97.0, 74.0, 146.0, 132.0, 126.0, 104.0, 88.0, 125.0, 161.0, 118.0, 149.0, 116.0, 128.0, 0.0, 68.0, 1.0, 117.0, 140.0, 0.0, 0.0, 0.0, 120.0, 0.0, 5.0, 110.0, 119.0, 90.0, 47.0, 63.0, 94.0, 178.0, 182.0, 145.0, 120.0, 75.0, 52.0, 134.0, 105.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0890428352973935, "mean_inference_ms": 2.660063545284824, "mean_action_processing_ms": 0.4310289707127457, "mean_env_wait_ms": 0.3381524409547142, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0077135562896728516, "StateBufferConnector_ms": 0.007122516632080078, "ViewRequirementAgentConnector_ms": 0.15692031383514404}, "num_episodes": 18, "episode_return_max": 300.2, "episode_return_min": -374.7, "episode_return_mean": -8.553, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1488000, "num_agent_steps_trained": 1488000, "num_env_steps_sampled": 372000, "num_env_steps_trained": 372000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 74.39807193827994, "num_env_steps_trained_throughput_per_sec": 74.39807193827994, "timesteps_total": 372000, "num_env_steps_sampled_lifetime": 372000, "num_agent_steps_sampled_lifetime": 1488000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1488000, "timers": {"training_iteration_time_ms": 59034.519, "restore_workers_time_ms": 0.015, "training_step_time_ms": 59034.42, "sample_time_ms": 1920.63, "learn_time_ms": 57086.547, "learn_throughput": 70.069, "synch_weights_time_ms": 21.046}, "counters": {"num_env_steps_sampled": 372000, "num_env_steps_trained": 372000, "num_agent_steps_sampled": 1488000, "num_agent_steps_trained": 1488000}, "done": false, "training_iteration": 93, "trial_id": "11e70_00000", "date": "2024-08-13_00-40-20", "timestamp": 1723524020, "time_this_iter_s": 53.7962110042572, "time_total_s": 5596.420412302017, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b4a5c820>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 5596.420412302017, "iterations_since_restore": 93, "perf": {"cpu_util_percent": 33.556578947368415, "ram_util_percent": 79.12763157894737}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 12.095034517245319, "cur_kl_coeff": 0.22500000000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.225703960247142, "policy_loss": -0.005631720600156951, "vf_loss": 8.230415090177425, "vf_explained_var": 0.13139607874804704, "kl": 0.004091596774393262, "entropy": 0.7388448711740907, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 176715.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 7.762588469692008, "cur_kl_coeff": 0.16875, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.817116943490568, "policy_loss": -0.011483442664107002, "vf_loss": 6.826934491011201, "vf_explained_var": -0.4823822645913987, "kl": 0.009871949532253132, "entropy": 0.9593385748446934, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 176715.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 376000, "num_env_steps_trained": 376000, "num_agent_steps_sampled": 1504000, "num_agent_steps_trained": 1504000}, "env_runners": {"episode_reward_max": 295.2, "episode_reward_min": -439.0, "episode_reward_mean": -45.897000000000006, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -394.9, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 147.2, "predator_policy": 198.0}, "policy_reward_mean": {"prey_policy": -109.23849999999999, "predator_policy": 86.29}, "custom_metrics": {}, "hist_stats": {"episode_reward": [146.50000000000003, -53.099999999999966, 1.500000000000229, 6.499999999999953, -68.50000000000117, 99.99999999999964, 87.80000000000011, -156.99999999999994, 41.30000000000018, -6.8999999999998, -59.999999999999794, 2.7000000000000384, 106.2999999999997, 17.000000000000217, -178.6, 1.8000000000000702, 13.600000000000012, 106.0, -85.3, 76.00000000000009, -74.8, -57.29999999999987, -116.70000000000057, 147.1999999999993, 222.09999999999997, -65.49999999999991, 139.1, 47.10000000000001, 5.500000000000101, -134.69999999999993, 44.79999999999998, 49.00000000000014, 18.000000000000163, -239.9, -178.4, -43.0, 113.5, 72.3999999999996, -242.29999999999995, 295.2, -135.1, 35.0, -47.39999999999989, -42.4, -282.7, 37.80000000000027, -126.0, -86.00000000000023, -286.5, -37.99999999999986, 40.0000000000003, -347.9, -239.0, -161.8, 13.100000000000124, -374.7, 177.7, 40.0000000000003, -70.00000000000003, -60.799999999999955, -239.39999999999998, 68.09999999999985, -58.999999999999844, -107.90000000000005, -288.7, 34.5, -35.899999999999906, 31.800000000000004, 162.39999999999947, -17.299999999999937, 34.50000000000022, 48.500000000000256, -17.399999999999906, -36.99999999999992, -218.9, -180.4, 0.5000000000000727, -32.99999999999982, 40.0000000000003, 26.70000000000008, -95.00000000000014, -366.4, 36.70000000000025, -58.9999999999998, -66.99999999999983, 54.000000000000064, 14.2, -51.99999999999991, 87.2, -439.0, -162.00000000000057, 43.79999999999983, -83.00000000000054, -331.0, 5.99999999999997, -308.0, -103.2, 26.000000000000004, -223.30000000000004, 74.99999999999997], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [29.0, 15.5, -39.099999999999994, -178.0, -3.099999999999965, -9.399999999999862, -230.5, 20.000000000000014, -124.90000000000057, -55.59999999999985, 20.000000000000014, 20.0, -47.2, 31.99999999999998, -148.0, -139.0, 20.000000000000014, -66.7, -139.9, 20.000000000000014, -229.0, 20.000000000000014, -277.6, 50.3, 65.89999999999999, 7.399999999999965, 20.000000000000014, -118.0, -127.0, -220.6, 13.69999999999997, -121.9, 20.000000000000014, -30.39999999999975, -25.0, 14.0, -142.0, -199.3, -16.0, 20.000000000000014, -161.20000000000002, -178.6, 20.000000000000014, -214.3, -381.7, 20.000000000000014, 1.0999999999999688, 106.1, 123.80000000000001, 41.3, -272.5, 20.000000000000014, 62.0, -10.899999999999999, -58.600000000000016, -106.3, -74.50000000000003, 20.000000000000014, -51.70000000000003, -250.0, 8.0, -71.2, 20.000000000000014, -52.0, 20.000000000000014, -172.0, -262.9, -178.0, -145.0, -165.4, 20.000000000000014, -286.0, 69.2, -27.700000000000003, 20.000000000000014, -19.6, -214.3, -199.0, 104.0, 147.2, -194.8, -157.3, 20.000000000000014, -148.0, -190.0, -9.399999999999855, -5.5, -298.9, -256.0, -255.7, 20.000000000000014, 15.799999999999963, -178.0, -136.0, -376.0, 20.000000000000014, -331.9, -226.6, 20.000000000000014, -328.0, 20.000000000000014, 20.000000000000014, -310.0, -319.9, -187.0, -250.0, -132.7, -267.1, 20.000000000000014, -109.9, -292.0, -339.7, 61.69999999999999, 71.0, 20.000000000000014, 20.000000000000014, -310.9, -9.1, -85.00000000000003, -146.8, -265.0, -252.4, -181.9, 20.000000000000014, -292.0, 20.000000000000014, -115.90000000000003, -271.0, -221.8, -331.9, -5.800000000000001, -87.7, -124.90000000000015, 20.000000000000014, 90.49999999999997, -315.7, 20.000000000000014, 142.39999999999998, -146.8, 9.499999999999964, 9.499999999999964, 20.000000000000014, -200.5, 20.000000000000014, -174.40000000000003, 20.000000000000014, 20.000000000000014, -214.0, -394.9, -184.0, -160.9, -284.5, -146.5, 20.000000000000014, 20.000000000000014, -292.0, 20.000000000000014, 20.000000000000014, -334.3, 20.000000000000014, 20.000000000000014, -310.0, -312.4, -376.0, 20.000000000000014, 13.699999999999964, -319.0, 20.000000000000014, 20.000000000000014, -367.0, -214.0, 20.000000000000014, -319.0, 48.2, -292.0, 20.000000000000014, 77.60000000000001, -180.4, -352.0, -394.0, -373.0, 20.000000000000014, -56.19999999999998, 20.000000000000014, 20.000000000000014, -373.0, -343.0, -280.0, 20.000000000000014, -304.0, -316.0, -274.0, -181.3, -247.9, 40.70000000000001, -300.7, -217.60000000000005, -270.7, -283.0, 50.00000000000001], "policy_predator_policy_reward": [20.0, 82.0, 127.0, 37.0, 0.0, 14.0, 107.0, 110.0, 47.0, 65.0, 0.0, 60.0, 52.0, 51.0, 105.0, 25.0, 86.0, 2.0, 0.0, 113.0, 103.0, 46.0, 82.0, 148.0, 33.0, 0.0, 50.0, 65.0, 102.0, 67.0, 10.0, 100.0, 24.0, 0.0, 28.0, 89.0, 129.0, 127.0, 0.0, 72.0, 167.0, 98.0, 90.0, 47.0, 69.0, 176.0, 40.0, 0.0, 0.0, 57.0, 123.0, 64.0, 88.0, 0.0, 105.0, 107.0, 13.0, 47.0, 71.0, 96.0, 84.0, 24.0, 32.0, 49.0, 110.0, 60.0, 106.0, 95.0, 7.0, 125.0, 119.0, 104.0, 72.0, 0.0, 0.0, 72.0, 107.0, 64.0, 44.0, 0.0, 97.0, 120.0, 74.0, 89.0, 63.0, 89.0, 130.0, 132.0, 117.0, 112.0, 0.0, 2.0, 86.0, 102.0, 118.0, 152.0, 127.0, 145.0, 131.0, 139.0, 0.0, 0.0, 172.0, 110.0, 159.0, 39.0, 147.0, 91.0, 71.0, 32.0, 138.0, 119.0, 0.0, 45.0, 0.0, 0.0, 140.0, 110.0, 97.0, 74.0, 146.0, 132.0, 126.0, 104.0, 88.0, 125.0, 161.0, 118.0, 149.0, 116.0, 128.0, 0.0, 68.0, 1.0, 117.0, 140.0, 0.0, 0.0, 0.0, 120.0, 0.0, 5.0, 110.0, 119.0, 90.0, 47.0, 63.0, 94.0, 178.0, 182.0, 145.0, 120.0, 75.0, 52.0, 134.0, 105.0, 0.0, 0.0, 174.0, 167.0, 120.0, 75.0, 157.0, 165.0, 3.0, 0.0, 173.0, 67.0, 182.0, 98.0, 131.0, 117.0, 144.0, 141.0, 79.0, 141.0, 105.0, 85.0, 109.0, 198.0, 191.0, 0.0, 80.0, 0.0, 176.0, 94.0, 162.0, 130.0, 163.0, 127.0, 127.0, 155.0, 149.0, 177.0, 155.0, 131.0, 108.0, 157.0, 157.0, 151.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.08644013318152, "mean_inference_ms": 2.6524771065971366, "mean_action_processing_ms": 0.4299143648924392, "mean_env_wait_ms": 0.3373089250998942, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.008749723434448242, "StateBufferConnector_ms": 0.007066011428833008, "ViewRequirementAgentConnector_ms": 0.14982950687408447}, "num_episodes": 22, "episode_return_max": 295.2, "episode_return_min": -439.0, "episode_return_mean": -45.897000000000006, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1504000, "num_agent_steps_trained": 1504000, "num_env_steps_sampled": 376000, "num_env_steps_trained": 376000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 74.94507050912725, "num_env_steps_trained_throughput_per_sec": 74.94507050912725, "timesteps_total": 376000, "num_env_steps_sampled_lifetime": 376000, "num_agent_steps_sampled_lifetime": 1504000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1504000, "timers": {"training_iteration_time_ms": 58814.503, "restore_workers_time_ms": 0.014, "training_step_time_ms": 58814.401, "sample_time_ms": 1825.334, "learn_time_ms": 56960.805, "learn_throughput": 70.224, "synch_weights_time_ms": 21.624}, "counters": {"num_env_steps_sampled": 376000, "num_env_steps_trained": 376000, "num_agent_steps_sampled": 1504000, "num_agent_steps_trained": 1504000}, "done": false, "training_iteration": 94, "trial_id": "11e70_00000", "date": "2024-08-13_00-41-13", "timestamp": 1723524073, "time_this_iter_s": 53.405292987823486, "time_total_s": 5649.825705289841, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2b06160>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 5649.825705289841, "iterations_since_restore": 94, "perf": {"cpu_util_percent": 28.840789473684207, "ram_util_percent": 76.93552631578947}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 9.884712156543026, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.114564918336415, "policy_loss": -0.008048550130691005, "vf_loss": 6.121916212858977, "vf_explained_var": 0.17490572068426344, "kl": 0.006197854353365175, "entropy": 0.7459636532440388, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 178605.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 14.095311883328453, "cur_kl_coeff": 0.16875, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.185354549796493, "policy_loss": -0.014824708363179255, "vf_loss": 5.198259380885533, "vf_explained_var": -0.15857873710374984, "kl": 0.0113769097665314, "entropy": 0.9317585687788706, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 178605.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 380000, "num_env_steps_trained": 380000, "num_agent_steps_sampled": 1520000, "num_agent_steps_trained": 1520000}, "env_runners": {"episode_reward_max": 295.2, "episode_reward_min": -439.0, "episode_reward_mean": -37.69700000000002, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 184.7, "predator_policy": 198.0}, "policy_reward_mean": {"prey_policy": -111.50349999999999, "predator_policy": 92.655}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-85.3, 76.00000000000009, -74.8, -57.29999999999987, -116.70000000000057, 147.1999999999993, 222.09999999999997, -65.49999999999991, 139.1, 47.10000000000001, 5.500000000000101, -134.69999999999993, 44.79999999999998, 49.00000000000014, 18.000000000000163, -239.9, -178.4, -43.0, 113.5, 72.3999999999996, -242.29999999999995, 295.2, -135.1, 35.0, -47.39999999999989, -42.4, -282.7, 37.80000000000027, -126.0, -86.00000000000023, -286.5, -37.99999999999986, 40.0000000000003, -347.9, -239.0, -161.8, 13.100000000000124, -374.7, 177.7, 40.0000000000003, -70.00000000000003, -60.799999999999955, -239.39999999999998, 68.09999999999985, -58.999999999999844, -107.90000000000005, -288.7, 34.5, -35.899999999999906, 31.800000000000004, 162.39999999999947, -17.299999999999937, 34.50000000000022, 48.500000000000256, -17.399999999999906, -36.99999999999992, -218.9, -180.4, 0.5000000000000727, -32.99999999999982, 40.0000000000003, 26.70000000000008, -95.00000000000014, -366.4, 36.70000000000025, -58.9999999999998, -66.99999999999983, 54.000000000000064, 14.2, -51.99999999999991, 87.2, -439.0, -162.00000000000057, 43.79999999999983, -83.00000000000054, -331.0, 5.99999999999997, -308.0, -103.2, 26.000000000000004, -223.30000000000004, 74.99999999999997, 81.59999999999994, -61.99999999999984, 256.5999999999999, -52.999999999999986, 207.69999999999996, 5.699999999999966, -30.899999999999842, 1.9999999999999631, 145.3999999999997, 54.00000000000026, 181.8, 201.59999999999926, -311.0, 177.7999999999992, 45.90000000000023, 40.0000000000003, 99.0999999999998, -115.40000000000077], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-142.0, -199.3, -16.0, 20.000000000000014, -161.20000000000002, -178.6, 20.000000000000014, -214.3, -381.7, 20.000000000000014, 1.0999999999999688, 106.1, 123.80000000000001, 41.3, -272.5, 20.000000000000014, 62.0, -10.899999999999999, -58.600000000000016, -106.3, -74.50000000000003, 20.000000000000014, -51.70000000000003, -250.0, 8.0, -71.2, 20.000000000000014, -52.0, 20.000000000000014, -172.0, -262.9, -178.0, -145.0, -165.4, 20.000000000000014, -286.0, 69.2, -27.700000000000003, 20.000000000000014, -19.6, -214.3, -199.0, 104.0, 147.2, -194.8, -157.3, 20.000000000000014, -148.0, -190.0, -9.399999999999855, -5.5, -298.9, -256.0, -255.7, 20.000000000000014, 15.799999999999963, -178.0, -136.0, -376.0, 20.000000000000014, -331.9, -226.6, 20.000000000000014, -328.0, 20.000000000000014, 20.000000000000014, -310.0, -319.9, -187.0, -250.0, -132.7, -267.1, 20.000000000000014, -109.9, -292.0, -339.7, 61.69999999999999, 71.0, 20.000000000000014, 20.000000000000014, -310.9, -9.1, -85.00000000000003, -146.8, -265.0, -252.4, -181.9, 20.000000000000014, -292.0, 20.000000000000014, -115.90000000000003, -271.0, -221.8, -331.9, -5.800000000000001, -87.7, -124.90000000000015, 20.000000000000014, 90.49999999999997, -315.7, 20.000000000000014, 142.39999999999998, -146.8, 9.499999999999964, 9.499999999999964, 20.000000000000014, -200.5, 20.000000000000014, -174.40000000000003, 20.000000000000014, 20.000000000000014, -214.0, -394.9, -184.0, -160.9, -284.5, -146.5, 20.000000000000014, 20.000000000000014, -292.0, 20.000000000000014, 20.000000000000014, -334.3, 20.000000000000014, 20.000000000000014, -310.0, -312.4, -376.0, 20.000000000000014, 13.699999999999964, -319.0, 20.000000000000014, 20.000000000000014, -367.0, -214.0, 20.000000000000014, -319.0, 48.2, -292.0, 20.000000000000014, 77.60000000000001, -180.4, -352.0, -394.0, -373.0, 20.000000000000014, -56.19999999999998, 20.000000000000014, 20.000000000000014, -373.0, -343.0, -280.0, 20.000000000000014, -304.0, -316.0, -274.0, -181.3, -247.9, 40.70000000000001, -300.7, -217.60000000000005, -270.7, -283.0, 50.00000000000001, 20.000000000000014, 35.60000000000015, -388.0, 20.000000000000014, 109.4, 108.19999999999997, 20.000000000000014, -400.0, -295.0, 184.7, -7.299999999999891, -73.00000000000003, 28.099999999999987, -358.0, 20.000000000000014, -376.0, 20.000000000000014, 31.400000000000006, -274.0, 20.000000000000014, -115.0, 105.8, 20.000000000000014, 179.59999999999997, -250.0, -352.0, 144.79999999999993, 20.000000000000014, 20.900000000000013, -256.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 31.100000000000044, -116.50000000000077, -334.9], "policy_predator_policy_reward": [129.0, 127.0, 0.0, 72.0, 167.0, 98.0, 90.0, 47.0, 69.0, 176.0, 40.0, 0.0, 0.0, 57.0, 123.0, 64.0, 88.0, 0.0, 105.0, 107.0, 13.0, 47.0, 71.0, 96.0, 84.0, 24.0, 32.0, 49.0, 110.0, 60.0, 106.0, 95.0, 7.0, 125.0, 119.0, 104.0, 72.0, 0.0, 0.0, 72.0, 107.0, 64.0, 44.0, 0.0, 97.0, 120.0, 74.0, 89.0, 63.0, 89.0, 130.0, 132.0, 117.0, 112.0, 0.0, 2.0, 86.0, 102.0, 118.0, 152.0, 127.0, 145.0, 131.0, 139.0, 0.0, 0.0, 172.0, 110.0, 159.0, 39.0, 147.0, 91.0, 71.0, 32.0, 138.0, 119.0, 0.0, 45.0, 0.0, 0.0, 140.0, 110.0, 97.0, 74.0, 146.0, 132.0, 126.0, 104.0, 88.0, 125.0, 161.0, 118.0, 149.0, 116.0, 128.0, 0.0, 68.0, 1.0, 117.0, 140.0, 0.0, 0.0, 0.0, 120.0, 0.0, 5.0, 110.0, 119.0, 90.0, 47.0, 63.0, 94.0, 178.0, 182.0, 145.0, 120.0, 75.0, 52.0, 134.0, 105.0, 0.0, 0.0, 174.0, 167.0, 120.0, 75.0, 157.0, 165.0, 3.0, 0.0, 173.0, 67.0, 182.0, 98.0, 131.0, 117.0, 144.0, 141.0, 79.0, 141.0, 105.0, 85.0, 109.0, 198.0, 191.0, 0.0, 80.0, 0.0, 176.0, 94.0, 162.0, 130.0, 163.0, 127.0, 127.0, 155.0, 149.0, 177.0, 155.0, 131.0, 108.0, 157.0, 157.0, 151.0, 7.0, 19.0, 116.0, 190.0, 26.0, 13.0, 184.0, 143.0, 154.0, 164.0, 16.0, 70.0, 173.0, 126.0, 170.0, 188.0, 42.0, 52.0, 155.0, 153.0, 114.0, 77.0, 2.0, 0.0, 143.0, 148.0, 13.0, 0.0, 142.0, 139.0, 0.0, 0.0, 19.0, 29.0, 159.0, 177.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.084111987932235, "mean_inference_ms": 2.646497755229333, "mean_action_processing_ms": 0.4289233862454166, "mean_env_wait_ms": 0.3366470060636994, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.009239554405212402, "StateBufferConnector_ms": 0.0068961381912231445, "ViewRequirementAgentConnector_ms": 0.16556239128112793}, "num_episodes": 18, "episode_return_max": 295.2, "episode_return_min": -439.0, "episode_return_mean": -37.69700000000002, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1520000, "num_agent_steps_trained": 1520000, "num_env_steps_sampled": 380000, "num_env_steps_trained": 380000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 75.13278957335645, "num_env_steps_trained_throughput_per_sec": 75.13278957335645, "timesteps_total": 380000, "num_env_steps_sampled_lifetime": 380000, "num_agent_steps_sampled_lifetime": 1520000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1520000, "timers": {"training_iteration_time_ms": 58195.907, "restore_workers_time_ms": 0.015, "training_step_time_ms": 58195.803, "sample_time_ms": 1905.961, "learn_time_ms": 56259.411, "learn_throughput": 71.099, "synch_weights_time_ms": 23.586}, "counters": {"num_env_steps_sampled": 380000, "num_env_steps_trained": 380000, "num_agent_steps_sampled": 1520000, "num_agent_steps_trained": 1520000}, "done": false, "training_iteration": 95, "trial_id": "11e70_00000", "date": "2024-08-13_00-42-07", "timestamp": 1723524127, "time_this_iter_s": 53.257648229599, "time_total_s": 5703.08335351944, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b4a76a60>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 5703.08335351944, "iterations_since_restore": 95, "perf": {"cpu_util_percent": 32.348684210526315, "ram_util_percent": 80.0407894736842}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 9.501972322110776, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.473894259286305, "policy_loss": -0.008017856317261854, "vf_loss": 6.481207112155894, "vf_explained_var": 0.175123868953614, "kl": 0.006266790613420006, "entropy": 0.6926664007403863, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 180495.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 14.4604744879657, "cur_kl_coeff": 0.16875, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.795741751332763, "policy_loss": -0.013056029190885879, "vf_loss": 6.807321409699778, "vf_explained_var": 0.06396772546112223, "kl": 0.008748911932865255, "entropy": 0.9836491298423242, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 180495.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 384000, "num_env_steps_trained": 384000, "num_agent_steps_sampled": 1536000, "num_agent_steps_trained": 1536000}, "env_runners": {"episode_reward_max": 289.69999999999993, "episode_reward_min": -439.0, "episode_reward_mean": -12.839000000000024, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 184.7, "predator_policy": 198.0}, "policy_reward_mean": {"prey_policy": -96.26950000000001, "predator_policy": 89.85}, "custom_metrics": {}, "hist_stats": {"episode_reward": [35.0, -47.39999999999989, -42.4, -282.7, 37.80000000000027, -126.0, -86.00000000000023, -286.5, -37.99999999999986, 40.0000000000003, -347.9, -239.0, -161.8, 13.100000000000124, -374.7, 177.7, 40.0000000000003, -70.00000000000003, -60.799999999999955, -239.39999999999998, 68.09999999999985, -58.999999999999844, -107.90000000000005, -288.7, 34.5, -35.899999999999906, 31.800000000000004, 162.39999999999947, -17.299999999999937, 34.50000000000022, 48.500000000000256, -17.399999999999906, -36.99999999999992, -218.9, -180.4, 0.5000000000000727, -32.99999999999982, 40.0000000000003, 26.70000000000008, -95.00000000000014, -366.4, 36.70000000000025, -58.9999999999998, -66.99999999999983, 54.000000000000064, 14.2, -51.99999999999991, 87.2, -439.0, -162.00000000000057, 43.79999999999983, -83.00000000000054, -331.0, 5.99999999999997, -308.0, -103.2, 26.000000000000004, -223.30000000000004, 74.99999999999997, 81.59999999999994, -61.99999999999984, 256.5999999999999, -52.999999999999986, 207.69999999999996, 5.699999999999966, -30.899999999999842, 1.9999999999999631, 145.3999999999997, 54.00000000000026, 181.8, 201.59999999999926, -311.0, 177.7999999999992, 45.90000000000023, 40.0000000000003, 99.0999999999998, -115.40000000000077, 134.99999999999997, -17.70000000000001, 130.29999999999995, 47.0, -259.9, 100.79999999999998, 289.69999999999993, 12.099999999999994, 5.999999999999995, 99.69999999999993, 148.69999999999965, -29.299999999999713, 33.400000000000205, 70.39999999999998, 126.09999999999965, 268.5, 270.5, 194.49999999999926, -94.00000000000026, 251.4, 173.79999999999944, 210.3, 175.4000000000001], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, -148.0, -190.0, -9.399999999999855, -5.5, -298.9, -256.0, -255.7, 20.000000000000014, 15.799999999999963, -178.0, -136.0, -376.0, 20.000000000000014, -331.9, -226.6, 20.000000000000014, -328.0, 20.000000000000014, 20.000000000000014, -310.0, -319.9, -187.0, -250.0, -132.7, -267.1, 20.000000000000014, -109.9, -292.0, -339.7, 61.69999999999999, 71.0, 20.000000000000014, 20.000000000000014, -310.9, -9.1, -85.00000000000003, -146.8, -265.0, -252.4, -181.9, 20.000000000000014, -292.0, 20.000000000000014, -115.90000000000003, -271.0, -221.8, -331.9, -5.800000000000001, -87.7, -124.90000000000015, 20.000000000000014, 90.49999999999997, -315.7, 20.000000000000014, 142.39999999999998, -146.8, 9.499999999999964, 9.499999999999964, 20.000000000000014, -200.5, 20.000000000000014, -174.40000000000003, 20.000000000000014, 20.000000000000014, -214.0, -394.9, -184.0, -160.9, -284.5, -146.5, 20.000000000000014, 20.000000000000014, -292.0, 20.000000000000014, 20.000000000000014, -334.3, 20.000000000000014, 20.000000000000014, -310.0, -312.4, -376.0, 20.000000000000014, 13.699999999999964, -319.0, 20.000000000000014, 20.000000000000014, -367.0, -214.0, 20.000000000000014, -319.0, 48.2, -292.0, 20.000000000000014, 77.60000000000001, -180.4, -352.0, -394.0, -373.0, 20.000000000000014, -56.19999999999998, 20.000000000000014, 20.000000000000014, -373.0, -343.0, -280.0, 20.000000000000014, -304.0, -316.0, -274.0, -181.3, -247.9, 40.70000000000001, -300.7, -217.60000000000005, -270.7, -283.0, 50.00000000000001, 20.000000000000014, 35.60000000000015, -388.0, 20.000000000000014, 109.4, 108.19999999999997, 20.000000000000014, -400.0, -295.0, 184.7, -7.299999999999891, -73.00000000000003, 28.099999999999987, -358.0, 20.000000000000014, -376.0, 20.000000000000014, 31.400000000000006, -274.0, 20.000000000000014, -115.0, 105.8, 20.000000000000014, 179.59999999999997, -250.0, -352.0, 144.79999999999993, 20.000000000000014, 20.900000000000013, -256.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 31.100000000000044, -116.50000000000077, -334.9, 96.8, -164.8, -231.10000000000002, -49.600000000000016, 14.00000000000002, 23.30000000000001, -109.0, 38.0, -337.9, -217.0, -94.0, 60.79999999999998, 62.900000000000006, 162.79999999999995, -229.0, 46.10000000000001, -355.0, 20.000000000000014, 20.000000000000014, 22.69999999999999, 20.000000000000014, 88.7, -133.3000000000005, 20.000000000000014, 20.000000000000014, 7.399999999999965, -41.80000000000001, 6.200000000000022, 61.10000000000005, 20.000000000000014, 123.49999999999997, 80.0, 53.0, 153.5, 168.49999999999994, 20.000000000000014, 20.000000000000014, -400.0, 110.0, 94.4, 20.000000000000014, 147.79999999999998, 129.2, -64.9, 30.499999999999957, 92.89999999999998], "policy_predator_policy_reward": [74.0, 89.0, 63.0, 89.0, 130.0, 132.0, 117.0, 112.0, 0.0, 2.0, 86.0, 102.0, 118.0, 152.0, 127.0, 145.0, 131.0, 139.0, 0.0, 0.0, 172.0, 110.0, 159.0, 39.0, 147.0, 91.0, 71.0, 32.0, 138.0, 119.0, 0.0, 45.0, 0.0, 0.0, 140.0, 110.0, 97.0, 74.0, 146.0, 132.0, 126.0, 104.0, 88.0, 125.0, 161.0, 118.0, 149.0, 116.0, 128.0, 0.0, 68.0, 1.0, 117.0, 140.0, 0.0, 0.0, 0.0, 120.0, 0.0, 5.0, 110.0, 119.0, 90.0, 47.0, 63.0, 94.0, 178.0, 182.0, 145.0, 120.0, 75.0, 52.0, 134.0, 105.0, 0.0, 0.0, 174.0, 167.0, 120.0, 75.0, 157.0, 165.0, 3.0, 0.0, 173.0, 67.0, 182.0, 98.0, 131.0, 117.0, 144.0, 141.0, 79.0, 141.0, 105.0, 85.0, 109.0, 198.0, 191.0, 0.0, 80.0, 0.0, 176.0, 94.0, 162.0, 130.0, 163.0, 127.0, 127.0, 155.0, 149.0, 177.0, 155.0, 131.0, 108.0, 157.0, 157.0, 151.0, 7.0, 19.0, 116.0, 190.0, 26.0, 13.0, 184.0, 143.0, 154.0, 164.0, 16.0, 70.0, 173.0, 126.0, 170.0, 188.0, 42.0, 52.0, 155.0, 153.0, 114.0, 77.0, 2.0, 0.0, 143.0, 148.0, 13.0, 0.0, 142.0, 139.0, 0.0, 0.0, 19.0, 29.0, 159.0, 177.0, 108.0, 95.0, 129.0, 134.0, 18.0, 75.0, 51.0, 67.0, 127.0, 168.0, 73.0, 61.0, 44.0, 20.0, 67.0, 128.0, 185.0, 156.0, 19.0, 38.0, 15.0, 25.0, 11.0, 73.0, 6.0, 0.0, 15.0, 91.0, 33.0, 12.0, 48.0, 17.0, 22.0, 42.0, 6.0, 0.0, 140.0, 146.0, 27.0, 20.0, 6.0, 0.0, 62.0, 84.0, 43.0, 9.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0805777495364886, "mean_inference_ms": 2.637931662472999, "mean_action_processing_ms": 0.42749979769074764, "mean_env_wait_ms": 0.33569941062272923, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007604479789733887, "StateBufferConnector_ms": 0.0037250518798828125, "ViewRequirementAgentConnector_ms": 0.16204333305358887}, "num_episodes": 23, "episode_return_max": 289.69999999999993, "episode_return_min": -439.0, "episode_return_mean": -12.839000000000024, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1536000, "num_agent_steps_trained": 1536000, "num_env_steps_sampled": 384000, "num_env_steps_trained": 384000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 68.4491612772401, "num_env_steps_trained_throughput_per_sec": 68.4491612772401, "timesteps_total": 384000, "num_env_steps_sampled_lifetime": 384000, "num_agent_steps_sampled_lifetime": 1536000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1536000, "timers": {"training_iteration_time_ms": 58402.771, "restore_workers_time_ms": 0.015, "training_step_time_ms": 58402.666, "sample_time_ms": 1901.036, "learn_time_ms": 56472.456, "learn_throughput": 70.831, "synch_weights_time_ms": 22.428}, "counters": {"num_env_steps_sampled": 384000, "num_env_steps_trained": 384000, "num_agent_steps_sampled": 1536000, "num_agent_steps_trained": 1536000}, "done": false, "training_iteration": 96, "trial_id": "11e70_00000", "date": "2024-08-13_00-43-05", "timestamp": 1723524185, "time_this_iter_s": 58.58471083641052, "time_total_s": 5761.66806435585, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3f1d8b0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 5761.66806435585, "iterations_since_restore": 96, "perf": {"cpu_util_percent": 47.10120481927711, "ram_util_percent": 83.34578313253013}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 8.516269556807462, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.044503009634674, "policy_loss": -0.010369154908410987, "vf_loss": 6.054073946564285, "vf_explained_var": 0.06431389236576343, "kl": 0.007095141737816636, "entropy": 0.7186650527848137, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 182385.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 12.630051551672517, "cur_kl_coeff": 0.16875, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.4809852630373035, "policy_loss": -0.012735092115992552, "vf_loss": 6.492131440349357, "vf_explained_var": -0.02197566104944421, "kl": 0.009415734598176682, "entropy": 0.9478171374431994, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 182385.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 388000, "num_env_steps_trained": 388000, "num_agent_steps_sampled": 1552000, "num_agent_steps_trained": 1552000}, "env_runners": {"episode_reward_max": 289.69999999999993, "episode_reward_min": -439.0, "episode_reward_mean": 25.536999999999964, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 184.7, "predator_policy": 198.0}, "policy_reward_mean": {"prey_policy": -69.1465, "predator_policy": 81.915}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-60.799999999999955, -239.39999999999998, 68.09999999999985, -58.999999999999844, -107.90000000000005, -288.7, 34.5, -35.899999999999906, 31.800000000000004, 162.39999999999947, -17.299999999999937, 34.50000000000022, 48.500000000000256, -17.399999999999906, -36.99999999999992, -218.9, -180.4, 0.5000000000000727, -32.99999999999982, 40.0000000000003, 26.70000000000008, -95.00000000000014, -366.4, 36.70000000000025, -58.9999999999998, -66.99999999999983, 54.000000000000064, 14.2, -51.99999999999991, 87.2, -439.0, -162.00000000000057, 43.79999999999983, -83.00000000000054, -331.0, 5.99999999999997, -308.0, -103.2, 26.000000000000004, -223.30000000000004, 74.99999999999997, 81.59999999999994, -61.99999999999984, 256.5999999999999, -52.999999999999986, 207.69999999999996, 5.699999999999966, -30.899999999999842, 1.9999999999999631, 145.3999999999997, 54.00000000000026, 181.8, 201.59999999999926, -311.0, 177.7999999999992, 45.90000000000023, 40.0000000000003, 99.0999999999998, -115.40000000000077, 134.99999999999997, -17.70000000000001, 130.29999999999995, 47.0, -259.9, 100.79999999999998, 289.69999999999993, 12.099999999999994, 5.999999999999995, 99.69999999999993, 148.69999999999965, -29.299999999999713, 33.400000000000205, 70.39999999999998, 126.09999999999965, 268.5, 270.5, 194.49999999999926, -94.00000000000026, 251.4, 173.79999999999944, 210.3, 175.4000000000001, 115.19999999999956, 98.30000000000001, 214.0, 182.29999999999995, 51.20000000000005, 39.30000000000018, 222.59999999999997, 44.00000000000013, 128.19999999999965, 221.19999999999996, 28.400000000000063, 119.29999999999984, -1.4999999999999716, 40.0000000000003, 59.500000000000014, 97.19999999999999, 280.79999999999995, 138.8], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-85.00000000000003, -146.8, -265.0, -252.4, -181.9, 20.000000000000014, -292.0, 20.000000000000014, -115.90000000000003, -271.0, -221.8, -331.9, -5.800000000000001, -87.7, -124.90000000000015, 20.000000000000014, 90.49999999999997, -315.7, 20.000000000000014, 142.39999999999998, -146.8, 9.499999999999964, 9.499999999999964, 20.000000000000014, -200.5, 20.000000000000014, -174.40000000000003, 20.000000000000014, 20.000000000000014, -214.0, -394.9, -184.0, -160.9, -284.5, -146.5, 20.000000000000014, 20.000000000000014, -292.0, 20.000000000000014, 20.000000000000014, -334.3, 20.000000000000014, 20.000000000000014, -310.0, -312.4, -376.0, 20.000000000000014, 13.699999999999964, -319.0, 20.000000000000014, 20.000000000000014, -367.0, -214.0, 20.000000000000014, -319.0, 48.2, -292.0, 20.000000000000014, 77.60000000000001, -180.4, -352.0, -394.0, -373.0, 20.000000000000014, -56.19999999999998, 20.000000000000014, 20.000000000000014, -373.0, -343.0, -280.0, 20.000000000000014, -304.0, -316.0, -274.0, -181.3, -247.9, 40.70000000000001, -300.7, -217.60000000000005, -270.7, -283.0, 50.00000000000001, 20.000000000000014, 35.60000000000015, -388.0, 20.000000000000014, 109.4, 108.19999999999997, 20.000000000000014, -400.0, -295.0, 184.7, -7.299999999999891, -73.00000000000003, 28.099999999999987, -358.0, 20.000000000000014, -376.0, 20.000000000000014, 31.400000000000006, -274.0, 20.000000000000014, -115.0, 105.8, 20.000000000000014, 179.59999999999997, -250.0, -352.0, 144.79999999999993, 20.000000000000014, 20.900000000000013, -256.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 31.100000000000044, -116.50000000000077, -334.9, 96.8, -164.8, -231.10000000000002, -49.600000000000016, 14.00000000000002, 23.30000000000001, -109.0, 38.0, -337.9, -217.0, -94.0, 60.79999999999998, 62.900000000000006, 162.79999999999995, -229.0, 46.10000000000001, -355.0, 20.000000000000014, 20.000000000000014, 22.69999999999999, 20.000000000000014, 88.7, -133.3000000000005, 20.000000000000014, 20.000000000000014, 7.399999999999965, -41.80000000000001, 6.200000000000022, 61.10000000000005, 20.000000000000014, 123.49999999999997, 80.0, 53.0, 153.5, 168.49999999999994, 20.000000000000014, 20.000000000000014, -400.0, 110.0, 94.4, 20.000000000000014, 147.79999999999998, 129.2, -64.9, 30.499999999999957, 92.89999999999998, 20.000000000000014, 57.2, 17.0, -45.7, 113.0, -1.0, 41.0, 74.29999999999998, 20.000000000000014, -56.80000000000001, 20.000000000000014, -108.7, 46.1, 93.5, 20.000000000000014, -64.0, 20.000000000000014, 66.2, 104.6, 47.6, -127.6, 20.000000000000014, 50.3, 20.000000000000014, -113.5, -19.0, 20.000000000000014, 20.000000000000014, 52.4, -103.90000000000006, -111.70000000000005, 59.9, 109.1, 118.69999999999999, -28.900000000000006, 34.7], "policy_predator_policy_reward": [97.0, 74.0, 146.0, 132.0, 126.0, 104.0, 88.0, 125.0, 161.0, 118.0, 149.0, 116.0, 128.0, 0.0, 68.0, 1.0, 117.0, 140.0, 0.0, 0.0, 0.0, 120.0, 0.0, 5.0, 110.0, 119.0, 90.0, 47.0, 63.0, 94.0, 178.0, 182.0, 145.0, 120.0, 75.0, 52.0, 134.0, 105.0, 0.0, 0.0, 174.0, 167.0, 120.0, 75.0, 157.0, 165.0, 3.0, 0.0, 173.0, 67.0, 182.0, 98.0, 131.0, 117.0, 144.0, 141.0, 79.0, 141.0, 105.0, 85.0, 109.0, 198.0, 191.0, 0.0, 80.0, 0.0, 176.0, 94.0, 162.0, 130.0, 163.0, 127.0, 127.0, 155.0, 149.0, 177.0, 155.0, 131.0, 108.0, 157.0, 157.0, 151.0, 7.0, 19.0, 116.0, 190.0, 26.0, 13.0, 184.0, 143.0, 154.0, 164.0, 16.0, 70.0, 173.0, 126.0, 170.0, 188.0, 42.0, 52.0, 155.0, 153.0, 114.0, 77.0, 2.0, 0.0, 143.0, 148.0, 13.0, 0.0, 142.0, 139.0, 0.0, 0.0, 19.0, 29.0, 159.0, 177.0, 108.0, 95.0, 129.0, 134.0, 18.0, 75.0, 51.0, 67.0, 127.0, 168.0, 73.0, 61.0, 44.0, 20.0, 67.0, 128.0, 185.0, 156.0, 19.0, 38.0, 15.0, 25.0, 11.0, 73.0, 6.0, 0.0, 15.0, 91.0, 33.0, 12.0, 48.0, 17.0, 22.0, 42.0, 6.0, 0.0, 140.0, 146.0, 27.0, 20.0, 6.0, 0.0, 62.0, 84.0, 43.0, 9.0, 38.0, 0.0, 91.0, 36.0, 55.0, 47.0, 43.0, 24.0, 66.0, 22.0, 57.0, 71.0, 36.0, 47.0, 43.0, 45.0, 21.0, 21.0, 20.0, 49.0, 72.0, 64.0, 49.0, 0.0, 70.0, 61.0, 0.0, 0.0, 22.0, 89.0, 81.0, 68.0, 40.0, 13.0, 47.0, 86.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.077960016109502, "mean_inference_ms": 2.631602212147856, "mean_action_processing_ms": 0.42639049434305853, "mean_env_wait_ms": 0.33497078400627217, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0069773197174072266, "StateBufferConnector_ms": 0.003640294075012207, "ViewRequirementAgentConnector_ms": 0.1591811180114746}, "num_episodes": 18, "episode_return_max": 289.69999999999993, "episode_return_min": -439.0, "episode_return_mean": 25.536999999999964, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1552000, "num_agent_steps_trained": 1552000, "num_env_steps_sampled": 388000, "num_env_steps_trained": 388000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 74.32426481768954, "num_env_steps_trained_throughput_per_sec": 74.32426481768954, "timesteps_total": 388000, "num_env_steps_sampled_lifetime": 388000, "num_agent_steps_sampled_lifetime": 1552000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1552000, "timers": {"training_iteration_time_ms": 57927.093, "restore_workers_time_ms": 0.023, "training_step_time_ms": 57926.981, "sample_time_ms": 1867.995, "learn_time_ms": 56033.27, "learn_throughput": 71.386, "synch_weights_time_ms": 21.153}, "counters": {"num_env_steps_sampled": 388000, "num_env_steps_trained": 388000, "num_agent_steps_sampled": 1552000, "num_agent_steps_trained": 1552000}, "done": false, "training_iteration": 97, "trial_id": "11e70_00000", "date": "2024-08-13_00-43-59", "timestamp": 1723524239, "time_this_iter_s": 53.85355496406555, "time_total_s": 5815.521619319916, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2b064c0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 5815.521619319916, "iterations_since_restore": 97, "perf": {"cpu_util_percent": 41.40394736842106, "ram_util_percent": 76.90526315789474}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 7.247671378920318, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.595760278348569, "policy_loss": -0.011148846500045644, "vf_loss": 6.605821148806779, "vf_explained_var": 0.1336843145587457, "kl": 0.00967096733519598, "entropy": 0.7681537317220496, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 184275.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 10.297144948174713, "cur_kl_coeff": 0.16875, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.522666519659537, "policy_loss": -0.01087550901519578, "vf_loss": 6.532020603412043, "vf_explained_var": -0.36960770408943217, "kl": 0.009015967532615255, "entropy": 0.9557165754535211, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 184275.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 392000, "num_env_steps_trained": 392000, "num_agent_steps_sampled": 1568000, "num_agent_steps_trained": 1568000}, "env_runners": {"episode_reward_max": 289.69999999999993, "episode_reward_min": -439.0, "episode_reward_mean": 53.31699999999994, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 184.7, "predator_policy": 198.0}, "policy_reward_mean": {"prey_policy": -46.70650000000001, "predator_policy": 73.365}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-366.4, 36.70000000000025, -58.9999999999998, -66.99999999999983, 54.000000000000064, 14.2, -51.99999999999991, 87.2, -439.0, -162.00000000000057, 43.79999999999983, -83.00000000000054, -331.0, 5.99999999999997, -308.0, -103.2, 26.000000000000004, -223.30000000000004, 74.99999999999997, 81.59999999999994, -61.99999999999984, 256.5999999999999, -52.999999999999986, 207.69999999999996, 5.699999999999966, -30.899999999999842, 1.9999999999999631, 145.3999999999997, 54.00000000000026, 181.8, 201.59999999999926, -311.0, 177.7999999999992, 45.90000000000023, 40.0000000000003, 99.0999999999998, -115.40000000000077, 134.99999999999997, -17.70000000000001, 130.29999999999995, 47.0, -259.9, 100.79999999999998, 289.69999999999993, 12.099999999999994, 5.999999999999995, 99.69999999999993, 148.69999999999965, -29.299999999999713, 33.400000000000205, 70.39999999999998, 126.09999999999965, 268.5, 270.5, 194.49999999999926, -94.00000000000026, 251.4, 173.79999999999944, 210.3, 175.4000000000001, 115.19999999999956, 98.30000000000001, 214.0, 182.29999999999995, 51.20000000000005, 39.30000000000018, 222.59999999999997, 44.00000000000013, 128.19999999999965, 221.19999999999996, 28.400000000000063, 119.29999999999984, -1.4999999999999716, 40.0000000000003, 59.500000000000014, 97.19999999999999, 280.79999999999995, 138.8, 254.19999999999993, 36.70000000000025, 155.99999999999946, -2.8999999999999715, 27.000000000000114, 199.89999999999998, 173.89999999999986, 81.7, -22.5, 67.20000000000013, 40.0000000000003, 120.99999999999997, -5.900000000000091, 179.29999999999995, 83.70000000000002, 137.29999999999995, -39.79999999999997, 11.5, 131.79999999999964, -13.999999999999979, 60.999999999999915, 157.2], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-312.4, -376.0, 20.000000000000014, 13.699999999999964, -319.0, 20.000000000000014, 20.000000000000014, -367.0, -214.0, 20.000000000000014, -319.0, 48.2, -292.0, 20.000000000000014, 77.60000000000001, -180.4, -352.0, -394.0, -373.0, 20.000000000000014, -56.19999999999998, 20.000000000000014, 20.000000000000014, -373.0, -343.0, -280.0, 20.000000000000014, -304.0, -316.0, -274.0, -181.3, -247.9, 40.70000000000001, -300.7, -217.60000000000005, -270.7, -283.0, 50.00000000000001, 20.000000000000014, 35.60000000000015, -388.0, 20.000000000000014, 109.4, 108.19999999999997, 20.000000000000014, -400.0, -295.0, 184.7, -7.299999999999891, -73.00000000000003, 28.099999999999987, -358.0, 20.000000000000014, -376.0, 20.000000000000014, 31.400000000000006, -274.0, 20.000000000000014, -115.0, 105.8, 20.000000000000014, 179.59999999999997, -250.0, -352.0, 144.79999999999993, 20.000000000000014, 20.900000000000013, -256.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 31.100000000000044, -116.50000000000077, -334.9, 96.8, -164.8, -231.10000000000002, -49.600000000000016, 14.00000000000002, 23.30000000000001, -109.0, 38.0, -337.9, -217.0, -94.0, 60.79999999999998, 62.900000000000006, 162.79999999999995, -229.0, 46.10000000000001, -355.0, 20.000000000000014, 20.000000000000014, 22.69999999999999, 20.000000000000014, 88.7, -133.3000000000005, 20.000000000000014, 20.000000000000014, 7.399999999999965, -41.80000000000001, 6.200000000000022, 61.10000000000005, 20.000000000000014, 123.49999999999997, 80.0, 53.0, 153.5, 168.49999999999994, 20.000000000000014, 20.000000000000014, -400.0, 110.0, 94.4, 20.000000000000014, 147.79999999999998, 129.2, -64.9, 30.499999999999957, 92.89999999999998, 20.000000000000014, 57.2, 17.0, -45.7, 113.0, -1.0, 41.0, 74.29999999999998, 20.000000000000014, -56.80000000000001, 20.000000000000014, -108.7, 46.1, 93.5, 20.000000000000014, -64.0, 20.000000000000014, 66.2, 104.6, 47.6, -127.6, 20.000000000000014, 50.3, 20.000000000000014, -113.5, -19.0, 20.000000000000014, 20.000000000000014, 52.4, -103.90000000000006, -111.70000000000005, 59.9, 109.1, 118.69999999999999, -28.900000000000006, 34.7, 94.39999999999999, 141.79999999999995, 20.000000000000014, 13.699999999999964, 20.000000000000014, 71.0, 20.000000000000014, -163.89999999999998, 20.000000000000014, -115.0, 53.0, 50.89999999999998, 57.20000000000002, 46.7, 56.29999999999998, -124.6, -77.5, -121.0, 20.000000000000014, -56.8, 20.000000000000014, 20.000000000000014, 151.99999999999997, -337.0, -50.500000000000014, -54.4, 63.5, 24.799999999999997, 88.7, -181.0, 38.0, -36.699999999999996, -112.0, -47.8, -63.4, -39.099999999999994, 36.8, 20.000000000000014, -151.0, 20.000000000000014, -49.0, 20.000000000000014, -16.0, 87.2], "policy_predator_policy_reward": [157.0, 165.0, 3.0, 0.0, 173.0, 67.0, 182.0, 98.0, 131.0, 117.0, 144.0, 141.0, 79.0, 141.0, 105.0, 85.0, 109.0, 198.0, 191.0, 0.0, 80.0, 0.0, 176.0, 94.0, 162.0, 130.0, 163.0, 127.0, 127.0, 155.0, 149.0, 177.0, 155.0, 131.0, 108.0, 157.0, 157.0, 151.0, 7.0, 19.0, 116.0, 190.0, 26.0, 13.0, 184.0, 143.0, 154.0, 164.0, 16.0, 70.0, 173.0, 126.0, 170.0, 188.0, 42.0, 52.0, 155.0, 153.0, 114.0, 77.0, 2.0, 0.0, 143.0, 148.0, 13.0, 0.0, 142.0, 139.0, 0.0, 0.0, 19.0, 29.0, 159.0, 177.0, 108.0, 95.0, 129.0, 134.0, 18.0, 75.0, 51.0, 67.0, 127.0, 168.0, 73.0, 61.0, 44.0, 20.0, 67.0, 128.0, 185.0, 156.0, 19.0, 38.0, 15.0, 25.0, 11.0, 73.0, 6.0, 0.0, 15.0, 91.0, 33.0, 12.0, 48.0, 17.0, 22.0, 42.0, 6.0, 0.0, 140.0, 146.0, 27.0, 20.0, 6.0, 0.0, 62.0, 84.0, 43.0, 9.0, 38.0, 0.0, 91.0, 36.0, 55.0, 47.0, 43.0, 24.0, 66.0, 22.0, 57.0, 71.0, 36.0, 47.0, 43.0, 45.0, 21.0, 21.0, 20.0, 49.0, 72.0, 64.0, 49.0, 0.0, 70.0, 61.0, 0.0, 0.0, 22.0, 89.0, 81.0, 68.0, 40.0, 13.0, 47.0, 86.0, 13.0, 5.0, 3.0, 0.0, 23.0, 42.0, 89.0, 52.0, 35.0, 87.0, 23.0, 73.0, 39.0, 31.0, 128.0, 22.0, 91.0, 85.0, 43.0, 61.0, 0.0, 0.0, 167.0, 139.0, 99.0, 0.0, 28.0, 63.0, 80.0, 96.0, 50.0, 86.0, 39.0, 81.0, 31.0, 83.0, 36.0, 39.0, 88.0, 29.0, 33.0, 57.0, 35.0, 51.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0746681562161207, "mean_inference_ms": 2.6249771334644896, "mean_action_processing_ms": 0.4250982721963497, "mean_env_wait_ms": 0.3342166757067617, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006261348724365234, "StateBufferConnector_ms": 0.003615260124206543, "ViewRequirementAgentConnector_ms": 0.1539442539215088}, "num_episodes": 22, "episode_return_max": 289.69999999999993, "episode_return_min": -439.0, "episode_return_mean": 53.31699999999994, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1568000, "num_agent_steps_trained": 1568000, "num_env_steps_sampled": 392000, "num_env_steps_trained": 392000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 72.95127671439228, "num_env_steps_trained_throughput_per_sec": 72.95127671439228, "timesteps_total": 392000, "num_env_steps_sampled_lifetime": 392000, "num_agent_steps_sampled_lifetime": 1568000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1568000, "timers": {"training_iteration_time_ms": 56160.839, "restore_workers_time_ms": 0.022, "training_step_time_ms": 56160.73, "sample_time_ms": 1685.755, "learn_time_ms": 54448.997, "learn_throughput": 73.463, "synch_weights_time_ms": 21.868}, "counters": {"num_env_steps_sampled": 392000, "num_env_steps_trained": 392000, "num_agent_steps_sampled": 1568000, "num_agent_steps_trained": 1568000}, "done": false, "training_iteration": 98, "trial_id": "11e70_00000", "date": "2024-08-13_00-44-54", "timestamp": 1723524294, "time_this_iter_s": 54.86756992340088, "time_total_s": 5870.389189243317, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3f6f790>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 5870.389189243317, "iterations_since_restore": 98, "perf": {"cpu_util_percent": 41.30897435897435, "ram_util_percent": 78.72051282051282}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 10.676814112146065, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.540606147271616, "policy_loss": -0.007131737559816983, "vf_loss": 6.546990982186857, "vf_explained_var": 0.09523344311133894, "kl": 0.006639149488936756, "entropy": 0.7167908381848108, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 186165.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 9.757308939083543, "cur_kl_coeff": 0.16875, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.205313710560874, "policy_loss": -0.010367148971214653, "vf_loss": 6.2139786084493, "vf_explained_var": -0.5588465996204861, "kl": 0.010087504557984475, "entropy": 0.878969127065921, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 186165.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 396000, "num_env_steps_trained": 396000, "num_agent_steps_sampled": 1584000, "num_agent_steps_trained": 1584000}, "env_runners": {"episode_reward_max": 289.69999999999993, "episode_reward_min": -311.0, "episode_reward_mean": 74.20699999999992, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 184.7, "predator_policy": 190.0}, "policy_reward_mean": {"prey_policy": -23.471500000000013, "predator_policy": 60.575}, "custom_metrics": {}, "hist_stats": {"episode_reward": [74.99999999999997, 81.59999999999994, -61.99999999999984, 256.5999999999999, -52.999999999999986, 207.69999999999996, 5.699999999999966, -30.899999999999842, 1.9999999999999631, 145.3999999999997, 54.00000000000026, 181.8, 201.59999999999926, -311.0, 177.7999999999992, 45.90000000000023, 40.0000000000003, 99.0999999999998, -115.40000000000077, 134.99999999999997, -17.70000000000001, 130.29999999999995, 47.0, -259.9, 100.79999999999998, 289.69999999999993, 12.099999999999994, 5.999999999999995, 99.69999999999993, 148.69999999999965, -29.299999999999713, 33.400000000000205, 70.39999999999998, 126.09999999999965, 268.5, 270.5, 194.49999999999926, -94.00000000000026, 251.4, 173.79999999999944, 210.3, 175.4000000000001, 115.19999999999956, 98.30000000000001, 214.0, 182.29999999999995, 51.20000000000005, 39.30000000000018, 222.59999999999997, 44.00000000000013, 128.19999999999965, 221.19999999999996, 28.400000000000063, 119.29999999999984, -1.4999999999999716, 40.0000000000003, 59.500000000000014, 97.19999999999999, 280.79999999999995, 138.8, 254.19999999999993, 36.70000000000025, 155.99999999999946, -2.8999999999999715, 27.000000000000114, 199.89999999999998, 173.89999999999986, 81.7, -22.5, 67.20000000000013, 40.0000000000003, 120.99999999999997, -5.900000000000091, 179.29999999999995, 83.70000000000002, 137.29999999999995, -39.79999999999997, 11.5, 131.79999999999964, -13.999999999999979, 60.999999999999915, 157.2, 73.99999999999932, 32.99999999999998, 8.699999999999996, -234.0, 37.00000000000001, -155.60000000000136, 26.500000000000156, 40.0000000000003, 84.59999999999945, 40.0000000000003, 49.499999999999574, -25.599999999999994, 139.59999999999957, 2.200000000000169, 40.0000000000003, -100.30000000000001, 125.39999999999966, -22.0], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-283.0, 50.00000000000001, 20.000000000000014, 35.60000000000015, -388.0, 20.000000000000014, 109.4, 108.19999999999997, 20.000000000000014, -400.0, -295.0, 184.7, -7.299999999999891, -73.00000000000003, 28.099999999999987, -358.0, 20.000000000000014, -376.0, 20.000000000000014, 31.400000000000006, -274.0, 20.000000000000014, -115.0, 105.8, 20.000000000000014, 179.59999999999997, -250.0, -352.0, 144.79999999999993, 20.000000000000014, 20.900000000000013, -256.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 31.100000000000044, -116.50000000000077, -334.9, 96.8, -164.8, -231.10000000000002, -49.600000000000016, 14.00000000000002, 23.30000000000001, -109.0, 38.0, -337.9, -217.0, -94.0, 60.79999999999998, 62.900000000000006, 162.79999999999995, -229.0, 46.10000000000001, -355.0, 20.000000000000014, 20.000000000000014, 22.69999999999999, 20.000000000000014, 88.7, -133.3000000000005, 20.000000000000014, 20.000000000000014, 7.399999999999965, -41.80000000000001, 6.200000000000022, 61.10000000000005, 20.000000000000014, 123.49999999999997, 80.0, 53.0, 153.5, 168.49999999999994, 20.000000000000014, 20.000000000000014, -400.0, 110.0, 94.4, 20.000000000000014, 147.79999999999998, 129.2, -64.9, 30.499999999999957, 92.89999999999998, 20.000000000000014, 57.2, 17.0, -45.7, 113.0, -1.0, 41.0, 74.29999999999998, 20.000000000000014, -56.80000000000001, 20.000000000000014, -108.7, 46.1, 93.5, 20.000000000000014, -64.0, 20.000000000000014, 66.2, 104.6, 47.6, -127.6, 20.000000000000014, 50.3, 20.000000000000014, -113.5, -19.0, 20.000000000000014, 20.000000000000014, 52.4, -103.90000000000006, -111.70000000000005, 59.9, 109.1, 118.69999999999999, -28.900000000000006, 34.7, 94.39999999999999, 141.79999999999995, 20.000000000000014, 13.699999999999964, 20.000000000000014, 71.0, 20.000000000000014, -163.89999999999998, 20.000000000000014, -115.0, 53.0, 50.89999999999998, 57.20000000000002, 46.7, 56.29999999999998, -124.6, -77.5, -121.0, 20.000000000000014, -56.8, 20.000000000000014, 20.000000000000014, 151.99999999999997, -337.0, -50.500000000000014, -54.4, 63.5, 24.799999999999997, 88.7, -181.0, 38.0, -36.699999999999996, -112.0, -47.8, -63.4, -39.099999999999994, 36.8, 20.000000000000014, -151.0, 20.000000000000014, -49.0, 20.000000000000014, -16.0, 87.2, -49.0, 20.000000000000014, 6.800000000000011, -161.8, -246.1, 27.800000000000004, -217.0, -211.0, 61.70000000000002, -180.70000000000002, -106.00000000000068, -118.60000000000068, -152.19999999999993, 52.700000000000024, 20.000000000000014, 20.000000000000014, -3.4000000000000057, 20.000000000000014, 20.000000000000014, 20.000000000000014, -25.0, -11.500000000000007, -52.0, -106.6, 20.000000000000014, 86.59999999999997, 20.000000000000014, -125.80000000000001, 20.000000000000014, 20.000000000000014, -212.5, -62.8, 100.39999999999998, 20.000000000000014, -34.0, -136.0], "policy_predator_policy_reward": [157.0, 151.0, 7.0, 19.0, 116.0, 190.0, 26.0, 13.0, 184.0, 143.0, 154.0, 164.0, 16.0, 70.0, 173.0, 126.0, 170.0, 188.0, 42.0, 52.0, 155.0, 153.0, 114.0, 77.0, 2.0, 0.0, 143.0, 148.0, 13.0, 0.0, 142.0, 139.0, 0.0, 0.0, 19.0, 29.0, 159.0, 177.0, 108.0, 95.0, 129.0, 134.0, 18.0, 75.0, 51.0, 67.0, 127.0, 168.0, 73.0, 61.0, 44.0, 20.0, 67.0, 128.0, 185.0, 156.0, 19.0, 38.0, 15.0, 25.0, 11.0, 73.0, 6.0, 0.0, 15.0, 91.0, 33.0, 12.0, 48.0, 17.0, 22.0, 42.0, 6.0, 0.0, 140.0, 146.0, 27.0, 20.0, 6.0, 0.0, 62.0, 84.0, 43.0, 9.0, 38.0, 0.0, 91.0, 36.0, 55.0, 47.0, 43.0, 24.0, 66.0, 22.0, 57.0, 71.0, 36.0, 47.0, 43.0, 45.0, 21.0, 21.0, 20.0, 49.0, 72.0, 64.0, 49.0, 0.0, 70.0, 61.0, 0.0, 0.0, 22.0, 89.0, 81.0, 68.0, 40.0, 13.0, 47.0, 86.0, 13.0, 5.0, 3.0, 0.0, 23.0, 42.0, 89.0, 52.0, 35.0, 87.0, 23.0, 73.0, 39.0, 31.0, 128.0, 22.0, 91.0, 85.0, 43.0, 61.0, 0.0, 0.0, 167.0, 139.0, 99.0, 0.0, 28.0, 63.0, 80.0, 96.0, 50.0, 86.0, 39.0, 81.0, 31.0, 83.0, 36.0, 39.0, 88.0, 29.0, 33.0, 57.0, 35.0, 51.0, 40.0, 63.0, 94.0, 94.0, 112.0, 115.0, 85.0, 109.0, 47.0, 109.0, 69.0, 0.0, 44.0, 82.0, 0.0, 0.0, 24.0, 44.0, 0.0, 0.0, 45.0, 41.0, 55.0, 78.0, 33.0, 0.0, 47.0, 61.0, 0.0, 0.0, 60.0, 115.0, 0.0, 5.0, 38.0, 110.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.07266706834281, "mean_inference_ms": 2.6193475646398325, "mean_action_processing_ms": 0.4241561086867509, "mean_env_wait_ms": 0.3334931853415256, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005189418792724609, "StateBufferConnector_ms": 0.0037500858306884766, "ViewRequirementAgentConnector_ms": 0.14971983432769775}, "num_episodes": 18, "episode_return_max": 289.69999999999993, "episode_return_min": -311.0, "episode_return_mean": 74.20699999999992, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1584000, "num_agent_steps_trained": 1584000, "num_env_steps_sampled": 396000, "num_env_steps_trained": 396000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 72.01629115707348, "num_env_steps_trained_throughput_per_sec": 72.01629115707348, "timesteps_total": 396000, "num_env_steps_sampled_lifetime": 396000, "num_agent_steps_sampled_lifetime": 1584000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1584000, "timers": {"training_iteration_time_ms": 56106.9, "restore_workers_time_ms": 0.022, "training_step_time_ms": 56106.79, "sample_time_ms": 1664.183, "learn_time_ms": 54416.924, "learn_throughput": 73.507, "synch_weights_time_ms": 21.428}, "counters": {"num_env_steps_sampled": 396000, "num_env_steps_trained": 396000, "num_agent_steps_sampled": 1584000, "num_agent_steps_trained": 1584000}, "done": false, "training_iteration": 99, "trial_id": "11e70_00000", "date": "2024-08-13_00-45-50", "timestamp": 1723524350, "time_this_iter_s": 55.59555697441101, "time_total_s": 5925.984746217728, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3f6f1f0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 5925.984746217728, "iterations_since_restore": 99, "perf": {"cpu_util_percent": 44.082499999999996, "ram_util_percent": 78.39625}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 12.32570607372062, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.333205365882349, "policy_loss": -0.00845206238270279, "vf_loss": 6.340894600449416, "vf_explained_var": 0.10629284173723251, "kl": 0.006780784341996853, "entropy": 0.6893190164730032, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 188055.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 15.992760578539006, "cur_kl_coeff": 0.16875, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.4067193340372155, "policy_loss": -0.011090341765216734, "vf_loss": 5.4160550514856975, "vf_explained_var": -0.7685790849741174, "kl": 0.010397832389759845, "entropy": 0.7780287622459351, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 188055.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 400000, "num_env_steps_trained": 400000, "num_agent_steps_sampled": 1600000, "num_agent_steps_trained": 1600000}, "env_runners": {"episode_reward_max": 289.69999999999993, "episode_reward_min": -259.9, "episode_reward_mean": 70.96899999999997, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 168.49999999999994, "predator_policy": 185.0}, "policy_reward_mean": {"prey_policy": -12.80050000000001, "predator_policy": 48.285}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-259.9, 100.79999999999998, 289.69999999999993, 12.099999999999994, 5.999999999999995, 99.69999999999993, 148.69999999999965, -29.299999999999713, 33.400000000000205, 70.39999999999998, 126.09999999999965, 268.5, 270.5, 194.49999999999926, -94.00000000000026, 251.4, 173.79999999999944, 210.3, 175.4000000000001, 115.19999999999956, 98.30000000000001, 214.0, 182.29999999999995, 51.20000000000005, 39.30000000000018, 222.59999999999997, 44.00000000000013, 128.19999999999965, 221.19999999999996, 28.400000000000063, 119.29999999999984, -1.4999999999999716, 40.0000000000003, 59.500000000000014, 97.19999999999999, 280.79999999999995, 138.8, 254.19999999999993, 36.70000000000025, 155.99999999999946, -2.8999999999999715, 27.000000000000114, 199.89999999999998, 173.89999999999986, 81.7, -22.5, 67.20000000000013, 40.0000000000003, 120.99999999999997, -5.900000000000091, 179.29999999999995, 83.70000000000002, 137.29999999999995, -39.79999999999997, 11.5, 131.79999999999964, -13.999999999999979, 60.999999999999915, 157.2, 73.99999999999932, 32.99999999999998, 8.699999999999996, -234.0, 37.00000000000001, -155.60000000000136, 26.500000000000156, 40.0000000000003, 84.59999999999945, 40.0000000000003, 49.499999999999574, -25.599999999999994, 139.59999999999957, 2.200000000000169, 40.0000000000003, -100.30000000000001, 125.39999999999966, -22.0, -11.499999999999993, 14.399999999999974, 34.59999999999994, 119.89999999999966, -143.7999999999999, -5.999999999999986, 40.0000000000003, 40.00000000000018, 80.9, 48.09999999999988, 213.89999999999995, 11.600000000000144, 33.400000000000205, 31.20000000000026, 33.40000000000023, 40.0000000000003, 126.19999999999975, 28.900000000000105, 27.00000000000027, 99.99999999999979, 39.80000000000015, -15.29999999999994, 85.99999999999983], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-337.9, -217.0, -94.0, 60.79999999999998, 62.900000000000006, 162.79999999999995, -229.0, 46.10000000000001, -355.0, 20.000000000000014, 20.000000000000014, 22.69999999999999, 20.000000000000014, 88.7, -133.3000000000005, 20.000000000000014, 20.000000000000014, 7.399999999999965, -41.80000000000001, 6.200000000000022, 61.10000000000005, 20.000000000000014, 123.49999999999997, 80.0, 53.0, 153.5, 168.49999999999994, 20.000000000000014, 20.000000000000014, -400.0, 110.0, 94.4, 20.000000000000014, 147.79999999999998, 129.2, -64.9, 30.499999999999957, 92.89999999999998, 20.000000000000014, 57.2, 17.0, -45.7, 113.0, -1.0, 41.0, 74.29999999999998, 20.000000000000014, -56.80000000000001, 20.000000000000014, -108.7, 46.1, 93.5, 20.000000000000014, -64.0, 20.000000000000014, 66.2, 104.6, 47.6, -127.6, 20.000000000000014, 50.3, 20.000000000000014, -113.5, -19.0, 20.000000000000014, 20.000000000000014, 52.4, -103.90000000000006, -111.70000000000005, 59.9, 109.1, 118.69999999999999, -28.900000000000006, 34.7, 94.39999999999999, 141.79999999999995, 20.000000000000014, 13.699999999999964, 20.000000000000014, 71.0, 20.000000000000014, -163.89999999999998, 20.000000000000014, -115.0, 53.0, 50.89999999999998, 57.20000000000002, 46.7, 56.29999999999998, -124.6, -77.5, -121.0, 20.000000000000014, -56.8, 20.000000000000014, 20.000000000000014, 151.99999999999997, -337.0, -50.500000000000014, -54.4, 63.5, 24.799999999999997, 88.7, -181.0, 38.0, -36.699999999999996, -112.0, -47.8, -63.4, -39.099999999999994, 36.8, 20.000000000000014, -151.0, 20.000000000000014, -49.0, 20.000000000000014, -16.0, 87.2, -49.0, 20.000000000000014, 6.800000000000011, -161.8, -246.1, 27.800000000000004, -217.0, -211.0, 61.70000000000002, -180.70000000000002, -106.00000000000068, -118.60000000000068, -152.19999999999993, 52.700000000000024, 20.000000000000014, 20.000000000000014, -3.4000000000000057, 20.000000000000014, 20.000000000000014, 20.000000000000014, -25.0, -11.500000000000007, -52.0, -106.6, 20.000000000000014, 86.59999999999997, 20.000000000000014, -125.80000000000001, 20.000000000000014, 20.000000000000014, -212.5, -62.8, 100.39999999999998, 20.000000000000014, -34.0, -136.0, -86.5, -103.0, 20.000000000000014, -109.60000000000002, -105.4, 20.000000000000014, -32.20000000000003, 88.1, -199.0, -86.80000000000003, -127.0, -133.00000000000003, 20.000000000000014, 20.000000000000014, -70.0, 20.000000000000014, -0.09999999999998188, 20.000000000000014, 20.000000000000014, -37.89999999999999, 65.89999999999999, 95.0, 7.399999999999965, -77.80000000000001, 7.399999999999965, 20.000000000000014, 3.1999999999999806, 20.000000000000014, 20.000000000000014, 7.399999999999973, 20.000000000000014, 20.000000000000014, 91.7, -11.499999999999819, -90.1, 20.000000000000014, -85.0, 20.000000000000014, 20.000000000000014, 11.0, -82.0, 15.799999999999962, -160.0, 13.70000000000001, -7.59999999999998, 20.600000000000023], "policy_predator_policy_reward": [127.0, 168.0, 73.0, 61.0, 44.0, 20.0, 67.0, 128.0, 185.0, 156.0, 19.0, 38.0, 15.0, 25.0, 11.0, 73.0, 6.0, 0.0, 15.0, 91.0, 33.0, 12.0, 48.0, 17.0, 22.0, 42.0, 6.0, 0.0, 140.0, 146.0, 27.0, 20.0, 6.0, 0.0, 62.0, 84.0, 43.0, 9.0, 38.0, 0.0, 91.0, 36.0, 55.0, 47.0, 43.0, 24.0, 66.0, 22.0, 57.0, 71.0, 36.0, 47.0, 43.0, 45.0, 21.0, 21.0, 20.0, 49.0, 72.0, 64.0, 49.0, 0.0, 70.0, 61.0, 0.0, 0.0, 22.0, 89.0, 81.0, 68.0, 40.0, 13.0, 47.0, 86.0, 13.0, 5.0, 3.0, 0.0, 23.0, 42.0, 89.0, 52.0, 35.0, 87.0, 23.0, 73.0, 39.0, 31.0, 128.0, 22.0, 91.0, 85.0, 43.0, 61.0, 0.0, 0.0, 167.0, 139.0, 99.0, 0.0, 28.0, 63.0, 80.0, 96.0, 50.0, 86.0, 39.0, 81.0, 31.0, 83.0, 36.0, 39.0, 88.0, 29.0, 33.0, 57.0, 35.0, 51.0, 40.0, 63.0, 94.0, 94.0, 112.0, 115.0, 85.0, 109.0, 47.0, 109.0, 69.0, 0.0, 44.0, 82.0, 0.0, 0.0, 24.0, 44.0, 0.0, 0.0, 45.0, 41.0, 55.0, 78.0, 33.0, 0.0, 47.0, 61.0, 0.0, 0.0, 60.0, 115.0, 0.0, 5.0, 38.0, 110.0, 105.0, 73.0, 41.0, 63.0, 87.0, 33.0, 34.0, 30.0, 57.0, 85.0, 146.0, 108.0, 0.0, 0.0, 44.0, 46.0, 41.0, 20.0, 58.0, 8.0, 32.0, 21.0, 45.0, 37.0, 0.0, 6.0, 5.0, 3.0, 3.0, 3.0, 0.0, 0.0, 36.0, 10.0, 56.0, 43.0, 22.0, 70.0, 34.0, 35.0, 68.0, 38.0, 104.0, 27.0, 45.0, 28.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0707973310529753, "mean_inference_ms": 2.6099822184508445, "mean_action_processing_ms": 0.4228570511645747, "mean_env_wait_ms": 0.33218476328730007, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004868984222412109, "StateBufferConnector_ms": 0.003783583641052246, "ViewRequirementAgentConnector_ms": 0.12389004230499268}, "num_episodes": 23, "episode_return_max": 289.69999999999993, "episode_return_min": -259.9, "episode_return_mean": 70.96899999999997, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1600000, "num_agent_steps_trained": 1600000, "num_env_steps_sampled": 400000, "num_env_steps_trained": 400000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 78.79091980177142, "num_env_steps_trained_throughput_per_sec": 78.79091980177142, "timesteps_total": 400000, "num_env_steps_sampled_lifetime": 400000, "num_agent_steps_sampled_lifetime": 1600000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1600000, "timers": {"training_iteration_time_ms": 55911.895, "restore_workers_time_ms": 0.022, "training_step_time_ms": 55911.79, "sample_time_ms": 1597.601, "learn_time_ms": 54290.464, "learn_throughput": 73.678, "synch_weights_time_ms": 20.03}, "counters": {"num_env_steps_sampled": 400000, "num_env_steps_trained": 400000, "num_agent_steps_sampled": 1600000, "num_agent_steps_trained": 1600000}, "done": true, "training_iteration": 100, "trial_id": "11e70_00000", "date": "2024-08-13_00-46-41", "timestamp": 1723524401, "time_this_iter_s": 50.81025290489197, "time_total_s": 5976.79499912262, "pid": 3814, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2b67d30>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10, 3), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 5976.79499912262, "iterations_since_restore": 100, "perf": {"cpu_util_percent": 30.572222222222226, "ram_util_percent": 74.66944444444442}}
